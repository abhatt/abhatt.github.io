<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" class="message" title="internal server error">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" class="message" title="internal server error">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" class="message" title="internal server error">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" class="message" title="internal server error">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" class="message" title="internal server error">CS Theory Events</a>
<br>
<a class="feedlink" href="https://cstheory.stackexchange.com/feeds/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" class="message" title="internal server error">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" class="message" title="internal server error">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" class="message" title="internal server error">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" class="message" title="internal server error">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" class="message" title="internal server error">Gil Kalai</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" class="message" title="internal server error">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" class="message" title="internal server error">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="internal server error">Luca Aceto</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" class="message" title="internal server error">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" class="message" title="internal server error">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" class="message" title="internal server error">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" class="message" title="internal server error">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" class="message" title="internal server error">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" class="message" title="internal server error">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" class="message" title="internal server error">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" class="message" title="internal server error">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="internal server error">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="internal server error">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="internal server error">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" class="message" title="internal server error">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A> &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at January 08, 2019 12:42 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42171">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation">Minimum relevant variables in linear system - additive approximation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the problem <a href="https://en.wikipedia.org/wiki/Minimum_relevant_variables_in_linear_system" rel="nofollow noreferrer">Minimum Relevant Variables in Linear System</a> (Min-RVLS), the input is a linear system, e.g.:</p>

<p><span class="math-container">$$ A x = b $$</span></p>

<p>and the goal is to find a solution <span class="math-container">$x$</span> with as few nonzero variables as possible. </p>

<p>The problem is known to be NP-hard and hard to approximate to within a constant multiplicative factor (see the wikipedia page for details). </p>

<p>My question is: is anything known about <em>additive</em> approximations? In particular: what is the complexity of finding a solution that has at most <span class="math-container">$\text{OPT}+d$</span> nonzero variables, where <span class="math-container">$\text{OPT}$</span> is the smallest number of nonzero variables in a solution, and <span class="math-container">$d$</span> is some constant?</p>

<p>A related problem is: there always exists a solution with at most <span class="math-container">$m$</span> nonzero variables, where <span class="math-container">$m$</span> is the number of constraints (number of rows in <span class="math-container">$A$</span>). What is the complexity of finding a solution that has at most <span class="math-container">$m-d$</span> nonzero variables, for some constant <span class="math-container">$d$</span>?</p></div>







<p class="date">
by Erel Segal-Halevi <a href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation"><span class="datestr">at January 07, 2019 04:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42170">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42170/is-there-exists-a-polynomial-time-algorithm-to-find-a-order-k-subgroup">Is there exists a polynomial time algorithm to find a order $k$ subgroup?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>How to find subgroups ( unique up to isomorphism) of order <span class="math-container">$k$</span> of a group <span class="math-container">$G$</span>, when the input group is given in the <a href="http://mathworld.wolfram.com/MultiplicationTable.html" rel="nofollow noreferrer">explicit</a> form. The idea coming to my mind follows, try all possible subsets of size <span class="math-container">$k$</span> and then check whether they form a subgroup of <span class="math-container">$G$</span> or not which can be checked in polynomial time but overall runtime may not be polynomial in the order of the group <span class="math-container">$G$</span> depending upon the value of <span class="math-container">$k$</span>. What is the fastest known algorithm for the task described above? What if the input group is a <span class="math-container">$p$</span>-group? Is it possible to find an order <span class="math-container">$k$</span> subgroup in polynomial time, when <span class="math-container">$k$</span> is very large? </p></div>







<p class="date">
by aaaa <a href="https://cstheory.stackexchange.com/questions/42170/is-there-exists-a-polynomial-time-algorithm-to-find-a-order-k-subgroup"><span class="datestr">at January 07, 2019 03:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42169">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition">Optimal algorithm to compare lines of different files without repetition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have 1600 ASCII files with 1000 lines in each file. Each line has only one entry and is a floating point number e.g. 1.67923.
Let's denote the line1 of file1 with <code>L(1,1)</code>, line2 of file1 with <code>L(1,2)</code> and so forth to ...<code>L(1,1000)</code>. Similarly, line1 of file2 will be <code>L(2,1)</code> and the last line of file1600 will thus be <code>L(1600,1000)</code>.
My task is to come up with a memory efficient algorithm to compare all lines between each file and the lines within each file. Since, I have 1600 files and 1000 lines in each file, it will take approx. <code>10^12</code> calculations. These first comparisons will look like this:</p>

<pre><code>1. {L(1,1)-L(1,2)}, {L(1,1)-L(1,3)},....,{L(1,1)-L(1,1000)}
2. {L(1,1)-L(2,1)}, {L(1,1)-L(2,2)},....,{L(1,1)-L(2,1000)}
3. {L(1,1)-L(3,1)}, {L(1,1)-L(3,2)},....,{L(1,1)-L(3,1000)}
.
.
. 
</code></pre>

<p>Please note that I don't want repetitions i.e <code>{L(1,1)-L(2,1)} = {L(2,1)-L(1,1)}</code>.
I need to code this problem in Fortran but any help on a general scheme as to how the problem needs to be approached will be useful.
Thank you in advance!  </p></div>







<p class="date">
by Abedin Y. Abedin <a href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition"><span class="datestr">at January 07, 2019 03:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42167">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs">Decomposition for a certain class of graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Suppose a graph, <span class="math-container">$G = (V,E)$</span> is characterized as a lattice/network of cliques as in the picture below. Does there exist some decomposition principle (i.e. on the right) for <span class="math-container">$G$</span>, that yields some special structure that may be used to explain efficiencies experienced with what are supposed to be combinatorial hard problems?</p>

<p><a href="https://i.stack.imgur.com/FTbx8.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/FTbx8.png" alt="enter image description here" /></a></p></div>







<p class="date">
by Student <a href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs"><span class="datestr">at January 07, 2019 06:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42166">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings">Algorithm for K-best NON perfect bipartite matchings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I was reading this great article: <a href="https://core.ac.uk/download/pdf/82129717.pdf" rel="nofollow noreferrer">https://core.ac.uk/download/pdf/82129717.pdf</a></p>

<p>It solves a generalization of the maximum sum assignment problem by finding the k best assignments and not only the best.
However, it only looks at perfect matchings. I'm am especially interested in bipartite matchings.</p>

<p>In particular, for the bipartite graphs, the Theorem 1 p. 161 uses the fact that the matchings are considered perfect.</p>

<p>How can I solve the k-best assignment problem for general bipartite graphs?</p></div>







<p class="date">
by Labo <a href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings"><span class="datestr">at January 06, 2019 11:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15562">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/">Predictions For 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>The problem of predicting ‘when’ not just ‘what’</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg"><img src="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg?w=180&amp;h=167" alt="" width="180" class="alignright wp-image-15564" height="167" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Toronto Star <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s <em>1984</em>. He wrote an exclusive <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">feature</a> for the Toronto Star newspaper predicting what the world would be like 35 years hence, that is, in 2019.</p>
<p>
Today we give our take on his predictions and make our own for the rest of 2019.</p>
<p>
Asimov’s essay began by presupposing the absence of nuclear holocaust without predicting it. It then focused on two subjects: computerization and use of outer space. On the spectrum of evaluations subtended by this laudatory BBC <a href="https://www.bbc.com/news/technology-46736024">piece</a> and this critical <a href="https://www.thestar.com/news/world/2018/12/27/isaac-asimov-you-were-no-nostradamus.html">column</a> in the Toronto Star itself, we’re closer to the latter. On space he predicted we’d be mining the Moon by now; instead nothing more landed on the Moon until the Chinese <a href="https://en.wikipedia.org/wiki/Chang'e_3">Chang’e 3</a> mission in 2013 and <a href="https://en.wikipedia.org/wiki/Chang'e_4">Chang’e 4</a> happening now. His 35-year span should be lengthened to over a century.</p>
<p>
On computerization and robotics he was mostly right except again for the timespan: he said the transition would be “about over” by 2019 whereas it may be entering its period of greatest flux only now. However, for the end of 1983 we think the “whats” of his predictions were easy. Personal computers had already been around for almost a decade. Computer systems for business were plentiful. The Internet was already a proclaimed goal and the text-based <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a> was already operating. Asimov’s essay seems to miss how the combination of these three would soon move points of control outward to end-users. </p>
<p>
We still think what he wrote about space and robots will happen. This shows the problem of predictions is not just ‘what’ but ‘when.’ For another instance of being wrong on ‘when’ too soon, Ken told a Harvard Law graduate who visited him in Oxford in 1984 that what we now call <a href="https://en.wikipedia.org/wiki/Deepfake">deepfake</a> videos were imminent. We’ll make the rest of this post more about ‘when’ than ‘what.’</p>
<p>
</p><p></p><h2> Predictions in Past Years </h2><p></p>
<p></p><p>
Here are some predictions that we have made before. Seems we did not make any new predictions last year—oh well—but see <a href="https://rjlipton.wordpress.com/2018/01/02/predictions-we-didnt-make/">this</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>No circuit lower bound of <img src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1000n}" class="latex" title="{1000n}" /> or better will be proved for SAT.</em> Well that’s a freebie.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>At least five claims that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}=\mathsf{NP}}" class="latex" title="{\mathsf{P}=\mathsf{NP}}" /> and five that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" title="{\mathsf{P} \neq \mathsf{NP}}" /> will be made.</em> </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> A “provably” secure crypto-system will be broken. For this one we don’t have to check any claims. We just pocket the ‘yes’ answer. Really, could you ever prove the opposite? How about the <a href="https://cacm.acm.org/magazines/2019/1/233523-imperfect-forward-secrecy/abstract">attack</a> on Diffie-Hellman in the current CACM?</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>An Earth-sized planet will be detected orbiting within the habitable zone of its single star.</em> The “when” for this one came in 2017 already. We are retiring it.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>A Clay problem will be solved, or at least notable progress made.</em> Again we sense that the answer on progress is “no.” This includes saying that nothing substantial seems to have emerged from Sir Michael Atiyah’s <a href="https://aperiodical.com/2018/09/atiyah-riemann-hypothesis-proof-final-thoughts/">claim</a> of proving the Riemann Hypothesis. However, we note <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">via</a> Gil Kalai’s blog that a longstanding problem called the <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" />-conjecture for spheres has been <a href="https://arxiv.org/abs/1812.10454">solved</a> by Karim Adiprasito.</p>
<p>
</p><p></p><h2> Predictions This Year </h2><p></p>
<p></p><p>
We will add some new predictions—it seems unfair to keep repeating sure winners. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Deep learning methods will be found able to solve integer factoring.</em> This will place current cryptography is trouble.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Deep learning methods will be found to help prove that factoring is hard.</em></p>
<p>
These may not be as contradictory as they seem. There is a long-known <a href="http://www.cs.sfu.ca/~kabanets/papers/natural-learning-short.pdf">connection</a> between certain learning algorithms and the <a href="https://en.wikipedia.org/wiki/Natural_proof">natural</a> <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">proofs</a> of Alexander Razborov and Stephen Rudich. The hardness predicate at the core of a natural proof is a classifier to distinguish (succinct) hard Boolean functions from easy ones. There is a duality between upper and lower bounds that in particular leads to the unconditional result that the discrete log problem, which is related to factoring and equally amenable to Peter Shor’s famous polynomial-time quantum algorithm, does not have natural proofs of hardness—because their existence would make discrete log relatively easy. </p>
<p>
Talking about quantum, we predict:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>An algorithm originating in a theoretical model will be enshrined in law.</em> </p>
<p>
There are several near-term opportunities for this. The Supreme Court yesterday agreed to <a href="https://www.cnn.com/2019/01/04/politics/supreme-court-gerrymandering-cases/index.html">hear</a> two cases on partisan gerrymandering, at least one of which promises to codify an algorithmic criterion for excessive vote dilution. Maine adopted a automatic-runoff voting system whose dependence on computer implementation gave grounds for an unsuccessful <a href="https://www.americanthinker.com/blog/2018/11/maine_gop_rep_sues_to_stop_counting_ranked_choice_ballots.html">lawsuit</a>. Algorithmic fairness is a burgeoning area which we <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">discussed</a> a year-plus ago. <a href="https://www.sciencemag.org/news/2019/01/can-set-equations-keep-us-census-data-private">Use</a> of differential privacy by the U.S. Census could involve legislation. We distinguish legal provisions from the myriad problematic uses of algorithmic models in public and private <em>policy</em> ranging from credit evaluations to parole decisions to college admissions and much else.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>The lines between heuristically solvable and really hard problems will become clearer.</em> We have <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">previously</a> <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">opined</a> that the great success of SAT solvers in particular renders the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P=NP}}" class="latex" title="{\mathsf{P=NP}}" /> question moot for many purposes. Well, now we say the opposite: SAT solvers will hit a wall.</p>
<p>
</p><p></p><h2> Quantum Supremacy and Advantage </h2><p></p>
<p></p><p>
Ken recently attended a workshop in central New York that aimed to bring together researchers in many fields working on quantum devices. Materials for the workshop led off with the question of building quantum computers and highlighted Gil Kalai’s skeptical position in particular. An <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">eight</a>–<a href="https://rjlipton.wordpress.com/2012/02/15/nature-does-not-conspire/">part</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">debate</a> between him and Aram Harrow which we hosted in 2012 <a href="https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/">involved</a> also John Preskill and <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">ended</a> with a discussion of quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>, a term advanced that year by Preskill. The workshop preferred the term quantum <em>advantage</em>. We interpret these terms as having the following distinction:</p>
<ul>
<li>
(a) Quantum <em>supremacy</em> means that a quantum device can perform general-purpose computations that no classical program or device can emulate in comparably feasible time. <p></p>
</li><li>
(b) Quantum <em>advantage</em> means that some particular practical task can be achieved by available quantum devices at lower costs than near-term available classical devices.
</li></ul>
<p>
As theoreticians we tend to think about (a) but many businesses and public-sector organizations would be ecstatic to have (b) in important applications. </p>
<p>
A new angle on (a) was shown by the new construction by Ran Raz and Avishay Tal of an oracle <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{BQP}^A}" class="latex" title="{\mathsf{BQP}^A}" /> is not in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPH%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{PH}^A}" class="latex" title="{\mathsf{PH}^A}" />. This was <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">hailed</a> as the “result of the year” by Lance Fortnow (his second and our first is this <a href="https://eccc.weizmann.ac.il/report/2018/006/">progress</a> on the Unique Games Conjecture), and Scott Aaronson furnished a great <a href="https://www.scottaaronson.com/blog/?p=3827">discussion</a> of its genesis and further ramifications in complexity theory. <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Several</a> <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">popular</a> <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">articles</a> tried to pump this as non-oracle evidence for (a). But there is the over-arching problem:</p>
<blockquote><p><b> </b> <em> We know <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Csubseteq+BPP+%5Csubseteq+BQP+%5Csubseteq+PP+%5Csubseteq+P%5E%7B%5C%23P%7D+%5Csubseteq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" class="latex" title="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" /> but we don’t know <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq PSPACE}}" class="latex" title="{\mathsf{P \neq PSPACE}}" />. </em>
</p></blockquote>
<p></p><p>
So how are we ever going to be able to <em>prove</em> any form of supremacy? Even if we replace ‘polynomial time’ as our definition of ‘feasible’ by something more concrete, how can we prove that successful classical heuristics <em>do not exist</em>? On a certain practical problem of general import, Ewin Tang, a teenager in Texas advised by Scott, <a href="https://arxiv.org/abs/1807.04271">designed</a> an improved classical algorithm for low-rank matrix completion that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">eliminated</a> a previous quantum exponential advantage in the time dependence on the rank parameter. It is not just a case of <em>whether</em> we can prove supremacy, but judging <em>when</em> general quantum computers will be built to realize it.</p>
<p>
Whereas, the <em>when</em> involved in (b) is <em>now</em>. If a quantum device can do something useful now that classical methods are not delivering now, then it does not matter if the latter could be improved at greater hardware and development cost to work a year from now. This has been the gung-ho tenor of many responses to the recently-<a href="https://www.fedscoop.com/trump-signs-national-quantum-initiative-law/">signed</a> National Quantum Initiative Act. We do, however, still need to find and build said devices…</p>
<p>
As for the status of (a), we don’t know any better thought for January than the Janus-like title of this <a href="https://arxiv.org/abs/1807.10749">paper</a> by Igor Markov, Aneeqa Fatima, Sergei Isakov, and Sergio Boixo: </p>
<blockquote><p><b> </b> <em> “Quantum Supremacy Is Both Closer and Farther than It Appears.” </em>
</p></blockquote>
<p>
</p><p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What are your predictions for 2019? What are the most important matters we’ve left unsaid?</p>
<p>
[added some words to end of intro]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/"><span class="datestr">at January 06, 2019 07:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42163">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model">Immutable Space Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have heard it said that time is more precious than space because we can reuse space but not time.  What if we treat space with this much reverence?</p>

<h3>What is generally known about models of computation in which space is immutable?</h3>

<p>I would expect such models to initialize each memory cell to some "blank" state and then only allow the writing of some "non-blank" value to each cell at most once.</p>

<p>The study of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="noreferrer">persistent data structures</a> seems to me like a possible way to answer this question.</p>

<p>I thought of this question while studying functional programming, which highly values immutability.</p></div>







<p class="date">
by Tyson Williams <a href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model"><span class="datestr">at January 06, 2019 03:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42161">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete">Is this partition problem strongly NP-complete?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>







<p class="date">
by Mohammad Al-Turkistany <a href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete"><span class="datestr">at January 06, 2019 12:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42160">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph">maximize edges minus vertices in a weighted graph</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>







<p class="date">
by andrew <a href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph"><span class="datestr">at January 06, 2019 11:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42159">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often">NuSMV - How to indicate the execution should visit some states infinitely often?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have the following kripke structure:</p>

<p><a href="https://i.stack.imgur.com/3xDPG.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/3xDPG.png" alt="enter image description here" /></a></p>

<p>I need my model to follow the LTL constraint that state d will be visited infinitely often:</p>

<pre><code>LTLSPEC  G F (modelState=d)
</code></pre>

<p>This constraint fails due to existence of the loop .... b-&gt;c-&gt;b-&gt;c ......  </p>

<p>Question: What would be a solution to this problem? This may be related to fair traces, but I am not very familiar with that, or how to indicate d as a fair state in NuSMV. </p>

<p>I am learning model checking on my own and I appreciate your help very much.</p></div>







<p class="date">
by Fabiana <a href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often"><span class="datestr">at January 06, 2019 05:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42158">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems">Best polynomial-time approximation factor for NP-optimization problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Let us say that a function <span class="math-container">$f(n)$</span> is the <strong>best approximation factor</strong> for an NP-optimization problem, if both of the following hold:</p>

<ol>
<li><p>There exist a polynomial-time algorithm <span class="math-container">$A,$</span> and an integer <span class="math-container">$n_0$</span>, such that <span class="math-container">$A$</span> provides an <span class="math-container">$f(n)$</span>-approximation for the NP-optimization problem for every instance with size <span class="math-container">$n\geq n_0$</span>. (Note: the role of <span class="math-container">$n_0$</span> is merely to treat potentially deviant small instances, which might make the function "ugly.")</p></li>
<li><p>There is no polynomial-time <span class="math-container">$(1-o(1))f(n)$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p></li>
</ol>

<p>A classic example where such a best approximation is known is the SET COVER problem (for a summary and references see its Wikipedia page): the Greedy Algorithm provides an <span class="math-container">$\ln n$</span> approximation, but there is no  <span class="math-container">$(1-o(1))\ln n$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p>

<p><strong>Questions:</strong></p>

<ol>
<li><p>Which are some other interesting NP-optimization problems for which a best approximation factor, along with its realizing algorithm, are known?  </p></li>
<li><p>Are there any counterexamples, i.e., NP-optimization problems, for which such a best approximation cannot exist, unless <span class="math-container">$P=NP$</span>?</p></li>
</ol></div>







<p class="date">
by Andras Farago <a href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems"><span class="datestr">at January 05, 2019 04:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42155">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1">Why can't a left-recursive, non-deterministic, or ambiguous grammar be LL(1)?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I've learned from several sources that an LL(1) grammar is:</p>

<ol>
<li>unambiguous,</li>
<li>not left-recursive,</li>
<li>and, deterministic (left-factorized).</li>
</ol>

<p>What I can't fully understand is why the above is true for any LL(1) grammar. I know the LL(1) parsing table will have multiple entries at some cells, but what I really want to get is a formal and general (not with an example) proof to the following proposition(s):</p>

<p>A left-recursive (1), non-deterministic (2), or ambiguous (3) grammar is not LL(1).</p></div>







<p class="date">
by Mr Geek <a href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1"><span class="datestr">at January 05, 2019 01:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42150">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com">Prove that if A is NP-complete and B is coNP-complete, than AxB is NP-, coNP-complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>AxB means cartesian product of A and B.</p>

<p>May someone help me with this? I even have no idea how to prove that AxB belongs to NP or coNP</p></div>







<p class="date">
by guest <a href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com"><span class="datestr">at January 04, 2019 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42148">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission">Feel dissatisfied after each submission</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am a third year graduate student at a "top-20" university who works on fine-grained complexity (lots of playing with 3-SUM, OV and the usual popular hardness conjectures). I have been fairly productive over the last year or so and have 3 accepted papers and two submitted papers. All of this to say that I am a fairly experienced graduate student and what I am about to describe is not anecdotal.</p>

<p>Every submission brings me more dissatisfaction than satisfaction. Just before I start working on a problem, me and my advisor identify a list of concrete questions that need to be answered. After lots of thinking, we have some very nice non-trivial results which gives me a lot of happiness and satisfaction. As we start to write down all of the results, inevitably, there are some more interesting variants that pop up but are much harder to make progress on. After the initial euphoria point, I feel everything seems to go downhill. There are so many variants that also need to be answered, are clearly in the purview of the problem at hand but I am not able to. By the time we submit the paper, I am so dismayed that results in the paper seem almost trivial. Perhaps this is simply tunnel vision, but I can't overcome the sadness about not being able to answer peripheral questions (although these make for a terrific conclusion section).</p>

<p>This has happened every single time and I am wondering if this is a common feeling. Do other people in theory community feel the same way? I am not sure if this is an academia wide feeling. My fellow graduate students from other areas are over the moon after every submission (but this is just anecdotal).</p>

<p>Edit - I see that there is another soft-question on the front page. I apologize for adding another one. Its holiday season and (only?) after a few drinks, one starts to ponder over these things!</p></div>







<p class="date">
by karmanaut <a href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission"><span class="datestr">at January 04, 2019 05:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1474">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/">On PAC Analysis and Deep Neural Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Guest post by <a href="http://amitdaniely.com/">Amit Daniely</a> and <a href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>.</em></p>
<p>For years now—especially since the landmark work of <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krishevsky et. al.</a>—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving <em>theoretical</em> tasks?</p>
<p>Specifically, focusing on supervised learning:</p>
<blockquote><p>Can a deep neural network, paired with a stochastic gradient method, be shown to <a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC learn</a> any interesting concept class in polynomial time?</p></blockquote>
<p>Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently:</p>
<blockquote><p><strong>Theorem:</strong> Networks with depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />,<a href="https://theorydish.blog/feed/#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> having standard activation functions,<a href="https://theorydish.blog/feed/#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds.</p></blockquote>
<p>Learning constant-degree polynomials can also be done simply <em>with a linear predictor</em> over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also <em>essentially the state of the art</em> in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. We will return to this point later, and discuss some limitations of PAC analysis once they are more apparent. In this sense, this post will turn out to be as much an overview of some PAC learning theory as it is about neural networks.</p>
<p>Naturally, there is a wide variety of theoretical perspectives on neural network analysis, especially in the past couple of years. Our goal in this post is not to survey or cover any extensive body of work, but simply to summarize our own recent line (from two papers: <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">DFS’16</a> and <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">D’17</a>), and to highlight the interaction with PAC learning.</p>
<h2 id="neural-network-learning">Neural network learning</h2>
<p>First, let’s define a learning task. To keep things simple, we’ll focus on binary classification over the boolean cube, without noise. Formally:</p>
<blockquote><p><strong>(Binary classification.)</strong> Given examples of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Ch%5E%2A%28x%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(x,h^*(x))" class="latex" title="(x,h^*(x))" />, where <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> is sampled from some unknown distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" /> on <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" />, and <img src="https://s0.wp.com/latex.php?latex=h%5E%2A%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h^*:\{\pm 1\}^n\to\{\pm 1\}" /> is some unknown function (the one that we wish to learn), find a function <img src="https://s0.wp.com/latex.php?latex=h%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h:\{\pm 1\}^n\to\{\pm 1\}" /> whose error, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h%29+%3D+%5Cmathrm%7BPr%7D_%7Bx%5Csim%5Cmathcal%7BD%7D%7D+%5Cleft%28h%28x%29+%5Cne+h%5E%2A%28x%29%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" class="latex" title="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" />, is small.</p></blockquote>
<p>Second, define a neural network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" /> formally as a directed acyclic graph <img src="https://s0.wp.com/latex.php?latex=%28V%2C+E%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(V, E)" class="latex" title="(V, E)" /> whose vertices <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="V" class="latex" title="V" /> are called neurons. Of them, <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> are input neurons, one is an output neuron, and the rest are called hidden neurons.<a href="https://theorydish.blog/feed/#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> A network together with a weight vector <img src="https://s0.wp.com/latex.php?latex=w+%3D+%5C%7Bw_%7Buv%7D+%3A+uv+%5Cin+E%5C%7D+%5Ccup+%5C%7Bb_v+%3A+v+%5Cin+V+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" class="latex" title="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" /> defines a predictor <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" /> whose prediction is computed by propagating <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> forward through the network. Concretely:</p>
<ul>
<li>For an input neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, <img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x)" class="latex" title="h_{v,w}(x)" /> is the corresponding coordinate in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />.</li>
<li>For a hidden neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, define<img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29+%3D+%5Csigma%5Cleft%28+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28v%29%7D+w_%7Buv%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_v+%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." class="latex" title="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." />The scalar weight <img src="https://s0.wp.com/latex.php?latex=b_v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b_v" class="latex" title="b_v" /> is called a “bias.” In this post, the function <img src="https://s0.wp.com/latex.php?latex=%5Csigma+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma : \mathbb{R} \to \mathbb{R}" class="latex" title="\sigma : \mathbb{R} \to \mathbb{R}" /> is the ReLU activation <img src="https://s0.wp.com/latex.php?latex=%5Csigma%28t%29+%3D+%5Cmax%5C%7Bt%2C+0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma(t) = \max\{t, 0\}" class="latex" title="\sigma(t) = \max\{t, 0\}" />, though others are possible as well.</li>
<li>For the output neuron <img src="https://s0.wp.com/latex.php?latex=o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o" class="latex" title="o" />, we drop the activation: <img src="https://s0.wp.com/latex.php?latex=h_%7Bo%2Cw%7D%28x%29+%3D+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28o%29%7D+w_%7Buo%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" class="latex" title="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" />.</li>
</ul>
<p>Finally, let <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D%28x%29+%3D+h_%7Bo%2C+w%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w}(x) = h_{o, w}(x)" class="latex" title="h_{\mathcal N, w}(x) = h_{o, w}(x)" />. This computes a real-valued function, so where we’d like to use it for classification, we do so by thresholding, and abuse the notation <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w)" class="latex" title="\mathrm{Err}(h_w)" /> to mean <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28%5Cmathrm%7Bsign%7D+%5Ccirc+h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(\mathrm{sign} \circ h_w)" class="latex" title="\mathrm{Err}(\mathrm{sign} \circ h_w)" />.</p>
<p>Some intuition for this definition would come from verifying that:</p>
<ul>
<li>Any function <img src="https://s0.wp.com/latex.php?latex=h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h : \{\pm 1\}^n \to \{\pm 1\}" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="2^n" class="latex" title="2^n" /> hidden neurons.</li>
<li>The parity function <img src="https://s0.wp.com/latex.php?latex=h%28x%29+%3D+%5Cprod_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h(x) = \prod_{i=1}^n x_i" class="latex" title="h(x) = \prod_{i=1}^n x_i" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=4n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="4n" class="latex" title="4n" /> hidden neurons. (NB: this one is a bit more challenging.)</li>
</ul>
<p>In practice, the network architecture (this DAG) is designed based on some domain knowledge, and its design can impact the predictor that’s later selected by SGD. One default architecture, useful in the absence of domain knowledge, is the multi-layer perceptron, comprised of layers of complete bipartite graphs:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/full_con_net.png?w=431&amp;h=426" alt="full_con_net" width="431" class="  wp-image-1479 aligncenter" height="426" />A toy “fully-connected neural network”, a.k.a. a multi-layer perceptronAnother paradigmatic architecture is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional network</a>:<p></p>
</figure>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/conv_net.png?w=490&amp;h=463" alt="conv_net" width="490" class="  wp-image-1478 aligncenter" height="463" />A toy convolutional neural network</figure>
<p>Convolutional nets capture the notion of spatial input locality in signals such as images and audio.<a href="https://theorydish.blog/feed/#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> In the toy example drawn, each clustered triple of neurons is a so-called convolution filter applied to two components below it. In image domains, convolutions filters are two-dimensional and capture responses to spatial 2-D patches of the image or of an intermediate layer.</p>
<p>Training a neural net comprises (i) initialization, and (ii) iterative optimization run until <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsign%7D%28h_w%28x%29%29+%3D+h%5E%2A%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{sign}(h_w(x)) = h^*(x)" class="latex" title="\mathrm{sign}(h_w(x)) = h^*(x)" /> for sufficiently many examples <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />. The initialization step sets the starting values of the weights <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> at random:</p>
<blockquote><p><strong>(Glorot initialization.)</strong> Draw weights <img src="https://s0.wp.com/latex.php?latex=%5C%7Bw%5E0_%7Buv%7D%5C%7D_%7Buv%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{w^0_{uv}\}_{uv\in E}" class="latex" title="\{w^0_{uv}\}_{uv\in E}" /> from centered Gaussians with variance <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathrm%7BIN%7D%28v%29%7C%5E%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|\mathrm{IN}(v)|^{-1}" class="latex" title="|\mathrm{IN}(v)|^{-1}" /> and biases <img src="https://s0.wp.com/latex.php?latex=%5C%7Bb%5E0_%7Bv%7D%5C%7D_%7Bv%5Cin+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{b^0_{v}\}_{v\in V}" class="latex" title="\{b^0_{v}\}_{v\in V}" /> from independent standard Gaussians.<a href="https://theorydish.blog/feed/#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p></blockquote>
<p>While other initialization schemes exists, this one is canonical, simple, and, as the reader can verify, satisfies <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bw%5E0%7D%5Cleft%5B%28h_%7Bv%2Cw%5E0%7D%28x%29%29%5E2%5Cright%5D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" class="latex" title="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" /> for every neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" /> and input <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \in \{\pm 1\}^n" class="latex" title="x \in \{\pm 1\}^n" />.</p>
<p>The optimization step is essentially a local search method from the initial point, using <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD) or a variant thereof.<a href="https://theorydish.blog/feed/#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> To apply SGD, we need a function suitable for descent, and we’ll use the commonplace logistic loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%28z%29+%3D+%5Clog_2%281%2Be%5E%7B-z%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell(z) = \log_2(1+e^{-z})" class="latex" title="\ell(z) = \log_2(1+e^{-z})" />, which bounds the zero-one loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%5E%7B0-1%7D%28z%29+%3D+%5Cmathbf%7B1%7D%5Bz+%5Cle+0%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" class="latex" title="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" /> from above:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/losses.png?w=329&amp;h=246" alt="losses" width="329" class="  wp-image-1480 aligncenter" height="246" />The logistic and zero-one losses</figure>
<p> </p>
<p>Define <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D%28w%29+%3D+%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathcal+D%7D%5Cleft%5B+%5Cell%28h_w%28x%29h%5E%2A%28x%29%29+%5Cright%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" class="latex" title="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" />. Note that <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29+%5Cle+L_%7B%5Cmathcal+D%7D%28w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" class="latex" title="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" />, so finding weights <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> for which the upper bound <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is small enough implies low error in turn. Meanwhile, <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is amenable to iterative gradient-based minimization.</p>
<p>Given samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, stochastic gradient descent creates an unbiased estimate of the gradient at each step <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t" class="latex" title="t" /> by drawing a batch of i.i.d. samples <img src="https://s0.wp.com/latex.php?latex=S_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_t" class="latex" title="S_t" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. The gradient <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+L_%7BS_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\nabla L_{S_t}" class="latex" title="\nabla L_{S_t}" /> at a point <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> can be computed efficiently by the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm.</p>
<p>In more complete detail, our prototypical neural network training algorithm is as follows. On input a network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" />, an iteration count <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, a batch size <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b" class="latex" title="b" />, and a step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta &gt; 0" class="latex" title="\eta &gt; 0" />:</p>
<p><strong>Algorithm: <em>SGDNN</em></strong></p>
<ol type="1">
<li>Let <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> be random weights sampled per Glorot initialization</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=t+%3D+1%2C+%5Cldots%2C+T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t = 1, \ldots, T" class="latex" title="t = 1, \ldots, T" />:
<ol type="1">
<li>Sample a batch <img src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D+%3D+%5C%7B%28x%5Et_1%2C+h%5E%2A%28x%5Et_1%29%29%2C+%5Cldots%2C+%28x%5Et_b%2C+h%5E%2A%28x%5Et_b%29%29%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" class="latex" title="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" />, where <img src="https://s0.wp.com/latex.php?latex=x%5Et_1%2C+%5Cldots%2C+x%5Et_b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x^t_1, \ldots, x^t_b" class="latex" title="x^t_1, \ldots, x^t_b" /> are i.i.d. samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />.</li>
<li>Update <img src="https://s0.wp.com/latex.php?latex=w%5Et+%5Cgets+w%5E%7Bt-1%7D+-+%5Ceta+%5Cnabla+L_%7BS_t%7D%28w%5E%7Bt-1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" class="latex" title="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" />, where<img src="https://s0.wp.com/latex.php?latex=L_%7BS_t%7D%28w%5E%7Bt-1%7D%29+%3D+b%5E%7B-1%7D+%5Csum_%7Bi%3D1%7D%5Eb+%5Cell%28h_%7Bw%7D%28x%5Et_i%29+h%5E%2A%28x%5Et_i%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" class="latex" title="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" />.</li>
</ol>
</li>
<li>Output <img src="https://s0.wp.com/latex.php?latex=w%5ET&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^T" class="latex" title="w^T" /></li>
</ol>
<h2 id="pac-learning">PAC learning</h2>
<p>Learning a predictor from example data is a general task, and a hard one in the worst case. We cannot efficiently (i.e. in <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(n)" class="latex" title="\mathrm{poly}(n)" /> time) compute, let alone learn, general functions from <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}" class="latex" title="\{\pm 1\}" />. In fact, any learning algorithm that is guaranteed to succeed in general (i.e. with any target predictor <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> over any data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />) runs, in the worst case, in time exponential in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" />. This is true even for rather weak definitions of “success,” such as finding a predictor with error less than <img src="https://s0.wp.com/latex.php?latex=1%2F2+-+2%5E%7B-n%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1/2 - 2^{-n/2}" class="latex" title="1/2 - 2^{-n/2}" />, i.e. one that slightly outperforms a random guess.</p>
<p>While it is impossible to efficiently learn general functions under general distributions, it might still be possible to learn efficiently under some assumptions on the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> or the distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. Charting out such assumptions is the realm of learning theorists: by now, they’ve built up a broad catalog of function classes, and have studied the complexity of learning when the target function is in each such class. Although their primary aim has been to develop theory, the potential guidance for practice is easy to imagine: if one’s application domain happens to be modeled well by one of these easily-learnable function classes, there’s a corresponding learning algorithm to consider as well.</p>
<p>The vanilla PAC model makes no assumptions on the data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, but it does assume the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> belongs to some simple, predefined class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" />. Formally, a <em>PAC learning problem</em> is defined by a function class<a href="https://theorydish.blog/feed/#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H+%5Csubset+%5C%7B%5Cpm+1%5C%7D%5E%7B%5C%7B%5Cpm+1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" class="latex" title="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" />. A learning algorithm <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal A" class="latex" title="\mathcal A" /> <em>learns</em> the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" /> if, whenever <img src="https://s0.wp.com/latex.php?latex=h%5E%2A+%5Cin+%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^* \in \mathcal H" class="latex" title="h^* \in \mathcal H" />, and provided <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon &gt; 0" class="latex" title="\epsilon &gt; 0" />, it runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%281%2F%5Cepsilon%2C+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(1/\epsilon, n)" class="latex" title="\mathrm{poly}(1/\epsilon, n)" />, and returns a function of error at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, with probability at least 0.9. Note that:</p>
<ol type="1">
<li>The learning algorithm need not return a function from the learnt class.</li>
<li>The polynomial-time requirement means in particular that the learning algorithm cannot output a complete truth table, as its size would be exponential. Instead, it must output a short description of a hypothesis that can be evaluated in polynomial time.</li>
</ol>
<p>For a taste of the computational learning theory literature, here are some of the function classes studied by theorists over the years:</p>
<ol type="1">
<li><em>Linear thresholds (halfspaces):</em> functions that map a halfspace to 1 and its complement to -1. Formally, functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Ctheta%28%5Clangle+w%2C+x+%5Crangle%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \theta(\langle w, x \rangle)" class="latex" title="x \mapsto \theta(\langle w, x \rangle)" /> for some <img src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w \in \mathbb{R}^n" class="latex" title="w \in \mathbb{R}^n" />, where <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = 1" class="latex" title="\theta(z) = 1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z &gt; 0" class="latex" title="z &gt; 0" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = -1" class="latex" title="\theta(z) = -1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%5Cle+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z \le 0" class="latex" title="z \le 0" />.</li>
<li><em>Large-margin linear thresholds:</em> for<img src="https://s0.wp.com/latex.php?latex=%5Crho%28z%29+%3D+%5Cbegin%7Bcases%7D+1+%26+z+%5Cge+1+%5C%5C+%2A+%26+-1+%5Cle+z+%5Cle+1+%5C%5C+-1+%26+z+%5Cle+-1+%5Cend%7Bcases%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," class="latex" title="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," />the class<img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%28%5Clangle+w%2Cx+%5Crangle%29+%5Ctext%7B+with+%7D+%5C%7Cw%5C%7C_2%5E2+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." /></li>
<li><em>Intersections of halfspaces:</em> functions that map an intersection of polynomially many halfspaces to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> and its complement to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" />.</li>
<li><em>Polynomial threshold functions:</em> thresholds of constant-degree polynomials.</li>
<li><em>Large-margin polynomial threshold functions:</em> the class</li>
</ol>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%5Cleft%28+%5Csum_%7BA+%5Csubset+%5Bn%5D%2C+%7CA%7C+%5Cle+O%281%29%7D+%5Calpha_A+%5Cprod_%7Bi+%5Cin+A%7D+x_i+%5Cright%29+%5C%3B%5Ctext%7B+with+%7D%5C%3B+%5Csum_%7BA%7D+%5Calpha%5E2_A+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." /></p>
<ol type="1">
<li><em>Decision trees</em>, <em>deterministic automata</em>, and <em><a href="https://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a> formulas</em> of polynomial size.</li>
<li><em>Monotone conjunctions:</em> functions that, for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" /> map <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> if <img src="https://s0.wp.com/latex.php?latex=x_i+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_i = 1" class="latex" title="x_i = 1" /> for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in A" class="latex" title="i \in A" />, and to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" /> otherwise.</li>
<li><em>Parities:</em> functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cprod_%7Bi+%5Cin+A%7D+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \prod_{i \in A} x_i" class="latex" title="x \mapsto \prod_{i \in A} x_i" /> for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" />.</li>
<li><em>Juntas:</em> functions that depend on at most <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" /> variables.</li>
</ol>
<p>Learning theorists look at these function classes and work to distinguish those that are efficiently learnable from those that are <em>hard</em> to learn. They establish hardness results by reduction from other computational problems that are conjectured to be hard, such as random XOR-SAT (though none today are conditioned outright on NP hardness); see for example <a href="https://arxiv.org/abs/1404.3378">these</a> <a href="https://arxiv.org/abs/1505.05800">two</a> results. Meanwhile, halfspaces are learnable by linear programming. Parities, or more generally, <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions for a field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />, are learnable by Gaussian elimination. In turn, via reductions, many other classes are efficiently learnable. This includes polynomial thresholds, decision lists, and more. To give an idea of what’s known in the literature, here is an artist’s depiction of some of what’s currently known:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes.png?w=620" alt="classes" class=" size-full wp-image-1477 aligncenter" />Learnable and conjectured hard-to-learn function classes</figure>
<p> </p>
<p>At a high-level, the upshot from all of this—and if you take away just one thing from this quick tour of PAC—is that:</p>
<blockquote><p>Barring a small handful of exceptions, all known efficiently learnable classes can be reduced to halfspaces or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions.</p></blockquote>
<p>Or, to put it more bluntly, <strong>the state of the art in PAC-learnability is essentially linear prediction</strong>.</p>
<h2 id="pac-analyzing-neural-nets">PAC analyzing neural nets</h2>
<p>Research in algorithms and complexity often follows these steps:</p>
<ol type="1">
<li>define a computational problem,</li>
<li>design an algorithm that solves it, and then</li>
<li>establish bounds on the resource requirements of that algorithm.</li>
</ol>
<p>A bound on the algorithm’s performance forms, in turn, a bound on the <em>computational problem’s</em> inherent complexity.</p>
<p>By contrast, we have already decided on our SGDNN algorithm, and we’d like to attain some grasp on its capabilities. So we’d like to do things in a different order:</p>
<ol type="1">
<li>define an <em>algorithm</em> (done),</li>
<li>design a computational problem to which the algorithm can be applied, and then</li>
<li>establish bounds on the resource requirements of the algorithm in solving the problem.</li>
</ol>
<p>Our computational problem will be a PAC learning problem, corresponding to a function class. For SGDNN, an ambitious function class we might consider is the class of all functions realizable by the network. But if we were to follow this approach, we would run up against the same hardness results mentioned before.</p>
<p>So instead, we’ve established the theorem stated at the top of this post. That is, that SGDNN, over a range of network configurations, learns a class that we <em>already know</em> to be learnable: large margin polynomial thresholds. Restated:</p>
<blockquote><p><strong>Theorem, again:</strong> There is a choice of SGDNN step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta" class="latex" title="\eta" /> and number of steps <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, as well as a with parameter <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, where <img src="https://s0.wp.com/latex.php?latex=T%2C+r+%5Cle+%5Cmathrm%7Bpoly%7D%28n%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T, r \le \mathrm{poly}(n/\epsilon)" class="latex" title="T, r \le \mathrm{poly}(n/\epsilon)" />, such that SGDNN on a multi-layer perceptron of depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />, and of width<a href="https://theorydish.blog/feed/#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, learns large magin polynomials.</p></blockquote>
<p>How rich are large margin polynomials? They contain disjunctions, conjunctions, DNF and <a href="https://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a> formulas with a constant many terms, DNF and CNF formulas with a constant many literals in each term. By corollary, SGDNN can PAC learn these classes as well. And at this point, we’ve covered a considerable fraction of the function classes known to be poly-time PAC learnable by <em>any</em> method.</p>
<p>Exceptions include constant-degree polynomial thresholds with no restriction on the coefficients, decision lists, and parities. It is well known that SGDNN cannot learn parities, and in ongoing work with Vitaly Feldman, we show that SGDNN cannot learn decision lists nor constant-degree polynomial thresholds with unrestricted coefficients. So the picture becomes more clear:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes_nn.png?w=620" alt="classes_nn" class=" size-full wp-image-1476 aligncenter" />Conjectured hard-to-learn classes, known learnable classes, and those known to be learnable by SGDNN.</figure>
<p> </p>
<p>The theorem above runs SGDNN with a multi-layer perceptron. What happens if we change the network architecture? It can be shown then that SGDNN learns a qualitatively different function class. For instance, with convolutional networks, the learnable functions include certain polynomials of <em>super-constant</em> degree.</p>
<h3 id="a-word-on-the-proof">A word on the proof</h3>
<p>The path to the theorem traverses two papers. There’s a corresponding outline for the proof.</p>
<p>The first step is to show that, with high probability, the Glorot random initialization renders the network in a state where the final hidden layer (just before the output node) is rich enough to approximate all large-margin polynomial threshold functions (LMPTs). Namely, every LMPT can be approximated by the network up to some setting of the weights that enter the output neuron (all remaining weights random). The tools for this part of the proof include (i) the connection between kernels and random features, (ii) a characterization of symmetric kernels of the sphere, and (iii) a variety of properties of Hermite polynomials. It’s described in our <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">2016 paper</a>.</p>
<p>An upshot of this correspondence is that if we run SGD <em>only on the top layer</em> of a network, leaving the remaining weights as they were randomly initialized, we learn LMPTs. (Remember when we said that we won’t beat what a linear predictor can do? There it is again.) The second step of the proof, then, is to show that the correspondence continues to hold even if we train all the weights. In the assumed setting (e.g. provided at most logarithmic depth, sufficient width, and so forth), what’s represented in the final hidden layer changes sufficiently slowly that, over the course of SGDNN’s iterations, it <em>remains</em> rich enough to approximate all LMPTs. The final layer does the remaining work of picking out the right LMPT. The argument is in Amit’s <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">2017 paper</a>.</p>
<h2 id="pacing-up">PACing up</h2>
<p>To what extent should we be satisfied, knowing that our algorithm of interest (SGDNN) can solve a (computationally) easy problem?</p>
<p>On the positive side, we’ve managed to say something at all about neural network training in the PAC framework. Roughly speaking, some class of non-trivially layered neural networks, trained as they typically are, learns any known learnable function class that isn’t “too sensitive.” It’s also appealing that the function classes vary across different architectures.</p>
<p>On the pessimistic side, we’re confronted to a major limitation on the “function class” perspective, prevalent in PAC analysis and elsewhere in learning theory. All of the classes that SGDNN learns, <em>under the assumptions</em> touched on in this post, are so-called large-margin classes. Large-margin classes are essentially linear predictors over a <em>fixed and data-independent</em> embedding of input examples, as alluded to before. These are inherently “shallow models.”</p>
<p>That seems rather problematic in pursuing any kind of theory for learning layered networks, where the entire working premise is that a deep network uses its hidden layers to learn a representation adapted to the example domain. Our analysis—both its goal and its proof—clash with this intuition: it works out that a “shallow model” can be learned when assumptions imply that “not too much” change takes place in hidden layers. It seems that the representation learning phenomenon is what’s interesting, yet the typical PAC approach, as well as the analysis touched on in this post, all avoid capturing it.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1">Here <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> is the dimension of the instance space.<a href="https://theorydish.blog/feed/#fnref1"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn2">For instance, ReLU activations, of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmax%5C%7Bx%2C0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \max\{x,0\}" class="latex" title="x \mapsto \max\{x,0\}" />.<a href="https://theorydish.blog/feed/#fnref2"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn3">Recurrent networks allow for cycles, but in this post we stick to DAGs.<a href="https://theorydish.blog/feed/#fnref3"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn4">Convolutional networks often also constrain subsets of their weights to be equal; that turns out not to bear much on this post.<a href="https://theorydish.blog/feed/#fnref4"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn5">Although not essential to the results described, it also simplifies this post to zero the weights on edges incident to the output node as part of the initialization.<a href="https://theorydish.blog/feed/#fnref5"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Variants of SGD</a> are used in practice, including algorithms used elsewhere in optimization (e.g. <a href="https://distill.pub/2017/momentum/">SGD with momentum</a>, <a href="http://www.jmlr.org/papers/v12/duchi11a.html">AdaGrad</a>) or techniques developed more specifically for neural nets (e.g. RMSprop, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="https://arxiv.org/abs/1502.03167">batch norm</a>). We’ll stick to plain SGD.<a href="https://theorydish.blog/feed/#fnref6"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn7">More accurately, a sequence of function classes <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H_n" class="latex" title="\mathcal H_n" /> for <img src="https://s0.wp.com/latex.php?latex=n+%3D+1%2C+2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n = 1, 2, \ldots" class="latex" title="n = 1, 2, \ldots" />.<a href="https://theorydish.blog/feed/#fnref7"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn8">The width of a multi-layer perceptron is the number of neurons in each hidden layer.<a href="https://theorydish.blog/feed/#fnref8"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
</ol>
</section></div>







<p class="date">
by amitdanielymailhujiacil <a href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/"><span class="datestr">at January 04, 2019 03:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42145">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications">Grid-Minor Theorem of Robertson and Seymour and its Algorithmic Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Graph-Minor Theorem of Robertson and Seymour [<a href="https://www.sciencedirect.com/science/article/pii/S0095895684710732" rel="nofollow noreferrer">1</a>] states that if graph G has large treewidth, then it contains a large grid as minor. Most approximation results on general classes of graphs with excluded minors make heavy use of Robertson and Seymour’s structure theory for graphs with excluded minors, especially when the treewidth is large (small treewidth usually makes problem to be easily solved by dynamic programming) [<a href="http://chekuri.cs.illinois.edu/talks/NIPS-Tutorial.pdf" rel="nofollow noreferrer">2</a>]. </p>

<p>However, there are some results are trying to avoid using the grid minor theorem. For example, Chekuri and Chuzhoy [<a href="https://arxiv.org/abs/1304.1577" rel="nofollow noreferrer">3</a>] show a framework for using theorems to bypass the well-known Grid-Minor Theorem of Robertson and Seymour in some applications. In particular, this leads to substantially improved parameters in some Erdos-Posa-type results, and faster running times for algorithms for some fi�xed parameter tractable problems.</p>

<p>Do you know any other examples of problems with large treewidth avoid using the grid minor theorem? </p></div>







<p class="date">
by Rupei Xu <a href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications"><span class="datestr">at January 04, 2019 09:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42144">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph">Maximum Weight Independent Set on a Changing Graph?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Suppose I have an optimal solution to the maximum weight independent/stable set problem on an arbitrary graph. If I were to induce a clique among a subset of its vertices (and perhaps add in some additional nodes that are only adjacent to the nodes of the induced clique), does there exist an efficient way in which I use the original optimal solution (i.e. its structure as a starting solution) to find the new optimal maximum weight independent set in the modified graph??</p></div>







<p class="date">
by Student <a href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph"><span class="datestr">at January 04, 2019 07:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7217">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/01/03/quantum-games/">Quantum Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Nilin Abrahamsen <font face="courier new">nilin@mit.edu</font>
</p><p>Daniel Alabi <font face="courier new">alabid@g.harvard.edu</font>
</p><p>Mitali Bafna <font face="courier new">mitalibafna@g.harvard.edu</font>
</p><p>Emil Khabiboulline <font face="courier new">ekhabiboulline@g.harvard.edu</font>
</p><p>Juspreet Sandhu <font face="courier new">jus065@g.harvard.edu</font>

<br />
<br />
Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a <em>verifier</em> sends questions privately to each of two collaborating <em>provers</em> , who then aim to respond with a compatible pair of answers without communicating with each other. Sharing quantum entanglement allows the provers to improve their strategy without any communication, illustrating an apparent paradox of the quantum postulates. These notes aim to give an introduction to the role of entanglement in nonlocal games, as they are called in the quantum literature. We see how nonlocal games have rich connections within computer science and quantum physics, giving rise to theorems ranging from hardness of approximation to the resource theory of entanglement.
</p><h2>Introduction</h2>
In these notes we discuss 2-prover 1-round games and the classical complexity of approximating the value of such games in the setting where the provers can share entanglement. That is, given the description of a game, we ask how hard it is to estimate the winning probability of the best winning strategy of the entangled provers. Let us first formally define games and its relation to the label cover problem. We write <img src="https://s0.wp.com/latex.php?latex=%7B+%5Bn%5D%3D%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ [n]=\{1,\ldots,n\}}" class="latex" title="{ [n]=\{1,\ldots,n\}}" />.
<h4>Definition (Label cover)</h4>
<em> A label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%3D%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I=(S,T,\Sigma,\Pi)}" class="latex" title="{ I=(S,T,\Sigma,\Pi)}" /> consists of variable sets <img src="https://s0.wp.com/latex.php?latex=%7B+S%3D%5C%7Bs_i%5C%7D_%7Bi%5Cin%5Bn%5D%7D%2CT%3D%5C%7Bt_j%5C%7D_%7Bj%5Cin%5Bn%5D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" class="latex" title="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" />, alphabet set <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" />, and a collection <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> of constraints of the form <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%3Df_%7Bi%2Cj%7D%28s_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j=f_{i,j}(s_i)}" class="latex" title="{ t_j=f_{i,j}(s_i)}" />. Given an assignment (or coloring) <img src="https://s0.wp.com/latex.php?latex=%7B+c+%3A+S%5Ccup+T+%5Crightarrow+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c : S\cup T \rightarrow \Sigma}" class="latex" title="{ c : S\cup T \rightarrow \Sigma}" /> we define its value to be <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28c%29%3D%5Cmathbb+P_%7Bf_%7Bij%7D%5Csim%5CPi%7D%5Cbig%28c%28t_j%29%3Df_%7Bij%7D%28c%28s_i%29%29%5Cbig%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" class="latex" title="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" />. Define the value of <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> to be the maximum over all possible assignments, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29+%3D+%5Cmax_%7Bc%7D+%5Comega%28c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I) = \max_{c} \omega(c)}" class="latex" title="{ \omega(I) = \max_{c} \omega(c)}" />. </em>



Many familiar computational problems can be formulated as a label cover, such as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3SAT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3SAT}}" class="latex" title="{ \textsc{3SAT}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3Lin%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3Lin}}" class="latex" title="{ \textsc{3Lin}}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7BMaxCut%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{MaxCut}}" class="latex" title="{ \textsc{MaxCut}}" />.
<figure style="width: 11em; margin: auto;">

<a href="https://windowsontheory.org/?attachment_id=7236"><img src="https://windowsontheory.files.wordpress.com/2019/01/labelcover.png?w=110&amp;h=150" alt="" width="110" class="attachment-thumbnail size-thumbnail" height="150" /></a>
Label cover graph</figure>
<h4>Definition (2-prover 1-round game)</h4>
<em> Let <img src="https://s0.wp.com/latex.php?latex=%7B+I+%3D+%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I = (S,T,\Sigma,\Pi)}" class="latex" title="{ I = (S,T,\Sigma,\Pi)}" /> be a label cover instance. We can then associate the following two-prover one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G(I)}" class="latex" title="{ G(I)}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%2CP_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1,P_2}" class="latex" title="{ P_1,P_2}" /> be two provers who cannot communicate, and let <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> be the verifier. Given the label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />, the verifier uniformly samples a constraint <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bi%2Cj%7D+%5Cin+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{i,j} \in \Pi}" class="latex" title="{ f_{i,j} \in \Pi}" /> and sends <img src="https://s0.wp.com/latex.php?latex=%7B+s_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s_i}" class="latex" title="{ s_i}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1}" class="latex" title="{ P_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j}" class="latex" title="{ t_j}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_2}" class="latex" title="{ P_2}" />. The provers then reply with <img src="https://s0.wp.com/latex.php?latex=%7B+a+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a \in \Sigma}" class="latex" title="{ a \in \Sigma}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%5Cin%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b\in\Sigma}" class="latex" title="{ b\in\Sigma}" /> respectively to <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" />. Finally, <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> outputs <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7B+b+%3D+f_%7Bi%2Cj%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b = f_{i,j}(a)}" class="latex" title="{ b = f_{i,j}(a)}" />. </em>


<figure style="width: 25em; margin: auto;">
 
<a href="https://windowsontheory.org/?attachment_id=7235"><img src="https://windowsontheory.files.wordpress.com/2019/01/game.png?w=150&amp;h=104" alt="" width="150" class="attachment-thumbnail size-thumbnail" height="104" /></a>


The game view of label cover</figure>
Any coloring of the label cover instance corresponds to a deterministic strategy for the corresponding game. Therefore, with an optimal strategy the provers win the game associated to label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I)}" class="latex" title="{ \omega(I)}" />. That is, the value of the game equals that of the label cover instance. However, this is with the assumption that provers can only use deterministic strategies or convex combinations of these (that is, using shared randomness). If the provers share an entangled quantum state, then the provers (who still cannot communicate) can enjoy correlations that allow them to win with a higher probability than classically. In the quantum literature, these 2P-1R games are known as nonlocal games referring to the fact that the correlations arise without signaling between the provers. We are concerned with the complexity of approximating the winning probability of this strategy.

We refer to the optimal winning probability within some class (classical or entangled) of strategies as the classical and quantum value of the game, respectively, and we use the terms quantum strategy and entangled strategy interchangeably.

Fixing different constraint families in the label cover game changes the complexity of finding the (classical and entangled) values of the game. We will show that approximating the entangled value of XOR games, or more generally <em>unique games</em> (to be defined later on), is possible in polynomial time. This is remarkable because a famous conjecture known as the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture"> <em>unique games conjecture</em> </a> says that approximating the classical value of unique games is NP-hard. In contrast, we will see that for unrestricted edge constraints, it is NP-hard to approximate the entangled value of a nonlocal game. Thus, hardness of approximation of the game’s value, established by the celebrated <em>PCP theorem</em> , still applies in the presence of entanglement. In the quantum world, we have new complexity classes such as QMA (which can be regarded as “quantum NP”), so one may conjecture whether approximating the entangled value of a general game is QMA-hard (the games formulation of the <em>quantum PCP conjecture</em> ). We will indicate progress in this direction but will explicitly demonstrate the NP-hardness result.

Entanglement is often regarded as an expensive resource in quantum information because it is difficult to produce and maintain. Hence, even if sharing entanglement can improve the success probability of winning a game, the resource consumption may be costly. We will conclude by discussing lower bounds on the number of shared entangled bits required to achieve the optimal value of a game.
<h2>Notation and quantum postulates</h2>
Let us first establish notation and define what is meant by an entangled strategy. In keeping with physics notation we write a column vector as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \in\mathbb C^d}" class="latex" title="{ |{v}\rangle \in\mathbb C^d}" /> and its conjugate-transpose (a row vector) as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| }" class="latex" title="{ \langle{v}| }" /> . More generally the conjugate-transpose (Hermitian conjugate) of a matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag}" class="latex" title="{ A^\dag}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| w\rangle}" class="latex" title="{ \langle{v}| w\rangle}" /> is the inner product of two vectors (a scalar) and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Clangle%7Bw%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \langle{w}| }" class="latex" title="{ |{v}\rangle \langle{w}| }" /> the outer product (a rank-1 matrix). A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is said to be <em>Hermitian</em> if <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%3DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag=A}" class="latex" title="{ A^\dag=A}" />. A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is <em>positive semidefinite</em> , written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Csucceq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\succeq 0}" class="latex" title="{ A\succeq 0}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B+A%3DB%5E%5Cdag+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A=B^\dag B}" class="latex" title="{ A=B^\dag B}" /> for some matrix <img src="https://s0.wp.com/latex.php?latex=%7B+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B}" class="latex" title="{ B}" />. We write the identity matrix as <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}}" class="latex" title="{ {\mathbb{I}}}" />, denote by <img src="https://s0.wp.com/latex.php?latex=%7B+Herm%28%5Cmathbb%7BC%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Herm(\mathbb{C}^d)}" class="latex" title="{ Herm(\mathbb{C}^d)}" /> the set of <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> Hermitian matrices.
<h3> Observables, states, and entanglement</h3>
In a quantum theory the <em>observables</em> are Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Cin+Herm%28%5Cmathbb+C%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\in Herm(\mathbb C^d)}" class="latex" title="{ A\in Herm(\mathbb C^d)}" /> on a vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />. It then makes sense to say that a <em>state</em> is a functional <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi}" class="latex" title="{ \varphi}" /> on the set of observables. That is, to specify the state of a physical system means giving a (expected) value for each observable. It turns out states are <em>linear</em> functionals of the observables, and such functionals can be written <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%28A%29%3D%5Clangle+A%2C%5Crho%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi(A)=\langle A,\rho\rangle}" class="latex" title="{ \varphi(A)=\langle A,\rho\rangle}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />. We call <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> the density matrix and require moreover that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> is positive semidefinite and has trace <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />. Every density matrix is a convex combination of rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Clangle%5Cpsi%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\langle\psi|}" class="latex" title="{ |\psi\rangle\langle\psi|}" /> known as pure states. The unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> are also themselves known as pure states.

If the state of one particle is described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (referring here to pure states), then two particles are described by a vector in the tensor product <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ \mathbb C^d\otimes\mathbb C^d}" />. The two particles are entangled if their state is not in the form of a pure tensor <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cotimes%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\otimes|\psi\rangle}" class="latex" title="{ |\phi\rangle\otimes|\psi\rangle}" />. We also write product states as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle|\psi\rangle}" class="latex" title="{ |\phi\rangle|\psi\rangle}" />, omitting the tensor symbol.
<h3> Quantum measurements</h3>
A quantum measurement can be described in terms of a <em>projection-valued measure</em> (PVM).
<b>Definition 1 (PVM)</b> <em><a name="measurement"></a> A projection-valued measure on vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (where the quantum states live) is a list of projection matrices <img src="https://s0.wp.com/latex.php?latex=%7B+A_1%2C%5Cldots%2CA_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_1,\ldots,A_k}" class="latex" title="{ A_1,\ldots,A_k}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+A_iA_j%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_iA_j=0}" class="latex" title="{ A_iA_j=0}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\neq j}" class="latex" title="{ i\neq j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+A_i%3D%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_i A_i={\mathbb{I}}}" class="latex" title="{ \sum_i A_i={\mathbb{I}}}" />. The PVM describes a measurement which, on state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> outputs measurement outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cpsi%7C+A_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\psi| A_i|\psi\rangle}" class="latex" title="{ \langle\psi| A_i|\psi\rangle}" />. The quantum state after obtaining outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%5C%7CA_i%7C%5Cpsi%5Crangle%5C%7C%7DA_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" class="latex" title="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" />. </em>
When the projections are rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%3D+%7C%7B%5Cbeta_i%7D%5Crangle+%5Clangle%7B%5Cbeta_i%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" class="latex" title="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" /> we say that we measure in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_i%7D%5Crangle+%5C%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_i}\rangle \}_i}" class="latex" title="{ \{ |{\beta_i}\rangle \}_i}" />. In this case the probability of outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> in state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle}" class="latex" title="{ |\psi\rangle}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_i+%7C%7B%5Cpsi%7D%5Crangle+%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_i |{\psi}\rangle |^2}" class="latex" title="{ |\langle\beta_i |{\psi}\rangle |^2}" />, and the post-measurement state is simply <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_i%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_i}\rangle}" class="latex" title="{ |{\beta_i}\rangle}" /> .

Applying the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%29_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i)_i}" class="latex" title="{ (A_i)_i}" /> on the left half of a two-particle state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5CPsi%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" /> means applying the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i\otimes {\mathbb{I}})_{i}}" class="latex" title="{ (A_i\otimes {\mathbb{I}})_{i}}" /> on the two-particle state.
<h3> Quantum strategies for nonlocal games</h3>
We now introduce the notion of a quantum strategy for a nonlocal game. Each prover holds a particle, say with state space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />, and Alices particle may be entangled with Bob’s. The global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" />. Each player receives a question from the verifier and then chooses a measurement (a PVM) depending on the question. The player applies the measurement to their own particle and responds to the verifier with their measurement outcome. Hence for Alice we specify <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\in S}" class="latex" title="{ s\in S}" /> is a question, and each PVM is a list <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_%7Ba%3D1%7D%2C%5Cldots%2CA%5Es_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_{a=1},\ldots,A^s_k}" class="latex" title="{ A^s_{a=1},\ldots,A^s_k}" />. By definition <a href="https://windowsontheory.org/feed/#measurement">1</a>, given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the probability that Alice outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and Bob outputs <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> is <a name="Qstrategy"></a>

<a name="Qstrategy">
</a><a name="Qstrategy"></a>
<p align="center"><a name="Qstrategy"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28a%2Cb%7Cs%2Ct%29%3D%5C%7C%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b%29%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5C%7C%5E2%3D+%5Clangle%7B%5Cphi%7D%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" class="latex" title="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" /></a></p>
<a name="Qstrategy">
</a><a name="Qstrategy"></a> where we have used that squaring a projection leaves it unchanged.
<h2>Quantum strategies beat classical ones</h2>
For any 2P-1R game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />, let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> be the maximum probability — over the players’ classical strategies — that the verifier accepts and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> the maximum probability that the verifier accepts when the provers use qubits such that player 1’s qubits are entangled with those of player 2.

The game of Clauser, Horne, Shimony, and Holt (CHSH) has the property that the provers can increase their chance of winning by sharing an entangled pair of qubits, even when no messages are exchanged between the players. We show that there’s a characterization of the CHSH game’s value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" class="latex" title="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" /> which is better than the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)\leq \frac{3}{4}}" class="latex" title="{ \omega(G)\leq \frac{3}{4}}" />. Let us first define XOR games, of which the CHSH game is a special case.
<h4>Definition (XOR game)</h4>
<em> An XOR game is a 2-player classical game (the questions and answers are classical bits) where: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> Questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%5Cin%5C%7B0%2C+1%2C+%5Cldots%2C+n-1%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" class="latex" title="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" /> are asked according to some distribution <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> (e.g. uniform).</li>
 	<li> Answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" /> are provided by players (call them Alice and Bob).</li>
 	<li> The verifier computes a predicate <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b%7Cs%2C+t%29+%3D+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" class="latex" title="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" /> used to decide acceptance/rejection.</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>


<h4>Definition (CHSH Game)</h4>
<em> An XOR game with <img src="https://s0.wp.com/latex.php?latex=%7B+n%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n=2}" class="latex" title="{ n=2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in\{0, 1\}}" class="latex" title="{ s, t\in\{0, 1\}}" /> are independent random bits and <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b+%7C+s%2C+t%29%3D1+%5CLongleftrightarrow+a%5Coplus+b+%3D+s%5Cwedge+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" class="latex" title="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" />. </em>



To win the CHSH game, Alice and Bob need to output bits <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> (from Alice) and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> (from Bob) that disagree if <img src="https://s0.wp.com/latex.php?latex=%7B+s%3Dt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=t=1}" class="latex" title="{ s=t=1}" /> and agree otherwise.

If Alice and Bob are classical then they can do no better than by always outputting <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />, say, in which case they win in the three out of four cases when one of the questions is <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />. Equivalently, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%3D%5Cfrac34%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)=\frac34}" class="latex" title="{ \omega(G)=\frac34}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> is the CHSH game. This is the content of <em>Bell’s inequality</em> :
<h4>Lemma (Bell’s Inequality)</h4>
<em> For any two functions <img src="https://s0.wp.com/latex.php?latex=%7B+g%2C+h%3A+%5C%7B0%2C+1%5C%7D%5Crightarrow%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" class="latex" title="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" />, we have </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D+%5Cleq+%5Cfrac%7B3%7D%7B4%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" /></em>

<em>
</em><em></em><em> where <img src="https://s0.wp.com/latex.php?latex=%7B+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x}" class="latex" title="{ x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ y}" class="latex" title="{ y}" /> are independent uniformly random bits. </em>



<em><br /><b>Proof.</b></em> The probability of any event is a multiple of <img src="https://s0.wp.com/latex.php?latex=%7B+1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1/4}" class="latex" title="{ 1/4}" /> so it suffices to show that <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D%5Cneq1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" />. So assume for contradiction that <img src="https://s0.wp.com/latex.php?latex=%7B+g%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(x)\oplus h(y) = x\wedge y}" class="latex" title="{ g(x)\oplus h(y) = x\wedge y}" /> for all pairs <img src="https://s0.wp.com/latex.php?latex=%7B+x%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x,y}" class="latex" title="{ x,y}" />. Then we have that <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(0) = 0}" class="latex" title="{ g(0)\oplus h(0) = 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%281%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(1) = 0}" class="latex" title="{ g(0)\oplus h(1) = 0}" /> which implies that <img src="https://s0.wp.com/latex.php?latex=%7B+h%280%29%3Dh%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ h(0)=h(1)}" class="latex" title="{ h(0)=h(1)}" />. But then <img src="https://s0.wp.com/latex.php?latex=%7B+0%3Dg%281%29%5Coplus+h%280%29+%3Dg%281%29%5Coplus+h%281%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" class="latex" title="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" /> which is a contraction. 
<div align="right">□</div>
<h3> The strategy</h3>
The entangled strategy for the CHSH game requires that Alice and Bob each hold a qubit, so that their two qubits together are described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E2%5Cotimes%5Cmathbb+C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^2\otimes\mathbb C^2}" class="latex" title="{ \mathbb C^2\otimes\mathbb C^2}" />. The two qubits together are in the state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B0%7D%5Crangle+_A+%7C%7B0%7D%5Crangle+_B+%2B+%7C%7B1%7D%5Crangle+_A+%7C%7B1%7D%5Crangle+_B%5Cright%29%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" class="latex" title="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" />

forming what is known as an EPR (Einstein-Podolsky-Rosen) pair. Now for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctheta%5Cin%5B-%5Cpi%2C+%5Cpi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \theta\in[-\pi, \pi]}" class="latex" title="{ \theta\in[-\pi, \pi]}" /> define <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Ctheta%29%7D%5Crangle+%3D+%5Ccos%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Csin%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" class="latex" title="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Ctheta%29%7D%5Crangle+%3D+-%5Csin%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Ccos%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" class="latex" title="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" /> .

Now we describe a (quantum) strategy with winning probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. In each case Alice and Bob respond with their measurement outcome, where subscripts of the measurement basis vectors correspond to the answer to be sent back to the verifier.
<ul>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%280%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%280%29%7D%5Crangle+%5C%7D+%3D+%5C%7B+%7C%7B0%7D%5Crangle+%2C+%7C%7B1%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" class="latex" title="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1}" class="latex" title="{ s=1}" />, Alice measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" />. Alice answers bit <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 0}" class="latex" title="{ a = 0}" /> if outcome is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbeta_0%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \beta_0(\cdot)}" class="latex" title="{ \beta_0(\cdot)}" /> and answers <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 1}" class="latex" title="{ a = 1}" /> otherwise.</li>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" />, Bob measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=1}" class="latex" title="{ t=1}" />, Bob measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" />.</li>
 	<li> Each player responds with their respective measurement outcome.</li>
</ul>
<b>Lemma 2</b> <em><a name="goodstrategy"></a> Alice and Bob win the CHSH game with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. </em>
<em><br /><b></b>Proof.</em> We will show that for each pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the pair of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> is correct with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />. We can split the pairs of questions into the two cases <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />:
<ul>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" />) The three cases <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%3D%280%2C0%29%2C%280%2C1%29%2C%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)=(0,0),(0,1),(1,0)}" class="latex" title="{ (s,t)=(0,0),(0,1),(1,0)}" /> are all analogous: in each case Alice an Bob must output the same answer, and in each case Bob’s measurement basis is almost the same as Alice’s except rotated by a small angle <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpm%5Cpi%2F8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pm\pi/8}" class="latex" title="{ \pm\pi/8}" />.
Of the three above cases we consider the one where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t=0}" class="latex" title="{ s,t=0}" /> and check that indeed the two measurement outcomes agree with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />: When Alice measures her qubit and obtains some bit <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" />, the shared pair <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta}\rangle}" class="latex" title="{ |{\beta}\rangle}" /> collapses to <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle _A |{a}\rangle _B}" class="latex" title="{ |{a}\rangle _A |{a}\rangle _B}" />. Indeed, since the question was <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures her qubit in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle,|1\rangle\}}" class="latex" title="{ \{|0\rangle,|1\rangle\}}" />. This means that Alice applies the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%5Clangle+0%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%2C%7C1%5Crangle%5Clangle+1%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" class="latex" title="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" /> on the global state. The post-measurement state is the normalization of

<img src="https://s0.wp.com/latex.php?latex=%7B+%28+%7C%7Ba%7D%5Crangle+%5Clangle%7Ba%7D%7C+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%3D%5Cfrac%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B0%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C0%7D%7D%5Cotimes+%7C+0%5Crangle+%2B+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B1%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C1%7D%7D%5Cotimes+%7C%7B1%7D%5Crangle+%3D%5Cfrac+%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" class="latex" title="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" />

because <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+a+%7C%7Ba%27%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle a |{a'}\rangle}" class="latex" title="{ \langle a |{a'}\rangle}" /> can be viewed as a Kronecker delta of <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a'}" class="latex" title="{ a'}" />. In particular, Bob is now in the pure state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle}" class="latex" title="{ |{a}\rangle}" /> .

Because Bob received question <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" /> he measures in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_b%28%5Cpi%2F8%29%7D%5Crangle+%5C%7D_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" class="latex" title="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" /> Therefore his probability of correctly outputting <img src="https://s0.wp.com/latex.php?latex=%7B+b%3Da%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=a}" class="latex" title="{ b=a}" /> is

<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D%5B%5Ctext%7BBob+gets+outcome+%7Da%5D+%3D+%7C%5Clangle%5Cbeta_a%28%5Ctfrac%7B%5Cpi%7D%7B8%7D%29+%7C%7Ba%7D%5Crangle+%7C%5E2+%3D+%5Ccos%5E2%5Cleft%28%5Cfrac%7B%5Cpi%7D%7B8%7D%5Cright%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" class="latex" title="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" />

</li>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />)
Now consider the case <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%2Ct%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1,t=1}" class="latex" title="{ s=1,t=1}" /> where Alice and Bob are supposed to give different answers. Alice measures in basis consisting of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B-%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" />. If Alice gets outcome <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> then the post-measurement global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" class="latex" title="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" /> . Therefore when Bob applies the measurement in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%5C%7D_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" class="latex" title="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" /> he mistakenly outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> only with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_a%28%5Cfrac%5Cpi4%29+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%7C%5E2%3D%5Csin%5E2%28%5Cfrac%5Cpi8%29%3D1-%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" class="latex" title="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" />.</li>
</ul>

<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#goodstrategy">2</a> implies a lower bound on the value of the CHSH game.
<h4>Corollary</h4>
<em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%5Cge%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" class="latex" title="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" /> </em>

 
<br />It turns out that this lower bound is sharp, that is, the strategy just described is optimal.

<h4>Lemma</h4><em> The value of the CHSH game using a quantum strategy is at most <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+%3D+%5Ccos%5E2%5Cfrac%7B%5Cpi%7D%7B8%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" class="latex" title="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" />. </em>



<em><b>Proof.</b></em>

We can describe the quantum strategy of Alice and Bob in an XOR game by (i) a shared quantum state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" /> (note that for the CHSH game, <img src="https://s0.wp.com/latex.php?latex=%7B+d%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d=2}" class="latex" title="{ d=2}" />); (ii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA%5E0_s%2C+A%5E1_s%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A^0_s, A^1_s\}}" class="latex" title="{ \{A^0_s, A^1_s\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> sent to Alice; (iii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB%5E0_t%2C+B%5E1_t%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B^0_t, B^1_t\}}" class="latex" title="{ \{B^0_t, B^1_t\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> sent to Bob.

The probability of answering <img src="https://s0.wp.com/latex.php?latex=%7B+%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a, b)}" class="latex" title="{ (a, b)}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)}" class="latex" title="{ (s, t)}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" class="latex" title="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" /> . Now let us write <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%3DA%5E0_s+-+A%5E1_s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s=A^0_s - A^1_s}" class="latex" title="{ A_s=A^0_s - A^1_s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_t%3DB%5E0_t+-+B%5E1_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_t=B^0_t - B^1_t}" class="latex" title="{ B_t=B^0_t - B^1_t}" /> so that for any <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" />, we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5Ea+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%2C+B_t%5Eb+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" class="latex" title="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" />

Note that since the possible outcomes here are finite, <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are Hermitian and we may assume have bounded norm of 1. Furthermore, we assume that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are <em>observables</em> so that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5E2+%3D+B_t%5E2+%3D+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^2 = B_t^2 = {\mathbb{I}}}" class="latex" title="{ A_s^2 = B_t^2 = {\mathbb{I}}}" /> .

Now denoting <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(a\oplus b)}" class="latex" title="{ f_{s, t}(a\oplus b)}" /> as the XOR predicate to be computed, we can write the quantum game value as

<img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5Ea%5C%7D%2C+%5C%7BB_t%5Eb%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%28-1%29%5E%7Bab%7D%7D%7B4%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29%7D%7B2%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " class="latex" title="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " />

where the summation <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Ba%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%28%5Ccdot%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" class="latex" title="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" /> has been evaluated in the last line.

Now note that the first term is independent of the quantum strategy and as a result equals the value of the uniformly random strategy which is 1/2. So we proceed to focus on the second term. Note that for CHSH <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29+%3D+%28-1%29%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" class="latex" title="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" /> simplifying the second term to

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B8%7D%28+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+-+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+%29.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" class="latex" title="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" />

Next, we invoke Tsirelson’s Theorem (See Theorem <a href="https://windowsontheory.org/feed/#thmtsirelson">3</a>) to bound this second term as

<img src="https://s0.wp.com/latex.php?latex=%3D+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1+%2B+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%5C%7C%7B%5Ctextbf%7Bx%7D%7D_0%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7By%7D%7D_1%5C%7C+%2B+%5C%7C%7B%5Ctextbf%7Bx%7D%7D_1%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7By%7D%7D_1%5C%7C%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B8%7D%5Csqrt%7B2%5C%7C%7B%5Ctextbf%7By%7D%7D_0%5C%7C%5E2+%2B+2%5C%7C%7B%5Ctextbf%7By%7D%7D_1%5C%7C%5E2%7D+%5Cleq+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " class="latex" title="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " />

where we have used Cauchy-Schwartz and the concavity of the <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csqrt%7B%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sqrt{\cdot}}" class="latex" title="{ \sqrt{\cdot}}" /> function.

This completes our proof showing the exact characterization of the value (<img src="https://s0.wp.com/latex.php?latex=%7B+%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%3D%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" class="latex" title="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" />) of the CHSH game using a quantum strategy. This proof is an adaptation of the one in [12]. 
<div align="right">□</div>
<b>Theorem 3 (Tsirelson’s Theorem [1])</b> <em><a name="thmtsirelson"></a> For any <img src="https://s0.wp.com/latex.php?latex=%7B+n%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n\times n}" class="latex" title="{ n\times n}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+C+%3D+%28C_%7Bs%2C+t%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C = (C_{s, t})}" class="latex" title="{ C = (C_{s, t})}" />, the following are equivalent: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> There exist <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cin%5Cmathbb%7BN%7D%2C+%7C%7B%5Cphi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5E%7Bd%7D%5Cotimes%5Cmathbb%7BC%7D%5E%7Bd%7D%2C+A_s%2C+B_t%5Cin%5Ctext%7BHerm%7D%28%5Cmathbb%7BC%7D%5Ed%29%2C+A_s%5E2+%3D+B_t%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" class="latex" title="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" /> such that for any <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in[n]}" class="latex" title="{ s, t\in[n]}" /> <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" class="latex" title="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" /> . Further this would imply that <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cleq+2%5E%7B%5Clceil%5Cfrac%7Bn%2B2%7D%7B2%7D%5Crceil%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" class="latex" title="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" />;</li>
 	<li> There exist real unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%2C+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%5Cin%7B%5Cmathbb%7BR%7D%7D%5E%7Bn%2B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" class="latex" title="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in [n]}" class="latex" title="{ s, t\in [n]}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%5Ccdot+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" class="latex" title="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" />;</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
<h2>Entangled unique games are easy</h2>
The CHSH game provides the first example that the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> of a nonlocal game can exceed the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" />. XOR-games like the CHSH game are the special case corresponding to alphabet size <img src="https://s0.wp.com/latex.php?latex=%7B+k%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k=2}" class="latex" title="{ k=2}" /> of the class of <em>unique games</em> :
<h4>Definition (Unique Games)</h4>
<em> A 2-prover 1-round game is called a <em>unique game</em> if its constraints are of the form <img src="https://s0.wp.com/latex.php?latex=%7B+b%3D%5Cpi_%7Bij%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=\pi_{ij}(a)}" class="latex" title="{ b=\pi_{ij}(a)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpi_%7Bij%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pi_{ij}}" class="latex" title="{ \pi_{ij}}" /> is a permutation of the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" /> for each edge <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Csim+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\sim j}" class="latex" title="{ i\sim j}" />. </em>

 The famous <em>unique games conjecture</em> (UGC) by Khot says that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> is NP-hard to approximate for unique games. Surprisingly, Kempe et al. showed that a natural semidefinite relaxation for unique games yields an approximation to the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> which can be computed in polynomial time. In other words the UGC is false for entangled provers, in contrast to the classical case where the conjecture is open.
<br />Theorem 4 <em><a name="efficientUGC"></a> There is an efficient (classical) algorithm which takes a description of a nonlocal game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> as its input and outputs <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" /> such that </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+1-6%281-%5Chat%5Comega%28G%29%29%5Cle%5Comega%5E%2A%28G%29%5Cle%5Chat%5Comega%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" class="latex" title="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" /></em>

<em>Put differently, if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D1-%5Cvarepsilon%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=1-\varepsilon^*}" class="latex" title="{ \omega^*(G)=1-\varepsilon^*}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D1-%5Chat%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=1-\hat\varepsilon}" class="latex" title="{ \hat\omega(G)=1-\hat\varepsilon}" />, then</em>

<em><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarepsilon%5E%2A%5Cin%5B%5Chat%5Cvarepsilon%2C6%5Chat%5Cvarepsilon%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" class="latex" title="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" /></em>

<em>
</em><em></em><em></em><em></em><em> </em>
<br />The algorithm of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> proceeds by relaxing the set of quantum strategies to a larger convex set <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> of <em>pseudo-strategies</em> and maximizing over <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> instead of actual strategies, a much easier task. In approximation theory one often encounters a collection of hypothetical moments not arising from a distribution, known as a pseudo-distribution. In contrast, our pseudo-strategies are actual conditional probability distributions on answers (conditional on the questions). What makes <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> a set of “pseudo”-strategies rather than actual strategies is that they may enjoy correlations which cannot be achieved without communication.
<h3> Convex relaxation of quantum strategies</h3>
We will define <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> to be a class of conditional probability distributions <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> on answers given questions. We will require that the pseudo-strategies satisfy a positive semidefinite constraint when arranged in matrix form. In particular this matrix has to be symmetric, so we symmetrize the conditional probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> by allowing each of <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> to be either a question for Alice or for Bob. That is, we extend the domain of definition for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times S\times T}" class="latex" title="{ \Sigma^2\times S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times (S\cup T)^2}" class="latex" title="{ \Sigma^2\times (S\cup T)^2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> are the question sets. So each question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> and answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> can be either for Alice or Bob — we indicate this by changing notation from <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%5Cin+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)\in S\times T}" class="latex" title="{ (s,t)\in S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" /> and for the answers replacing <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> by <img src="https://s0.wp.com/latex.php?latex=%7B+c%2Cc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c,c'}" class="latex" title="{ c,c'}" />.

<br />Definition 5 (Block-matrix form) <em><a name="to_matrix"></a> Given a function <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" /> defined on <img src="https://s0.wp.com/latex.php?latex=%7B+%28S%5Ccup+T%29%5E2%5Ctimes+%5CSigma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (S\cup T)^2\times \Sigma^2}" class="latex" title="{ (S\cup T)^2\times \Sigma^2}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+%7CS%7C%3D%7CT%7C%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |S|=|T|=n}" class="latex" title="{ |S|=|T|=n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5CSigma%7C%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\Sigma|=k}" class="latex" title="{ |\Sigma|=k}" />, define a <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> whose rows are indexed by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%2Cc%29%5Cin%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q,c)\in(S\cup T)\times\Sigma}" class="latex" title="{ (q,c)\in(S\cup T)\times\Sigma}" /> and columns by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%27%2Cc%27%29%5Cin+%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q',c')\in (S\cup T)\times\Sigma}" class="latex" title="{ (q',c')\in (S\cup T)\times\Sigma}" />, and whose entries are </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28q%2Cc%29%2C%28q%27%2Cc%27%29%7D%3D%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" class="latex" title="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" /></em>

<em>
</em><em></em><em> In other words <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> consists of <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> blocks where the block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> at position <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'}" class="latex" title="{ q,q'}" /> contains the entries <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7Cq%2Cq%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(\cdot\cdot|q,q')}" class="latex" title="{ \tilde{P}(\cdot\cdot|q,q')}" />. </em><br />
Definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a> is simply a convenient change of notation and we identify <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />, using either notation depending on the context.
<br />Definition 6 (Pseudo-strategies) <em><a name="Sdef"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> be the question sets for Alice and Bob, respectively. We say that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" /> (or its matrix form <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />) is a pseudo-strategy if: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite.<a name="positive"></a></li>
 	<li> For any pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Bc%2Cc%27%3D1%7D%5Ek+%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" class="latex" title="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" />.<a name="sum1"></a></li>
 	<li> The blocks <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> on the diagonal are themselves diagonal <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> matrices.<a name="diagonal"></a></li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
Define the winning probability or value of a pseudo-strategy as:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29%3D%5Cmathbb+E_%7B%28s%2Ct%29%5Csim+%5CPi%7D+%5Csum_%7Ba%2Cb%7D+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29V%28a%2Cb%7Cs%2Ct%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" class="latex" title="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" />

The algorithm outputs the maximum winning probability:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" class="latex" title="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" />

over pseudo-strategies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in \mathcal S}" class="latex" title="{ \tilde{P}\in \mathcal S}" />. This maximum is efficiently computable using standard semidefinite programming algorithms. As we will see, actual quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> which immediately implies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%5Cge%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)\ge\omega^*(G)}" class="latex" title="{ \hat\omega(G)\ge\omega^*(G)}" />. It then remains to show that the optimal pseudo-strategy can be approximated by an actual entangled strategy, thus bounding the gap from <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" />.
<h3> Quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /></h3>
Let us establish that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> is indeed a relaxation of the class of quantum strategies, that is, it contains the quantum strategies. So suppose we are given a quantum strategy. By equation <a href="https://windowsontheory.org/feed/#Qstrategy">1</a> the probability of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> is of the form

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%3D%5Clangle%5Cphi%7C%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b+%29%7C%5Cphi%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" />

for some PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> and some <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" />. This conditional probability distibution is not immediately in the form of a pseudo-strategy because we cannot evaluate it on pairs of Alice-questions or pairs of Bob-questions. We therefore have to extend it, as follows: Place all the column vectors <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" class="latex" title="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ca%29%5Cin+S%5Ctimes+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,a)\in S\times \Sigma}" class="latex" title="{ (s,a)\in S\times \Sigma}" /> side by side, and then append the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+I%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I\otimes B^t_b|\phi\rangle}" class="latex" title="{ I\otimes B^t_b|\phi\rangle}" />, resulting in a <img src="https://s0.wp.com/latex.php?latex=%7B+d%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d^2}" class="latex" title="{ d^2}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R}" class="latex" title="{ R}" />. We then define <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" /> through its matrix form (see the comment below definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a>): <a name="eqMp"></a>
<p align="center"><a name="eqMp"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7BP%7D%3A%3DR%5E%5Cdag+R%3D%5Cbegin%7Bpmatrix%7D+%28%5Clangle%5Cphi%7CA%5Es_a+A%5E%7Bs%27%7D_%7Ba%27%7D%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28s%27%2Ca%27%29%7D+%28%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D+%5C%5C%5C%5C+%28%5Clangle%5Cphi%7CB%5Et_b%5Cotimes+A%5Es_a+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28s%2Ca%29%7D+%28%5Clangle%5Cphi%7C%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_bB%5E%7Bt%27%7D_%7Bb%27%7D+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28t%27%2Cb%27%29%7D+%5Cend%7Bpmatrix%7D+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" class="latex" title="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" /></a></p>
<a name="eqMp">
</a><a name="eqMp"></a>
<b>Lemma 7</b> <em><a name="relaxation"></a> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}}" class="latex" title="{ M^{P}}" /> defined in <a href="https://windowsontheory.org/feed/#eqMp">2</a> is a pseudo-strategy, that is, <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\in\mathcal S}" class="latex" title="{ M^{P}\in\mathcal S}" />. </em>
<em><br />Proof.</em> We verify the conditions in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a>. Condition <a href="https://windowsontheory.org/feed/#positive">1</a> (<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Csucceq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\succeq0}" class="latex" title="{ M^{P}\succeq0}" />) holds because it is of the form <img src="https://s0.wp.com/latex.php?latex=%7B+R%5E%5Cdag+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R^\dag R}" class="latex" title="{ R^\dag R}" />. Condition <a href="https://windowsontheory.org/feed/#sum1">2</a> (Each block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}_{q,q'}}" class="latex" title="{ M^{P}_{q,q'}}" /> sums to <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />) holds because PVM’s sum to the identity. Condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> (Diagonal blocks <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DM%5E%7BP%7D_%7Bqq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=M^{P}_{qq}}" class="latex" title="{ \tilde M=M^{P}_{qq}}" /> are diagonal) holds because the projections in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^q}" class="latex" title="{ A^q}" /> are mutually orthogonal, hence <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Eq_cA%5Eq_%7Bc%27%7D+%7C%7B%5Cphi%7D%5Crangle+%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" class="latex" title="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" /> if <img src="https://s0.wp.com/latex.php?latex=%7B+c%5Cneq+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c\neq c'}" class="latex" title="{ c\neq c'}" />. 
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#relaxation">7</a> means <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%7BP%7D%5Cin+%5Cmathcal+S%7D%5Comega%5E%7BP%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" class="latex" title="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" /> is an (efficiently computable) upper bound for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" />:
<h4>Corollary</h4><em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%5Cge+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega\ge \omega^*(G)}" class="latex" title="{ \hat\omega\ge \omega^*(G)}" />. </em>



<br />To finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> we need to show that any pseudo-strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> can be <em>rounded</em> to an actual quantum strategy with answer probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> such that <a name="roundingobjective"></a>
<p align="center"><a name="roundingobjective"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Comega%5E%7BP%7D%5Cle+6%281-%5Comega%5E%7B%5Ctilde+P%7D%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" class="latex" title="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" /></a></p>
<a name="roundingobjective">
</a><a name="roundingobjective"></a> Applying this rounding to the optimal pseudo-strategy implies that

<img src="https://s0.wp.com/latex.php?latex=%7B+1-%5Comega%5E%2A%5Cle+6%281-%5Chat%5Comega%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-\omega^*\le 6(1-\hat\omega) }" class="latex" title="{ 1-\omega^*\le 6(1-\hat\omega) }" />

or <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%5Cge+1-6%281-%5Chat%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*\ge 1-6(1-\hat\omega)}" class="latex" title="{ \omega^*\ge 1-6(1-\hat\omega)}" />, which will finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.

<em><br /><b>Proof.</b></em>[Proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>] Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in\mathcal S}" class="latex" title="{ \tilde{P}\in\mathcal S}" /> be a pseudo-strategy. We construct a quantum strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DR%5E%5Cdag+R+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=R^\dag R }" class="latex" title="{ \tilde M=R^\dag R }" />

for <em>some</em> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%5Cin+%5Cmathbb+C%5E%7Br%5Ctimes+2nk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R\in \mathbb C^{r\times 2nk}}" class="latex" title="{ R\in \mathbb C^{r\times 2nk}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+r%5Cleq+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r\leq 2nk}" class="latex" title="{ r\leq 2nk}" />. Now let us define <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+u%5Es_a%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde u^s_a\rangle}" class="latex" title="{ |\tilde u^s_a\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+v%5Et_b%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde v^t_b\rangle}" class="latex" title="{ |\tilde v^t_b\rangle}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^{r}}" class="latex" title="{ \mathbb C^{r}}" />, and let <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_a%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_a}\rangle}" class="latex" title="{ |{u^s_a}\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%5Et_b%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v^t_b}\rangle}" class="latex" title="{ |{v^t_b}\rangle}" /> be the same vectors normalized. The strategy is constructed as follows. Alice and Bob share the maximally entangled state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%3D%5Cfrac1%7B%5Csqrt+r%7D%5Csum_%7Bi%3D1%7D%5Er%7Ci%5Crangle%7Ci%5Crangle%5Cin%5Cmathbb+C%5Er%5Cotimes%5Cmathbb+C%5Er+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" class="latex" title="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" />

Before deciding on Alice and Bob’s PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> let us see what this choice of shared state means for the conditional distribution on answers (see equation <a href="https://windowsontheory.org/feed/#Qstrategy">(1)</a>).
<p align="center"> <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle+%3D%5Cfrac1r%5Csum_%7Bi%2Cj%3D1%7D%5Er%5Clangle+i+%7C+A%5Es_a%7C+j%5Crangle%5Clangle+i+%7C+B%5Et_b%7C+j%5Crangle+%3D%5Cfrac1r+A%5Es_a%5Ccdot+B%5Et_b%3D%5Cfrac1r%5Clangle+A%5Es_a%2C%5Coverline%7BB%5Et_b%7D%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" class="latex" title="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" />, (*)</p>
where the bar represents entrywise complex conjugation, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cdot}" class="latex" title="{ \cdot}" /> is the entrywise dot product of matrices, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5C%3A%2C%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\:,\rangle}" class="latex" title="{ \langle\:,\rangle}" /> the entrywise complex inner product (Hilbert-Schmidt inner product).

We now choose the measurements. Given question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, Alice measures in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%3D%28A%5Es_a%29_%7Ba%3D0%7D%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s=(A^s_a)_{a=0}^k}" class="latex" title="{ A^s=(A^s_a)_{a=0}^k}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%3D+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%5Ctext%7B+for+%7Da%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DA%5Es_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" class="latex" title="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" />

Similarly, Bob on question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> applies the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et_b%3D+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%5Ctext%7B+for+%7Db%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DB%5Et_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" class="latex" title="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" />

The condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a> ensures that for any question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_1%7D%5Crangle+%2C%5Cldots%2C+%7C%7Bu%5Es_1%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" class="latex" title="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" /> are orthogonal so that this is a valid PVM.

The measurement outcome “<img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />” is interpreted as “fail”, and upon getting this outcome the player attempts the measurement again on their share of a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />. This means that the strategy requires many copies of the entangled state to be shared before the game starts. It also leads to the complication of ensuring that with high probability the players measure the same number of times before outputting their measurement, so that the outputs come from measuring the same entangled state.

By (*), at a given round of measurements the conditional distribution of answers is given by

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%3D%5Cfrac1r%5CBig%5Clangle+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7B+u%5Es_a%7D%7C+%5C%3A%2C%5C%3A+%7C%7B%7Bv%5Et_b%7D%5Crangle+%7D+%5Clangle%7B+%7Bv%5Et_b%7D%7C+%7D%5CBig%5Crangle%3D%5Cfrac1r%7C%5Clangle+%7Bu%5Es_a%7D%7Cv%5Et_b%5Crangle%7C%5E2%3D%5Cfrac1%7Br%7C%5Ctilde+u%5Es_a%7C%5E2%7C%5Ctilde+v%5Et_b%7C%5E2%7D%5CBig%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29%5E2%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" />

We wish to relate the LHS to <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}}" />, so to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1r}" class="latex" title="{ \frac1r}" /> each prover performs repeated measurements, each time on a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />, until getting an outcome <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cneq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \neq0}" class="latex" title="{ \neq0}" />. Moreover, to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%7Cu%5Es_a%7C%5E2%7Cv%5Et_b%7C%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{|u^s_a|^2|v^t_b|^2}}" class="latex" title="{ \frac1{|u^s_a|^2|v^t_b|^2}}" />, each prover consults public randomness and accepts the answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a\in[k]}" class="latex" title="{ a\in[k]}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cu%5Ea_s%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |u^a_s|^2}" class="latex" title="{ |u^a_s|^2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cv%5Eb_t%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |v^b_t|^2}" class="latex" title="{ |v^b_t|^2}" /> respectively, or rejects and start over depending on the public randomness. Under a few simplifying conditions (more precisely, assuming that the game is <em>uniform</em> meaning that an optimal strategy exists where the marginal distribution on each prover’s answers is uniform), we can let <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cle+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ca%2Ct%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,a,t,b}" class="latex" title="{ s,a,t,b}" />, and one can ensure that the conditional probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> of the final answers satisfy
<p align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1%2Fk-P%28a%2Cb%7Cs%2Ct%29%5Cle+3%5Cbig%281%2Fk-k%28M%5E%7B%5Ctilde+P%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2%5Cbig%29%2C%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" class="latex" title="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" />
<a name="PM"></a>

At this stage it is important that we are dealing with a <em>unique game</em> . Indeed, by <a href="https://windowsontheory.org/feed/#PM">(4)</a> we have for every <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" />,

<img src="https://s0.wp.com/latex.php?latex=1-%5Csum_%7Ba%3D1%7D%5Ek+P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29%3D%5Csum_a+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29+%5CBig%29+%5C%5C+%5Cleq+3%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-k%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2+%5CBig%29+%5C%5C+%5Cleq+6%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D%5Cbig%28%5Cfrac%7B1%7D%7Bk%7D-M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cbig%29%3D6%5CBig%281-%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " class="latex" title="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " />

where the last inequality follows from concavity. Taking the expectation over <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> implies the bound <a href="https://windowsontheory.org/feed/#roundingobjective">(3)</a>, thus concluding the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.
</p><div align="right">□</div>
<h2>General games are hard</h2>
We just saw that a specific class of games becomes easy in the presence of shared entanglement, in that semidefinite programming allows the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> to be approximated to within exponential precision in polynomial time. Does this phenomenon hold more generally, so that the value of entangled games can always be efficiently approximated? We answer in the negative, by constructing a game where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> is NP-hard to approximate to within inverse-polynomial factors. The complexity for 2P-1R entangled games can be strengthened to constant-factor NP-hardness, putting it on par with the classical PCP theorem. This result is used to prove (with some conditions) the games formulation of the quantum PCP theorem, which states that the entangled value of general games is QMA-hard to approximate within a constant factor.
<h3> Formulation of game</h3>
Given any instance <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> of a <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP (constraint satisfaction problem, where <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> is the number of literals), we can define a clause-vs-variable game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> (see clause-vs-variable figure):
<ol>
 	<li> The referee (verifier) randomly sends a clause to Alice (first prover) and a variable to Bob (second prover).</li>
 	<li> Alice and Bob reply with assignments.</li>
 	<li> The referee accepts if Alice’s assignment satisfies the clause and Bob’s answer is consistent with Alice’s.</li>
</ol>
To show hardness of approximation, we need to go beyond the usual 2-player construction. In particular, in our game [3] one of the players receives an extra dummy question (see subfigure (a)). Mathematically, the result is very similar to introducing another player and having the referee play the 2-player game with two players chosen randomly [4] (see subfigure (b)). In either variation, the quantum phenomenon of <em>monogamy of entanglement</em> , imposing that only two parties can be maximally entangled to one another, is key to establishing hardness. The players do not know where to use their entanglement, which prevents them from coordinating as well as they could in the standard game.
<figure style="width: 25em; margin: auto;">  
<a href="https://windowsontheory.org/?attachment_id=7233"><img src="https://windowsontheory.files.wordpress.com/2019/01/2player.png?w=107&amp;h=150" alt="" width="107" class="attachment-thumbnail size-thumbnail" height="150" /></a>
<a href="https://windowsontheory.org/?attachment_id=7234"><img src="https://windowsontheory.files.wordpress.com/2019/01/3player.png?w=107&amp;h=150" alt="" width="107" class="attachment-thumbnail size-thumbnail" height="150" /></a>


Two variations of a 2-player clause-vs-variable game; new features are in red and shared entanglement is denoted in blue. In the standard game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" />, given <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%3D%28C_1%2C%5Cldots%2CC_m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi=(C_1,\ldots,C_m)}" class="latex" title="{ \phi=(C_1,\ldots,C_m)}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> variables <img src="https://s0.wp.com/latex.php?latex=%7B+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x_i}" class="latex" title="{ x_i}" />, (1) the referee R randomly sends a clause <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> to Alice A and a literal index <img src="https://s0.wp.com/latex.php?latex=%7B+t%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t\in[k]}" class="latex" title="{ t\in[k]}" /> to Bob B, (2) A replies with an assignment <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> and B replies with assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" />, (3) R accepts iff <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a_t%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_t=b}" class="latex" title="{ a_t=b}" />. In variation (a), R sends an additional dummy index <img src="https://s0.wp.com/latex.php?latex=%7B+l%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ l\in[k]}" class="latex" title="{ l\in[k]}" />, so that B replies with an additional assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b'}" class="latex" title="{ b'}" />, but he does not know which is the right variable. Equivalently, in (b) a third player Charlie C is introduced, but <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> is played with two randomly chosen players. Since only parties can be maximally entangled and the players do not know who is playing the game, they cannot coordinate perfectly. </figure>
<h3> NP-hardness of approximating the entangled value</h3>
To prove hardness, we rely on several results from classical complexity theory.
<br />Theorem 8 ([6]) <em> Given an instance of 1-in-3 3SAT (a CSP), it is NP-hard to distinguish whether it is satisfiable or no assignments satisfy more than a constant fraction of clauses. <a name="thmCSP"></a> </em>
<br />Theorem 9 ([2]) <em> For a PCP game <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (emulating the CSP) and its oracularization <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> (transformation to a 2P-1R game), </em>

<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%28G%29%5Cleq+%5Comega%28G%27%29%5Cleq+1-%5Cfrac%7B1-%5Comega%28G%29%7D%7B3%7D%5C%2C.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" class="latex" title="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" /></em></p>
<em>
</em><em> <a name="thmMIP"></a> </em>
Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a> establishes the CSP variant of the classical PCP theorem: distinguishing between <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)=1}" class="latex" title="{ \omega(\phi)=1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq 1/2}" class="latex" title="{ \omega(\phi)\leq 1/2}" /> is NP-hard for some <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP. Here, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)}" class="latex" title="{ \omega(\phi)}" /> denotes the maximum fraction of clauses that are simultaneously satisfiable. Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> relates the general game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> obtained from the CSP to a two-player one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G'}" class="latex" title="{ G'}" />, in terms of the value (probability of winning) the game. The first inequality, equivalently saying <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega(G_\phi)}" class="latex" title="{ \omega(\phi)\leq \omega(G_\phi)}" />, is achieved since the players can answer the questions in the game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> to satisfy the clauses in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" />. These theorems together imply that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G_\phi)}" class="latex" title="{ \omega(G_\phi)}" /> is NP-hard to approximate to within constant factors.

Allowing the two players to share entanglement can increase the game value to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%5Cgeq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" />. Classical results do not necessarily carry over, but exploiting monogamy of entanglement allows us to limit the power of entangled strategies. One can show the following lemma, which is weaker than what we have classically.
<br /><b>Lemma 10 ([3])</b> <em> There exists a constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c&gt;0}" class="latex" title="{c&gt;0}" /> such that for a CSP <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" />, </em>
<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" class="latex" title="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" /></em></p>
<em>
</em><em> where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the number of variables. <a name="lemmaIto"></a> </em>
Combining Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> and Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a>, we have

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" class="latex" title="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" />

Using Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a>, approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)}" /> is NP-hard to within inverse polynomial factors. Proving Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a> takes some work in keeping track of approximations. For simplicity, we will show a less quantitative statement and indicate where the approximations come in.
<br />Proposition 11 (adapted from [13]) <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> is satisfiable iff <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%5E%2A%28G_%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\omega^*(G_\phi)=1}" class="latex" title="{\omega^*(G_\phi)=1}" />. <a name="proposition"></a> </em>
<h3> Proof of Proposition <a href="https://windowsontheory.org/feed/#proposition">11</a></h3>
The forward direction is straightforward: If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> is satisfiable, then there exists a perfect winning strategy where the questions are answered according to the satisfying assignment.

For the reverse direction, suppose there exists a strategy that succeeds with probability 1, specified by a shared entangled state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" /> and measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%28A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%29_%7Ba_1%2C%5Cldots%2Ca_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" class="latex" title="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" /> for Alice and <img src="https://s0.wp.com/latex.php?latex=%7B+%28B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%29_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (B^{t,l}_{b,b'})_{b,b'}}" class="latex" title="{ (B^{t,l}_{b,b'})_{b,b'}}" /> for Bob, where the questions <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+t%2Cl%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t,l\in[k]}" class="latex" title="{ t,l\in[k]}" /> and the answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> are from the CSP’s alphabet. Since one of the questions/answers for Bob corresponds to a dummy variable that is irrelevant to the game, trace over the dummy variable to define a new measurement operator <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5Et_b%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl%2Cb%27%7D+B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" class="latex" title="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" />. We can introduce a distribution on assignments to the <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> relevant variables,

<a name="eqpB"></a>
<p align="center"><a name="eqpB"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D%5Ccdots%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C.++%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" class="latex" title="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" /></a></p>
<a name="eqpB">
</a><a name="eqpB"></a> If we show that the distribution for assignments <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{i_1},\ldots,a_{i_k}}" class="latex" title="{a_{i_1},\ldots,a_{i_k}}" /> on variables <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cldots%2Cx_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i_1},\ldots,x_{i_k}}" class="latex" title="{x_{i_1},\ldots,x_{i_k}}" /> in any clause <img src="https://s0.wp.com/latex.php?latex=%7BC_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_j}" class="latex" title="{C_j}" /> is <a name="eqpA"></a>
<p align="center"><a name="eqpA"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" class="latex" title="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" /></a></p>
<a name="eqpA">
</a><a name="eqpA"></a> then, since the players win with certainty, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> has a satisfying assignment. To transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a>, we need a relation between the <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> measurement operators and a way to commute the <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> operators.

The success probability of the players’ strategy is expressed as

<img src="https://s0.wp.com/latex.php?latex=%7B+P%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%5Cin%5Bm%5D%7D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%5Cin+C_j%7D+%5Csum_%7B%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D+%5Clangle%7B%5Cpsi%7D%7C+A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%2C%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" class="latex" title="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" />

where <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is the index of one of the <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> variables on which <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> acts, and <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)\vdash C_j}" class="latex" title="{ (a_1,\ldots,a_k)\vdash C_j}" /> indicates that the assignment satisfies the clause. By positivity and summation to identity of the measurement operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}}" class="latex" title="{ \tilde{B}}" />, each term is at most 1; for our hypothesis <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1}" class="latex" title="{ P=1}" />, each has to be 1. Hence, using orthogonality of the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%5Cotimes%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" class="latex" title="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_i}" class="latex" title="{ a_i}" />, we have <a name="eqrelation"></a>
<p align="center"><a name="eqrelation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7B%5Csubstack%7B%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5Cvdash+C_j+%5C%5C+a_i%3Db%7D%7D+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%3D+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D%7C%5Cpsi%5Crangle%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" class="latex" title="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" /></a></p>
<a name="eqrelation">
</a><a name="eqrelation"></a> for any <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cin+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\in C_j}" class="latex" title="{ i\in C_j}" />.

We now demonstrate that two different <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_1}_{b_1}}" class="latex" title="{ \tilde{B}^{t_1}_{b_1}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_2}_{b_2}}" class="latex" title="{ \tilde{B}^{t_2}_{b_2}}" /> commute, so that Bob can match any satisfied clause/variable.

<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%3D++%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_1%2Cb_1%27%7D+B%5E%7Bt_1%2Cl_1%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_2%2Cb_2%27%7D+B%5E%7Bt_2%2Cl_2%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_2%2Cb_1%27%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_1%2Cb_2%27%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " class="latex" title="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate the measurements. The third line follows by the orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^{t_1,t_2}_{b_1,b_2}}" class="latex" title="{ B^{t_1,t_2}_{b_1,b_2}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+b_1%2Cb_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b_1,b_2}" class="latex" title="{ b_1,b_2}" />. For the fourth equation, we simply swap <img src="https://s0.wp.com/latex.php?latex=%7B+t_1%2Ct_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_1,t_2}" class="latex" title="{ t_1,t_2}" /> since the questions are indistinguishable to Bob. Thus, we can see how the dummy variable comes into play. If we had assumed <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1-\epsilon}" class="latex" title="{ P=1-\epsilon}" /> and kept track of approximations, we would find <a name="eqcommutation"></a>
<p align="center"><a name="eqcommutation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Cb_1%7D%5Csum_%7Bt_2%2Cb_2%7D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%28%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+-+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%29+%7C%5Cpsi%5Crangle+%5CrVert%5E2+%3D+O%28%5Cepsilon%29%5C%2C.++%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" class="latex" title="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" /></a></p>
<a name="eqcommutation">
</a><a name="eqcommutation"></a> This approximate commutativity results in the hardness of approximation holding only to within inverse poly<img src="https://s0.wp.com/latex.php?latex=%7B+%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (n)}" class="latex" title="{ (n)}" /> factors.

Now we are ready to transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a> to conclude the proof.

<img src="https://s0.wp.com/latex.php?latex=p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D+%5Cldots+%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bi_1%7D_%7Ba_%7Bi_1%7D%7D+%5Cldots+%5Ctilde%7BB%7D%5E%7Bi_k%7D_%7Ba_%7Bi_k%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3Dp%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5C%2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " class="latex" title="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqcommutation">10</a>) to commute the measurement operators, along with their properties of orthogonality and summation to identity. For the third equality, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate Bob’s measurements to Alice’s, along with orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Ej_%7Ba_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^j_{a_{i_1,\ldots,i_k}}}" class="latex" title="{ A^j_{a_{i_1,\ldots,i_k}}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_{i_1,\ldots,i_k}}" class="latex" title="{ a_{i_1,\ldots,i_k}}" />. 
<div align="right">□</div>
<h3> Constant-factor NP-hardness</h3>
The weakness in the above two-player game carries over from the original three-player variant. Thus, to achieve constant-factor NP-hardness of approximation, we could start with a different multiplayer game. Vidick [11] establishes the soundness of the “plane-vs-point” low-degree test (checking that the restriction of a low-degree polynomial to a plane matches its value at some point) in the presence of shared entanglement. <em> Soundness </em>, in the eponymous probabilistically checkable proof (PCP) formulation of the PCP theorem, refers to the verifier accepting a wrong proof with some bounded probability; bounding with a constant maps to constant-factor hardness of approximation. Here, soundness comes from a strong bound on error accumulation, similar to our approximate commutativity, but relies on the players’ Hilbert space being decomposable into three parts (i.e., there being three players). The particular game is constructed by combining the low-degree test with the 3-SAT test (encoding satisfying assignments in a low-degree polynomial), which can be reduced to the three-player QUADEQ test (testing satisfiability of a system of quadratic equations in binary variables, which is NP-complete). By the strong soundness result, the entangled value is NP-hard to approximate to within constant factors. Natarajan et al. [7] show that soundness holds even for two players, using a semidefinite program. They then construct a two-player game in a way similar to what we demonstrated.
<h3> Constant-factor QMA-hardness</h3>
The above can be thought of as the games formulation of the classical PCP theorem holding under shared entanglement. A true quantum PCP theorem states that the entangled value of general games is QMA-hard to approximate to within constant factors. Natarajan et al. [8] establish such a theorem, but under randomized reductions. This requirement stems from the lack of a sufficiently strong QMA-hardness result for local Hamiltonians (the quantum analog of CSPs). The soundness of the two-player low-degree test above is one instrumental component in the proof.
<h2>How much entanglement is needed?</h2>
We now focus on the question of quantifying exactly how much entanglement is needed to play XOR games optimally. As we shall see, the answer depends on the size of the question sets posed to Alice &amp; Bob in the game. The previous bound given by Tsirelson [10] (see table below) is tight for certain families of games, but is not tight for other families of games (such as a generalization of the CHSH game). The reason for this discrepancy is closely tied in with the the properties of the representation of the Observables that form the Optimal Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />). Slofstra [9] shows that if the Observables constitute a Clifford Algebra (that is, the solutions are pair-wise anti-commutative), then the strategy is minimally entangled (uses the least number of entangled bits) iff the strategy is a unique solution to the SDP rounding problem. As a trivial corollary, if the SDP rounding problem does not have a unique solution (and a correspondingly unique strategy), then there exists a Non-Clifford optimal strategy that uses (atleast) <img src="https://s0.wp.com/latex.php?latex=%7B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |T|}" class="latex" title="{ |T|}" /> bits of entanglement less than the Clifford strategy. Slofstra further states that minimally entangled <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-optimal strategies may be constructed for XOR games where the optimal strategies have ‘stable’ representations. For the purposes of this post, we will analyze the exact result and merely state the approximate result.
<h3> Main Results</h3>
<h4><u>EXACT</u></h4>
For the exact realm, the table below summarizes Slofstra and Tsirelson’s main results.
<table border="1px">
<tbody>
<tr>
<th>Person</th>
<th> Strategy</th>
<th> Bound(entangled bits)</th>
</tr>
<tr>
<td> Slofstra</td>
<td> (Possibly) Non-Clifford</td>
<td> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(N)}" class="latex" title="{ \log_{2}(N)}" /></td>
</tr>
<tr>
<td> Tsirelson</td>
<td>Clifford</td>
<td><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" /></td>
</tr>
</tbody>
</table>
Here, <img src="https://s0.wp.com/latex.php?latex=%7B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r}" class="latex" title="{ r}" /> is the largest integer such that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbinom%7Br+%2B+1%7D%7B2%7D+%3C+%7CS%7C+%2B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \binom{r + 1}{2} &lt; |S| + |T|}" class="latex" title="{ \binom{r + 1}{2} &lt; |S| + |T|}" /> and corresponds to the maximum-rank of an extremal point in the quantum correlation matrix corresponding to an optimal strategy.
<img src="https://s0.wp.com/latex.php?latex=%7B+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ N}" class="latex" title="{ N}" /> is the minimum dimension of the representations of the Operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />).
<h4><u>APPROXIMATE</u></h4>
In the approximate realm, the minimum entanglement dimension of the representation of the Operators from an <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-Optimal Strategy is: min(<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BO%7D%28%5Cepsilon%5E%7B%5Cfrac%7B-1%7D%7B12%7D%7D%29%2C+2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" />).

As we shall see, Slofstra’s theorem allows us to recover Tsirelson’s bound easily by using a fact from Representation Theory about the irreducible representations of Clifford Algebras, but stands as a more general lower bound for solutions that aren’t Clifford.
<h3> Marginals and Solution Algebras</h3>
We’ll begin by introducing 3 key ideas:
i) Degeneracy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \leftrightarrow}" class="latex" title="{ \leftrightarrow}" /> Non-Degeneracy
ii) Existence of Marginals
iii) Solution Algebra

Once these ideas are defined and their notions made clear, we will be in a position to state the main result and sketch a proof for it.
<h4>Definition (Marginal Strategy)</h4>
<em> Given an Optimal Quantum Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />), a marginal constitutes <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}_{j \in T}}" class="latex" title="{ \{B_{j}\}_{j \in T}}" />, and the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> with respect to <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> (<img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{B}}" class="latex" title="{ \rho_{B}}" />). </em>

 It is also possible to dualize the definition for obtaining <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}_{i \in S}}" class="latex" title="{ \{A_{i}\}_{i \in S}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{A}}" class="latex" title="{ \rho_{A}}" />.
We now define the notion of degeneracy, which is critical when proving the main theorem. The main point to drive home is that a degenerate optimal quantum strategy can be reduced to a unique, non-degenerate optimal quantum strategy.
<h4>Definition (Degenerate Quantum Strategy)</h4>
<em> A quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />) is said to be degenerate if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cexists+%28P+%5Cin+H_A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \exists (P \in H_A)}" class="latex" title="{ \exists (P \in H_A)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28Q+%5Cin+H_B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (Q \in H_B)}" class="latex" title="{ (Q \in H_B)}" /> such that:
i) <img src="https://s0.wp.com/latex.php?latex=%7B+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P}" class="latex" title="{ P}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i}" class="latex" title="{ A_i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28P+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" />
ii) <img src="https://s0.wp.com/latex.php?latex=%7B+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Q}" class="latex" title="{ Q}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_j}" class="latex" title="{ B_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+Q%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" /> </em>

 Since we can efficiently construct for any degenerate Optimal Quantum Strategy a unique, non-degenerate Optimal Quantum Strategy, we will now assume WLOG that every Optimal Quantum Strategy is non-degenerate (and unique).

We now define the (unique) existence of marginal biases, which correspond to constants for the rows of the quantum correlation matrix (which is a generalization of the classical pay-off). An equivalent statement can be made for columns (<img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j}}" class="latex" title="{ d_{j}}" />) by dualizing the existence of row marginals. These constants can be thought of as representing the (expected) optimum-payoff possible for a set of operator choices by one player, given that the other player’s choice is fixed. Intuitively, this can be seen as “collapsing” the quantum correlation matrix into a column, by summing over the rows (or collapsing into a row, by summing over the columns).
<br /><b>Lemma 12 (Existence of Marginals)</b> <em> For all <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR games G, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5C%7Bc_%7Bi%7D+%5Cgeq+0+%5Chspace%7B1mm%7D+%7C+%5Chspace%7B1mm%7D+i+%5Cin+%7CS%7C%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" class="latex" title="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" />, such that, if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_%7Bi%7D%5C%7D_%7Bi+%5Cin+%7CS%7C%7D%2C+%5C%7Bv_%7Bj%7D%5C%7D_%7Bj+%5Cin+%7CT%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" class="latex" title="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" /> form an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-optimal vector strategy where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Cleq+%5Cfrac%7B1%7D%7B4%28m%2Bn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon \leq \frac{1}{4(m+n)}}" class="latex" title="{\epsilon \leq \frac{1}{4(m+n)}}" />,
<a name="eqmarginale"></a></em>
<p align="center"><em><a name="eqmarginale"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+-+c_%7Bi%7Du_%7Bi%7D%5C%7C+%5Cleq+%5Csqrt%7B10%7D%28m+%2B+n%29%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%5Cepsilon%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" class="latex" title="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" /></a></em></p>
<em><a name="eqmarginale">
</a></em><em><a name="eqmarginale"></a> <a name="lemma"></a> </em>
If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> and our strategy is perfectly optimal, we recover an exact estimation of the marginal biases: <a name="eqmarginal"></a>
<p align="center"><a name="eqmarginal"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+%3D+c_%7Bi%7Du_%7Bi%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" class="latex" title="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" /></a></p>
<a name="eqmarginal">
</a><a name="eqmarginal"></a> The proof for the above lemma provided by Slofstra relies on using techniques to analyze the structure of the SDP program that pertains to quantum marginals. In particular, conducting trace analysis on SDP matrices that correspond to using the game matrix as off-diagonal elements leads us to the construction of the desired marginal biases.
It is also critical to note that a dual statement allows us to recover the column biases <img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j} \geq 0}" class="latex" title="{ d_{j} \geq 0}" />: <a name="eqmarginalc"></a>
<p align="center"><a name="eqmarginalc"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%5Cin%5B%7CS%7C%5D%7DG_%7Bij%7Du_%7Bi%7D+%3D+d_%7Bj%7Dv_%7Bj%7D%2C+%5Cforall+j++%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" class="latex" title="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" /></a></p>
<a name="eqmarginalc">
</a><a name="eqmarginalc"></a> We now move on to defining the notion of a solution algebra.
<br />Definition 13 (Solution Algebra) <em> A solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> consists of self-adjoint (Hermitian) operators <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j}}" class="latex" title="{X_{j}}" /> that satisfy the following predicates:  <a name="eqhermit"></a></em>
<p align="center"><em><a name="eqhermit"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%7D%5E%7B2%7D+%3D+%5Cmathbb%7BI%7D%2C+%5Cforall+1+%5Cleq+j+%5Cleq+n++%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" class="latex" title="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" /></a></em></p>
<em><a name="eqhermit">
</a><a name="eqhermit"></a> <a name="eqbiasespay"></a>
</em>
<p align="center"><em><a name="eqbiasespay"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Csum_%7Bj%5Cin%5B%7CT%7C%5D%7DG_%7Bij%7DX_%7Bj%7D%29%5E%7B2%7D+%3D+%28c_%7Bi%7D%29%5E%7B2%7D%5Ccdot%5Cmathbb%7BI%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" class="latex" title="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" /></a></em></p>
<em>
</em><em><a name="eqbiasespay">
</a></em><em><a name="eqbiasespay"></a> </em>
The definition above merely enforces the property that our unknown marginal operators be Hermitian <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a> and that they respect the optimal marginal biases (or payoffs) <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> we saw in <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a>, so that they correspond to being constructed from an optimal vector strategy. These unknown operators will be mapped to operators that are the marginal strategy corresponding to the optimal quantum strategy. This is at the heart of the main theorem we will now state:
<b>Theorem 14 (Slofstra, 2010)</b> <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" />, a collection of Linear Operators <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{B_{j}\}}" class="latex" title="{\{B_{j}\}}" /> and density matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> are the marginal of an optimal strategy iff the map <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j} \rightarrow B_{j}}" class="latex" title="{X_{j} \rightarrow B_{j}}" /> induces a density-matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> commutes with <img src="https://s0.wp.com/latex.php?latex=%7Bim%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{im(\mathcal{A})}" class="latex" title="{im(\mathcal{A})}" />. <a name="th20"></a> </em>
Put simply, the theorem states that our unknown self-adjoint operators map to an optimal marginal strategy iff the density matrix (traced from the joint Hilbert-Space) commutes with all the mapped operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />). The result we desire on the lower bound for the number of entangled bits, given a mapping from these indeterminate operators to the marginal of an optimal strategy, comes from a corollary to <a href="https://windowsontheory.org/feed/#th20">(14)</a>.
<br />Corollary 15 <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> with minimum dimension <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> among non-zero representations, the strategy for minimum entanglement uses <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log_{2}(N)}" class="latex" title="{\log_{2}(N)}" /> entangled bits. <a name="co21"></a> </em>
The proof for this corollary follows from the eigenspace decomposition of the joint Hilbert Space <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> in terms of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />, which is preserved by the action of <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" />. As a result, each eigenspace decomposes into a finite sum of irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />. The minimum entanglement is realized when there is exactly one invariant subspace (with one irreducible representation). The entanglement used by such a representation is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28%5Ctext%7Bdim%7D%5C%2CH%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(\text{dim}\,H)}" class="latex" title="{ \log_{2}(\text{dim}\,H)}" />.
<h3> Proof of Theorem 20</h3>
The rest of the section is dedicated to sketching a brief (but formal) proof for Theorem <a href="https://windowsontheory.org/feed/#th20">(14)</a>, and then using a simple fact about the representations of a Clifford Algebra to show how Slofstra’s result subsumes Tsirelson’s bound.

For this section, <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> refers to an arbitrary state in <img src="https://s0.wp.com/latex.php?latex=%7B+H+%3D+H_%7BA%7D+%5Cotimes+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H = H_{A} \otimes H_{B}}" class="latex" title="{ H = H_{A} \otimes H_{B}}" /> (the joint Hilbert space). We can write <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Csum_%7Bi%7D+%7C%7Bi%7D%5Crangle+%5Clambda+%7C%7Bi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" class="latex" title="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" /> over some basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{{i}\}}" class="latex" title="{ \{{i}\}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda}" class="latex" title="{ \lambda}" /> is a linear map. Then, the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> is given by <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho+%3D+%5Clambda%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho = \lambda\lambda^{*}}" class="latex" title="{ \rho = \lambda\lambda^{*}}" />.
Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BB%7D_%7BA%7D%2C+%5Cmathcal%7BB%7D_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" class="latex" title="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" /> denote the algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7B1%7D%2C..%2CA_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{1},..,A_{m}}" class="latex" title="{ A_{1},..,A_{m}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7B1%7D%2C..%2CB_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{1},..,B_{n}}" class="latex" title="{ B_{1},..,B_{n}}" />. Here, the generating elements are the observables of an optimal quantum strategy.

To arrive at a proof for the theorem, we will rely on 2 additional lemmas which we will not prove but state.
<br />Lemma 16 <em> Given Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Cin+H_%7BA%7D%2C+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \in H_{A}, H_{B}}" class="latex" title="{B \in H_{A}, H_{B}}" />,
<a name="eqfrob"></a></em>
<p align="center"><em><a name="eqfrob"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5C%7C%5Clambda%5Coverline%7BA%7D+-+B%5Clambda%5C%7C_%7BF%7D++%5C+%5C+%5C+%5C+%5C+%2816%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" /></a></em></p>
<em><a name="eqfrob">
</a><a name="eqfrob"></a> This allows us to conclude that,
<a name="eqcomm"></a>
</em>
<p align="center"><em><a name="eqcomm"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5Cepsilon+%5Cimplies+%5C%7C%5Crho%28B%29+-+B%5Crho%5C%7C_%7BF%7D+%5Cleq+2%5Cepsilon++%5C+%5C+%5C+%5C+%5C+%2817%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" /></a></em></p>
<em>
</em><em><a name="eqcomm">
</a></em><em><a name="eqcomm"></a> <a name="lecomm"></a> </em>
<b>Lemma 17</b> <em> The optimal strategy in question is non-degenerate iff <a name="eqcl1"></a></em>
<p align="center"><em><a name="eqcl1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+closure%28%5Cmathcal%7BB%7D_%7BA%7D%5Clambda%5E%7B%2A%7DH_%7BB%7D%29.+%5C%5C++%5C+%5C+%5C+%5C+%5C+%2818%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" /></a></em></p>
<em><a name="eqcl1">
</a><a name="eqcl1"></a> As a special case:
<a name="eqcl2"></a>
</em>
<p align="center"><em><a name="eqcl2"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+H_%7BB%7D+%5Cleftrightarrow+closure%28%5Crho+H_%7BB%7D%29+%3D+H_%7BB%7D++%5C+%5C+%5C+%5C+%5C+%2819%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" /></a></em></p>
<em>
</em><em><a name="eqcl2">
</a></em><em><a name="eqcl2"></a> <a name="lecl"></a> </em>
<b> Forward direction </b>:
We use the first lemma to prove commutativity of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> with all <img src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="B_{j}" class="latex" title="B_{j}" />, and we use the second lemma to show that the closure of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />.
We first show the forward direction:
Suppose we are given an optimal quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" class="latex" title="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" />) for a game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />. Then, we fix our optimal vector strategy as:
<a name="eqrs"></a>
<p align="center"><b><a name="eqrs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u_%7Bi%7D+%3D+%28A_%7Bi%7D+%5Cotimes+%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2820%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" class="latex" title="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" /></a></b></p>
<b><a name="eqrs">
</a><a name="eqrs"></a> <a name="eqcs"></a>
</b>
<p align="center"><b><a name="eqcs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v_%7Bj%7D+%3D+%28%5Cmathbb%7BI%7D+%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2821%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" class="latex" title="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" /></a></b></p>
<a name="eqcs">
</a><a name="eqcs"></a>

We can now use Equations <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a> and <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> to establish our optimal marginal biases to write a relationship between them and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> , and apply Lemma <a href="https://windowsontheory.org/feed/#lecomm">(16)</a> to show commutativity and Lemma <a href="https://windowsontheory.org/feed/#lecl">(17)</a> to show that <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" /> = cyclic(<img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}, \rho}" class="latex" title="{ B_{j}, \rho}" />).
Using <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> with <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a>, we have:
<a name="eqqs1"></a>
<p align="center"><a name="eqqs1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_%7Bj%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bi%7DG_%7Bij%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2822%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" class="latex" title="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" /></a></p>
<a name="eqqs1">
</a><a name="eqqs1"></a> We can now use <a href="https://windowsontheory.org/feed/#eqcomm">(17)</a> with <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> on <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> to see that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with every <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.
Additionally, as the terms in <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> constitute linear combinations of <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{i}}" class="latex" title="{ A_{i}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />, we can compute the closure of their actions on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H_{A}}" class="latex" title="{ \lambda H_{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%5E%7B%2A%7D+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda^{*} H_{B}}" class="latex" title="{ \lambda^{*} H_{B}}" />, which will be equivalent. Therefore, <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\rho)}" class="latex" title="{ im(\rho)}" /> = <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />, which follows from the special case of <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a>.
For the dual case, we substitute <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a> into <a href="https://windowsontheory.org/feed/#eqmarginal">(12)</a>:
<a name="eqdn"></a>
<p align="center"><a name="eqdn"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c_%7Bi%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj%7DG_%7Bij%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" class="latex" title="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" /> </a></p>
<a name="eqdn"></a>

<a name="eqdn">
</a><a name="eqdn"></a><a name="eqdn"></a> On taking the norm of the above on both sides and using a little algebra, we finally obtain the fact that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> satisfy predicate <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> making them the representations of <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j}}" class="latex" title="{ X_{j}}" />:

<img src="https://s0.wp.com/latex.php?latex=%7B+%28%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%29%5E%7B2%7D+%3D+c_%7Bi%7D%5E%7B2%7D%7B%5Cmathbb%7BI%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" class="latex" title="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" />

This shows that the map from <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j} \rightarrow B_{j}}" class="latex" title="{ X_{j} \rightarrow B_{j}}" /> computes a density matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.

<br /><b> Backward Direction </b>:
The proof for the backward direction is much less involved:
If we knew that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}, \rho}" class="latex" title="{ \{B_{j}\}, \rho}" /> constituted the cyclic representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" /> with commutativity (with <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />), then we can use Lemma <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a> to conclude that the image of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> would form a subspace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H}" class="latex" title="{ \lambda H}" />. We define:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Coverline%7BA%7D_%7Bi%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%7D%7Bc_%7Bi%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" class="latex" title="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" />

allowing us to recover our original marginal biases <img src="https://s0.wp.com/latex.php?latex=%7B+c_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c_{i}}" class="latex" title="{ c_{i}}" /> that satisfy <a href="https://windowsontheory.org/feed/#eqdn">(23)</a> and therefore correspond to the optimal strategy. This shows us that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> would constitute an optimal quantum strategy. 
<div align="right">□</div>
Having proved this theorem, we now obtain Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, which is the main desired result. To see how it subsumes Tsirelson’s result as a special case, we use a simple fact from Representation Theory:
<br /><b>Lemma 18</b> <em> For a Clifford Algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1%7D%2C..%2CX_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1},..,X_{r}}" class="latex" title="{X_{1},..,X_{r}}" />, there exist one or two irreducible representations of dimension <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" /> <a name="lecr"></a> </em>
Plugging Lemma <a href="https://windowsontheory.org/feed/#lecr">18</a> into Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, we simply recover the fact that the number of entangled bits of a solution algebra that is Clifford is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" />. However, note that being Clifford means an extra constraint:
<img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bi%7DX_%7Bj%7D+%3D+-X_%7Bj%7DX_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{i}X_{j} = -X_{j}X_{i}}" class="latex" title="{ X_{i}X_{j} = -X_{j}X_{i}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cforall+i%2C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \forall i, j}" class="latex" title="{ \forall i, j}" />

The constraints on the Solution Algebra <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a>, <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> given by Slofstra do \textit{not} necessarily mean that the solution is Clifford. In fact, when an optimal quantum strategy with minimal entanglement is Clifford, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> are constructed from a unique set of <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bu_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{u_{i}\}}" class="latex" title="{ \{u_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bv_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{v_{j}\}}" class="latex" title="{ \{v_{j}\}}" />.
To end, we write down a lemma that shows there exist XOR games where the optimal strategy is not unique and for minimal entanglement, a solution generated by a Non-Clifford algebra must be used:
<h4>Lemma (Existence of XOR games with Non-Clifford optimal strategies)</h4>
<em> There exist a family of <img src="https://s0.wp.com/latex.php?latex=%7B+m+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ m \times n}" class="latex" title="{ m \times n}" /> XOR games <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BG%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{G\}}" class="latex" title="{ \{G\}}" /> that correspond to generalizations of the CHSH games (<img src="https://s0.wp.com/latex.php?latex=%7BCL_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{CL_{n}}" class="latex" title="{CL_{n}}" />), such that, the optimal strategy of minimal entanglement is Non-Clifford. </em>


<h2>References</h2>
<p>[1] David Avis, Sonoko Moriyama, and Masaki Owari. From bell inequalities to tsirelson’s theorem. IEICE Transactions, 92-A(5):1254–1267, 2009.

</p><p>[2] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. Theoretical Computer Science, 134(2):545 – 557, 1994.

</p><p>[3] T. Ito, H. Kobayashi, and K. Matsumoto. Oracularization and Two-Prover One-Round Interactive Proofs against Nonlocal Strategies. ArXiv e-prints, October 2008.

</p><p>[4] J. Kempe, H. Kobayashi, K. Matsumoto, B. Toner, and T. Vidick. Entangled games are hard to approximate. ArXiv e-prints, April 2007.

</p><p>[5] Julia Kempe, Oded Regev, and Ben Toner. Unique games with entangled provers are easy. SIAM Journal on Computing, 39(7):3207– 3229, 2010.

</p><p>[6] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863–1920, 2001.

</p><p>[7] Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard. arXiv e-prints, page arXiv:1710.03062, October 2017.

</p><p>[8] Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a quantum entangled games PCP for QMA. arXiv e-prints, page arXiv:1801.03821, January 2018.

</p><p>[9] William Slofstra. Lower bounds on the entanglement needed to play xor non-local games. CoRR, abs/1007.2248, 2010.

</p><p>[10] B.S. Tsirelson. Quantum analogues of the bell inequalities. the case of two spatially separated domains. Journal of Soviet Mathematics, 36(4):557–570, 1987.

</p><p>[11] Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate. arXiv e-prints, page arXiv:1302.1242, February 2013.

</p><p>[12] Thomas Vidick. Cs286.2 lecture 15: Tsirelson’s characterization of xor games. Online, December 2014. Lecture Notes.

</p><p>[13] Thomas Vidick. Cs286.2 lecture 17: Np-hardness of computing <img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\omega^*(G)" class="latex" title="\omega^*(G)" />. Online, December 2014. Lecture Notes.



</p><p></p></div>







<p class="date">
by mitalibafna <a href="https://windowsontheory.org/2019/01/03/quantum-games/"><span class="datestr">at January 04, 2019 04:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42140">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic">Explanation of Monadic Second Order Logic [on hold]</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am reading Wolfgang's Book <a href="https://drona.csa.iisc.ac.in/~deepakd/atc-common/wolfgang-aat.pdf" rel="nofollow noreferrer">Applied Automata Theory </a>, wherein, I came across what Monadic Second Order Logic means. </p>

<blockquote>
  <p>MSO stands for “monadic second-order”:
  Second-order because it allows quantification not only over (first-order) position
  variables but also over (second-order) set variables.
  Monadic because quantification is allowed at most over unary (monadic) relations,
  namely sets.</p>
</blockquote>

<p>I have a fundamental question , how do position variables become first order variables, and how are set variables second order? I am not able to go further, since I cannot wrap my head around this. </p></div>







<p class="date">
by GermanShepherd <a href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic"><span class="datestr">at January 03, 2019 01:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16724">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/01/02/jean/">Jean</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png"><img src="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=640&amp;h=500" alt="" width="640" class="alignnone size-full wp-image-16725" height="500" /></a></p>
<p><span style="color: #ff0000;">Jean Bourgain and Joram Lindenstrauss.</span></p>
<p>I was very sad to hear that Jean Bourgain, among the greatest mathematicians of our time, and a dear friend, passed away.  I first met Jean about forty years ago and later we have become friends and collaborators.  In the 80s and 90s Jean used to visit Israel quite often and had close collaboration with the Banach space Israeli community, and with the Ergodic theory community,  and with the Harmonic analysis community, and the PDE community, and later also with the combinatorics, probability,  algebra, number theory,  and theoretical computer science communities.  I always admired his immense mathematical powers and his deep devotion to mathematics.</p>
<p>You can read about Jean Bourgain in Terry Tao’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/">beautiful obituary post</a>.  I was also moved by Svetlana Jitomirskaya’s beautiful <a href="https://www.facebook.com/photo.php?fbid=10106557607678501&amp;set=a.10102850768938051&amp;type=3&amp;theater">facebook post</a>. Some of Jean’s contributions to combinatorics (which formed a small portion of his interests) are mentioned in <a href="https://gilkalai.wordpress.com/tag/jean-bourgain/">several posts </a>over my blog (and my lecture below). I will try to come back to these mathematical topics at a later post and here I post a few pictures of Jean over the years. Here is the moving <a href="https://www.ias.edu/news/2018/bourgain-obituary-notice">IAS obituary notice</a>. See also Ryan O’Donnell’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/#comment-509792">moving comment</a>. And here is a MathOverflow question <a href="https://mathoverflow.net/questions/319893/jean-bourgains-relatively-lesser-known-significant-contributions">Jean Bourgains relatively lesser known significant contributions</a>.</p>
<p> </p>
<p></p>
<p><span style="color: #ff0000;"><strong>My 2016 lecture “Questions for Jean Bourgain” about questions that I (and some colleagues) asked Jean Bourgain over the years, mainly in the areas of combinatorics and combinatorial aspects of convexity.</strong></span></p>
<p><span id="more-16724"></span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png"><img src="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png?w=640" alt="" class="alignnone size-full wp-image-16740" /></a></p>
<p class="_14f3 _14f5 _5pbw _5vra" id="js_6s"><span style="color: #0000ff;"><strong><span class="fwn fcg"><span class="fwb fcg">Svetlana Jitomirskaya:</span></span></strong></span></p>
<p>Вечности заложник<br />
У времени в плену</p>
<p>Eternity’s ambassador<br />
held captive by the time…</p>
<p>He was truly a gift from God to humanity and yet unparalleled in his kindness, humbleness, and generosity.</p>
<p>It is an enormous loss</p>
<p>February 28, 1954 – December 22, 2018</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg"><img src="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg?w=640&amp;h=439" alt="" width="640" class="alignnone size-full wp-image-16742" height="439" /></a></p>
<p>Hermann K<em>ö</em>nig,Tadeusz Figiel, Jean Bourgain, and Lior Tzafriri  (<a href="http://www.math.kent.edu/~mtackett/mathweb/pictures/banach.html">Banach Center Photo Archive</a>)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg"><img src="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg?w=640&amp;h=454" alt="" width="640" class="alignnone size-full wp-image-16747" height="454" /></a></p>
<p>With <span dir="ltr">Russell Impagliazzo </span>(picture taken from the IAS obituary)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JB.jpg"><img src="https://gilkalai.files.wordpress.com/2019/01/JB.jpg?w=640&amp;h=489" alt="" width="640" class="alignnone size-full wp-image-16743" height="489" /></a></p>
<p>An early picture near the blackboard</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png"><img src="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png?w=640" alt="" class="alignnone size-full wp-image-16755" /></a></p>
<p>Alex Gamburd, Jean Bourgain, and Peter Sarnak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg"><img src="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg?w=640" alt="" class="alignnone size-full wp-image-16744" /></a></p>
<p>Crafoord day, Lund 2012 Carlos Kenig, Ben Green, Jean, Terry Tao, me, and Michael Christ.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png"><img src="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png?w=640&amp;h=470" alt="" width="640" class="alignnone size-full wp-image-16741" height="470" /></a></p>
<p>At IHES, 1989</p>
<h3>Pictures of early version of our first joint work (around 1990) with Izzy Katznelson, Jeff Kahn and Nati Linial.</h3>
<p>The initial approach had a 22 page long proof and my copy has a dense (Hebrew) handwritten explanation all the way to page 15.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png"><img src="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png?w=640&amp;h=325" alt="" width="640" class="alignnone size-full wp-image-16738" height="325" /></a></p>
<p> </p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of Page 6</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png"><img src="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png?w=640&amp;h=399" alt="" width="640" class="alignnone size-full wp-image-16739" height="399" /></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of page 19</span></p>
<p>At the end we found a shortcut to the problem itself, but both Jean and I have felt over the years that the deeper methods developed initially by Jean may have further important use.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/01/02/jean/"><span class="datestr">at January 02, 2019 07:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42135">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42135/strong-seeded-randomness-extractors-with-low-entropy-loss">Strong seeded randomness extractors with low entropy loss</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I would like to implement a strong seeded randomness extractor for flat sources as a part of my project. </p>

<p>Most of the literature on seeded extractors is concentrated on minimizing seed length. However, low entropy loss is crucial for my construction. What are the known extractors with minimal entropy loss? How efficient is the extractor in practice? </p>

<p>Is there a lower bound on the entropy loss for strong seeded extractors? </p>

<p>Are there any implementations of extractors that I can use off the shelf?</p></div>







<p class="date">
by satya <a href="https://cstheory.stackexchange.com/questions/42135/strong-seeded-randomness-extractors-with-low-entropy-loss"><span class="datestr">at January 02, 2019 04:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/31/linkage.html">Linkage for the end of the year</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://twitter.com/trannosaurusma/status/959423514485841925?s=21">LaTeX, the game</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101252368314388741"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/BAwHG7Tnc2N">G+</a>, <a href="https://mathstodon.xyz/@ejk/101201955004129570">via</a>). It should be an even higher level to get the commutative diagram to format in Wikipedia’s lobotomized version of LaTeX.</p>
  </li>
  <li>
    <p><a href="http://aperiodical.com/2018/12/byrnes-euclid-recreated-for-the-web/">Byrne’s Euclid recreated for the web</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101259384727886209"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/4Z1pWdmcWui">G+</a>, <a href="https://plus.google.com/+Aperiodical/posts/KdfBH9YMFMV">via</a>, <a href="https://www.metafilter.com/178260/Byrnes-Euclid">also via</a>. Beautiful three-color figures, hard-to-read old-faſhioned orthography, and all. I have the Taſchen reprint in my office, but I prefer the Dover Heath edition for actually uſing the books rather than looking pretty.</p>
  </li>
  <li>
    <p><a href="https://www.theengineer.co.uk/electric-eel-hydrogel-battery/">Electric eel inspires biocompatible hydrogel battery</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101264841241151850"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/EioURA7NEmH">G+</a>, <a href="https://www.nature.com/articles/nature24670">original paper</a>, <a href="https://news.umich.edu/electricity-eel-style-soft-power-cells-could-run-tomorrow-s-implantables/">see also</a>). The part that caught my attention is that they’re using a Miura fold to simultaneously align and press together many pairs of droplets of four types (salty, fresh water, or two kinds of charge-selective hydrogel), creating an origami-activated electrical discharge.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/in-the-universe-of-equations-virtually-all-are-prime-20181210/">In the universe of equations, virtually all are prime</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101270526352782325"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/d7hvGtho5FJ">G+</a>, <a href="https://plus.google.com/+QuantamagazineOrgNews/posts/9e2bRyNfyeF">via</a>, <a href="https://arxiv.org/abs/1810.13360">original paper</a>). Choose a polynomial’s coefficients randomly and independently from your favorite nontrivial distribution. Then it should be irreducible with high probability for polynomials of high enough degree. This was previously conjectured for the uniform distribution on  by Odlyzko and Poonen; now Breuillard and Varjú have proven that it follows from a form of the Riemann hypothesis.</p>
  </li>
  <li>
    <p>A tricky Sudoku (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101277538292220348"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/NDeATkTyEKT">G+</a>):</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/sudoku.svg" alt="A sudoku puzzle" /></p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/In-Talks-With-Elsevier-UCLA/245311">UCLA suggests that its faculty refrain from publishing with or reviewing for Elsevier while negotiations are ongoing</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101281900329465390"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/E4KAhwXct6y">G+</a>). For those willing to take a longer-term stand, there’s always <a href="http://thecostofknowledge.com/">thecostofknowledge.com</a>.</p>
  </li>
  <li>
    <p><a href="https://suomela.github.io/snowflake/">A161330 Snowflake</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101293131395532694"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/N1gsDwSmjrX">G+</a>, <a href="https://plus.google.com/+JukkaSuomela/posts/b7rngpsTaVc">via</a>). An animated holiday greeting from <a href="https://twitter.com/JukkaSuomela">Jukka Suomela</a> based on <a href="https://oeis.org/A161330">integer sequence A161330</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@unknown/101273978649098365">Festive two-to-one star dissection</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101298812633911915"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Bf3kWzhc9Yh">G+</a>). A Christmas greeting from <a href="https://mathstodon.xyz/@unknown/">@unknown@mathstodon.xyz</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=uNJ7riiPHOY">Journeys of women in mathematics</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101311027456154189"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/5CXnPF36FMz">G+</a>, <a href="https://blogs.scientificamerican.com/roots-of-unity/women-mathematicians-in-their-own-words/">via</a>). A 20-minute documentary profiling three women mathematicians from developing countries: Neela Nataraj of IIT Bombay in India, Aminatou Pecha Nijahouo from Cameroon, and Carolina Araujo at IMPA in Brazil, with brief quotes from many more.</p>
  </li>
  <li>
    <p><a href="https://wikiedu.org/blog/2018/12/20/three-things-i-learned-as-a-wiki-scholar/">Three things i learned as a Wiki scholar</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101314727270253883"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/hmWXq3eDTqf">G+</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_Women_in_Red">via</a>). Historian Rachel Boyle on some cultural differences between academia and Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:Mendocino_Beacon_Building.jpg">Mendocino Beacon Building</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101320263516053157"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/ik4GHTux6wN">G+</a>). It feels like I haven’t been taking and posting enough photos. So here’s a cell phone shot that I took to illustrate the Wikipedia article on the <em><a href="https://en.wikipedia.org/wiki/Mendocino_Beacon">Mendocino Beacon</a></em>. The <em>Beacon</em> hasn’t actually lived there for nearly 20 years, but their old sign still hangs on the building.</p>
  </li>
  <li>
    <p><em><a href="http://algorithms.wtf/">Algorithms</a></em> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101327166193790839"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Vsin2Hxwpaj">G+</a>, <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">via</a>). Jeff Erickson’s open-licensed algorithms text is finally more-or-less complete and available in prepublication form.</p>
  </li>
  <li>
    <p><a href="https://wyss.harvard.edu/studying-aliens-of-the-deep/">Using unfolded polyhedra to catch and later release deep-sea creatures without harming them</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101332999043783606"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/j42xnNxs7nW">G+</a>, <a href="https://news.ycombinator.com/item?id=18769435">via</a>).</p>
  </li>
  <li>
    <p><a href="https://plus.google.com/100003628603413742554/posts/WSizeQTqrZH">In which I say goodbye to Google+</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101338372532836995"></a>).</span></p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/31/linkage.html"><span class="datestr">at December 31, 2018 04:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42122">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42122/what-to-do-as-a-theoretical-computer-science-phd-student-in-a-free-time">What to do as a Theoretical computer science PhD student in a free time?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am a mid-stage theoretical computer science student. Although I have a busy schedule, I still have a one or one a half hour in a day which I devote to reading and solving the question given Jeff Erickson's lecture note etc. I am doing this thing from many months and wondering. Is this a right thing for me to do in free time as now I am a Ph.D. student not an undergraduate student. Now why I do this to become more strong in an algorithm, discrete maths etc part. Another thing which seems more valuable to me is to read more and more research paper of my research domain as my goal after my Ph.D. is to publish more quality research papers in the field related to my current field. I am wondering which one is better or suggest anything else which may be more valuable to me keeping my future perspective in mind.</p>

<p><strong>Question:</strong> What to do as a Theoretical computer science PhD student in free time? I am wondering what star experienced researchers do in their time ( assuming they have a free time ).</p>

<p>Some of my free time I also spent on watching video lecture of workshops related to my field.</p>

<p>After looking at all the comments and answers, I have to edit my question. I think, I have not been able to convey what I was trying to ask. My question was how to sharp my technical skills in the free time for a better future. It has nothing to do with my personal life or some one's personal space. I was here for the various possibilities and opinions of users, who have experience in theoretical computer science. Let me clarify my question further, I was to trying to ask in the free time what is more significant to do " continue to think about the research problem at hand or do the problems related to maths or algorithms " and so on. Looking at the comments have made me realise that definitely I need to improve my writing skills also. </p></div>







<p class="date">
by A_Theory <a href="https://cstheory.stackexchange.com/questions/42122/what-to-do-as-a-theoretical-computer-science-phd-student-in-a-free-time"><span class="datestr">at December 31, 2018 12:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42120">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42120/is-a-binary-sequence-computable-iff-the-kolmogorov-complexity-of-its-initial-seg">Is a binary sequence computable iff the Kolmogorov complexity of its initial segments is bounded?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><strong>Disclaimer:</strong> I am mostly unfamiliar with theoretical computer science, making it hard for me to navigate literature in the field. I ask the following out of curiosity.</p>

<p><strong>Background/Motivation:</strong> Coming from information theory, I recently learned about a connection of entropy and Kolmogorov complexity: Loosely speaking, entropy of a random variable is the expected rate at which the Kolmogorov complexity of a long sample sequence increases per sample. <a href="http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf" rel="nofollow noreferrer">[Elements of Information Theory, p. 154]</a> Kolmogorov complexity can therefore capture the notion of entropy, but it is more general than that. Hereby, and in the following, whenever I write complexity, I implicitly refer to the complexity given the length of the output.</p>

<p>For non-zero entropy, the Kolmogorov complexity of initial segments of an infinite sequence of samples from a random variable is therefore unbounded. I was wondering whether this is equivalent to the fact that an infinite sequence of samples is uncomputable. This led me to the hypothesis in the title: Is a binary sequence computable if and only if the Kolmogorov complexity of its initial segments is bounded?</p>

<p>If the hypothesis was true, then computability could be understood as an indicator that the "amount of information" in a sequence is finite. In some sense, the initial segment complexities would allow a more finely graded characterization of infinite sequences than just "computable" and "uncomputable". We could get a notion of "information content" and "information rate" of infinite sequences by analyzing the size of the bound or, in the unbounded case, the rate/type of growth, as in the entropy case above. My question boils down to whether "computable" and "uncomputable" are regions on this scale.</p>

<p>If the hypothesis is true, I'd be interested in whether this perspective is useful for TCS research. If yes, are there references elaborating this idea? If not, why not?</p>

<p><strong>What I found in literature:</strong> It is shown that a sequence is Martin-Löf random iff there is a constant <span class="math-container">$c$</span> so that there are infinitely many initial segments with complexity greater than <span class="math-container">$n - c$</span> where <span class="math-container">$n$</span> is the segment length. <a href="https://arxiv.org/pdf/math/0110086.pdf" rel="nofollow noreferrer">[Randomness, p. 18]</a></p>

<p>This means that random sequences have unbounded initial segment complexity. Since they are not computable, the hypothesis is true at least for this case. If I am not mistaken, a similar argument could even be made for a weaker form of randomness, since Mises-Wald-Church random sequences cannot have initial segment complexity of O(log n). <a href="https://www.math.uni-heidelberg.de/logic/merkle/ps/JCSS-stoch.pdf" rel="nofollow noreferrer">[The complexity of stochastic sequences]</a></p>

<p><strong>What's missing for a proof:</strong></p>

<p><span class="math-container">$\Leftarrow$</span>:
Assume a sequence is computable. We know that a program <code>generate_bit(n)</code> exists that generates any bit of the sequence. Now, we can build a program <code>generate_initial_segment(n) = concat(map(1..n, generate_bit))</code> that, given the segment length <span class="math-container">$n$</span>, generates the initial segment up to position n by invoking <code>generate_bit</code> <span class="math-container">$n$</span> times and concatenating the results. The Kolmogorov complexity of this task is therefore bounded by the length of this program. ☐</p>

<p><span class="math-container">$\Rightarrow$</span>: I struggle to prove/disprove this direction, namely: If initial segment complexity is bounded, is a sequence always computable?</p>

<p>Update: The last two pages of <a href="https://www.sciencedirect.com/science/article/pii/S0019995869905385/pdf?md5=5ff60459e171a92caef1156280e1ce2c&amp;pid=1-s2.0-S0019995869905385-main.pdf" rel="nofollow noreferrer">A variant of the Kolmogorov concept of complexity</a> prove this direction.</p></div>







<p class="date">
by Julius Kunze <a href="https://cstheory.stackexchange.com/questions/42120/is-a-binary-sequence-computable-iff-the-kolmogorov-complexity-of-its-initial-seg"><span class="datestr">at December 31, 2018 09:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:typepad.com,2003:post-6a00d83452383469e2022ad3ca27b2200b">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/erickson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">Steal This Book!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup" class="asset-img-link"><img src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" alt="BookCover" style="display: block; margin-left: auto; margin-right: auto;" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" title="BookCover" /></a><br />Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>







<p class="date">
by Jeff Erickson <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html"><span class="datestr">at December 29, 2018 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3371">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/">SIGecom Test of Time Award</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation.</div>
<div></div>
<p></p>
<div>To be eligible, a paper or series of papers must be on a topic in the intersection of economics and computation, including topics in electronic commerce, and must have been first published, in preliminary or final form, in an archival journal or conference proceedings no less than ten years and no more than twenty-five years before the year the award is conferred. Papers for which all authors are deceased at the time the Award Committee makes its decision are not eligible for the award.</div>
<div></div>
<p></p>
<div>The 2019 SIGecom Test of Time Award will be given for papers published no earlier than 1994 and no later than 2009. Nominations are due by February 20th, 2019, and must be made by email to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a>) with “ACM SIGecom Test of Time Award” in the subject.</div>
<div></div>
<p></p>
<div>Any member of SIGecom may submit a nomination. Self-nomination is not allowed. Nominations must include the following, preferably in a single PDF file:</div>
<div></div>
<p></p>
<div>1. Bibliographic data for the paper or series of papers demonstrating publication, in preliminary or final form, at least ten years and at most twenty-five years before the award year.</div>
<div></div>
<p></p>
<div>2. An endorsement letter by the nominator of no more than two pages describing the content of the paper or series of papers and the lasting contribution, significance, and impact of the work.</div>
<div></div>
<p></p>
<div>3. The names, email addresses, and affiliations of at least two and at most three other endorsers. Endorsers, like the nominator, may not be authors of the paper or papers under consideration.</div>
<div></div>
<p></p>
<div>4. A one-sentence statement that describes the contribution of the paper or series of papers.</div>
<div></div>
<p></p>
<div>The additional endorsers should send letters directly to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a>) by the same deadline. Each letter should specify the relationship of the endorser to nominees and describe, in 500 words or fewer, the lasting contribution, significance, and impact of the paper or papers.</div>
<div></div>
<p></p>
<div>An unsuccessful nomination can be reconsidered for three award cycles, with the option of updating the original nomination to reflect additional impact. Subsequently, a new nomination must be provided. All matters relating to the selection process that are not specified here are left to the discretion of the Award Committee.</div>
<div></div>
<p></p>
<div>The award, conferred annually at the ACM Conference on Economics and Computation, includes a plaque and complimentary conference registration for each winner and an honorarium of $1,000 to be shared among the winners. The award may not be given if the nominations are judged not to meet the standards of the award.</div>
<div></div>
<p></p>
<div>It is expected that at least one of the nominated authors, if selected for the award, will attend the next ACM Conference on Economics and Computation on June 24-28, 2019, in Phoenix, AZ, USA, to accept the award and give a presentation on the work. The award includes complimentary registration but does not cover travel expenses to attend the conference.</div>
<div></div>
<p></p>
<div>The Award Committee welcomes questions from anyone considering or intending to submit a nomination. The Award Committee is happy to provide feedback on informal proposals for potential nominees, should it be needed.</div>
<div></div>
<p></p>
<div>On behalf of the 2019 Award Committee:</div>
<div></div>
<p></p>
<div>Nikhil Devanur</div>
<div>Robert Kleinberg</div>
<div>Tim Roughgarden (Chair)</div>
<div><a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a></div></div>







<p class="date">
by timroughgarden <a href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/"><span class="datestr">at December 28, 2018 08:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15551">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/">ACM Great Results</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A Puck-ish take on promised technological advances</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg?w=189&amp;h=189" alt="" width="189" class="alignright wp-image-15552" height="189" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Das_festliche_Jahr_img398_(Ruprecht).jpg">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. <a href="https://en.wikipedia.org/wiki/Puck_(folklore)">Puck</a>. The Simpsons’ <a href="https://en.wikipedia.org/wiki/Santa's_Little_Helper">dog</a> “Santa’s Little Helper” is named “Knecht Ruprecht” in the show’s German edition.</p>
<p>
Today we do a nice-or-naughty riff on technological gifts suggested by yesterday’s ACM TechNews mailing.<br />
<span id="more-15551"></span></p>
<p>
The ACM mailings highlight the achievements of the whole field: from quantum to everything else. We thought it might be fun to be a bit puckish ourselves and deliver some “coal” to ACM. The stories can be sometimes a bit much. We hope that all involved are in good spirits and accept the “coal” as a holiday-inspired gift—with some echo of the general discussion about naughty-or-nice effects of tech advances.</p>
<p>
</p><p></p><h2> Our Versions of the Stories </h2><p></p>
<p>
</p><p>
Here are some that could be reported in the near future. The originals are <a href="https://technews.acm.org/archives.cfm?fo=2018-12-dec/dec-26-2018.html">here</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>Real-Time Readouts of Thinking in Faculty</i>. <br />
Mighty News<br />
December 19, 2018<br />
Researchers from a university consortium have developed an open source system delivering fast, precise neural decoding and real-time readouts of where CS faculty think they are. The neural decoding software decrypts hippocampal spatiotemporal patterns detected from tetrode recordings without requiring spike sorting, an error-prone computational process. Implementing this software on a graphical processing unit (GPU) chip demonstrated a 20- to 50-fold upgrade in decoding and analysis speed over conventional multicore central processing unit (CPU) chips. This builds on work previous done on rats as reported by ACM previously. The lab director says that the CS faculty work presented many challenges beyond that required for rats. The applications—she says—are immense. Faculty currently cannot always tell where they are, and the new system could help them get to classes on time.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A Robotic Hand Able To Type At Desktop Keyboard At 20 Words Per Minute</i>.<br />
New Yolk Times<br />
December 19, 2018 <br />
Researchers at Can’t-Abridge University have for the first time taught a robotic hand to type on a normal keyboard. The researchers claim that their system can type at rates in excess of 20 words per minute. They say, “this could change the way that computers interact with others.” The system, which now weighs about 500 pounds, could be reduced in size and cost in the future. That the robot sometimes destroys the keys by hitting them too hard continues to be a challenge.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>How AI Spotted Every Solar Panel in the U.S.</i><br />
Pretty Big Solar NewsHour<br />
December 19, 2018<br />
Engineers at the University of St. Anford have located every solar panel in the contiguous U.S. via a network built around a deep learning computer model called Inception. The network completed this task in less than a month, ascertaining that regions with more sun exposure had greater solar panel adoption than areas with less average sunlight. DeepSolar also learned that adoption was higher in locations of increasing average household income. Unbelievable—who would have guessed this?</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>An Amoeba Just Found an Entirely New Way to Write Articles</i>. <br />
ScienceAlarm <br />
December 21, 2018<br />
Researchers at Knockout University in Japan gave an assistant professorship to a “true slime mold” amoeba, and found as the papers-per-year target increased from four to eight, the single-celled organism only needed a linear amount of more time to generate minimum publishable units. This is part of an ongoing project on using lower-level organisms to do research. The project previously used graduate students. The leader of the multiple institution project said that using amoebae could reduce the costs of writing up research by up to 50%. He also said that the amoeba sometimes made various grammar errors, but that the project was attempting to fix this issue.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A Quantum Computer Just Found an Entirely Old Way to Visit Cities</i>. <br />
ScienceAllure <br />
December 21, 2018<br />
Researchers at TKO University in Japan gave the Traveling Salesman Problem (TPS) to a vast array of noisy astronomical scale quantum (NASQ) processors, and found that as the cities increased from four to eight, the system only needed a linear amount of more time to determine a single reasonable route. This was fresh off its success at factoring numbers higher than 291,311 = 523*557 that it didn’t even <a href="https://en.wikipedia.org/wiki/Integer_factorization_records#Records_for_efforts_by_quantum_computers">know</a> it was factoring. TPS is an optimization problem requiring a computer to look at a list of cities and determine the shortest route in which each city is visited exactly once. The team said their results “may lead to the development of quantum algorithms for problems on as many as ten cities.” </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg?w=300&amp;h=148" alt="" width="300" class="aligncenter size-medium wp-image-15555" height="148" /></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Modified from <a href="https://www.flickr.com/photos/jared422/11839818825">source</a><br />
</font>
</td>
</tr>
</tbody></table>
<p><img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Programming Proteins to Pair Precisely</i>.<br />
C++ News<br />
December 19, 2018<br />
The <b>std::pair</b> construct in C++ is a common annoyance because human programmers frequently forget its implicit presence when iterating over maps or inserting into sets. This necessitates the re-typing of millions of lines of source code per annum. Absent the development of a robotic hand able to type at a desktop keyboard at 20 words per minute, software companies can improve productivity by optimizing the nutritional intake of programmers. Nanosoft has partnered with CodeURIKA to provide protein-rich drinks worldwide, after a study of electronic sweatshops found that proteins minimize both syntactic and semantic bugs better over the long term than sugars and PEDs. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Room for Improvement? New Hotelier Tests an Algorithmic System</i>.<br />
Wallbanger Street Journal<br />
December 19, 2018<br />
The Lite House hotelier is experimenting with an algorithmic pricing system to set different room rates for guests who arrive in self-driving cars. Once customers book for the first time at a standard rate, they fill out a questionnaire of 200 questions to specify how often they will need the car, how frequently they visit the hotel bar, and other details. The hotelier then activates a key to drive the car into an appropriate space. The optimized use of vertical space and savings from not hiring car valets will enable conference participants who are not staying at the hotel to park there at a rate low enough to include in the conference registration fee. A spokesman said, “Most of the big hotel operating companies are not focused on their conference guests,” while Lite House’s algorithmic rate-setting “is next-generation.”</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Companies Use VR to Train Employees for Difficult Customers</i>.<br />
ESPN Technology Review<br />
December 20, 2018.<br />
Major corporations like Wallstore, ChippedPot, and Horizon are using virtual reality (VR) to prepare employees for potentially difficult situations on the job. For example, Horizon has more than 1,600 stores in the U.S. whose front-line employees participate in a digital scenario in which a customer asks to use the bathroom. In a “Harry Potter-Style Photos for Muggles” twist, researchers have developed software that can animate the central character in a photograph while leaving the rest of the image untouched. Its skeleton can then be animated to create the sense of movement, solving the problem of pose estimation for a limited set of circumstances in which bathroom requests occur. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>New Attack Intercepts Keystrokes Via Digital Watches</i>.<br />
TubeNet<br />
December 19, 2018<br />
A team of researchers from Burning Man University has developed a new side-channel attack that exploits the heat generated by people wearing Orange Digital Watches while working on their PCs. Heat amplifies the watches’ ability to detect keystrokes from both hands. Videos known to generate large amounts of heat include comic videos and videos on carpet cleaning. The attack becomes more adept at guessing correct keys as the user gets hotter, as it amasses more key presses from graphic libraries. </p>
<p></p><p><br />
There are some other items, including one particularly chilling, that we chose not to parody.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Will the next year’s advances in AI and other areas of tech be anything like we imagine? Will they bring humanity more gifts than lumps of coal?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/"><span class="datestr">at December 28, 2018 01:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html">Motorcycle graphs and the eventual fate of sparse Life</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The <a href="http://jeffe.cs.illinois.edu/open/cycles.html">motorcycle graph</a> is a geometric structure devised by Jeff Erickson as a simplified model for the behavior of <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>, motivated by the light cycle game in the movie Tron. Its initial data consists of a set of points in the plane (the motorcycles), each with an initial velocity. The motorcycles leave a trail behind them as they move, and a motorcycle crashes (stopping the growth of its trail) when it hits the trail of another motorcycle.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/motorcycle-graph.svg" alt="A motorcycle graph" /></p>

<p>The motorcycles can be constrained in various ways, and one of these constrained variants is much older. It’s the <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>, a motorcycle graph in which the motorcycles start out in pairs traveling in opposite directions, all at the same speed, with a random initial placement for the pairs. Edgar Gilbert wrote about it in 1967, as a model for the growth of <a href="https://en.wikipedia.org/wiki/Acicular_(crystal_habit)">acicular (needle-shaped) crystals</a> and similar systems.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation.svg"><img src="https://11011110.github.io/blog/assets/2018/Gilbert-tessellation.svg" alt="A Gilbert tessellation, by Claudio Rocchini" /></a></p>

<p>One obvious difference between the Gilbert tessellation and more general types of motorcycle graph is that all the Gilbert tessellation cells are convex polygons. More general motorcycle graphs leave degree-one vertices at the starting position of each motorcycle, but this is hidden by the way the Gilbert graph starts motorcycles in pairs. If we constrain the motorcycles even more, to travel in axis-parallel directions, the polygons become rectangles.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation_axis.svg"><img src="https://11011110.github.io/blog/assets/2018/Gilbert-rectangles.svg" alt="Axis-aligned Gilbert tessellation subdivides the plane into rectangles, by Claudio Rocchini" /></a></p>

<p>In my paper “<a href="https://arxiv.org/abs/0911.2890">Growth and decay in life-like cellular automata</a>” I noticed that the <a href="https://en.wikipedia.org/wiki/Life-like_cellular_automaton">Life-like cellular automaton</a> rule B017/S1 has a very simple <a href="https://en.wikipedia.org/wiki/Replicator_(cellular_automaton)">replicator</a> consisting of two orthogonally-adjacent live cells, and that initial fields consisting of very sparse randomly placed live cells become dominated by rows and columns of these replicators. Here’s an example for an initial random fill density of 1%, the lowest I can go in <a href="http://golly.sourceforge.net/">Golly</a>.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/b017s1.png" alt="Replicator chaos in B017/S1" /></p>

<p>Although I didn’t notice it at the time, this looks very similar to the rectangular Gilbert tessellation! I think that’s not a coincidence. With a fill density of , the most common constellation (connected group of live cells) of the initial configuration will be a single live cell, with density (number of constellations per unit area) approximately  . But the isolated cells all die off immediately. The second most common constellations,  with density , have two live cells. If the two cells are diagonally adjacent, they form a small oscillator, and if they are orthogonally adjacent, they form a replicator. The replicators will then grow either horizontally or vertically in both directions until they run into something, usually (but not always) another replicator. When two replicators collide, they tend to form a stable blob that blocks both of them. The one that was there first will usually (but not always) have copies of itself on both sides of the blob, so its line of copies stays more or less unchanged in place. The replicator that arrives second will usually (but not always) be blocked by the first replicator, and stay on one side of the collision point. And when replicators are bounded on both sides by stable blobs, they usually (but not always) turn into stable oscillators, continuing to fill the line they have already marked out. If all of the usual things always happened, we would get a Gilbert tessellation; instead, we get something that looks a lot like a Gilbert tessellation but with typically a constant number of oscillators in its rectangles and with occasional other differences from the expected behavior.</p>

<p>Could this happen for sparse initial conditions of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a>? Maybe!</p>

<p>In a sequence of papers from 1998 to his 2010 “<a href="https://doi.org/10.1007/978-1-84996-217-9_20">Emergent Complexity in Conway’s Game of Life</a>”, Nick Gotts has explored the behavior of random Life initial conditions, in the limit as the fill density  goes to zero. We don’t know what happens to these patterns in the long term, but we can say something rigorous about their behavior in the short and medium terms. Here, by “short term” I mean what happens after a constant number of steps, and by “medium term” I mean a number of steps that’s polynomial in  with a small-enough exponent.</p>

<p>Initially, near most points of the plane, the nearest objects will be isolated cells, spaced  units from each other (the inverse square root of their density). However, these immediately die off. So in the short term, the nearest objects will usually be “blonks” (blinkers and blocks, generated from initial constellations of three live cells), with density  and spacing . More widely scattered are gliders, either generated directly from constellations of five initial live cells, or from <a href="http://www.conwaylife.com/wiki/R-pentomino">R pentominos</a> which create a bounded number of gliders before stabilizing. Both possibilities give the gliders density . Even more widely scattered, at density , are the simplest patterns that produce infinite growth rather than stability or simple motion: the <a href="http://www.conwaylife.com/wiki/Block-laying_switch_engine">block-laying switch engines</a>, generated from initial constellations of ten live cells. These are puffer trains rather than replicators: they have a single live head that lays down a trail of blocks as it moves.</p>

<p>If the field stayed like this throughout the medium term, things would be boring. The gliders and switch engines would typically crash into blonks in  steps, in most cases stopping their motion. And so one might expect that at numbers of steps with higher exponents, most points would have only stable or low-period debris as their nearest live pattern. Occasionally there would be a trail of a crashed and dead switch engine but these would be very far apart, at a typical distance , compared to their typical length of . So from a high-level point of view, these trails would just look like randomly placed line segments rather than forming anything like a motorcycle graph or Gilbert tessellation.</p>

<p>However, what Gotts discovered is that something much more complicated and confusing happens. The gliders (with short-term density ) start crashing into blonks, but when they do they sometimes produce one or more new gliders. Those gliders, in turn, might crash into something else and produce even more gliders, perhaps including some that return to the previous crash site. Gotts defines a “standard collision sequence” to be a sequence of events of this type, involving a single initial glider and a widely scattered collection of blonks. There are finitely many different standard collision sequences that involve a given number  of initial blonks. Any one of these sequences can happen to a given glider with a probability that tends to a constant as the number of time steps goes to , the expected time for any glider to complete its collision sequence in the absence of interactions with the crash debris of other gliders.</p>

<p>But the crash debris starts to add up, preventing this analysis from actually staying valid all the way to that limiting point. In particular, some standard collision sequences can produce infinite growth patterns like the block-laying switch engine. If we ignored interactions with other gliders and just considered standard collision sequences, it would appear that the density of switch engines constructed in this way would approach  as the number of time steps went to , and therefore that the density of blocks in switch engine trails would approach , much more dense than the density of initial blonks. That can’t happen, and our analysis breaks down. What’s less clear and not rigorously proven is exactly how it breaks down.</p>

<p>One possibility for the breakdown is the following. Switch engines or other puffer engines start being produced in increasing density by standard collision sequences, and they start growing trails of blocks behind them. As their trails grow and the typical distance between the puffers shrinks, at some point these two distances cross over, and the trails become longer than the typical distance. This crossover distance is well below the  distance one would expect a puffer to travel before hitting an initial blonk. Once this happens, most puffers will crash into the trail of another puffer, and their trails will divide up space into something resembling a motorcycle graph. (It’s not a Gilbert tessellation, because each puffer starts out moving in a single direction.) The cells of this graph prevent anything else from moving across it, leading to eventual stabilization.</p>

<p>Another possibility is that some other pattern (perhaps initial or perhaps produced by a standard collision sequence) does something quickly enough to disrupt the creation of a motorcycle graph before it happens, or breaks through it after it is constructed. We don’t know what these patterns might look like, but we also don’t know that they don’t exist. Life patterns can do complicated things. Because so much is still unknown, what Gotts actually proves is more cautious: either infinite-growth patterns created from collision sequences eventually cause the total population to be significantly denser than its original density, or the infinite-growth patterns created through standard collision sequences will themselves become more dense than they were in the initial field.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101316148318254282"></a>, <a href="https://plus.google.com/100003628603413742554/posts/ehARHPdEkde">G+</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html"><span class="datestr">at December 27, 2018 05:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42104">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42104/does-a-given-regular-language-contain-an-infinite-prefix-free-subset">Does a given regular language contain an infinite prefix-free subset?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>A set of words over a finite alphabet is <em>prefix-free</em> if there are no two distinct words where one is a prefix of the other.</p>

<p>The question is: </p>

<p><strong>What is the complexity of checking whether a regular language given as an NFA contains an infinite prefix-free subset?</strong></p>

<p><strong>Answer (due to Mikhail Rudoy, here below)</strong>: It can be done in polynomial time, and I think in even in NL. </p>

<p>Paraphrasing Mikhail's answer, let <span class="math-container">$(\Sigma,q_0,F,\delta)$</span> be the input NFA in the normal form (no epsilon transitions, trim), and let <span class="math-container">$L[p,r]$</span> (resp. <span class="math-container">$L[p,R]$</span>) be the language obtained by having state <span class="math-container">$r$</span> as initial state and <span class="math-container">$\{s\}$</span> as final state (resp. state <span class="math-container">$r$</span> as inital and the set <span class="math-container">$S$</span> as final). For a word <span class="math-container">$u$</span> let <span class="math-container">$u^\omega$</span> be the infinite word obtained by iterating <span class="math-container">$u$</span>.</p>

<p>The following are equivalent:</p>

<ol>
<li>The language <span class="math-container">$L[q_0,F]$</span> contains an infinite prefix-free subset.</li>
<li><span class="math-container">$\exists q \in Q$</span>, <span class="math-container">$\exists u \in L[q,q]$</span> <span class="math-container">$\exists v \in L[q,F]$</span> so that <span class="math-container">$v$</span> is not a prefix of <span class="math-container">$u^\omega$</span>.</li>
<li><span class="math-container">$\exists q \in Q$</span> <span class="math-container">$L[q,q] \neq \emptyset$</span> <span class="math-container">$\forall u \in L[q,q]$</span> <span class="math-container">$\exists v \in L[q,F]$</span> so that <span class="math-container">$v$</span> is not a prefix of <span class="math-container">$u^\omega$</span>.</li>
</ol>

<p>Proof:</p>

<p>3<span class="math-container">$\Rightarrow$</span>2 trivial.</p>

<p>For 2<span class="math-container">$\Rightarrow$</span>1, it suffices to see that for any <span class="math-container">$w \in L[q_0,q]$</span> we have that <span class="math-container">$w (u^{|v|})^* v$</span> is an infinite prefix-free subset of <span class="math-container">$L[q_0,F]$</span>.</p>

<p>Finally, 1<span class="math-container">$\Rightarrow$</span>3 is the "correctness" proof in Mikhail's answer.</p></div>







<p class="date">
by Googlo <a href="https://cstheory.stackexchange.com/questions/42104/does-a-given-regular-language-contain-an-infinite-prefix-free-subset"><span class="datestr">at December 27, 2018 03:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16645">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">Amazing: Karim Adiprasito proved the g-conjecture for spheres!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg"><img src="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg?w=640&amp;h=853" alt="" width="640" class="alignnone size-full wp-image-12390" height="853" /></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Karim in his youth with a fan</span></p>
<p>Congratulations, Karim!</p>
<p><strong>Update</strong>: <a href="https://arxiv.org/abs/1812.10454">Here is the link to the paper</a></p>
<p><em>From the arXive, Dec 26, 2018. (Link will be added tomorrow.)</em></p>
<p>COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY</p>
<p>by Karim Adiprasito</p>
<p><strong>Abstract:</strong> Consider a simplicial complex that allows for an embedding into <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^d" class="latex" title="\mathbb R^d" />. How many faces of dimension <img src="https://s0.wp.com/latex.php?latex=d%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d/2" class="latex" title="d/2" /> or higher can it have? How dense can they be?</p>
<p>This basic question goes back to Descartes. Using it and other fundamental combinatorial<br />
problems, we will introduce a version of the Kähler package beyond positivity,<br />
allowing us to prove the Lefschetz theorem for toric varieties even when the ample<br />
cone is empty. A particular focus lies on replacing the Hodge-Riemann relations by a<br />
non-degeneracy relation at torus-invariant subspaces, allowing us to state and prove a<br />
generalization of the theorems of Hall and Laman in the setting of toric varieties. Of<br />
the many applications, we highlight two main applications, one because it is the most<br />
well-known, the other because it provided the most guiding light.</p>
<p>(1) We fully characterize the possible face numbers of simplicial spheres, resolving the<br />
so called <em>g</em>-conjecture of McMullen in full generality and generalizing Stanley’s<br />
earlier proof for simplicial polytopes.</p>
<p>(2) We prove that for a simplicial complex <em>K</em> that embeds into <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5E%7B2d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^{2d}" class="latex" title="\mathbb R^{2d}" />, the number of <em>d</em>-dimensional simplices exceeds the number of <em>(d − 1)</em>-dimensional simplices by a factor of at most <em>d + 2</em>. This generalizes a result of Descartes, and resolves the Grünbaum-Kalai-Sarkaria conjecture.</p>
<p>_______</p>
<p>(GK:) A few further comments. Probably the <em>g</em>-conjecture for spheres is the single problem I knock my head against the most. It is great to see it settled and it is even greater to see it settled by my friend and colleague Karim Adiprasito.</p>
<p>To the three ingredients of the standard conjectures (See also the <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">previous post</a>), Poincare duality <strong>(PD</strong>), Hard Lefschetz (<strong>HL</strong>) and Hodge-Riemann (<strong>HR</strong>), Karim adds the <strong>Hall-Laman relations</strong>. Very roughly, the Hall-Laman relations  substitute<strong> (HR)</strong> and apply genericity (rather than definiteness) toward <strong>(HL)</strong>.</p>
<p>(We still need a good acronym for Hall-Laman, maybe <strong>(AHL)</strong>.)</p>
<p>One very nice feature of Karim’s proof is that <strong>vertex decomposable</strong> spheres play a special role in the path toward the proof. Those were introduced by Provan and Billera in the context of the Hirsch conjecture.</p>
<p>We have devoted <a href="https://gilkalai.wordpress.com/tag/g-conjecture/">plenty of posts</a> to the <em>g</em>-conjecture for spheres, and mentioned it in <a href="https://gilkalai.wordpress.com/page/2/?s=g-conjecture">even more posts</a>.  For an introduction to the conjecture see <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">Eran Nevo introductory post</a>, and the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/" rel="bookmark">How the g-Conjecture Came About</a>. There is also plenty left to be done <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">beyond the g-conjecture</a>.</p>
<p><span style="color: #0000ff;">Merry X-mas and Happy new year 2019 to all our readers.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/"><span class="datestr">at December 25, 2018 02:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16429">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">ICM 2018 Rio (4): Huh; Balog &amp; Morris; Wormald</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p> </p>
<p>This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures related to combinatorics. I also met quite a few combinatorialists. As I mentioned in my <a href="https://gilkalai.wordpress.com/2012/11/17/a-few-mathematical-snapshots-from-india-icm2010/">ICM 2010 post</a>, one thing that I enjoyed was to unexpectedly meet some old friends and this also happened in Rio (maybe a little less compared to Hyderabad as I learned to expect the unexpected). I also had an irrational expectation to unexpectedly meet the <em>same</em> people that I met unexpectedly in India. It was a pleasure meeting  Tadeusz Januszkiewicz again   but I was irrationally disappointed not to bump again into <a href="http://www-ma4.upc.edu/~oserra">Oriol Serra</a> and Anna Llado whom I had met  by surprise in Hyderabad.</p>
<p>This post will be about the Monday afternoon Session in combinatorics. Let me mention that the <a href="https://www.youtube.com/channel/UCnMLdlOoLICBNcEzjMLOc7w">ICM 2018 You Tube channel</a> now contains high quality videos for plenary and invited talks (as well as discussion panels, public lectures, and various other activities). This is a valuable resource! Here is the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmVE7DUBxr4CFu4TNhiJM8Hj">combinatorics session playlist</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWQ9pIGF1ObG4Ag472sg2hm">CS session</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmXn3FrOaMN7ZVNqsY_fWDHw">probability and statistics</a> session, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmW5F1S9OGR6esa9XpTOTq6e">plenary lectures</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWTsHKdFtIP7H2zsvwI0Uq4">public lectures</a>. Also, here is the most recent version of my ICM paper <a href="https://gilkalai.files.wordpress.com/2018/12/icm-draft-Dec-2018.pdf">THREE PUZZLES ON MATHEMATICS, COMPUTATION, AND GAMES</a>. Last minute corrections and comments are most welcome.</p>
<h1>Monday’s afternoon combinatorics</h1>
<p>The Monday afternoon combinatorics session featured three lectures that knocked my socks off. The talks were great and I was in a perfect position to enjoy them as I knew something about the problems and some related results  and yet each lecture surprised me.  The three talks were <span title="Combinatorial applications of the Hodge–Riemann relations – June Huh – ICM2018" class="watch-title" dir="ltr" id="eow-title"><a href="https://youtu.be/ceGEZdjnxRw">Combinatorial applications of the Hodge–Riemann relations</a> </span>by June Huh, <span class="watch-title" dir="ltr" title="The method of hypergraph containers – József Balogh &amp; Robert Morris – ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> by József Balogh &amp; Robert Morris,  </span><span title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018" class="watch-title" dir="ltr" id="eow-title"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a> by Nicholas Wormald. Bella Bollobas chaired the session and gave a very nice and thoughtful introduction to each of the four speakers.</span></p>
<p><span title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018" class="watch-title" dir="ltr" id="eow-title"> </span></p>
<h2>June Huh, and the Lefschetz package in combinatorics</h2>
<p></p>
<blockquote><p><strong><span style="color: #ff0000;">June Huh: The standard conjectures are both ubiquitous and fundamental</span></strong></p></blockquote>
<p class="watch-title-container"><a href="https://youtu.be/ceGEZdjnxRw"><span title="Combinatorial applications of the Hodge–Riemann relations – June Huh – ICM2018" class="watch-title" dir="ltr" id="eow-title">Combinatorial applications of the Hodge–Riemann relations</span></a></p>
<p>June Huh talked about a mysterious package of conjectures (PD), (HL) and (HR), referred to as the standard conjectures,  for certain algebras associated with geometric and combinatorial objects. PD stands for the Poincare Duality, and it asserts that certain vector spaces <img src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i" class="latex" title="A_i" /> and <img src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{d-i}" class="latex" title="A_{d-i}" /> are dual. HD stands for Hard Lefschetz and it asserts that certain linear maps <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi_k" class="latex" title="\phi_k" /> from <img src="https://s0.wp.com/latex.php?latex=A_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k" class="latex" title="A_k" /> to <img src="https://s0.wp.com/latex.php?latex=A_k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k+1" class="latex" title="A_k+1" />  have the property that their composition from <img src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i" class="latex" title="A_i" /> all the way to <img src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{d-i}" class="latex" title="A_{d-i}" /> is an injection. (HR) stands for Hodge Riemann relations. (PD) and (HD) imply that a certain bilinear form  is nondegenerate and (HR) is a stronger statement that this form is definite!</p>
<p>June started with some startling applications of the Hard-Lefschetz theorem in combinatorics pioneered by Stanley. He then mentioned a startling new application with Wang: Consider <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points spanning a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional space.  Let <img src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_i" class="latex" title="w_i" /> be the number of flats of dimension <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> spanned by the point.  Motzkin  conjectured in 1936 and proved over the reals that  <img src="https://s0.wp.com/latex.php?latex=w_1+%5Cle+w_d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_1 \le w_d" class="latex" title="w_1 \le w_d" />. The planar case follows from the classic Erdos deBruijn theorem. Hu and Wang used {HL} to prove <img src="https://s0.wp.com/latex.php?latex=w_i+%5Cle+w_d-i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_i \le w_d-i" class="latex" title="w_i \le w_d-i" />, <img src="https://s0.wp.com/latex.php?latex=i+%5Cle+%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \le [d/2]" class="latex" title="i \le [d/2]" /> which was conjectured by Dowling and Wilson.</p>
<p>Next came applications of (HR), starting with Huh’s proof of the log concavity of coefficients of chromatic polynomials for graphs (Read conjecture ) and the far-reaching extension by Adiprasito-Huh-Kats to general matroids (Rota’s conjecture). We mentioned the Adiprasito-Huh-Katz solution of the Rota-Heron conjecture in <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">the previous post</a> and in <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">this one</a>.</p>
<p>Here is the link to the ICM paper by June Huh: <a href="https://arxiv.org/abs/1711.11176">Combinatorial applications of the Hodge-Riemann relations</a>.</p>
<p> </p>
<h2>József Balogh and Rob Morris and the container method</h2>
<p></p>
<p><span class="watch-title" dir="ltr" title="The method of hypergraph containers – József Balogh &amp; Robert Morris – ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> </span></p>
<p>The container theorem for hypergraphs is one of the most important tools in extremal combinatorics with many applications also to random graphs and hypergraphs, additive combinatorics, discrete geometry, and more.</p>
<p>Rob Morris explained the container theorem for triangle-free graphs. It asserts that there is a collection <img src="https://s0.wp.com/latex.php?latex=%5Ccal+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cal C" class="latex" title="\cal C" /> of graphs on <img src="https://s0.wp.com/latex.php?latex=n+vertices&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n vertices" class="latex" title="n vertices" /> with the following three properties:</p>
<p>(1) Every graph in the collection contains <img src="https://s0.wp.com/latex.php?latex=o%28n%5E3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="o(n^3)" class="latex" title="o(n^3)" /> triangles,</p>
<p>(2) The number of graphs in the collection is <img src="https://s0.wp.com/latex.php?latex=n%5E%7BC+%5Ccdot+3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^{C \cdot 3/2}" class="latex" title="n^{C \cdot 3/2}" />,</p>
<p>(3) Each triangle free graph is contained in a graph in the collection.</p>
<p>Rob explained the origins of this theorem, how it follows from a container theorem for 3-uniform hypergraphs,   and how the later extends to the very general and important container theorem for <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-uniform hypergraphs that was achieved in 2012 independently by Saxton and Thomason (Here is the link to <a href="https://arxiv.org/abs/1204.6595">their paper</a>), and by Balogh, Morris, and Samotij (Here is a link to <a href="https://arxiv.org/abs/1204.6530">their paper</a>).</p>
<p>Jozsef Balogh described two consequences of the container theorem to additive combinatorics and to discrete geometry. Let me describe the result in discrete geometry by Balogh and Solymosi. The (4,3) problem ask for the size $\alpha (n)$ of the largest subset of points in general position (no three on a line) that can always be found in a planar configuration of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points with the property that no four points lie on a line. The container method is used to show (surprisingly!) that <img src="https://s0.wp.com/latex.php?latex=%5Calpha%28n%29%3Dn%5E%7B5%2F6%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha(n)=n^{5/6+o(1)}" class="latex" title="\alpha(n)=n^{5/6+o(1)}" /> .</p>
<p>For a recent beautiful application to <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(p,q)" class="latex" title="(p,q)" />-Helly type theorems see <a href="https://arxiv.org/abs/1809.06451">A new lower bound on Hadwiger-Debrunner numbers in the plane</a> by Chaya Keller and Shakhar Smorodinsky.</p>
<p>Here is a link to the ICM survey paper: <a href="https://arxiv.org/abs/1801.04584">The method of hypergraph containers</a>, by József Balogh, Robert Morris, and Wojciech Samotij</p>
<p>(In a previous post  <a href="https://gilkalai.wordpress.com/2015/01/20/midrasha-mathematicae-18-in-and-around-combinatorics/" rel="bookmark">Midrasha Mathematicae #18: In And Around Combinatorics, </a>we gave links to a series of lectures Wojiech Samotij: Toward the hypergraph “container” theorem (4 lectures) <a href="https://www.youtube.com/watch?v=SpAyBN4rccU">Video 1, </a><a href="http://youtu.be/N6rP1yUcE0M">video 2</a> <a href="https://www.youtube.com/watch?v=cSFfKhcyN14">video 3</a> <a href="https://www.youtube.com/watch?v=efVlsmiws-I">video 4</a>.)</p>
<h2>Nick Wormald and counting regular graphs.</h2>
<p></p>
<p><span title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018" class="watch-title" dir="ltr" id="eow-title"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a></span></p>
<p>How many <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-regular graphs are there? This is a very central problem in combinatorics and Nick Wormald was quite interested in its solution ever since his Ph. D.  The talk describes the early history of the problem, the early works by Wormald and McKay from the 90s,  the recent breakthrough by Antia Liebenau and Nick Wormald,  the techniques involved in the old and new proofs and some related results.</p>
<p>A good place to start is with Read’s 1958 formula for the number <img src="https://s0.wp.com/latex.php?latex=g_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_3(n)" class="latex" title="g_3(n)" /> of 3-regular graphs with n labelled vertices</p>
<p><img src="https://s0.wp.com/latex.php?latex=g_3%28n%29+%5Csim+%283n%29%21+e%5E%7B-2%7D%2F%283n%2F2%29%21288%5E%7Bn%2F2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." class="latex" title="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." /></p>
<p>Following an important model of Bollobas for creating regular graphs, general formulas were developed for low degrees, By McKay, McKay and Wormald, and others that depend on the probability of a random graph in Bollobas’ model to be simple. (See pictures below). Some results were proven also for the high degree regime and McKay and Wormald gave in 1990 and 1997 unified conjectural formulas for the number of <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular graphs for a wide range of parameters. Moreover these conjectures extend to a large range of vectors of degree sequences.</p>
<p>In 2017 Anita Liebenau and Nick Wormald proved all these conjectures!!! (<a href="https://arxiv.org/abs/1702.08373">Here is a link to the paper</a>.)</p>
<p>The formula for the behavior of the number of <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular graphs with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vertices is remarkably elegant</p>
<p><img src="https://s0.wp.com/latex.php?latex=e%5E%7B1%2F4%7D%5Csqrt%7B2%7Dd%5Ed%28n-1-d%29%5E%7Bn-1-d%7D%28n-1%29%5E%7B-%28n-1%29%7D%7B%7Bn-1%7D+%5Cchoose+%7Bd%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" class="latex" title="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" />.</p>
<p>The full result is very general, and the method extends further in various directions.</p>
<p>Here is the link to paper: <a href="https://arxiv.org/abs/1702.08373">Asymptotic enumeration of graphs by degree sequence, and the degree sequence of a random graph</a>, by Anita Liebenau and Nick Wormald.</p>
<h3>A bit psychedelic pictures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg"><img src="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg?w=300&amp;h=225" alt="" width="300" class="alignnone size-medium wp-image-16681" height="225" /></a>    <a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg"><img src="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg?w=300&amp;h=225" alt="" width="300" class="alignnone size-medium wp-image-16682" height="225" /></a></p>
<p>With Nick Wormald and Yoshi Kohayakawa just before my lecture.</p>
<h2>Some important pictures from the Session</h2>
<h3>Bela Bollobas</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/bela.png"><img src="https://gilkalai.files.wordpress.com/2018/12/bela.png?w=640" alt="" class="alignnone size-full wp-image-16650" /></a></p>
<p><span style="color: #ff0000;">Bela Bollobas served as the session chair</span></p>
<h3>Nick Wormald on enumeration of regular graphs</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W2.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W2.png?w=640&amp;h=406" alt="" width="640" class="alignnone size-full wp-image-16660" height="406" /></a></p>
<p><span style="color: #ff0000;">Read’s formula and Bollobas model.</span></p>
<p><img src="https://gilkalai.files.wordpress.com/2018/12/W3.png?w=640&amp;h=368" alt="" width="640" class="alignnone size-full wp-image-16661" height="368" /></p>
<p><span style="color: #ff0000;">Formulas by McKay and McKay-Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W4.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W4.png?w=640&amp;h=352" alt="" width="640" class="alignnone size-full wp-image-16662" height="352" /></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W5.png?w=640&amp;h=370" alt="" width="640" class="alignnone size-full wp-image-16663" height="370" /></a></p>
<p><span style="color: #ff0000;">General conjectures (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W6.png?w=640&amp;h=365" alt="" width="640" class="alignnone size-full wp-image-16664" height="365" /></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W7.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W7.png?w=640&amp;h=353" alt="" width="640" class="alignnone size-full wp-image-16665" height="353" /></a></p>
<p><span style="color: #ff0000;">The Theorem by Liebenau and Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W8.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W8.png?w=640&amp;h=356" alt="" width="640" class="alignnone size-full wp-image-16666" height="356" /></a></p>
<p> </p>
<h3>Balogh and Morris on containers</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers1.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers1.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16614" height="360" /></a></p>
<p><span style="color: #ff0000;">The Container theorem for triangle-free graphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers2.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers2.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16615" height="360" /></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem for 3-uniform hypergraphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container3.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container3.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16616" height="360" /></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem in full generality.</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container4.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container4.png?w=640&amp;h=371" alt="" width="640" class="alignnone size-full wp-image-16653" height="371" /></a></p>
<p><span style="color: #ff0000;">An application for the number of subsets of integers without k-term arithmetic progressions.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers5.png?w=640&amp;h=348" alt="" width="640" class="alignnone size-full wp-image-16654" height="348" /></a></p>
<p><span style="color: #ff0000;">What was known and expected on the (4,3) problem (above) and the new breakthrough (below)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers6.png?w=640&amp;h=368" alt="" width="640" class="alignnone size-full wp-image-16655" height="368" /></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers7.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers7.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16656" height="360" /></a></p>
<p><span style="color: #ff0000;">Applications of the container method</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container8.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container8.png?w=640&amp;h=332" alt="" width="640" class="alignnone size-full wp-image-16690" height="332" /></a></p>
<h3>June Huh on the standard conjectures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16607" height="360" /></a></p>
<p><span style="color: #ff0000;">Five seemingly unrelated mathematical objects</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16609" height="360" /></a></p>
<p><span style="color: #ff0000;">Poincare duality (PD), Hard Lefschetz (HL), and Hodge Riemann (HR).</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16610" height="360" /></a></p>
<p><span style="color: #ff0000;">A 1964 letter from Serre to Grothendieck on young Bombieri</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16611" height="360" /></a></p>
<p><span style="color: #ff0000;">The algebraic setting for the standard conjectures. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png?w=640&amp;h=360" alt="" width="640" class="alignnone size-full wp-image-16612" height="360" /></a></p>
<p><span style="color: #ff0000;">Five cases were the standard conjectures are known and the original open case.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/"><span class="datestr">at December 24, 2018 08:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7021">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/">Introduction to Quantum Walks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<hr class="wp-block-separator" />



<p>author: Beatrice Nash</p>



<p>Abstract</p>



<p>In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks based algorithms for certain applications.</p>



<h1>Continuous time quantum walks</h1>



<p>We begin our discussion of quantum walks by introducing the quantum analog of the continuous random walk. First, we review the behavior of the classical continuous random walk in order to develop the definition of the continuous quantum walk.</p>



<p>Take a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> with vertices <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and edges <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" />. The adjacency matrix <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is defined as follows:</p>



<p><img src="https://s0.wp.com/latex.php?latex=A_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" title="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" /></p>



<p>And the Laplacian <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> is given by:</p>



<p><img src="https://s0.wp.com/latex.php?latex=L_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+-%5Ctext%7Bdegree%7D%28i%29+%5Cquad+%26%5Ctext%7Bif+++%7D++i+%3D+j+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" title="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" /></p>



<p>The Laplacian determines the behavior of the classical continuous random walk, which is described by a length <img src="https://s0.wp.com/latex.php?latex=%7CV%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|V|" class="latex" title="|V|" /> vector of probabilities, <strong>p</strong>(t). The <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th entry of <strong>p</strong>(t) represents the probability of being at vertex <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. <strong>p</strong>(t) is given by the following differential equation:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Ctext%7Bp%7D_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Ctext%7Bp%7D_%7Bj%7D%28%5Ctext%7Bt%7D%29%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" class="latex" title="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" /></p>



<p>which gives the solution <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bp%7D%28t%29+%3D+e%5E%7BLt%7D%5Ctextbf%7Bp%7D%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" class="latex" title="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" />.</p>



<p>Recalling the Schrödinger equation <img src="https://s0.wp.com/latex.php?latex=i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cleft%7C%5Cpsi%5Cright%3E%3D+H+%5Cleft%7C%5Cpsi%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" class="latex" title="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" />, one can see that by inserting a factor of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> on the left hand side of the equation for <strong>p</strong>(t) above, the Laplacian can be treated as a Hamiltonian. One can see that the Laplacian preserves the normalization of the state of the system. Then, the solution to the differential equation:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cpsi_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Cpsi_%7Bj%7D%28%5Ctext%7Bt%7D%29%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" class="latex" title="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" />,</p>



<p>which is <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%28t%29%5Cright%3E+%3D+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" class="latex" title="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" />, determines the behavior of the quantum analog of the continuous random walk defined previously. A general quantum walk does not necessarily have to be defined by the Laplacian; it can be defined by any operator which “respects the structure of the graph,” that is, only allows transitions to between neighboring vertices in the graph or remain stationary [7]. To get a sense of how the behavior of the quantum walk differs from the classical one, we first discuss the example of the continuous time quantum walk on the line, before moving on to the discrete case.</p>



<h2>Continuous time quantum walk on the line</h2>



<p>An important example of the continuous time quantum walk is that defined on the infinite line. The eigenstates of the Laplacian operator for the graph representing the infinite line are the momentum states with eigenvalues <img src="https://s0.wp.com/latex.php?latex=2%28%5Ctext%7Bcos%7D%28p%29+-+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2(\text{cos}(p) - 1)" class="latex" title="2(\text{cos}(p) - 1)" />, for <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> in range <img src="https://s0.wp.com/latex.php?latex=%5B-%5Cpi%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-\pi,\pi]" class="latex" title="[-\pi,\pi]" />. This can be seen by representing the momentum states in terms of the position states and applying the Laplacian operator:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+L%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%2B1%5Cright%3E%2B+e%5E%7Bipx%7D+%5Cleft%7Cx-1%5Cright%3E+-+2e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+%28e%5E%7Bip%7D+%2B+e%5E%7B-ip%7D+-+2%29+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+2%28%5Ctext%7Bcos%7D%28p%29+-+1%29+%5Cleft%7Cp%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" /></p>



<p>Hence the probability distribution at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, <img src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%7C+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" class="latex" title="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" />, with initial position <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \left|0\right&gt;" /> is given by:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C0%5Cright%3E+%7C+%5E%7B2%7D+%26%3D++%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+%5Cleft%3C+x%7Cp%5Cright%3E+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+e%5E%7Bipx%7D+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%7C+J_%7Bx%7D%282t%29+%7C%5E%7B2%7D.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" class="latex" title="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" /></p>



<figure class="wp-block-image is-resized"><img width="451" alt="" class="wp-image-7071" src="https://windowsontheory.files.wordpress.com/2018/12/quantum-1.png?w=451" />Figure 1.a) Probability distribution for continuous time quantum walk on the infinite line at time <img src="https://s0.wp.com/latex.php?latex=t+%3D+80&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 80" class="latex" title="t = 80" />.</figure>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/classical-1.png?w=451&amp;h=300" alt="" width="451" class="wp-image-7073" height="300" /><br />Figure 1.b) Approximate probability<br /> distribution of the continuous time random walk on the infinite line at<br /> time <img src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=30" class="latex" title="t=30" />.<br /></figure>



<p>While the probability distribution for the classical continuous time<br /> random walk on the same graph approaches, for large <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B4%5Cpi+t%7D%7D+e%5E%7B%5Cfrac%7B-x%5E%7B2%7D%7D%7B4t%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" class="latex" title="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" />, or a Gaussian of width <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\sqrt{t}" class="latex" title="2\sqrt{t}" />. One can see that the quantum walk has its largest peaks at the extrema, with oscillations in between that decrease in amplitude as one approaches the starting position at <img src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=0" class="latex" title="x=0" />. This is due to the destructive interference between states of different phases that does not occur in the classical case. The probability distribution of the classical walk, on the other hand, has no oscillations and instead a single peak centered at <img src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=0" class="latex" title="x=0" />, which widens and flattens as <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> increases.</p>



<h2>Walk on the glued trees graph</h2>



<p>A <em>glued tree</em> is a graph obtained by taking two binary trees of equal height and connecting each of the leaves of one of the trees to exactly two leaves of the other tree so that each node that was a leaf in one of the original trees now has degree exactly <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />. An example of such a graph is shown in Figure 2.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/glued-1.png?w=1024" alt="" class="wp-image-7077" />Figure 2: An example of a glued tree graph, from [2].</figure>



<p>The time for the quantum walk on this graph to reach the right root from the left one is exponentially faster than in the classical case. Consider the classical random walk on this graph. While in the left tree, the probability of transitioning to a node in the level one to the right is twice that of transitioning to a node in the level one to the left. However, while in the right tree, the opposite is true. Therefore, one can see that in the middle of the graph, the walk will get lost, as, locally, there is no way to determine which node is part of which tree. It will instead get stuck in the cycles of identical nodes and will have exponentially small probability of reaching the right node.</p>



<p>To construct a continuous time quantum walk on this graph, we consider the graph in terms of <em>columns</em>. One can visualize the columns of Figure 2 as consisting of all the nodes equidistant from the entrance and exit nodes. If each tree is height <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, then we label the columns <img src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Ctext%7B...%7D%2C2n%2C2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0,1,\text{...},2n,2n+1" class="latex" title="0,1,\text{...},2n,2n+1" />, where column <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> contains the nodes with shortest path of length <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> from the leftmost root node. We describe the state of each column as a superposition of the states of each node in that column. The number of nodes in column <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, <img src="https://s0.wp.com/latex.php?latex=N_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N_{i}" class="latex" title="N_{i}" />, will be <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{i}" class="latex" title="2^{i}" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B0%2Cn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [0,n]" class="latex" title="i \in [0,n]" /> and <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%2B1-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2n+1-i}" class="latex" title="2^{2n+1-i}" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B1%2C2n%2B1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n+1,2n+1]" class="latex" title="i \in [n+1,2n+1]" />. Then, we can define the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\text{col} \; i\right&gt;" class="latex" title="\left|\text{col} \; i\right&gt;" /> as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cunderset%7Bj+%5Cin+%5Ctext%7Bcol%7D+%5C%3B+i%7D%7B%5Csum%7D+%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" /></p>



<p>The factor of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{N_{i}}} " class="latex" title="\frac{1}{\sqrt{N_{i}}} " />latex  ensures that the state is normalized. Since the adjacency matrix <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of the glued tree is Hermitian, then we can treat <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> as the Hamiltonian of the system determining the behavior of the quantum walk. By acting on this state with the adjacency matrix operator <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />, we get the result (for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B1%2Cn-1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [1,n-1]" class="latex" title="i \in [1,n-1]" />):</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E++%26%3D+2%5Cfrac%7B%5Csqrt%7BN_%7Bi-1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Cfrac%7B%5Csqrt%7BN_%7Bi%2B1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E+%5C%5C+%26%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" /><br /></p>



<p>Then for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B2%2C2n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n+2,2n]" class="latex" title="i \in [n+2,2n]" />, we get the same result, because of symmetry.<br /></p>



<p>For <img src="https://s0.wp.com/latex.php?latex=i+%3D+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = n" class="latex" title="i = n" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E+%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3Bn-1%5Cright%3E+%2B+2+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" /></p>



<p>The case of <img src="https://s0.wp.com/latex.php?latex=i+%3D+n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = n+1" class="latex" title="i = n+1" /> is symmetric. One can see that the walk on this graph is equivalent to the quantum walk on the finite line with nodes corresponding to the columns. All of the edges, excluding that between columns <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" />, have weight <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sqrt{2}" class="latex" title="\sqrt{2}" />. The edge between column <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" /> has weight <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />.</p>



<p>The probability distribution of the quantum walk on this line can be roughly approximated using the infinite line. In the case of the infinite line, the probability distribution can be seen as a wave propagating with speed linear in the time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. Thus, in time linear in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, the probability that the state is measured at distance <img src="https://s0.wp.com/latex.php?latex=2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2n+1" class="latex" title="2n+1" /> from the starting state is <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D+%5C%3B+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\text{poly} \; n}" class="latex" title="\frac{1}{\text{poly} \; n}" />. In [3] it is shown that the fact that the line is finite and has a single differently weighted edge from the others (that between <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" />) does not change the fact that in polynomial time, the quantum walk will travel from the left root node to the right one, although in this case there is no limiting distribution as the peaks oscillate. This was the first result that gives an exponential speed up over the classical case using quantum walks.</p>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/glued-tree-1.png?w=451&amp;h=291" alt="" width="451" class="wp-image-7082" height="291" />Figure 3: Although the quantum walk on the glued trees graph does not have a limiting distribution, this is an example of the resulting probability distribution at time <img src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=30" class="latex" title="t=30" /> for a <img src="https://s0.wp.com/latex.php?latex=n%3D4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n=4" class="latex" title="n=4" /> column glued tree graph.  The x-axis corresponds to the columns.  One can see that the probability of being at the columns at either extremes is significantly larger than that of being in the middle of the graph. In contrast, the classical random walk takes exponential time to ever reach the exit root node.</figure>



<h1>Discrete time quantum walks</h1>



<p>In this section, we will first give an introduction to the discrete quantum walk, including the discrete quantum walk on the line and the Markov chain quantum walk, as defined in [7]. Next, we discuss how Grover search can be viewed as a quantum walk algorithm, which leads us into Ambainis’s quantum-walks based algorithm from [1] for the element distinctness problem, which gives a speed up over classical and other quantum non-walks based algorithms.</p>



<p>The discrete time quantum walk is defined by two operators: the <em>coin flip</em> operator, and the <em>shift</em> operator. The coin flip operator <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> determines the direction of the walk, while the shift operator <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> makes the transition to the new state conditioned on the result of the coin flip. The Hilbert space governing the walk is <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D%7BC%7D+%5Cotimes+%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" class="latex" title="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}{C}" class="latex" title="\mathcal{H}{C}" /> corresponds to the space associated with the result of the coin flip operator, and <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}{S}" class="latex" title="\mathcal{H}{S}" /> corresponds to the locations in the graph on which the walk is defined.</p>



<p>For example, consider the discrete time walk on the infinite line. Since there are two possible directions (left or right), then the Hilbert space associated with the coin flip operator is two dimensional. In the unbiased case, the coin flip is the Hadamard operator,</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bbmatrix%7D+1+%26+1+%5C%5C+1+%26+-1++%5Cend%7Bbmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" class="latex" title="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" /></p>



<p>and shift operator that produces the transition from state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j\right&gt;" class="latex" title="\left|j\right&gt;" /> to <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j+1\right&gt;" class="latex" title="\left|j+1\right&gt;" /> or <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j-1\right&gt;" class="latex" title="\left|j-1\right&gt;" />,<br /> conditioned on the result of the coin flip, is <img src="https://s0.wp.com/latex.php?latex=S+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%3C+0%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj%2B1%5Cright%3E+%5Cleft%3C+j%5Cright%7C+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%3C+1%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj+-+1%5Cright%3E+%5Cleft%3C+j%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" class="latex" title="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" />.</p>



<p>Each step of the walk is determined by an application of the unitary<br /> operator <img src="https://s0.wp.com/latex.php?latex=U+%3D+S+%5Ccdot+%28H+%5Cotimes+I%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = S \cdot (H \otimes I)" class="latex" title="U = S \cdot (H \otimes I)" />. If the walk starts at position<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x\right&gt;" class="latex" title="\left|x\right&gt;" />, then measuring the state after one application of <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> gives <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x+1\right&gt;" class="latex" title="\left|x+1\right&gt;" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2}" class="latex" title="\frac{1}{2}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x-1\right&gt;" class="latex" title="\left|x-1\right&gt;" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2}" class="latex" title="\frac{1}{2}" />. This is exactly the same as the case of the classical random walk on the infinite line; the difference between the two walks becomes apparent after a few steps.</p>



<p>For example, the result of the walk starting at state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" /> after 4 steps gives:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+3%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E-%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" title="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" /></p>



<p>One can see that the distribution is becoming increasingly skewed<br /> towards the right, while in the classical case the distribution will be<br /> symmetric around the starting position. This is due to the destructive<br /> interference discussed earlier. The distribution after <img src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 20" class="latex" title="t = 20" /> time<br /> steps is shown in Figure 4.</p>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/discrete.png?w=451&amp;h=291" alt="" width="451" class="wp-image-7090" height="291" />Figure 4: Distribution at time <img src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 20" class="latex" title="t = 20" />, with <img src="https://s0.wp.com/latex.php?latex=20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="20" class="latex" title="20" /> on the x-axis corresponding to position <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />.</figure>



<p>Now, consider the walk starting at state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-3%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" title="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" /></p>



<p><br /> This distribution given by this walk is the mirror image of the first.<br /> To generate a symmetric distribution, consider the start state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%5Cleft%7C0%5Cright%3E+-i%5Cleft%7C1%5Cright%3E%29%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" />. The resulting distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps will be <img src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%5Cfrac%7B1%7D%7B2%7D+p_%7B0%7D%28x%2Ct%29+%2B+%5Cfrac%7B1%7D%7B2%7D+p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" class="latex" title="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" />, where <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}(x,t)" class="latex" title="p_{0}(x,t)" /> is the probability distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps resulting from the start state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi(0) = \left|0\right&gt;\left|0\right&gt;" class="latex" title="\psi(0) = \left|0\right&gt;\left|0\right&gt;" /> and <img src="https://s0.wp.com/latex.php?latex=p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{1}(x,t)" class="latex" title="p_{1}(x,t)" /> is the probability distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps resulting from the start state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" class="latex" title="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" />. The result will be symmetric, with peaks near the extrema, as we saw in the continuous case.</p>



<h2>Markov chain quantum walk</h2>



<p>A reversible, ergodic Markov chain with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> states can be represented by a <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \times n" class="latex" title="n \times n" /> transition matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> with <img src="https://s0.wp.com/latex.php?latex=P_%7Bj%2Ci%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{j,i}" class="latex" title="P_{j,i}" /> equal to the probability of transitioning from state <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> to state <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=P+%3D+P%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P = P^{*}" class="latex" title="P = P^{*}" />. Then, <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}P" class="latex" title="p_{0}P" />, where <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}" class="latex" title="p_{0}" /> is an initial probability distribution over the states, gives the distribution after one step.<br />Since <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bj%7D+P_%7Bi%2Cj%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{j} P_{i,j} = 1" class="latex" title="\sum_{j} P_{i,j} = 1" /> for all <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is stochastic and thus preserves normalization.</p>



<p>There are multiple ways to define a discrete quantum walk, depending on the properties of the transition matrix and the graph on which it is defined (overview provided in [4]). Here we look at the quantum walk on a Markov chain as given in [2]. For the quantum walk on this graph, we define state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|i\right&gt;\left|j\right&gt;" class="latex" title="\left|i\right&gt;\left|j\right&gt;" /> as the state that represents currently being at position <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and facing in the direction of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />. Then, we define the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi_%7Bj%7D%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi_{j}\right&gt;" class="latex" title="\left|\psi_{j}\right&gt;" /> as a superposition of the states associated with position <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E+%3D+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Csqrt%7BP_%7Bj%2Ci%7D%7D+%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" /></p>



<p>The unitary operator,</p>



<p><img src="https://s0.wp.com/latex.php?latex=D+%3D+2+%5Cunderset%7Bi%7D%7B%5Csum%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E%5Cleft%3C+%5Cpsi_%7Bi%7D%5Cright%7C+-+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" class="latex" title="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" />,</p>



<p>acts as a coin flip for the walk on this graph. Since <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is reversible, we can let the shift operator be the unitary <img src="https://s0.wp.com/latex.php?latex=SWAP&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SWAP" class="latex" title="SWAP" /> operator:</p>



<p><img src="https://s0.wp.com/latex.php?latex=SWAP+%3D+%5Cunderset%7Bi%2Cj%7D%7B%5Csum%7D+%5Cleft%7Ci%2Cj%5Cright%3E%5Cleft%3C+j%2Ci%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" class="latex" title="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" />.</p>



<p>A quantum walk can also be defined for a non-reversible Markov chain using a pair of reflection operators (the coin flip operator is an example of a reflection operator). This corresponds to the construction given in [7].</p>



<h2>Search as a quantum walk algorithm</h2>



<p>Given a black box function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> and a set of inputs <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> with <img src="https://s0.wp.com/latex.php?latex=%7CS%7C+%3D+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|S| = N" class="latex" title="|S| = N" />, say we want to find whether an input <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in S" class="latex" title="x \in S" /> exists for which <img src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x)" class="latex" title="f(x)" /> equals some output value. We refer to the set of inputs <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> for which this is true as marked. Classically, this requires <img src="https://s0.wp.com/latex.php?latex=O%28N%2F%7CM%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N/|M|)" class="latex" title="O(N/|M|)" /> queries, for nonempty <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" />. Using the Grover search algorithm, this problem requires <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" /> quantum queries. In this section, we give a quantum walks based algorithm that also solves this problem in <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" /> time. If we define a doubly stochastic matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> with uniform transitions, then we can construct a new transition matrix <img src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P'" class="latex" title="P'" /> from <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=P_%7Bi%2Cj%7D%27+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B1%7D%7BN-1%7D+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cin+M+%5C%5C+0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cin+M.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" class="latex" title="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" /></p>



<p>Then, when the state of the first register is unmarked, the operator <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> defined in the previous section acts as a diffusion over its neighbors. When the state in the first register is marked, then <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> will act as the operator <img src="https://s0.wp.com/latex.php?latex=-I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-I" class="latex" title="-I" />, and the walk stops, as a marked state has been reached. This requires two queries to the black box function: one to check whether the input is marked, and then another to uncompute. By rearranging the order of the columns in <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> so that the columns corresponding to the non-marked elements come before the columns corresponding to the marked elements, we get:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%27+%3D+%5Cbegin%7Bpmatrix%7D+P_%7B0%7D+%26+0+%5C%5C+P_%7B1%7D+%26+I+%5Cend%7Bpmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" class="latex" title="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" /></p>



<p>where <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" /> gives the transitions between non-marked elements and <img src="https://s0.wp.com/latex.php?latex=P_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{1}" class="latex" title="P_{1}" /> gives the transitions from non-marked to marked elements.</p>



<p>We now look at the hitting time of the classical random walk. Assume<br /> that there is zero probability of starting at a marked vertex. Then, we<br /> can write the starting distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, where the last <img src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|M|" class="latex" title="|M|" /> elements of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, corresponding to the marked elements, are zero, as<br /> <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5Cunderset%7B%5Clambda%7D%7B%5Csum%7D+%5Calpha_%7B%5Clambda%7D+%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" class="latex" title="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" />, where <img src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda" class="latex" title="\lambda" /> are the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" />, and <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\lambda\right&gt;" class="latex" title="\left|\lambda\right&gt;" /> are the corresponding eigenvectors, with the last <img src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|M|" class="latex" title="|M|" /> entries zero. Let <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda^{}" class="latex" title="\lambda^{}" /> be the principal (largest) eigenvalue. Then, the probability that, after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps, a marked element has not yet been reached will be <img src="https://s0.wp.com/latex.php?latex=%5Csum+%28P_%7B0%7D%5E%7Bt%7Dp%29_%7Bi%7D+%5Cleq+%5Clambda%5E%7B%2At%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" class="latex" title="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" />. Then, the<br /> probability that a marked element has been reached in that time will be<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+1+-+%5Clambda%5E%7Bt%7D+%5Cgeq+1+-+t+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" class="latex" title="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" />. Setting<br /> <img src="https://s0.wp.com/latex.php?latex=t+%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = \frac{1}{1-\lambda^{*}}" class="latex" title="t = \frac{1}{1-\lambda^{*}}" /> gives probability <img src="https://s0.wp.com/latex.php?latex=%5COmega%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega(1)" class="latex" title="\Omega(1)" /> that a marked element will be reached in that time.</p>



<p>The eigenvalues of <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" /> will be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{N-|M|-1}{N-1}" class="latex" title="\frac{N-|M|-1}{N-1}" /> and<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B-1%7D%7BN-%7CM%7C-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{-1}{N-|M|-1}" class="latex" title="\frac{-1}{N-|M|-1}" />. Then, the classical hitting time will be:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t+%26%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B1-%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D%7D+%5C%5C+%26%3D+O%5Cleft%28%5Cfrac%7BN%7D%7B%7CM%7C%7D%5Cright%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" class="latex" title="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" /></p>



<p>It can be showed that for a walk defined by a Markov chain, the<br /> classical hitting time will be <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{1}{\delta \epsilon})" class="latex" title="O(\frac{1}{\delta \epsilon})" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3D+1+-+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta = 1 - \lambda^{*}" class="latex" title="\delta = 1 - \lambda^{*}" />, the <em>spectral gap</em>, and <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cleq+%5Cfrac%7B%7CM%7C%7D%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon \leq \frac{|M|}{N}" class="latex" title="\epsilon \leq \frac{|M|}{N}" /> [2].</p>



<p>Magniez <em>et al</em> proved in [6] that for a reversible, ergodic<br /> Markov chain, the quantum hitting time for a walk on this chain is<br /> within a factor of the square root of the classical hitting time. Since<br /> the walk on this input acts as a walk on a reversible Markov chain until<br /> a marked element is reached, then this is also true for a walk defined<br /> by our transition matrix <img src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P'" class="latex" title="P'" />. This arises from the fact that the<br /> spectral gap of the matrix describing the quantum walk corresponding to<br /> stochastic matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is quadratically larger than the spectral gap of<br /> the matrix describing the classical random walk corresponding to <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />, the proof of which is given in [2]. Thus, the quantum hitting time<br /> is <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" />, which exactly matches the quantum query complexity of Grover search.</p>



<h2>Element distinctness problem</h2>



<p>Now, we describe Ambainis’s algorithm given in [1] for solving<br /> the <em>element distinctness problem</em> in <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{2}{3}})" class="latex" title="O(N^{\frac{2}{3}})" /> time, which<br /> produces a speed up over the classical algorithm, which requires <img src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N)" class="latex" title="O(N)" /> queries, and also over other known quantum algorithms that do not make use of quantum walks, which require <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B3%7D%7B4%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{3}{4}})" class="latex" title="O(N^{\frac{3}{4}})" /> queries. The element distinctness problem is defined as follows: given a function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> on a size <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N" class="latex" title="N" /> set of inputs</p>



<p><img src="https://s0.wp.com/latex.php?latex=S%3D%5C%7Bx_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S=\{x_{1}" class="latex" title="S=\{x_{1}" />,…,<img src="https://s0.wp.com/latex.php?latex=x_%7BN%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{N}\}" class="latex" title="x_{N}\}" />,</p>



<p>determine whether there exists a pair <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2C%5C%3B+x_%7B2%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1},\; x_{2} \in S" class="latex" title="x_{1},\; x_{2} \in S" /> for which <img src="https://s0.wp.com/latex.php?latex=f%28x_%7B1%7D%29+%3D+f%28x_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x_{1}) = f(x_{2})" class="latex" title="f(x_{1}) = f(x_{2})" />.  As in the search problem defined in the previous section, this is a decision problem; we are not concerned with finding the values of these pairs, only whether at least one exists.</p>



<p>The algorithm is similar to the search algorithm described in the previous section, except we define the walk on a <em>Hamming graph</em>. A Hamming graph <img src="https://s0.wp.com/latex.php?latex=H%28N%2Cm%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(N,m)" class="latex" title="H(N,m)" /> is defined as follows: each vertex <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> corresponds to an <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />-tuple, (<img src="https://s0.wp.com/latex.php?latex=i_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{1}" class="latex" title="i_{1}" />,…,<img src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{m}" class="latex" title="i_{m}" />), where <img src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{k} \in S" class="latex" title="i_{k} \in S" /> for all <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> and repetition is allowed (that is, <img src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{k}" class="latex" title="i_{k}" /> may equal <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j}" class="latex" title="i_{j}" /> for <img src="https://s0.wp.com/latex.php?latex=k+%5Cneq+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \neq j" class="latex" title="k \neq j" />), and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> is a parameter we will choose. Edges will exist between vertices that differ in exactly one coordinate (order matters in this graph). We describe the state of each vertex as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci+%5Cright%3E%3D%7C+i_%7B1%7D%2Ci_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|i \right&gt;=| i_{1},i_{2}" class="latex" title="\left|i \right&gt;=| i_{1},i_{2}" />,…,<img src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D%2Cf%28i_%7B1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{m},f(i_{1})" class="latex" title="i_{m},f(i_{1})" />,…,<img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bm%7D%29%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{m})&gt;" class="latex" title="f(i_{m})&gt;" /></p>



<p>Then, moving along each edge that replaces the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th coordinate with <img src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{k}" class="latex" title="x_{k}" /> such that <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j} \neq x_{k}" class="latex" title="i_{j} \neq x_{k}" />  requires two queries to the black box function to erase <img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{j})" class="latex" title="f(i_{j})" /> and compute <img src="https://s0.wp.com/latex.php?latex=f%28x_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x_{k})" class="latex" title="f(x_{k})" />. In the case, the marked vertices will be those that contain some <img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bk%7D%29+%3D+f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{k}) = f(i_{j})" class="latex" title="f(i_{k}) = f(i_{j})" /> for <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j} \neq i_{k}" class="latex" title="i_{j} \neq i_{k}" />. Since the function values are stored in the description of the state, then no additional queries to the black box are required to check if in a marked state.</p>



<p>The transition matrix is given by <img src="https://s0.wp.com/latex.php?latex=P+%3D+%5Cfrac%7B1%7D%7Bm%28n-1%29%7D+%5Cunderset%7Bi+%5Cin+%5B1%2Cm%5D%7D%7B%5Csum%7D+%28J+-+I%29%5E%7B%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" class="latex" title="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" />. <img src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J" class="latex" title="J" /> is the <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \times n" class="latex" title="n \times n" /> all one matrix, and the superscript <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> denotes the operator acting on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th coordinate. The factor of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{m(n-1)}" class="latex" title="\frac{1}{m(n-1)}" /> normalizes the degree, since the graph is regular. We can compute the spectral gap of this graph to be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bn%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{n}{m(n-1)}" class="latex" title="\frac{n}{m(n-1)}" /> (for details of this computation, see [2]). Then, noting that that the fraction of marked vertices, <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, is<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Cfrac%7Bm%28m-1%29%28n-2%29%5E%7Bm-2%7D%7D%7Bn%5E%7Bm%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" class="latex" title="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" />, classically, the query complexity is <img src="https://s0.wp.com/latex.php?latex=m+%2B+O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29+%3D+m+%2B+O%28%5Cfrac%7Bn%5E%7B2%7D%7D%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" class="latex" title="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" />, where <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> is the queries required to construct the initial state. Setting the parameters equal to minimize with respect to <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> gives classical query complexity <img src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N)" class="latex" title="O(N)" />, as expected.</p>



<p>Then in the quantum case, <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> queries are still required to set up the state. <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7B%5Csqrt%7Bm%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{n}{\sqrt{m}})" class="latex" title="O(\frac{n}{\sqrt{m}})" /> queries are required to perform the walk until a marked state is reached, by [6]. Setting parameters equal gives <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{2}{3}})" class="latex" title="O(N^{\frac{2}{3}})" /> queries, as desired.</p>



<p>[1] Ambainis, A. Quantum walk algorithm for element distinctness, SIAM Journal on Computing 37(1):210-239 (2007). arXiv:quant-ph/0311001</p>



<p>[2] Childs, A. Lecture Notes on Quantum Algorithms (2017). <a href="https://www.cs.umd.edu/ amchilds/qa/qa.pdf" rel="nofollow">https://www.cs.umd.edu/ amchilds/qa/qa.pdf</a></p>



<p>[3] Childs, A., Farhi, E. Gutmann, S. An example of the difference between<br /> quantum and classical random walks. Journal of Quantum Information<br /> Processing, 1:35, 2002. Also quant-ph/0103020.</p>



<p>[4] Godsil, C., Hanmeng, Z. Discrete-Time Quantum Walks and Graph Structures<br /> (2018). arXiv:1701.04474</p>



<p>[5] Kempe, J. Quantum random walks: an introductory overview, Contemporary<br /> Physics, Vol. 44 (4) (2003) 307:327. arXiv:quant-ph/0303081</p>



<p>[6] Magniez, F., Nayak, A., Richter, P.C. et al. On the hitting times of<br /> quantum versus random walks, Algorithmica (2012) 63:91.<br /> <a href="https://doi.org/10.1007/s00453-011-9521-6" rel="nofollow">https://doi.org/10.1007/s00453-011-9521-6</a></p>



<p>[7] Szegedy, M. Quantum Speed-up of Markov Chain Based Algorithms, 45th<br /> Annual IEEE Symposium on Foundations of Computer Science (2004).<br /> <a href="https://ieeexplore.ieee.org/abstract/document/1366222" rel="nofollow">https://ieeexplore.ieee.org/abstract/document/1366222</a></p>



<p>[8] Portugal, R. <em>Quantum Walks and Search Algorithms</em>. Springer, New York, NY (2013).</p>



<p></p></div>







<p class="date">
by beanash <a href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/"><span class="datestr">at December 23, 2018 05:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6939">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/">Towards Quantum PCP: A Proof of the NLETS Theorem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By Abhijit Mudigonda, Richard Wang, and Lisa Yang</p>



<p><i>This is part of a series of blog posts for <a href="https://www.boazbarak.org/fall18seminar/">CS 229r: Physics and Computation</a>. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the NLETS theorem, and then settle on providing a proof of the NLETS theorem. This new proof, due to Nirkhe, Vazirani, and Yuen, makes it clear that the Hamiltonian family used to resolve the NLETS theorem cannot help us in resolving the NLTS conjecture.</i></p>



<h2>Introduction</h2>
<p>We are all too familiar with <b>NP</b> problems. Consider now an upgrade to <b>NP</b> problems, where an omniscient prover (we’ll call this prover Merlin) can send a polynomial-sized proof to a <b>BPP</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#BPP">bounded-error probabilistic polynomial-time</a>) verifier (and we’ll call this verifier Arthur). Now, we have more decision problems in another complexity class, <b>MA</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#MA">Merlin-Arthur</a>). Consider again, the analogue in the quantum realm where now the prover sends over qubits instead and the verifier is in <b>BQP</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:B#bqp">bounded-error quantum polynomial-time</a>). And now we have <b>QMA</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qma">quantum Merlin-Arthur</a>).</p>

<p>We can show that there is a hierarchy to these classes, where <b>NP</b> <img src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\subseteq " class="latex" title="\subseteq " /> <b>MA</b> <img src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\subseteq " class="latex" title="\subseteq " /> <b>QMA</b>.</p>

<p>Our goal is to talk about progress towards a <b>quantum PCP theorem</b> (and since nobody has proved it in the positive or negative, we’ll refer to it as a quantum PCP <i>conjecture</i> for now), so it might be a good idea to first talk about the PCP theorem. Suppose we take a Boolean formula, and we want to verify that it is satisfiable. Then someone comes along and presents us with a certificate — in this case, a satisfying assignment — and we can check in polynomial time that either this is indeed a satisfying assignment to the formula (a correct certificate) or it is not (an incorrect certificate).</p>

<p>But this requires that we check the entire certificate that is presented to us. Now, in comes the <b>PCP Theorem</b> (for <i>probabilistically checkable proofs</i>), which tells us that a certificate can be presented to us such that we can read a constant number of bits from the certificate, and have two things guaranteed: one, if this certificate is correct, then we will never think that it is incorrect even if we are not reading the entire certificate, and two, if we are presented with an incorrect certificate, we will reject it with high probability [<a href="https://windowsontheory.org/feed/#arora2009computational">1</a>].</p>

<p>In short, one formulation of the PCP theorem tells us that, puzzingly, we might not need to read the entirety of a proof in order to be convinced with high probability that it is a good proof or a bad proof. But a natural question arises, which is to ask: is there a quantum analogue of the PCP theorem?</p>

<h2>Progress</h2>

<p>The answer is, we’re still not sure. But to make progress towards resolving this question, we will present the work of <a href="https://arxiv.org/pdf/1802.07419.pdf">Nirkhe, Vazirani, and Yuen</a> in providing an alternate proof of an earlier result of <a href="https://arxiv.org/pdf/1510.02082.pdf">Eldar and Harrow</a> on the NLETS theorem.

</p><p>Before we state the quantum PCP conjecture, it would be helpful to review information about local Hamiltonians and the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem. <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">A previous blog post by Ben Edelman</a> covers these topics. Now, let’s state the quantum PCP conjecture:</p>

<p><b>(<i>Quantum PCP Conjecture</i>)</b>: It is QMA-hard to decide whether a given local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+%3D+H_%7B1%7D+%2B+...+%2B+H_%7Bm%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = H_{1} + ... + H_{m} " class="latex" title="H = H_{1} + ... + H_{m} " /> (where each <img src="https://s0.wp.com/latex.php?latex=%7C%7CH_%7Bi%7D%7C%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="||H_{i}|| \leq 1" class="latex" title="||H_{i}|| \leq 1" />) has ground state energy at most <img src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a " class="latex" title="a " /> or at least <img src="https://s0.wp.com/latex.php?latex=b+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b " class="latex" title="b " /> when <img src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b-a \geq c||H|| " class="latex" title="b-a \geq c||H|| " /> for some universal constant <img src="https://s0.wp.com/latex.php?latex=c+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c &gt; 0" class="latex" title="c &gt; 0" />.</p>

<p>Recall that MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-SAT being NP-hard corresponds to the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem being QMA-hard when <img src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+1%2Fpoly%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b-a \geq 1/poly(n)" class="latex" title="b-a \geq 1/poly(n)" />. (We can refer to <a href="https://www.cs.cmu.edu/~odonnell/quantum15/lecture24.pdf">Theorem 4.1 in these scribed notes of Ryan O’Donnell’s lecture</a>, and more specifically to  <a href="https://arxiv.org/pdf/quant-ph/0406180.pdf">Kempe-Kitaev-Regev’s original paper</a> for proof of this fact.) The quantum PCP conjecture asks if this is still the case when the gap is <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H||" class="latex" title="c||H||" />.</p>

<p>Going back to the PCP theorem, an implication of the PCP theorem is that it is NP-hard to approximate certain problems to within some factor. Just like its classical analogue, the qPCP conjecture can be seen as stating that it is QMA-hard to approximate the ground state energy to a factor better than <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H||" class="latex" title="c||H||" />.</p>

<h3>Reformulation: NLTS conjecture</h3>
<p>Let’s make the observation that, taking <img src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a " class="latex" title="a " /> to be the ground state energy, the qPCP conjecture sort of says that there exists a family of Hamiltonians for which there is no trivial state (a state generated by a low depth circuit) such that the energy is at most <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H|| " class="latex" title="c||H|| " /> above the ground state energy.</p>

<p>Freedman and Hastings came up with an easier goal called the <b>No Low-Energy Trivial States conjecture</b>, or <b>NLTS conjecture</b>. We expect that ground states of local Hamiltonians are sufficiently hard to describe (if NP <img src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq " class="latex" title="\neq " /> QMA). So low-energy states might not be generated by a quantum circuit of constant depth. More formally:</p>

<p><b>(<i>NLTS Conjecture</i>)</b>: <i>There exists a universal constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon &gt; 0 " class="latex" title="\epsilon &gt; 0 " /> and a family of local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" title="\{H^{(n)}\}_{n=1}^{\infty} " /> where <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> acts on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles and consists of <img src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m_{n} " class="latex" title="m_{n} " /> local terms, s.t. any family of states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi_{n}\rangle\} " class="latex" title="\{|\psi_{n}\rangle\} " /> satisfying <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " /> requires circuit depth that grows faster than any constant.</i></p>

<p>To reiterate, if we did have such a family of NLTS Hamiltonians, then it we wouldn’t be able to give “easy proofs” for the minimal energy of a Hamiltonian, because we couldn’t just give a small circuit which produced a low energy state.</p>

<h2>Progress: NLETS theorem</h2>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " />-error states are states that differ from the ground state in at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon n " class="latex" title="\epsilon n " /> qubits. Now, consider <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states (which “agree” with the ground state on most qubits). Then for bounded-degree local Hamiltonians (analogously in the classical case, those where each variable participates in a bounded number of clauses), these states are also low energy. So any theorem which applies to low energy states (such as the NLTS conjecture), should also apply to states with <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error (as in the NLETS theorem).</p>

<p>To define low-error states more formally:</p>

<p><b>Definition 2.1</b> (<img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " />-error states): <i>Let <img src="https://s0.wp.com/latex.php?latex=%5Crho%2C+%5Csigma+%5Cin+D%28%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " class="latex" title="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " /> (the space of positive semidefinite operators of trace norm equal to 1 on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" title="(\mathbb{C}^{d})^{\otimes n}" />). Let <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> be a local Hamiltonian acting on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" title="(\mathbb{C}^{d})^{\otimes n}" />. Then:</i></p>

<p></p><ul>
    <li><img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state of <img src="https://s0.wp.com/latex.php?latex=%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho " class="latex" title="\rho " /> if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exists S \subseteq [n] " class="latex" title="\exists S \subseteq [n] " /> of size at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon n " class="latex" title="\epsilon n " /> s.t. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D%28%5Crho%29+%3D+%5Ctext%7BTr%7D_%7BS%7D%28%5Csigma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" class="latex" title="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" />.</li>
    <li><img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state for <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exists \rho " class="latex" title="\exists \rho " /> s.t. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28H%5Crho%29+%3D+%5Clambda_%7Bmin%7D%28H%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(H\rho) = \lambda_{min}(H) " class="latex" title="\text{Tr}(H\rho) = \lambda_{min}(H) " /> and <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state for <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />.</li>
</ul><p></p>

<p>Here, see that <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_{S} " class="latex" title="\text{Tr}_{S} " /> is just the partial trace on some subset of integers <img src="https://s0.wp.com/latex.php?latex=S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S " class="latex" title="S " />, like we’re tracing out or “disregarding” some subset of <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits.</p>

<p>In 2017, Eldar and Harrow showed the following result which is the NLETS theorem.</p>

<p><b>Theorem 1</b> (NLETS Theorem): <i>There exists a family of 16-local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> s.t. any family of <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5CPhi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\Phi_{n}\rangle\} " class="latex" title="\{|\Phi_{n}\rangle\} " /> for <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> requires circuit depth <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega(\log n) " class="latex" title="\Omega(\log n) " /> where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+10%5E%7B-9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon = 10^{-9}" class="latex" title="\epsilon = 10^{-9}" />.</i></p>

<p>In the next two sections, we will provide background for an alternate proof of the NLETS theorem due to Nirkhe, Vazirani, and Yuen. After this, we will explain why the proof of NLETS cannot be used to prove NLTS, since the local Hamiltonian family we construct for NLETS can be linearized. Nirkhe, Vazirani, and Yuen’s proof of NLETS makes use of the Feynman-Kitaev clock Hamiltonian corresponding to the circuit generating the cat state (Eldar and Harrow make use of the Tillich-Zemor hypergraph product construction; refer to section 8 of <a href="https://arxiv.org/pdf/1510.02082.pdf">their paper</a>). What is this circuit? It is this one:</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/cat_state.png?w=326&amp;h=210" alt="" width="326" class="wp-image-6977" height="210" />Image from [2]</figure></div>



<p>First, we apply the Hadamard gate (drawn as <img src="https://s0.wp.com/latex.php?latex=%5Cboxed%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boxed{H}" class="latex" title="\boxed{H}" />) which maps the first qubit <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle+%5Crightarrow+%5Cfrac%7B%7C0%5Crangle+%2B+%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" class="latex" title="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" />. Then we can think of the CNOT gates (drawn as <img src="https://s0.wp.com/latex.php?latex=%5Cbullet-%5Coplus&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bullet-\oplus" class="latex" title="\bullet-\oplus" />) as propagating whatever happens to the first qubit to the rest of the qubits. If we had the first qubit mapping to 0, then the rest of the qubits map to 0, and likewise for 1. This generates the cat state <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bn%7D%5Crangle+%3D+%5Cfrac%7B%7C0%5Crangle%5E%7B%5Cotimes+n%7D+%2B+%7C1%5Crangle%5E%7B%5Cotimes+n%7D%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" class="latex" title="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" />, which is highly entangled.</p>

<p>Why do we want a highly entangled state? Roughly our intuition for using the cat state is this: if the ground state of a Hamiltonian is highly entangled, then any quantum circuit which generates it has non-trivial depth. So if our goal is to show the existence of local Hamiltonians which have low energy or low error states that need deep circuits to generate, it makes sense to use a highly entangled state like the cat state.</p>

<h2>Quantum circuits</h2>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/operators.png?w=446&amp;h=221" alt="" width="446" class="wp-image-6978" height="221" />Image from [2]</figure></div>



<p>(We’ll write that the state of a qudit – a generalization of a qubit to more than two dimensions, and in this case <img src="https://s0.wp.com/latex.php?latex=q+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q " class="latex" title="q " /> dimensions – is a vector in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5E%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{C}^{q}" class="latex" title="\mathbb{C}^{q}" />. In our diagram above, we’ll see 4 qudits, labelled appropriately.)</p>

<p>Let’s briefly cover the definitions for the quantum circuits we’ll be using.</p>

<p>Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a unitary operator acting on a system of <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qudits (in other words, acting on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bq%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{q})^{\otimes n}" class="latex" title="(\mathbb{C}^{q})^{\otimes n}" />), where <img src="https://s0.wp.com/latex.php?latex=U+%3D+U_%7Bm%7D+%5Chdots+U_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = U_{m} \hdots U_{1}" class="latex" title="U = U_{m} \hdots U_{1}" />. Here, each <img src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{i} " class="latex" title="U_{i} " /> is a unitary operator (a gate) acting on at most two qudits, and <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is a product of <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> such operators.</p>

<p>If there exists a partition <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> into products of non-overlapping two-qudit unitaries (we call these layers and denote them as <img src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D+%3D+%5Cbigotimes_%7Bj%7DU_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i} = \bigotimes_{j}U_{ij}" class="latex" title="L_{i} = \bigotimes_{j}U_{ij}" />, where each <img src="https://s0.wp.com/latex.php?latex=U_%7Bj%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{j} " class="latex" title="U_{j} " /> here is in layer <img src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i}" class="latex" title="L_{i}" />) such that <img src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = L_{d} \hdots L_{1} " class="latex" title="U = L_{d} \hdots L_{1} " /> then we say <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> has <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> layers.</p>

<p>In other words, <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> has size <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> and circuit depth <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />.</p>

<h3>Lightcones, effect zones, shadow zones</h3>
<p>Consider <img src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = L_{d} \hdots L_{1} " class="latex" title="U = L_{d} \hdots L_{1} " /> and <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> an operator.</p>

<p>For <img src="https://s0.wp.com/latex.php?latex=j+%3C+d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j &lt; d " class="latex" title="j &lt; d " /> define <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j)} " class="latex" title="K^{(j)} " /> as the gates in layer <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> whose supports overlap that of any gate in <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j+1)}" class="latex" title="K^{(j+1)}" />, …, <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28d%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(d)} " class="latex" title="K^{(d)} " /> or with <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />.</p>

<p><b>Definition 3.1</b> (lightcone): <i>The <i>lightcone</i> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the union of <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j)}" class="latex" title="K^{(j)}" />: <img src="https://s0.wp.com/latex.php?latex=K_%7BU%7D+%5Ctriangleq+%5Cbigcup_%7Bj%7D+K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K_{U} \triangleq \bigcup_{j} K^{(j)}" class="latex" title="K_{U} \triangleq \bigcup_{j} K^{(j)}" />.</i></p>

<p>So we can think of the lightcone as the set of gates spreading out of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> all the way to the first layer of the circuit. In our diagram, the lightcone of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> is the dash-dotted region. We have <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%283%29%7D+%3D+%5Cvarnothing&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(3)} = \varnothing" class="latex" title="K^{(3)} = \varnothing" />, <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(2)} = \{U_{21}\}" class="latex" title="K^{(2)} = \{U_{21}\}" />, and <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(1)} = \{U_{11}, U_{12}\}" class="latex" title="K^{(1)} = \{U_{11}, U_{12}\}" />.</p>

<p>We also want a definition for what comes back from the lightcone: the set of gates from the first layer (the widest part of the cone) back to the last layer.</p>

<p>Define <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+K%5E%7B%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(1)} = K^{(1)}" class="latex" title="E^{(1)} = K^{(1)}" />. For <img src="https://s0.wp.com/latex.php?latex=j+%5Cgeq+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j \geq 2" class="latex" title="j \geq 2" />, let <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(j)} " class="latex" title="E^{(j)} " /> be the set of gates whose supports overlap with any gate in <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(j-1)}" class="latex" title="E^{(j-1)}" />.</p>

<p><b>Definition 3.2</b> (effect zone): <i>The <i>effect zone</i> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the union <img src="https://s0.wp.com/latex.php?latex=E_%7BU%7D%28A%29+%5Ctriangleq+%5Cbigcup_%7Bj%7D+E%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" class="latex" title="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" />.</i></p>

<p>In our diagram, see that <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(1)} = \{U_{11}, U_{12}\}" class="latex" title="E^{(1)} = \{U_{11}, U_{12}\}" />, <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(2)} = \{U_{21}\}" class="latex" title="E^{(2)} = \{U_{21}\}" />, and <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%283%29%7D+%3D+%5C%7BU_%7B31%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(3)} = \{U_{31}\}" class="latex" title="E^{(3)} = \{U_{31}\}" />. The effect zone of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> is the dotted region.</p>

<p><b>Definition 3.3</b> (shadow of the effect zone): <i>The <i>shadow of the effect zone</i> <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A) " class="latex" title="W_{U}(A) " /> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the set of qudits acted on by the gates in the effect zone.</i></p>

<p>In our diagram, the first three qudits are effected by gates in the effect zone. So <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+%3D+%5C%7B1%2C+2%2C+3%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A) = \{1, 2, 3\}" class="latex" title="W_{U}(A) = \{1, 2, 3\}" />.</p>

<p>Given all of these definitions, we make the following claim which will be important later, in a proof of a generalization of NLETS.</p>

<p><b><a id="claim3"></a>Claim 3.1</b> (Disjoint lightcones): <i>Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a circuit and <img src="https://s0.wp.com/latex.php?latex=A%2C+B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A, B " class="latex" title="A, B " /> operators. If the qudits <img src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B " class="latex" title="B " /> acts on are disjoint from <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A)" class="latex" title="W_{U}(A)" />, then the lightcones of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> and <img src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B " class="latex" title="B " /> in <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> are disjoint.</i></p>

<h2>Toward the Feynman-Kitaev clock</h2>
<p>Now we’ll give some definitions that will become necessary when we make use of the Feynman-Kitaev Hamiltonian in our later proofs.</p>

<p>Let’s define a unary clock. It will basically help us determine whatever happened at any time little <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> along the total time big <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. Let <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle+%3D+%7C0%5Crangle%5E%7B%5Cotimes%28T-t%29%7D+%5Cotimes+%7C1%5Crangle%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" class="latex" title="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" />. For our purposes today, we won’t worry about higher dimensional clocks. So we’ll write <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{clock}_{k}(t, T)\rangle" class="latex" title="|\textsf{clock}_{k}(t, T)\rangle" />, but we’ll really only consider the case where <img src="https://s0.wp.com/latex.php?latex=k+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 1" class="latex" title="k = 1" />, which corresponds to <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t, T)\rangle" class="latex" title="|\textsf{unary}(t, T)\rangle" />. For simplicity’s sake, we will henceforth just write <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t)\rangle" class="latex" title="|\textsf{unary}(t)\rangle" />.</p>

<p>Our goal is to construct something a little similar to the tableaux in the Cook-Levin theorem, so we also want to define a history state:</p>

<p><b>Definition 4.1</b> (History state): <i>Let <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> be a quantum circuit that acts on a witness register and an ancilla register. Let <img src="https://s0.wp.com/latex.php?latex=C_%7B1%7D%2C+...%2C+C_%7BT%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{1}, ..., C_{T} " class="latex" title="C_{1}, ..., C_{T} " /> denote the sequence of two-local gates in <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. Then for all <img src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \in \mathbb{N}" class="latex" title="k \in \mathbb{N}" />, a state <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle " class="latex" title="|\Psi\rangle " /> is a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-dimensional history state of <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> if:</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BT%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5E%7BT%7D%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle+%5Cotimes+%7C%5Cpsi_%7Bt%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " /></p></div>

<p>where we have the clock state to keep track of time and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_{t} " class="latex" title="\psi_{t} " /> is some state such that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7Bt%7D%5Crangle+%3D+C_%7Bt%7D%7C%5Cpsi_%7Bt-1%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " class="latex" title="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7B0%7D%5Crangle+%3D+%7C%5Cxi%5Crangle_%7Bwitness%7D+%5Cotimes+%7C0%5Crangle_%7Bancilla%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" class="latex" title="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" />. With this construction, we should be able to make a measurement to get back the state at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />.</p>

<h2>Proof of NLETS</h2>
<p>We provide a proof of (a simplified case of) the NLETS theorem proved by Nirkhe, Vazirani, and Yuen in [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>].</p>

<p><b>Theorem 2</b> (NLETS): <i>There exists a family of <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> on a line (Each Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> can be defined on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles arranged on a line such that each local Hamiltonian acts on a particle and its two neighbors) such that for all <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \in \mathbb{N}" class="latex" title="n \in \mathbb{N}" />, the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error ground state for <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> is at least logarithmic in <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " />.</i></p>

<p>First, we’ll show the circuit lower bound.  Then we’ll explain why these Hamiltonians can act on particles on a line and what this implies about the potential of these techniques for proving NLTS.</p>

<p><i>Proof</i>: We will use the <b>Feynman-Kitaev clock construction</b> to construct a <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}^{(n)} " class="latex" title="\mathcal{H}^{(n)} " /> for the circuit <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />: <img src="https://s0.wp.com/latex.php?latex=%7C0%5En%5Crangle+%5Cto+%7C%5Ctextsf%7BCAT%7D_n%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0^n\rangle \to |\textsf{CAT}_n\rangle " class="latex" title="|0^n\rangle \to |\textsf{CAT}_n\rangle " />.</p>

<p>Fix <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \in \mathbb{N} " class="latex" title="n \in \mathbb{N} " /> and let <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> have size <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />.  The Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> acts on <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubits and consists of several local terms depending on <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />:</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t+%2B+H_%7Bout%7D+%2B+H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " class="latex" title="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " /></p></div>

<p>We can think of a <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state as representing a <img src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T " class="latex" title="T " /> step computation on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits (i.e. for each time <img src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B0%2CT%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t \in [0,T]" class="latex" title="t \in [0,T]" />, we have a <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> bit computation state <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_t " class="latex" title="\textsf{state}_t " /> of <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />).  Intuitively, a <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state has energy <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> with respect to <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> iff it is the history state of <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />.  This is because <img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> checks that at time <img src="https://s0.wp.com/latex.php?latex=t%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=0" class="latex" title="t=0" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_0 " class="latex" title="\textsf{state}_0 " /> consists of the input <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5En+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle^n " class="latex" title="|0\rangle^n " /> to <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />.  Each <img src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_t " class="latex" title="H_t " /> checks that <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_{t} " class="latex" title="\textsf{state}_{t} " /> proceed correctly from <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt-1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_{t-1} " class="latex" title="\textsf{state}_{t-1} " /> (i.e. that the <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />th gate of <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> is applied correctly).  Then <img src="https://s0.wp.com/latex.php?latex=H_%7Bout%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{out} " class="latex" title="H_{out} " /> checks that at time <img src="https://s0.wp.com/latex.php?latex=t%3DT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=T" class="latex" title="t=T" />, the output is <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />.  Finally, <img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> checks that the <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state is a superposition only over states where the first <img src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T " class="latex" title="T " /> qubits represent “correct times” (i.e. a unary clock state where time <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> is represented by <img src="https://s0.wp.com/latex.php?latex=T-t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T-t " class="latex" title="T-t " /> zeros followed by <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> ones).</p>

<p>Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> has a unique ground state, the history state of <img src="https://s0.wp.com/latex.php?latex=C_n%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n|0^n\rangle" class="latex" title="C_n|0^n\rangle" />, with energy <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />:</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes+%7C%5Cpsi_t%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes+%7C0%5Crangle%5E%7B%5Cotimes+%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " /></p></div>

<p>Later we will show how to transform <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> into a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qutrits on a line.  Intuitively, the structure of <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> allows us to fuse the <img src="https://s0.wp.com/latex.php?latex=T%3Dn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T=n " class="latex" title="T=n " /> time qubits and <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> state qubits and represent unused state qubits by <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />.  For the Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />, the ground state becomes</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Cpsi_t%5Crangle+%3D+%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes%7C2%5Crangle%5E%7B%5Cotimes%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " /></p></div>

<p>For the rest of this proof, we work with respect to <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.</p>

<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> be an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state and let <img src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S \subseteq [n] " class="latex" title="S \subseteq [n] " /> be the subset of qutrits such that <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_S%28%5Csigma%29+%3D+%5Ctext%7BTr%7D_S%28%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" class="latex" title="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" />.  We define two projection operators which, when applied to <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> alone, produce nontrivial measurements, but when applied to <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> together, produce trivial measurements.</p>

<p><b>Definition 5.1</b>: <i>For any <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\in[n]" class="latex" title="i\in[n]" />, the projection operator</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DA_i+%3D+%7C0%5Crangle%5Clangle+0%7C_i+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " class="latex" title="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " /></p></div>

<p><i>projects onto the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit.</i></p>

<p><i>For any <img src="https://s0.wp.com/latex.php?latex=j%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j\in[n]" class="latex" title="j\in[n]" />, the projection operator</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+B_j+%3D+%7C1%5Crangle%5Clangle+1%7C_i%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " class="latex" title="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " /></p></div>

<p><i>projects onto the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 " class="latex" title="1 " /> on the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrit.</i></p>

<p><b>Claim 5.1</b>:
<i>For <img src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\not\in S" class="latex" title="i\not\in S" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" title="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" />.  For <img src="https://s0.wp.com/latex.php?latex=j%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j\not\in S" class="latex" title="j\not\in S" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" />.  Note that these values are positive for any <img src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j\in [n]" class="latex" title="i,j\in [n]" />.</i></p>

<p><i>Proof</i>: If <img src="https://s0.wp.com/latex.php?latex=i+%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \not\in S" class="latex" title="i \not\in S" />, then measurements on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit are the same for <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle\langle\Psi|" class="latex" title="|\Psi\rangle\langle\Psi|" />.</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29%5C%5C+++++%26%3D+%5Ctext%7BTr%7D%5Cleft%28A_i+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%5Cright%29%5C%5C+++++%26%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%29+++%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " class="latex" title="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=t%3Dt%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=t'" class="latex" title="t=t'" />, then any <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qutrit pure state cannot have nonzero weight in both <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%27%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_{t'} " class="latex" title="\psi_{t'} " /> (every pure state ends in some number of <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />s which tells which <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> (if any) it can be a part of). Therefore,</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%7D%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle+%5Cpsi_t%7CA_i%7C%5Cpsi_t%5Crangle+%5Censpace.+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " class="latex" title="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=i+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \le t" class="latex" title="i \le t" />, then projecting onto the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit gives <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" />. Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Cleft%28%5Cfrac%7Bn-i%2B1%7D%7B2%7D%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" title="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" />.</p>

<p>Similarly, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p><b>Claim 5.2</b>: <i>For <img src="https://s0.wp.com/latex.php?latex=i%2Cj+%5Cnot%5Cin+S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j \not\in S " class="latex" title="i,j \not\in S " /> such that <img src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i &lt; j" class="latex" title="i &lt; j" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i \otimes B_j \sigma) = 0" class="latex" title="\text{Tr}(A_i \otimes B_j \sigma) = 0" />.</i></p>

<p><i>Proof</i>:
As before, we can calculate</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle%5Cpsi_t%7CA_i%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " class="latex" title="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=j+%3E+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j &gt; t" class="latex" title="j &gt; t" />, then the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrit of <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> is <img src="https://s0.wp.com/latex.php?latex=2+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2 " class="latex" title="2 " /> so <img src="https://s0.wp.com/latex.php?latex=B_j%7C%5Cpsi_t%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B_j|\psi_t\rangle = 0" class="latex" title="B_j|\psi_t\rangle = 0" />. If <img src="https://s0.wp.com/latex.php?latex=j+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j \le t" class="latex" title="j \le t" />, then <img src="https://s0.wp.com/latex.php?latex=A_i+%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%3D+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i \otimes B_j|\psi_t\rangle = 0 " class="latex" title="A_i \otimes B_j|\psi_t\rangle = 0 " /> because the first <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> qutrits of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_t%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_t\rangle " class="latex" title="|\psi_t\rangle " /> contain the <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{CAT}_{t}\rangle " class="latex" title="|\textsf{CAT}_{t}\rangle " /> state so under any measurement, the <img src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i " class="latex" title="i " /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrits must be the same. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p>Now we use these claims to prove a circuit lower bound.  Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a circuit generating (a state with density matrix) <img src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma" class="latex" title="\sigma" />.  Let <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> be the depth of <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" />.</p>

<p>Consider some <img src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\not\in S" class="latex" title="i\not\in S" />.  For any operator acting on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit, its lightcone consists of at most <img src="https://s0.wp.com/latex.php?latex=2%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^d " class="latex" title="2^d " /> gates so its effect zone consists of at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d} " class="latex" title="2^{2d} " /> gates which act on at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} " class="latex" title="2^{2d+1} " /> qudits (called the shadow of the effect zone).</p>

<p>Assume towards contradiction that <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%3C+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} &lt; n-\epsilon n" class="latex" title="2^{2d+1} &lt; n-\epsilon n" />. Then the shadow of any operator acting only on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit has size at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cle+n+-+%7CS%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} \le n - |S| " class="latex" title="2^{2d+1} \le n - |S| " /> since <img src="https://s0.wp.com/latex.php?latex=%7CS%7C+%5Cle+%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|S| \le \epsilon n" class="latex" title="|S| \le \epsilon n" />.  So there is some <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> outside of the shadow which is in the complement of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" />.  By <a href="https://windowsontheory.org/feed/#claim3">Claim 3.1</a>, we have found two indices <img src="https://s0.wp.com/latex.php?latex=i%2Cj+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j " class="latex" title="i,j " /> such that any pair of operators acting on <img src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i " class="latex" title="i " /> and <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> have disjoint lightcones in <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" />. WLOG let <img src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i &lt; j" class="latex" title="i &lt; j" />.  The lightcones of <img src="https://s0.wp.com/latex.php?latex=A_i%2CB_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i,B_j " class="latex" title="A_i,B_j " /> are disjoint which implies
<img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+%5Ctext%7BTr%7D%28A_i+%5Csigma%29%5Ccdot%5Ctext%7BTr%7D%28B_j+%5Csigma%29.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " class="latex" title="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " /></p>

<p>By the two claims above, we get a contradiction.</p>

<p>Therefore, <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cge+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} \ge n-\epsilon n" class="latex" title="2^{2d+1} \ge n-\epsilon n" />.  We can take any constant epsilon: letting <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon = 1/2" class="latex" title="\epsilon = 1/2" />, we get</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7Dd+%5Cge+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28%5Clog+%5Cfrac%7Bn%7D%7B2%7D+-+1%5Cright%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " class="latex" title="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " /></p></div>

<p><img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p>This analysis relies crucially on the fact that any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state matches the groundstate on most qudits.  However, NLTS is concerned with states which may differ from the groundstate on many qudits, as long as they have low energy.</p>

<p><b>Remark 2.1</b>: <i>The paper of Nirkhe, Vazirani, and Yuen [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>] actually proves more:
</i></p><ul><i>
    </i><li><i>A more general lower bound: logarithmic lower bound on the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta" class="latex" title="\delta" />-approximate (<img src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta " class="latex" title="\delta " /> far in L1 norm) <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-noisy state (probability distribution over <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states).</i></li><i>
    </i><li><i>Assuming QCMA <img src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq " class="latex" title="\neq " /> QMA (QCMA takes a <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> bit witness string instead of a <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> qubit state as witness), they show a superpolynomial lower bound (on the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta" class="latex" title="\delta" />-approximate <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-noisy state).</i></li><i>
    </i><li><i>“Approximate qLWC codes”, using techniques from their superpolynomial lower bound.</i></li><i>
</i></ul><p></p>

<h2>Back to NLTS – Tempering our Optimism</h2>

<p>So far, we’ve shown a local Hamiltonian family for which all low-error (in “Hamming distance”) states require logarithmic quantum circuit depth to compute, thus resolving the NLETS conjecture. Now, let’s try to tie this back into the NLTS conjecture. Since it’s been a while, let’s recall the statement of the conjecture:</p>

<p><b>Conjecture</b> (NLTS): <i>There exists a universal constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon &gt; 0 " class="latex" title="\epsilon &gt; 0 " /> and a family of local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" title="\{H^{(n)}\}_{n=1}^{\infty} " /> where <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> acts on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles and consists of <img src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m_{n} " class="latex" title="m_{n} " /> local terms, s.t. any family of states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi_{n}\rangle\} " class="latex" title="\{|\psi_{n}\rangle\} " /> satisfying <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " /> requires circuit depth that grows faster than any constant.</i></p>

<p>In order to resolve the NLTS conjecture, it thus suffices to exhibit a local Hamiltonian family for which all low-energy states require logarithmic quantum circuit depth to compute. We might wonder if the local Hamiltonian family we used to resolve NLETS, which has “hard ground states”, might also have hard low-energy states. Unfortunately, as we shall show, this cannot be the case. We will start by showing that Hamiltonian families that lie on constant-dimensional lattices (in a sense that we will make precise momentarily) cannot possibly be used to resolve NLTS,  and then show that the Hamiltonian family we used to prove NLTS can be linearized (made to lie on a one-dimensional lattice!).</p>

<h3>The Woes of Constant-Dimensional Lattices</h3>
<p><b>Definition 6.1</b>: <i>A local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> acting on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits is said to <b>lie on a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /></b> if there is an injection of qubits into vertices of the graph such that the set of qubits in any interaction term correspond to a connected component in the graph</i>.</p>

<p><b>Theorem 2</b>: <i>If <img src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H^{(n)}) " class="latex" title="(H^{(n)}) " /> is a local Hamiltonian family that lies on an <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" />-dimensional lattice, then <img src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H^{(n)}) " class="latex" title="(H^{(n)}) " /> has a family of low-energy states with low circuit complexity. In particular, if <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> is a local Hamiltonian on a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice acting on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits for large enough <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, then for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, there exists a state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle " class="latex" title="|\psi\rangle " /> that can be generated by a circuit of constant depth and such that <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle+%5Cleq+H_0+%2B+%5Cepsilon+%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " class="latex" title="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " /> where <img src="https://s0.wp.com/latex.php?latex=H_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_0 " class="latex" title="H_0 " /> is the ground-state energy.</i></p>

<p><i>Proof</i>: In what follows, we’ll omit some of the more annoying computational details in the interest of communicating the high-level idea.</p>

<p>Start by partitioning the <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice (the one that <img src="https://s0.wp.com/latex.php?latex=H%5E%28n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^(n) " class="latex" title="H^(n) " /> lives on) into hypercubes of side length <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" />. We can “restrict” <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> to a given hypercube (let’s call it <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />) by throwing away all local terms containing a qubit not in <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />. This gives us a well-defined Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{\rho} " class="latex" title="H_{\rho} " /> on the qubits in <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />. Define <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi_{\rho}\rangle " class="latex" title="|\phi_{\rho}\rangle " /> to be the <img src="https://s0.wp.com/latex.php?latex=L%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L^d" class="latex" title="L^d" />-qubit ground state of <img src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{\rho}" class="latex" title="H_{\rho}" />, and define</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cphi%5Crangle+%3A%3D+%5Cbigotimes_%7B%5Ctext%7Bhypercubes+%7D+%5Crho%7D+%7C%5Cphi_%7B%5Crho%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " class="latex" title="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " /></p></div>

<p>where <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> is an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit state. Each <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi_{\rho}\rangle " class="latex" title="|\phi_{\rho}\rangle " /> can be generated by a circuit with at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d} " class="latex" title="2^{L^d} " /> gates, hence at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d} " class="latex" title="2^{L^d} " /> depth. Then, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by putting all of these individual circuits in parallel – this doesn’t violate any sort of no-cloning condition because the individual circuits act on disjoint sets of qubits. Therefore, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by a circuit of depth at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d}" class="latex" title="2^{L^d}" />. <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> and <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> are both constants, so <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by a constant-depth circuit.</p>

<p>We claim that, for the right choice of <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" />, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> is also a low-energy state. Intuitively, this is true because <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi " class="latex" title="\phi " /> can only be “worse” than a true ground state of <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> on local Hamiltonian terms that do not lie entirely within a single hypercube (i.e. the boundary terms), and by choosing <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> appropriately we can make this a vanishingly small fraction of the local terms of <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)}" class="latex" title="H^{(n)}" />. Let’s work this out explicitly.</p>

<p>Each hypercube has surface area <img src="https://s0.wp.com/latex.php?latex=2dL%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2dL^{d-1}" class="latex" title="2dL^{d-1}" />, and there are <img src="https://s0.wp.com/latex.php?latex=n%2FL%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n/L^d " class="latex" title="n/L^d " /> hypercubes in the lattice. Thus, the total number of qubits on boundaries is at most <img src="https://s0.wp.com/latex.php?latex=2d%5Cfrac%7Bn%7D%7BL%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2d\frac{n}{L}" class="latex" title="2d\frac{n}{L}" />. The number of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-connected components containing a given point in a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice is a function of <img src="https://s0.wp.com/latex.php?latex=k+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k " class="latex" title="k " /> and <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />. Both of these are constants. Therefore, the number of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-connected components containing a given vertex, and hence the number of local Hamiltonian terms containing a given qubit, is constant. Thus, the total number of violated local Hamiltonian terms is at most <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7BL%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{n}{L})" class="latex" title="O(\frac{n}{L})" />. Taking <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> to be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\epsilon}" class="latex" title="\frac{1}{\epsilon}" />, we get the desired bound. Note that to be fully rigorous, we need to justify that the boundary terms don’t blow up the energy, but this is left as an exercise for the reader. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<h3>Linearizing the Hamiltonian</h3>
<p>Now that we have shown that Hamiltonians that live on constant-dimensional lattices cannot be used to prove NLTS, we will put the final nail in the coffin by showing that our NLETS Hamiltonian (the Feynman-Kitaev clock Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> on the circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />) can be made to lie on a line (a <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />-dimensional lattice). To do so, we will need to understand the details of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> a bit better.</p>

<p><b><a id="prop6">Proposition 6.1</a></b>: <i><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> for the circuit <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> is <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local.</i></p>

<p><i>Proof</i>: Recall that we defined</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3A%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t%2B++H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " class="latex" title="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " /></p></div>

<p>Let’s go through the right-hand-side term-by-term. We will use <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Btime%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathsf{time}(t)\rangle " class="latex" title="|\mathsf{time}(t)\rangle " /> to denote the <img src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t^{\text{th}} " class="latex" title="t^{\text{th}} " /> qubit of the time register and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Bstate%7D%28s%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathsf{state}(s)\rangle " class="latex" title="|\mathsf{state}(s)\rangle " /> to denote the <img src="https://s0.wp.com/latex.php?latex=s%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s^{\text{th}} " class="latex" title="s^{\text{th}} " /> qubit of the state register.</p>

<p>
  </p><ul>
    <li><img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> needs to serially access the qubit pairs

    <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cmathsf%7Btime%7D%280%29%5Crangle%5Cotimes%5Ctextsf%7Bstate%7D%28s%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " class="latex" title="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " />

    for all <img src="https://s0.wp.com/latex.php?latex=s+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s " class="latex" title="s " /> and ensure that they are all set to <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle" class="latex" title="|0\rangle" />. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> is <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />-local.</li>
    <li>Each <img src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_t " class="latex" title="H_t " /> term needs to access the states <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t-1%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle%2C+%7C%5Ctextsf%7Bstate%7D%28s%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" class="latex" title="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" />, and  <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{state}(t)\rangle " class="latex" title="|\textsf{state}(t)\rangle " /> and ensure that the state transitions are correct. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{t} " class="latex" title="H_{t} " /> is <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local.</li>
    <li><img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> needs to access the states

    <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " class="latex" title="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " />

    and ensure that the progression of the time register is correct. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> is <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />-local. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></li>
  </ul>
<p></p>


<p>Now, we follow an approach of [<a href="https://windowsontheory.org/feed/#aharonov2017">3</a>] to embed <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> into a line.</p>

<p><b>Theorem 3</b>: <i>The Feynman-Kitaev clock Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> can be manipulated into a <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local Hamiltonian acting on qutrits on a line.</i></p>

<p><i>Proof</i>: Rather than having <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> act on <img src="https://s0.wp.com/latex.php?latex=2n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2n " class="latex" title="2n " /> total qubits (<img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> time qubits and <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> state qubits), let’s fuse each <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(i)\rangle " class="latex" title="|\textsf{time}(i)\rangle " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{state}(i)\rangle " class="latex" title="|\textsf{state}(i)\rangle " /> pair into a single qudit of dimension <img src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="4" class="latex" title="4" />. If we view <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> as acting on the space of particles <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" class="latex" title="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" />, we observe that, following <a href="https://windowsontheory.org/feed/#prop6">Proposition 6.1</a>, each local term needs to check at most the particles corresponding to times <img src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t-1" class="latex" title="t-1" />, <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, and <img src="https://s0.wp.com/latex.php?latex=t%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t+1" class="latex" title="t+1" />. Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> is <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local and on a line, as desired.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/qutrits.png?w=600" alt="" class="wp-image-6979" />Image from [2]</figure>



<p>To see that we can have <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> act on particles of dimension <img src="https://s0.wp.com/latex.php?latex=3+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3 " class="latex" title="3 " /> (qutrits) rather than particles of dimension <img src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="4" class="latex" title="4" />, note that the degree of freedom corresponding to <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+%3D+%7C0%5Crangle+%5Cotimes+%7C1%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " class="latex" title="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " /> is unused, as the <img src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t^{\text{th}} " class="latex" title="t^{\text{th}} " /> qubit of the state is never nonzero until timestamp <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. Thus, we can take the vectors</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C0%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C0%5Crangle%2C+%7C1%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C1%5Crangle%2C+%7C2%5Crangle+%3A%3D+%7C0%5Crangle%5Cotimes%7C0%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " class="latex" title="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " /></p></div>

<p>as a basis for each qutrit.</p>

<p>Even though we’ve shown that the clock Hamiltonian for our original circuit cannot be used to prove NLTS (which is still weaker than the original Quantum PCP conjecture) this does not necessarily rule out the use of this approach for other “hard” circuits which might then allow us to prove NLTS. Furthermore, NLETS is independently interesting, as the notion of being low “Hamming distance” away from vectors is exactly what is used in error-correcting codes.</p>

<h1>References</h1>
<ul>
<li><a id="arora2009computational">[1]</a> Sanjeev Arora and Boaz Barak. <i>Computational complexity: a modern approach.</i> Cambridge University Press, 2009.</li>
<li><a id="nirkhe2018approximate">[2]</a> Chinmay Nirkhe, Umesh Vazirani,  and Henry Yuen. Approximate low-weight check codes and circuit lower bounds for noisy ground states. <i>arXiv preprint arXiv:1802.07419</i>, 2018.</li>
<li><a id="aharonov2017">[3]</a> Dorit Aharonov, Wim van Dam, Julia Kempe, Zeph Landau, Seth Lloyd, and Oded Regev. Adiabatic quantum computation is equivalent to standard quantum computation. <i>SIAM J. Comput.</i>, 2007.</li></ul></div>







<p class="date">
by richardmwang <a href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/"><span class="datestr">at December 23, 2018 01:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6948">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/">Quantum Approximate Optimization Algorithm and Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2>Motivation</h2>
<p> </p>
<p>Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers outperforming classical computers) has been explored for three general groups of problems:</p>
<ol>
<li>Structured problems, such as factoring and discrete logarithm. Out quantum computer takes advantage of the structure of these classes of problems to offer an exponential speedup compared to the best known classical alternative. While these speedups are the most promising, they require a large number of resources and are cannot be feasibly implemented in the near future.</li>
<li>Quantum Simulations, originally proposed by Richard Feynman in the late 80s was thought to be the first motivation behind exploring quantum computation. Due to the fact that the space of all possible states of the system scales exponentially with the addition of a new element (eg. an atom), complex systems are very difficult to simulate classically. It has been shown that we can use a quantum computer to tackle interesting problems in quantum chemistry and chemical engineering. Furthermore, there are results on sampling the output of random quantum circuits which have been used for “quantum supremacy experiments”.</li>
<li>General constraint satisfaction and optimization problems. Since these problems are NP-hard it is widely believed that we cannot gain an exponential speedup using a quantum computer, however, we can obtain quadratic speedup but utilizing a variation of Grover’s algorithm.</li>
</ol>
<p>While these quantum algorithms are very exciting, they are beyond the capabilities of our near-term quantum computers; for example, any useful application of Shor’s factoring algorithm requires anywhere between tens of thousands to millions of qubits with error correction compared to quantum devices with hundreds of qubits that we might have available in the next few years.</p>
<p>Recently there has been increasing interest in hybrid classical-quantum algorithms among the community. The general idea behind this approach is to supplement the noisy intermediate-scale quantum (NISQ) devices with classical computers. In this blog post, we discuss the Quantum Approximate Optimization Algorithm (QAOA), which is a hybrid algorithm, alongside some of its applications.</p>
<h2>Introduction</h2>
<p>QAOA is used for optimizing combinatorial problems. Let’s assume a problem with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> bits and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> clauses. Each clause is a constraint on a subset of the bits which satisfies a certain assignment. We can define a cost function as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C%28z%29%3D%5Csum_%7B%5Calpha%3D1%7D%5Em+C_%5Calpha+%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " class="latex" title="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=z%3Dz_1z_2...z_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z=z_1z_2...z_n" class="latex" title="z=z_1z_2...z_n" /> is the bit string. In this article we consider a minimization problem, therefore we want <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha%28z%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha(z)=0" class="latex" title="C_\alpha(z)=0" /> if <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" /> satisfies clause <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> and 1 otherwise. Note that in the case of a maximization problem we only need to switch the value assigned to a satisfactory clause to 1. Our objective is to find a (qu)bit string that minimizes (or maximizes) our cost function.</p>
<p>At a higher level, we start with a quantum state in a uniform superposition of all possible inputs <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" />. This can be accomplished with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits which span a space of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" />. Our goal is to come up with a series of operations that would evolve our initial quantum state into a superposition of states in which the valid solutions would have a significantly higher probability than other states. In manner, upon sampling the quantum state we are likely to get the correct solution with high probability. QAOA uses the cost function to construct a set of operations that would be able to efficiently map the unifrom superposition state into the desired quantum state. These operators involve single qubits rotations around the x-axis, and multiqubit rotations around the z-axis of our qubits.</p>
<p>Now let’s discuss the details of QAOA. For this algorithm we assume that our quantum computer works in the computation basis of <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C0+%5Cright+%3E+%2C+%5Cleft+%7C+1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |0 \right &gt; , \left | 1 \right &gt; " class="latex" title="\left |0 \right &gt; , \left | 1 \right &gt; " />. We start by setting our initial state to a uniform superposition over computational basis states:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7Cs+%5Cright+%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5En%7D%7D%5Csum_%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%5Cleft+%7Cz+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " class="latex" title="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " /></p>
<p>Next, we define a unitary operator using the cost function as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U%28%5Chat%7BC%7D%2C%5Cgamma%29+%3D+e%5E%7Bi%5Cgamma+%5Chat%7BC%7D%7D%3D+%5Cprod_%7B%5Calpha+%3D+1%7D%5Em+e%5E%7B-i%5Cgamma+%5Chat%7BC%7D_%5Calpha%7D%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha} " class="latex" title="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha} " /></p>
<p>Here we convert every clause <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha" class="latex" title="C_\alpha" /> to a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}" class="latex" title="\hat{C_\alpha}" /> consisting of Pauli Z ($\sigma^z$) operators. Just as a review, the two Pauli operators (X and Z) used in this blog post are representated as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ex+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+0+%26+1+%5C%5C%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%5Cend%7Bpmatrix%7D+%5C%3A+%5C%3A+%5C%3A+%5C%3A++%5Csigma%5Ez+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%C2%A0%C2%A0%C2%A0+0+%26+-1+%5C%5C%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^x = \begin{pmatrix}    0 &amp; 1 \\    1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}    1 &amp; 0 \\    0 &amp; -1 \\\end{pmatrix} " class="latex" title="\sigma^x = \begin{pmatrix}    0 &amp; 1 \\    1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}    1 &amp; 0 \\    0 &amp; -1 \\\end{pmatrix} " /></p>
<p>For example if <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha%3Dx+%5Coplus+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha=x \oplus y" class="latex" title="C_\alpha=x \oplus y" /> we can map the clause to <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D%3D%5Cfrac%7B1%7D%7B2%7D%281%2B%5Csigma%5Ez_x+%5Csigma%5Ez_y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" class="latex" title="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" /> for a minimization problem. If <img src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C0+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=\left |0 \right &gt;  " class="latex" title="x=\left |0 \right &gt;  " /> , then <img src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ez_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^z_x" class="latex" title="\sigma^z_x" /> will return a value of 1, and if <img src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=\left |1 \right &gt; " class="latex" title="x=\left |1 \right &gt; " /> the operator will return -1. The same applies to qubit <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> as well. Therefore it is not hard to see that if <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> have the same value, then the operator <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}" class="latex" title="\hat{C_\alpha}" /> as defined above will result in a 1, and it’ll result in 0 otherwise. Furthermore, since <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C}" class="latex" title="\hat{C}" /> has integer eigenvalues we can restrict the angle <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\gamma" class="latex" title="\gamma" /> to lie in <img src="https://s0.wp.com/latex.php?latex=%5B0%2C2%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[0,2\pi]" class="latex" title="[0,2\pi]" />.</p>
<p>Next, we define the admixing Hamiltonian:</p>
<p><img src="https://s0.wp.com/latex.php?latex=B%3D%5Csum_%7Bj%3D1%7D%5En+%5Csigma%5Ex_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B=\sum_{j=1}^n \sigma^x_j " class="latex" title="B=\sum_{j=1}^n \sigma^x_j " /></p>
<p>and use it to define a unitary operator which consists of a product of commuting one qubit operations:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29+%3D+e%5E%7B-i%5Cbeta+B%7D%3D+%5Cprod_%7Bj%3D1%7D%5En+e%5E%7B-i+%5Cbeta+%5Csigma_j%5Ex%7D%C2%A0%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}  " class="latex" title="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cin+%5B0%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta \in [0,\pi]" class="latex" title="\beta \in [0,\pi]" />. It’s easy to see that <img src="https://s0.wp.com/latex.php?latex=U%28%5CHat%7BC%7D%2C%5Cgamma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(\Hat{C},\gamma)" class="latex" title="U(\Hat{C},\gamma)" /> couples 2 or more qubits, while <img src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(B,\beta)" class="latex" title="U(B,\beta)" /> performs a single qubit rotation on the qubits in our system. Using these unitaries and our initial state we define a QAOA angle-dependent “ansatz” state as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%C2%A0%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E%3D+U%28B%2C%5Cbeta_p%29U%28%5CHat%7BC%7D%2C%5Cgamma_p%29...U%28B%2C%5Cbeta_1%29U%28%5CHat%7BC%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |  \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " class="latex" title="\left |  \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 1" class="latex" title="p\geq 1" /> is the “depth” of our QAOA circuit, and <img src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cgamma%7D%3D%28%5Cgamma_p%2C...%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" class="latex" title="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" />, <img src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cbeta%7D%3D%28%5Cbeta_p%2C...%2C%5Cbeta_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" class="latex" title="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" /> are each a vector of length <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> controlling the angles for each layer. In the worst case scenario this state can be produce by a quantum circuit of depth <img src="https://s0.wp.com/latex.php?latex=mp%2Bp&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="mp+p" class="latex" title="mp+p" />, however by taking advantage of the structure of the instance we can further reduce the number of layers required. Let <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> be the expectation of <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C}" class="latex" title="\hat{C}" /> in our ansatz:</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29%3D%5Cleft+%3C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%7C+%5Chat%7BC%7D+%5Cleft+%7C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " class="latex" title="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " /></p>
<p>and let <img src="https://s0.wp.com/latex.php?latex=M_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p" class="latex" title="M_p" /> be the minimum of <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> over angles,</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_p%3D%5Cmin_%7B%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%7D+F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " class="latex" title="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " /></p>
<p>Note that minimization at <img src="https://s0.wp.com/latex.php?latex=p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p-1" class="latex" title="p-1" /> layers can be viewed as a constrained minimization at <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> layers, therefore</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_p+%5Cleq+M_%7Bp-1%7D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p \leq M_{p-1}  " class="latex" title="M_p \leq M_{p-1}  " /></p>
<p>Using an adiabatic approach [1] We can show that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bp+%5Crightarrow+%5Cinfty%7D+M_p+%3D+%5Cmin_z+C%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " class="latex" title="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " /></p>
<p>Based on these results our QAOA algorithm will look like the following:</p>
<ul>
<li> c: pick a <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /></li>
<li>c: choose a set of angles <img src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D_0%2C%5CVec%7B%5Cbeta%7D_0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\Vec{\gamma}_0,\Vec{\beta}_0)" class="latex" title="(\Vec{\gamma}_0,\Vec{\beta}_0)" /></li>
<li>q: prepare <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " /></li>
<li>q: compute <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /></li>
<li>c: perform gradient descend/ascend on <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> and get a new set of angles <img src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\Vec{\gamma},\Vec{\beta})" class="latex" title="(\Vec{\gamma},\Vec{\beta})" /></li>
<li>repeat from step 3 till convergence</li>
<li>report the measurement result of <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " /> in computational basis</li>
</ul>
<p>If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> does not asymptotically grow with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> <img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})" class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})" /> can be efficiently computed in <img src="https://s0.wp.com/latex.php?latex=O%28m%5E2%2Bmn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(m^2+mn)" class="latex" title="O(m^2+mn)" /></p>
<h2>Application: MaxCut</h2>
<p>In this section we apply the QAOA algorithm to the MaxCut problem with bounded degree. MaxCut is an NP-hard problem that asks for a subset <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> of the vertex set such that the number of edges between <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> and the complementary subset is as large as possible. While QAOA does not offer a theoretical guarantee to solve MaxCut in polynomial time, it offers a path to utilizing NISQ devices for tackling such optimization problems and discuss patterns in such problems that can be used for reducing the number of steps required.</p>
<p>For this section, let’s assume <img src="https://s0.wp.com/latex.php?latex=p%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p=O(1)" class="latex" title="p=O(1)" />, and we have a graph with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vertices and an edge set <img src="https://s0.wp.com/latex.php?latex=%5C%7B%3Cjk%3E%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{&lt;jk&gt;\}" class="latex" title="\{&lt;jk&gt;\}" /> of size <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />. We can construct a cost function to be maximized as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C+%3D+%5Csum_%7B%3Cjk%3E%7D+C_%7B%3Cjk%3E%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " class="latex" title="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%281-%5Csigma%5Ez_j+%5Csigma%5Ez_k%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " class="latex" title="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " /></p>
<p>We can the compute the angle dependent cost of our ansatz as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_%7B%3Cjk%3E%7D%5Cleft+%3C%7Bs%7D+%5Cright+%7C+U%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " /></p>
<p>Let’s consider the operation associated with some edge <img src="https://s0.wp.com/latex.php?latex=%3Cjk%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="&lt;jk&gt;" class="latex" title="&lt;jk&gt;" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U+%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " class="latex" title="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " /></p>
<p>Since QAOA consists of local operations, we may take advantage by thinking about the problem in terms of subproblems (or subgraphs) involving certain nodes. This property will allow us to simplify our clauses even further depending on the desired depth <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> of our quantum circuit, therefore decreasing the amount of resources necessary to implement the algorithm.</p>
<p>The operator <img src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{&lt;jk&gt;}" class="latex" title="C_{&lt;jk&gt;}" /> includes qubits (nodes) <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />, therefore the sequence of operators above will only involve qubits that are at most distance <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> away from qubits <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. Let’s consider the example of <img src="https://s0.wp.com/latex.php?latex=p%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p=1" class="latex" title="p=1" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crightarrow+U%5E%5Cdagger%28C%2C%5Cgamma_1%29e%5E%7Bi%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+C_%7B%3Cjk%3E%7D+e%5E%7B-i%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+U%28C%2C%5Cgamma_1%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " class="latex" title="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " /></p>
<p>It’s easy to see that any factor of <img src="https://s0.wp.com/latex.php?latex=U%28C%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(C,\gamma_1)" class="latex" title="U(C,\gamma_1)" /> that does not depend on <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> or <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> will commute through and cancel out. Since the degree is bounded, each subgraph contains a number of qubits that is independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, which allows for the evaluation of <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> in terms of subsystems of size independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />.</p>
<p>For an subgraph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> define:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C_G%3D%5Csum_%7B%3Cl+l%5E%5Cprime%3E%7D+C_%7B%3Cl+l%5E%5Cprime%3E%7D%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28C_G%2C%5Cgamma%29%3De%5E%7B-i+%5Cgamma+C_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}  \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " class="latex" title="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}  \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=B_G+%3D+%5Csum_%7Bj+%5Cin+G%7D+%5Csigma%5Ex_j%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28B_G%2C%5Cbeta%29+%3D+e%5E%7B-i+%5Cbeta+B_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B_G = \sum_{j \in G} \sigma^x_j  \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " class="latex" title="B_G = \sum_{j \in G} \sigma^x_j  \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+s%2CG+%5Cright+%3E+%C2%A0%C2%A0%3D+%5Cprod_%7Bl+%5Cin+G%7D+%5Cleft+%7C%2B+%5Cright+%3E+_l++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | s,G \right &gt;   = \prod_{l \in G} \left |+ \right &gt; _l  " class="latex" title="\left | s,G \right &gt;   = \prod_{l \in G} \left |+ \right &gt; _l  " /></p>
<p>We can define our total cost as a sum over the cost of each subgraph:</p>
<p><img src="https://s0.wp.com/latex.php?latex=f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Cleft+%3C+s%2Cg%28j%2Ck%29+%5Cright+%7C%C2%A0+U+%5E%5Cdagger%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29...U%5E%5Cdagger%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+...+U%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs%2Cg%28j%2Ck%29+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |  U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " class="latex" title="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |  U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=g%28j%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g(j,k)" class="latex" title="g(j,k)" /> is a subgraph of type <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> and “…” is used to omit the sequence of angle depending unitaries constructed using the elements of <img src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Vec{\gamma}" class="latex" title="\Vec{\gamma}" /> and <img src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Vec{\beta}" class="latex" title="\Vec{\beta}" />. <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> is then</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_g+w_g+f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_g" class="latex" title="w_g" /> is the number of occurrence of the subgraph <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> in the original edge sum. The function <img src="https://s0.wp.com/latex.php?latex=f_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_g" class="latex" title="f_g" /> does not depend on <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />, and the only dependence on these variables comes through the weights <img src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_g" class="latex" title="w_g" /> from the original graph. The maximum number of qubits that can appear in our sequence of operators comes when the subgraph is a tree. For a graph with maximum degree <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" />, the number of qubits in this tree is</p>
<p><img src="https://s0.wp.com/latex.php?latex=q_%7Btree%7D%3D2%5B%5Cfrac%7B%28v-1%29%5E%7Bp%2B1%7D-1%7D%7B%28v-1%29-1%7D%5D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " class="latex" title="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " /></p>
<p>(or <img src="https://s0.wp.com/latex.php?latex=2p%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2p+2" class="latex" title="2p+2" /> if <img src="https://s0.wp.com/latex.php?latex=v%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v=2" class="latex" title="v=2" />), which is independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />. Therefore we can see that for constant <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> can be efficiently computed.</p>
<p>Next, let’s consider the spread of C measured in the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " />.</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%3C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C%5E2%5Cleft+%7C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%5Cright+%3E+%C2%A0-%5Cleft+%3C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C+%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%5E2+%5Cleq+2%5B%5Cfrac%7B%28v-1%29%5E%7B2p%2B2%7D-1%7D%7B%28v-1%29-1%7D%5D.m++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt;  -\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " class="latex" title="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt;  -\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " /></p>
<p>For fixed <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" /> and <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> we see that the standard deviation of <img src="https://s0.wp.com/latex.php?latex=C%28z%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(z)" class="latex" title="C(z)" /> is upper-bounded by <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{m})" class="latex" title="O(\sqrt{m})" />. Using this fact and the appropriate probability bounds we can see that the result of measuring the cost function of the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2Cvec%7B%5Cbeta_%7Bopt%7D%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt;  " class="latex" title="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt;  " /> will be very close to the intended value of <img src="https://s0.wp.com/latex.php?latex=F_p%28%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2C%5Cvec%7B%5Cbeta_%7Bopt%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" class="latex" title="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" /> which bounds the uncertainty present in quantum measurement.</p>
<h2>Bibliography</h2>
<p>[1] E. Farhi, J. Goldstone, and S. Gutmann, “A Quantum Approximate Optimization Algorithm,” 2014.</p>
<p>[2] J. S. Otterbach, et. al, “Unsupervised Machine Learning on a Hybrid Quantum Computer,” 2017.</p></div>







<p class="date">
by karamlou <a href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/"><span class="datestr">at December 22, 2018 11:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html">Circles crossing at equal angles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Let , , , and  be four circles, with pairs , , , and  crossing at equal angles (and no crossings among the other two pairs). Then it turns out that the two curvy quadrilaterals forming the inside and outside boundaries of the union of disks each have a circle through their four vertices:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-45.svg" alt="Four circles crossing at equal angles, and the two circles through their crossing points" /></p>

<p>The proof of the theorem is not difficult, once you notice that it’s invariant under Möbius transformations: the four given circles and their crossing angles transform to another four circles with the same crossing angles, preserving any cocircularities among the eight crossing points.
So start by finding a Möbius transformation that makes two opposite circles  and  become the same size as each other. Because of the equality of crossing angles, both of the other two circles must have centers on the perpendicular bisector to line . There’s still a one-dimensional family of Möbius transformations remaining that preserves the position of  and  but moves the other circles along this bisector; use this remaining degree of freedom to move the other two circles so that their centers are equidistant from line . Then, because of the equality of crossing angles, circles  and  must have the same radii. So we have transformed the input to a position where the circles are centered at the vertices of a rhombus with opposite pairs having the same radius. By symmetry, the crossing points must lie on two rectangles, and the four corners of each rectangle are cocircular.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-rect.svg" alt="Four circles crossing at equal angles at the corners of a rhombus, and the two rectangles through their crossing points" /></p>

<p>This can be extended to some configurations of circles where the opposite pairs cross each other rather than staying disjoint, but you have to be more careful about what happens when more than two circles cross at one point, and about determining which of the two supplementary angles at each crossing to use as the crossing angle of the two circles. If you’re not careful, you get situations like the one below  where two degenerate circles (the coordinate axes) are crossed at equal angles by two more circles, but where the eight crossings do not form another two circles.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-bad.svg" alt="Two degenerate circles (the coordinate axes) and two circles that cross them at equal angles, without forming two more sets of four cocircular points" /></p>

<p>Maybe the easiest way to state the more general result is that if a non-self-crossing quadrilateral with circular-arc sides has four equal interior angles at its vertices, then it is <a href="https://en.wikipedia.org/wiki/Cyclic_quadrilateral">cyclic</a>.
I used a special case of this, for right-angled quadrilaterals, in my paper “A Möbius-invariant power diagram and its applications to soap bubbles and planar Lombardi drawing” (<a href="https://doi.org/10.1007/s00454-014-9627-0"><em>Discrete Comput. Geom.</em> 2014</a>).
This formulation also works for the special case when all four angles are zero, which was used in a mesh generation algorithm by Bern, Mitchell, and Ruppert (“Linear-size nonobtuse triangulation of polygons”, <a href="https://doi.org/10.1007/BF02570715"><em>Discrete Comput. Geom.</em> 1995</a>).</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-cusp.svg" alt="A chain of four tangent circles and a fifth circle through their four points of tangency" /></p>

<p>I don’t know whether this theorem has appeared previously, but it’s obviously related to <a href="https://11011110.github.io/blog/2006/03/22/miquels-six-circles.html">Miquel’s six-circle theorem</a>, which takes five circles (without assumption about angles) and produces a sixth in a configuration closely resembling what you get from the four given circles and two produced circles of this theorem.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101287137001551762"></a>, <a href="https://plus.google.com/100003628603413742554/posts/9p3Hza4hGE1">G+</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html"><span class="datestr">at December 22, 2018 02:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15529">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/">Explanations and Explorations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Comparing proofs for the Jaccard metric</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg?w=142&amp;h=158" alt="" width="142" class="alignright wp-image-15530" height="158" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">BetterExplained <a href="https://betterexplained.com/about/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Kalid Azad is the founder of the <a href="https://betterexplained.com/">website</a> <em>Better Explained</em>. It is devoted to explaining mathematical concepts. He also has written <a href="https://betterexplained.com/ebook/math/">two</a> <a href="https://www.amazon.com/gp/product/B017ZXWY3U/">books</a>. </p>
<p>
Today we discuss how some proofs provide a concise <em>explanation</em> whereas others promote <em>exploration</em> of related concepts.<br />
<span id="more-15529"></span></p>
<p>
Azad’s site has a rich <a href="https://betterexplained.com/articles/proofs-vs-explanations/">page</a> titled, “Math Proofs vs. Explanations (aka Nutrition vs. Taste).” It argues that the best <em>explanations</em> start with an analogy to a relation that readers already understand. Even if the connection is not sharp, it can be refined once the reader’s attention is solid. This is opposed to a formal proof in which every step is sharp and correct but intuition is wanting.</p>
<p>
To this we add the role proofs can play in <em>exploration</em>. If you have one proof of a theorem that you understand, there is value in seeking other proofs that use other ideas. Usually we think of ideas as coming first—as thoughts we refine into a proof. The advantage of starting with a proof is already having certitude and sharpness—you know a recipe that works and now can try varying and augmenting it. </p>
<p>
</p><p></p><h2> Jaccard Distance as Example </h2><p></p>
<p></p><p>
Azad’s page gives examples of proofs for the Pythagorean Theorem and for <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%7D+%3D+%5Ccos%28%5Ctheta%29+%2B+i%5Csin%28%5Ctheta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" class="latex" title="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" />. It then quotes from William Thurston’s <a href="http://arxiv.org/abs/math/9404236">essay</a> “On Proofs and Progress in Mathematics,” which we once <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">mentioned</a>. We will use the example of Jaccard distance <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta}" class="latex" title="{J_\delta}" /> from our previous <a href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/">post</a>. We start with this definition: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CB%29+%3D+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " class="latex" title="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " /></p>
<p>now using <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> for the symmetric difference <img src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Ccup+B%29+%5Csetminus+%28A+%5Ccap+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A \cup B) \setminus (A \cap B)}" class="latex" title="{(A \cup B) \setminus (A \cap B)}" />. So the triangle inequality becomes, for any finite sets <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" />: <a name="triangle"></a></p><a name="triangle">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cleq+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" class="latex" title="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" /></p>
</a><p><a name="triangle"></a> We think the proof we gave in the last post is simple and direct and intuitive but maybe not explorative. It first connects the solid understanding that without the denominators this would be the well-known triangle inequality for Hamming distance. To reprise, it considers <img src="https://s0.wp.com/latex.php?latex=%7BA%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,C}" class="latex" title="{A,C}" /> fixed and varies <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> to arrive at that simpler fact in three steps:</p>
<ol>
<li>
If <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> contains <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> elements not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> then removing them subtracts <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> from both right-hand numerators and both right-hand denominators. Since those fractions are each <img src="https://s0.wp.com/latex.php?latex=%7B%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt; 1}" class="latex" title="{&lt; 1}" /> (else <a href="https://rjlipton.wordpress.com/feed/#triangle">1</a> would be immediately true), the right-hand side goes down. <p></p>
</li><li>
Then we have <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> and can replace the denominators by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> without increasing the right-hand side. <p></p>
</li><li>
Now we have a common denominator and a statement equivalent to the known truth about Hamming distance. Since undoing the first two steps to restore the original <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> can only increase the right-hand side, (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is proved in all cases.
</li></ol>
<p>
This reasoning readily extends to nonnegative measures <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> on <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" /> besides simple counting, provided the removal of elements from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> makes the same additive-or-proportional change to <img src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5C%3B%5CDelta%5C%3B+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(A \;\Delta\; B)}" class="latex" title="{f(A \;\Delta\; B)}" /> as it does to <img src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5Ccup+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(A \cup B)}" class="latex" title="{f(A \cup B)}" />, and likewise for the other fraction. </p>
<p>
</p><p></p><h2> Three Snapshot Proofs </h2><p></p>
<p></p><p>
The first short proof should join the pantheon of half-page journal papers. Under fair use, here it is in one screenshot:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png"><img src="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png?w=295&amp;h=410" alt="" width="295" class="aligncenter wp-image-15547" height="410" /></a></p>
<p>
Perhaps this is <i>too</i> short. We think this proof would have been more satisfying if a few more lines of calculation had been added. Let us divide the region <img src="https://s0.wp.com/latex.php?latex=%7BT_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_1}" class="latex" title="{T_1}" /> into its inner part <img src="https://s0.wp.com/latex.php?latex=%7BT_%7B1i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{1i}}" class="latex" title="{T_{1i}}" /> and outer part <img src="https://s0.wp.com/latex.php?latex=%7BT_%7B1o%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{1o}}" class="latex" title="{T_{1o}}" /> and do likewise for <img src="https://s0.wp.com/latex.php?latex=%7BT_2%2CT_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_2,T_3}" class="latex" title="{T_2,T_3}" />. Then it seems the intent was: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++d%28S_1%2CS_3%29+%26%3D%26+1+-+%5Cfrac%7B%7CS_1+%5Ccap+S_3%7C%7D%7B%7CS_1+%5Ccup+S_3%7C%7D++%3D+1+-+%5Cfrac%7B%7CT_%7B2i%7D%7C+%2B+%7CV%7C%7D%7B%7CU%7C+-+%7CT_%7B2o%7D%7C%7D%5C%5C+%26%5Cleq%26+1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CU%7C+-+%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C+-+%7CT_%7B3o%7D%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C+-+%7CT_%7B1o%7D%7C%7D+%3D+d%28S_1%2CS_2%29+%2B+d%28S_2%2CS_3%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " /></p>
<p>The end uses the symmetric-difference definition of <img src="https://s0.wp.com/latex.php?latex=%7BJ_%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_{\delta}}" class="latex" title="{J_{\delta}}" />, so perhaps fully expanding this paper’s intent would have been longer. One can also begin with that definition to get a shorter calculation, but it skips over the <img src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 - \frac{|V|}{|U|}}" class="latex" title="{1 - \frac{|V|}{|U|}}" /> step. Indeed, it does not mention <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> at all, so it was not intended. The proof by Artur Grygorian and Ionut Iacob in a short <a href="https://www.tandfonline.com/doi/abs/10.1080/07468342.2018.1526020">paper</a> in last October’s <em>College J. Math.</em> strikes us as a similar-style proof. </p>
<p>
The second proof comes from a MathOverflow <a href="https://mathoverflow.net/q/315845">thread</a>. It assigns a variable to each region of the Venn diagram, forms the fractions, and cross-multiplies to obtain “the following monstrosity”:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg?w=400&amp;h=232" alt="" width="400" class="aligncenter wp-image-15532" height="232" /></a></p>
<p>
The fact that no coefficient is negative completes the proof. This is clear from a computer algebra system, but what about <em>why</em> no negative term appears? </p>
<p>
We have realized since the last post that the second of two proofs given in the 2016 <a href="https://arxiv.org/pdf/1612.02696.pdf">paper</a> by Sven Kosub, which we linked in that post, is really equivalent to ours. This is easier to see if one just presumes <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(\emptyset) = 0}" class="latex" title="{f(\emptyset) = 0}" /> in the following:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png"><img src="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png?w=500&amp;h=360" alt="" width="500" class="aligncenter wp-image-15533" height="360" /></a></p>
<p>
Here <em>sub-modularity</em> is a standard property for which Kosub cites the equivalent condition that whenever <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq D}" class="latex" title="{B \subseteq D}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cnotin+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \notin D}" class="latex" title="{x \notin D}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28B+%5Ccup%5C%7Bx%5C%7D%29+-+f%28B%29+%5Cgeq+f%28D+%5Ccup+%5C%7Bx%5C%7D%29+-+f%28D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " class="latex" title="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " /></p>
<p>This suffices for step 1 of our earlier proof, first taking <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+A+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = A \cup B}" class="latex" title="{D = A \cup B}" /> then <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+B+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = B \cup C}" class="latex" title="{D = B \cup C}" />; the rest of that proof needs only that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is monotone (and implicitly <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(\emptyset) = 0}" class="latex" title="{f(\emptyset) = 0}" />). </p>
<p>
</p><p></p><h2> A Magical Proof </h2><p></p>
<p></p><p>
Now we look at proofs that add ideas. The first one still strikes us as clean and magical. We are computer scientists so it is natural to think of finite sets as binary-valued vectors of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. They have a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in position <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> precisely when <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> is in the set. Of course <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the size of the “universe.” </p>
<p>
Now let <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> be such a non-zero vector. The key is to use a probabilistic proof. We will show that we can relate the Jaccard distance to the outcome of a simple random experiment. The experiment once selected leads to a simple proof—it only requires the union bound. Recall this is the fact that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%5BE_%7B1%7D+%5Cvee+E_%7B2%7D%5D+%5Cle+P%5BE_%7B1%7D%5D+%2BP%5BE_%7B2%7D%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " class="latex" title="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " /></p>
<p>for any two events <img src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{1}}" class="latex" title="{E_{1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BE_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{2}}" class="latex" title="{E_{2}}" />. </p>
<p>
The cool idea is to look at the permutations of the vector <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. For a permutation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" /> let us define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(X)}" class="latex" title="{\pi(X)}" /> to be 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_%7B%5Cpi%281%29%7D%2C%5Ccdots%2Cx_%7B%5Cpi%28n%29%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " class="latex" title="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28X%29%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(X)=i}" class="latex" title="{\mathsf{first}(X)=i}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i}}" class="latex" title="{x_{i}}" /> is the first value that is equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Of course since <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is non-empty it follows that this is well defined. </p>
<p>
Note <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X))}" class="latex" title="{\mathsf{first}(\pi(X))}" /> is a random variable that depends on the choice of the permutation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" />. The key is to see that the probability that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%3D%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" class="latex" title="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" /> when we average over all permutations uniformly is equal to 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CX+%5Ccap+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " class="latex" title="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " /></p>
<p>This follows by noting that there are <img src="https://s0.wp.com/latex.php?latex=%7B%7CXY%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|XY|}" class="latex" title="{|XY|}" /> ways to select the same <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and there are <img src="https://s0.wp.com/latex.php?latex=%7B%7CX+%5Ccup+Y%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|X \cup Y|}" class="latex" title="{|X \cup Y|}" /> total ways to select an <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. Complementing gives us that the probability of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" class="latex" title="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta(X,Y)}" class="latex" title="{J_\delta(X,Y)}" />.</p>
<p>
Now hark back to our sets <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" />. The event </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " class="latex" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " /></p>
<p>is subsumed by the disjunction of events </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cvee+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " class="latex" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " /></p>
<p>regardless of what <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is. By the simple union bound, the probability of the first event is at most the sum of the probabilities of the latter two events. We have thus proved </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CC%29+%5Cleq+J_%5Cdelta%28A%2CB%29+%2B+J_%5Cdelta%28B%2CC%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " class="latex" title="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " /></p>
<p>
The last step is the same as in the proof that Hamming distance is a metric. What does the randomized view gain us? It gains a nice interpretation of <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta(A,B)}" class="latex" title="{J_\delta(A,B)}" /> as the probability that <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> hash to different values under the <em>min-hash</em> function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%5Ccirc%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}\circ\pi}" class="latex" title="{\mathsf{first}\circ\pi}" /> for random <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" />. Min-hashing is used all the time—see this <a href="http://infolab.stanford.edu/~ullman/mmds/ch3.pdf">book chapter</a> by Jure Leskovec, Anand Rajaraman, and Jeffrey Ullman, with this proof in section 3.3.3. 		 </p>
<p></p><h2> A Gradient Idea </h2><p></p>
<p></p><p>
Atri Rudra suggested to us the “game” of adjusting <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> one element at a time to walk it toward an extreme value. The sets <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> can be adjusted too. We start by assuming the triangle inequality (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is false and make moves that can only keep it that way, until we reach a case where it is obviously true. </p>
<p>
Step 1 of our proof already plays this game by removing from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> any elements not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. So we really start the game with <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> and we want to walk it to <img src="https://s0.wp.com/latex.php?latex=%7BB+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B = A \cup C}" class="latex" title="{B = A \cup C}" />. Simply replacing the denominators <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup B|}" class="latex" title="{|A \cup B|}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \cup C|}" class="latex" title="{|B \cup C|}" /> in (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> was good in step 2 of the proof but is not a legal move in this game. </p>
<p>
What we can do legally is add elements from <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cap C}" class="latex" title="{A \cap C}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />: those leave the denominators unchanged but lower the numerators <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \;\Delta\; B|}" class="latex" title="{|A \;\Delta\; B|}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \;\Delta\; C|}" class="latex" title="{|B \;\Delta\; C|}" />. The interesting case is when we want to add to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> an element from <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Csetminus+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \setminus C}" class="latex" title="{A \setminus C}" /> or from <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Csetminus+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \setminus A}" class="latex" title="{C \setminus A}" />. The former add decreases the numerator <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \;\Delta\; B|}" class="latex" title="{|A \;\Delta\; B|}" /> and increases the denominator <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \cup C|}" class="latex" title="{|B \cup C|}" /> while leaving <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup B}" class="latex" title="{A \cup B}" /> unchanged, but it <em>increases</em> the numerator <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \;\Delta\; C|}" class="latex" title="{|B \;\Delta\; C|}" />. Let us abstract the right-hand side of (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{q} + \frac{r}{s}}" class="latex" title="{\frac{p}{q} + \frac{r}{s}}" />. Then the former add converts it to </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+%5Cqquad%5Ctext%7Band+the+latter+add+to%7D%5Cqquad+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " class="latex" title="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " /></p>
<p>If <em>both</em> moves increase the right-hand side, then we must have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D%2C+%5Cquad%5Ctext%7Bso%7D%5Cquad+%5Cfrac%7B1%7D%7Bq%7D+%3C+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+-+%5Cfrac%7Br%7D%7Bs%7D+%3D+%5Cfrac%7Bs-r%7D%7Bs%28s%2B1%29%7D+%3C+%5Cfrac%7B1%7D%7Bs%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " class="latex" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " /></p>
<p>And from </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D%2C+%5Cquad%5Ctext%7Bwe+get%7D%5Cquad+%5Cfrac%7B1%7D%7Bs%7D+%3C+%5Cfrac%7B1%7D%7Bq%2B1%7D%5C%3B.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " class="latex" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " /></p>
<p>But cross-multiplying gives the contradiction <img src="https://s0.wp.com/latex.php?latex=%7Bq%2B+1+%3C+s+%3C+s%2B1+%3C+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q+ 1 &lt; s &lt; s+1 &lt; q}" class="latex" title="{q+ 1 &lt; s &lt; s+1 &lt; q}" />. So one or both moves must always be possible. This grows <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> to include either all of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> or all of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The rest of the argument to gobble up all of <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> we leave to you, dear readers.</p>
<p>
Compared to the above proofs, this is tedious. But it captures some tensions among the sizes of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> that may inform intuitions about Jaccard similarity under changes in the sets. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Which proof do you like best for explanation and which for creative impulse? </p>
<p>
This is our <img src="https://s0.wp.com/latex.php?latex=%7B801%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{801^{st}}" class="latex" title="{801^{st}}" /> post. We intended this discussion as number 800 but were surprised to find the simple proof by reduction to triangle for Hamming distance (steps numbered 1-2-3 above). Are we really the first to write it down, with acknowledgment also to Kosub?</p>
<p>
[some typo fixes]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/"><span class="datestr">at December 22, 2018 01:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6524">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">Tensor Networks, Matrix Product States and Density Matrix Renormalization Group</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>by Fred Zhang</strong></p>
<p><em>This is the second installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given by the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. For the basic definitions of local Hamiltonians, see <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">Ben’s first post</a>. Also check out <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">Boriana and Prayaag’s followup note</a> on area laws.</em></p>
<p>This post introduces tensor networks and matrix product states (MPS). These are useful linear-algebraic objects for describing quantum states of low entanglement.</p>
<p>We then discuss how to efficiently compute the ground states of the Hamiltonians of <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{1}" class="latex" title="{1}" />D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.</p>
<p><b>1. Introduction </b></p>
<p class="p1">We are interested in computing the ground state—the minimum eigenvector—of a quantum Hamiltonian, a <img src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n \times 2^n" class="latex" title="2^n \times 2^n" /> complex matrix that governs the evolution of a quantum system of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits. We restrict our attention to the local Hamiltonian, where the matrix is a sum of Hamiltonians each acting only on <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> qubits.  In the previous article, we discussed some hardness results. Namely, a local Hamiltonian can be used to encode SAT instances, and we further gave a proof that computing the ground state is QMA-Complete.</p>
<p>Despite the hardness results, physicists have come up with a variety of heuristics for solving this problem. If quantum interactions occur locally, we would hope that its ground state has low entanglement and thus admits a succinct classical representation. Further, we hope to find such a representation efficiently, using classical computers.</p>
<p>In this note, we will see <i>tensor networks</i> and <i>matrix product states</i> that formalize the idea of succinctly representing quantum states of low entanglement. As a side remark for the theoretical computer scientists here, one motivation to study tensor network is that it provides a powerful visual tool for thinking about linear algebra. It turns indices into edges in a graph and summations over indices into contractions of edges. In particular, we will soon see that the most useful inequality in TCS and mathematics can be drawn as a cute tensor network.</p>
<p></p><div style="width: 276px;" class="wp-caption aligncenter" id="attachment_6535"><a href="https://windowsontheory.files.wordpress.com/2018/12/note0x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600" alt="" class="wp-image-6535 size-full" /></a><p class="wp-caption-text">Guess what this is?</p></div><p></p>
<p>In the end, we will discuss the density matrix renormalization group (DMRG), which has established itself as “the most powerful tool for treating 1D quantum systems” over the last decade [<a href="https://windowsontheory.org/feed/#Xfehske2007computational">FSW07</a>]. For many 1D systems that arise from practice, the heuristic efficiently finds an (approximate) ground state in its matrix product state, specified only by a small number of parameters.</p>
<p><b>2. Tensor Networks </b></p>
<p>Now let us discuss our first subject, <i>tensor networks</i>. If you have not seen <i>tensors</i> before, it is a generalization of matrices. In computer scientists’ language, a matrix is a two-dimensional array, and a tensor is a multi-dimensional array. In other words, if we think of a matrix as a square, then a 3 dimensional tensor looks like a cube. Formally, a (complex) n dimensional tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{T}" class="latex" title="{T}" /> maps <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> indices to complex values, namely, to its entries:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T+%3A+%5Bd_1%5D+%5Ctimes+%5Bd_2%5D+%5Ctimes+%5Ccdots+%5Ctimes+%5Bd_n%5D+%5Crightarrow+%5Cmathbb%7BC%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." class="latex" title="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." /></p>
<p>The simplest tensor network is a graphical notation for a tensor. For an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{n}" class="latex" title="{n}" />-dimensional tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, we draw a star graph and label the center as <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> and the edges as the indices. To evaluate this tensor network, we put values on the edges, <i>i.e.</i>, indices, and then the tensor network would spit out its entry specified by the indices.</p>
<p></p><div style="width: 170px;" class="wp-caption aligncenter" id="attachment_6550"><a href="https://windowsontheory.files.wordpress.com/2018/12/note2x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note2x.png?w=600" alt="" class="wp-image-6550 size-full" /></a><p class="wp-caption-text">A simple tensor network of 4 dimensions <a name="figsimp-1"></a></p></div><p></p>
<p></p><div style="width: 354px;" class="wp-caption aligncenter" id="attachment_6551"><a href="https://windowsontheory.files.wordpress.com/2018/12/note3x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note3x.png?w=600" alt="" class="wp-image-6551 size-full" /></a><p class="wp-caption-text">Evaluating a simple tensor network, <img src="https://s0.wp.com/latex.php?latex=%7BT%281%2C5%2C3%2C1%29%3D1%2F%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(1,5,3,1)=1/\sqrt{2}}" class="latex" title="{T(1,5,3,1)=1/\sqrt{2}}" />. The numbers are chosen arbitrarily.<a name="figsimp-2"></a></p></div><p></p>
<p>Notice that the degree of the center is the number of indices. Hence, a tensor network of degree <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> is a vector, and that of degree <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> is a matrix, and so forth.<a name="figsimple-tn"></a></p>
<p></p><div style="width: 34px;" class="wp-caption aligncenter" id="attachment_6574"><a href="https://windowsontheory.files.wordpress.com/2018/12/note6x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note6x.png?w=600" alt="" class="wp-image-6574 size-full" /></a><p class="wp-caption-text">A vector</p></div><p></p>
<p></p><div style="width: 106px;" class="wp-caption aligncenter" id="attachment_6575"><a href="https://windowsontheory.files.wordpress.com/2018/12/note7x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note7x.png?w=600" alt="" class="wp-image-6575 size-full" /></a><p class="wp-caption-text">A matrix</p></div><p></p>
<p></p><div style="width: 158px;" class="wp-caption aligncenter" id="attachment_6576"><a href="https://windowsontheory.files.wordpress.com/2018/12/note8x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note8x.png?w=600" alt="" class="wp-image-6576 size-full" /></a><p class="wp-caption-text">A 3d tensor</p></div><p></p>
<p>How is this related to quantum information? For the sake of genearlity we will deal with qudits in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb{C}^d}" class="latex" title="{\mathbb{C}^d}" />, instead of qubits in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb{C}^2}" class="latex" title="{\mathbb{C}^2}" />. Now recall that a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi_n%5Crangle%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{|\psi_n\rangle}" class="latex" title="{|\psi_n\rangle}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{n}" class="latex" title="{n}" /> qudits can be encoded as an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> dimensional tensor. It can be written as</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_n%5Crangle+%3D+%5Cdisplaystyle%5Csum_%7Bi_1%2C%5Ccdots%2Ci_n+%3D+0%7D%5E%7Bd-1%7D+T%28i_1%2C%5Ccdots%2C+i_n%29+%7Ci_1%2C%5Ccdots%2C+i_n+%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." class="latex" title="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." /></p>
<p>It is easy to see that all the information, namely, the amplitudes, is just the tensor <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. In the later sections, we will see more powerful examples of using tensor networks to represent a quantum state.</p>
<p>So far our discussion is focused merely on these little pictures. The power of tensor networks come from its composition rules, which allow us to join two simple tensor networks together and impose rich internal structures.</p>
<p><b> 2.1. Composition Rules </b></p>
<p>We introduce two ways of joining two simple tensor networks. Roughly speaking, they correspond to multiplication and summation, and I will give the definitions by showing examples, instead of stating them in the full formalism</p>
<p><strong>Rule #1: Tensor Product.</strong> The product rule allows us to put two tensor networks together and view them as a whole. The resulting tensor is the tensor product of the two if we think of them as vectors. More concretely, consider the following picture.</p>
<p></p><div style="width: 364px;" class="wp-caption aligncenter" id="attachment_6564"><a href="https://windowsontheory.files.wordpress.com/2018/12/note10x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note10x.png?w=600" alt="" class="wp-image-6564 size-full" /></a><p class="wp-caption-text">This is viewed as a single tensor network <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> of 7 edges<span> </span>.<a name="figtp"></a></p></div><p></p>
<p>The definition of this joint tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{T}" class="latex" title="{T}" /> is</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=T%28i_1%2Ci_2%2C%5Ccdots%2C+i_7%29+%3D+T_1%28i_1%2Ci_2%2Ci_3%2Ci_4%29+T_2%28i_5%2Ci_6%2Ci_7%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." class="latex" title="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." /></p>
<p><strong>Rule #2: Edge Contractions</strong>. At this moment, we can only make up disconnected tensor networks. Edge contractions allow us to link two tensor networks. Suppose we have two <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" /> dimensional tensor networks. Contracting two edges, one from each, gives us a tensor network of <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> <i>free edges</i>. This now corresponds a tensor of <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> dimensions.</p>
<p></p><div style="width: 310px;" class="wp-caption aligncenter" id="attachment_6579"><a href="https://windowsontheory.files.wordpress.com/2018/12/note12x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note12x.png?w=300&amp;h=116" alt="" width="300" class="size-medium wp-image-6579" height="116" /></a><p class="wp-caption-text">Two 3d tensors</p></div><p></p>
<p></p><div style="width: 310px;" class="wp-caption aligncenter" id="attachment_6563"><a href="https://windowsontheory.files.wordpress.com/2018/12/note13x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note13x.png?w=300&amp;h=116" alt="" width="300" class="size-medium wp-image-6563" height="116" /></a><p class="wp-caption-text">Join two tensor networks by contracting an edge</p></div><p></p>
<p>We name the contracted edge as <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. The definition of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T%28i_1%2Ci_2%2Cj_1%2Cj_2%29+%3D%5Csum_k+T_1%28i_1%2Ci_2%2C+k%29+T_2%28j_1%2Cj_2%2C+k%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." class="latex" title="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." /></p>
<p><b> 2.2. Useful Examples </b></p>
<p>Before we move on, let’s take some examples. Keep in mind that the degree of the vertex determines the number of indices (dimensions of this tensor).</p>
<p></p><div style="width: 127px;" class="wp-caption aligncenter" id="attachment_6584"><img src="https://windowsontheory.files.wordpress.com/2018/12/note15x.png?w=600" alt="note15x" class="alignnone size-full wp-image-6584" /><p class="wp-caption-text">vector inner product <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle u,v \rangle}" class="latex" title="{\langle u,v \rangle}" /></p></div><p></p>
<p></p><div style="width: 178px;" class="wp-caption aligncenter" id="attachment_6585"><img src="https://windowsontheory.files.wordpress.com/2018/12/note16x.png?w=600" alt="note16x" class="alignnone size-full wp-image-6585" /><p class="wp-caption-text">Matrix inner product</p></div><p></p>
<p>Here, one needs to remember that an edge between two tensor nodes is a summation over the index corresponding to the edge. For example, in the vector inner product picture, <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv%5Crangle+%3D+%5Csum_i+u_i+%5Ccdot+v_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" class="latex" title="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" />, where edge is labeled as <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. Now you would realize that this picture</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600" alt="" class="wp-image-6535 size-full aligncenter" /></p>
<p>is the famous</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Clangle+u%2Cv+%5Crangle%5E2+%5Cleq+%5C%7Cu%5C%7C%5E2+%5C%7Cv%5C%7C%5E2.+%5Cquad%5Cquad+%28%5Ctext%7BCauchy-Schwarz+inequality%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " class="latex" title="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " /></p>
<p>For us, the most important building block is matrix multiplication. Let <img src="https://s0.wp.com/latex.php?latex=%7BH%3DMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H=MN}" class="latex" title="{H=MN}" />. By definition</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=H%28i%2Cj%29+%3D+%5Csum_k+M%28i%2Ck%29+N%28k%2C+j%29.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(i,j) = \sum_k M(i,k) N(k, j). " class="latex" title="H(i,j) = \sum_k M(i,k) N(k, j). " /></p>
<p>This is precisely encoded in the picture below.</p>
<p></p><div style="width: 276px;" class="wp-caption aligncenter" id="attachment_6587"><img src="https://windowsontheory.files.wordpress.com/2018/12/note20x.png?w=600" alt="note20x.png" class="alignnone size-full wp-image-6587" /><p class="wp-caption-text">Matrix multiplication, <img src="https://s0.wp.com/latex.php?latex=%7BMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{MN}" class="latex" title="{MN}" />.<span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span><a style="color: #3d596d; font-size: 16px;" name="figmat-mul"></a><span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span></p></div><p></p>
<p>We are ready to talk about matrix product states. In the language of tensor network, a matrix product state is the following picture.</p>
<p></p><div style="width: 590px;" class="wp-caption aligncenter" id="attachment_6588"><img src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600" alt="note21x" class="alignnone size-full wp-image-6588" /><p class="wp-caption-text">A matrix product state.</p></div><p></p>
<p>As the degrees indicate, the two boundary vertices <img src="https://s0.wp.com/latex.php?latex=%7BA_1%2CA_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1,A_n}" class="latex" title="{A_1,A_n}" /> represent matrices and the internal vertices represent <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" />-dimensional tensors. We can view each matrix as a set of (column) vectors and each <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" />-dimensional tensor as a stack of matrices. Then each one of the free edges picks out a vector or a matrix, and the contracted edges multiply them together which gives out a scalar. If this confused you, move on to the next section. I will introduce the formal definition of matrix product states, and you will see that it is just the picture above.</p>
<p><b>3. Matrix Product States </b></p>
<p>Before giving the definition, let’s talk about how matrix product state (MPS) naturally arises from the study of quantum states with low entanglement. Matrix product state can be viewed as a generalization of <i>product state</i>—(pure) quantum state with no entanglement. Let’s consider a simple product state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> qubits. It can be factorized: <a name="eqnmps0"></a></p>
<p align="center"><a name="eqnmps0"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cpsi%5Crangle+%3D+%5Cleft%28%5Csum_%7Bi%3D0%7D%5E1+%5Calpha_1%5Ei%5C+%7Ci%5Crangle+%5Cright%29%5Cleft%28%5Csum_%7Bj%3D0%7D%5E1+%5Calpha_2%5Ej+%5C+%7Cj%5Crangle%5Cright%29%5Cnonumber+%3D+%5Csum_%7Bi%2Cj%3D0%7D%5E1+%5Calpha_1%5Ei+%5Calpha_2%5Ej%5C+%7Cij%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" class="latex" title="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" /></p>
<p><a name="eqnmps0"></a><br />
<a name="eqnmps0"></a> This state is described by <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> complex scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B%5Calpha_1%5E0%2C%5Calpha_1%5E1%2C%5Calpha_2%5E0%2C%5Calpha_2%5E1%5Cright%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" class="latex" title="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" />, and there is nothing quantum about it. However, if the state has entanglement among its qubits, then we know that it is impossible to be factorized and thereby written as (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>). MPS generalizes the form of (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>) by replacing the scalars with matrices and vectors.</p>
<p>More formally, a matrix product state starts with the following setup. For an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qudit system, we associate</p>
<ul>
<li>a qudit in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,n\}}" class="latex" title="{\{1,n\}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> vectors <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_1%5E%7Bj_1%7D%5Cright%5C%7D%2C+%5Cleft%5C%7BA_n%5E%7Bj_n%7D%5Cright%5C%7D+%5Cin+%5Cmathbb%7BR%7D%5ED%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" class="latex" title="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" />; and</li>
<li>a qudit <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B2%2C3%2C%5Ccdots%2C+n-1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{2,3,\cdots, n-1\}}" class="latex" title="{\{2,3,\cdots, n-1\}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> matrices <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D%5Cin+%5Cmathbb%7BR%7D%5E%7BD%5Ctimes+D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" class="latex" title="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" />.</li>
</ul>
<p>Here, <img src="https://s0.wp.com/latex.php?latex=%7Bj_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_i}" class="latex" title="{j_i}" /> range from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d-1}" class="latex" title="{d-1}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is called <i>bond dimension</i>. One can think of the set of vectors as a <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> matrix and the set of matrices as a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> three-dimensional tensor. Then let them correspond to the vertices in MPS picture. With this setup, a quantum state is in matrix product state if it can be written as</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj_1%2C%5Ccdots%2Cj_n%3D1%7D%5En+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D+%7Cj_1+j_2%5Ccdots+j_n%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." class="latex" title="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." /></p>
<p>It is important to keep in mind that <img src="https://s0.wp.com/latex.php?latex=%7BA_1%5E%7Bj_1%7D%2CA_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1^{j_1},A_n^{j_n}}" class="latex" title="{A_1^{j_1},A_n^{j_n}}" /> are two vectors, and the other inner terms are matrices, and we get a scalar from the product. Thus, this represents the tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%28j_1%2Cj_2%2C%5Ccdots%2C+j_n%29+%3D+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" title="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" />.</p>
<p>Now back to the picture,</p>
<p></p><div style="width: 590px;" class="wp-caption aligncenter" id="attachment_6588"><img src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600" alt="note21x" class="alignnone size-full wp-image-6588" /><p class="wp-caption-text">MPS</p></div><p></p>
<p>notice that each amplitude <img src="https://s0.wp.com/latex.php?latex=%7B+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" title="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" /> from the equation above is an output of the tensor in the picture, where the free edges take values <img src="https://s0.wp.com/latex.php?latex=%7Bj_1%2C+j_2+%2C%5Ccdots%2C+j_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_1, j_2 ,\cdots, j_n}" class="latex" title="{j_1, j_2 ,\cdots, j_n}" />. Also, as discussed earlier, the contracted edges in MPS tensor network correspond to matrix and vector multiplications, so the tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is precisely represented by the picture.</p>
<p>The complexity of the MPS is closely related to the bond dimension <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />. In particular, the number of parameters in this model is <img src="https://s0.wp.com/latex.php?latex=%7BO%28ndD%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(ndD^2)}" class="latex" title="{O(ndD^2)}" />. We would expect that with higher <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />, we may describe quantum states of more entanglement. In other words, the representation power of an MPS increases with <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />. In principle, one can represent any quantum state as an MPS; however, <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> can be exponentially large. See, <i>e.g.</i>, Section 4.1.3 of~\cite{schollwock2011density} for a proof. On the other extreme, the product state example shows that if <img src="https://s0.wp.com/latex.php?latex=%7BD%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D=1}" class="latex" title="{D=1}" />, one can represent and <i>only</i> represent unentangled states. To summarize, here is the picture you should keep in mind.</p>
<p></p><div style="width: 776px;" class="wp-caption alignnone" id="attachment_6594"><img src="https://windowsontheory.files.wordpress.com/2018/12/note33x.png?w=600" alt="note33x" class="alignnone size-full wp-image-6594" /><p class="wp-caption-text">Representation power of MPS increases with bond dimension D.</p></div><p></p>
<p><a name="figpower"></a></p>
<p> </p>
<p><b>4. Density Matrix Renormalization Group </b></p>
<p>We are now ready to describe Density Matrix Renormalization Group, proposed originally in [<a href="https://windowsontheory.org/feed/#XPhysRevLett.69.2863">Whi92</a>, <a href="https://windowsontheory.org/feed/#XPhysRevB.48.10345">Whi93</a>]. As mentioned earlier, it does not come with provable guarantees. In fact, one can construct artificial hard instances such that the algorithm get stuck at certain local minima [<a href="https://windowsontheory.org/feed/#Xschuch2008computational">SCV08</a>]. However, it has remained one of the most successful heuristics for <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D systems. We refer the readers to [<a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>] for a complete survey.</p>
<p>DMRG is a simple alternating minimization scheme for computing the ground state of a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D Hamiltonian. We start with an arbitrary MPS. Then each step we optimize over the set of matrices <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D_%7Bj_i%3D0%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" class="latex" title="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" /> associated with site <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, while fixing everything else, and iterate until convergence. (You may wonder if one can simultaneously optimize over multiple sites. It turns out that it is an NP-hard problem<span class="LinLibertineT-tlf-ot-1x-x-90"> </span><span class="cite"><span class="LinLibertineT-tlf-ot-1x-x-90">[</span><a href="https://windowsontheory.org/feed/#XPhysRevLett.97.260501">Eis06</a><span class="LinLibertineT-tlf-ot-1x-x-90">]</span></span>.)</p>
<p>Formally, the Hamiltonian problem can be phrased as a eigenvalue problem given a Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />, and thus we want to optimize over all <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> in MPS of a fixed bond dimension <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> <a name="eqnham"></a></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5Cfrac%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " class="latex" title="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " /></p>
<p>Here, we assume that the input Hamiltonian is in the product form. In particular, it means that it can be written as a tensor network as</p>
<p></p><div style="width: 430px;" class="wp-caption aligncenter" id="attachment_6596"><img src="https://windowsontheory.files.wordpress.com/2018/12/note36x.png?w=600" alt="note36x" class="alignnone size-full wp-image-6596" /><p class="wp-caption-text">Input <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D Hamiltonian is of the particular product form.</p></div><p></p>
<p>so the numerator of the optimization objective looks like</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note37x.png?w=600" alt="note37x" class=" size-full wp-image-6597 aligncenter" /><a name="figdmrg1"></a></p>
<p>The DMRG works with the Langrangian of the objective. For some <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda&gt;0}" class="latex" title="{\lambda&gt;0}" />, we will consider <a name="eqndmrg2"></a></p>
<p align="center"><a name="eqndmrg2"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5C%2C%5C%2C+%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" class="latex" title="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" /></p>
<p><a name="eqndmrg2"></a><br />
<a name="eqndmrg2"></a>DMRG optimizes over the set of matrices associated with one qudit. Both terms in (<a href="https://windowsontheory.org/feed/#eqndmrg2">2</a>) are quadratic in this set of matrices.</p>
<p></p><div style="width: 919px;" class="wp-caption aligncenter" id="attachment_6598"><img src="https://windowsontheory.files.wordpress.com/2018/12/note39x.png?w=600" alt="note39x" class="alignnone size-full wp-image-6598" /><p class="wp-caption-text">The Langrangian <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" class="latex" title="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" /> as a tensor network.</p></div><p></p>
<p>Now to optimize over the set of parameters associated with one site, calculus tells you to set the (partial) derivative to <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />, and the derivative of a quadratic thing is linear. Without going through any algebra, we can guess that the derivative of  with respect to a particular site, say the second one, is the same picture except removing the second site on one side.</p>
<p></p><div style="width: 919px;" class="wp-caption alignnone" id="attachment_6599"><img src="https://windowsontheory.files.wordpress.com/2018/12/note40x.png?w=600" alt="note40x" class="alignnone size-full wp-image-6599" /><p class="wp-caption-text">The derivative that we set to <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and solve.</p></div><p></p>
<p>Notice that the unknown is still there, on the bottom side of each term. The trick of DMRG is to view the rest of the network as a linear map applied to the unknown.</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note41x.png?w=600" alt="note41x" class="alignnone size-full wp-image-6600" /></p>
<p>Given <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />, we now have a clean numerical linear algebra problem of solving</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H%27x+%3D+%5Clambda+Bx.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" class="latex" title="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" /></p>
<p>This is called a generalized eigenvalue problem, and it is well studied. Importantly, for <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D systems, <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> is typically very sparse, which enables very fast solvers in practice. Finally, DMRG sweeps over the sites one after another and stops until convergence is achieved.</p>
<p><b>5. Concluding Remarks </b></p>
<p class="noindent">Our presentation of tensor networks and MPS roughly follows <span class="cite">[<a href="https://windowsontheory.org/feed/#Xgharibian2015quantum">GHLS15</a>]</span>, a nice introductory survey on quantum Hamiltonian complexity.</p>
<p>The notion of tensor networks extends well beyond 1D systems, and a generalization of MPS is called tensor product state. It leads to algorithms for higher dimensional quantum systems. One may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcirac2009renormalization">CV09</a>]</span> for a comprehensive survey.</p>
<p>Tensor network has been interacting with other concepts. Within physics, it has been used in quantum error correction <span class="cite">[<a href="https://windowsontheory.org/feed/#Xferris2014tensor">FP14</a>, <a href="https://windowsontheory.org/feed/#Xpastawski2015holographic">PYHP15</a>]</span>, conformal field theory <span class="cite">[<a href="https://windowsontheory.org/feed/#Xorus2014advances">Orú14</a>]</span>, and statistical mechanics <span class="cite">[<a href="https://windowsontheory.org/feed/#XPhysRevLett.115.180405">EV15</a>]</span>. In TCS , we have found its connections with Holographic algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xvaliant2008holographic">Val08</a>, <a href="https://windowsontheory.org/feed/#Xcai2016complete">CGW16</a>]</span>, arithmetic complexity <span class="cite">[<a href="https://windowsontheory.org/feed/#Xbeaudry2007complexity">BH07</a>, <a href="https://windowsontheory.org/feed/#Xcapelli2016arithmetic">CDM16</a>, <a href="https://windowsontheory.org/feed/#Xaustrin19">AKK19</a>]</span>, and spectral algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xmoitra2018spectral">MW18</a>]</span>. In machine learning, it has been applied to probabilistic graphical models <span class="cite">[<a href="https://windowsontheory.org/feed/10.1093/imaiai/iay009">RS18</a>]</span>, tensor decomposition <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcichocki2016low">CLO16</a>]</span>, and quantum machine learning <span class="cite">[<a href="https://windowsontheory.org/feed/#X10.1088/2058-9565/aaea94">HPM18</a>]</span>.</p>
<p>For DMRG, we have only given a rough outline, with many details omitted, such as how to set <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> and how to obtain the Hamiltonian in the matrix product form, and how to compute the linear maps <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> for each iteration. An interested reader may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xschollwock2005density">Sch05</a>, <a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>]</span>.</p>
<p><strong>References</strong></p>
<p class="bibitem"><span class="biblabel">[AKK19] <span class="bibsp">   </span></span><a id="Xaustrin19"></a>Per Austrin, Peeri Kaski, and Kaie Kubjas. Tensor network complexity of multilinear maps. In <span class="LinLibertineTI-tlf-ot-1x-x-109">Proceedings of the 2019 Conference on Innovations in Theoretical Computer Science</span>. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">[BH07] <span class="bibsp">   </span></span><a id="Xbeaudry2007complexity"></a>Martin Beaudry and Markus Holzer. The complexity of tensor circuit evaluation. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Complexity</span>, 16(1):60, 2007.</p>
<p class="bibitem"><span class="biblabel">[CDM16] <span class="bibsp">   </span></span><a id="Xcapelli2016arithmetic"></a>Florent Capelli, Arnaud Durand, and Stefan Mengel. e arithmetic complexity of tensor contraction. <span class="LinLibertineTI-tlf-ot-1x-x-109">eory of Computing Systems</span>, 58(4):506{527, 2016.</p>
<p class="bibitem"><span class="biblabel">[CGW16] <span class="bibsp">   </span></span><a id="Xcai2016complete"></a>Jin-Yi Cai, Heng Guo, and Tyson Williams. A complete dichotomy rises from the capture of vanishing signatures. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 45(5):1671{1728, 2016.</p>
<p class="bibitem"><span class="biblabel">[CLO16] <span class="bibsp">   </span></span><a id="Xcichocki2016low"></a>Andrzej Cichocki, Namgil Lee, Ivan V Oseledets, A-H Phan, Qibin Zhao, and D Mandic. Low-rank tensor networks for dimensionality reduction and large-scale optimization problems: Perspectives and challenges part 1. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint arXiv:1609.00893</span>, 2016.</p>
<p class="bibitem"><span class="biblabel">[CV09] <span class="bibsp">   </span></span><a id="Xcirac2009renormalization"></a>J Ignacio Cirac and Frank Verstraete. Renormalization and tensor product states in spin chains and laices. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of Physics A: Mathematical and Theoretical</span>, 42(50):504004, 2009.</p>
<p class="bibitem"><span class="biblabel">[Eis06] <span class="bibsp">   </span></span><a id="XPhysRevLett.97.260501"></a>Jens Eisert. Computational difficulty of global variations in the density matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 97:260501, Dec 2006.</p>
<p class="bibitem"><span class="biblabel">[EV15] <span class="bibsp">   </span></span><a id="XPhysRevLett.115.180405"></a>G. Evenbly and G. Vidal. Tensor network renormalization. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 115:180405, Oct 2015.</p>
<p class="bibitem"><span class="biblabel">[FP14] <span class="bibsp">   </span></span><a id="Xferris2014tensor"></a>Andrew J Ferris and David Poulin. Tensor networks and quantum error correction. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 113(3):030501, 2014.</p>
<p class="bibitem"><span class="biblabel">[FSW07] <span class="bibsp">   </span></span><a id="Xfehske2007computational"></a>Holger Fehske, Ralf Schneider, and Alexander Weie. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational Many-Particle Physics</span>. Springer, 2007.</p>
<p class="bibitem"><span class="biblabel">[GHLS15] <span class="bibsp">   </span></span><a id="Xgharibian2015quantum"></a>Sevag Gharibian, Yichen Huang, Zeph Landau, and Seung Woo Shin. Quantum Hamiltonian complexity. <span class="LinLibertineTI-tlf-ot-1x-x-109">Foundations and Trends in Theoretical Computer Science</span>, 10(3):159, 2015.</p>
<p class="bibitem"><span class="biblabel">[HPM18]<span class="bibsp">   </span></span><a id="X10.1088/2058-9565/aaea94"></a>William James Huggins, Piyush Patil, Bradley Mitchell, K Birgia Whaley, and Miles Stoudenmire. Towards quantum machine learning with tensor networks. Qu<span class="LinLibertineTI-tlf-ot-1x-x-109">antum Science and</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Technology</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[MW18] <span class="bibsp">   </span></span><a id="Xmoitra2018spectral"></a>Ankur Moitra and Alexander S Wein. Spectral methods from tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv:1811.00944</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Orú14] <span class="bibsp">   </span></span><a id="Xorus2014advances"></a>Román Orús. Advances on tensor network theory: symmetries, fermions, entanglement, and holography. <span class="LinLibertineTI-tlf-ot-1x-x-109">e European Physical Journal B</span>, 87(11):280, 2014.</p>
<p class="bibitem"><span class="biblabel">[PYHP15] <span class="bibsp">   </span></span><a id="Xpastawski2015holographic"></a>Fernando Pastawski, Beni Yoshida, Daniel Harlow, and John Preskill. Holographic quantum error-correcting codes: Toy models for the bulk/boundary correspondence. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of High Energy</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Physics</span>, 2015(6):149, 2015.</p>
<p class="bibitem"><span class="biblabel">[RS18] <span class="bibsp">   </span></span><a id="Xdoi:10.1093/imaiai/iay009"></a>Elina Robeva and Anna Seigal. Duality of graphical models and tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">Information</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">and Inference: A Journal of the IMA</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Sch05] <span class="bibsp">   </span></span><a id="Xschollwock2005density"></a>Ulrich Schollwöck. The density-matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Rev. Mod. Phys.</span>, 77(1):259, 2005.</p>
<p class="bibitem"><span class="biblabel">[Sch11] <span class="bibsp">   </span></span><a id="Xschollwock2011density"></a>Ulrich Schollwöck. The density-matrix renormalization group in the age of matrix product states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Annals of Physics</span>, 326(1):96, 2011.</p>
<p class="bibitem"><span class="biblabel">[SCV08] <span class="bibsp">   </span></span><a id="Xschuch2008computational"></a>Norbert Schuch, Ignacio Cirac, and Frank Verstraete. Computational difficulty of finding matrix product ground states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 100(25):250501, 2008.</p>
<p class="bibitem"><span class="biblabel">[Val08] <span class="bibsp">   </span></span><a id="Xvaliant2008holographic"></a>Leslie G Valiant. Holographic algorithms. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 37(5):1565, 2008.</p>
<p class="bibitem"><span class="biblabel">[Whi92] <span class="bibsp">   </span></span><a id="XPhysRevLett.69.2863"></a>Steven R. White. Density matrix formulation for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 69:2863, Nov 1992.</p>
<p class="bibitem"><span class="biblabel">[Whi93] <span class="bibsp">   </span></span><a id="XPhysRevB.48.10345"></a>Steven R. White. Density-matrix algorithms for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">B</span>, 48:10345, Oct 1993.</p></div>







<p class="date">
by Fred Zhang <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/"><span class="datestr">at December 20, 2018 09:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6720">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/">Efficient preparation of thermal states of quantum systems: natural or artificial</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<article class="post-content"><p>Cross-posted from <a href="https://wsmoses.com/blog/2018/12/18/boaz/">https://wsmoses.com/blog/2018/12/18/boaz/</a></p><p>Lecturer: Aram Harrow</p><p>Scribes: Sinho Chewi, <a href="http://wsmoses.com">William S. Moses,</a> Tasha Schoenstein, Ary Swaminathan</p><p>November 9, 2018</p></article><p><br /></p><article class="post-content"><h3 id="outline">Outline</h3><p>Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We will then discuss Markov chains that have Gibbs distributions as stationary distributions. This leads into a discussion of the equivalence of mixing in time (i.e. the Markov chain quickly equilibrates over time) and mixing in space (i.e. sites that are far apart have small correlation). For the classical case, this equivalence is known. After discussing what is known classically, we will discuss difficulties that arise in the quantum case, including (approximate) Quantum Markov states and the equivalence of mixing in the quantum case.</p><h1 id="gibbs-distributions">Gibbs distributions</h1><p>We have already learned about phase transitions in a <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">previous blog post</a>, but they are important, so we will review them again. The <strong>Gibbs</strong> or <strong>thermal distribution</strong> is defined as follows: Suppose that we have an <strong>energy function</strong> <img src="https://s0.wp.com/latex.php?latex=E+%3A+%7B%5C%7B0%2C1%5C%7D%7D%5En+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E : {\{0,1\}}^n \to {\mathbb R}" class="latex" title="E : {\{0,1\}}^n \to {\mathbb R}" /> , which takes <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> -bit strings to real numbers. Usually, <img src="https://s0.wp.com/latex.php?latex=E+%3D+%5Csum_%7Bi%3D1%7D%5Em+E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E = \sum_{i=1}^m E_i" class="latex" title="E = \sum_{i=1}^m E_i" /> , where each <img src="https://s0.wp.com/latex.php?latex=E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_i" class="latex" title="E_i" /> term depends only on a few bits. For example, the energy might be the number of unsatisfied clauses in a 3-SAT formula, or it may arise from the Ising model. The Gibbs distribution is</p><p><span style="display: block;"> <img src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%5Cfrac%7B%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" class="latex" title="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" /> </span></p><p>where the normalization factor in the denominator, also called the <strong>partition function</strong>, is <img src="https://s0.wp.com/latex.php?latex=Z+%3D+%5Csum_%7Bx+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En%7D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" class="latex" title="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" /> . Another, perhaps more operational, way to define the Gibbs distribution is:</p><p><span style="display: block;"> <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%3B%5Cmathrm%7Barg%5C%2Cmax%7D_%7Bq+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29%7D+H%28q%29%7E%5Ctext%7Bsubject+to+the+constraint%7D%7E+%5Clangle%7Bq%2CE%7D%5Crangle+%3D+%5Cbar%7BE%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." class="latex" title="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." /> </span></p><p>In this expression, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{P}}({\{0,1\}}^n)" class="latex" title="{\mathcal{P}}({\{0,1\}}^n)" /> is the set of probability distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\{0,1\}}^n" class="latex" title="{\{0,1\}}^n" /> , <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is the Shannon entropy, and <img src="https://s0.wp.com/latex.php?latex=%5Cbar+E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bar E" class="latex" title="\bar E" /> is a constant representing the average energy. We are thinking of probability distributions and <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> as vectors of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" /> . It turns out that if we solve this optimization problem, then the Gibbs distribution is the unique solution.</p><h2 id="uses-of-gibbs-distributions">Uses of Gibbs distributions</h2><p>Why is it useful to work with Gibbs distributions?</p><ul><li><p>Gibbs distributions arise naturally in statistical physics systems, such as constraint satisfaction problems (CSPs), the Ising model, and spin glasses. One approach to deal with Gibbs distributions is through <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">belief propagation</a> (BP), which yields exact inference on tree graphical models and sometimes phase transition predictions on loopy graphs. Instead, we will focus on a different approach, namely, <em>sampling</em> from the Gibbs distribution.</p></li><li><p>If we want to minimize <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> (say, to find a 3-SAT solution), we can use <strong>simulated annealing</strong>. The idea of annealing is that we want to produce a crystal; a crystal is the lowest energy configuration of molecules. If we heat up the substance to a liquid and then cool it quickly, we will not get a nice crystal, because little bits of the material will point in different directions. In order to form a crystal, we need to cool the system slowly.</p><p>In computer science terms, we take a sample from a high temperature because sampling is generally easier at a higher temperature than at a lower temperature. We then use that sample as the starting point for an equilibration process at a slightly lower temperature, and repeat this procedure. If we reach zero temperature, then we are sampling from the minimizers of <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> . In practice, the system will usually stop mixing before we get to zero temperature, but this is a good heuristic. You can think of this process as gradient descent, with some additional randomness.</p></li><li><p>Gibbs distributions are used to simulate physical systems.</p></li><li><p>Gibbs distributions are used in Bayesian inference due to the Hammersley-Clifford theorem, which will be discussed next.</p></li><li><p>Gibbs distributions are also connected to multiplicative weights for linear programming (not discussed in this blog post).</p></li></ul><h2 id="bayesian-inference--the-hammersley-clifford-theorem">Bayesian inference &amp; the Hammersley-Clifford theorem</h2><p>In order to present the Hammersley-Clifford theorem, we must first discuss Markov networks. For this part, we will generalize our setup to a finite alphabet <img src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma" class="latex" title="\Sigma" /> , so the energy function is now a function <img src="https://s0.wp.com/latex.php?latex=%5CSigma%5En+%5Cto+%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma^n \to \mathbb R" class="latex" title="\Sigma^n \to \mathbb R" /> .</p><h3 id="markov-chains">Markov chains</h3><p>First, let us recall the idea of a <strong>Markov chain</strong> with variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> .</p></article>


<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p1.png?w=600" alt="" class="wp-image-6784" /></figure>



<p>The random variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> form a Markov chain if their joint distribution can be written in a factored way: <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B1%2C2%7D%28x_1%2Cx_2%29p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" class="latex" title="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" /> . For example, imagine that <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> represent the weather on Monday, Tuesday, and Wednesday respectively. These random variables form a Markov chain if, conditioned on the weather on Tuesday, we have all of the information we need to forecast the weather on Wednesday. Another way to say this is that conditioned on the weather on Tuesday, then the weather on Monday and the weather on Wednesday are <strong>conditionally independent</strong>. Note that the weather on Monday and the weather on Wednesday are <em>not</em> independent; there can be correlations, but these correlations are mediated through the weather on Tuesday. It is important to note that the definition of a Markov chain is symmetric with respect to going forwards or backwards in time, so we can also write the conditional independence condition as <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B2%2C3%7D%28x_2%2Cx_3%29+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" class="latex" title="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" /> .</p>



<p>The conditional independence condition can also be written as <img src="https://s0.wp.com/latex.php?latex=p_%7B1%2C3+%5Cmid+2%7D%28x_1%2C+x_3+%5Cmid+x_2%29+%3D+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29+p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." class="latex" title="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." /> Recall that for two random variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> and <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> with joint distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> , they are independent, i.e., <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%29+%3D+p_1%28x_1%29+p_2%28x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2) = p_1(x_1) p_2(x_2)" class="latex" title="p(x_1,x_2) = p_1(x_1) p_2(x_2)" /> , if and only if <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_2%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1; X_2) = 0" class="latex" title="I(X_1; X_2) = 0" /> , where <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" /> here denotes the mutual information. Similarly, conditional independence is equivalent to the <strong>conditional mutual information</strong> <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1; X_3 \mid X_2)" class="latex" title="I(X_1; X_3 \mid X_2)" /> equaling zero. This quantity is defined as <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3BX_3+%5Cmid+X_2%29+%3D+H%28X_1+%5Cmid+X_2%29+%2B+H%28X_3+%5Cmid+X_2%29+-+H%28X_1%2C+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" class="latex" title="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" /> .</p>



<p>Keep in mind that conditional independence is characterized in two equivalent ways: via an algebraic condition on the distributions, and via mutual information.</p>



<h3 id="markov-networks">Markov networks</h3>



<p>A <strong>Markov network</strong> is like a Markov chain, but with more random variables and a more interesting structure. Imagine that we have a graph, where each node is associated with a random variable and the edges encode possible correlations. A Markov network has the property that if we take any disjoint collection of nodes <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> such that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> are fully separated by <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> (that is, any path from <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> to <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> must go through <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , or alternatively, removing <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> leaves <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> disconnected), then <img src="https://s0.wp.com/latex.php?latex=I%28X_A%3B+X_C+%5Cmid+X_B%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_A; X_C \mid X_B) = 0" class="latex" title="I(X_A; X_C \mid X_B) = 0" /> . The notation <img src="https://s0.wp.com/latex.php?latex=X_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_A" class="latex" title="X_A" /> here means the collection of random variables associated with the nodes in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> .</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p2.png?w=600" alt="" class="wp-image-6785" /></figure>



<p>For example:</p>



<p>Here, if <img src="https://s0.wp.com/latex.php?latex=A%3D%5C%7B1%2C5%2C6%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A=\{1,5,6\}" class="latex" title="A=\{1,5,6\}" /> , <img src="https://s0.wp.com/latex.php?latex=B%3D%5C%7B2%2C7%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B=\{2,7\}" class="latex" title="B=\{2,7\}" /> , and <img src="https://s0.wp.com/latex.php?latex=C%3D%5C%7B3%2C4%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C=\{3,4\}" class="latex" title="C=\{3,4\}" /> , then <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> separates <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> .</p>



<p>A Markov network is also called a <strong>graphical model</strong> or a <strong>Markov random field</strong>; and yet another name for them is <em>Gibbs distribution</em>, which is the content of the following theorem:</p>



<p><strong>Theorem 1</strong> (Hammersley-Clifford Theorem): <em>Let <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> be a strictly positive distribution on <img src="https://s0.wp.com/latex.php?latex=%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma^n" class="latex" title="\Sigma^n" /> . Then, <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> can be represented as a Markov network with respect to a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> if and only if <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> can be expressed as a Gibbs distribution <img src="https://s0.wp.com/latex.php?latex=p%28x%29+%5Cpropto+%5Cexp%5C%7B-%5Csum_%7BC+%5Cin+%7B%5Cmathcal%7BC%7D%7D%28G%29%7D+E_C%28x_C%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" class="latex" title="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" /> , where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{C}}(G)" class="latex" title="{\mathcal{C}}(G)" /> is the set of cliques (fully connected subsets) of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> . </em></p>



<p>This theorem says that Markov networks are the same as Gibbs states, <em>with the same notion of locality</em>.</p>



<p>The Hammersley-Clifford theorem implies an area law for mutual information; we will explain what this is and sketch why this is true. Divide a system into two disjoint pieces <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . We want to know about the mutual information between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , <img src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A;B)" class="latex" title="I(A;B)" /> . The Hammersley-Clifford theorem gives us a bound which depends only on the size of the boundary <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> between these sets. For simplicity, assume <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial \subseteq B" class="latex" title="\partial \subseteq B" /> . Also, assume that the interactions have bounded range; then, the Hammersley-Clifford theorem tells us that <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B \mid \partial) = 0" class="latex" title="I(A; B \mid \partial) = 0" /> .</p>



<p>Now, we will use the fact <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+I%28A%3B+B%2C%5Cpartial%29+-+I%28A%3B+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" class="latex" title="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" /> . We can see this by writing out the expressions, but the intuition is that the term on the left asks about how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , having already known about <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> . This equals how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> combined, minus how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> alone. In this case, since we said <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial \subseteq B" class="latex" title="\partial \subseteq B" /> , then <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B)" class="latex" title="I(A; B)" /> is the same as <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%2C+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B, \partial)" class="latex" title="I(A; B, \partial)" /> . In general, however, we have an upper bound:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29+%5Cle+I%28A%3B+B%2C+%5Cpartial%29+%3D+I%28A%3B+%5Cpartial%29+%2B+I%28A%3BB+%5Cmid+%5Cpartial%29+%5Cle+H%28%5Cpartial%29+%5Cle+%7C%5Cpartial%7C+%5Clog+%7C%5CSigma%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" class="latex" title="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" /> </p>



<p>In this calculation, we have used <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+%5Cpartial%29+%3D+H%28%5Cpartial%29+-+H%28%5Cpartial+%5Cmid+A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; \partial) = H(\partial) - H(\partial \mid A)" class="latex" title="I(A; \partial) = H(\partial) - H(\partial \mid A)" /> (the information between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> is the amount by which the entropy of <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> gets reduced once we know <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> ) and <img src="https://s0.wp.com/latex.php?latex=H%28%5Cpartial+%5Cmid+A%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(\partial \mid A) \ge 0" class="latex" title="H(\partial \mid A) \ge 0" /> (which is true classically).</p>



<p>Since the mutual information only scales with the <em>surface area</em> of the boundary and not with the area of the two regions <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , this is known as an <em>area law</em> <a href="https://windowsontheory.org/feed/#gharibian">[1]</a>.</p>



<h3 id="relationship-to-bayesian-inference">Relationship to Bayesian inference</h3>



<p>In Bayesian inference, we have a model for a system which can be very complicated. The model represents our assumptions on how parts of the system are causally related to the rest of the system. We have some observations, and we want to sample from a distribution conditionally on the fixed observations. Sampling from a conditional distribution is not the same as sampling from the original distribution, but we can still formally represent the conditional distribution as a Markov network. Therefore, sampling from Markov networks is a broadly useful task.</p>



<p>As an example of a complicated Bayesian model, consider a <em>hierarchical Bayesian model</em> <a href="https://windowsontheory.org/feed/#keener">[2]</a>. Bayesian statistics requires choosing a prior distribution, and when there is a natural parameterized family of priors that a statistician can use, it may make sense to introduce a distribution over the priors; this is known as <em>introducing a hyperparameter</em>, and inference in the resulting hierarchical model (including computation of the posterior distribution) is frequently intractable. However, it is still desirable to work with these models because they are often more accurate than models in which the prior is handpicked by a statistician.</p>



<h1 id="sampling-from-gibbs-distributions">Sampling from Gibbs distributions</h1>



<p>The task of sampling from an arbitrary Gibbs distribution is MA-complete <a href="https://windowsontheory.org/feed/#crosson_making_2010">[3]</a>, and it is not hard to see that at low enough temperatures this problem is at least NP-hard. So, how do we sample from these distributions?</p>



<p>This section will discuss Monte Carlo Markov chain (MCMC) methods, namely the Metropolis-Hastings algorithm and Glauber dynamics. Readers familiar with these methods may wish to skip to the discussion of <a href="https://windowsontheory.org/feed/#scn_mixing_in_time">mixing in time</a>. For readers who wish to build more intuition about Markov chains before proceeding, see the <a href="https://windowsontheory.org/feed/#scn_appendix">Appendix</a>, where the simple example of the random walk on a cycle is treated in detail.</p>



<h2 id="monte-carlo-markov-chain-mcmc-methods">Monte Carlo Markov chain (MCMC) methods</h2>



<p>The general approach is to use a Markov chain. Let <img src="https://s0.wp.com/latex.php?latex=%5COmega%3D%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega=\Sigma^n" class="latex" title="\Omega=\Sigma^n" /> be the possible states of the system. Effectively, a Markov chain is a way of doing a random walk over <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> .</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p3.png?w=600" alt="" class="wp-image-6786" /></figure>



<p>The transition probabilities of the Markov chain are<sup><a href="https://windowsontheory.org/feed/#fn_1">1</a></sup> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%28t%2B1%29+%3D+y+%5Cmid+X%28t%29+%3D+x%5C%7D+%3D+T_%7By%2Cx%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." class="latex" title="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." /> Here, <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is the <strong>transition probability matrix</strong>. The column at index <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is the probability distribution of the next state of the Markov chain, if the current state is <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . The row at index <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a row of probability values which give the probabilities of jumping into state <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> from every other state. It has the properties that its entries are non-negative and for every <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7By+%5Cin+%5COmega%7D+T_%7By%2Cx%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{y \in \Omega} T_{y,x} = 1" class="latex" title="\sum_{y \in \Omega} T_{y,x} = 1" /> . These properties say that <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is a (column) <strong>stochastic matrix</strong>.</p>



<p>Suppose we start at a state <img src="https://s0.wp.com/latex.php?latex=x%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x(0)" class="latex" title="x(0)" /> ; or, more generally, we will start with a distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> over <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> . If we move according to the chain once, the distribution will be <img src="https://s0.wp.com/latex.php?latex=Tp&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tp" class="latex" title="Tp" /> . If we move agian, the distribution will be <img src="https://s0.wp.com/latex.php?latex=T%5E2+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^2 p" class="latex" title="T^2 p" /> . In general, after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> movements, the distribution is <img src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t p" class="latex" title="T^t p" /> . So, we can express the dynamics of the chain as matrix-vector multiplication.</p>



<p>It is worth mentioning that if we are simulating the chain on a computer and we are manipulating <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> -bit numbers, then these probability vectors are of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" /> so it becomes impractical to store the entire probability distributions.</p>



<p>The justification for our algorithms is the following theorem.</p>



<p><strong>Theorem 2</strong> (Perron-Frobenius Theorem): <em>If <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is a stochastic aperiodic matrix, then one of the eigenvalues is <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> , and all other eigenvalues have magnitude strictly less than <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . There is a unique probability distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> such that <img src="https://s0.wp.com/latex.php?latex=T%5Cpi+%3D+%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T\pi = \pi" class="latex" title="T\pi = \pi" /> . </em></p>



<p>The theorem implies that <img src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t p" class="latex" title="T^t p" /> will converge to the stationary distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> as <img src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\to\infty" class="latex" title="t\to\infty" /> . So, if we want to sample from a distribution, this provides a method of doing so: cook up a Markov chain that equilibrates to the desired distribution, and then run the Markov chain until convergence. <em>A priori</em>, it is not obvious how we can design the Markov chain. At first, our problem was to sample from a probability distribution (a vector), and now we have changed the problem to designing an entire matrix, which does not appear to make our task easier.</p>



<p>Now, the question becomes: how does one come up with Markov chains that give you the desired stationary distribution?</p>



<h2 id="metropolis-hastings-algorithm">Metropolis-Hastings algorithm</h2>



<p>The first algorithm we will introduce is the <strong>Metropolis-Hastings algorithm</strong>. One more desirable feature of a Markov chain is that it satisfies <strong>detailed balance</strong>, which says <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x+T_%7By%2Cx%7D+%3D+%5Cpi_y+T_%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x T_{y,x} = \pi_y T_{x,y}" class="latex" title="\pi_x T_{y,x} = \pi_y T_{x,y}" /> for all <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> . This condition says that if we pick a point with probability according to the stationary distribution and transition, the probability of picking <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and then moving to <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> should be the same as picking <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> and then moving to <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> .</p>



<p>For a Markov chain in equilibrium, the total amount of probability flowing out of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> must equal the total amount of probability flowing into <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . For example, the United States might export products to Europe and import from China. Detailed balance says that the flow along each edge must balance, which is a more demanding condition. In the example with country trade deficits, we are requiring that all bilateral trade deficits must be zero.</p>



<p>Mathematically, detailed balance implies that <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> can be transformed, via similarity transformations, into a symmetric matrix. The Metropolis-Hastings algorithm says that we should choose <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> with the property <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BT_%7Bx%2Cy%7D%7D%7BT_%7By%2Cx%7D%7D+%3D+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." class="latex" title="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." /> Suppose that we have an underlying graph on our state space, and suppose that we are at a state <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . The algorithm chooses a random neighbor, say <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> , and then accepts or rejects this move with some probability. If the move is accepted, then we move to <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> and continue the algorithm from there. Otherwise, if the move is rejected, then we stay at <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . We are free to choose any underlying graph (as long as it is connected and has a self-loop), and then we will tune the acceptance probability so that detailed balance holds.</p>



<p>Look at the trial move <img src="https://s0.wp.com/latex.php?latex=x%5Cto+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\to y" class="latex" title="x\to y" /> . One way we can accomplish detailed balance is by looking at the ratio <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x" class="latex" title="\pi_y/\pi_x" /> . If <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%5Cge+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x \ge 1" class="latex" title="\pi_y/\pi_x \ge 1" /> , then always accept the move. If <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%3C+1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x &lt; 1 " class="latex" title="\pi_y/\pi_x &lt; 1 " /> , then accept the move with probability <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x%2F%5Cpi_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x/\pi_y" class="latex" title="\pi_x/\pi_y" /> .</p>



<p>To get an idea for how the algorithm works, suppose that our underlying graph is <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> -regular. Then, for neighbors <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> ,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DT_%7By%2Cx%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%2C+%5C%5C+T_%7Bx%2Cy%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%5C%3B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " class="latex" title="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " /> </p>



<p><strong>Claim</strong>: <img src="https://s0.wp.com/latex.php?latex=T_%7By%2Cx%7D+%5Cpi_x+%3D+%5Cfrac%7B1%7D%7Bd%7D+%5Cmin%5C%7B%5Cpi_x%2C%5Cpi_y%5C%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," class="latex" title="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," /> which is manifestly symmetric in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> ; thus, we have reversibility. This is the basic idea of the Metropolis-Hastings algorithm.</p>



<p>How does it work for a Gibbs distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x+%3D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%2FZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x = \exp\{-E(x)/T\}/Z" class="latex" title="\pi_x = \exp\{-E(x)/T\}/Z" /> , where the energy function might, for example, count the number of violated clauses in a 3-SAT formula? In this case, we might be a little worried. The numerator of <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x" class="latex" title="\pi_x" /> is pretty easy to compute (we can count how many violated constraints there are), but the denominator is hard to compute. In general, it is #P-hard to compute the denominator, because as <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> drops to <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> , the partition function in this case approaches the number of 3-SAT solutions. So, how do we calculate the ratios <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x" class="latex" title="\pi_y/\pi_x" /> that the algorithm requires? We’re able to do this because the ratio does not depend on <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> :</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D+%3D+%5Cexp+%5Cfrac%7BE%28x%29-E%28y%29%7D%7BT%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." class="latex" title="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." /> </p>



<p>Suppose that the energy is a sum of local terms, and the underlying graph corresponds to modifying one site at at a time. What this means is that the graph is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%3D+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega = {\{0,1\}}^n" class="latex" title="\Omega = {\{0,1\}}^n" /> and the edges in the graph correspond to flipping exactly one bit. In this case, it becomes very easy to evaluate the computations needed for the algorithm; in fact, we can even do them in parallel.</p>



<p>How do we choose the underlying graph? The key idea is that we do not want the majority of our moves to be rejected. A good example to keep in mind is the <strong>Ising model</strong>, where the configurations are <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in {\{0,1\}}^n" class="latex" title="x \in {\{0,1\}}^n" /> and the energy is <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+-%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" title="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" /> . If <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} \ge 0" class="latex" title="J_{i,j} \ge 0" /> for all <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> , <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> , then we say that the model is <strong>ferromagnetic</strong> (we obtain lower energy by making the sites agree with each other). Of course, an <strong>antiferromagnetic</strong> model is just the opposite of this.</p>



<p>Assume that the bits are laid out in a square and <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} = J" class="latex" title="J_{i,j} = J" /> if <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> are neighbors on the square, and <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} = 0" class="latex" title="J_{i,j} = 0" /> if they are not. As we vary the quantity <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> , we observe a <em>phase transition</em>. If <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> is small, then the coupling between the random variables is weak and the different parts of the system are almost independent; we call this the <strong>disordered phase</strong>. If <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> is large, then the spins want to align in the same direction and the Gibbs distribution will look almost like the following: with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> , all spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> , and with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> , all spins are <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> ; we call this the <strong>ordered phase</strong>.</p>



<p>In the disordered phase, when the spins do not need to align so closely, the Metropolis-Hastings algorithm will work well. In the ordered phase, the algorithm is doomed. Indeed, suppose that most of the spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . As time proceeds, any <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> s will switch to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . There may be islands of <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> spins initially, but it will be energetically favorable for these islands to shrink over time. Therefore, there will be an exponentially small chance for the system to switch to a configuration with mostly <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> ’s, and thus the chain takes exponentially long to mix. Here, people are interested in understanding the <em>autocorrelation time</em>, because the goal is to run the chain for some time, get one sample, run the chain for some more time, get another sample, etc.</p>



<h2 id="glauber-dynamics">Glauber dynamics</h2>



<p>This next method (<strong>Glauber dynamics</strong>) is essentially the same as Metropolis-Hastings, but this is not immediately obvious. We are at a state <img src="https://s0.wp.com/latex.php?latex=x+%3D+%28x_1%2C%5Cdotsc%2Cx_n%29+%5Cin+%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x = (x_1,\dotsc,x_n) \in \Sigma^n" class="latex" title="x = (x_1,\dotsc,x_n) \in \Sigma^n" /> . (For the Metropolis-Hastings algorithm, we could be walking on a state space without a product structure. However, Glauber dynamics requires a product structure.) Then, we update <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> to <img src="https://s0.wp.com/latex.php?latex=%28x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_i%27%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" class="latex" title="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" /> with chance <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%5Cmid+-i%7D%28x_i%27+%5Cmid+x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" class="latex" title="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" /> . In other words, we hold all other bits fixed, and conditioned on those other bits, we resample the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> th bit. Like Metropolis-Hastings, <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> is stationary for this chain.</p>



<p>It is not obvious that these conditional distributions can be computed efficiently, but it is possible since normalizing the conditional distribution only requires summing over the possible configurations for a single random variable. On a Markov network, the conditional probability is <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi+%5Cmid+N%28i%29%7D%28x_i%27+%5Cmid+x_%7BN%28i%29%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" class="latex" title="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" /> , where <img src="https://s0.wp.com/latex.php?latex=N%28i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N(i)" class="latex" title="N(i)" /> denotes the set of neighbors of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> . This makes the computation a constant-sized calculation (i.e., does not depend on the size of the system).</p>



<p>For example, in the Ising model, suppose we are at state <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in {\{\pm 1\}}^n" class="latex" title="x \in {\{\pm 1\}}^n" /> . In Glauber dynamics, we pick a vertex <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> u.a.r. and update it to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> with probability <img src="https://s0.wp.com/latex.php?latex=p_%7Bi+%5Cmid+N%28i%29%7D%28%2B+%5Cmid+x_%7BN%28i%29%7D%29+%3D+%5Cfrac%7B%5Cexp%28T%5E%7B-1%7D%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D%7B%5Cexp%28-T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29+%2B+%5Cexp%28T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." class="latex" title="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." /></p>



<h1 id="scn:mixing_in_time">Mixing in time</h1>



<p>Mixing in time means that the dynamics will equilibrate rapidly. It turns out that this is equivalent to mixing in space, which means that <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> itself has decaying correlations. For example, the Ising model at low temperature has a lot of long-range correlations, but at high temperature it does not. For the high temperature regime, we can prove that mixing in time occurs. We will prove this for the ferromagnetic Ising model. The result is known more generally, but the proofs are much easier for the Ising model.</p>



<p>People have known about the Metropolis-Hastings algorithm since the 1950s, but only recently have researchers been able to prove convergence guarantees for the 2D Ising model. There is a large gap between theory and practice, but in some situations we can prove that the algorithm works.</p>



<p>Sampling from the distribution is roughly equivalent to estimating the partition function (sampling-counting equivalence). There have been many papers addressing tasks such as estimating the non-negative permanent, the number of colorings of a graph, etc.<sup><a href="https://windowsontheory.org/feed/#fn_2">2</a></sup> A dominant way of accomplishing these tasks is proving that the Metropolis-Hastings algorithm converges for these problems. It is easy to find algorithms for these problems that converge to Gibbs distributions, but the convergence may take exponential time.</p>



<p>We will look at the situation when the energy function looks like the Ising model, in the sense that the interactions are local and reflect the structure of some underlying space. Also, assume that the interactions are of size <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> and that the scaling comes from the size of the system. When can we expect that our algorithms work? There are two main cases when we can argue that there should be rapid mixing.</p>



<ul><li>High temperature regime: The system is very disordered, and in the limit as the temperature approaches infinity, we get the uniform distribution.</li><li>One-dimension: In 1D, we can exactly compute the partition function using dynamic programming. Before, we mentioned that if there are a sea of <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> s and an island of <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> s, then it is energetically favorable for the island to shrink; note that this is no longer true in 1D. In a way, 1D systems are more “boring” because they cannot exhibit arbitrarily long-range correlations.</li></ul>



<p>In this part of the blog post, we will try to be more proof-oriented. We will start by explaining why it is plausible that high temperature means that the chain will mix rapidly in time.</p>



<h2 id="coupling-method">Coupling method</h2>



<p>One method of proving rates of convergence for Markov chains is by analzying the spectral gap. Another method is the <strong>coupling method</strong>.</p>



<p>The idea behind the coupling method is to start with two configurations <img src="https://s0.wp.com/latex.php?latex=X%280%29%2CY%280%29+%5Cin+%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0),Y(0) \in \Omega" class="latex" title="X(0),Y(0) \in \Omega" /> . We want each one to evolve under the Markov chain.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p4.png?w=600" alt="" class="wp-image-6787" /></figure>



<p>The key part is that there is still some freedom with respect to what the dynamics looks like. In particular, we are allowed to correlate the <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> processes. Thus, we are defining a joint transition probability <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%281%29%3Dx%281%29%2CY%281%29%3Dy%281%29+%5Cmid+X%280%29%2CY%280%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" class="latex" title="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" /> . We want to design the process such that <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> are closer together than <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> . Imagine that we have two particles bouncing around. Each particle follows the dynamics of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> , but they are correlated so that they drift together, and once they meet, they stick together. It turns out that the mixing time can be upper bounded by the time it takes for the particles to meet each other.</p>



<p>Assume we have some sort of distance function <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}" class="latex" title="\;\mathrm{dist}" /> on the underlying space and we can prove that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%28X%281%29%2CY%281%29%29+%5Cle+%5Cexp%28-%5Calpha%29+%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" class="latex" title="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" /> . Then, it turns out that the mixing time <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon)" class="latex" title="t_{\rm mix}(\epsilon)" /> , i.e. the time required to get within <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> of the stationary distribution, is upper bounded as</p>



<p> <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%5C%7B%28%5C%3B%5Cmathrm%7Bdiam%7D%5COmega%29%2F%5Cepsilon%5C%7D%7D%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" class="latex" title="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" /> </p>



<p>Initially, the two particles can be <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiam%7D%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{diam}\Omega" class="latex" title="\;\mathrm{diam}\Omega" /> apart, but the expected distance is exponentially shrinking as we run the coupling, so the mixing time is logarithmic in the diameter.</p>



<p>The distance between probability distributions is defined as follows. Let <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> be two probability distributions on <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> . Then, the metric is:<sup><a href="https://windowsontheory.org/feed/#fn_3">3</a></sup></p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+%5C%7Cp-q%5C%7C_1+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bx+%5Cin+%5COmega%7D%7Cp%28x%29-q%28x%29%7C+%3D+%5Cmin_%7B%5Csubstack%7B%28X%2CY%29+%5Csim+r+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%5COmega+%5Ctimes+%5COmega%29+%5C%5C+r_1+%3D+p+%5C%5C+r_2+%3D+q%7D%7D+%7B%5Cmathbb+P%7D_r%5C%7BX+%5Cne+Y%5C%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." class="latex" title="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." /> </p>



<p>In this expression, <img src="https://s0.wp.com/latex.php?latex=r_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r_1" class="latex" title="r_1" /> and <img src="https://s0.wp.com/latex.php?latex=r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r_2" class="latex" title="r_2" /> denote the first and second marginals of <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> respectively. The minimum is taken over all <em>couplings</em> of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> . This is the correct way to measure the distance between distributions. To give some intuition for this quantity, the quantity on the right represents the best <em>test</em> to distinguish the two distributions. If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> are the same, we can take a coupling in which <img src="https://s0.wp.com/latex.php?latex=X+%5Csim+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X \sim p" class="latex" title="X \sim p" /> and <img src="https://s0.wp.com/latex.php?latex=Y+%5Csim+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y \sim q" class="latex" title="Y \sim q" /> are always identical. If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> have disjoint supports, then no matter what coupling we use, <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> will never be equal.</p>



<p>It suffices to consider when <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> are neighbors, i.e. at distance <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> apart. This is because if we have <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> far apart, then we could look at the path between them and reduce to the case when they are neighbors. Formally, this is known as <em>path coupling</em>. The formal statement is in Theorem 12.3 of <a href="https://windowsontheory.org/feed/#nature">[4]</a>:</p>



<p><strong>Theorem 3</strong>: <em>Let <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> be a connected weighted graph on the state space, where no edge has weight less than <img src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmin%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{\min}" class="latex" title="d_{\min}" /> . Let <img src="https://s0.wp.com/latex.php?latex=d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d(C,C')" class="latex" title="d(C,C')" /> be the length of the shortest path from <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> to <img src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'" class="latex" title="C'" /> in <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> and let <img src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmax%7D+%3D+%5Cmax_%7BC%2CC%27+%5Cin+%5COmega%7D+d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" class="latex" title="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" /> be the diameter of <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> . Suppose there is a coupling such that for some <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta &gt; 0" class="latex" title="\delta &gt; 0" /> </em>,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5Cbigl%5Bd%5Cbigl%28X%281%29%2CY%281%29%5Cbigr%29+%5Cbigm%5Cvert+%5Cbigl%28X%280%29%2CY%280%29%5Cbigr%29+%3D+%28C%2CC%27%29%5Cbigr%5D+%5Cle+%281-%5Cdelta%29d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" class="latex" title="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" /> </p>



<p><em>for all neighboring pairs <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> , <img src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'" class="latex" title="C'" /> , i.e., those pairs connected by an edge in <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> . Then, the mixing time is bounded by </em></p>



<p> <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%28%5Cepsilon%5E%7B-1%7Dd_%7B%5Cmax%7D%2Fd_%7B%5Cmin%7D%29%7D%7B%5Cdelta%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." class="latex" title="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." /> </p>



<h2 id="glauber-dynamics-at-high-temperature">Glauber dynamics at high temperature</h2>



<p>Recall that in Glauber dynamics, we pick a site <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> randomly and then update the site conditioned on its neighbors. The first way we will couple together <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> is by picking the <em>same</em> site for both of them.</p>



<ol><li>Pick a random <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> .</li><li>If <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_%7BN%28i%29%7D+%3D+%7BY%280%29%7D_%7BN%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" class="latex" title="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" /> , then set <img src="https://s0.wp.com/latex.php?latex=%7BX%281%29%7D_i+%3D+%7BY%281%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(1)}_i = {Y(1)}_i" class="latex" title="{X(1)}_i = {Y(1)}_i" /> (if the neighborhoods of the two points agree, then update them the same way). Otherwise, update them using the best possible coupling, i.e., pick a coupling for <img src="https://s0.wp.com/latex.php?latex=%28%7BX%281%29%7D_i%2C+%7BY%281%29%7D_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="({X(1)}_i, {Y(1)}_i)" class="latex" title="({X(1)}_i, {Y(1)}_i)" /> which minimizes <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7B+%7BX%281%29%7D_i+%5Cne+%7BY%281%29%7D_i+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" class="latex" title="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" /> .</li></ol>



<p>So if <img src="https://s0.wp.com/latex.php?latex=X%280%29+%3D+Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0) = Y(0)" class="latex" title="X(0) = Y(0)" /> , then the points will never drift apart. The reason why analyzing this coupling is non-trivial is because there is a chance that the distance between the two points can <em>increase</em>.</p>



<p>Assume that the degree of the graph is <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> . Suppose that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}(X(0),Y(0)) = 1" class="latex" title="\;\mathrm{dist}(X(0),Y(0)) = 1" /> , that is, there is a single <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_a \ne {Y(0)}_a" class="latex" title="{X(0)}_a \ne {Y(0)}_a" /> . What will happen to <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> ? We start by picking a random <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> . There are three cases:</p>



<ol><li><img src="https://s0.wp.com/latex.php?latex=i+%5Cnotin+%28%5C%7Ba%5C%7D+%5Ccup+N%28a%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \notin (\{a\} \cup N(a))" class="latex" title="i \notin (\{a\} \cup N(a))" /> (with probability <img src="https://s0.wp.com/latex.php?latex=1+-+%28%5CDelta+%2B+1%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 - (\Delta + 1)/n" class="latex" title="1 - (\Delta + 1)/n" /> ): Nothing changes; <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> agree at <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> , and <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> will also agree at <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> . The distance remains at <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> .</li><li><img src="https://s0.wp.com/latex.php?latex=i+%3D+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = a" class="latex" title="i = a" /> (with probability <img src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/n" class="latex" title="1/n" /> ): We picked the one spot in which the two configurations differ. The neighborhoods of <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> are the same for <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> , so we update in the same way for both processes, and the distance drops to <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> .</li><li><img src="https://s0.wp.com/latex.php?latex=i+%5Cin+N%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in N(a)" class="latex" title="i \in N(a)" /> (with probability <img src="https://s0.wp.com/latex.php?latex=%5CDelta%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta/n" class="latex" title="\Delta/n" /> ): We could have different updates. Here, we have to use the high temperature assumption, which says that if we change one bit, the probability of a configuration cannot change too much.In the Ising model, <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" title="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" /> . Changing <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> can bias the energy by at most <img src="https://s0.wp.com/latex.php?latex=%5CDelta%5Cmax_i+J_%7Bi%2Ca%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta\max_i J_{i,a}" class="latex" title="\Delta\max_i J_{i,a}" /> , so the expected distance afterwards is <img src="https://s0.wp.com/latex.php?latex=1+%2B+O%28%5Cmax_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D%2FT%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 + O(\max_{i,j=1}^n J_{i,j}/T)" class="latex" title="1 + O(\max_{i,j=1}^n J_{i,j}/T)" /> .</li></ol>



<p>Adding these cases up to get the overall expected distance gives</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%5Cbigl%28X%281%29%2C+Y%281%29%5Cbigr%29+%3D+1-%5Cfrac%7B1%7D%7Bn%7D+%2B+%5Cunderbrace%7BO%5CBigl%28%5Cfrac%7B%5CDelta+J_%7B%5Cmax%7D%7D%7BT%7D%5CBigr%29%7D_%7B%5Cle+1%7D%5Cfrac%7B1%7D%7Bn%7D+%3D+1+-+%5Cfrac%7Bc%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" class="latex" title="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" /> </p>



<p>for <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> large enough, so the expected distance will shrink. This argument also tells us how large the temperature must be, which is important for applications. This gives us <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%3D+O%5CBigl%28n%5Clog%5Cfrac%7Bn%7D%7B%5Cepsilon%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." class="latex" title="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." /> Notice that this is the same dependence as the coupon collector problem. Therefore, in the high temperature regime, the system behaves qualitatively as if there are no correlations.</p>



<h2 id="temporal-and-spatial-mixing-equivalence">Temporal and spatial mixing equivalence</h2>



<p>The analysis of Glauber dynamics at high temperature is already a version of the equivalence between mixing in time and mixing in space. It says that if the correlations even with the immediate neighbors of a node are weak, then Glauber dynamics rapidly mixes.</p>



<p>Now, we want to consider the situation in which there can be strong correlations between immediate neighbors, but weak correlation with far away sites. We want to show that spatial mixing implies temporal mixing.</p>



<p>We will give a few definitions of correlation decay. (Note: The definitions of correlation decay below are not exactly the ones from Aram’s lecture. These definitions are from <a href="https://windowsontheory.org/feed/#martinelli1">[5]</a> and <a href="https://windowsontheory.org/feed/#martinelli2">[6]</a>.)</p>



<p>For non-empty <img src="https://s0.wp.com/latex.php?latex=W+%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W \subseteq V" class="latex" title="W \subseteq V" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau \in \Sigma^{V\setminus W}" class="latex" title="\tau \in \Sigma^{V\setminus W}" /> , let <img src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_W^\tau" class="latex" title="\mu_W^\tau" /> be the distribution of the spins in <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> conditional on the spins in <img src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V \setminus W" class="latex" title="V \setminus W" /> being fixed to <img src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau" class="latex" title="\tau" /> . For <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> , let <img src="https://s0.wp.com/latex.php?latex=%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_{W,\Delta}^\tau" class="latex" title="\mu_{W,\Delta}^\tau" /> be the marginal of <img src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_W^\tau" class="latex" title="\mu_W^\tau" /> on the spins in <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> . We will assume that the interactions between the spins have finite range <img src="https://s0.wp.com/latex.php?latex=r+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r &gt; 0" class="latex" title="r &gt; 0" /> , and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial_r+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial_r W" class="latex" title="\partial_r W" /> denotes the <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> -boundary of <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> , i.e., <img src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%5Cin+V+%5Csetminus+W+%3A+%5C%3B%5Cmathrm%7Bdist%7D%28v%2CW%29+%5Cle+r%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" class="latex" title="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" /> .</p>



<ul><li>(<strong>Weak decay of correlations</strong>) Weak spatial mixing holds for <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> if there exist constants <img src="https://s0.wp.com/latex.php?latex=C%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C, \xi &gt; 0" class="latex" title="C, \xi &gt; 0" /> such that for any subset <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Csum_%7Bx%5Cin%5CDelta%2C+%5C%3B+y+%5Cin+%5Cpartial_r+W%7D+%5Cexp%5CBigl%28-+%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28x%2Cy%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." class="latex" title="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." /></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing holds for <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> if there exist constants <img src="https://s0.wp.com/latex.php?latex=C%2C%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C,\xi &gt; 0" class="latex" title="C,\xi &gt; 0" /> such that for every <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> and every <img src="https://s0.wp.com/latex.php?latex=%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau,\tau' \in \Sigma^{V\setminus W}" class="latex" title="\tau,\tau' \in \Sigma^{V\setminus W}" /> differing only at site <img src="https://s0.wp.com/latex.php?latex=y+%5Cin+V%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y \in V\setminus W" class="latex" title="y \in V\setminus W" /> , <img src="https://s0.wp.com/latex.php?latex=%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Cexp%5CBigl%28-%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28y%2C%5CDelta%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." class="latex" title="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." /></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing in the <em>truncated</em> sense holds for <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> if there exist <img src="https://s0.wp.com/latex.php?latex=n%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n, \xi &gt; 0" class="latex" title="n, \xi &gt; 0" /> such that for all functions <img src="https://s0.wp.com/latex.php?latex=f%2C+g+%3A+%5COmega+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f, g : \Omega \to {\mathbb R}" class="latex" title="f, g : \Omega \to {\mathbb R}" /> which depend only on the sites at <img src="https://s0.wp.com/latex.php?latex=%5CLambda_f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Lambda_f" class="latex" title="\Lambda_f" /> and <img src="https://s0.wp.com/latex.php?latex=%5CLambda_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Lambda_g" class="latex" title="\Lambda_g" /> respectively and such that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28%5CLambda_f%2C%5CLambda_g%29+%5Cge+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" class="latex" title="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D+%5C%3B%5Cmathrm%7Bcov%7D_%7B%5Cmu_W%5E%5Ctau%7D%28f%2C+g%29+%5Cle+%7C%5CLambda_f%7C%7C%5CLambda_g%7C%5C%7Cf%5C%7C_%5Cinfty+%5C%7Cg%5C%7C_%5Cinfty+%5Cexp%5CBigl%28-%5Cfrac%7Bd%28%5CLambda_f%2C%5CLambda_g%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." class="latex" title="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." /></li></ul>



<p>Here, <img src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\xi" class="latex" title="\xi" /> is the <strong>correlation length</strong> (in physics, it is the characteristic length scale of a system). In the disordered phase, the correlation length is a constant independent of system size. For our purposes, the main consequence of these definitions is that the effective interaction range of each spin is <img src="https://s0.wp.com/latex.php?latex=O%28%5Cxi%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\xi)" class="latex" title="O(\xi)" /> . For the Ising model, there is a key simplification due to <em>monotonicity</em>. Namely, the ferromagnetic Ising model has the nice property (which is not true for other models) that if we flip a sign from <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> , this only makes <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> more likely everywhere. This is because the spins want to agree. There are a lot of boundary conditions to consider, but here, due to monotonicity, we only need to consider two: all of the spins are <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> , and all of the spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . All <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spins will give the highest probability of a <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spin, and all <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> spin will give the lowest probability of a <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spin. This monotonicity property is generally not required for time-space mixing equivalence to hold, but it greatly simplifies proofs.</p>



<p>It is a very non-obvious fact that all of these notions of spatial mixing are equivalent. We will sketch a proof that strong correlation decay implies that <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D+%3D+O%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix} = O(n\log n)" class="latex" title="t_{\rm mix} = O(n\log n)" /> .</p>



<p>The idea is to use another coupling argument. Let <img src="https://s0.wp.com/latex.php?latex=X%280%29%2C+Y%280%29+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5EV&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0), Y(0) \in {\{\pm 1\}}^V" class="latex" title="X(0), Y(0) \in {\{\pm 1\}}^V" /> differ in one coordinate, i.e., <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_a \ne {Y(0)}_a" class="latex" title="{X(0)}_a \ne {Y(0)}_a" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_i+%3D+%7BY%280%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_i = {Y(0)}_i" class="latex" title="{X(0)}_i = {Y(0)}_i" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \ne a" class="latex" title="i \ne a" /> . We want to argue that the expected distance between the processes will decrease. The proof uses a generalization of Glauber dynamics called <strong>block Glauber dynamics</strong>. In Glauber dynamics, we take a single spin and resample it conditioned on its neighbors. In block Glauber dynamics, we take an <img src="https://s0.wp.com/latex.php?latex=L%5Ctimes+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L\times L" class="latex" title="L\times L" /> box and resample it conditioned on its neighbors. There is an argument, called <em>canonical paths</em>, which can be used to show that if block Glauber dynamics mixes, then regular Glauber dynamics also mixes (slightly more slowly; we lose a <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bpoly%7D%28L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{poly}(L)" class="latex" title="\;\mathrm{poly}(L)" /> factor, but anyway <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> will be a large constant) so analyzing block Glauber dynamics is fine.</p>



<p>If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> lies in the box, then the expected change in distance is <img src="https://s0.wp.com/latex.php?latex=-L%5E2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-L^2/n" class="latex" title="-L^2/n" /> . If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> is far away from the box, then there is no change. If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> is in the boundary of the box, then it is possible for the distance to increase. However, strong spatial mixing allows us to control the influence of a single site, so the expected change in distance is bounded by <img src="https://s0.wp.com/latex.php?latex=O%28L%5Cxi%5E2%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(L\xi^2/n)" class="latex" title="O(L\xi^2/n)" /> . Now, since <img src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\xi" class="latex" title="\xi" /> is a constant, if we choose <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> sufficiently large, then we will have the same situation as in the high temperature case: the expected distance will exponentially shrink over time.</p>



<h1 id="quantum-systems">Quantum systems</h1>



<p>The quantum version of Markov chains has many more difficulties. The first difficulty is that the Hammersley-Clifford theorem (which we have been relying on throughout this blog post) fails.</p>



<h2 id="notation">Notation</h2>



<p>To properly discuss what we mean, let’s set up some notation. Readers already familiar with density matrices, quantum entropy, and quantum mutual information may wish to skip to the next subsection. Most of the time we discuss quantum objects here, we’ll be using density matricies, often denoted <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> . A density matrix can be thought of as an extension to regular quantum states <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle " class="latex" title="|{\psi}\rangle " /> , where there is some classical source of uncertainty.</p>



<p>A density matrix is a positive semidefinite matrix with trace <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . This extends the notion of a classical probability distribution; in the quantum setting, a classical probability distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> (thought of as a vector whose entries sum to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> ) is represented as the density matrix <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{diag}(p)" class="latex" title="\;\mathrm{diag}(p)" /> .</p>



<p>For example, we can consider a situation in which there is a <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> probability that we started with the quantum state <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle " class="latex" title="|{\psi}\rangle " /> and a <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> probability that we started with the quantum state <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cphi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\phi}\rangle " class="latex" title="|{\phi}\rangle " /> . This would be denoted as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5Clangle%7B%5Cpsi%7D%7C+%2B+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle+%5Clangle%7B%5Cphi%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " class="latex" title="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " /> </p>



<p>Density matricies are generally useful for a lot of tasks, but for our purposes a density matrix will be used to discuss both the classical and quantum “uncertainty” we have about what state we have.</p>



<p>Now let’s also talk about a second important piece of notation: the tensor product. Often when discussing quantum states, it is important to discuss multiple quantum states simultaneously. For example, Alice has one system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and Bob has another system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . However, these systems might be entangled, meaning that the results of the two systems are correlated.</p>



<p>For instance, let us consider the following state:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+_A+%7C%7B%2B%7D%5Crangle+_B+%2B+%7C%7B-%7D%5Crangle+_A+%7C%7B-%7D%5Crangle+_B+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" class="latex" title="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" /> </p>



<p>This particular state has the property that Alice and Bob will always both measure <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> or they will both measure <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> . The notation for tensors is often ambiguous in the literature as there are many ways of specifying tensors. For instance, above we used subscripts to explicitly denote which particle was in system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and which was in system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . One may also choose to simply use the index of the system as below. The symbol <img src="https://s0.wp.com/latex.php?latex=%5Cotimes&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\otimes" class="latex" title="\otimes" /> is used to denote a tensor between states (where it is assumed that the first state is system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and the second, system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> ). Gradually folks may shorten the notation as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+%7C%7B%2B%7D%5Crangle+%2B+%7C%7B-%7D%5Crangle+%7C%7B-%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bpmatrix%7D+1%5C%5C0+%5Cend%7Bpmatrix%7D+%5Cotimes+%5Cbegin%7Bpmatrix%7D+0%5C%5C1+%5Cend%7Bpmatrix%7D+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " class="latex" title="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " /> </p>



<p>These are all notations for the same state. Let’s now talk about this state in the context of a density matrix. The density matrix of this state is as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29+%5Cleft%28+%5Clangle%7B%2B%2B%7D%7C+%2B+%5Clangle%7B--%7D%7C+%5Cright%29%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1%260%260%261%5C%5C0%260%260%260%5C%5C0%260%260%260%5C%5C1%260%260%261+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " class="latex" title="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " /> </p>



<p>Writing the density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> as <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B}" class="latex" title="\rho_{A,B}" /> makes explicit that this is the density matrix over systems <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> .</p>



<p>A crucial operation that one will often perform using density matricies is the partial trace. The partial trace is a way of allowing us to consider only a smaller part of the larger part of the system, while taking into account the influence of the larger system around it.</p>



<p>Here’s an example: Suppose Bob wants to know what his state is. However, Bob really doesn’t care about Alice’s system and just wants to know what the density matrix for his system is. Bob’s density matrix is simply the following density matrix (a 50% chance of being in <img src="https://s0.wp.com/latex.php?latex=%7C%7B%2B%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{+}\rangle " class="latex" title="|{+}\rangle " /> and a 50% chance of being in <img src="https://s0.wp.com/latex.php?latex=%7C%7B-%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{-}\rangle " class="latex" title="|{-}\rangle " /> ).</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+%5Clangle%7B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+%5Clangle%7B-%7D%7C+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " class="latex" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " /> </p>



<p>More explicitly, we could write the following:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " class="latex" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " /> </p>



<p>The partial trace is an operation that will let us take our original density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B}" class="latex" title="\rho_{A,B}" /> and generates a new density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_B" class="latex" title="\rho_B" /> that ignores system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> . This is specifically called the partial trace over <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , or <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}_A" class="latex" title="\;\mathrm{tr}_A" /> .</p>



<p>So how do we do this? We simply sum over the state <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> (effectively taking a trace, but only along one axis):</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Csum_i+%5Clangle%7Bi%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7Bi%7D%5Crangle+_A%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " class="latex" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " /> </p>



<p>This is easier to evaluate using certain choices of notation:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Clangle%7B%2B%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%5C%5C%26%5Cqquad+%7B%7D%2B+%5Clangle%7B-%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%5Cright%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Crho_B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " class="latex" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " /> </p>



<p>This gives us the answer that we had expected.</p>



<p>We now have all of the tools we need to talk about quantum entropy. Intuitively, entropy can be thought of as the amount of uncertainty we have for our system, or equivalently the amount of information it takes to define our system. The entropy for a quantum system <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is defined as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H%28%5Crho%29+%26%3D+-%5C%3B%5Cmathrm%7Btr%7D%28%5Crho+%5Clog_2+%5Crho%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " class="latex" title="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " /> </p>



<p>Note that here we use the shorthand <img src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_B" class="latex" title="\rho_B" /> to denote <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}_A \rho_{A,B}" class="latex" title="\;\mathrm{tr}_A \rho_{A,B}" /> . Here, writing <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}" class="latex" title="\;\mathrm{tr}" /> without the subscript indicates that this is the full or normal trace that one might expect (or equivalently performing the partial trace over all systems). We can now define the conditional entropy of a system as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BH%28A+%5Cmid+B%29%7D_%5Crho+%26%3D+H%28%5Crho_%7BA%2CB%7D%29+-+H%28%5Crho_B%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " class="latex" title="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " /> </p>



<p>This definition intuitively makes sense since we can think of conditional entropy as the amount of information it takes to describe our joint system <img src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A,B)" class="latex" title="(A,B)" /> , given that we already know what <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> is.</p>



<p>We can now discuss quantum mutual information, the amount of information that measuring system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> will provide you about system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . Like the classical case, this is defined as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB%29%7D_%5Crho+%26%3D+%7BH%28A%2CB%29%7D_%5Crho+-+%7BH%28A%5Cmid+B%29%7D_%5Crho+-+%7BH%28B%5Cmid+A%29%7D_%5Crho%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " class="latex" title="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " /> </p>



<p>We can now finally discuss <strong>quantum mutual information (QCMI)</strong>, defined as follows: <img src="https://s0.wp.com/latex.php?latex=%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%3D+%7BI%28A%3BB%2CC%29%7D_%5Crho+-+%7BI%28A%3BC%29%7D_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" class="latex" title="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" /> . With some algebraic simplifications, one can arrive at the expression:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%26%3D+%7BH%28A%2CC%29%7D_%5Crho+%2B+%7BH%28B%2CC%29%7D_%5Crho+-+%7BH%28A%2CB%2CC%29%7D_%5Crho+-+%7BH%28C%29%7D_%5Crho.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " class="latex" title="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " /> </p>



<p>The QCMI equals <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is a <strong>quantum Markov state</strong>. Classically, the entropic characterization of conditional independence corresponds to an algebraic characterization.</p>



<h2 id="recovery-maps">Recovery Maps</h2>



<p>Here, the algebraic characterization is more grueling. We have</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Cexp%28%5Clog+%5Crho_%7BAB%7D+%2B+%5Clog+%5Crho_%7BBC%7D+-+%5Clog+%5Crho_B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" class="latex" title="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" /> </p>



<p>Equivalently,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BBC%7D%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%3D+R_%7BB%5Cto+AB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" class="latex" title="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" /> </p>



<p>Here, <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+AB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to AB}" class="latex" title="R_{B\to AB}" /> is called the <strong>Petz recovery map</strong>,<sup><a href="https://windowsontheory.org/feed/#fn_4">4</a></sup> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BB%5Cto+AB%7D%28X%29+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+X%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" class="latex" title="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" /> . One can think of a recovery may as a way that we can reconstruct the entire system <img src="https://s0.wp.com/latex.php?latex=A%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A, B" class="latex" title="A, B" /> using just system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . It is not obvious that this is a quantum channel, but it is.</p>



<p>Suppose <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is a probability distribution, so <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho =\;\mathrm{diag}(p)" class="latex" title="\rho =\;\mathrm{diag}(p)" /> for some vector <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> . Then, all of the density matrices are diagonal and commuting. Then, the recovery map means that we divide by <img src="https://s0.wp.com/latex.php?latex=p_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_B" class="latex" title="p_B" /> and multiply by <img src="https://s0.wp.com/latex.php?latex=p_%7BAB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{AB}" class="latex" title="p_{AB}" /> , i.e., multiply by <img src="https://s0.wp.com/latex.php?latex=p_%7BA+%5Cmid+B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{A \mid B}" class="latex" title="p_{A \mid B}" /> . This is the natural thing to do if we lost our information about <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and were trying to figure out what <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> was based on our knowledge of <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . This is why <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to A,B}" class="latex" title="R_{B\to A,B}" /> is known as a <em>recovery</em> map, and it is used to discuss conditional distributions in the quantum setting. In the classical case, if we start with <img src="https://s0.wp.com/latex.php?latex=B%2C+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B, C" class="latex" title="B, C" /> , look only at <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , and use this to reconstruct <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , then we would have the whole state in a Markov chain. That is why this is a plausible quantum version of being a Markov chain.</p>



<p>However, quantum Gibbs states are not, in general, quantum Markov chains. The failure of this statement to hold is related to <em>topological order</em>, which is similar to the degrees of freedom that show up in error correcting codes.</p>



<h2 id="quantum-markov-networks">Quantum Markov Networks</h2>



<p>Here, we will formally define a quantum Markov network. The reference for this is <a href="https://windowsontheory.org/feed/#leifer">[7]</a>.</p>



<p>Let <img src="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G = (V, E)" class="latex" title="G = (V, E)" /> be a finite graph. We associate with each vertex <img src="https://s0.wp.com/latex.php?latex=v+%5Cin+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v \in V" class="latex" title="v \in V" /> a Hilbert space <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{H}}_v" class="latex" title="{\mathcal{H}}_v" /> and we consider a density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> acting on <img src="https://s0.wp.com/latex.php?latex=%5Cbigotimes_%7Bv%5Cin+V%7D+%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bigotimes_{v\in V} {\mathcal{H}}_v" class="latex" title="\bigotimes_{v\in V} {\mathcal{H}}_v" /> . Then, <img src="https://s0.wp.com/latex.php?latex=%28G%2C+%5Crho_V%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(G, \rho_V)" class="latex" title="(G, \rho_V)" /> is a <strong>quantum Markov network</strong> if for all <img src="https://s0.wp.com/latex.php?latex=U%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\subseteq V" class="latex" title="U\subseteq V" /> , <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> is conditionally independent of <img src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V \setminus (U \cup \partial U)" class="latex" title="V \setminus (U \cup \partial U)" /> given <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial U" class="latex" title="\partial U" /> , where the conditional independence statement is w.r.t. <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> and means that the corresponding QCMI satisfies <img src="https://s0.wp.com/latex.php?latex=%7BI%28U%3B+V%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29+%5Cmid+%5Cpartial+U%29%7D_%7B%5Crho_V%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" class="latex" title="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" /> .</p>



<p>A quantum Markov network is called <strong>positive</strong> if <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> has full rank. (Recall that in the statement of the Hammersley-Clifford Theorem, , it is assumed that the distribution is strictly positive.)</p>



<p>Now, consider the following example. First, we introduce the Pauli matrices</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csigma%5Ex+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ez+%3A%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+-1+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ey+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+-i+%5C%5C+i+%26+0+%5Cend%7Bbmatrix%7D.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " class="latex" title="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " /> </p>



<p>We define a Hamiltonian on three qubits <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> by</p>



<p> <img src="https://s0.wp.com/latex.php?latex=H+%3A%3D+%28%5Csigma_A%5Ex+%5Csigma_B%5Ex+%2B+%5Csigma_A%5Ey+%5Csigma_B%5Ey+%2B+%5Csigma_A%5Ez+%5Csigma_B%5Ez%29+I_C+%2B+I_A+%28%5Csigma_B%5Ex+%5Csigma_C%5Ex+%2B+%5Csigma_B%5Ey+%5Csigma_C%5Ey+%2B+%5Csigma_B%5Ez+%5Csigma_C%5Ez%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" class="latex" title="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" /> </p>



<p>(Juxtaposition in the above expression signifies the tensor product as discussed before.) Finally, for <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta &gt; 0" class="latex" title="\beta &gt; 0" /> , we define the Gibbs state</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D%28%5Cbeta%29+%3A%3D+%5Cfrac%7B1%7D%7BZ%28%5Cbeta%29%7D+%5Cexp%28-%5Cbeta+H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" class="latex" title="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" /> </p>



<p>The Hamiltonian here has local terms which correspond to interactions <img src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A,B)" class="latex" title="(A,B)" /> , <img src="https://s0.wp.com/latex.php?latex=%28B%2C+C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(B, C)" class="latex" title="(B, C)" /> . However, it can be shown that the QCMI between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> conditioned on <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> w.r.t. <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B,C}" class="latex" title="\rho_{A,B,C}" /> is non-zero, which means that this is not a quantum Markov network w.r.t. the line graph <img src="https://s0.wp.com/latex.php?latex=A+%5Cleftrightarrow+B+%5Cleftrightarrow+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A \leftrightarrow B \leftrightarrow C" class="latex" title="A \leftrightarrow B \leftrightarrow C" /> . This demonstrates the failure of the Hammersley-Clifford Theorem in the quantum setting.</p>



<h2 id="important-results">Important Results</h2>



<p>We will briefly discuss the results of two papers.</p>



<ol><li><a href="https://windowsontheory.org/feed/#brandao1">[8]</a> This paper shows that mixing in space implies mixing in time in the quantum case. However, the result of the paper only applies to commuting Hamiltonians. For commuting Hamiltonians, it turns out that quantum Gibbs states are quantum Markov networks. They use a version of Glauber dynamics, which can be simulated on a quantum computer but are also plausible dynamics for a physical system in nature. This is a difficult paper to read, but it is worth digesting if you want to work in the field.</li><li><a href="https://windowsontheory.org/feed/#brandao2">[9]</a> This second paper is much easier and more general, covering non-commuting Hamiltonians, but it requires more conditions. They give a method of preparing the Gibbs state which can run on a quantum computer, but the dynamics are not plausible as a physical system because they are too complicated. The more complicated dynamics allows them to make the proof work. The paper also uses QCMI.They have two assumptions. The first assumption looks like mixing in space (weak correlation decay). The second assumption is that the state looks approximately like a quantum Markov network (this is definitely not met in general). A very important paper in this space is a recent breakthrough (<a href="https://windowsontheory.org/feed/#fawzi">[10]</a>) which characterizes quantum Markov chains. They show that if the QCMI is bounded by <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> , then the recovery map <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to A,B}(\rho_{BC})" class="latex" title="R_{B\to A,B}(\rho_{BC})" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon'" class="latex" title="\epsilon'" /> -close to <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC}" class="latex" title="\rho_{ABC}" /> , i.e., low QCMI implies that the recovery map works well. This is trivial to prove classically, but very difficult in the quantum world.The algorithm in <a href="https://windowsontheory.org/feed/#brandao2">[9]</a> is very elegant. Essentially, we take the entire system and punch out constant-sized boxes. If we can reconstruct the region outside of the boxes, then we can use the recovery maps to reconstruct the regions inside of the boxes, and the boxes are far apart enough so they are almost independent. For this argument, we must assume that the QCMI decays exponentially. Whenever we have exponential decay, we get a correlation decay that sets the size of the boxes. It is very difficult to condition on quantum states, but recovery maps provide a sense in which it is meaningful to do so. The paper gives an efficient method of preparing Gibbs states and simulating quantum systems on quantum computers.</li></ol>



<h1 id="additional-reading">Additional reading</h1>



<p>The standard treatment of information theory is <a href="https://windowsontheory.org/feed/#info">[11]</a>. This book contains definitions and properties of entropy, conditional entropy, mutual information, and conditional mutual information.</p>



<p>To see a treatment of the subject of Markov chains from the perspective of probability theory, see <a href="https://windowsontheory.org/feed/#durrett1">[12]</a> or the mathematically more sophisticated counterpart <a href="https://windowsontheory.org/feed/#durrett2">[13]</a>. An introduction to coupling can be found in <a href="https://windowsontheory.org/feed/#mitzenmacher">[14]</a>, as well as <a href="https://windowsontheory.org/feed/#nature">[4]</a> (the latter also contains an exposition to spatial mixing). The connection between Markov chain mixing and the so-called <em>logarithmic Sobolev inequality</em> is described in <a href="https://windowsontheory.org/feed/#cesi">[15]</a>.</p>



<h1 id="scn:appendix">Appendix: Intuition for Markov chains</h1>



<h2 id="random-walk-on-the-cycle">Random walk on the cycle</h2>



<p>We have <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points on the cycle, <img src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0,1,\dotsc,n-1" class="latex" title="0,1,\dotsc,n-1" /> . At each step, we move left or right with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> . We can write the transition matrix as</p>



<p> <img src="https://s0.wp.com/latex.php?latex=T+%3D+%5Cfrac%7BS+%2B+S%5E%7B-1%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T = \frac{S + S^{-1}}{2}" class="latex" title="T = \frac{S + S^{-1}}{2}" /> </p>



<p>where <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> is the shift operator <img src="https://s0.wp.com/latex.php?latex=S+%7C%7Bx%7D%5Crangle+%3D+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S |{x}\rangle = |{x+1 \bmod n}\rangle " class="latex" title="S |{x}\rangle = |{x+1 \bmod n}\rangle " /> . The matrix <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> is diagonalized by the Fourier transform. Define, for <img src="https://s0.wp.com/latex.php?latex=k%3D0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=0,1,\dotsc,n-1" class="latex" title="k=0,1,\dotsc,n-1" /> ,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Ctilde+k%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " class="latex" title="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " /> </p>



<p>We have the same amount of amplitude at every point, but there is a varying phase which depends on <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> . If <img src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 0" class="latex" title="k = 0" /> , we get the all-ones vector. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is small, then the phase is slowly varying. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is large, then the phase is rapidly varying. Look at what happens after we apply the shift operator:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+S+%7C%7B%5Ctilde+k%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D1%7D%5En+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+%28x-1%29%7D%7Bn%7D+%5CBigr%29+%7C%7Bx+%5Cbmod+n%7D%5Crangle+%3D+%5Cexp%5CBigl%28-+%5Cfrac%7B2%5Cpi+i+k%7D%7Bn%7D+%5CBigr%29+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " class="latex" title="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " /> </p>



<p>After the shift, we pick up an additional phase based on how rapidly the phase is varying. From this, we get:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%26%3D+%5Cfrac%7B%5Cexp%282%5Cpi+i+k+%2F+n%29+%2B+%5Cexp%28-2%5Cpi+i+k+%2F+n%29%7D%7B2%7D+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Ccos%5CBigl%28%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%5CBigr%29+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " class="latex" title="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " /> </p>



<p>The eigenvalues are</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%3D+%5Ccos+%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%2C+%5Cqquad+k%3D0%2C1%2C%5Cdotsc%2Cn-1.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." class="latex" title="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." /> </p>



<p>Only <img src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 0" class="latex" title="k = 0" /> will give me an eigenvalue of <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> .</p>



<p>How do we analyze <img src="https://s0.wp.com/latex.php?latex=T%5Et+%7C%7Bp%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t |{p}\rangle " class="latex" title="T^t |{p}\rangle " /> ? We should Fourier transform the distribution.</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T%5Et+%7C%7Bp%7D%5Crangle+%3D+T%5Et+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%5Clambda_k%5Et+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" class="latex" title="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" /> </p>



<p>If <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is odd, then as <img src="https://s0.wp.com/latex.php?latex=t%5Crightarrow%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\rightarrow\infty" class="latex" title="t\rightarrow\infty" /> , <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k%5Et+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_k^t \to 0" class="latex" title="\lambda_k^t \to 0" /> for all <img src="https://s0.wp.com/latex.php?latex=k%3D1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=1,\dotsc,n-1" class="latex" title="k=1,\dotsc,n-1" /> , so <img src="https://s0.wp.com/latex.php?latex=T%5Et+%5Cto+%7C%7B%5Cpi%7D%5Crangle+%5Clangle%7B1_n%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t \to |{\pi}\rangle \langle{1_n}| " class="latex" title="T^t \to |{\pi}\rangle \langle{1_n}| " /> . Whatever you put into this operator, you get <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> out.</p>



<h2 id="spectral-gap">Spectral gap</h2>



<p>The example of the random walk on the cycle shows that there is generally a unique stationary distribution and suggests that the speed of convergence is determined by how close the other eigenvalues are to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . Specifically, suppose for simplicity that the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> are <img src="https://s0.wp.com/latex.php?latex=1+%3D+%5Clambda_0+%5Cge+%5Clambda_1%5Cge%5Ccdots+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" class="latex" title="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" /> (real and positive). Then, the convergence time is on the order of <img src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sim 1/(1-\lambda_1)" class="latex" title="\sim 1/(1-\lambda_1)" /> .</p>



<p>Typically, the distance of the eigenvalues from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> reflects the size of the physical system. Even from the simple example, we can get some physical intuition from this. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is small, then the spectral gap is <img src="https://s0.wp.com/latex.php?latex=%5Ccos%282%5Cpi+k%2Fn%29+%3D+1-O%28k%5E2%2Fn%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cos(2\pi k/n) = 1-O(k^2/n^2)" class="latex" title="\cos(2\pi k/n) = 1-O(k^2/n^2)" /> . Thus, the convergence time is <img src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29+%5Csim+n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sim 1/(1-\lambda_1) \sim n^2" class="latex" title="\sim 1/(1-\lambda_1) \sim n^2" /> , which is indeed the convergence time for a random walk on a cycle.</p>



<h2 id="references">References</h2>



<hr class="wp-block-separator" />



<ol><li>S. Gharibian, Y. Huang, Z. Landau, and S. W. Shin, “Quantum Hamiltonian complexity,” <em>Found. Trends Theor. Comput. Sci.</em>, vol. 10, no. 3, pp. front matter, 159–282, 2014. </li><li>R. W. Keener, <em>Theoretical statistics</em>. Springer, New York, 2010, p. xviii+538. </li><li>E. Crosson, D. Bacon, and K. R. Brown, “Making Classical Ground State Spin Computing Fault-Tolerant,” <em>Physical Review E</em>, vol. 82, no. 3, Sep. 2010. </li><li>C. Moore and S. Mertens, <em>The nature of computation</em>. Oxford University Press, Oxford, 2011, p. xviii+985. </li><li>F. Martinelli, “Lectures on Glauber dynamics for discrete spin models,” in <em>Lectures on probability theory and statistics (Saint-Flour, 1997)</em>, vol. 1717, Springer, Berlin, 1999, pp. 93–191. </li><li>F. Martinelli and E. Olivieri, “Finite volume mixing conditions for lattice spin systems and exponential approach to equilibrium of Glauber dynamics,” in <em>Cellular automata and cooperative systems (Les Houches, 1992)</em>, vol. 396, Kluwer Acad. Publ., Dordrecht, 1993, pp. 473–490. </li><li>M. S. Leifer and D. Poulin, “Quantum graphical models and belief propagation,” <em>Ann. Physics</em>, vol. 323, no. 8, pp. 1899–1946, 2008. </li><li>M. J. Kastoryano and F. G. S. L. Brandão, “Quantum Gibbs samplers: the commuting case,” <em>Comm. Math. Phys.</em>, vol. 344, no. 3, pp. 915–957, 2016. </li><li>F. G. S. L. Brandão and M. J. Kastoryano, “Finite correlation length implies efficient preparation of quantum thermal states,” <em>ArXiv e-prints</em>, Sep. 2016. </li><li>O. Fawzi and R. Renner, “Quantum conditional mutual information and approximate Markov chains,” <em>Comm. Math. Phys.</em>, vol. 340, no. 2, pp. 575–611, 2015. </li><li>T. M. Cover and J. A. Thomas, <em>Elements of information theory</em>, Second. Wiley-Interscience [John Wiley &amp; Sons], Hoboken, NJ, 2006, p. xxiv+748. </li><li>R. Durrett, <em>Essentials of stochastic processes</em>. Springer, Cham, 2016, p. ix+275. </li><li>R. Durrett, <em>Probability: theory and examples</em>, Fourth., vol. 31. Cambridge University Press, Cambridge, 2010, p. x+428. </li><li>M. Mitzenmacher and E. Upfal, <em>Probability and computing</em>, Second. Cambridge University Press, Cambridge, 2017, p. xx+467. </li><li>F. Cesi, “Quasi-factorization of the entropy and logarithmic Sobolev inequalities for Gibbs random fields,” <em>Probab. Theory Related Fields</em>, vol. 120, no. 4, pp. 569–584, 2001. </li></ol>



<hr class="wp-block-separator" />



<ol><li>This is the opposite of the probabilists’ convention, i.e., the transition probability matrix that we define here is the <em>transpose</em> of the one usually found in most probability theory textbooks. <a href="https://windowsontheory.org/feed/#fnref_1"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>As a side note, it may be a good research question to investigate to what extent quantum algorithms can be used to compute summations whose terms are possibly negative. In quantum Monte Carlo, the quantum Hamiltonian is converted to a classical energy function; this conversion always works, but sometimes you end up with complex energies, which is terrible for estimating the partition function because terms can cancel each other out. <a href="https://windowsontheory.org/feed/#fnref_2"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>You may recognize this as the total variation norm. <a href="https://windowsontheory.org/feed/#fnref_3"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>Petz wrote about quantum relative entropy in 1991, way before it was cool. <a href="https://windowsontheory.org/feed/#fnref_4"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li></ol></div>







<p class="date">
by wsmoses <a href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/"><span class="datestr">at December 20, 2018 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/">Theory Blog Aggregator Up!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The <strong>Theory of Computing Blog Aggregator</strong> is now back online at a new website: <a href="http://cstheory-feed.org/" rel="nofollow">http://cstheory-feed.org/</a> . There is also a twitter feed at <a href="https://twitter.com/cstheory" rel="nofollow">https://twitter.com/cstheory</a> .</p>
<p>See <a href="http://blog.geomblog.org/2018/12/the-theorycs-blog-aggregator-reborn.html">this blog post</a> by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to thank Arvind Narayanan who created the software to run it and maintained it all these years.</p>
<p>If you don’t want to rely on the aggregator to follow windows on theory, you can use the <strong>“Follow Blog by email”</strong> button on our side bar, and join the 590 other happy customers who don’t need to wait to the feed to get the <a href="https://windowsontheory.org/category/physics/">latest lecture notes</a> from our physics and computation seminar.</p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/"><span class="datestr">at December 20, 2018 09:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6358">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">What is Quantum Hamiltonian Complexity?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>by Ben Edelman</strong></p>
<p><em>This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. The second installment is <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">here</a>, and the third installment is <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">here</a>.</em></p>
<p>Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both physics and computation. Our hope is that these three posts will provide an accessible (and incomplete) preview of the subject for readers who know the basics of theoretical computer science and quantum information. Much of the material is adapted from an <a href="https://arxiv.org/abs/1401.3916">excellent survey by Gharibian et al.</a>.</p>
<p>In a nutshell, quantum Hamiltonian complexity is the study of the <em>local Hamiltonian problem</em>. Why is this problem important enough to justify the existence of an entire subfield? To illustrate why, here are two informal characterizations of it:</p>
<ol>
<li>To a <strong>physicist</strong>, the local Hamiltonian problem is a formalization of the difficulty of simulating and understanding many-particle quantum systems. There are deep connections between the complexity of this problem and the amount of quantum entanglement in a system. In practical terms, physicists would love to be able to solve this problem on a regular basis, and they’ve developed a rich theory of heuristics to that end.</li>
<li>To a <strong>computer scientist</strong>, local Hamiltonian problem is the quantum version of constraint satisfaction problems. Any CSP can be written as a local Hamiltonian problem; and just as constraint satisfaction is the prototypical NP-complete problem by the Cook-Levin theorem, the local Hamiltonian problem plays the equivalent role for QMA (a quantum analogue of NP) by the “quantum Cook-Levin theorem.” The connections to classical complexity go on… there is even a <a href="https://arxiv.org/pdf/1309.7495.pdf">quantum PCP conjecture</a>!</li>
</ol>
<p>But let’s take a step back and start at the beginning. To make sure we understand what a quantum Hamiltonian is and why it is important, it will be instructive to briefly rehash some of the <a href="https://windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">fundamentals of classical statistical mechanics</a>.</p>
<h2>Classical energy and ground states</h2>
<p>In the classical world, a physical system can be in any one of various states <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in \mathcal{X}" class="latex" title="x \in \mathcal{X}" />, each of which is a vector, with different coordinates representing different particles. Every state of the system has an <em>energy</em>, given by an energy function <img src="https://s0.wp.com/latex.php?latex=E%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E: \mathcal{X} \to \mathbb{R}" class="latex" title="E: \mathcal{X} \to \mathbb{R}" />. For example, in the classic Ising model of ferromagnetism, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D+%3D+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{X} = \{\pm 1\}^n" class="latex" title="\mathcal{X} = \{\pm 1\}^n" />. Each coordinate <img src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_i" class="latex" title="x_i" /> represents the spin of atom <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, and atoms <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> interact with each other whenever <img src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(i,j)" class="latex" title="(i,j)" /> is an edge in a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, which is usually a low-dimensional lattice. Energy for this system is defined as <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7B%28i%2Cj%29+%5Cin+G%7D-x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = \sum_{(i,j) \in G}-x_i x_j" class="latex" title="E(x) = \sum_{(i,j) \in G}-x_i x_j" />.</p>
<p>Suppose we ignore our system for a long time, letting it interact with its external environment until, in the limit, it reaches thermal equilibrium at temperature <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. Then the probability the system is in state <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> is given by Boltzmann’s distribution: <img src="https://s0.wp.com/latex.php?latex=%5CPr%5Bx%5D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+E%28x%29%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" class="latex" title="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cpropto+1%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta \propto 1/T" class="latex" title="\beta \propto 1/T" /> and <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> is the partition function required to normalize the probabilities. As the temperature tends to infinity, this distribution will approach the uniform distribution over <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{X}" class="latex" title="\mathcal{X}" />, and as the temperature tends to absolute zero, the distribution will approach the uniform distribution over the states with minimum energy. We call these minimum energy states <em>ground states</em>, and we call their energy the <em>ground state energy</em>. If we want to calculate something about a system, then it is often crucial to know the ground states and ground state energy of the system. Going back to our example, the Ising model has two ground states whenever <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is connected. These are the states <img src="https://s0.wp.com/latex.php?latex=%28%2B1%2C%2B1%2C%5Cldots%2C%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(+1,+1,\ldots,+1)" class="latex" title="(+1,+1,\ldots,+1)" /> and <img src="https://s0.wp.com/latex.php?latex=%28-1%2C-1%2C%5Cldots%2C-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(-1,-1,\ldots,-1)" class="latex" title="(-1,-1,\ldots,-1)" /> in which all atoms have the same spin. The ground state energy is <img src="https://s0.wp.com/latex.php?latex=-%7C%5C%7Bi%2Cj%3A%28i%2Cj%29+%5Cin+G%5C%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-|\{i,j:(i,j) \in G\}|" class="latex" title="-|\{i,j:(i,j) \in G\}|" />.</p>
<h2>Quantum Hamiltonians</h2>
<p>A quantum Hamiltonian is essentially the quantum analogue of the classical energy function. Unlike with classical systems, when a quantum system is in a given <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%5Cright%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi\right\rangle" class="latex" title="\left|\psi\right\rangle" />, it doesn’t have a determinate energy. Instead, when we measure the energy, the value we obtain may be probabilistic and will correspond to one of the eigenvalues of the observable matrix for energy. This Hermitian matrix, denoted <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" />, is the quantum Hamiltonian, and just as the energy function characterizes a classical system, the Hamiltonian characterizes a quantum system. For a given eigenvector <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_i\rangle" class="latex" title="|\lambda_i\rangle" /> of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> with eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" />, when we measure the energy of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> we obtain the result <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\psi|\lambda_i\rangle" class="latex" title="\langle\psi|\lambda_i\rangle" />, and the system collapses to the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_i\rangle" class="latex" title="|\lambda_i\rangle" /> (assuming the eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" /> has multiplicity 1). Thus, the ground state and ground state energy of a quantum system with eigenvalue <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> are the minimum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0" class="latex" title="\lambda_0" /> of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> and the corresponding eigenvector <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_0\rangle" class="latex" title="|\lambda_0\rangle" />.</p>
<p>The Boltzmann distribution also has a quantum analogue. A quantum system at thermal equilibrium will be in the following mixed state: <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+H%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" class="latex" title="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" />. As the temperature approaches absolute zero, <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{\text{eq}}" class="latex" title="\rho_{\text{eq}}" /> will approach a superposition over the ground states.</p>
<p>Not only does the Hamiltonian tell us the energy of a system, it also describes the time evolution of the system (as long as it is closed). Schrödinger’s equation states that <img src="https://s0.wp.com/latex.php?latex=-i+%5Chbar+%5Cfrac%7Bd%7C%5Cpsi%5Crangle%7D%7Bdt%7D+%3D+H%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" class="latex" title="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" />, where <img src="https://s0.wp.com/latex.php?latex=%5Chbar&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hbar" class="latex" title="\hbar" /> is Planck’s constant and <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> is time. Thus, if a closed system is in the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_0" class="latex" title="|\psi\rangle_0" /> at time 0, its state at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> will be <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_t+%3D+e%5E%7B-itH%2F%5Chbar%7D%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" class="latex" title="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" />. Since <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is Hermitian, <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-itH%2F%5Chbar%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e^{-itH/\hbar}" class="latex" title="e^{-itH/\hbar}" /> is unitary, which is another way of saying that quantum mechanical states are subject to unitary evolution.</p>
<h1>The Local Hamiltonian problem</h1>
<p>As we have seen, understanding the Hamiltonian of a quantum system is crucial for understanding both the system’s equilibrium behavior and its time evolution. There are a huge variety of questions physicists are interested in asking about systems, all of which boil down to questions about equilibrium behavior, time evolution, or both. There is a single problem that captures the complexity of many of these questions, in the sense that most of the questions can’t be answered without solving it. This is the problem of estimating the ground state energy of the Hamiltonian. Especially in condensed matter physics, this problem is ubiquitous.</p>
<p>Formally, we will study the following promise problem: (note: this will not be our final formulation)</p>
<hr />
<p><strong>The “Hamiltonian Problem”</strong></p>
<p>Given a Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" /> and non-negative reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> with <img src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b \geq a+1" class="latex" title="b \geq a+1" />,</p>
<ul>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \leq a" class="latex" title="\lambda_0(H) \leq a" />, output YES<p></p>
</li>
<li>
<p>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \geq b" class="latex" title="\lambda_0(H) \geq b" />, output NO</p>
</li>
</ul>
<hr />
<p>One issue with this definition is that the input includes an enormous <img src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n \times 2^n" class="latex" title="2^n \times 2^n" /> matrix. For a reasonable-sized system, there’d be no use in even trying to solve this problem through classical computation, and how to deal with it in the quantum computing setting is far from obvious. Luckily, physicists have found that in real-life systems, interactions tend to be <em>local</em>, and if we consider the special case of <em>local Hamiltonians</em>, the input for the problem is of reasonable size.</p>
<p></p><div style="width: 295px;" class="wp-caption aligncenter" id="attachment_6361"><img src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram0.png?w=285&amp;h=300" alt="circle_diagram0" width="285" class="aligncenter size-medium wp-image-6361" height="300" /><p class="wp-caption-text">Hamiltonians are too big to work with. What if we restrict our focus to local Hamiltonians?</p></div><p></p>
<p>A <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian is a Hamiltonian that is decomposed into a sum of terms, each of which represents a Hamiltonian acting on a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-unit subset of the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits in the system. In other words, <img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_i+%28H_i%29_%7BS_i%7D+%5Cotimes+I_%7B%5Bn%5D%5Cbackslash+S_i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" class="latex" title="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" />, where each <img src="https://s0.wp.com/latex.php?latex=S_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_i" class="latex" title="S_i" /> is a subset of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[n]" class="latex" title="[n]" /> of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. For brevity’s sake, we abuse notation and write <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> as <img src="https://s0.wp.com/latex.php?latex=%5Csum_i+H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_i H_i" class="latex" title="\sum_i H_i" />. We can think of the <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />’s as local constraints, and the ground state as the state that simultaneously satisfies the constraints to the maximal possible extent. Here, then, is the new-and-improved problem definition:</p>
<hr />
<p><strong><img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-Local Hamiltonian Problem</strong></p>
<p>Given a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" /> specified as a collection of <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> local interactions <img src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H_i\}" class="latex" title="\{H_i\}" />, and non-negative reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> with <img src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b \geq a+1" class="latex" title="b \geq a+1" />,</p>
<ul>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \leq a" class="latex" title="\lambda_0(H) \leq a" />, output YES</li>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \geq b" class="latex" title="\lambda_0(H) \geq b" />, output NO</li>
</ul>
<hr />
<p>Presuming the matrices <img src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H_i\}" class="latex" title="\{H_i\}" /> and the reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> are specified to polynomial precision, then the input size is polynomial in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, since <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is a constant and each of the matrices <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" /> has <img src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ccdot+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k \cdot 2^k" class="latex" title="2^k \cdot 2^k" /> entries. Thus, not only is our new problem physically realistic, it is also a problem we might hope to attack with classical computation. However, we will later see that in fact this problem is likely hard even for quantum computers. The remaining installments in this series of notes will deal with further restrictions of the class of Hamiltonians for which the local Hamiltonian problem may be tractable.</p>
<h2>Computer science motivation</h2>
<p>As we mentioned in the intro, the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem (henceforth denoted <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH) doesn’t just have myriad applications in physics—it is also important from a computer science perspective because it is a quantum generalization of constraint satisfiability (you may have noticed that quantum analogues of classical concepts are a running theme). Specifically, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP is a special case of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH.</p>
<p>Suppose we have a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP instance <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" />, and we want to turn it into a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH instance. A clause <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> with constituent variables <img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cldots%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \ldots, x_k" class="latex" title="x_1, \ldots, x_k" /> becomes a <img src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ctimes+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k \times 2^k" class="latex" title="2^k \times 2^k" /> diagonal <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\}" class="latex" title="\{0,1\}" /> matrix <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> acting on the qubits <img src="https://s0.wp.com/latex.php?latex=%7Cx_1%5Crangle%2C%5Cldots%2C%7Cx_k%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|x_1\rangle,\ldots,|x_k\rangle" class="latex" title="|x_1\rangle,\ldots,|x_k\rangle" />. Note that the rows and columns of this matrix are indexed by the assignment vectors <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B0%2C1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in \{0,1\}^k" class="latex" title="x \in \{0,1\}^k" />. Formally, <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> encodes the truth table of <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> in the following manner: <img src="https://s0.wp.com/latex.php?latex=%28H_C%29_%7Bx%2Cx%7D+%3D+1+-+C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H_C)_{x,x} = 1 - C(x)" class="latex" title="(H_C)_{x,x} = 1 - C(x)" />. Another way of stating this is <img src="https://s0.wp.com/latex.php?latex=H_C+%3D+%5Csum_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5Ek%5Ctext%7B+s.t.+%7DC%28x%29%3D0%7D%7Cx%5Crangle%5Clangle%7Bx%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" class="latex" title="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" />.</p>
<p>Informally, <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> takes the clauses of <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> and turns them into local quantum interactions. We’ve constructed <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> so that it has two eigenvalues: 0 and 1. The eigenspace corresponding to 0 is spanned by the set of computational basis vectors <img src="https://s0.wp.com/latex.php?latex=%7Cx%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|x\rangle" class="latex" title="|x\rangle" /> that satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />, and the eigenspace corresponding to 1 is spanned by the computational basis vectors that don’t satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. In effect, when we consider <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> as a term of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />, we are giving an energy penalty to any variable assignment that doesn’t satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. <img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_%7BC%7DH_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = \sum_{C}H_C" class="latex" title="H = \sum_{C}H_C" /> will have the eigenvalue 0 (in other words, a ground state energy of 0) if and only if there is some assignment of the variables <img src="https://s0.wp.com/latex.php?latex=x_1%2C%5Cldots%2Cx_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1,\ldots,x_n" class="latex" title="x_1,\ldots,x_n" /> that satisfies all of the clauses (in other words, iff <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable). Otherwise, the ground state energy of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> will be at least 1, so determining whether <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable is equivalent to solving <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH with inputs <img src="https://s0.wp.com/latex.php?latex=a+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a = 0" class="latex" title="a = 0" />, and <img src="https://s0.wp.com/latex.php?latex=b+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b = 1" class="latex" title="b = 1" />. (In fact, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH generalizes MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP, since the ground state energy of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is exactly the number of clauses minus the maximum number of satisfiable clauses.)</p>
<p><span id="more-6358"></span></p>
<p></p>
<p></p>
<p>Let’s work through an example. Consider the following 2-SAT formula:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cvarphi%28x_1%2Cx_2%2Cx_3%29+%3D+%28x_1+%5Cvee+x_2%29+%5Cwedge+%28%5Coverline%7Bx_1%7D+%5Cvee+x_3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" class="latex" title="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" /></p>
<p>The truth table for the first clause <img src="https://s0.wp.com/latex.php?latex=C_1+%3D+%28x_1+%5Cvee+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1 = (x_1 \vee x_2)" class="latex" title="C_1 = (x_1 \vee x_2)" /> is:</p>
<table>
<tbody>
<tr>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /></th>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_2" class="latex" title="x_2" /></th>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_1+%5Cvee+x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1 \vee x_2" class="latex" title="x_1 \vee x_2" /></th>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>So <img src="https://s0.wp.com/latex.php?latex=H_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_1" class="latex" title="H_1" /> is the following matrix:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_1+%3D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" title="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" /></p>
<p>We also have</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_2+%3D+%5Cbegin%7Bpmatrix%7D+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" title="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" /></p>
<p>Then,<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%26%3D+%28H_1%29_%7B1%2C2%7D+%5Cotimes+I_%7B3%7D+%2B+%28H_2%29_%7B1%2C3%7D+%5Cotimes+I_%7B2%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%260%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%260%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%2B+%5Cbegin%7Bpmatrix%7D+0%26%26%26%26%26%26%26+%5C%5C+%260%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" class="latex" title="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> has diagonal entries that are zero, so it has 0 as an eigenvalue. We can therefore conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable. (In this example it was easy to write out <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> and see that it has zeros on the diagonal, but when <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is large, <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> becomes exponentially big, so we can’t just compute it explicitly and look through its diagonal entries.)</p>
<h1>Quantum Cook-Levin Theorem</h1>
<p>We’ve seen that any <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP problem can be thought of as a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH problem (with a diagonal Hamiltonian matrix). And the analogy can be drawn even further. One reason <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP is so useful is that it (and in particular 3-SAT) is NP-complete, according to the Cook-Levin Theorem. 3-SAT captures the difficulty of classical efficiently verifiable computation. It may not come as a surprise, then, that <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH captures the difficulty of <em>quantum</em> efficiently verifiable computation. This result is the “quantum Cook-Levin theorem”, but before we see it we need to define the complexity class QMA, the quantum analogue of NP.</p>
<p>Because quantum computation is probabilistic, QMA is more precisely the quantum analogue of MA (Merlin Arthur), which allows the verifier to have a chance of error:</p>
<hr />
<p><strong>MA</strong></p>
<p><img src="https://s0.wp.com/latex.php?latex=L+%5Cin+%5Ctext%7BMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L \in \text{MA}" class="latex" title="L \in \text{MA}" /> iff there exists a probabilistic poly-time verifier <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and a polynomial <img src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(n)" class="latex" title="p(n)" /> such that</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L%2C+%5Cexists+y+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" class="latex" title="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" /><p></p>
</li>
<li>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \notin L" class="latex" title="\forall x \notin L" />, <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" class="latex" title="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" /></p>
</li>
</ul>
<hr />
<p>For QMA, the verifier is a quantum computer and the witness is a quantum state. Moreover, we’re interested in the complexity of promise problems:</p>
<hr />
<p><strong>QMA</strong></p>
<p>A promise problem <img src="https://s0.wp.com/latex.php?latex=L+%3D+L_%7Byes%7D+%5Ccup+L_%7Bno%7D+%5Cin+%5Ctext%7BQMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L = L_{yes} \cup L_{no} \in \text{QMA}" class="latex" title="L = L_{yes} \cup L_{no} \in \text{QMA}" /> iff there exists a quantum poly-time verifier <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and a polynomial <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> such that</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L_%7Byes%7D%2C+%5Cexists+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" class="latex" title="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" /><p></p>
</li>
<li>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L_%7Bno%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \notin L_{no}" class="latex" title="\forall x \notin L_{no}" />, <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" class="latex" title="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" /></p>
</li>
</ul>
<hr />
<p>A problem is QMA-complete if it is in QMA and if any problem in QMA can be reduced to it in polynomial time. In 2002, Kitaev proved that <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH is QMA-complete for all <img src="https://s0.wp.com/latex.php?latex=k+%5Cgeq+5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \geq 5" class="latex" title="k \geq 5" />. This was the first time a natural problem was shown to be QMA-complete. In 2003 Kempe and Regev proved that 3-LH is QMA-complete, and finally in 2006 Kempe, Kitaev and Regev proved that 2-LH is QMA complete, achieving the best possible result unless P = QMA. (3-SAT is NP-complete but 2-SAT is in P, so it may seem curious that 2-LH is QMA-complete. But in fact, this isn’t too surprising, because as we mentioned earlier, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH corresponds to MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-SAT, and MAX-2-SAT is NP-complete.)</p>
<hr />
<p><strong>“Quantum Cook-Levin Theorem”</strong></p>
<p>The 2-local Hamiltonian problem is QMA-complete.</p>
<hr />
<p><em>A very sketchy proof sketch.    </em>This theorem is called the quantum Cook-Levin theorem not just because of the result, but also because the proof is along the same lines as the proof of the Cook-Levin theorem.</p>
<p>Recall that in the proof of the Cook-Levin theorem, we start with a verifier Turing machine that takes as input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" /> and, in time <img src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(n)" class="latex" title="p(n)" /> accepts iff <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> being in the language. We then devise (for each <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />) a 3-SAT formula such that any satisfying solution to the instance must be an encoding of a valid history of the Turing machine from start to finish on the input <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />. The constraints must guarantee that (a) the input indeed starts with <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, (b) at every time step <img src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B1%2Cp%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t \in [1,p(n)]" class="latex" title="t \in [1,p(n)]" /> the state of the machine correctly follows from its state at time <img src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t-1" class="latex" title="t-1" />, and that (c) the final state of the machine indicates acceptance. The constraints for (a) and (c) are trivial, and the reason we can do (b) is because Turing machines compute <em>locally</em>.</p>
<p>For our quantum Cook-Levin proof, we follow the same template. Given a quantum circuit, we construct a local Hamiltonian that has ground energy below some constant only if there is a quantum encoding of the circuit that includes the proper (a) initial state, (b) intermediate computation, and (c) final state. As before, (a) and (c) are easy, because the parts of the initial and final states we need to ‘inspect’ (with the local terms of the Hamiltonian) are essentially classical. But when we try to compute local constraints for (b), we run into a big problem: entanglement.</p>
<p>Consider some step of the computation. This will consist of applying a quantum gate <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> to a state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> to obtain <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" />. Even assuming we’ve already written down constraints to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> is correct, it is non-trivial to write down constraints to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" /> because <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> may differ from <img src="https://s0.wp.com/latex.php?latex=U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U|\psi\rangle" class="latex" title="U|\psi\rangle" /> in a highly <em>non-local</em> way if there is entanglement between far-flung qubits. For example, suppose for the sake of illustration that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> and <img src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = I" class="latex" title="U = I" />. And suppose we want to check that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> with 1-local constraints. Unfortunately, there is no way to distinguish <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+-+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" class="latex" title="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" /> by looking at one qubit at a time: the reduced density matrix of either state for either qubit is the same: <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" />/2. There are examples like this that apply for <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local constraints for any <img src="https://s0.wp.com/latex.php?latex=k+%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k &gt;1" class="latex" title="k &gt;1" />, so we can’t even verify the ‘trivial’ gate <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" />, let alone gates that actually change the state. It would seem that we are stuck.</p>
<p>Luckily, although quantum superposition makes this problem more difficult, we can actually use superposition in a clever manner in order to surmount the difficulty. Instead of encoding the states <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> separately, we can put them in superposition in a way that will allow us to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" />. Suppose again that <img src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = I" class="latex" title="U = I" />, so we want to check that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = |\psi\rangle" class="latex" title="|\psi'\rangle = |\psi\rangle" />. Let <img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C%5Cpsi%5Crangle%7C0%5Crangle+%2B+%7C%5Cpsi%27%5Crangle%7C1%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" class="latex" title="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" />. Then, just by looking at the last qubit of <img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle" class="latex" title="|\eta\rangle" />, we can tell how close <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> is to <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" />: the reduced density matrix of the last qubit contains information about the angle between <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bpmatrix%7D+1+%26+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%5C%5C+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" class="latex" title="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" /></p>
<p>The challenge is to describe a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> that has a state with energy below some parameter <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> whenever <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, and otherwise has no state with energy below <img src="https://s0.wp.com/latex.php?latex=b%3Ea&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b&gt;a" class="latex" title="b&gt;a" />. We won’t cover the details here, but the crucial idea is that when <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, the following ‘witness state’ (which is a superposition of the states of the quantum computer over all the time steps) will have low energy for a carefully-devised <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7Bp%28n%29%7D%5Csum_%7Bt%3D0%7D%5E%7Bp%28n%29%7D%28U_t%5Ccdots+U_1%7C%5Cpsi_0%5Crangle%29%5Cotimes%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" class="latex" title="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7Cx%5Crangle%7Cy%5Crangle%7C0%5Crangle%5E%7B%5Cotimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" class="latex" title="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" /> is the initial state of the computation, and <img src="https://s0.wp.com/latex.php?latex=%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|t\rangle" class="latex" title="|t\rangle" /> is called the “clock register”. Note that because the size of the clock register is logarithmic in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, we actually need to use <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />-local constraints. For 5-local constraints to suffice, the witness state will need to be a little more complicated (the proof for 2-local constraints is even more difficult). Even for the case of <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />-LH, the complete proof must demonstrate that no state besides the witness state has low energy.</p>
<p style="text-align: right;">□</p>
<h1>Roadmap</h1>
<p>The upshot is that 2-LH is the canonical QMA-complete problem. This is a beautiful result from a quantum complexity theory perspective, but from a physics perspective it is very bad news. The QMA-completeness of the local Hamiltonian problem means that (presuming BQP <img src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq" class="latex" title="\neq" /> QMA) we can’t solve 2-LH, and we couldn’t even solve it with a quantum computer. Because of the central importance of finding the ground energy, this in turn means that <em>almost anything a physicist would like to compute about a system is intractable</em>.</p>
<p>So is all hope lost? No! Just as we started out wanting to understand Hamiltonians in general and restricted our focus to <em>local</em> Hamiltonians, the approach the physics community has taken is to focus on even more restricted classes of Hamiltonians that still capture interesting physical systems. One route is to restrict the topology of the system encoded by the Hamiltonian: for example, in many physics models, the particles form a low-dimensional lattice and the only interactions between them are 2-local interactions along edges. Even this isn’t enough, though: the problem remains QMA-hard on many simple topologies like lattices (for example, 2-LH on the 2-D lattice is QMA-complete, and 2-LH on even the 1-D lattice is QMA-complete when instead of qubits we are dealing with 8-dimensional qudits). So we add a further restriction, which is to focus on <em>gapped</em> Hamiltonians: these are Hamiltonians for which there is a constant gap between the ground energy and the second-lowest energy.</p>
<p></p><div style="width: 392px;" class="wp-caption aligncenter" id="attachment_6405"><img src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram1.png?w=382&amp;h=336" alt="circle_diagram1.png" width="382" class="  wp-image-6405 aligncenter" height="336" /><p class="wp-caption-text">Even local Hamiltonians are intractable in general. Gapped Hamiltonians on low-dimensional lattices, though, may be tractable.</p></div><p></p>
<p>Thus, in the notes to follow, we will focus our energies on trying to solve the gapped local Hamiltonian problem for 1-D and 2-D lattices. The reason there is hope in these settings is that entanglement is (or is conjectured to be) limited by ‘area laws’. In the next post, Fred Zhang will describe a diagrammatic language (‘tensor networks’) for thinking about low-entanglement quantum states, and he’ll show how physicists solve the local Hamiltonian problem for gapped 1-D systems.</p></div>







<p class="date">
by benedelman <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/"><span class="datestr">at December 20, 2018 09:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
