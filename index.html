<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc ‚Äì QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs ‚Äì Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="G√∂del‚Äôs Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I‚Äôm a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Caf√©: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at March 28, 2019 10:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/045">TR19-045 |  On the Fine-grained Complexity of Least Weight Subsequence in Graphs | 

	Jiawei Gao</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Least Weight Subsequence (LWS) is a type of highly sequential optimization problems with form $F(j) = \min_{i &lt; j} [F(i) + c_{i,j}]$. They can be solved in quadratic time using dynamic programming, but it is not known whether these problems can be solved faster than $n^{2-o(1)}$ time. Surprisingly, each such problem is subquadratic time reducible to a highly parallel, non-dynamic programming problem [KPS17]. In other words, if a "static"  problem is faster than quadratic time, so is an LWS problem. For many instances of LWS, the sequential versions are equivalent to their static versions by subquadratic time reductions. The previous result applies to LWS on linear structures, and this paper extends this result to LWS on paths in sparse graphs. When the graph is a multitree (i.e. a DAG where any pair vertices can have at most one path) or when the graph is a DAG whose underlying undirected graph has constant treewidth, we show that LWS on this graph is still subquadratically reducible to their corresponding static problems. For many instances, the graph versions are still equivalent to their static versions.

Moreover, this paper shows that on these graphs, property testing of form $\exists x \exists y (\text{TC}_E(x,y) \wedge P(x,y))$ is subquadratically reducible to property testing of form $\exists x \exists y P(x,y)$, where $P$ is a property checkable in time linear to the sizes of $x$ and $y$, and $\text{TC}_E$ is the transitive closure of relation $E$. Furthermore, when $P$ is definable by a first-order logic formula with at most one quantified variable, then the above two problems are equivalent to each other by subquadratic reductions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/045"><span class="datestr">at March 28, 2019 08:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=345">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/03/28/tcs-talk-wednesday-april-3rd-richard-peng-georgia-tech/">TCS+ talk: Wednesday, April 3rd ‚Äî Richard Peng, Georgia Tech</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, April 3rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Richard Peng</strong> from Georgia Tech will speak about ‚Äú<em>Fully Dynamic Spectral Vertex Sparsifiers and Applications</em>‚Äù (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Problems arising from analyzing and understanding graph structures have motivated the development of many powerful tools for storing and compressing graphs and networks. Many, if not most, of these massive graphs are accumulations of updates over time. Maintaining updates and queries on dynamically changing graphs more efficiently than recomputing from scratch is a well-studied topic, with several important open problems related to global, optimization related queries.</p>
<p>We study dynamic graph algorithms for maintaining spectral vertex sparsifiers with respect to a subset of terminal vertices. Such sparsifiers preserve key structures in spectral algorithms, including effective resistances (which can be viewed as a numerical generalization of connectivity), solutions to systems of Laplacian linear equations, and energy of electrical flows between terminal vertices. We give data structures that maintain, in sublinear time, these sparsifiers under insertions/deletions of edges, as well as terminal additions.</p>
<p>This primitive in turn leads to sublinear time data structures for key primitives in spectral graph algorithms, including ones at the core of the ‚ÄúLaplacian paradigm‚Äù for designing graph optimization algorithms. In particular, we obtain <img src="https://s0.wp.com/latex.php?latex=O%28m%5E%7B4%2F3%7D%5Cepsilon%5E%7B-4%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(m^{4/3}\epsilon^{-4})" class="latex" title="O(m^{4/3}\epsilon^{-4})" /> time per query/update for effective resistances on unweighted graphs, and <img src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B11%2F12%7D%5Cepsilon%5E%7B-5%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(n^{11/12}\epsilon^{-5})" class="latex" title="O(n^{11/12}\epsilon^{-5})" /> time per query/update for implicit access to linear system solutions, where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> is the relative approximation accuracy.</p>
<p>The majority of the talk will focus on key components of this data structure: (1) an interpretation of vertex sparsifiers as a sum of random walks, (2) a suitable choice of terminals to keep these walks local, and (3) maintenance of local walks and numerical solutions. Potential avenues in generalizing these techniques to provide new building blocks for dynamic graph algorithms will also be discussed.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/03/28/tcs-talk-wednesday-april-3rd-richard-peng-georgia-tech/"><span class="datestr">at March 28, 2019 05:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7487">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/03/28/nominate-tcs-papers-for-research-highlights/">Nominate TCS papers for research highlights</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[Guest post by Aleksander MƒÖdry]</em></p>



<p>To me, one of the best things about working in theoretical computer <br />science has always the exciting rate of progress we make as a community.¬†<br />On (what appears to be) a regular basis, we produce breakthroughs on¬†<br />problems that are absolutely fundamental to our field. Problems that¬†<br />often look impossible to tackle, right up until someone actually tackles¬†<br />them.</p>



<p>However, as inspiring as all these developments were to me, I also¬†<br />always felt that we, as a community, could do more to properly recognize¬†<br />and highlight them, both internally and to the outside world. This kind¬†<br />of outreach would make it easier for us to capitalize on the¬†<br />breakthroughs as well as to accelerate the impact of the underlying¬†<br />ideas on the other areas of computer science, and beyond.</p>



<p>Fortunately, this is about to change!</p>



<p>One of the first decisions of our newly (re-)elected <a href="https://www.sigact.org/">SIGACT committee</a> was to create a committee (as committees are wont to do <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="üôÇ" style="height: 1em;" class="wp-smiley" /> whose mission will be to help  promote top computer science theory research. This <strong>SIGACT Research Highlights Committee</strong> ‚Äì consisting of <a href="https://www.boazbarak.org/">Boaz Barak</a>, <a href="https://omereingold.wordpress.com/">Omer Reingold</a>,  <a href="https://sites.google.com/site/marywootters/">Mary Wootters</a> and <a href="https://people.csail.mit.edu/madry/">myself</a> ‚Äì will, in particular, work to identify results to be recommended for consideration for the <a href="http://cacm.acm.org/">CACM </a>Research Highlights section as well  as other general-audience research outlets in computer science and other  fields.</p>



<p>Of course, to do a proper job here we require your help! To this end,¬†<br />the committee solicits two types of nominations:</p>



<p>1) Conference nominations. Each year, the committee will ask the PC¬†<br />chairs of a broad set of theoretical computer science conferences to¬†<br />send a selection of up to three top papers from these conferences¬†<br />(selected based on both their technical merit and the potential¬†<br />significant interest to non-theory audiences) and forwarding them to the¬†<br />committee for consideration.</p>



<p>2) Community nominations. The committee will accept nominations from the  members of the community. Each such nomination should summarize the  contribution of the nominated (and recently published) paper and also <br />argue why this paper particularly merits a broader outreach. The¬†<br />nomination should be no more than a page in length and can be submitted¬†<br />at any time by emailing it to¬†<a href="mailto:sigact.cacm.nominations@gmail.com" target="_blank" rel="noreferrer noopener">sigact.cacm.nominations@gmail.com</a>.¬†<br />Self-nominations are discouraged.</p>



<p>To be considered in the upcoming round of our deliberations, we need to¬†<br />receive your nomination by <strong>April 30</strong>.</p>



<p>Looking forward to learning about all the new exciting research that you¬†<br />all are doing!

</p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2019/03/28/nominate-tcs-papers-for-research-highlights/"><span class="datestr">at March 28, 2019 03:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4213">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/03/28/and-now-for-something-completely-different/">And now for something completely different</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 After 22 years in the United States, 19 of which spent in the San Francisco Bay Area, this Summer I will move to Milan to take a job at <a href="https://en.wikipedia.org/wiki/Bocconi_University">Bocconi University</a>.</p>
<p>
Like a certain well-known Bay Area institution, Bocconi is a private university that was endowed by a rich merchant in memory of his dead son. Initially characterized by an exclusive focus on law, economics and business, it has had for a while a high domestic recognition for the quality of teaching and, more recently, a good international profile both in teaching and research. Despite its small size, compared to Italy‚Äôs giant public universities, in 2017 Bocconi was the Italian university which had received the most ERC grants during the first ten years of existence of the European Research Council (in second place was my Alma Mater, the Sapienza University of Rome, which has about nine times more professors) <a href="https://milano.repubblica.it/cronaca/2017/03/07/news/in_bocconi_i_fuoriclasse_della_ricerca-159919972/">(source)</a>.</p>
<p>
About three years ago, Bocconi started planning for a move in the space of computing, in the context of their existing efforts in <a href="http://www.bidsa.unibocconi.eu/wps/wcm/connect/Site/Bidsa/Home">data science</a>. As a first step, they recruited <a href="https://sites.google.com/view/riccardozecchina/home">Riccardo Zecchina</a>. You may remember Riccardo from his work providing a non-rigorous calculation of the threshold of random 3-SAT, his work on the ‚Äúsurvey propagation‚Äù algorithm for SAT and other constraint satisfaction problems, as well as other work that brought statistical physics techniques to computer science. Currently, Riccardo and his group are doing very exciting work on the theory of deep learning.</p>
<p>
Though I knew of his work, I had never met Riccardo until I attended a 2017 workshop at the Santa Fe Institute on <a href="https://www.santafe.edu/events/thermodynamics-and-computation-towards-new-synthes">‚ÄúThermodynamics and computation,‚Äù</a> an invitation that I had accepted on whim, mostly based on the fact that I had never been to New Mexico and I had really liked Breaking Bad. Riccardo had just moved to Bocconi, he told me about their future plans, and he asked me if I was interested. I initially politely declined, but one thing led to another, and now here I am putting up my San Francisco house for sale.</p>
<p>
Last August, as I was considering this move, I applied for an <a href="https://lucatrevisan.wordpress.com/2018/07/31/erc-vs-nsf/">ERC grant</a> from the European Union, and I just learned that the <a href="https://erc.europa.eu/news/erc-2018-advanced-grants-results">grant has been approved</a>. This grant is approximately the same amount as the total of all the grants that I have received from the NSF over the past twenty years, and it will support several postdoc positions, as well as visitors ranging from people coming for a week to give a talk and meet with my group to a full-year sabbatical visit.</p>
<p>
 Although it‚Äôs a bit late for that, I am looking for postdocs starting as early as this September: if you are interested please contact me. The postdoc positions will pay a highly competitive salary, which will be free of Italian income tax (<s>although American citizens will owe federal income tax to the IRS</s> correction: American citizens would not owe anything to IRS either). As a person from Rome, I am not allowed to say good things about Milan or else I will have to return my Roman card (it‚Äôs kind of a NY versus LA thing), but I think that the allure of the city speaks for itself.</p>
<p>
Likewise, if you are a senior researcher, and you have always wanted to visit me and work together on spectral methods, approximation algorithms, graph theory or graph algorithms, but you felt that Berkeley had insufficiently many Leonardo mural paintings and opera houses, and that it was too far from the Alps, then now you are in luck!</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/03/28/and-now-for-something-completely-different/"><span class="datestr">at March 28, 2019 12:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2959222585780083759">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/scooped.html">Scooped</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
At Dagstuhl I got a few ideas for future posts but then...<br />
<br />
We had some discussions about STOC allowing program committee members to submit papers that I planned to post about. But then Suresh wrote a <a href="http://blog.geomblog.org/2019/03/on-pc-submissions-at-soda-2020.html">fine post</a> on the same issue for SODA. My thoughts: PC members should not submit--no matter how you try to avoid the conflict of interest, there will always be a cloud on the process. Suresh suggest blind reviews that other non-theory conferences use, but I prefer the tiered PC system. It's fine to have PC members submit papers if the top of the tier, a senior PC or the PC chairs, makes the final calls.<br />
<br />
I was also going to post about Yann LeCun's¬†<a href="https://www.facebook.com/story.php?story_fbid=10152719972317143&amp;id=722677142">Facebook rant</a>¬†about stodgy CS departments but then Yann goes ahead and <a href="https://www.nytimes.com/2019/03/27/technology/turing-award-ai.html">wins a Turing award</a> with¬†Geoffrey Hinton and Yoshua Bengio for their work on machine learning. I knew Yann from when we worked together at NEC Research in the early 2000's and let's just congratulate him and the others and let them bask in glory for truly transforming how we think of computing today. I'll get back to his post soon enough.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/scooped.html"><span class="datestr">at March 28, 2019 11:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/044">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/044">TR19-044 |  DEEP-FRI: Sampling Outside the Box Improves Soundness | 

	Eli Ben-Sasson, 

	Lior Goldberg, 

	Swastik Kopparty, 

	Shubhangi Saraf</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Motivated by the quest for scalable and succinct zero knowledge arguments, we revisit worst-case-to-average-case reductions for linear spaces, raised by [Rothblum, Vadhan, Wigderson, STOC 2013]. The previous state of the art by [Ben-Sasson, Kopparty, Saraf, CCC 2018] showed that if some member of an affine space $U$ is $\delta$-far in relative Hamming distance from a linear code $V$ ‚Äî this is the worst-case assumption ‚Äî then most elements of $U$ are almost-$\delta$-far from $V$ ‚Äî this is the average case. However, this result was known to hold only below the ‚Äúdouble Johnson‚Äù function of the relative distance $\delta_V$ of the code $V$ , i.e., only when $\delta &lt; 1 ? (1 ? \delta_V)^{1/4}$.
First, we increase the soundness-bound to the ‚Äúone-and-a-half Johnson‚Äù function of $\delta_V$ and show that the average distance of $U$ from $V$ is nearly $\delta$ for any worst-case distance $\delta$ smaller than $1 ? (1 ? \delta_V)^{1/3}$. This bound is tight, which is somewhat surprising because the one-and-a-half Johnson function is unfamiliar in the literature on error correcting codes.
To improve soundness further for Reed Solomon codes we sample outside the box. We suggest a new protocol in which the verifier samples a single point $z$ outside the box $D$ on which codewords are evaluated, and asks the prover for the value at $z$ of the interpolating polynomial of a random element of $U$. Intuitively, the answer provided by the prover ‚Äúforces‚Äù it to choose one codeword from a list of ‚Äúpretenders‚Äù that are close to $U$. We call this technique Domain Extending for Eliminating Pretenders (DEEP).
The DEEP method improves the soundness of the worst-case-to-average-case reduction for RS codes up their list decoding radius. This radius is bounded from below by the Johnson bound, implying average distance is approximately $\delta$ for all $\delta &lt; 1 ? (1 ? \delta_V)^{1/2}$. Under a plausible conjecture about the list decoding radius of Reed-Solomon codes, average distance from $V$ is approximately $\delta$ for all $\delta$. The DEEP technique can be generalized to all linear codes, giving improved reductions for capacity-achieving list-decodable codes.
Finally, we use the DEEP technique to devise two new protocols:
‚Ä¢ An Interactive Oracle Proof of Proximity (IOPP) for RS codes, called DEEP-FRI. This soundness of the protocol improves upon that of the FRI protocol of [Ben-Sasson et al., ICALP 2018] while retaining linear arithmetic proving complexity and logarithmic verifier arithmetic complexity.
‚Ä¢ An Interactive Oracle Proof (IOP) for the Algebraic Linking IOP (ALI) protocol used to construct zero knowledge scalable transparent arguments of knowledge (ZK-STARKs) in [Ben-Sasson et al., eprint 2018]. The new protocol, called DEEP-ALI, improves soundness of this crucial step from a small constant $&lt; 1/8$ to a constant arbitrarily close to $1$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/044"><span class="datestr">at March 28, 2019 07:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11445">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11445">Stability analysis of kinetic orientation-based shape descriptors</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meulemans:Wouter.html">Wouter Meulemans</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verbeek:Kevin.html">Kevin Verbeek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wulms:Jules.html">Jules Wulms</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11445">PDF</a><br /><b>Abstract: </b>We study three orientation-based shape descriptors on a set of continuously
moving points $P$: the first principal component, the smallest oriented
bounding box and the thinnest strip. Each of these shape descriptors
essentially defines a cost capturing the quality of the descriptor (sum of
squared distances for principal component, area for oriented bounding box, and
width for strip), and uses the orientation that minimizes the cost. This
optimal orientation may be very unstable as the points are moving, which is
undesirable in many practical scenarios. Alternatively, we can bound the speed
with which the orientation of the descriptor may change. However, this can
increase the cost (and hence lower the quality) of the resulting shape
descriptor. In this paper we study the trade-off between stability and quality
of these shape descriptors. % We first show that there is no stateless
algorithm, which depends only on the input points in one time step and not on
previous states, that both approximates the minimum cost of a shape descriptor
and achieves bounded speed. On the other hand, if we can use the previous state
of the shape descriptor to compute the new state, then we can define "chasing"
algorithms that attempt to follow the optimal orientation with bounded speed.
Under mild conditions, we show that chasing algorithms with sufficient bounded
speed approximate the optimal cost at every time step for oriented bounding
boxes and strips, but not for principal components. The analysis of such
chasing algorithms is challenging and has received little attention in
literature, hence we believe that our methods used to perform this analysis are
of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11445"><span class="datestr">at March 28, 2019 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11316">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11316">Treewidth and Counting Projected Answer Sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Johannes K. Fichte, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hecher:Markus.html">Markus Hecher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11316">PDF</a><br /><b>Abstract: </b>In this paper, we introduce novel algorithms to solve projected answer set
counting (#PAs). #PAs asks to count the number of answer sets with respect to a
given set of projected atoms, where multiple answer sets that are identical
when restricted to the projected atoms count as only one projected answer set.
Our algorithms exploit small treewidth of the primal graph of the input
instance by dynamic programming (DP). We establish a new algorithm for
head-cycle-free (HCF) programs and lift very recent results from projected
model counting to #PAs when the input is restricted to HCF programs. Further,
we show how established DP algorithms for tight, normal, and disjunctive answer
set programs can be extended to solve #PAs. Our algorithms run in polynomial
time while requiring double exponential time in the treewidth for tight,
normal, and HCF programs, and triple exponential time for disjunctive programs.
Finally, we take the exponential time hypothesis (ETH) into account and
establish lower bounds of bounded treewidth algorithms for #PAs. Under ETH, one
cannot significantly improve our obtained worst-case runtimes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11316"><span class="datestr">at March 28, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11287">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11287">Convexly independent subsets of Minkowski sums of convex polygons</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skomra:Mateusz.html">Mateusz Skomra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">St√©phan Thomass√©</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11287">PDF</a><br /><b>Abstract: </b>We show that there exist convex $n$-gons $P$ and $Q$ such that the largest
convex polygon in the Minkowski sum $P+Q$ has size $\Theta(n\log n)$. This
matches an upper bound of Tiwary.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11287"><span class="datestr">at March 28, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11139">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11139">Robust NFP generation for Nesting problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rocha:Pedro.html">Pedro Rocha</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11139">PDF</a><br /><b>Abstract: </b>Cutting and packing problems arise in a large variety of industrial
applications, where there is a need to cut pieces from a large object, or
placing them inside a containers, without overlap. When the pieces or the
containers have irregular outline, the problem is classified as a Nesting
problem. The geometrical challenges of the Nesting problem are addressed by
focusing on the geometric aspect of the 2D pieces and containers involved. The
challenges of the geometrical component are mainly derived from the complexity
of the pieces, due to high number of vertices, which is common when dealing
with real world scenarios. This complexity is challenging for current
algorithms to process efficiently and effectively, leading to high
computational cost and less satisfactory results, particularly when dealing
with overlap verification operations. Usually, when tackling Nesting problems,
the overlap verification process between two objects is done through the use of
a structure known as No-Fit-Polygon (NFP).
</p>
<p>In this work, the generation of the NFP is achieved through a simple
algorithm which produces a simplified shape while reducing numerical precision
errors and fully representing the region that forms the NFP including positions
with perfect fits.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11139"><span class="datestr">at March 28, 2019 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11131">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11131">Differential Geometric Foundations for Power Flow Computations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolter:Franz=Erich.html">Franz-Erich Wolter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Benjamin.html">Benjamin Berger</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11131">PDF</a><br /><b>Abstract: </b>This paper aims to systematically and comprehensively initiate a foundation
for using concepts from computational differential geometry as instruments for
power flow computing and research. At this point we focus our discussion on the
static case, with power flow equations given by quadratic functions defined on
voltage space with values in power space; both spaces have real Euclidean
coordinates. Central issue is a differential geometric analysis of the power
flow solution space boundary (SSB) both in voltage and in power space. We
present different methods for computing tangent vectors, tangent planes and
normals of the SSB and the normals' derivatives. Using the latter we compute
normal and principal curvatures. All this is needed for tracing the orthogonal
projection of curves in voltage and power space onto the SSB for points on the
SSB cosest to given points on the curves, thus obtaining estimates for the
distance to the SSB. Furthermore, we present a new high precision continuation
method for power flow solutions. We also compute geodesics on the SSB or an
implicitly defined submanfold thereof and, used to define geodesic coordinates
together with their Jacobians on the manifolds. These computations might be the
most innovative and most significant contribution of this paper, because this
concept provides a comprehensive coordinate system for sub many folds defined
by implicit equations. Therefore while moving on geodesics described by the
geodesic coordinates of the sub manifold at hand we get, via systematic
navigation guided by geodesic coordinates, access to all feasible operation
points of the system. We propose some applications and show some properties of
the Jacobian of the power flow map.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11131"><span class="datestr">at March 28, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11062">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11062">Testing isomorphism of circular-arc graphs in polynomial time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nedela:Roman.html">Roman Nedela</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Ponomarenko:Ilia.html">Ilia Ponomarenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zeman:Peter.html">Peter Zeman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11062">PDF</a><br /><b>Abstract: </b>A graph is said to be circular-arc if the vertices can be associated with
arcs of a circle so that two vertices are adjacent if and only if the
corresponding arcs overlap. It is proved that the isomorphism of circular-arc
graphs can be tested by the Weisfeiler-Leman algorithm after individualization
of two vertices.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11062"><span class="datestr">at March 28, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4211">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/03/27/tested-by-time/">Tested by time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I was delighted (and not at all surprised) to hear that this year‚Äôs Turing Award will go to <a href="https://amturing.acm.org/">LeCun, Hinton, and Bengio</a> for their work on deep learning.</p>
<p>Like public-key cryptography, deep learning was ahead of its time when first studied, but, thanks to the pioneering efforts of its founders, it was ready to be used when the technology caught up. </p>
<p>Mathematical developments take a long time to mature, so it is essential that applied mathematical research be done ahead of the time of its application, that is, at a time when it is basic research. Maybe quantum computing will be the next example to teach this lesson.</p>
<p>By the way, this summer the Simons Institute will host a <a href="https://simons.berkeley.edu/programs/dl2019">program on the foundations of deep learning</a>, co-organized by Samy Bengio.</p>
<p>Sometimes, it is not just the practical applications of a mathematical advance that take time to develop: the same can be true even for its <i>theoretical</i> applications! Which brings me to the next announcement of this post, namely that the call for nominations for the <a href="http://focs2019.cs.jhu.edu/tota/">FOCS test of time award</a> is out. Nominations are due in about four weeks.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/03/27/tested-by-time/"><span class="datestr">at March 27, 2019 08:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3381">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2019/03/27/call-for-papers-workshop-on-behavioral-economics-and-computation-at-ec-2019/">Call for Papers: Workshop on Behavioral Economics and Computation at EC 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<pre class="aLF-aPX-K0-aPE">-------------------------------------------------------------------------------------
Call for Papers:

Workshop on Behavioral Economics and Computation
<a href="https://sites.google.com/view/behavioralec/">https://sites.google.com/view/behavioralec/</a>
June 28, 2019, Phoenix, AZ
In conjunction with the 20th ACM Conference on Economics and Computation 
(ACM EC '19)

SUBMISSIONS DUE May 1, 2019, 11:59pm PDT.
-------------------------------------------------------------------------------------
We solicit research contributions and participants for The 1st
Workshop on Behavioral Economics and Computation, to be held in
conjunction with the 20th ACM Conference on Economics and Computation 
(ACM EC '19). The workshop will bring together researchers and
practitioners from diverse subareas of EC, who are interested in the 
intersection of human economic behavior and computation, to share new 
results and to discuss future directions for behavioral research 
related to economics and computation. It will be a full-day workshop, 
and will feature invited speakers, contributed paper presentations and 
a panel discussion.

The gap between rationality-based analysis that assumes utility-maximizing 
agents and the actual human behavior in the real world has been well 
recognized in economics, psychology and other social sciences. In recent 
years, there has been a growing interest in conducting behavioral research 
across many of the sub-areas related to economics and computation to 
address this gap. In one direction, some of these studies leverage insights 
on human decision making from behavioral economics and social psychology 
literature to study economic and computational systems with human users. 
In the other direction, computational tools are used to study and gain 
insights on human behavior and a data-driven approach is sometimes used to 
learn behavior models from user-generated data.

The Behavioral EC workshop aims to bring together researchers and 
practitioners from diverse fields, including but not limited to computer 
science, economics, psychology and sociology, to exchange ideas related to 
behavioral research in economics and computation. In addition to sharing new 
results, we hope the workshop will foster a lively discussion of future 
directions and methodologies for behavioral research related to economics 
and computation as well as fruitful cross-pollination of behavioral 
economics, cognitive psychology and computer science. 

We welcome studies at the intersection of economic behavior and computation 
from a rich set of theoretical, experimental and empirical perspectives. The 
topics of interest for the workshop are behavioral research in all settings 
covered by EC, including but not limited to:

Behavioral mechanism design and applied mechanism design
Empirical studies of economic behavior
Boundedly-rational models of economic decision making
Model evaluation and selection based on behavioral data
Online prediction markets, experiments, and crowdsourcing platforms
Hybrid human-machine systems
Models and experiments about social considerations (e.g. fairness) in 
decision making 
Methods for behavioral EC: information aggregation, probability elicitation, 
quality control


Submission Instructions
=======================

Submission deadline: May 1, 2019, 11:59pm PDT.

Notification: May 20, 2019

We will give priority to new (unpublished) research papers, but will 
also consider ongoing research and recently published papers that may 
be of interest to the workshop audience. For submissions of published 
papers, authors must clearly state the venue of publication. Papers 
will be reviewed for relevance, significance, originality, research 
contribution, and likelihood to catalyze discussion. The workshop will 
not have archival proceedings but will post accepted papers on the 
workshop website. Position papers and panel discussion proposals are also 
welcome. At least one author of each accepted paper will be expected 
to attend and present their findings at the workshop.

Submissions can be in any format and can be up to 18 pages long (plus 
a title page and excluding appendices that can be arbitrarily long). We 
recommend the format of the EC submissions. The limit of 18 pages on 
the main body is an upper bound, and papers can be significantly shorter. 

Submissions should be uploaded to the submission server no later 
than May 1, 2019, 11:59pm PDT.


Organizing Committee
====================
Yiling Chen, Harvard University
Dan Goldstein, Microsoft Research 
Kevin Leyton-Brown, University of British Columbia
Shengwu Li, Harvard University
Gali Noti, Hebrew University


More Information
================
For more information or questions, visit the workshop website:
<a href="https://sites.google.com/view/behavioralec/">https://sites.google.com/view/behavioralec/</a>
or email the organizing committee: <a href="mailto:behavioralec2019@easychair.org">behavioralec2019@easychair.org</a></pre></div>







<p class="date">
by Kevin Leyton-Brown <a href="https://agtb.wordpress.com/2019/03/27/call-for-papers-workshop-on-behavioral-economics-and-computation-at-ec-2019/"><span class="datestr">at March 27, 2019 01:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.11016">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.11016">Malleable scheduling beyond identical machines</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fotakis:Dimitris.html">Dimitris Fotakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matuschke:Jannik.html">Jannik Matuschke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papadigenopoulos:Orestis.html">Orestis Papadigenopoulos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.11016">PDF</a><br /><b>Abstract: </b>In malleable job scheduling, jobs can be executed simultaneously on multiple
machines with the processing time depending on the number of allocated
machines. Jobs are required to be executed non-preemptively and in unison, in
the sense that they occupy, during their execution, the same time interval over
all the machines of the allocated set. In this work, we study generalizations
of malleable job scheduling inspired by standard scheduling on unrelated
machines. Specifically, we introduce a general model of malleable job
scheduling, where each machine has a (possibly different) speed for each job,
and the processing time of a job $j$ on a set of allocated machines $S$ depends
on the total speed of $S$ for $j$. For machines with unrelated speeds, we show
that the optimal makespan cannot be approximated within a factor less than
$\frac{e}{e-1}$, unless $P = NP$. On the positive side, we present
polynomial-time algorithms with approximation ratios $2\frac{e}{e-1}$ for
machines with unrelated speeds, $3$ for machines with uniform speeds, and $7/3$
for restricted assignments on identical machines. Our algorithms are based on
deterministic LP rounding and result in sparse schedules, in the sense that
each machine shares at most one job with other machines. We also prove lower
bounds on the integrality gap of $1+\varphi$ for unrelated speeds ($\varphi$ is
the golden ratio) and $2$ for uniform speeds and restricted assignments. To
indicate the generality of our approach, we show that it also yields constant
factor approximation algorithms (i) for minimizing the sum of weighted
completion times; and (ii) a variant where we determine the effective speed of
a set of allocated machines based on the $L_p$ norm of their speeds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.11016"><span class="datestr">at March 27, 2019 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10983">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10983">A Tight Runtime Analysis for the cGA on Jump Functions---EDAs Can Cross Fitness Valleys at No Extra Cost</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doerr:Benjamin.html">Benjamin Doerr</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10983">PDF</a><br /><b>Abstract: </b>We prove that the compact genetic algorithm (cGA) with hypothetical
population size $\mu = \Omega(\sqrt n \log n) \cap \text{poly}(n)$ with high
probability finds the optimum of any $n$-dimensional jump function with jump
size $k &lt; \frac 1 {20} \ln n$ in $O(\mu \sqrt n)$ iterations. Since it is known
that the cGA with high probability needs at least $\Omega(\mu \sqrt n + n \log
n)$ iterations to optimize the unimodal OneMax function, our result shows that
the cGA in contrast to most classic evolutionary algorithms here is able to
cross moderate-sized valleys of low fitness at no extra cost.
</p>
<p>Our runtime guarantee improves over the recent upper bound $O(\mu n^{1.5}
\log n)$ valid for $\mu = \Omega(n^{3.5+\varepsilon})$ of Hasen\"ohrl and
Sutton (GECCO 2018). For the best choice of the hypothetical population size,
this result gives a runtime guarantee of $O(n^{5+\varepsilon})$, whereas ours
gives $O(n \log n)$.
</p>
<p>We also provide a simple general method based on parallel runs that, under
mild conditions, (i)~overcomes the need to specify a suitable population size,
but gives a performance close to the one stemming from the best-possible
population size, and (ii)~transforms EDAs with high-probability performance
guarantees into EDAs with similar bounds on the expected runtime.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10983"><span class="datestr">at March 27, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10943">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10943">Maintaining the Union of Unit Discs under Insertions with Near-Optimal Overhead</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Ravid.html">Ravid Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Halperin:Dan.html">Dan Halperin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10943">PDF</a><br /><b>Abstract: </b>We present efficient data structures for problems on unit discs and arcs of
their boundary in the plane. (i) We give an output-sensitive algorithm for the
dynamic maintenance of the union of $n$ unit discs under insertions in $O(k
\log^2 n)$ update time and $O(n)$ space, where $k$ is the combinatorial
complexity of the structural change in the union due to the insertion of the
new disc. (ii) As part of the solution of (i) we devise a fully dynamic data
structure for the maintenance of lower envelopes of pseudo-lines, which we
believe is of independent interest. The structure has $O(\log^2 n)$ update time
and $O(\log n)$ vertical ray shooting query time. To achieve this performance,
we devise a new algorithm for finding the intersection between two lower
envelopes of pseudo-lines in $O(\log n)$ time, using \emph{tentative} binary
search; the lower envelopes are special in that at $x=-\infty$ any pseudo-line
contributing to the first envelope lies below every pseudo-line contributing to
the second envelope. (iii) We also present a dynamic range searching structure
for a set of circular arcs of unit radius (not necessarily on the boundary of
the union of the corresponding discs), where the ranges are unit discs, with
$O(n \log n)$ preprocessing time, $O(n^{1/2+\varepsilon} + \ell)$ query time
and $O(\log^2 n)$ amortized update time, where $\ell$ is the size of the output
and for any $\varepsilon&gt;0$. The structure requires $O(n)$ storage space.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10943"><span class="datestr">at March 27, 2019 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10942">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10942">Reconstruction of r-Regular Objects from Trinary Images</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Helene Svane, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Plessis:Andrew_du.html">Andrew du Plessis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10942">PDF</a><br /><b>Abstract: </b>We study digital images of r-regular objects where a pixel is black if it is
completely inside the object, white if it is completely inside the complement
of the object, and grey otherwise. We call such images trinary. We discuss
possible configurations of pixels in trinary images of r-regular objects at
certain resolutions and propose a method for reconstructing objects from such
images. We show that the reconstructed object is close to the original object
in Hausdorff norm, and that there is a homeomorphism of the plane taking the
reconstructed set to the original.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10942"><span class="datestr">at March 27, 2019 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10710">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10710">Computing the Homology of Semialgebraic Sets. II: General formulas</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=uuml=rgisser:Peter.html">Peter B√ºrgisser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cucker:Felipe.html">Felipe Cucker</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tonelli=Cueto:Josu=eacute=.html">Josu√© Tonelli-Cueto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10710">PDF</a><br /><b>Abstract: </b>We describe and analyze an algorithm for computing the homology (Betti
numbers and torsion coefficients) of semialgebraic sets given by Boolean
formulas. The algorithm works in weak exponential time. This means that outside
a subset of data having exponentially small measure, the cost of the algorithm
is single exponential in the size of the data. This extends the previous work
of the authors in <a href="http://export.arxiv.org/abs/1807.06435">arXiv:1807.06435</a> to arbitrary semialgebraic sets.
</p>
<p>All previous algorithms proposed for this problem have doubly exponential
complexity (and this is so for almost all input data).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10710"><span class="datestr">at March 27, 2019 11:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10706">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10706">Complexity Thresholds in Inclusion Logic</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hannula:Miika.html">Miika Hannula</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hella:Lauri.html">Lauri Hella</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10706">PDF</a><br /><b>Abstract: </b>Logics with team semantics provide alternative means for logical
characterization of complexity classes. Both dependence and independence logic
are known to capture non-deterministic polynomial time, and the frontiers of
tractability in these logics are relatively well understood. Inclusion logic is
similar to these team-based logical formalisms with the exception that it
corresponds to deterministic polynomial time in ordered models. In this article
we examine connections between syntactical fragments of inclusion logic and
different complexity classes in terms of two computational problems: maximal
subteam membership and the model checking problem for a fixed inclusion logic
formula. We show that very simple quantifier-free formulae with one or two
inclusion atoms generate instances of these problems that are complete for
(non-deterministic) logarithmic space and polynomial time. Furthermore, we
present a fragment of inclusion logic that captures non-deterministic
logarithmic space in ordered models.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10706"><span class="datestr">at March 27, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10701">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10701">Syntactic View of Sigma-Tau Generation of Permutations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rytter:Wojciech.html">Wojciech Rytter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuba:Wiktor.html">Wiktor Zuba</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10701">PDF</a><br /><b>Abstract: </b>We give a syntactic view of the Sawada-Williams $(\sigma,\tau)$-generation of
permutations. The corresponding sequence of $\sigma-\tau$-operations, of length
$n!-1$ is shown to be highly compressible: it has $O(n^2\log n)$ bit
description. Using this compact description we design fast algorithms for
ranking and unranking permutations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10701"><span class="datestr">at March 27, 2019 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10700">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10700">On the tractability of the maximum independent set problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dharmarajan:R=.html">R. Dharmarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramachandran:D=.html">D. Ramachandran</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10700">PDF</a><br /><b>Abstract: </b>The maximum independent set problem is a classical NP-complete problem in
graph theory and has important practical applications in many domains. In this
paper we show, in a partially non-constructive way, the existence of an exact
polynomial-time algorithm for this problem. We outline the algorithm in
pseudo-code style. Then we prove its exactness and efficiency by analysis.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10700"><span class="datestr">at March 27, 2019 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10618">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10618">Faster Random $k$-CNF Satisfiability</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lincoln:Andrea.html">Andrea Lincoln</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html">Adam Yedidia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10618">PDF</a><br /><b>Abstract: </b>We describe an algorithm to solve the problem of Boolean CNF-Satisfiability
when the input formula is chosen randomly.
</p>
<p>We build upon the algorithms of Sch{\"{o}}ning 1999 and Dantsin et al.~in
2002. The Sch{\"{o}}ning algorithm works by trying many possible random
assignments, and for each one searching systematically in the neighborhood of
that assignment for a satisfying solution. Previous algorithms for this problem
run in time $O(2^{n (1- \Omega(1)/k)})$.
</p>
<p>Our improvement is simple: we count how many clauses are satisfied by each
randomly sampled assignment, and only search in the neighborhoods of
assignments with abnormally many satisfied clauses. We show that assignments
like these are significantly more likely to be near a satisfying assignment.
This improvement saves a factor of $2^{n \Omega(\lg^2 k)/k}$, resulting in an
overall runtime of $O(2^{n (1- \Omega(\lg^2 k)/k)})$ for random $k$-SAT.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10618"><span class="datestr">at March 27, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.10583">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.10583">Algorithms to compute the Burrows-Wheeler Similarity Distribution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Felipe A. Louza, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Telles:Guilherme_P=.html">Guilherme P. Telles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gog:Simon.html">Simon Gog</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Liang.html">Liang Zhao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.10583">PDF</a><br /><b>Abstract: </b>The Burrows-Wheeler transform (BWT) is a well studied text transformation
widely used in data compression and text indexing. The BWT of two strings can
also provide similarity measures between them, based on the observation that
the more their symbols are intermixed in the transformation, the more the
strings are similar. In this article we present two new algorithms to compute
similarity measures based on the BWT for string collections. In particular, we
present practical and theoretical improvements to the computation of the
Burrows-Wheeler similarity distribution for all pairs of strings in a
collection. Our algorithms take advantage of the BWT computed for the
concatenation of all strings, and use compressed data structures that allow
reducing the running time with a small memory footprint, as shown by a set of
experiments with real and artificial datasets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.10583"><span class="datestr">at March 27, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-3721224241252487082">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/PTrXNVY99dg/on-pc-submissions-at-soda-2020.html">On PC submissions at SODA 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
SODA 2020 (in SLC!!) is experimenting with a new submission guideline: PC members will be allowed to submit papers. I had a conversation about this with Shuchi Chawla (the PC chair) and she was kind enough (thanks Shuchi!) to share the guidelines she's provided to PC members about how this will work.<br /><br />  <br /><blockquote class="tr_bq"><span class="s1">SODA is allowing PC members (but not the PC chair) to submit papers this year. To preserve the integrity of the review process, we will handle PC member submissions as follows.</span>¬†</blockquote><blockquote class="tr_bq"><span class="s1">1. PC members are required to declare a conflict for papers that overlap in content with their own submissions (in addition to other CoI situations). These will be treated as hard conflicts. If necessary, in particular if we don't have enough confidence in our evaluation of a paper, PC members will be asked to comment on papers they have a hard conflict with. However, they will not have a say in the final outcome for such papers.¬†</span>¬†</blockquote><blockquote class="tr_bq"><span class="s1">2. PC submissions will receive 4 reviews instead of just 3. This is so that we have more confidence on our evaluation and ultimate decision.</span>¬†</blockquote><blockquote class="tr_bq"><span class="s1">3. We will make early accept/reject decisions on PC members submissions, that is, before we start considering "borderline" papers and worrying about the total number of papers accepted. This is because the later phases of discussion are when subjectivity and bias tend to creep in the most.</span>¬†</blockquote><blockquote class="tr_bq"><span class="s1">4. In order to be accepted, PC member submissions must receive no ratings below "weak accept" and must receive at least two out of four ratings of "accept" or above.</span>¬†¬†</blockquote><blockquote class="tr_bq">5. PC member submissions will not be eligible for the best paper award.</blockquote><br />My understanding is that this was done to solve the problem of not being able to get people to agree to be on the PC - this year's PC has substantially more members than prior years.<br /><br />And yet....<br /><br />Given all the discussion about conflicts of interest, implicit bias, and double blind review, this appears to be a bizarrely retrograde move, and in fact one that sends a very loud message that issues of implicit bias aren't really viewed as a problem. As one of my colleagues put it sarcastically when I described the new plan:<br /><br /><blockquote class="tr_bq">"why don't they just cut out the reviews and accept all PC submissions to start with?"</blockquote>and as another colleague pointed out:<br /><br /><blockquote class="tr_bq">"It's mostly ridiculous that they seem to be tying themselves in knots trying to figure out how to resolve COIs when there's a really easy solution that they're willfully ignoring..."</blockquote><br />Some of the arguments I've been hearing in support of this policy frankly make no sense to me.<br /><br />First of all, the idea that a more heightened scrutiny of PC papers can alleviate the bias associated with reviewing papers of your colleagues goes against basically all of what we know about implicit bias in reviewing. The most basic tenet of human judgement is that we are very bad at filtering our own biases and this only makes it worse. The one thing that theory conferences (compared to other venues) had going for them regarding issues of bias was that PC members couldn't submit papers, but now....<br /><br />Another claim I've heard is that the¬†scale of SODA makes double blind review difficult. It's hard to hear this claim without bursting out into hysterical laughter (and from the reaction of the people I mentioned this to, I'm not the only one).¬† Conferences that manage with double blind review (and PC submissions btw) are at least an order of magnitude bigger (think of all the ML conferences). Most conference software (including easy chair) is capable of managing the conflicts of interest without too much trouble. Given that SODA (and theory conferences in general) are less familiar with this process, I‚Äôve recommended in the past that there be a ‚Äúworkflow chair‚Äù whose job it is to manage the unfamiliarity associated with dealing the software. Workflow chairs are common at bigger¬†conferences that typically deal with 1000s of reviewers and conflicts.<br /><br />Further, as a colleague points out, what one should really be doing is "aligning nomenclature and systems with other fields:¬†call current PC as SPC or Area Chairs, or your favorite nomenclature, and add other folks as reviewers. This way you (i) get a list of all conflicts entered into the system, and (ii) recognize the work that the reviewers are doing more officially as labeling the PC members. "<br /><br /><br />Changes in format (and culture) take time, and I'm still hopeful that the SODA organizing team¬† will take a lesson from <a href="https://algo2019.ak.in.tum.de/index.php/menue-esa/esa-call">ESA 2019</a>¬† (and their own resolution to look at DB review more carefully that was passed a year or so ago) and consider exploring DB review. But this year's model is certainly not going to help.<br /><div><br /><b>Update: </b><a href="https://twitter.com/stevemblackburn/status/1111068299796705280?s=20">Steve Blackburn outlines how PLDI handles PC submissions</a> (in brief, double blind + external review committee)<br /></div><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=PTrXNVY99dg:dU6PgEFG5Fg:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=PTrXNVY99dg:dU6PgEFG5Fg:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/PTrXNVY99dg" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/PTrXNVY99dg/on-pc-submissions-at-soda-2020.html"><span class="datestr">at March 26, 2019 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17141">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/">10 Milestones in the History of Mathematics according to Nati and Me</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>Breaking news:</strong> David Harvey and Joris Van Der Hoeven. <a href="https://hal.archives-ouvertes.fr/hal-02070778?fbclid=IwAR3Mww03vOBjDTfhBT4UQUxBQpPBb0ZJfF6QyeyR2h4UosKNB8stB5ewY2Y">Integer multiplication in time O(nlogn).</a> 2019. (<span class="fwb">I heard about it from Yoni Rozenshein on FB (◊ó◊§◊ô◊®◊ï◊™ ◊¢◊ú ◊û◊™◊û◊ò◊ô◊ß◊î) )¬†</span></p>
<p>_____</p>
<p>In 2006, the popular science magazine ‚ÄúGalileo‚Äù prepared a special issue devoted to milestones in the History of several areas of science and Nati Linial and me wrote the article about mathematics <a href="http://www.cs.huji.ac.il/~nati/PAPERS/galileo.pdf">Ten milestones in the history of mathematics</a> (in Hebrew). Our article had 10 sections highlighting one or two discoveries in each section.</p>
<p>Here are our choices. <span style="color: #993366;"><strong>What would you add? what would you delete?</strong></span></p>
<p>¬†</p>
<h3><a href="https://gilkalai.files.wordpress.com/2019/03/galileo1.png"><img width="300" alt="" src="https://gilkalai.files.wordpress.com/2019/03/galileo1.png?w=300&amp;h=161" class="alignnone size-medium wp-image-17241" height="161" /></a> <a href="https://gilkalai.files.wordpress.com/2019/03/gal3.png">¬†<img width="300" alt="" src="https://gilkalai.files.wordpress.com/2019/03/gal3.png?w=300&amp;h=227" class="alignnone size-medium wp-image-17256" height="227" /></a><a href="https://gilkalai.files.wordpress.com/2019/03/gal7.png">¬†</a></h3>
<h3></h3>
<h1><span style="color: #0000ff;">The list</span></h1>
<h3>1) Numbers and Number Systems ‚Äì The Irrationality of the square root of 2</h3>
<blockquote><p><em><strong><span style="color: #ff0000;">Discovery No.1: the square root of 2 is not a rational number.</span></strong></em></p></blockquote>
<p>¬†</p>
<h3>2) Geometry, the Discovery of Non-Euclidean Geometry, and Topology</h3>
<blockquote><p><em><strong><span style="color: #ff0000;">Discovery no.2(A): Euclidean Geometry</span></strong></em></p>
<p><strong><span style="color: #ff0000;"><em>Discovery no.2(B): Non-Euclidean Geometry</em></span></strong></p></blockquote>
<p>¬†</p>
<h3>3) Algebra, Equations and Mathematical Formulas. Galois Theory.<strong><strong><br />
</strong></strong></h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no.3:¬† Abel-Galois Theorem: there is no solution with radicals to the general equation of the fifth degree and above.</strong></span></em></p></blockquote>
<h3></h3>
<h3>4) Analysis and the Connection to Physics</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 4(A): Differential and integral calculus (Isaac Newton, Gottfried Leibniz, 17<sup>th</sup> Century).</strong></span></em></p>
<p><em><span style="color: #ff0000;"><strong>Discovery no. 4(B): The analysis of complex functions (Augustin-Louis </strong><strong>Cauchy, Bernhard Riemann, 19<sup>th</sup> century)</strong></span>.</em></p>
<p>¬†</p></blockquote>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/nati.jpg"><img src="https://gilkalai.files.wordpress.com/2019/03/nati.jpg?w=640" alt="" class="alignnone size-full wp-image-17251" /></a></p>
<h3><span style="color: #0000ff;"><strong>Nati Linial</strong></span></h3>
<h3>5) Proofs and their Limitations: Logic, Set Theory, the Infinity, and G√∂del‚Äôs Incompleteness Theorem.</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 5(A): There are various kinds of infinity. For example, there are more real numbers than natural numbers.</strong></span></em></p></blockquote>
<p><span id="more-17141"></span></p>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 5(B): G√∂del‚Äôs Incompleteness theorem: A mathematical theory broad enough includes true statements that cannot be proven.</strong></span></em><br />
<em>¬†</em></p></blockquote>
<h3></h3>
<h3>6)¬† Linear Algebra, Linear Programming and Optimization</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 6(A): The Gauss elimination method for solving systems of linear equations.</strong></span></em></p>
<p><em><strong><span style="color: #ff0000;">Discovery no. 6(B): Linear programming and the Simplex algorithm for solving it.</span></strong></em></p></blockquote>
<h3></h3>
<p>¬†</p>
<h3>7) Probability Theory and the Bell curve</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 7: The Bell Curve and the Central Limit Theorem</strong></span></em></p>
<p>¬†</p></blockquote>
<h3><a href="https://gilkalai.files.wordpress.com/2019/03/galileo6.png"><img width="300" alt="" src="https://gilkalai.files.wordpress.com/2019/03/galileo6.png?w=300&amp;h=174" class="alignnone size-medium wp-image-17245" height="174" /></a></h3>
<p>¬†</p>
<h3>8) Prime Numbers and their Density</h3>
<blockquote><p><em><strong><span style="color: #ff0000;">Discovery no. 8: The Prime Number Theorem.</span></strong></em></p></blockquote>
<h3></h3>
<p>¬†</p>
<h3>9) Algorithms, Digital Computers and their Limitations</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 9 (a): The theory of computability. Undecidable problems.</strong></span></em></p>
<p><em><span style="color: #ff0000;"><strong>Discovery no. 9 (b): Computational Complexity theory. The theory of NP-complete problems.</strong></span></em><br />
<em>¬†</em></p></blockquote>
<h3></h3>
<h3>10)¬† Applied Mathematics</h3>
<blockquote><p><em><span style="color: #ff0000;"><strong>Discovery no. 10: Additional paradigms of mathematical research beyond the paradigm of theorem/proof. Numerical methods, simulations, scientific computation and the development of mathematical models.</strong></span></em></p></blockquote>
<p>¬†</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/galileo2-1.png"><img width="300" alt="" src="https://gilkalai.files.wordpress.com/2019/03/galileo2-1.png?w=300&amp;h=283" class="alignnone size-medium wp-image-17244" height="283" /></a></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/"><span class="datestr">at March 26, 2019 07:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7484">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/03/26/news-addicts-sign-up-for-the-catcs-newsletter/">News addicts: Sign up for the CATCS newsletter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>If, like others following <a href="https://xkcd.com/1227/">the pace of modern life</a>, you‚Äôre the kind of person that needs to get just on time updates on the state of theoretical computer science, consider signing up for the newsletter of CATCS.  You can get information about funding opportunities, advocacy efforts, and more. Sure, at the hectic rate of two messages per year, it might flood your inbox, but it is worth it.</p>



<p></p>



<p>Dear Theoretical Computer Scientist,</p>



<p><br />The <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science </a>(CATCS) was established by SIGACT to deal with funding, outreach, and advocacy issues for our community. If you would like to receive our newsletter (no more than twice annually) we encourage you to sign up for the Google group below:<br /><a href="https://groups.google.com/forum/#!forum/catcs-news" target="_blank" rel="noreferrer noopener">https://groups.google.com/forum/#!forum/catcs-news</a><br />(Navigate to the page above and click ‚ÄúJoin group.‚Äù You can unsubscribe at any time from the same page.)<br />Best wishes, CATCS </p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2019/03/26/news-addicts-sign-up-for-the-catcs-newsletter/"><span class="datestr">at March 26, 2019 04:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/">postdoc at Bar Ilan University (apply by May 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In the our big data lab, we have several postdoctoral positions in Algorithms, Data Structures, Distributed, and Compress Sensing.</p>
<p>Website: <a href="http://www.cs.biu.ac.il/~porately/">http://www.cs.biu.ac.il/~porately/</a><br />
Email: porately@cs.biu.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/"><span class="datestr">at March 25, 2019 08:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2572656159267507055">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html">Random Thoughts on the admissions scandal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In light of the recent academic scandal I am going to list ways I've heard to help get your kid into college and thoughts on how ethical they are (hint: bribing a coach to claim your kid is on the rowing team is not ethical).<br />
<br />
1) Your kid likes (1) helping the homeless and (2)¬† Ramsey Theory and (3)¬† helping the homeless learn Ramsey Theory. Or perhaps they like¬† rowing or Latin or fencing or Pig Latin or....¬† Great! encourage them, get them books and tutors,¬† and whatever they need. You have an eye towards how this will look on for college admissions; however, it is your kids choice as to what they like. Also note that these activities are in addition to doing well in school, SATs, etc, not instead of it.¬† Perfectly ethical, though I note that this avenue is not open to poor families and in some cases even middle class families.<br />
<br />
2) Item 1 is the extreme on a spectrum in terms of how much are the extra things the kid does there idea OR planned by you to GET INTO A GOOD COLLEGE. This item will be the other extreme, but realize there is a continuum (actually I doubt there are a continuum number of options here, but there are many in between. Maybe its omega + omega*.) You have heard that being on the¬†<a href="https://en.wikipedia.org/wiki/Chess_boxing">chess boxing</a> teams is good on a college application so you TELL YOUR KID that they¬† likes both Chess AND Boxing and should be on the team. You also hear this about being on the fencing team and knowing <a href="https://en.wikipedia.org/wiki/Pig_Latin">pig latin</a>, so your kid can taunt their opponents like this:<br />
<br />
youah, aint-kay ence-fay orth-way eans-bay<br />
<br />
This might not be as bad as it sounds if the kid learns to like Chess-Boxing.¬† But it may be worse than it sounds if the kid rebels against all of this and becomes a crack whore.<br />
<br />
Is this ethical? It may be bad for the kid, but it may push him into things he ends up liking. One drawback: you've HEARD that being on the chess boxing team is good for college admissions, but is it true?<br />
<br />
And again, not open to some families.<br />
<br />
3) Item 2 (or even 1) but with an addition: Hire a college adviser to help you. Someone who knows (or claims to know) what colleges look for- Trombone, Latin, Chess-boxing, whatever. Still ethical but I again worry about the kids future rehab bills.<br />
<br />
4) Here is where it gets murky. The college adviser helps:<br />
<br />
a) Polish the kids essay (my parents, who are both in English, helped polish my essay to get into graduate school (I don't recall if there was one for ugrad). They told me to use lots of `ing' words so it sounds like I am actively doing things. They also helped me figure out when recursion-theoretic is hyphenated. I got into Harvard but not MIT, so make of that what you will.) Polishing, proofreading, that could be okay. But it can slip into b or c below.<br />
<br />
b) The adviser (or the parents) talk to the kids to find out what to write, but then writes it. Maybe the kid proofreads and polishes. Maybe not even. The adviser is¬† a ghostwriter. Clearly unethical but the line between helping-to-polish and adviser-wrote-it is again a continuum.<br />
<br />
c) Adviser writes it and it is completely fictional. I once heard a rumor that a particular sample of an essay to get into med school was used¬† by several¬† med school applicant. Gee,they can't all have gotten inspired by watching their grandfather in his pajamas die of cancer. This is awful of course, but I wonder- what if the student writes a fictional essay all by themselves! Some combination of how much the essay is true and how much help you got on it is unethical. But some might be okay. Is it bad to polish stories that are basically true to make them flow more easily?¬† Prob not. But there is a 2-dim continuum based on both accuracy and how much help the student got.<br />
<br />
As a side note- how much does the personal statement matter for admissions? I suspect that if an elite school gets LOTS of REALLY QUALIFIED applicants, the essay may be all that distinguishes them.So it can be important. I also wonder if people on admissions can tell if an essay is not written by the applicant. Or maybe if there is an interview that can help detect it.<br />
<br />
5) Parents give X amount of money to the college and the kid gets in. This is talked about a lot though I don't know how common it is for someone NOT qualified to GET IN based on money. College admissions has many factors so its not quite so clear cut what NOT qualified means. Even so, if seems odd that this is not in any way shape or form illegal. It IS transparent, so I guess thats a plus. The argument I've heard is that the money is used for scholarships to fund students who get in but can't afford to go. I do not know if this is true. And this one¬† is only available to the top Z %, not sure what Z is, but there are people who can do 1,2,3,4 who can't do 5. I would call this unethical though colleges don't seem to think so. Or they do but they do it anyway.<br />
<br />
6) Before I list the current scandal I want to list another issue: having a psychologist (or whoever it is who judges these things) say your kid is Learning Disabled so they get more time on the SATs. Perhaps bribing them, or perhaps its understood what you want.¬† Again, I do not know how common this is.¬† An alternative if you can't afford some of the above options, or done in conjunction with a lot of the above options.<br />
<br />
7) The current scandal. Obviously unethical. A few things I wonder about:<br />
<br />
a) One story was that they bribed someone to say their daughter was Learning Disabled and had to take the SAT (or whatever it was) in a separate room, making it easier to change the answers to the correct ones.¬† So twice unethical.<br />
<br />
b) Some of the students¬† were clearly NOT qualified.<br />
<br />
c) A parent does unethical things to get the kid into college.<br />
<br />
The kid later lies to the parents about their grades or their plans<br />
<br />
The parents are SHOCKED that their kids lie and wonder where the learned such behaviour!<br />
<br />
8) Actually Item 2 --Parent has kid do things to plan to get into college-- is interesting for another reason. Are you your resume?<br />
<br />
Imagine that Alice helps the homeless her Sophmore year in High School NOT because she cares about the homeless but because its good for college admissions.<br />
<br />
Alice goes on to do other things that look good for college, NOT because she likes them or cares, but just to get into a good college.<br />
<br />
She gets into an elite college<br />
<br />
Did they take her in the hope she would KEEP doing these things or because she is the KIND OF PERSON who does these things?<br />
<br />
And it gets weirder- she DOES keep doing these things since she's heard its good for Business School (disclaimer- I do not know if its good for B-school)<br />
<br />
More generally, she keeps doing things she doesn't care about to advance. So her outward self really is doing good deeds and such, but her heart is not in it. So if her college or B-school or Job hired her because she DOES these things, that is NOT a lie. If they hired her because they want this KIND OF PERSON then... its a lie but I'm not sure what to make of that.<br />
<br />
9) Is there ANY reason to have legacy matter for admissions? This seems like the dumbest and most easily fixed aspect of the whole process.¬† I have never heard a good argument for it. Ever.<br />
<br />
10) College Sports--- that's an entire blog post or book all by itself, so I won't go there.<br />
<br />
11) One can argue whether helping the homeless, or being on the rowing team, or teaching the homeless how to row, should matter for college anyway. But lets assume that its legit to want people at your college who have lead interesting lives. So charity work or sports might be a MEASURE of that. But beware Goodhart's law:<br />
<br />
¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†<i> When a measure becomes a target is ceases to be a measure.</i><br />
<i><br /></i>
The recent scandal is Goodhart's law on steroids.<br />
(NOTE- I had in earlier version `Goodwin's law' but a commenter corrected me and reminded me that Goodwin's law is that if an internet discussion goes on long enough someone will be compared to Hitler. I wonder if that also applies in discussions by Nazi's.)<br />
<br />
12) Does getting into an Elite College really increase your income or happiness (these are two very different questions) over the course of your life? I do not know-- if you do, please comment.<br />
<br />
13) (ADDED LATER) A commenter pointed out that one could also go to a school outside of¬† the USA that values proficiency in the chosen discipline over the items above. Excellent question that raises a few more:<br />
<br />
Do schools outside of the USA hold Americans (or for that matter any non-citizen of their country) to a higher standard for admissions? I ask non-rhetorically.<br />
<br />
If you get a degree from outside of the USA will that help or hurt your job prospects in the USA? Of course this depends on the school you goto, but even with that I do not know the answer.<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html"><span class="datestr">at March 24, 2019 09:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/043">TR19-043 |  Nondeterministic and Randomized Boolean Hierarchies in Communication Complexity | 

	Toniann Pitassi, 

	Morgan Shirley, 

	Thomas Watson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the Boolean Hierarchy in the context of two-party communication complexity, as well as the analogous hierarchy defined with one-sided error randomness instead of nondeterminism. Our results provide a complete picture of the relationships among complexity classes within and across these two hierarchies. In particular, we prove a query-to-communication lifting theorem for all levels of the Boolean Hierarchy and use it to resolve an open problem stated in the paper by Halstenberg and Reischuk (CCC 1988) which initiated this topic.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/043"><span class="datestr">at March 24, 2019 07:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Danny Nguyen and Igor Pak: Presburger Arithmetic Problem Solved!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2>Short Presburger arithmetic is hard!</h2>
<p>This is a belated report on a remarkable breakthrough from 2017. The paper is <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>, by Nguyen and Pak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg"><img src="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg?w=640" alt="" class="alignnone size-full wp-image-17213" /></a></p>
<p><strong><span style="color: #ff0000;">Danny Nguyen</span></strong></p>
<h3>Integer programming in bounded dimension: Lenstra‚Äôs Theorem</h3>
<p>Algorithmic tasks are often intractable. But there are a few miracles where efficient algorithms exist: Solving systems of linear equations, linear programming, testing primality,¬† and solving integer programming problems when the number of variables is bounded. The last miracle is a historic 1983 theorem of Hendrik Lenstra (Here <a href="https://people.csail.mit.edu/rrw/presentations/Lenstra81.pdf">is the paper</a>) and it is the starting point of this post.</p>
<p><strong>Lensra‚Äôs theorem:</strong> Consider a system of linear inequalities</p>
<h3 style="text-align: center;"><em>Ax ‚â§ b</em></h3>
<p>where <img src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2Cx_2%2C%5Cdots+x_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=(x_1,x_2,\dots x_k)" class="latex" title="x=(x_1,x_2,\dots x_k)" /> is a vector of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> variables, <em>A</em> is an integral <em>k</em> by <em>n</em> matrix and <em>b</em> is an integral vector of length <em>n</em>.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> be a fixed integer. There is a polynomial time algorithm to determine if the system has an integral solution.</p>
<p>Of course, the full Integer Programming problem when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is part of the input, is <strong>NP-complete</strong>. This problem came already (second in Karp‚Äôs list!) in<a href="https://people.eecs.berkeley.edu/~luca/cs172/karp.pdf"> the Mayflower of NP-complete problems ‚Äì¬† Karp‚Äôs paper</a>.</p>
<p>Sasha Barvinok famously showed in 1993 that even counting the number of solutions is in <strong>P</strong>. (Barvinok¬†utilized the short generating function approach pioneered by Brion, Vergne and others.)</p>
<h3>Kannan‚Äôs theorem</h3>
<p>Next,¬† I want to describe an amazing 1990 theorem of Ravi Kannan,</p>
<p>Kannan‚Äôs theorem considers formulas with one quantifier alternation in the Presburger arithmetic and it asserts that when the number of variables is fixed,¬† there is a polynomial time algorithm to decide if the formula is satisfiable.</p>
<p>(Here is a free version of <a href="http://www.cs.yale.edu/homes/kannan/Papers/forall.pdf">Kannan‚Äôs paper</a>.) Also here the counting problems were tackled with great success. Barvinok and Kevin Woods remarkably showed <a href="http://www.ams.org/journals/jams/2003-16-04/S0894-0347-03-00428-4/S0894-0347-03-00428-4.pdf">how to count projections of integer points in a (single) polytope in polynomial time</a>, and subsequently Woods <a href="http://www2.oberlin.edu/faculty/kwoods/research/Presburger_full.pdf">extended this approach</a> to general Presburger expressions Œ¶ with a fixed number of inequalities!</p>
<p>An important strengthening was achieved by Friedrich Eisenbrand and ¬†Gennady Shmonin in the 2008 paper <a href="https://arxiv.org/abs/0801.4336">Parametric integer programming in fixed dimension</a>. See also the survey chapter by Barvinok <a href="https://www.csun.edu/~ctoth/Handbook/chap7.pdf">Lattice points and lattice polytopes</a>.</p>
<p>You can find the formulation of Kannan‚Äôs theorem in full generality a little further but let me present now a special case related to the famous Frobenius coin problem. (See <a href="https://rjlipton.wordpress.com/2009/03/07/finite-state-automata-binary-decision-diagrams-and-presburger-arithmetic/">this post on GLL</a> for more on Presburger arithmetic)</p>
<h3>Frobenius coin problem</h3>
<p>Given <em>k</em> coins with integral values, the <a href="https://en.wikipedia.org/wiki/Coin_problem">Frobinius coin problem</a> is to determine the largest integer that cannot be described as positive integer combinations of the values of the coins. (See also <a href="https://rjlipton.wordpress.com/2011/04/30/congrats-ravi-kannan/">this post</a> on GLL.)</p>
<p><strong>Theorem (Kannan):</strong> There is a polynomial time algorithm to solve the Frobenius coin problem for every fixed number of coins.</p>
<p>The issue of the way theory meets practice for the problems discussed in this post is very interesting but we will not discuss it. Let me remark that Herb Scarf (who along with Kannan played a role in B-L (Before Lenstra) developments) offered another approach for the solution of the Frobenius coin problem and related IP (Integer Programming)¬† problems based on his theory of maximal lattice-free convex bodies. See <a href="https://gilkalai.wordpress.com/2013/02/22/ann-lehmans-sculpture-based-on-herb-scarfs-maximal-lattice-free-convex-bodies/">this related post</a>.</p>
<h3>More than one quantifier</h3>
<p>Given the result of Kannan and later that of Barvinok and Woods, many people expected that also for two alternations, or even for any other fixed number of alternations, Presburger arithmetic would be in polynomial time. Nguyen and Pak proved that the problem is <strong>NP-complete</strong> already for two quantifier alternations! Here is the link to the paper <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>. Igor Pak‚Äôs homepage has a few other <a href="http://www.math.ucla.edu/~pak/papers/research.htm#ip">related papers</a>.</p>
<p>Let me bring here Sasha Barvinok‚Äôs <a href="http://www.math.ucla.edu/~pak/papers/PA-Barv-rev.pdf">MathSciNet featured review</a> of Nguyen and Pak‚Äôs paper which tells the story better than I could.</p>
<h2>Barvinok‚Äôs featured review to Nguyen and Pak‚Äôs paper</h2>
<p>Presburger arithmetic allows integer variables, integer constants, Boolean operations (&amp;, ‚àß, ¬¨), quantifiers (‚àÉ, ‚àÄ), equations and inequalities (=, &lt;, &gt;, ‚â§, ‚â•), addition and subtraction (+, ‚àí) and multiplication by integer constants. It does not allow multiplication of variables (if we allow multiplication of variables, we get Peano arithmetic).</p>
<p>Geometrically, a quantifier-free formula of Presburger arithmetic describes the set of integer points in a Boolean combination of rational polyhedra (that is, in the set obtained from finitely many rational polyhedra by taking unions, intersections and complements). Similarly, a formula of Presburger arithmetic with existential quantifiers only describes the set of integer points obtained from the set of integer points in a Boolean combination of polyhedra by a projection along some coordinates.</p>
<p>Unlike Peano arithmetic, Presburger arithmetic is decidable. Here the authors zoom in on the computational complexity of Presburger arithmetic, once the combinatorial complexity of the formula is bounded in advance. If we fix the number of variables, the validity of a formula with no quantifier alternations (that is, of the type ‚àÉ<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ‚àÉ<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />Œ¶(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+latex+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , latex x_k" class="latex" title="x_1, \dots , latex x_k" />) or of the type ‚àÄ<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ‚àÄ<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />Œ¶(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , x_k" class="latex" title="x_1, \dots , x_k" />)) can be established in polynomial time by Lenstra‚Äôs integer programming algorithm [see H. W. Lenstra Jr., Math. Oper. Res. 8 (1983), no. 4, 538‚Äì548; MR0727410].</p>
<p>For a fixed number of variables, formulas with one quantifier alternation (‚àÉ<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ‚àÉ<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />‚àÄ<img src="https://s0.wp.com/latex.php?latex=y_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_1" class="latex" title="y_1" /> . . . ‚àÄ<img src="https://s0.wp.com/latex.php?latex=y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_m" class="latex" title="y_m" />Œ¶(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k%2C+y_1%2C+%5Cdots+%2C+y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , x_k, y_1, \dots , y_m" class="latex" title="x_1, \dots , x_k, y_1, \dots , y_m" />)) can also be solved in polynomial time, as shown by R. Kannan [in Polyhedral combinatorics (Morristown, NJ, 1989), 39‚Äì47, DIMACS Ser. Discrete Math. Theoret. Comput. Sci., 1, Amer. Math. Soc., Providence, RI, 1990; MR1105115]. The decision procedure can be characterized as a polynomial time algorithm for parametric integer programming.</p>
<p>Suppose now that we fix the number of variables and the number of Boolean operations in advance (and hence get what is called a short formula of Presburger arithmetic). Thus the only parameters of the formula are the numerical values of the constants in the formula. The authors show that deciding validity becomes <strong>NP-complete</strong> if one allows<br />
two quantifier alternations. Remarkably, they present an example of a formula</p>
<p>‚àÉz ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" /> ‚àÄy ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> ‚àÉx ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> Œ¶(x, y, z)</p>
<p>with an <strong>NP-complete</strong> decision problem, even though Œ¶ contains at most 10 inequalities.<br />
Another remarkable example is an <strong>NP-complete</strong> decision problem for a formula of the<br />
type</p>
<p>‚àÉz ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" /> ‚àÄy ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> ‚àÉx ‚àà <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E6&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^6" class="latex" title="\mathbb Z^6" />: <em>Ax + By + Cz ‚â§ b,¬†¬†</em></p>
<p>with at most 24 inequalities.</p>
<p>As the number of quantifier alternations is allowed to increase, the computational complexity in the polynomial hierarchy also moves up. The authors also describe the computational complexity of corresponding counting problems.</p>
<p>The proof is very clever; it uses the continued fraction expansion of a rational number to encode a growing family of intervals, with the help of which the authors build an <strong>NP-complete</strong> problem.</p>
<p>¬†</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/"><span class="datestr">at March 22, 2019 09:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/">Workshop on Algebraic Complexity Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
March 25-29, 2019 The International Centre for Theoretical Sciences (ICTS), Bengaluru (India) https://www.icts.res.in/discussion-meeting/wact2019 The primary objective of this workshop is to bring together experts in the field of algebraic complexity and related areas to present their research, initiate collaborations etc. The idea is to continue the tradition of having a Workshop on Algebraic Complexity Theory ‚Ä¶ <a href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/" class="more-link">Continue reading <span class="screen-reader-text">Workshop on Algebraic Complexity¬†Theory</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/"><span class="datestr">at March 22, 2019 09:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://corner.mimuw.edu.pl/?p=1076">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/banach.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://corner.mimuw.edu.pl/?p=1076">The Curse of Euclidean Metric: Square Roots</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p style="text-align: justify;"><a href="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland.png"><img src="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland_small.png" align="right" class="wp-image-587 alignright" alt="The Curse of Metric Island" /></a></p>
<p>The deadline was approaching without mercy and there was, of course, still some polishing to be done for <a href="https://doi.org/10.1137/1.9781611975482.67">our SODA paper</a>. But then we run into an issue. To make things worse, this issue turned out to be a hard one, a fundamental known open problem in computational geometry. The good thing is, I liked the problem so much that I decided to dedicate it this post. This is the story about the Sum of Square Roots problem and how we bypassed (ignored) it without solving it.</p>
<p></p>
<p></p>
<p style="text-align: justify;">Everything began in the haze of the 70's of the last millennium. It is nebulous who stumbled first upon this enigma. <a href="https://www.ics.uci.edu/~eppstein/junkyard/small-dist.html">Some say</a> that Ron Graham has discussed the problem in public lectures, <a href="https://www.jstor.org/stable/2321488">some others</a> say that Joseph O'Rourke has posed it as an open question in the American Mathematical Monthly, while <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">some others</a> suspect that the problem had been already hiding in older different formulations. However, it is a historical fact that one shinny/cloudy day, three computer scientists finished polishing a manuscript that became a classical paper known as "<a href="https://doi.org/10.1145/800113.803626">Some NP-complete geometric problems</a>". In this paper, Michael Garey, Ron Graham and David Johnson showed the NP-hardness of two important problems in geometric metrics: Steiner Tree and Traveling Salesman. For the Euclidean plane, they showed only NP-hardness as they did not manage to show that these problems are contained in NP. Moreover, they accentuated that we cannot even rule out that the decision version of Euclidean Minimum Spanning Tree is outside of NP. What a seeming paradox given that we can compute such a minimum tree in polynomial time! So, whom did they blame? The short answer: The Euclidean metric. Garey and his coauthors explain that all these problems have a common hidden issue: They rely on comparing Euclidean lengths, that is, they rely on comparing irrational numbers based on square roots. Whereas this task is trivial if we just want to compare two line segments (e.g. by comparing the radicands), the problem starts when we want to compare two polygonal paths. Even assuming rational (or, after scaling, integer) coordinates, this problem translates into a question that is fundamental in computational geometry: Given two lists of integers, <em>a<sub>1</sub></em> ... and <em>b<sub>1</sub></em> ..., can we decide whether "<em>‚àë ‚àöa<sub>i</sub> ‚â• ‚àë ‚àöb<sub>i</sub></em>" in P? Put into words: <strong>Can we efficiently compare two sums of square roots over integers?</strong></p>
<p><span id="more-1076"></span></p>
<p></p>
<p></p>
<p style="text-align: justify;">To emphasize the significance of this question, let me cite <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">David Eppstein</a>: "A major bottleneck in proving NP-completeness for geometric problems is a mismatch between the real-number and Turing machine models of computation: one is good for geometric algorithms but bad for reductions, and the other vice versa. Specifically, it is not known on Turing machines how to quickly compare a sum of distances (square roots of integers) with an integer or other similar sums, so even (decision versions of) easy problems such as the minimum spanning tree are not known to be in NP."</p>
<p></p>
<p></p>
<p style="text-align: justify;">"Is this problem computable at all?" - might the curious reader ask after realizing that the approach of iteratively increasing the precision until the first difference in digits will never terminate if both numbers happen to be equal. Luckily, <a href="https://doi.org/10.1016/S0747-7171(85)80013-4">Allan Borodin et al.</a> and <a href="https://refubium.fu-berlin.de/handle/fub188/18449">Johannes Bl√∂mer</a> showed that polynomial time is enough to decide whether two such sums have the same value. Therefore, it is astonishing that the problem of deciding the sign of their difference, a question that seems only slightly harder, has been only recently spotted by <a href="https://doi.org/10.1137/070697926">Eric Allender et al</a> on an island of the counting hierarchy CH (3rd level) located in the wide ocean of PSPACE. Thus, it is still far far away from the needle head of P, where <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.5325">Gregorio Malajovich</a> conjectured it to live.¬†Until this will be shown, <a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">Jeff Erickson</a> proposes to study which problems are (<a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">non-boringly</a>) Œ£‚àö-hard.</p>
<p></p>
<p></p>
<p style="text-align: justify;">Oh, if we could only sufficiently bound the difference of the sums from below! Then we could bound from above the precision required to determine the correct sign of the difference: Just image that <em>B</em> is such a lower bound on the difference. Now, take a precision that allows us to compute an approximate difference being only <em>B/2</em> away from the real one. Then it is easy to verify that the following procedure determines the correct sign: Output the sign of the approximate difference if it is outside of <em>[-B/2,B/2]</em>, otherwise output <em>0</em>. What is the run time of this procedure? It is proportional to the precision, which corresponds to the length of <em>B</em>, that is, to <em>-log B</em>. Hence, if <em>-log B</em> is bounded from above by a polynomial in the length of the input, then we are in P! So, is there any reasonable lower bound for the worst case? That is, <strong>what is the smallest positive difference between any two sums of <em>k</em> square roots of integers of size at most <em>n</em>?</strong> Welcome to <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">Problem 33</a> of <a href="http://cs.smith.edu/~jorourke/TOPP/Welcome.html">The Open Problems Project</a>! Let <em>r(n,k)</em> denote such a minimum difference as a function of <em>n</em> and <em>k</em>. For instance, consider <em>n=20</em> and <em>k=2</em>. Then <em>r(n,k)</em> is roughly <em>0.0002</em> and it is attained by <em>‚àö{10} + ‚àö{11} - ‚àö{5} - ‚àö{18}</em>. As being an open problem, there is no tight bound known for <em>r(n,k)</em>. <a href="https://doi.org/10.1016/j.ipl.2006.05.002">Jianbo Qian and Cao An Wang</a> as well as <a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng and Yu-Hsin Li</a> proved(*) that there are sums where <em>-log r(n,k)</em> is at least in the order of magnitude of <em>k log n</em>. However, these lower bounds constitute an exponentially gap to the best known upper bounds which are <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Christoph Burnikel et al.</a>(**)] and <em>2<sup>O(n/log n)</sup></em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng et al.</a>]. So, maybe you, dear reader, will be the one to close the gap?</p>
<p></p>
<p></p>
<p style="text-align: justify;">In the dramatic opening of this post, I mentioned <a href="https://doi.org/10.1137/1.9781611975482.67">our paper</a>, where the problem of Sum of Square Roots appeared. There, we design a PTAS for the Traveling Salesman problem (TSP) with hyperplane neighborhoods, that is, we look for a <em>(1+Œµ)</em>-approximation of a minimum-length tour that, instead of points, visits a given set of hyperplanes in ‚Ñù<sup><em>d</em></sup> with <em>d</em> being fixed. The basis of our algorithm is an integer grid of constant size (depending on <em>Œµ</em> and <em>d</em>). Our key observation is that there is a translation and scaling of the grid such that snapping an (adequately sparsified) optimum solution to the grid results in a <em>(1+Œµ</em>)-approximation. Using this insight, we let our algorithm enumerate all (reasonable) TSP tours lying in our integer grid. With a simple LP, we translate and scale each tour such that it visits all the hyperplanes of the input whilst minimizing its tour length (i.e., the scaling factor). At the end, we obtain a set of feasible TSP tours and output the shortest one. And here we were confronted with the Sum of Square Roots problem. Which of the tours is the shortest one? Was all our work devastated, all our blood, sweat and tears in vain? Just because the very last line of our algorithm had unknown complexity? Our solution was simple: We just skipped the issue and our paper got accepted. Why? Well, the issue wasn't one for the following three reasons:</p>
<ul>
<li>We could be lazy and assume the real RAM computational model with constant time for square root operations (as often done in computational geometry).</li>
<li>We could be industrious and approximate the real tour lengths with a sufficiently small error since we look anyway for an approximation in overall.</li>
<li>We could think and then realize that our candidate tours consist of only¬†constant many vertices as our integer grid has constant size. Indeed, the best known lower bound on the difference <em>r(n,k)</em> implies the following nice take-away which shall conclude this epilogue:</li>
</ul>
<p><strong>We can compare two sums of square roots in polynomial time if the number of square roots is constant!</strong></p>
<p></p>
<p><em><a href="https://duch.mimuw.edu.pl/~tugboat/about-us/krzysztof-fleszar/">Krzysztof Fleszar</a></em></p>
<p></p>
<p style="text-align: justify;">-------------------------</p>
<p>Proof sketches for the interested reader of the lower and upper bounds on <em>r(n,k)</em>:</p>
<p>(*) <em>Œ©(k log n)</em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Cheng et al.</a>]: The interval <em>[k, k ‚àö{n}]</em> contains so many distinct sums of square roots (over square-free integers) that, by a pigeonhole argument, there are two sums with very small distance.</p>
<p>(**) <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Burnikel et al.</a>]: The difference is an algebraic integer and, consequently, the root of a polynomial with integer coefficients and degree at most <em>2<sup>2k</sup></em>. A simple inequality yields the bound.</p>
<p></p></div>







<p class="date">
by Renata Czarniecka <a href="http://corner.mimuw.edu.pl/?p=1076"><span class="datestr">at March 22, 2019 08:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15698">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/">The Shortest Path To The Abel Prize</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="G√∂del‚Äôs Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>While melding topology, geometry, and analysis</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg"><img width="150" alt="" src="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg?w=150&amp;h=180" class="alignright wp-image-15699" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">IAS <a href="https://www.ias.edu/scholars/karen-uhlenbeck">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Karen Uhlenbeck is a mathematician who has won a number of awards in the past and has just now been announced as winner of the 2019 Abel Prize. </p>
<p>
Today Ken and I want to explain a tiny bit about what Uhlenbeck did.</p>
<p>
The Abel Prize <a href="http://www.abelprize.no/c73996/seksjon/vis.html?tid=74013">citation</a> says that Uhlenbeck won for</p>
<blockquote><p><b> </b> <em> ‚Äúpioneering achievements in geometric partial differential equations, gauge theory, and integrable systems, and for the fundamental impact on analysis, geometry and mathematical physics.‚Äù </em>
</p></blockquote>
<p></p><p>
A <a href="https://www.quantamagazine.org/karen-uhlenbeck-uniter-of-geometry-and-analysis-wins-abel-prize-20190319/">story</a> in <em>Quanta</em> and <a href="https://www.scientificamerican.com/article/soap-bubble-pioneer-is-first-woman-to-win-prestigious-math-prize/">another</a> in <em>Scientific American</em> are among those with readable summaries of the general nature of this work. The latter describes Uhlenbeck‚Äôs discovery with the mathematician Jonathan Sacks of a phenomenon called <em>bubbling</em> as follows: </p>
<blockquote><p><b> </b> <em> Sacks and Uhlenbeck were studying ‚Äòminimal surfaces,‚Äô the mathematical theory of how soap films arrange themselves into shapes that minimize their energy. But the theory had been marred by the appearance of points at which energy appeared to become infinitely concentrated. Uhlenbeck‚Äôs insight was to ‚Äúzoom in‚Äù on those points to that this were caused by a new bubble splitting off the surface. </em>
</p></blockquote>
<p></p><p>
Some of the coolest comments are by Uhlenbeck‚Äôs doctoral graduate Mark Haskins in the <a href="https://www.nature.com/articles/d41586-019-00932-1">story</a> in the current issue of <em>Nature</em>. </p>
<blockquote><p><b> </b> <em> Haskins says Uhlenbeck is one of those mathematicians who have ‚Äòan innate sense of what should be true,‚Äô even if they cannot always explain why. </em>
</p></blockquote>
<p></p><p>
The story recounts his often being baffled by answers to his questions, thinking Uhlenbeck had misheard them. But</p>
<blockquote><p><b> </b> <em> ‚Äúmaybe weeks later, you would realize that you had not asked the correct question.‚Äù </em>
</p></blockquote>
<p>
</p><p></p><h2> Calculus Of Variations </h2><p></p>
<p></p><p>
Simon Donaldson wrote a <a href="https://www.ams.org/journals/notices/201903/rnoti-p303.pdf">piece</a> in the current issue of <i>AMS Notices</i> that explains Uhlenbeck‚Äôs research in the Calculus of Variations. The article starts with 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28u%29+%3D+%5Cint+%5CPhi%28u%2Cu%27%29+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(u) = \int \Phi(u,u') dx. " class="latex" title="\displaystyle  F(u) = \int \Phi(u,u') dx. " /></p>
<p>You can think of <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u)}" class="latex" title="{F(u)}" /> as assigning a cost to a function <img src="https://s0.wp.com/latex.php?latex=%7Bu%3Du%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u=u(x)}" class="latex" title="{u=u(x)}" />. The goal of the calculus of variations is to find the best <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> that minimizes <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u)}" class="latex" title="{F(u)}" /> subject to some conditions on <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" />. This is a huge generalization of simple minimization problems that arise in basic calculus. He then goes on to explain that in order to study the minimum solutions of such a function one quickly needs to examine partial differential equations. The math gets complex and beautiful very quickly. </p>
<p>
As computer scientists who like discrete structures this is not our sweet spot. We rarely use partial derivatives in our work. Well not very often. See <a href="https://rjlipton.wordpress.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">these</a> two <a href="https://rjlipton.wordpress.com/2010/08/19/projections-can-be-tricky/">posts</a> for an example. </p>
<p>
To get a taste of this area, we will consider a classic variation problem coming out of these helpful online <a href="http://farside.ph.utexas.edu/teaching/336k/Newtonhtml/node86.html">notes</a>. It leads to integrals such as 	 </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cint_%7B0%7D%5E%7Ba%7D+%281%2Bu%27%28x%29%5E%7B2%7D%29%5E%7B1%2F2%7D+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. " class="latex" title="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. " /></p>
<p>Well, we take to integrals even less than partial derivatives. </p>
<p>
</p><p></p><h2> Straight-line Shortest Path </h2><p></p>
<p></p><p>
We will change things up by starting with a discrete approach‚Äîas is our wont. Our given task is to prove in general that a straight line is the shortest path from the origin to a given point <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = (a,b)}" class="latex" title="{p = (a,b)}" />. We first consider polygonal paths with <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> line segments. </p>
<p>
First, if <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 1}" class="latex" title="{n = 1}" /> then the only option allowed is to go from <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,0)}" class="latex" title="{(0,0)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> in one line segment. Thus the conclusion holds trivially: the Euclidean distance <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" /> is the minimum length of a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />-segment path.</p>
<p>
Now let <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \geq 2}" class="latex" title="{n \geq 2}" />. Let </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3D+%280%2C0%29+%5Crightarrow+x_1+%5Crightarrow+x_2+%5Crightarrow+%5Ccdots+%5Crightarrow+x_n+%3D+%28a%2Cb%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) " class="latex" title="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) " /></p>
<p>be a series of line segments that form the shortest path from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. Now by induction, the minimum length of a path of up to <img src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n-1}" class="latex" title="{n-1}" /> segments from <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> is <img src="https://s0.wp.com/latex.php?latex=%7Bd%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(x_1,p)}" class="latex" title="{d(x_1,p)}" /> via a straight line from <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. And the length of the segment from the origin <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> of course is <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,x_1)}" class="latex" title="{d(0,x_1)}" />. Now the Euclidean triangle inequality says that the length <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29+%2B+d%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,x_1) + d(x_1,p)}" class="latex" title="{d(0,x_1) + d(x_1,p)}" /> which bounds the length of this path from below is not less than <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" />. Thus we have proved it for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and the induction goes through.</p>
<p>
What we really want to do, however, is prove that <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" /> is the shortest length for any path, period. The path need not have any straight segments. It may go in circular arcs, continually changing direction. The arcs need not be circular per-se; they could be anything.</p>
<p>
The idea that occurs to us computer scientists is to let <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> go to infinity. That is, we want to consider any path as being a limit of polygonal paths. But is this really legitimate? We can certainly approximate any path by paths of segments. But real analysis is littered with examples of complicated curves‚Äîthemselves defined by limits‚Äîthat defeat many intuitive expectations about continuity and limits. So how can we make such an infinitistic proof go through rigorously? This is where the calculus of variations takes over.</p>
<p>
</p><p></p><h2> Minimizers of Functionals </h2><p></p>
<p></p><p>
To set up the problem for fully general paths, we could represent them as functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%28t%29+%3D+%28x%28t%29%2Cy%28t%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(t) = (x(t),y(t))}" class="latex" title="{f(t) = (x(t),y(t))}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(0) = 0}" class="latex" title="{f(0) = 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf%281%29+%3D+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(1) = p}" class="latex" title="{f(1) = p}" />. The length of the path is then obtained by integrating all the horizontal and vertical displacements: <a name="length1"></a></p><a name="length1">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29%280%2Cp%29+%3D+%5Cint_%7Bt%3D0%7D%5E%7Bt%3D1%7D+%5Csqrt%7B%5Cleft%28%5Cfrac%7Bdx%28t%29%7D%7Bdt%7D%5Cright%29%5E2+%2B+%5Cleft%28%5Cfrac%7Bdy%28t%29%7D%7Bdt%7D%5Cright%29%5E2%7D+dt.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)" class="latex" title="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)" /></p>
</a><p><a name="length1"></a> Wrangling this integral seems daunting enough, but the real action involving <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> only begins after doing so. Both the length <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> and the body of the integral are <em>functionals</em>‚Äîthat is, functions of a function. We need to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> over all functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />. This is a higher-order task than minimizing a function at a point. </p>
<p>
Our source simplifies the problem by assuming without loss of generality that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> increases from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" />, giving the function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> as <img src="https://s0.wp.com/latex.php?latex=%7By%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y(x)}" class="latex" title="{y(x)}" /> instead. Then the problem becomes to minimize <a name="length21"></a></p><a name="length21">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29+%3D+%5Cint_%7Bx%3D0%7D%5E%7Bx%3Da%7D+%5Csqrt%7B1+%2B+%5Cleft%28%5Cfrac%7Bdy%28x%29%7D%7Bdx%7D%5Cright%29%5E2%7D+dx.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)" class="latex" title="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)" /></p>
</a><p><a name="length21"></a> The body can be abstracted as a functional <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%2Cu%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u,u')}" class="latex" title="{F(u,u')}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> and its derivative <img src="https://s0.wp.com/latex.php?latex=%7Bu%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u'}" class="latex" title="{u'}" /> are functions of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. Here we have <img src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u = y(x)}" class="latex" title="{u = y(x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u' = \frac{dy}{dx}}" class="latex" title="{u' = \frac{dy}{dx}}" />. The condition for <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D+%3D+%5Cint_x+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F} = \int_x F}" class="latex" title="{\mathcal{F} = \int_x F}" /> was derived by Leonhard Euler and Joseph Lagrange: <a name="EL"></a></p><a name="EL">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bd%7D%7Bdx%7D%5Cleft%28%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%27%7D%5Cright%29+%3D+%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%7D%5C%3B.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)" class="latex" title="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)" /></p>
</a><p><a name="EL"></a> We won‚Äôt reproduce here how our source derives this but give some interpretation. This is a kind of regularity property that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> must obey in order to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}}" class="latex" title="{\mathcal{F}}" />. To quote Donaldson‚Äôs survey:</p>
<blockquote><p><b> </b> <em> Then the condition that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is stationary with respect to compactly supported variations of <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> is a second order differential equation‚Äîthe Euler-Lagrange equation associated to the functional. </em>
</p></blockquote>
<p></p><p>
However you slice it, the point is that the equation (<a href="https://rjlipton.wordpress.com/feed/#EL">3</a>), when applied to cases like the above, is attackable. In the minimum-length path example, our source‚Äîafter doing eight more equation lines of work‚Äîdeduces that <img src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u' = \frac{dy}{dx}}" class="latex" title="{u' = \frac{dy}{dx}}" /> must be constant. Any function argument <img src="https://s0.wp.com/latex.php?latex=%7BF+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F = y(x)}" class="latex" title="{F = y(x)}" /> that yields this must be a straight line. The initial conditions force this to be the straight line from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />.</p>
<p>
</p><p></p><h2> Some of Uhlenbeck‚Äôs Work </h2><p></p>
<p></p><p>
The point we are emphasizing is that this simple case of paths in the plane‚Äîand its abstraction via functionals <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}}" class="latex" title="{\mathcal{F}}" /> that are ultimately founded on one variable <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />‚Äîhave a ready-made minimization scheme, thanks to Euler and Lagrange. The scheme is fully general‚Äînot subject to the caveats about our simple approximation by line segments.</p>
<p>
What happens in higher-dimensional cases? We can quote from the wonderful two-page <a href="http://www.abelprize.no/c73996/binfil/download.php?tid=74177">essay</a> accompanying the Abel Prize citation. It first notes the importance of a <a href="https://en.wikipedia.org/wiki/Palais-Smale_compactness_condition">condition</a> on functionals and their ambient spaces named for Richard Palais and Stephen Smale, which however fails for many cases of interest including harmonic maps.</p>
<blockquote><p><b> </b> <em> [T]he Palais-Smale compactness condition ‚Ä¶ guarantees existence of minimizers of geometric functionals and is successful in the case of 1-dimensional domains, such as closed geodesics. Uhlenbeck realized that the condition of Palais-Smale fails in the case of surfaces due to topological reasons. </em>
</p></blockquote>
<p></p><p>
The papers with Sacks explored the roots of these breakdowns and found a way to patch them. The violation of the Palais-Smale condition allows minimizing sequences of functionals to converge with dependence on points outside the space being analyzed. But those loci are governed by a finite set of singular points within the space. This enables the calculus outside the space to be treated as a re-scaling of what goes on inside the space. </p>
<p>
In general cases the view of the process from inside to outside can be described and analyzed as bubbles emerging from the singular locations. More than this picture and interpretation, the Sacks-Uhlenbeck papers produced a now-standard tool-set for higher-dimensional minimization of functionals. It is also another successful marriage of topology‚Äîdetermining the singularities‚Äîand analysis.</p>
<p>
This work was extensible to more-general kinds of functionals such as a central one of Yang-Mills theory in physics. Geometric properties of a Riemannian manifold <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> are expressed via the concept of a <a href="https://en.wikipedia.org/wiki/Connection_(mathematics)">connection</a> <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and the functional associates to <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> its <em>curvature</em> <img src="https://s0.wp.com/latex.php?latex=%7BF%28A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(A)}" class="latex" title="{F(A)}" />. This is the body for the Yang-Mills functional </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathcal%7BF%7D+%3D+%5Cint_M+%7CF%28A%29%7C%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. " class="latex" title="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. " /></p>
<p>There is a corresponding lifting of the Euler-Lagrange equation. This led to developments very much along lines of the previous work with Sacks and more besides. There was particular success analyzing cases where <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> has dimension 4 that were soon relevant to Donaldson‚Äôs own Fields Medal-winning research on these spaces. Most in particular, Uhlenbeck working solo proved that these cases were immune to the ‚Äúbubbling‚Äù issue‚Äîwith the consequence as related in <em>Quanta</em> that</p>
<blockquote><p><b> </b> <em> any finite-energy solution to the Yang-Mills equations that is well-defined in the neighborhood of a point will also extend smoothly to the point itself. </em>
</p></blockquote>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We‚Äôve been happy to report that Uhlenbeck has won the prestigious Abel Prize. We have avoided referencing one aspect‚Äîdespite giving numerous quotes verbatim‚Äîthat can be appreciated in subsequent fullness <a href="https://www.ias.edu/news/2018/women-and-mathematics-twenty-five-years">here</a> and <a href="https://www.ias.edu/pcmi">here</a> and in <a href="https://impa.br/en_US/page-noticias/karen-uhlenbeck-the-struggle-for-a-place-in-the-sun/">this</a>. By so doing we‚Äôve abided the desire stated in the twelfth paragraph of this <a href="https://web.ma.utexas.edu/users/uhlen/vita/pers.html">essay</a>. We wonder if this is the right way to do things. What do you think?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/"><span class="datestr">at March 22, 2019 02:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2570215373323645628">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html">Back at Dagstuhl</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="clear: both; text-align: center;" class="separator">
<a href="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg"><img width="320" src="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg" border="0" height="212" /></a></div>
<table cellpadding="0" align="center" style="margin-left: auto; margin-right: auto; text-align: center;" cellspacing="0" class="tr-caption-container"><tbody>
<tr><td style="text-align: center;"><a style="margin-left: auto; margin-right: auto;" href="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s1600/IMG_20190320_090009.jpg"><img width="320" src="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s320/IMG_20190320_090009.jpg" border="0" height="240" /></a></td></tr>
<tr><td style="text-align: center;" class="tr-caption">Participants and Their Research Interests</td></tr>
</tbody></table>
<br />
This week I'm in Germany for the Dagstuhl workshop on¬†<a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19121">Computational Complexity of Discrete Problems</a>¬†well timed for Georgia Tech spring break. No Bill, so no <a href="https://blog.computationalcomplexity.org/2018/09/still-typecasting-from-dagstuhl.html">typecast</a>, no <a href="https://blog.computationalcomplexity.org/2017/03/the-dagstuhl-family.html">family</a>, just a bunch of fellow theorists. New this year, beer.<br />
<br />
Dagstuhl always had bottled beer (and wine), after all this is Germany. However, Ronen Shaltiel is living his lifelong dream of bringing a keg to Dagstuhl. Turns out Dagstuhl had a refrigerator/tap for a beer keg, one only needs to order and pay for the beer. Ronen's daughter designed a special logo, though the keg contains Bitburger, a fine German pilsner. Prost to Ronen and thanks for the beer.<br />
<br />
<div style="clear: both; text-align: center;" class="separator">
<a style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;" href="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s1600/MVIMG_20190318_181047.jpg"><img width="150" src="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s200/MVIMG_20190318_181047.jpg" border="0" height="200" /></a><a style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s1600/IMG_20190318_193159.jpg"><img width="150" src="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s200/IMG_20190318_193159.jpg" border="0" height="200" /></a><a style="margin-left: 1em; margin-right: 1em;" href="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s1600/shaltieliner.jpg"><img width="200" src="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s200/shaltieliner.jpg" border="0" height="200" /></a></div>
<br />
Of course the fun is hanging with colleagues old and new. Talking about open problems old and new. Used to solve more of them back in the day, now it seems harder.<br />
<br />
I did learn a new old theorem, planarity testing, whether you can embed a given graph in the plane so no two edges cross, is computable in log space. In 2000 Eric Allender and Meena Mahajan <a href="https://doi.org/10.1016/j.ic.2003.09.002">showed</a> that you can test for planarity in symmetric log space, basically the complexity class whose complete problem is undirected connectivity. In 2005, Omer Reingold <a href="https://doi.org/10.1145/1391289.1391291">famously showed</a> that undirected connectivity is computable in log-space. Thus planarity testing is in log-space, a result you might have missed if you didn't know both papers.<br />
<br />
This came out in Eric's talk on his work with¬†Archit Chauhan, Samir Datta and Anish Mukherjee¬†<a href="https://eccc.weizmann.ac.il/report/2019/039/">showing</a> that checked whether there is a directed path from a given node s to a given node t in planar graphs can be computed by concurrent-read exclusive-write on parallel random-access machines in logarithmic time, and thus likely weaker than directed s-t paths on general graphs.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html"><span class="datestr">at March 21, 2019 10:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2019/03/19/CURL/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2019/03/19/CURL/">Contrastive Unsupervised Learning of Semantic Representations&amp;#58; A Theoretical Framework</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><em>Semantic representations</em> (aka  <em>semantic embeddings</em>) of complicated data types (e.g. images, text, video) have become central in machine learning, and also crop up in machine translation, language models, GANs, domain transfer, etc. 
These involve learning a <em>representation function</em> $f$ such that for any data point $x$ its representation $f(x)$ is ‚Äúhigh level‚Äù (retains semantic information while discarding low level details, such as color of individual pixels in an image) and ‚Äúcompact‚Äù (low dimensional). 
The test of a good representation is that it should greatly simplify solving <em>new</em> classification tasks, by allowing them to be solved via linear classifiers (or other low-complexity classifiers) using small amounts of labeled data.</p>

<p>Researchers are most interested in <em>unsupervised</em> representation learning using unlabeled data. A popular approach is to use objectives similar to the <strong>word2vec</strong> algorithm for word embeddings, which work well for diverse data types such as molecules, social networks, images, text etc. 
See the <a href="https://en.wikipedia.org/wiki/Word2vec">wikipage of word2vec</a> for references. 
Why do such objectives succeed in such diverse settings? 
This post is about an explanation for these methods by using our <a href="https://arxiv.org/abs/1902.09229">new theoretical framework</a> with coauthor Misha Khodak. 
The framework makes minimalistic assumptions, which is a good thing, since word2vec-like algorithms apply to vastly different data types and it is unlikely that they can share a common Bayesian generative model for the data. 
(An example of generative models in this space is described in an earlier <a href="http://www.offconvex.org/2016/02/14/word-embeddings-2/">blog post on the RAND-WALK model</a>.)
As a bonus this framework also yields principled ways to design new variants of the training objectives.</p>

<h2 id="semantic-representations-learning">Semantic representations learning</h2>
<p>Do good, broadly useful representations even <em>exist</em> in the first place? 
In domains such as computer vision, we know the answer is ‚Äúyes‚Äù because deep convolutional neural networks (CNNs), when  trained to high accuracy on large multiclass labeled datasets such as <a href="http://www.image-net.org/">ImageNet</a>, end up learning very powerful and succinct representations along the way. The penultimate layer of the net ‚Äî the input into the final <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax layer</a> ‚Äî serves as a good semantic embedding of the image in new unrelated visual tasks. 
(Other layers from the trained net can also serve as good embeddings.) 
In fact the availability of such embeddings from pre-trained (on large multiclass datasets) nets has led to a revolution in computer vision, allowing a host of new classification tasks to be solved with low-complexity classifiers (e.g. linear classifiers) using very little labeled data. 
Thus they are the gold standard to compare to if we try to learn embeddings via unlabeled data.</p>

<p style="text-align: center;">
<img width="50%" src="http://www.offconvex.org/assets/CURLheadless1.svg" />
</p>

<h3 id="word2vec-like-methods-curl">word2vec-like methods: CURL</h3>

<p>Since the success of <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word2vec</a>, similar approaches were used to learn embeddings for <a href="https://arxiv.org/pdf/1803.02893.pdf">sentences and paragraphs</a>, <a href="https://arxiv.org/abs/1505.00687">images</a> and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640716/">biological sequences</a>.
All of these methods share a key idea: they leverage access to pairs of similar data points $x, x^+$, and learn an embedding function $f$ such that the inner product of $f(x)$ and $f(x^+)$ is on average higher than the inner product of $f(x)$ and $f(x^-)$, where $x^{-}$ is a random data point (and thus presumably dissimilar to $x$). 
In practice similar data points are usually found heuristically, often using co-occurrences, e.g. consecutive sentences in a large text corpus, nearby frames in a video clip, different patches in the same image, etc.</p>

<p>A good example of such methods is <strong>Quick Thoughts</strong> (QT) from <a href="https://arxiv.org/pdf/1803.02893.pdf">Logeswaran and Lee</a>, which is the state-of-the-art unsupervised text embedding on many tasks. To learn a representation function $f$, QT minimizes the following loss function on a large text corpus</p>



<p>where $(x, x^+)$ are consecutive sentences and presumably ‚Äúsemantically similar‚Äù and $x^-$ is a random negative sample.
For images $x$ and $x^+$ could be <a href="https://arxiv.org/abs/1505.00687">nearby frames</a> from a video.
For text, two successive sentences serve as good candidates for a similar pair: for example, the following are two successive sentences in the Wikipedia page on word2vec: <em>‚ÄúHigh frequency words often provide little information.‚Äù</em> and <em>‚ÄúWords with frequency above a certain threshold may be subsampled to increase training speed.‚Äù</em>
Clearly they are much more similar than a random pair of sentences, and the learner exploits this. 
From now on we use <em>Contrastive Unsupervised Representation Learning (CURL)</em> to refer to  methods that leverage similar pairs of data points and our goal is to analyze these methods.</p>

<h3 id="need-for-a-new-framework">Need for a new framework</h3>

<p>The standard framework for machine learning involves minimizing some loss function, and learning is said to succeed (or <em>generalize</em>) if the loss is roughly the same on the average training data point and the average test data point.
In contrastive learning, however, the objective used at test time is very different from the training objective: generalization error is not the right way to think about this.</p>

<blockquote>
  <p><strong>Main Hurdle for Theory:</strong> We have to show that doing well on task A (minimizing the word2vec-like objective) allows the representation to do well on task B (i.e., classification tasks revealed later).</p>
</blockquote>

<p>Earlier methods along such lines include <em>kernel learning</em> and <em>semi-supervised learning</em>, but there training typically requires at least a few labeled examples from the classification tasks of future interest. Bayesian approaches using generative models are also well-established in simpler settings, but have proved difficult for complicated data such as images and text. 
Furthermore, the simple word2vec-like learners described above do not appear to operate like Bayesian optimizers in any obvious way, and also work for very different data types.</p>

<p>We tackle this problem by proposing a framework that formalizes the notion of semantic similarity that is implicitly used by these algorithms and use the framework to show why contrastive learning gives good representations, while defining what <em>good representations</em> mean in this context.</p>

<h2 id="our-framework">Our framework</h2>

<p>Clearly, the implicit/heuristic notion of similarity used in contrastive learning is connected to the downstream tasks in some way ‚Äî e.g., similarity carries a strong <em>hint</em> that on average the ‚Äúsimilar pairs‚Äù tend to be assigned the same labels in many downstream tasks (though there is no hard guarantee per se). We present a simple and minimalistic framework to formalize such a notion of similarity. 
For purposes of exposition we‚Äôll refer to data points as ‚Äúimages‚Äù.</p>

<h3 id="semantic-similarity">Semantic similarity</h3>

<p>We assume nature has many <em>classes</em> of images, and has a measure $\rho$ on a set of classes $\mathcal{C}$, so that if asked to pick a class it selects $c$  with probability $\rho(c)$. 
Each class $c$ also has an associated distribution $D_c$ on images i.e. if nature is asked to furnish examples of class $c$ (e.g., the class ‚Äúdogs‚Äù) then it picks image $x$ with probability $D_c(x)$. 
Note that classes can have arbitrary overlap, including no overlap. 
To formalize a notion of <em>semantic similarity</em> we assume that when asked to provide ‚Äúsimilar‚Äù images, nature picks a class $c^+$ from $\mathcal{C}$ using measure $\rho$ and then picks two i.i.d. samples $x, x^{+}$ from the distribution $D_{c^+}$. 
The dissimilar example $x^{-}$ is picked by selecting another class $c^-$ from measure $\rho$ and picking a random sample $x^{-}$ from $D_{c^-}$.</p>

<p style="text-align: center;">
<img width="80%" src="http://www.offconvex.org/assets/CURLframework.svg" />
</p>

<p>The training objective for learning the representation is exactly the QT objective from earlier, but now inherits the following interpretation from the framework
</p>

<p>Note that the function class $\mathcal{F}$ is an arbitrary deep net architecture mapping images to embeddings (neural net sans the final layer), and one would learn $f$ via gradient descent/back-propagation as usual. 
Of course, no theory currently exists for explaining when optimization succeeds for complicated deep nets, so our framework will simply assume that gradient descent has already resulted in some representation $f$ that achieves low loss, and studies how well this does in downstream classification tasks.</p>

<h3 id="testing-representations">Testing representations</h3>

<p>What defines a good representation? 
We assume that the quality of the representation is tested by using it to solve a binary (i.e., two-way) classification task using a linear classifier. 
(The paper also studies extensions to $k$-way classification in the downstream task.) 
How is this binary classification task selected? 
Nature picks two classes $c_1, c_2$ randomly according to measure $\rho$ and picks data points for each class according to the associated probability distributions $D_{c_1}$ and $D_{c_2}$. 
The representation is then used to solve this binary task via logistic regression: namely, find two vectors $w_1, w_2$ so as to minimize the following loss
</p>

<p>The quality of the representation is estimated as the <em>average</em> loss over nature‚Äôs choices of binary classification tasks.
</p>

<p>It is important to note that the latent classes present in the unlabeled data are the <em>same</em> classes present in the classification tasks. 
This allows us to formalize a sense of ‚Äòsemantic similarity‚Äô as alluded to above: the classes from which data points appear together more frequently are the classes that make up <em>relevant</em> classification tasks. 
Note that if the number of classes is large, then typically the data used in unsupervised training may involve <em>no samples</em> from the classes used at test time. 
Indeed, we are hoping to show that the learned representations are useful for classification on potentially unseen classes.</p>

<h2 id="provable-guarantees-for-unsupervised-learning">Provable guarantees for unsupervised learning</h2>

<p>What would be a dream result for theory? Suppose we fix a class of representation functions ${\mathcal F}$, say those computable by a ResNet 50 architecture with some choices of layer sizes etc.</p>

<blockquote>
  <p><strong>Dream Theorem:</strong> Minimizing the unsupervised loss (using modest amount of unlabeled data) yields a representation function $f \in {\mathcal F}$ that is competitive with the <strong>best</strong> representation from ${\mathcal F}$ on downstream classification tasks, even with very few labeled examples per task.</p>
</blockquote>

<p>While the number of unlabeled data pairs needed to learn an approximate minimizer can be controlled using Rademacher complexity arguments (see paper), we show that the dream theorem is impossible as phrased: we can exhibit a simple class ${\mathcal F}$ where the contrastive objective does not yield representations even remotely competitive with the best in the class.
This should not be surprising and only suggests that further progress towards such a dream result would require making more assumptions than the above minimalistic ones.</p>

<p>Instead, our paper makes progress by showing that under the above framework, if the unsupervised loss happens to be small at the end of contrastive learning then the resulting representations perform well on downstream classification.</p>

<blockquote>
  <p><strong>Simple Lemma:</strong> The average classification loss on downstream binary tasks is upper bounded by the unsupervised loss.

where $\alpha$ depends on $\rho$. ($\alpha\rightarrow 1$ when $|\mathcal{C}|\rightarrow\infty$, for uniform $\rho$)</p>
</blockquote>

<p>This says that the unsupervised loss function can be treated as a <strong>surrogate</strong> for the performance on downstream supervised tasks solved using linear classification, so minimizing it makes sense.
Furthermore, just a few labeled examples are needed to learn the linear classifiers in future downstream tasks.
Thus our minimalistic framework lets us show guarantees for contrastive learning and also highlights the labeled sample complexity benefits provided by it. For details as well as more finegrained analysis see <a href="https://arxiv.org/abs/1902.09229">the paper</a>.</p>

<h2 id="extensions-of-the-theoretical-analysis">Extensions of the theoretical analysis</h2>

<p>This conceptual framework not only allows us to reason about empirically successful variants of (1), but also leads to the design of new, theoretically grounded unsupervised objective functions. 
Here we give a high level view; details are in  <a href="https://arxiv.org/abs/1902.09229">our paper</a>.</p>

<p><em>A priori,</em> one might imagine that the log and exponentials in (1) have some information-theoretic interpretation; here we relate the functional form to the fact that logistic regression is going to be used in the downstream classification tasks. 
Analogously, if the classification is done via hinge loss, then (2) is true for a different unsupervised loss that uses a hinge-like loss instead. 
This objective, for instance, was used to learn image representations from videos by <a href="https://arxiv.org/abs/1505.00687">Wang and Gupta</a>. 
Also, usually in practice $k&gt;1$ negative samples are contrasted with each positive sample $(x,x^+)$ and the unsupervised objective looks like the $k$-class cross-entropy loss. 
We prove a statement similar to (2) for this setting, where the supervised loss now is the average $(k+1)$-way classification loss.</p>

<p>Finally, the framework provides guidelines for designing new unsupervised objectives when <em>blocks</em> of similar data are available (e.g., sentences in a paragraph). 
Replacing $f(x^+)$ and $f(x^-)$ in (1) with the average of the representations from the positive and the negative block respectively, we get a new objective which comes with stronger guarantees and better performance in practice. 
We experimentally verify the effectiveness of this variant in our paper.</p>

<h2 id="experiments">Experiments</h2>

<p>We report some controlled experiments to verify the theory. Lacking a canonical multiclass problem for text, we constructed a new 3029-class labeled dataset where a class is one of 3029 articles from Wikipedia,  and datapoints are one of $200$ sentences in these articles. Representations will be tested on a random binary classification task that involves two articles, where the labels of the data point is which of the two articles it belongs to. (A 10-way classification task is similarly defined.)  Datapoints for the test tasks will be held out while training representations. The class of sentence representation ${\mathcal F}$ is a simple multilayer architecture one based on Gated Recurrent Unit (GRU).</p>

<p>The supervised method for learning representations trains a multiclass classifier on the 3029-way task and the representation is taken from the layer before the final softmax output. This was the gold standard in above discussions.</p>

<p>The unsupervised method is fed pairs of similar data points generated according to our theory: similar data points are just pairs of sentences sampled from the same article. Representations are learnt by minimizing the above unsupervised loss objectives.</p>

<p style="text-align: center;">
<img width="60%" src="http://www.offconvex.org/assets/CURLexperiment.svg" />
</p>
<p>The highlighted parts in the table show that the unsupervised representations compete well with the supervised representations on the average $k$-way classification task ($k=2, 10$).</p>

<p>Additionally, even though not covered by our theory, the representation also performs respectably on the full  multiclass problem.
We find some support for a suggestion of our theory that the mean (centroid) of the unsupervised representations in each class should be good classifiers for average $k$-way supervised tasks. We find this to be true for unsupervised representations, and surprisingly for supervised representations as well.</p>

<p>The paper also has other experiments studying the effect of number of negative samples and larger blocks of similar data points, including experiments on the CIFAR-100 image dataset.</p>

<h2 id="conclusions">Conclusions</h2>
<p>While contrastive learning is a well-known <em>intuitive</em> algorithm, its practical success has been a mystery for theory. 
Our conceptual framework lets us formally show guarantees for representations learnt using such algorithms. 
While shedding light on such algorithms, the framework also lets us come up with and analyze variants of it. 
It also provides insights into what guarantees are provable and shapes the search for new assumptions that would allow stronger guarantees. 
While this is a first cut, possible extensions include imposing a metric structure among the latent classes.
Connections to meta-learning and transfer learning may also arise.
We hope that this framework influences and guides practical implementations in the future.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2019/03/19/CURL/"><span class="datestr">at March 19, 2019 07:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/042">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/042">TR19-042 |  Determinant equivalence test over finite fields and over $\mathbf{Q}$ | 

	Ankit Garg, 

	Nikhil Gupta, 

	Neeraj Kayal, 

	Chandan Saha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The determinant polynomial $Det_n(\mathbf{x})$ of degree $n$ is the determinant of a $n \times n$ matrix of formal variables. A polynomial $f$ is equivalent to $Det_n$ over a field $\mathbf{F}$ if there exists a $A \in GL(n^2,\mathbf{F})$ such that $f = Det_n(A \cdot \mathbf{x})$. Determinant equivalence test over $\mathbf{F}$ is the following algorithmic task: Given black-box access to a $f \in \mathbf{F}[\mathbf{x}]$, check if $f$ is equivalent to $Det_n$ over $\mathbf{F}$, and if so then output a transformation matrix $A \in GL(n^2,\mathbf{F})$. In Kayal (2012), a randomized polynomial time determinant equivalence test was given over $\mathbf{C}$. But, to our knowledge, the complexity of the problem over finite fields and over rationals was not well understood. 

In this work, we give a randomized $poly(n,\log |\mathbf{F}|)$ time determinant equivalence test over finite fields $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$). Over rationals, we give an efficient randomized reduction from factoring square-free integers to determinant equivalence test for quadratic forms (i.e. the $n=2$ case), assuming GRH. This shows that designing a polynomial-time determinant equivalence test over rationals is a challenging task. Nevertheless, we show that determinant equivalence test over rationals is decidable: For bounded $n$, there is a randomized polynomial-time determinant equivalence test over rationals with access to an oracle for integer factoring. Moreover, for any $n$, there is a randomized polynomial-time algorithm that takes input black-box access to a rational polynomial $f$ and if $f$ is equivalent to $Det_n$ over rationals then it returns a $A \in GL(n^2,\mathbf{L})$ such that $f = Det_n(A \cdot \mathbf{x})$, where $\mathbf{L}$ is an extension field of $\mathbf{Q}$ of degree at most $n$. 

The above algorithms over finite fields and over rationals are obtained by giving a polynomial-time randomized reduction from determinant equivalence test to another problem, namely the full matrix algebra isomorphism problem. We also show a reduction in the converse direction which is efficient if $n$ is bounded. These reductions, which hold over any $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$), establish a close connection between the complexity of the two problems. This then lead to our results via applications of known results on the full algebra isomorphism problem over finite fields and over $\mathbf{Q}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/042"><span class="datestr">at March 18, 2019 12:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4318994903152354716">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html">Third Poll on P vs NP and related Questions is out now! And the winner is Harambe!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
I took a poll of the theory community (and others) about P vs NP and related issues in 2002, 2012, and 2019 (sorry its not an arithmetic¬† sequence --- read the third poll article to see why).  The 2002 and 2012 polls are on the web (see¬†<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf">here</a>¬†and¬†<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper2.pdf">here</a>¬†), and now the third poll is out and its¬†<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper3.pdf">here</a>¬†or <a href="https://dl.acm.org/citation.cfm?doid=3319627.3319636">here</a>¬†. All three appear in Lane's Complexity Column in SIGACT News.<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf"></a><br />
<br />
I'll give some highlights and thought about the third poll, but for more read the article. Or read all three and see how opinions have changed over time.<br />
<br />
0) How many respondents: 100 the first time, and 152 the second time, 124 the third time.<br />
<br />
1) P‚â†NP is at about 80%. When restricted to people who have thought about the problem a lot (my judgement) then it goes to 99%. The strongest P‚â†NP is by Lance who says<br />
<br />
¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† People who think P=NP are like people who believe Elvis is alive.<br />
<br />
I disagree. I think Elvis is alive and is trying to prove P=NP.<br />
<br />
2) When will it be solved? 66% thought it would be solved before 2100, a bit more than in prior years. But also more thought it would never be solved. Some commented that a computer might solve it.¬† I doubt that, but I do think this poll will be done by a computer in 10 years.<br />
<br />
3) Because I used Survey monkey (1) each question got more answers, and (2) most¬† questions got a forced YES or NO¬† so less funny comments or room for creative answers. People could still leave comments, and some did.<br />
<br />
4) Related to point (3): The last time I did the poll P=BPP was thought by everyone <i>who answered</i> <i>the question</i>. This year far more people answered it and quite a few thought P‚â†BPP. This may be because Survey monkey had a psychological affect of making people vote even if they didn't really know (people who have thought a lot about P vs NP¬† all thought P=BPP). Has¬† there been evidence that P‚â†BPP that I am unaware of? Or since there has not been that much progress on it maybe they are unequal.  10  years ago I would have thought we would have L=RL by now.<br />
<br />
5) The last time I did the poll 10 people thought factoring IS in P and the NSA or the KGB knows that. This time around nobody thought that. Why? Those 10 people have vanished mysteriously.<br />
<br />
6) Five people thought P vs NP will be resolved by Harambe. That is more than any person got.<br />
<br />
7)¬† Is this poll worth doing? I would say yes (gee, I have to having done his poll three times) because it is good to have an objective record of subjective opinion. <br />
<br />
8) I'll give some of my answers: P‚â†NP, Elvis is dead, and both will be proven in the year 2525. For more about the future see <a href="https://www.youtube.com/watch?v=yesyhQkYrQM">this</a>.<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html"><span class="datestr">at March 17, 2019 10:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/041">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/041">TR19-041 |  Quantum hardness of learning shallow classical circuits | 

	Srinivasan Arunachalam, 

	Alex Bredariol Grilo, 

	Aarthi Sundaram</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we study the quantum learnability of constant-depth classical circuits under the uniform distribution and in the distribution-independent framework of PAC learning.  In order to attain our results, we  establish connections between quantum learning and quantum-secure  cryptosystems. We then achieve the following results. 

1) Hardness of learning $AC^0$ and $TC^0$ under the uniform distribution. Our first result concerns the concept class $TC^0$ (resp. $AC^0$), the class of constant depth and polynomial-sized circuits with unbounded fan-in majority gates (resp. AND, OR, NOT gates). We show that if there exists no quantum polynomial time (resp. sub-exponential time) algorithm to solve the Learning with Errors (LWE) problem, then there exists no polynomial time quantum learning algorithm for $TC^0$ (resp. $AC^0$) under the uniform distribution (even with access to quantum membership queries). The main technique in this result uses explicit pseudo-random generators that are believed to be quantum-secure to construct concept classes that are hard to learn quantumly under the uniform distribution. 


2) Hardness of learning $TC^0_2$ in the PAC setting. Our second result shows that if there exists no quantum polynomial time algorithm for the LWE problem, then there exists no polynomial time quantum PAC learning algorithm for the class $TC^0_2$, i.e., depth-$2$ $TC^0$ circuits. The main technique in this result is to establish a connection between the quantum security of public-key cryptosystems and the learnability of a concept class that consists of decryption functions of the cryptosystem. 


This gives a strong conditional negative answer to one of the "Ten Semi-Grand Challenges for Quantum Computing Theory" raised by Aaronson, who asked if $AC^0$ and $TC^0$ can be PAC-learned in quantum polynomial time.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/041"><span class="datestr">at March 17, 2019 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15684">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/03/16/leprechauns-go-universal/">Leprechauns Go Universal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="G√∂del‚Äôs Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Facing nonexistential realities</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/03/neillcounterfactual.png"><img width="143" alt="" src="https://rjlipton.files.wordpress.com/2019/03/neillcounterfactual.png?w=143&amp;h=150" class="alignright size-thumbnail wp-image-15685" height="150" /></a></p>
<p><font color="green"></font></p><font color="green">
<p>
Neil L. is a Leprechaun. He has <a href="https://rjlipton.wordpress.com/2009/03/16/happy-st-patricks-day-and-sum-of-squares/">graced</a> <a href="https://rjlipton.wordpress.com/2010/03/17/happy-st-patrick-day-again/">these</a> <a href="https://rjlipton.wordpress.com/2011/03/17/happy-st-patricks-day-again-again/">pages</a> <a href="https://rjlipton.wordpress.com/2013/03/17/happy-st-patricks-day-again-and-again-and-again-and-again/">before</a>.</p>
<p>
Today, the day before St. Patrick‚Äôs Day, we ponder universal riddles of existence. Ken, who will visit me this coming week, insisted on reporting what happened this morning.<br />
<span id="more-15684"></span></p>
<p>
I woke up early, walked alone into our living room, and was amazed to see Neil already here. He was looking out the window at dawn sunlight flooding over St. Patrick‚Äôs Cathedral and the many other landmarks we can see from our apartment in midtown Manhattan. </p>
<p>
Spring has at last given an earnest of coming. The scene was transfixing, exhilirating, all the glory of nature except for the green-clad little man puffing his pipe with his back to me.</p>
<p>
‚ÄúNeil‚Äî?‚Äù</p>
<p>
He turned and tipped his hat to me but then turned back to the window. I wondered if I had caught him in meditation. I stood back until he turned a second time. He had always visited me late on the evening before St. Patrick‚Äôs Day, or the morning of it.</p>
<p>
‚ÄúYou‚Äôre here early.‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúAye. Top o‚Äô the morning to ye.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúWhy?‚Äù</p>
<p>
He gave me a long stare but warmly, not hostile. </p>
<blockquote><p>
<font color="green"><br />
‚ÄúBy the living daylights in ye‚Ä¶‚Äù<br />
</font>
</p></blockquote>
<p>
Then I understood. The Romans have their Ides, the Irish have the 17th, but I got the day in between‚Äîwhen last year I was not here but in an operating room for long hours.</p>
<p>
‚ÄúThanks‚Äù was all I could say. I had actually come out to look up a mathematical idea for a ‚Äúpart 2‚Äù post I‚Äôve been struggling with ever since posting the ‚Äúpart 1‚Äù years ago. This pulled me back to math, then to how Neil has always tricked me and I‚Äôve never been able to pin him down. I realized this might be my best opportunity.</p>
<p>
‚ÄúNeil, may I ask you a Big Question? Not directly personal.‚Äù</p>
<p>
He simply said, ‚ÄúAye.‚Äù No tricks yet.</p>
<p>
</p><p></p><h2> The Question </h2><p></p>
<p></p><p>
I had my chance‚Äîsomething I‚Äôve wanted to ask him for years but not had an opening for.</p>
<p>
‚ÄúNeil, what can you tell me about <em>female</em> Leprechauns?‚Äù </p>
<p>
Neil had mentioned family, cousins, even siblings‚ÄîI figured they had to come from somewhere. But nothing I‚Äôd read mentioned female leprechauns. I braced for silence again, but Neil‚Äôs reply was immediate and forthright:</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThey comprise the most heralded subset of our people. They are included in everything we do.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúHow so?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúOur society agreed early on that every female leprechaun should have the highest station. All female leprechauns are sent to the best schools, with personal tutoring reserved in advanced subjects. They are our superpartners in every way.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúHow do you treat them?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúIf a lady leprechaun applies for a position, she is given full consideration. Whenever a lady leprechaun gives advice, it is harkened to. None of us has ever ‚Äòmalesplained‚Äô or demeaned a lady leprechaun in any way.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúAre they as short‚Äîuh, tall‚Äîas you?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúEvery adult female leprechaun is between one cubit and one-and-a-half in stature, like us menfolk. We don‚Äôt have quite the variation of your human species.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúI would surely like to meet one.‚Äù</p>
<p>
Neil heaved a sigh. </p>
<blockquote><p>
<font color="green"><br />
‚ÄúYe know the trepidation with us and your womenfolk.‚Äù Indeed, I recalled Neil‚Äôs <a href="https://rjlipton.wordpress.com/2015/03/17/leprechauns-will-find-you/">story</a> of what was evidently his own harrowing encounter with the wife of William Hamilton. ‚ÄúIt is symmetrical, I‚Äôm afraid. No female leprechaun has ventured into your world.‚Äù<br />
</font>
</p></blockquote>
<p>
I had figured that. </p>
<p>
‚ÄúBut can you give me an <em>example</em> of a female leprechaun? Someone who has done something notable.‚Äù</p>
<p>
</p><p></p><h2> The Reality </h2><p></p>
<p></p><p>
Neil puffed on his pipe. I knew I had him cornered and moved in.</p>
<p>
‚ÄúNeil, is everything you just said about female leprechauns <em>true</em>?‚Äù</p>
<p>
To my surprise, he answered quickly.</p>
<blockquote><p>
<font color="green"><br />
‚Äú<em>Aye.</em> As in mathematics, each of my statements was perfectly true.‚Äù<br />
</font>
</p></blockquote>
<p>
Oh. Then I realized how empty domains are treated in mathematical logic. I looked at him sharply. </p>
<p>
‚ÄúNeil, there <a href="https://thefw.com/things-you-didnt-know-about-leprechauns/">are</a> <a href="https://www.circa.com/story/2019/03/15/art-culture/where-are-all-the-female-leprechauns-we-asked-an-expert">no</a> female leprechauns. All of your statements have been vacuous, bull-.‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThat‚Äôs not right or fair. That which I told ye have been important values of our society from the beginning. Many studies of female leprechauns have established their natures precisely. We have devoted vast resources to the quest for female leprechauns. Readiness‚Äîhow we would integrate them‚Äîthis is enshrined in all of our laws. Even your late Senator, <a>Birch</a> <a href="https://books.google.com/books?id=O-sOBAAAQBAJ&amp;pg=PT275&amp;lpg=PT275&amp;dq=Bayh+Irish+name&amp;source=bl&amp;ots=bECfTQqWkJ&amp;sig=ACfU3U2yp53w6HQk_aXp2uT6okbmEG7Y3w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjtzKG6iIfhAhVuQt8KHdB5DmgQ6AEwDnoECAAQAQ#v=onepage&amp;q=Bayh Irish name&amp;f=false">Bayh</a>, was <a href="https://scholarship.law.nd.edu/ndlr/vol48/iss1/4/">informed</a> by us at Notre Dame.‚Äù<br />
</font>
</p></blockquote>
<p>
Neil‚Äôs sincerity was evident. I still felt bamboozled. He carried on.</p>
<blockquote><p>
<font color="green"><br />
‚ÄúYe have whole brilliant careers studying physical objects that may not exist. The analysis of them is still important in mathematics and other scientific applications. And in mathematics itself‚Äî‚Äù<br />
</font>
</p></blockquote>
<p>
I was actually relieved to turn the subject back toward mathematics, as Neil and I usually talked about.</p>
<blockquote><p>
<font color="green"><br />
‚Äú‚Äîyour most storied advance of the past quarter century was achieved by ten years‚Äô concerted study of the Frey-Hellegouarch <a href="https://en.wikipedia.org/wiki/Frey_curve">curve</a>. Which by Fermat‚Äôs Last Theorem does not exist.‚Äù<br />
</font>
</p></blockquote>
<p>
</p><p></p><h2> Existence </h2><p></p>
<p></p><p>
I could not argue with that. This set me pondering. Whether mathematical objects <em>exist</em> in reality defines the debate over Platonism. But what, then, is the reality of <em>nonexistent</em> mathematical objects? </p>
<p>
Nonexistent objects still follow rules and aid deductions about objects that do exist. So, they too exist? Moreover, we often cannot prove that those objects do not exist‚Äîfor all we know they may be just as real. Polynomial-time algorithms for satisfiability and many other problems‚Äîthose are bread and butter in theory. I wanted Neil to tell me more about some of them.</p>
<p>
‚ÄúNeil, have your folk worked on the projective plane of order 10?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚Äú<em>Aye</em>. Not only did we long ago have all the results of this <a href="https://www.sciencedirect.com/science/article/pii/0097316573900642">paper</a> on them, our engineers recommended it as the thoroughfare pattern for new towns.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúYou have built them?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúIndeed‚Äîin two new districts around Carlingford back home.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúBut they don‚Äôt exist.‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúBy our laws and treaties they exist until your people prove they don‚Äôt. Then they have a 50-year sunset. Which <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.8684&amp;rep=rep1&amp;type=pdf">means</a> the towns have 20 years left.<br />
</font>
</p></blockquote>
<p>
‚ÄúThat‚Äôs sad.‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúIt‚Äôs actually a much better system than the Scots have. Their villages of this type such as <a href="https://en.wikipedia.org/wiki/Brigadoon">Brigadoon</a> come <a href="https://www.glenlaurel.com/about-us/blog/the-legend-of-brigadoon">back</a> every 100 years just for one day. But Brexit may put paid to our two towns sooner. We are <a href="https://www.irishcentral.com/travel/leprechauns-protected-european-law">protected</a> under E.U. law, but those towns are just over the Northern Ireland border.<br />
</font>
</p></blockquote>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/03/carlingfordsign.png"><img width="350" alt="" src="https://rjlipton.files.wordpress.com/2019/03/carlingfordsign.png?w=350&amp;h=205" class="aligncenter wp-image-15686" height="205" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://thefw.com/things-you-didnt-know-about-leprechauns/">src1</a>, <a href="https://en.wikipedia.org/wiki/Carlingford,_County_Louth">src2</a></font>
</td>
</tr>
</tbody></table>
<p>
‚ÄúHow about odd perfect numbers?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚Äú<em>Nay</em>. Ye know the rules. We can nay tell that which your folk do not know, unless there is nothing else ye learn that ye could not learn without us.‚Äù<br />
</font>
</p></blockquote>
<p>
I pondered: what could I ask about computational complexity that Neil could respond to in this kind of zero-knowledge way? But Neil cut in.</p>
<blockquote><p>
<font color="green"><br />
‚ÄúIt will be much more fruitful to discuss objects that ye <em>know</em> do not exist‚Äîand yet ye <em>use</em> them anyway.‚Äù<br />
</font>
</p></blockquote>
<p>
</p><p></p><h2> Mathematical Leprechauns </h2><p></p>
<p></p><p>
I thought, which could he mean? I recalled the story we <a href="https://rjlipton.wordpress.com/2010/01/23/definitions-definitions-do-we-need-them/">told</a> about a student getting his degree for a thesis with many new results on a strong kind of Lipschitz/H√∂lder function even though an examiner observed that non-constant ones do not exist. Ken heard the same story as an undergraduate, with the detail that it was an undergraduate senior thesis, not PhD. The Dirac delta function? Well, that definitely exists as a <a href="https://en.wikipedia.org/wiki/Dirac_delta_function#As_a_measure">measure</a>. I forgot an obvious example until Neil said it.</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThere is the field with one element: <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathbb{F}_1}" class="latex" title="{\mathbb{F}_1}" />.‚Äù
</font></p></blockquote><font color="green">
<p>
Of course. We <a href="https://rjlipton.wordpress.com/2012/08/23/do-we-need-mysticism-in-theory/">posted</a> about it. </p>
<blockquote><p>
<font color="green"><br />
‚ÄúIt is an active research subject, especially in the past dozen years. Your Fields medalist Alain Connes has co-written a <a href="https://arxiv.org/pdf/0806.2401v1.pdf">whole</a> <a href="https://arxiv.org/abs/0809.2926">series</a> of <a href="https://arxiv.org/abs/0903.2024">papers</a> on it. Yuri Manin <a href="https://arxiv.org/abs/0809.1564">also</a>. Your blog friend Henry Cohn got a <a href="https://arxiv.org/abs/math/0407093">paper</a> on it into the <em>Monthly</em>‚Äîthink of the youngsters‚Ä¶ Edifices are even <a href="https://arxiv.org/abs/0909.0069">being</a> <a href="https://link.springer.com/content/pdf/10.1007/s00209-009-0638-0.pdf">built</a> <a href="https://arxiv.org/abs/1709.05831">upon</a> it.‚Äù<br />
</font>
</p></blockquote>
<p>
‚ÄúCan you give some less-obvious ones for our readers?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThere is the uniform distribution on the natural numbers. This <a href="http://www.stat.cmu.edu/tr/tr814/tr814.pdf">paper</a> gives variations that do exist, but it makes the need and use of the original concept clear.‚Äù<br />
</font>
</p></blockquote>
<p>
Ken had in fact once finished a lecture on Kolmogorov complexity when short on time by appealing to it.</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThere are fields <i>F</i> whose algebraic closures have degrees 3 and 5 over <i>F</i>. Those are highly useful.‚Äù<br />
</font>
</p></blockquote>
<p>
I knew by a <a href="https://kconrad.math.uconn.edu/blurbs/galoistheory/artinschreier.pdf">theorem</a> of Emil Artin and Otto Schreier that they cannot exist. But it struck me as natural that they <em>should</em> exist. I wondered how much one would need to tweak the rules of group theory to make them possible.</p>
<blockquote><p>
<font color="green"><br />
‚ÄúThen there is the free complete lattice on 3 generators.‚Äù<br />
</font>
</p></blockquote>
<p>
Wait‚ÄîI thought <a href="https://en.wikipedia.org/wiki/Complete_lattice#Free_complete_lattices">that</a> could exist if one loosened up set theory. So I asked:</p>
<p>
‚ÄúNeil, do some of these objects exist in alternative worlds known to leprechauns in which the rules of mathematics are crazy, not like the real world?‚Äù</p>
<blockquote><p>
<font color="green"><br />
‚ÄúWhat makes you think ye don‚Äôt live in one of those other worlds?‚Äù<br />
</font>
</p></blockquote>
<p>
Before I could react, Neil picked up a solid glass sphere art object that belonged to Kathryn. He pulled out a diamond-encrusted knife and slashed it as green light flashed in every direction until he stopped. Then from his hands he gave me <a href="https://en.wikipedia.org/wiki/Banach-Tarski_paradox">two</a> glass spheres of the same size. </p>
<blockquote><p>
<font color="green"><br />
‚ÄúFor the happy couple‚Äî<em>la le Padraig suna ye-uv!</em>‚Äù<br />
</font>
</p></blockquote>
<p>
And he was gone.</p>
<p>
</p><p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p></font><p><font color="green">
What is your view on the nature of mathematical reality? Do nonexistent mathematical objects exist? What are your favorite examples?  </font></p>
<p></p></font></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/03/16/leprechauns-go-universal/"><span class="datestr">at March 17, 2019 04:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
