<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 20, 2020 08:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/stoc2020/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/stoc2020/">Conference Digest - STOC 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a href="http://acm-stoc.org/stoc2020/">STOC 2020</a> was recently held online, as one of the first major theory conferences during the COVID-19 era.
It featured four papers on differential privacy, which we list and link below.
Each one is accompanied by a video from the conference, as well as a longer video if available.
Please let us know if we missed any papers on differential privacy, either in the comments below or by email.</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1911.08339">The Power of Factorization Mechanisms in Local and Central Differential Privacy</a> (<a href="https://www.youtube.com/watch?v=hSenRTxhZhM">video</a>)<br />
<a href="https://dblp.uni-trier.de/pers/hd/e/Edmonds:Alexander">Alexander Edmonds</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2005.04763">Private Stochastic Convex Optimization: Optimal Rates in Linear Time</a> (<a href="https://www.youtube.com/watch?v=Tlc-z-MFAmM">video</a>)<br />
<a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://tomerkoren.github.io/">Tomer Koren</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.04014">Interaction is necessary for distributed learning with privacy or communication constraints</a> (<a href="https://www.youtube.com/watch?v=AWgzaFOU_HM">video</a>)<br />
<a href="https://yuvaldagan.wordpress.com/">Yuval Dagan</a>, <a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.05271">Does Learning Require Memorization? A Short Tale about a Long Tail</a> (<a href="https://www.youtube.com/watch?v=sV59uoWJRnk">video</a>, <a href="https://www.youtube.com/watch?v=Fp7cgHRl8Yc">longer video</a>)<br />
<a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
</ul></div>







<p class="date">
by Gautam Kamath <a href="https://differentialprivacy.org/stoc2020/"><span class="datestr">at July 20, 2020 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://gradientscience.org/transfer-learning/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/madry.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://gradientscience.org/transfer-learning/">Transfer Learning with Adversarially Robust Models</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a style="float: left; width: 45%;" href="https://arxiv.org/abs/2007.08489" class="bbutton">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a style="float: left; width: 45%;" href="https://github.com/Microsoft/robust-models-transfer" class="bbutton">
<i class="fab fa-github"></i>
   Models and Code
</a>
<br /></p>

<p><i>In our <a href="https://arxiv.org/abs/2007.08489">latest paper</a>, in collaboration with <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, we explore adversarial
robustness as an avenue for training computer vision models with more transferrable
features. We find that robust models outperform their standard counterparts on
a variety of transfer learning tasks.</i></p>

<h2 id="what-is-transfer-learning">What is transfer learning?</h2>

<p>Transfer learning is a paradigm where one leverages information
from a “source” task to better solve another “target” task. Particularly when there is little training data or compute available for solving the target
task, transfer learning provides a simple and efficient way to obtain performant
machine learning models.</p>

<p>Transfer learning has already proven its utility in many ML contexts. In natural language processing, for example, one can leverage language models pre-trained on large
text corpora to beat state-of-the-art performance on
tasks like query answering, entity recognition or part-of-speech classification.</p>

<p>In our work we focus on computer vision; in this context, a standard—and
remarkably successful—transfer learning pipeline is “ImageNet pre-training.”
This pipeline starts with a deep neural network trained on the <a href="http://image-net.org">ImageNet-1K</a>
dataset, and then refines this pre-trained model for a target task. The target task can range
from classification of smaller datasets (e.g., <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a>) to more complex
tasks like object detection (e.g., <a href="http://host.robots.ox.ac.uk/pascal/VOC/">VOC</a>).</p>

<p>Although there are many ways in which one can refine a pre-trained model, we
will restrict our attention to the two most popular methods:</p>

<ul>
  <li><strong>Fixed-feature</strong>: In fixed-feature transfer learning, we replace the final
(linear) layer of the neural network with a new layer that has the correct
number of outputs for the target task. Then, keeping the rest of the layers
<em>fixed</em>, we train the newly replaced layer on the target task.</li>
  <li><strong>Full-network</strong>: In full-network transfer learning, we also replace the last
layer but do not freeze any layers afterwards. Instead, we use the pre-trained
network
as a sort of “initialization,” and continue training <em>all</em> the layers on the
target task.</li>
</ul>

<p>When at least a moderate amount of data is available, full-network transfer
learning typically outperforms the fixed-feature strategy.</p>

<h2 id="how-can-we-improve-transfer-learning">How can we improve transfer learning?</h2>

<p>Although we don’t have a comprehensive understanding of what makes transfer
learning algorithms tick, there has been a long line of work focused on identifying 
factors that improve (or worsen) performance (examples include
<a href="https://arxiv.org/abs/1406.5774">[1]</a>,
<a href="https://arxiv.org/abs/1608.08614">[2]</a>,
<a href="https://arxiv.org/abs/1805.08974">[3]</a>,
<a href="https://arxiv.org/abs/1804.08328">[4]</a>,
<a href="https://arxiv.org/abs/1411.1792">[5]</a>).</p>

<p>By design, the pre-trained ImageNet model itself plays a major role here:
indeed, a recent study by <a href="https://arxiv.org/abs/1805.08974">Kornblith, Shlens, and Le</a> finds that
pre-trained models which achieve a higher ImageNet accuracy also perform better when
transferred to downstream classification tasks, with a tight linear
correspondence between ImageNet accuracy and the accuracy on the target task:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/ksl.png" alt="A scatter plot of ImageNet accuracy versus downstream     transfer accuracy showing the linear relation." class="bigimg" /></p>
<div class="footnote">
Reproduced from <a href="https://arxiv.org/abs/1805.08974">[KSL19]</a>. 
Each dot is a pre-trained model whose $x$ coordinate is given by its 
ImageNet accuracy and $y$ coordinate is given by its downstream 
accuracy on the target task (after the corresponding refinement on that task).
</div>

<p>But is improving ImageNet accuracy of the pre-trained model the <em>only</em> way to improve transfer learning performance?</p>

<p>After all, we want to obtain models that have learned broadly applicable features from the
source dataset. ImageNet accuracy likely correlates with the quality of
features that a model has learned, but may not fully describe the downstream
utility of these features.
Ultimately, the nature of learned features stems from the <em>priors</em> placed on
them during training. For example, there have been studies of the (sometimes
implicit) priors imposed by architectural components (e.g., <a href="https://dmitryulyanov.github.io/deep_image_prior">convolutional layers</a>),
<a href="https://www.tandfonline.com/doi/abs/10.1198/10618600152418584">data</a>
<a href="https://arxiv.org/abs/1911.09071">augmentation</a>, 
<a href="https://arxiv.org/abs/1811.00401">loss functions</a> and even
<a href="https://stats385.github.io/assets/lectures/Stanford_Donoho_class_Nov_19.pdf">gradient descent</a> on neural network training.</p>

<p>In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, we study another prior: <em>adversarial robustness</em>.
Adversarial robustness—a rather frequent subject on this blog—refers to
model’s invariance to small (often imperceptible) perturbations of natural
inputs, called <a href="https://gradientscience.org/intro_adversarial">adversarial examples</a>.</p>

<p>Standard neural networks (i.e., trained with the goal of maximizing
accuracy) are extremely vulnerable to such adversarial examples. For example,
with just a tiny perturbation to the pig image below, a pre-trained ImageNet
classifier will predict it as an “airliner” with 99% confidence:</p>

<p><img src="https://gradientscience.org/images/piggie.png" alt="An adversarial example: a pig on the left which is imperceptibly perturbed to be classified as an airliner on the right." /></p>
<div class="footnote">
A "pigs-can-fly" adversarial example: The "pig" image on the left is correctly classified by a standard ML model, but its imperceptibly perturbed counterpart on the right is classified as an "airliner" with 99% confidence.
</div>

<p>Adversarial robustness is thus typically induced at training time by replacing
the standard loss minimization objective with a <em>robust optimization</em> objective
(see our <a href="https://gradientscience.org/robust_opt_pt1">post on robust optimization</a> for more background):</p>



<p>The above objective trains models to be robust to image perturbations that are
small in (pixel-wise) $\ell_2$ (Euclidean) normIn reality, an $\ell_2$ ball doesn't perfectly capture the
set of imperceptible perturbations we want models to be robust to—but robustness with respect to this fairly rudimentary notion of perturbations turns out to be already non-trivial and very helpful.. 
The parameter $\varepsilon$ is a hyperparameter
governing the intended degree of invariance of the resulting models to the
corresponding perturbations. Setting 
$\varepsilon = 0$ corresponds to standard training, and increasing $\varepsilon$
asks the model to be robust to increasingly large perturbations.
In short, the objective asks the model to minimize risk on not only the 
training datapoints but also the entire radius-$\varepsilon$
neighbourhood around them.</p>

<p><em>[A quick plug: Our <a href="https://github.com/MadryLab/robustness"><code class="language-plaintext highlighter-rouge">robustness</code> Python library</a>, used for the code release of this paper, enables one to easily train and manipulate both standard and adversarially robust models.]</em></p>

<p>Although adversarial robustness has been initially studied solely through the lens of machine learning security, a line
of recent work (including some that’s been <a href="https://gradientscience.org/adv">previously</a> 
<a href="https://gradientscience.org/robust_apps">covered</a> on this blog) has begun to study
adversarially robust models in their own right, framing adversarial robustness
as a prior that forces models to learn features that are locally stable.
These works have found that on the one hand, adversarially robust models tend
to attain lower accuracy than their standardly-trained
counterparts.</p>

<p>On the other hand, recent work suggests that the feature
representations of robust models carry several advantages over those of
standard models, such as <a href="https://arxiv.org/abs/1805.12152">better-behaved</a>
<a href="https://arxiv.org/abs/1905.09797">gradients</a>, <a href="https://arxiv.org/abs/1910.08640">representation
invertibility</a>, and more <a href="https://arxiv.org/abs/2005.10190">specialized
features</a>.
We’ve actually discussed some of these observations in earlier posts on this
blog—see, e.g., our posts about 
<a href="https://gradientscience.org/robust_reps">representation learning</a> and 
<a href="https://gradientscience.org/robust_apps">image synthesis</a>.</p>

<p>These desirable properties
might suggest that robust neural networks are learning better feature
representations than standard networks, which could improve transfer
performance.</p>

<h3 id="adversarial-robustness-and-transfer-learning">Adversarial robustness and transfer learning</h3>

<p>So in summary, we have standard models with high accuracy on the source task but
little (or no) robustness; and we have adversarially robust models, which are
worse in terms of ImageNet accuracy, but have the “nice”
representational properties identified and discussed by prior works. Which
models are better for transfer learning?</p>

<p>To answer this question, we trained and examined a large collection
of standard and robust ImageNet models, while grid searching over a wide range of
hyperparameters and architectures to find the best model of each type. (All
models are available for download via our <a href="https://github.com/microsoft/robust-models-transfer">code/model
release</a> and more
details on our training procedure can be found there and in <a href="https://arxiv.org/abs/2007.08489">our
paper</a>). We then performed transfer
learning (using both fixed-feature and full-network refinement) from each
trained model to 12 downstream classification tasks.</p>

<p>It turns out that 
adversarially robust source models fairly consistently outperform their standard counterparts in
terms of downstream accuracy. In the table below, we compare the accuracies of
the best standard model (searching over hyperparameters and
architecture) and the best robust model (searching over the
previous factors as well as robustness level $\varepsilon$):</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/results-table.svg" style="width: 100%;" class="bigimg" alt="Table showing that robust models     perform better than their standard counterparts." /></p>
<div class="footnote">
    The main result: Adversarially robust models outperform their standard counterparts when transferred to downstream classification tasks.
</div>

<p>This difference in performance tends to be particularly striking in the context of fixed-feature transfer learning. The following graph shows, for each architecture and
downstream classification task, the best standard model compared to the best
robust model in that setting. As we can see, adversarially robust models
improve on the performance of their standard counterparts, and the gap tends to
<em>increase</em> as networks increase in width:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/LogisticRegression.svg" alt="A bar chart showing that robust models improve on     standard ones even without taking the maximum over architectures." class="bigimg" /></p>
<div class="footnote">
    Adversarially robust models tend to improve over standard networks for
    individual architectures too. (An analogous graph for full-network
    transfer learning is given in Figure 3 of <a href="https://arxiv.org/abs/2007.08489">our paper</a>.)
</div>

<p>Adversarial robustness improved downstream transfer
performance even when the target task was not a classification one. For example, the
following table compares standard and robust pre-training for use in downstream
object detection and instance segmentation:</p>

<p><img src="https://gradientscience.org/../assets/robust-transfer-learning/obj-det-results.svg" style="width: 80%;" class="bigimg" /></p>
<div class="footnote">
</div>

<h3 id="robustness-versus-accuracy">Robustness versus accuracy</h3>

<p>So it seems like robust models, despite being less accurate on the source task, are actually
better for transfer learning purposes. Indeed, the linear relation between
 ImageNet accuracy and transfer performance observed in prior work (see our discussion above) doesn’t seem
 to hold when the robustness parameter is varied. Compare the graphs below to the ones at the very start of this post:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/wide_resnet50_4_LogisticRegression.svg" class="bigimg" /></p>
<div class="footnote">
    Source-task (ImageNet) versus target (fixed-feature) accuracy for models with the same
    architecture while varying the robustness levels. Each dot is a
    WideResNet-50x4 model with $x$ coordinate given by source-task accuracy and
    $y$ coordinate given by fixed-feature transfer learning accuracy.
    Contrast the trends here with the "fixed-feature" trend in the first
    figure of this post—the linear trend depicted there largely disappears as less
    accurate but more robust models perform better in terms of transfer.
</div>

<p>How do we reconcile our observations with these trends observed by prior work?</p>

<p>We hypothesize that robustness and accuracy have <em>disentangled</em> effects on
transfer performance. That is, for a fixed level of robustness, higher
accuracy on the source task helps transfer, and for a fixed level of
accuracy, increased robustness helps transfer. Indeed, as shown below, for a
fixed level of robustness, the accuracy-transfer relation tends to hold
strongly:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/fixed-robustness.svg" class="bigimg" /></p>
<div class="footnote">
Even though robust models appear to break the linear
accuracy-transfer trend, this trend is actually preserved for a fixed value of
robustness. Each dot in the graph is a different architecture, trained for the same level of robustness ($\varepsilon = 3.0$). The $x$ coordinate is source task (ImageNet) accuracy, and the $y$ coordinate is the downstream accuracy on each target dataset.
</div>

<p>In addition to reconciling our results with those of prior work, these findings suggest that ongoing work on developing more accurate robust models
may have the added benefit of further improving transfer learning performance.</p>

<h3 id="other-empirical-mysteries-and-future-work">Other empirical mysteries and future work</h3>

<p>This post discussed how adversarially robust models might constitute a promising
avenue for improving transfer learning, and already often outperform standard
models in terms of downstream accuracy. In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, 
we study this phenomenon more closely: for example, we examine the effects of
model width, and we compare adversarial robustness to other notions of
robustness. We also uncover a few somewhat mysterious properties: for example,
resizing images seems to have a non-trivial effect on the relationship between
robustness and downstream accuracy.</p>

<p>Finally, while our work provides evidence that adversarially
robust computer vision models transfer better, understanding precisely <em>why</em> this is the case remains open. More broadly, the results we
observe indicate that we still do not yet fully understand (even empirically)
the ingredients that make transfer learning successful. We hope that our work
prompts an inquiry into the underpinnings of modern transfer learning.</p></div>







<p class="date">
<a href="https://gradientscience.org/transfer-learning/"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09116">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09116">The Combinatorial Santa Claus Problem or: How to Find Good Matchings in Non-Uniform Hypergraphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Etienne Bamas, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Paritosh.html">Paritosh Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09116">PDF</a><br /><b>Abstract: </b>We consider hypergraphs on vertices $P\cup R$ where each hyperedge contains
exactly one vertex in $P$. Our goal is to select a matching that covers all of
$P$, but we allow each selected hyperedge to drop all but an
$(1/\alpha)$-fraction of its intersection with $R$ (thus relaxing the matching
constraint). Here $\alpha$ is to be minimized. We dub this problem the
Combinatorial Santa Claus problem, since we show in this paper that this
problem and the Santa Claus problem are almost equivalent in terms of their
approximability.
</p>
<p>The non-trivial observation that any uniform regular hypergraph admits a
relaxed matching for $\alpha = O(1)$ was a major step in obtaining a constant
approximation rate for a special case of the Santa Claus problem, which
received great attention in literature. It is natural to ask if the uniformity
condition can be omitted. Our main result is that every (non-uniform) regular
hypergraph admits a relaxed matching for $\alpha = O(\log\log(|R|))$, when all
hyperedges are sufficiently large (a condition that is necessary). In
particular, this implies an $O(\log\log(|R|))$-approximation algorithm for the
Combinatorial Santa Claus problem with large hyperedges.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09116"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09099">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09099">A dichotomy theorem for nonuniform CSPs simplified</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09099">PDF</a><br /><b>Abstract: </b>In a non-uniform Constraint Satisfaction problem CSP(G), where G is a set of
relations on a finite set A, the goal is to find an assignment of values to
variables subject to constraints imposed on specified sets of variables using
the relations from G. The Dichotomy Conjecture for the non-uniform CSP states
that for every constraint language G the problem CSP(G) is either solvable in
polynomial time or is NP-complete. It was proposed by Feder and Vardi in their
seminal 1993 paper. In this paper we confirm the Dichotomy Conjecture.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09099"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09075">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09075">Efficient Linear and Affine Codes for Correcting Insertions/Deletions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Kuan.html">Kuan Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haeupler:Bernhard.html">Bernhard Haeupler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xin.html">Xin Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09075">PDF</a><br /><b>Abstract: </b>This paper studies \emph{linear} and \emph{affine} error-correcting codes for
correcting synchronization errors such as insertions and deletions. We call
such codes linear/affine insdel codes.
</p>
<p>Linear codes that can correct even a single deletion are limited to have
information rate at most $1/2$ (achieved by the trivial 2-fold repetition
code). Previously, it was (erroneously) reported that more generally no
non-trivial linear codes correcting $k$ deletions exist, i.e., that the
$(k+1)$-fold repetition codes and its rate of $1/(k+1)$ are basically optimal
for any $k$. We disprove this and show the existence of binary linear codes of
length $n$ and rate just below $1/2$ capable of correcting $\Omega(n)$
insertions and deletions. This identifies rate $1/2$ as a sharp threshold for
recovery from deletions for linear codes, and reopens the quest for a better
understanding of the capabilities of linear codes for correcting
insertions/deletions.
</p>
<p>We prove novel outer bounds and existential inner bounds for the rate vs.
(edit) distance trade-off of linear insdel codes. We complement our existential
results with an efficient synchronization-string-based transformation that
converts any asymptotically-good linear code for Hamming errors into an
asymptotically-good linear code for insdel errors. Lastly, we show that the
$\frac{1}{2}$-rate limitation does not hold for affine codes by giving an
explicit affine code of rate $1-\epsilon$ which can efficiently correct a
constant fraction of insdel errors.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09075"><span class="datestr">at July 20, 2020 01:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09065">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09065">Improved Approximation Factor for Adaptive Influence Maximization via Simple Greedy Strategies</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Gianlorenzo D'Angelo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Poddar:Debashmita.html">Debashmita Poddar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinci:Cosimo.html">Cosimo Vinci</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09065">PDF</a><br /><b>Abstract: </b>In the adaptive influence maximization problem, we are given a social network
and a budget $k$, and we iteratively select $k$ nodes, called seeds, in order
to maximize the expected number of nodes that are reached by an influence
cascade that they generate according to a stochastic model for influence
diffusion. Differently from the non-adaptive influence maximization problem,
where all the seeds must be selected beforehand, here nodes are selected
sequentially one by one, and the decision on the $i$th seed is based on the
observed cascade produced by the first $i-1$ seeds. We focus on the myopic
feedback model, in which we can only observe which neighbors of previously
selected seeds have been influenced and on the independent cascade model, where
each edge is associated with an independent probability of diffusing influence.
Previous works showed that the adaptivity gap is at most $4$, which implies
that the non-adaptive greedy algorithm guarantees an approximation factor of
$\frac{1}{4}\left(1-\frac{1}{e}\right)$ for the adaptive problem. In this
paper, we improve the bounds on both the adaptivity gap and on the
approximation factor. We directly analyze the approximation factor of the
non-adaptive greedy algorithm, without passing through the adaptivity gap, and
show that it is at least $\frac{1}{2}\left(1-\frac{1}{e}\right)$. Therefore,
the adaptivity gap is at most $\frac{2e}{e-1}\approx 3.164$. To prove these
bounds, we introduce a new approach to relate the greedy non-adaptive algorithm
to the adaptive optimum. The new approach does not rely on multi-linear
extensions or random walks on optimal decision trees, which are commonly used
techniques in the field. We believe that it is of independent interest and may
be used to analyze other adaptive optimization problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09065"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09045">Integer factorization and Riemann's hypothesis: Why two-item joint replenishment is hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Andreas_S=.html">Andreas S. Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Telha:Claudio.html">Claudio Telha</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09045">PDF</a><br /><b>Abstract: </b>Distribution networks with periodically repeating events often hold great
promise to exploit economies of scale. Joint replenishment problems are a
fundamental model in inventory management, manufacturing, and logistics that
capture these effects. However, finding an efficient algorithm that optimally
solves these models, or showing that none may exist, has long been open,
regardless of whether empty joint orders are possible or not. In either case,
we show that finding optimal solutions to joint replenishment instances with
just two products is at least as difficult as integer factorization. To the
best of the authors' knowledge, this is the first time that integer
factorization is used to explain the computational hardness of any kind of
optimization problem. Under the assumption that Riemann's Hypothesis is
correct, we can actually prove that the two-item joint replenishment problem
with possibly empty joint ordering points is NP-complete under randomized
reductions, which implies that not even quantum computers may be able to solve
it efficiently. By relating the computational complexity of joint replenishment
to cryptography, prime decomposition, and other aspects of prime numbers, a
similar approach may help to establish (integer factorization) hardness of
additional open periodic problems in supply chain management and beyond, whose
solution has eluded standard methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09045"><span class="datestr">at July 20, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09023">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09023">Parameterized Complexity of Scheduling Chains of Jobs with Delays</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodlaender:Hans_L=.html">Hans L. Bodlaender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wegen:Marieke_van_der.html">Marieke van der Wegen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09023">PDF</a><br /><b>Abstract: </b>In this paper, we consider the parameterized complexity of the following
scheduling problem. We must schedule a number of jobs on $m$ machines, where
each job has unit length, and the graph of precedence constraints consists of a
set of chains. Each precedence constraint is labelled with an integer that
denotes the exact (or minimum) delay between the jobs. We study different
cases; delays can be given in unary and in binary, and the case that we have a
single machine is discussed separately. We consider the complexity of this
problem parameterized by the number of chains, and by the thickness of the
instance, which is the maximum number of chains whose intervals between release
date and deadline overlap.
</p>
<p>We show that this scheduling problem with exact delays in unary is
$W[t]$-hard for all $t$, when parameterized by the thickness, even when we have
a single machine ($m = 1$). When parameterized by the number of chains, this
problem is $W[1]$-complete when we have a single or a constant number of
machines, and $W[2]$-complete when the number of machines is a variable. The
problem with minimum delays, given in unary, parameterized by the number of
chains (and as a simple corollary, also when parameterized by the thickness) is
$W[1]$-hard for a single or a constant number of machines, and $W[2]$-hard when
the number of machines is variable.
</p>
<p>With a dynamic programming algorithm, one can show membership in XP for exact
and minimum delays in unary, for any number of machines, when parameterized by
thickness or number of chains. For a single machine, with exact delays in
binary, parameterized by the number of chains, membership in XP can be shown
with branching and solving a system of difference constraints. For all other
cases for delays in binary, membership in XP is open.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09023"><span class="datestr">at July 20, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.09018">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.09018">Solving hard cut problems via flow-augmentation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Eun_Jung.html">Eun Jung Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kratsch:Stefan.html">Stefan Kratsch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wahlstr=ouml=m:Magnus.html">Magnus Wahlström</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09018">PDF</a><br /><b>Abstract: </b>We present a new technique for designing FPT algorithms for graph cut
problems in undirected graphs, which we call flow augmentation. Our technique
is applicable to problems that can be phrased as a search for an (edge)
$(s,t)$-cut of cardinality at most $k$ in an undirected graph $G$ with
designated terminals $s$ and $t$.
</p>
<p>More precisely, we consider problems where an (unknown) solution is a set $Z
\subseteq E(G)$ of size at most $k$ such that (1) in $G-Z$, $s$ and $t$ are in
distinct connected components, (2) every edge of $Z$ connects two distinct
connected components of $G-Z$, and (3) if we define the set $Z_{s,t} \subseteq
Z$ as these edges $e \in Z$ for which there exists an $(s,t)$-path $P_e$ with
$E(P_e) \cap Z = \{e\}$, then $Z_{s,t}$ separates $s$ from $t$. We prove that
in this scenario one can in randomized time $k^{O(1)} (|V(G)|+|E(G)|)$ add a
number of edges to the graph so that with $2^{-O(k \log k)}$ probability no
added edge connects two components of $G-Z$ and $Z_{s,t}$ becomes a minimum cut
between $s$ and $t$.
</p>
<p>We apply our method to obtain a randomized FPT algorithm for a notorious
"hard nut" graph cut problem we call Coupled Min-Cut. This problem emerges out
of the study of FPT algorithms for Min CSP problems, and was unamenable to
other techniques for parameterized algorithms in graph cut problems, such as
Randomized Contractions, Treewidth Reduction or Shadow Removal.
</p>
<p>To demonstrate the power of the approach, we consider more generally Min
SAT($\Gamma$), parameterized by the solution cost. We show that every problem
Min SAT($\Gamma$) is either (1) FPT, (2) W[1]-hard, or (3) able to express the
soft constraint $(u \to v)$, and thereby also the min-cut problem in directed
graphs. All the W[1]-hard cases were known or immediate, and the main new
result is an FPT algorithm for a generalization of Coupled Min-Cut.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.09018"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08965">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08965">Escaping a Polygon</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abel:Zachary.html">Zachary Abel</a>, Hugo Akitaya, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Martin_L=.html">Martin L. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hesterberg:Adam.html">Adam Hesterberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Ku:Jason_S=.html">Jason S. Ku</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lynch:Jayson.html">Jayson Lynch</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08965">PDF</a><br /><b>Abstract: </b>Suppose an "escaping" player moves continuously at maximum speed 1 in the
interior of a region, while a "pursuing" player moves continuously at maximum
speed $r$ outside the region. For what $r$ can the first player escape the
region, that is, reach the boundary a positive distance away from the pursuing
player, assuming optimal play by both players? We formalize a model for this
infinitesimally alternating 2-player game that we prove has a unique winner in
any region with locally rectifiable boundary, avoiding pathological behaviors
(where both players can have "winning strategies") previously identified for
pursuit-evasion games such as the Lion and Man problem in certain metric
spaces. For some regions, including both equilateral triangle and square, we
give exact results for the critical speed ratio, above which the pursuing
player can win and below which the escaping player can win (and at which the
pursuing player can win). For simple polygons, we give a simple formula and
polynomial-time algorithm that is guaranteed to give a 10.89898-approximation
to the critical speed ratio, and we give a pseudopolynomial-time approximation
scheme for arbitrarily approximating the critical speed ratio. On the negative
side, we prove NP-hardness of the problem for polyhedral domains in 3D, and
prove stronger results (PSPACE-hardness and NP-hardness even to approximate)
for generalizations to multiple escaping and pursuing players.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08965"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08914">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08914">All-Pairs LCA in DAGs: Breaking through the $O(n^{2.5})$ barrier</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grandoni:Fabrizio.html">Fabrizio Grandoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Italiano:Giuseppe_F=.html">Giuseppe F. Italiano</a>, Aleksander Łukasiewicz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parotsidis:Nikos.html">Nikos Parotsidis</a>, Przemysław Uznański <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08914">PDF</a><br /><b>Abstract: </b>Let $G=(V,E)$ be an $n$-vertex directed acyclic graph (DAG). A lowest common
ancestor (LCA) of two vertices $u$ and $v$ is a common ancestor $w$ of $u$ and
$v$ such that no descendant of $w$ has the same property. In this paper, we
consider the problem of computing an LCA, if any, for all pairs of vertices in
a DAG. The fastest known algorithms for this problem exploit fast matrix
multiplication subroutines and have running times ranging from $O(n^{2.687})$
[Bender et al.~SODA'01] down to $O(n^{2.615})$ [Kowaluk and Lingas~ICALP'05]
and $O(n^{2.569})$ [Czumaj et al.~TCS'07]. Somewhat surprisingly, all those
bounds would still be $\Omega(n^{2.5})$ even if matrix multiplication could be
solved optimally (i.e., $\omega=2$). This appears to be an inherent barrier for
all the currently known approaches, which raises the natural question on
whether one could break through the $O(n^{2.5})$ barrier for this problem.
</p>
<p>In this paper, we answer this question affirmatively: in particular, we
present an $\tilde O(n^{2.447})$ ($\tilde O(n^{7/3})$ for $\omega=2$) algorithm
for finding an LCA for all pairs of vertices in a DAG, which represents the
first improvement on the running times for this problem in the last 13 years. A
key tool in our approach is a fast algorithm to partition the vertex set of the
transitive closure of $G$ into a collection of $O(\ell)$ chains and $O(n/\ell)$
antichains, for a given parameter $\ell$. As usual, a chain is a path while an
antichain is an independent set. We then find, for all pairs of vertices, a
\emph{candidate} LCA among the chain and antichain vertices, separately. The
first set is obtained via a reduction to min-max matrix multiplication. The
computation of the second set can be reduced to Boolean matrix multiplication
similarly to previous results on this problem. We finally combine the two
solutions together in a careful (non-obvious) manner.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08914"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08900">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08900">A fast approximate skeleton with guarantees for any cloud of points in a Euclidean space</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Yury Elkin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Di.html">Di Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurlin:Vitaliy.html">Vitaliy Kurlin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08900">PDF</a><br /><b>Abstract: </b>The tree reconstruction problem is to find an embedded straight-line tree
that approximates a given cloud of unorganized points in $\mathbb{R}^m$ up to a
certain error. A practical solution to this problem will accelerate a discovery
of new colloidal products with desired physical properties such as viscosity.
We define the Approximate Skeleton of any finite point cloud $C$ in a Euclidean
space with theoretical guarantees. The Approximate Skeleton ASk$(C)$ always
belongs to a given offset of $C$, i.e. the maximum distance from $C$ to
ASk$(C)$ can be a given maximum error. The number of vertices in the
Approximate Skeleton is close to the minimum number in an optimal tree by
factor 2. The new Approximate Skeleton of any unorganized point cloud $C$ is
computed in a near linear time in the number of points in $C$. Finally, the
Approximate Skeleton outperforms past skeletonization algorithms on the size
and accuracy of reconstruction for a large dataset of real micelles and random
clouds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08900"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08840">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08840">Adaptive Gradient Methods for Constrained Convex Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ene:Alina.html">Alina Ene</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vladu:Adrian.html">Adrian Vladu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08840">PDF</a><br /><b>Abstract: </b>We provide new adaptive first-order methods for constrained convex
optimization. Our main algorithm AdaAGD+ is an accelerated method, which is
universal in the sense that it achieves nearly-optimal convergence rates for
both smooth and non-smooth functions, even when it only has access to
stochastic gradients. In addition, it does not require any prior knowledge on
how the objective function is parametrized, since it automatically adjusts its
per-coordinate learning rate. This can be seen as a truly accelerated AdaGrad
method for constrained optimization.
</p>
<p>We complement it with a simpler algorithm AdaGrad+ which enjoys the same
features, and achieves the standard non-accelerated convergence rate. We also
present a set of new results involving adaptive methods for unconstrained
optimization and monotone operators.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08840"><span class="datestr">at July 20, 2020 01:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08836">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08836">Efficient Exact Algorithms for Maximum Balanced Biclique Search in Bipartite Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lu.html">Lu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Chengfei.html">Chengfei Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Rui.html">Rui Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jiajie.html">Jiajie Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianxin.html">Jianxin Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08836">PDF</a><br /><b>Abstract: </b>Given a bipartite graph, the maximum balanced biclique (\textsf{MBB})
problem, discovering a mutually connected while equal-sized disjoint sets with
the maximum cardinality, plays a significant role for mining the bipartite
graph and has numerous applications. Despite the NP-hardness of the
\textsf{MBB} problem, in this paper, we show that an exact \textsf{MBB} can be
discovered extremely fast in bipartite graphs for real applications. We propose
two exact algorithms dedicated for dense and sparse bipartite graphs
respectively. For dense bipartite graphs, an $\mathcal{O}^{*}( 1.3803^{n})$
algorithm is proposed. This algorithm in fact can find an \textsf{MBB} in near
polynomial time for dense bipartite graphs that are common for applications
such as VLSI design. This is because, using our proposed novel techniques, the
search can fast converge to sufficiently dense bipartite graphs which we prove
to be polynomially solvable. For large sparse bipartite graphs typical for
applications such as biological data analysis, an $\mathcal{O}^{*}(
1.3803^{\ddot{\delta}})$ algorithm is proposed, where $\ddot{\delta}$ is only a
few hundreds for large sparse bipartite graphs with millions of vertices. The
indispensible optimizations that lead to this time complexity are: we transform
a large sparse bipartite graph into a limited number of dense subgraphs with
size up to $\ddot{\delta}$ and then apply our proposed algorithm for dense
bipartite graphs on each of the subgraphs. To further speed up this algorithm,
tighter upper bounds, faster heuristics and effective reductions are proposed,
allowing an \textsf{MBB} to be discovered within a few seconds for bipartite
graphs with millions of vertices. Extensive experiments are conducted on
synthetic and real large bipartite graphs to demonstrate the efficiency and
effectiveness of our proposed algorithms and techniques.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08836"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08811">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08811">Parameterized Complexity of Graph Burning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08811">PDF</a><br /><b>Abstract: </b>Graph Burning asks, given a graph $G = (V,E)$ and an integer $k$, whether
there exists $(b_{0},\dots,b_{k-1}) \in V^{k}$ such that every vertex in $G$
has distance at most $i$ from some $b_{i}$. This problem is known to be
NP-complete even on connected caterpillars of maximum degree $3$. We study the
parameterized complexity of this problem and answer all questions arose by Kare
and Reddy [IWOCA 2019] about parameterized complexity of the problem. We show
that the problem is W[2]-complete parameterized by $k$ and that it does no
admit a polynomial kernel parameterized by vertex cover number unless
$\mathrm{NP} \subseteq \mathrm{coNP/poly}$. We also show that the problem is
fixed-parameter tractable parameterized by clique-width plus the maximum
diameter among all connected components. This implies the fixed-parameter
tractability parameterized by modular-width, by treedepth, and by distance to
cographs. Although the parameterization by distance to split graphs cannot be
handled with the clique-width argument, we show that this is also tractable by
a reduction to a generalized problem with a smaller solution size.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08811"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08787">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08787">Adaptive Exact Learning in a Mixed-Up World: Dealing with Periodicity, Errors, and Jumbled-Index Queries in String Reconstruction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshar:Ramtin.html">Ramtin Afshar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amir:Amihood.html">Amihood Amir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Pedro.html">Pedro Matias</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08787">PDF</a><br /><b>Abstract: </b>We study the query complexity of exactly reconstructing a string from
adaptive queries, such as substring, subsequence, and jumbled-index queries.
Such problems have applications, e.g., in computational biology. We provide a
number of new and improved bounds for exact string reconstruction for settings
where either the string or the queries are "mixed-up".
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08787"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08784">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08784">Optimal Algorithm for the Planar Two-Center Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Kyungjin Cho, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oh:Eunjin.html">Eunjin Oh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08784">PDF</a><br /><b>Abstract: </b>In this paper, we consider the \emph{planar two-center problem}: Given a set
$S$ of $n$ points in the plane, the goal is to find two smallest congruent
disks whose union contains all points of $S$. We present an $O(n\log n)$-time
algorithm for the planar two-center problem. This matches the best known lower
bound of $\Omega(n\log n)$ as well as improving the previously best known
algorithms which takes $O(n\log^2 n)$ time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08784"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08761">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08761">Dominated Minimal Separators are Tame (Nearly All Others are Feral)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gartland:Peter.html">Peter Gartland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08761">PDF</a><br /><b>Abstract: </b>A class ${\cal F}$ of graphs is called {\em tame} if there exists a constant
$k$ so that every graph in ${\cal F}$ on $n$ vertices contains at most $O(n^k)$
minimal separators, {\em strongly-quasi-tame} if every graph in ${\cal F}$ on
$n$ vertices contains at most $O(n^{k \log n})$ minimal separators, and {\em
feral} if there exists a constant $c &gt; 1$ so that ${\cal F}$ contains
$n$-vertex graphs with at least $c^n$ minimal separators for arbitrarily large
$n$. The classification of graph classes into tame or feral has numerous
algorithmic consequences, and has recently received considerable attention.
</p>
<p>A key graph-theoretic object in the quest for such a classification is the
notion of a $k$-{\em creature}. In a recent manuscript [Abrishami et al., Arxiv
2020] conjecture that every hereditary class ${\cal F}$ that excludes
$k$-creatures for some fixed constant $k$ is tame. We give a counterexample to
this conjecture and prove the weaker result that a hereditary class ${\cal F}$
is strongly quasi-tame if it excludes $k$-creatures for some fixed constant $k$
and additionally every minimal separator can be dominated by another fixed
constant $k'$ number of vertices. The tools developed also lead to a number of
additional results of independent interest.
</p>
<p>{\bf (i) We obtain a complete classification of all hereditary graph classes
defined by a finite set of forbidden induced subgraphs into strongly quasi-tame
or feral. This generalizes Milani\v{c} and Piva\v{c} [WG'19]. {\bf (ii)} We
show that hereditary class that excludes $k$-creatures and additionally
excludes all cycles of length at least $c$, for some constant $c$, are tame.
This generalizes the result of [Chudnovsky et al., Arxiv 2019]. {\bf (iii)} We
show that every hereditary class that excludes $k$-creatures and additionally
excludes a complete graph on $c$ vertices for some fixed constant $c$ is tame.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08761"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08738">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08738">Reliable Spanners for Metric Spaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Har=Peled:Sariel.html">Sariel Har-Peled</a>, Dániel Olah <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08738">PDF</a><br /><b>Abstract: </b>A spanner is reliable if it can withstand large, catastrophic failures in the
network. More precisely, any failure of some nodes can only cause a small
damage in the remaining graph in terms of the dilation, that is, the spanner
property is maintained for almost all nodes in the residual graph.
Constructions of reliable spanners of near linear size are known in the
low-dimensional Euclidean settings. Here, we present new constructions of
reliable spanners for planar graphs, trees and (general) metric spaces.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08738"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08717">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08717">Improved Approximation Algorithms for Tverberg Partitions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Har=Peled:Sariel.html">Sariel Har-Peled</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Timothy.html">Timothy Zhou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08717">PDF</a><br /><b>Abstract: </b>$\newcommand{\floor}[1]{\left\lfloor {#1} \right\rfloor}
\renewcommand{\Re}{\mathbb{R}}$
</p>
<p>Tverberg's theorem states that a set of $n$ points in $\Re^d$ can be
partitioned into $\floor{n/(d+1)}$ sets with a common intersection. A point in
this intersection (aka Tverberg point) is a centerpoint of the input point set,
and the Tverberg partition provides a compact proof of this, which is
algorithmically useful.
</p>
<p>Unfortunately, computing a Tverberg point exactly requires $n^{O(d^2)}$ time.
We provide several new approximation algorithms for this problem, which improve
either the running time or quality of approximation, or both. In particular, we
provide the first strongly polynomial (in both $n$ and $d$) approximation
algorithm for finding a Tverberg point.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08717"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08669">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08669">Memoryless Algorithms for the Generalized $k$-server Problem on Uniform Metrics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Christou:Dimitris.html">Dimitris Christou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fotakis:Dimitris.html">Dimitris Fotakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08669">PDF</a><br /><b>Abstract: </b>We consider the generalized $k$-server problem on uniform metrics. We study
the power of memoryless algorithms and show tight bounds of $\Theta(k!)$ on
their competitive ratio. In particular we show that the \textit{Harmonic
Algorithm} achieves this competitive ratio and provide matching lower bounds.
This improves the $\approx 2^{2^k}$ doubly-exponential bound of Chiplunkar and
Vishwanathan for the more general setting of uniform metrics with different
weights.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08669"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08643">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08643">Dynamic Geometric Independent Set</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardinal:Jean.html">Jean Cardinal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08643">PDF</a><br /><b>Abstract: </b>We present fully dynamic approximation algorithms for the Maximum Independent
Set problem on several types of geometric objects: intervals on the real line,
arbitrary axis-aligned squares in the plane and axis-aligned $d$-dimensional
hypercubes.
</p>
<p>It is known that a maximum independent set of a collection of $n$ intervals
can be found in $O(n\log n)$ time, while it is already \textsf{NP}-hard for a
set of unit squares. Moreover, the problem is inapproximable on many important
graph families, but admits a \textsf{PTAS} for a set of arbitrary pseudo-disks.
Therefore, a fundamental question in computational geometry is whether it is
possible to maintain an approximate maximum independent set in a set of dynamic
geometric objects, in truly sublinear time per insertion or deletion. In this
work, we answer this question in the affirmative for intervals, squares and
hypercubes.
</p>
<p>First, we show that for intervals a $(1+\varepsilon)$-approximate maximum
independent set can be maintained with logarithmic worst-case update time. This
is achieved by maintaining a locally optimal solution using a constant number
of constant-size exchanges per update.
</p>
<p>We then show how our interval structure can be used to design a data
structure for maintaining an expected constant factor approximate maximum
independent set of axis-aligned squares in the plane, with polylogarithmic
amortized update time. Our approach generalizes to $d$-dimensional hypercubes,
providing a $O(4^d)$-approximation with polylogarithmic update time.
</p>
<p>Those are the first approximation algorithms for any set of dynamic arbitrary
size geometric objects; previous results required bounded size ratios to obtain
polylogarithmic update time. Furthermore, it is known that our results for
squares (and hypercubes) cannot be improved to a
$(1+\varepsilon)$-approximation with the same update time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08643"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08585">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08585">Planar Distance Oracles with Better Time-Space Tradeoffs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Long:Yaowei.html">Yaowei Long</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pettie:Seth.html">Seth Pettie</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08585">PDF</a><br /><b>Abstract: </b>In a recent breakthrough, Charalampopoulos, Gawrychowski, Mozes, and Weimann
(STOC 2019) showed that exact distance queries on planar graphs could be
answered in $n^{o(1)}$ time by a data structure occupying $n^{1+o(1)}$ space,
i.e., up to $o(1)$ terms, optimal exponents in time (0) and space (1) can be
achieved simultaneously. Their distance query algorithm is recursive: it makes
successive calls to a point-location algorithm for planar Voronoi diagrams,
which involves many recursive distance queries. The depth of this recursion is
non-constant and the branching factor logarithmic, leading to $(\log
n)^{\omega(1)} = n^{o(1)}$ query times.
</p>
<p>In this paper we present a new way to do point-location in planar Voronoi
diagrams, which leads to a new exact distance oracle. At the two extremes of
our space-time tradeoff curve we can achieve either
</p>
<p>$n^{1+o(1)}$ space and $\log^{2+o(1)}n$ query time, or
</p>
<p>$n\log^{2+o(1)}n$ space and $n^{o(1)}$ query time.
</p>
<p>All previous oracles with $\tilde{O}(1)$ query time occupy space
$n^{1+\Omega(1)}$, and all previous oracles with space $\tilde{O}(n)$ answer
queries in $n^{\Omega(1)}$ time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08585"><span class="datestr">at July 20, 2020 01:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08575">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08575">Polyhedral value iteration for discounted games and energy games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozachinskiy:Alexander.html">Alexander Kozachinskiy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08575">PDF</a><br /><b>Abstract: </b>We present a deterministic algorithm solving discounted games with $n$ nodes
in strongly $n^{O(1)}\cdot (2 + \sqrt{2})^n$-time. For a special case of
bipartite discounted games our algorithm runs in $n^{O(1)}\cdot 2^n$-time.
Prior to our work no deterministic algorithm running in time $2^{o(n\log n)}$
regardless of the discount factor was known.
</p>
<p>We call our approach polyhedral value iteration. We rely on a well-known fact
that the values of a discounted game can be found from the so-called optimality
equations. In the algorithm we consider a polyhedron obtained by relaxing
optimality equations. We iterate the points on the border of this polyhedron by
moving each time along a carefully chosen shift as far as possible. This
continues until the current point satisfies optimality equations.
</p>
<p>Our approach is heavily inspired by a recent algorithm of Dorfman et al.
(ICALP 2019) for energy games. For completeness, we present their algorithm in
terms of polyhedral value iteration. Our exposition, unlike the original
algorithm, does not require edge weights to be integers and works for arbitrary
real weights.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08575"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08368">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08368">Shortest Watchman Tours in Simple Polygons under Rotated Monotone Visibility</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nilsson:Bengt_J=.html">Bengt J. Nilsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orden:David.html">David Orden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Palios:Leonidas.html">Leonidas Palios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seara:Carlos.html">Carlos Seara</a>, Paweł Żyliński <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08368">PDF</a><br /><b>Abstract: </b>We present an $O(nrG)$ time algorithm for computing and maintaining a minimum
length shortest watchman tour that sees a simple polygon under monotone
visibility in direction $\theta$, while $\theta$ varies in $[0,180^{\circ})$,
obtaining the directions for the tour to be the shortest one over all tours,
where $n$ is the number of vertices, $r$ is the number of reflex vertices, and
$G\leq r$ is the maximum number of gates of the polygon used at any time in the
algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08368"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08123">Dynamic Products of Ranks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08123">PDF</a><br /><b>Abstract: </b>We describe a data structure that can maintain a dynamic set of points given
by their Cartesian coordinates, and maintain the point whose product of ranks
within the two coordinate orderings is minimum or maximum, in time
$O(\sqrt{n\log n})$ per update.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08123"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08110">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08110">Private Approximations of a Convex Hull in Low Dimensions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Yuo Gao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheffet:Or.html">Or Sheffet</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08110">PDF</a><br /><b>Abstract: </b>We give the first differentially private algorithms that estimate a variety
of geometric features of points in the Euclidean space, such as diameter,
width, volume of convex hull, min-bounding box, min-enclosing ball etc. Our
work relies heavily on the notion of \emph{Tukey-depth}. Instead of
(non-privately) approximating the convex-hull of the given set of points $P$,
our algorithms approximate the geometric features of the $\kappa$-Tukey region
induced by $P$ (all points of Tukey-depth $\kappa$ or greater). Moreover, our
approximations are all bi-criteria: for any geometric feature $\mu$ our
$(\alpha,\Delta)$-approximation is a value "sandwiched" between
$(1-\alpha)\mu(D_P(\kappa))$ and $(1+\alpha)\mu(D_P(\kappa-\Delta))$.
</p>
<p>Our work is aimed at producing a \emph{$(\alpha,\Delta)$-kernel of
$D_P(\kappa)$}, namely a set $\calS$ such that (after a shift) it holds that
$(1-\alpha)D_P(\kappa)\subset \CH(\calS) \subset (1+\alpha)D_P(\kappa-\Delta)$.
We show that an analogous notion of a bi-critera approximation of a directional
kernel, as originally proposed by Agarwal et al~[2004], \emph{fails} to give a
kernel, and so we result to subtler notions of approximations of projections
that do yield a kernel. First, we give differentially private algorithms that
find $(\alpha,\Delta)$-kernels for a "fat" Tukey-region. Then, based on a
private approximation of the min-bounding box, we find a transformation that
does turn $D_P(\kappa)$ into a "fat" region \emph{but only if} its volume is
proportional to the volume of $D_P(\kappa-\Delta)$. Lastly, we give a novel
private algorithm that finds a depth parameter $\kappa$ for which the volume of
$D_P(\kappa)$ is comparable to $D_P(\kappa-\Delta)$. We hope this work leads to
the further study of the intersection of differential privacy and computational
geometry.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08110"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08069">Maximizing coverage while ensuring fairness: a tale of conflicting objective</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asudeh:Abolfazl.html">Abolfazl Asudeh</a>, Tanya Berger-Wolf, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/DasGupta:Bhaskar.html">Bhaskar DasGupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidiropoulos:Anastasios.html">Anastasios Sidiropoulos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08069">PDF</a><br /><b>Abstract: </b>Ensuring fairness in computational problems has emerged as a $key$ topic
during recent years, buoyed by considerations for equitable resource
distributions and social justice. It $is$ possible to incorporate fairness in
computational problems from several perspectives, such as using optimization,
game-theoretic or machine learning frameworks. In this paper we address the
problem of incorporation of fairness from a $combinatorial$ $optimization$
perspective. We formulate a combinatorial optimization framework, suitable for
analysis by researchers in approximation algorithms and related areas, that
incorporates fairness in maximum coverage problems as an interplay between
$two$ conflicting objectives. Fairness is imposed in coverage by using coloring
constraints that $minimizes$ the discrepancies between number of elements of
different colors covered by selected sets; this is in contrast to the usual
discrepancy minimization problems studied extensively in the literature where
(usually two) colors are $not$ given $a$ $priori$ but need to be selected to
minimize the maximum color discrepancy of $each$ individual set. Our main
results are a set of randomized and deterministic approximation algorithms that
attempts to $simultaneously$ approximate both fairness and coverage in this
framework.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08069"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08068">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08068">The Swendsen-Wang Dynamics on Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanca:Antonio.html">Antonio Blanca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, Daniel Štefankovič, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08068">PDF</a><br /><b>Abstract: </b>The Swendsen-Wang algorithm is a sophisticated, widely-used Markov chain for
sampling from the Gibbs distribution for the ferromagnetic Ising and Potts
models with inverse temperature $\beta&gt;0$. Due to the global nature of the
updates of the Swendsen-Wang algorithm, the underlying Markov chain often mixes
rapidly in the low temperature region (large $\beta$) where long-range
correlations impair the convergence rate of local chains such as the Glauber
dynamics. With few exceptions, tight bounds on the convergence rate of the
Swendsen-Wang algorithm only hold for high temperature regions (small $\beta$)
corresponding to the uniqueness or the decay of correlations region.
</p>
<p>We present tight bounds on the convergence rate of the Swendsen-Wang
algorithm for the complete $d$-ary tree that extend to the non-uniqueness
region. Specifically, we show that a spatial mixing property known as the
Variance Mixing condition introduced by Martinelli et al. (2004) implies
constant spectral gap of the Swendsen-Wang dynamics. This implies that the
relaxation time (i.e., the inverse of the spectral gap) is $O(1)$ for all
boundary conditions in the uniqueness region or when $\beta&lt;\beta_1$ where
$\beta_1$ exceeds the uniqueness threshold for the Ising model and for the
$q$-state Potts model when $q$ is small with respect to $d$. In addition, we
prove $O(1)$ relaxation time for all $\beta$ for the monochromatic boundary
condition. Our proof introduces a novel spectral view of the Variance Mixing
condition inspired by several recent rapid mixing results on high-dimensional
expanders.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08068"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08031">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08031">New Nearly-Optimal Coreset for Kernel Density Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tai:Wai_Ming.html">Wai Ming Tai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08031">PDF</a><br /><b>Abstract: </b>Given a point set $P\subset \mathbb{R}^d$, kernel density estimation for
Gaussian kernel is defined as $\overline{\mathcal{G}}_P(x) =
\frac{1}{\left|P\right|}\sum_{p\in P}e^{-\left\lVert x-p \right\rVert^2}$ for
any $x\in\mathbb{R}^d$. We study how to construct a small subset $Q$ of $P$
such that the kernel density estimation of $P$ can be approximated by the
kernel density estimation of $Q$. This subset $Q$ is called \emph{coreset}. The
primary technique in this work is to construct $\pm 1$ coloring on the point
set $P$ by the discrepancy theory and apply this coloring algorithm
recursively. Our result leverages Banaszczyk's Theorem. When $d&gt;1$ is constant,
our construction gives a coreset of size
$O\left(\frac{1}{\varepsilon}\sqrt{\log\log\frac{1}{\varepsilon}}\right)$ as
opposed to the best-known result of
$O\left(\frac{1}{\varepsilon}\sqrt{\log\frac{1}{\varepsilon}}\right)$. It is
the first to give a breakthrough on the barrier of $\sqrt{\log}$ factor even
when $d=2$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08031"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07994">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07994">Approximating the (continuous) Fr\'echet distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Connor Colombe, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fox:Kyle.html">Kyle Fox</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07994">PDF</a><br /><b>Abstract: </b>We describe the first strongly subquadratic time algorithm with
subexponential approximation ratio for approximately computing the Fr\'echet
distance between two polygonal chains. Specifically, let $P$ and $Q$ be two
polygonal chains with $n$ vertices in $d$-dimensional Euclidean space, and let
$\alpha \in [\sqrt{n}, n]$. Our algorithm deterministically finds an
$O(\alpha)$-approximate Fr\'echet correspondence in time $O((n^3 / \alpha^2)
\log n)$. In particular, we get an $O(n)$-approximation in near-linear $O(n
\log n)$ time, a vast improvement over the previously best know result, a
linear time $2^{O(n)}$-approximation. As part of our algorithm, we also
describe how to turn any approximate decision procedure for the Fr\'echet
distance into an approximate optimization algorithm whose approximation ratio
is the same up to arbitrarily small constant factors. The transformation into
an approximate optimization algorithm increases the running time of the
decision procedure by only an $O(\log n)$ factor.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07994"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07983">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07983">Optimal angle bounds for quadrilateral meshes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bishop:Christopher_J=.html">Christopher J. Bishop</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07983">PDF</a><br /><b>Abstract: </b>We show that any simple planar n-gon can be meshed in linear time by $O(n)$
quadrilaterals with all new angles bounded between $60$ and $120$ degrees.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07983"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07927">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07927">How to Morph Graphs on the Torus</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chambers:Erin_Wolf.html">Erin Wolf Chambers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erickson:Jeff.html">Jeff Erickson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Patrick.html">Patrick Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parsa:Salman.html">Salman Parsa</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07927">PDF</a><br /><b>Abstract: </b>We present the first algorithm to morph graphs on the torus. Given two
isotopic essentially 3-connected embeddings of the same graph on the Euclidean
flat torus, where the edges in both drawings are geodesics, our algorithm
computes a continuous deformation from one drawing to the other, such that all
edges are geodesics at all times. Previously even the existence of such a morph
was not known. Our algorithm runs in $O(n^{1+\omega/2})$ time, where $\omega$
is the matrix multiplication exponent, and the computed morph consists of
$O(n)$ parallel linear morphing steps. Existing techniques for morphing planar
straight-line graphs do not immediately generalize to graphs on the torus; in
particular, Cairns' original 1944 proof and its more recent improvements rely
on the fact that every planar graph contains a vertex of degree at most 5. Our
proof relies on a subtle geometric analysis of 6-regular triangulations of the
torus. We also make heavy use of a natural extension of Tutte's spring
embedding theorem to torus graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07927"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07720">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07720">An $\tilde{O}(n^{5/4})$ Time $\varepsilon$-Approximation Algorithm for RMS Matching in a Plane</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lahn:Nathaniel.html">Nathaniel Lahn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raghvendra:Sharath.html">Sharath Raghvendra</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07720">PDF</a><br /><b>Abstract: </b>The 2-Wasserstein distance (or RMS distance) is a useful measure of
similarity between probability distributions that has exciting applications in
machine learning. For discrete distributions, the problem of computing this
distance can be expressed in terms of finding a minimum-cost perfect matching
on a complete bipartite graph given by two multisets of points $A,B \subset
\mathbb{R}^2$, with $|A|=|B|=n$, where the ground distance between any two
points is the squared Euclidean distance between them. Although there is a
near-linear time relative $\varepsilon$-approximation algorithm for the case
where the ground distance is Euclidean (Sharathkumar and Agarwal, JACM 2020),
all existing relative $\varepsilon$-approximation algorithms for the RMS
distance take $\Omega(n^{3/2})$ time. This is primarily because, unlike
Euclidean distance, squared Euclidean distance is not a metric. In this paper,
for the RMS distance, we present a new $\varepsilon$-approximation algorithm
that runs in $O(n^{5/4}\mathrm{poly}\{\log n,1/\varepsilon\})$ time.
</p>
<p>Our algorithm is inspired by a recent approach for finding a minimum-cost
perfect matching in bipartite planar graphs (Asathulla et al., TALG 2020).
Their algorithm depends heavily on the existence of sub-linear sized vertex
separators as well as shortest path data structures that require planarity.
Surprisingly, we are able to design a similar algorithm for a complete
geometric graph that is far from planar and does not have any vertex
separators. Central components of our algorithm include a quadtree-based
distance that approximates the squared Euclidean distance and a data structure
that supports both Hungarian search and augmentation in sub-linear time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07720"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2418581440113974615">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html">Erdos-Turan for k=3 is True!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
(All of the math in this post is summarized (without proofs) in a writeup by Erik Metz and myself which you can find <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/3apblog.pdf">here</a>. It is a pdf file so you can click on links in it to get to the papers it refers to. There have been posts on this topic by <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Gil Kalai</a> and  <a href="https://lucatrevisan.wordpress.com/2020/07/08/silver-linings/">Luca Trevisan</a>. If you know of others then let me know so I can add them to this post.)<br />
<br />
<br />
<br />
This is a sequel to <a href="https://blog.computationalcomplexity.org/2010/12/breakthrough-result-on-density-and-3.html">A BREAKTHROUGH result on density and 3-AP's</a> and <a href="https://blog.computationalcomplexity.org/2017/06/big-news-on-w3r.html">Big news on W(3,r)!</a><br />
<br />
For this post N is large, and all inequalites have a big-O or a big-Omega.<br />
<br />
For this post [N] is {1,...,N}<br />
<br />
Let<br />
<br />
r(N) be the least w such that if A is a subset of [N] and |A|  &gt;  w, then A has a 3-AP.<br />
<br />
There has been a long sequence of results getting smaller and smaller upper bounds on r(N).<br />
<br />
The motivation for getting these results is that if r(N) is &lt; N/(log N)^{1+\delta} with delta&gt;0 then the following holds:<br />
<br />
If sum_{x\in A} 1/x diverges then A has a 3-AP.<br />
<br />
This is the k=3 case of one of the Erdos-Turan Conjectures.<br />
<br />
Bloom and Sisack HAVE gotten N/(log N)^{1+delta} so they HAVE gotten ET k=3. Wow!<br />
<br />
1) I am NOT surprised that its true.<br />
<br />
2) I am SHOCKED and DELIGHTED that it was proven.  Shocked because the results leading up to it (see the write up referenced at the beginning of this post) seemed Zeno-like, approaching the result needed got but not getting there. Delighted because... uh, as the kids say, just cause.<br />
<br />
I've heard that k=4 really is much harder (see my comments and Gil's response on his blog post, pointed to at the beginning of this post)  and it is true that there has been far less progress on that case (the write up I pointed to at the beginning of this post says what is known). Hence I will again be <i>shocked </i>if it is proven.  So, unlike The Who (see <a href="https://www.youtube.com/watch?v=UDfAdHBtK_Q">here</a>) I CAN be fooled again. That's okay--- I will  be <i>delighted</i>.<br />
<br />
Erdos offered a prize of $3000 for a proof that A has, for all k, a k-AP.  The prize is now $5000. After Erdos passed away Ronald Graham became the Erdos-Bank and paid out the money when people solved a problem Erdos put a bounty on. What happens now? (If I have the facts wrong and/or if you know the answer, please leave a polite and enlightening comment.)<br />
<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html"><span class="datestr">at July 19, 2020 07:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/109">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/109">TR20-109 |  On Testing Hamiltonicity in the Bounded Degree Graph Model | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that testing Hamiltonicity in the bounded-degree graph model requires a linear number of queries. This refers to both the path and the cycle versions of the problem, and similar results hold also for the directed analogues.
In addition, we present an alternative proof for the known fact that testing Independent Set Size (in this model) requires a linear number of queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/109"><span class="datestr">at July 19, 2020 03:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/108">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/108">TR20-108 |  Query Complexity of Global Minimum Cut | 

	Arijit Bishnu, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we resolve the query complexity of global minimum cut problem for a graph by designing a randomized algorithm for approximating the size of minimum cut in a graph, where the graph can be accessed through local queries like \textsc{Degree}, \textsc{Neighbor}, and \textsc{Adjacency} queries.

Given $\epsilon \in (0,1)$, the algorithm with high probability outputs an estimate $\hat{t}$ satisfying the following $(1-\epsilon) t \leq \hat{t} \leq (1+\epsilon) t$, where $m$ is the number of edges in the graph and $t$ is the size of minimum cut in the graph. The expected number of local queries used by our algorithm is $\min\left\{m+n,\frac{m}{t}\right\}\mbox{poly}\left(\log n,\frac{1}{\epsilon}\right)$ where $n$ is the number of vertices in the graph. Eden and Rosenbaum showed that $\Omega(m/t)$ many local queries are required for approximating the size of minimum cut in graphs. These two results together resolve the query complexity of the problem of estimating the size of minimum cut in graphs using local queries.

Building on the lower bound of Eden and Rosenbaum, we show that, for all $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to decide if the size of the minimum cut in the graph is $t$ or $t-2$. Also, we show that, for any $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to find all the minimum cut edges even if it is promised that the input graph has a minimum cut of size $t$. Both of our lower bound results are randomized, and hold even if we can make \textsc{Random Edge} query apart from local queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/108"><span class="datestr">at July 19, 2020 01:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/107">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/107">TR20-107 |  Testing linear inequalities of subgraph statistics | 

	Lior Gishboliner, 

	Asaf Shapira, 

	Henrique Stagni</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Property testers are fast randomized algorithms whose task is to distinguish between inputs satisfying some predetermined property ${\cal P}$ and those that are far from satisfying it. Since these algorithms operate by inspecting a small randomly selected portion of the input, the most natural property one would like to be able to test is whether the input does not contain certain forbidden small substructures. In the setting of graphs, such a result was obtained by Alon et al., who proved that for any finite family of graphs ${\cal F}$, the property of being induced ${\cal F}$-free (i.e. not containing an induced copy of any $F \in {\cal F}$) is testable.

It is natural to ask if one can go one step further and prove that more elaborate properties involving induced subgraphs are also testable. One such generalization of the result of Alon et al. was formulated by Goldreich and Shinkar who conjectured that for any finite family of graphs ${\cal F}$, and any linear inequality involving the densities of the graphs $F \in {\cal F}$ in the input graph,
the property of satisfying this inequality can be tested in a certain restricted model of graph property testing. Our main result in this paper disproves this conjecture in the following strong form: some properties of this type are not testable even in the classical (i.e. unrestricted) model of graph property testing.

The proof deviates significantly from prior non-testability results in this area. The main idea is to use a linear inequality relating induced subgraph densities in order to encode the property of being a quasirandom graph.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/107"><span class="datestr">at July 19, 2020 01:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08401">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08401">Optimal Vertex Fault-Tolerant Spanners in Polynomial Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodwin:Greg.html">Greg Bodwin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinitz:Michael.html">Michael Dinitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Robelle:Caleb.html">Caleb Robelle</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08401">PDF</a><br /><b>Abstract: </b>Recent work has pinned down the existentially optimal size bounds for vertex
fault-tolerant spanners: for any positive integer $k$, every $n$-node graph has
a $(2k-1)$-spanner on $O(f^{1-1/k} n^{1+1/k})$ edges resilient to $f$ vertex
faults, and there are examples of input graphs on which this bound cannot be
improved. However, these proofs work by analyzing the output spanner of a
certain exponential-time greedy algorithm. In this work, we give the first
algorithm that produces vertex fault tolerant spanners of optimal size and
which runs in polynomial time. Specifically, we give a randomized algorithm
which takes $\widetilde{O}\left( f^{1-1/k} n^{2+1/k} + mf^2\right)$ time. We
also derandomize our algorithm to give a deterministic algorithm with similar
bounds. This reflects an exponential improvement in runtime over [Bodwin-Patel
PODC '19], the only previously known algorithm for constructing optimal vertex
fault-tolerant spanners.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08401"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.08357">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.08357">Substring Complexity in Sublinear Space</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bernardini:Giulia.html">Giulia Bernardini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fici:Gabriele.html">Gabriele Fici</a>, Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pissis:Solon_P=.html">Solon P. Pissis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08357">PDF</a><br /><b>Abstract: </b>Shannon's entropy is a definitive lower bound for statistical compression.
Unfortunately, no such clear measure exists for the compressibility of
repetitive strings. Thus, ad-hoc measures are employed to estimate the
repetitiveness of strings, e.g., the size $z$ of the Lempel-Ziv parse or the
number $r$ of equal-letter runs of the Burrows-Wheeler transform. A more recent
one is the size $\gamma$ of a smallest string attractor. Unfortunately, Kempa
and Prezza [STOC 2018] showed that computing $\gamma$ is NP-hard. Kociumaka et
al. [LATIN 2020] considered a new measure that is based on the function $S_T$
counting the cardinalities of the sets of substrings of each length of $T$,
also known as the substring complexity. This new measure is defined as $\delta=
\sup\{S_T(k)/k, k\geq 1\}$ and lower bounds all the measures previously
considered. In particular, $\delta\leq \gamma$ always holds and $\delta$ can be
computed in $\mathcal{O}(n)$ time using $\Omega(n)$ working space. Kociumaka et
al. showed that if $\delta$ is given, one can construct an $\mathcal{O}(\delta
\log \frac{n}{\delta})$-sized representation of $T$ supporting efficient direct
access and efficient pattern matching queries on $T$. Given that for highly
compressible strings, $\delta$ is significantly smaller than $n$, it is natural
to pose the following question: Can we compute $\delta$ efficiently using
sublinear working space?
</p>
<p>It is straightforward to show that any algorithm computing $\delta$ using
$\mathcal{O}(b)$ space requires $\Omega(n^{2-o(1)}/b)$ time through a reduction
from the element distinctness problem [Yao, SIAM J. Comput. 1994]. We present
the following results: an $\mathcal{O}(n^3/b^2)$-time and
$\mathcal{O}(b)$-space algorithm to compute $\delta$, for any $b\in[1,n]$; and
an $\tilde{\mathcal{O}}(n^2/b)$-time and $\mathcal{O}(b)$-space algorithm to
compute $\delta$, for any $b\in[n^{2/3},n]$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.08357"><span class="datestr">at July 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
