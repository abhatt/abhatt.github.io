<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="https://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="no data">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://scottaaronson.blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 17, 2022 06:39 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=341">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2022/06/17/guest-post-colt-2022-call-for-open-problems/">Guest post: COLT 2022 Call for Open Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The tireless <a href="https://ccanonne.github.io/">Clément Canonne</a> is the open problem chair for COLT 2022. He asked to share this call for open problems. Please submit your best!</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p><a href="https://learningtheory.org/colt2022/index.html">The 35th Annual Conference on Learning Theory</a> (COLT 2022), to be held in London on July 2-5 and remotely, will follow in the footsteps of previous editions and feature an <em>Open Problems session</em>, where attendees can present their open problems and suggest them to the learning community — and possibly offer prizes for their resolution! (After all, a little incentive goes a long way…)</p>



<p>The deadline to submit an open problem has been extended to <em>Monday June 20, 4pm PDT.</em> If you have any nagging question or stubborn problem, please submit them!</p>



<p>More information and CfP: <a href="https://learningtheory.org/colt2022/cfp.html#openproblems" rel="nofollow">https://learningtheory.org/colt2022/cfp.html#openproblems</a></p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2022/06/17/guest-post-colt-2022-call-for-open-problems/"><span class="datestr">at June 17, 2022 04:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8366">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2022/06/17/stocial-2022-guest-post-by-clement-canonne/">STOCial 2022: Guest post by Clément Canonne</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>[To further prove that <a href="https://windowsontheory.org/2022/05/23/why-i-am-not-a-longtermist/">I am not a longtermist</a>, here is a guest post by Clément about activities in STOC that will happen <strong>next week.</strong> –Boaz]</p>



<p>The <a href="http://acm-stoc.org/stoc2022/">54th Annual ACM Symposium on Theory of Computing</a> (STOC’22) is starting next week in Rome, as part of the broader TheoryFest. Now, while this probably is not coming as a surprise to you, did you now about the <em>social and mentoring events</em> at STOC, which, not to miss a good portmanteau when one sees one,* we shall refer henceforth as <em>STOCial’22?</em></p>



<p>Organised by <a href="https://sites.google.com/uniroma1.it/federicofusco/home">Federico Fusco</a>, <a href="https://www.cs.cornell.edu/~teganwilson/">Tegan Wilson</a>, <a href="https://sites.google.com/site/marywootters/">Mary Wootters</a>, and myself, <a href="https://sites.google.com/view/stocial-2022">STOCial’22</a> includes a bonanza of activities, games, and fun, including (but not limited to):</p>



<ul><li>a student lunch!</li><li>two senior/junior lunches!</li><li>cartoon caption contests!</li><li>a scavenger hunt! <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f9e9.png" style="height: 1em;" class="wp-smiley" alt="🧩" /></li><li>a STOC-themed crossword!</li><li>a game of socc… football! <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/26bd.png" style="height: 1em;" class="wp-smiley" alt="⚽" /></li><li>PRIZES! <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f3c6.png" style="height: 1em;" class="wp-smiley" alt="🏆" /></li></ul>



<p>To learn more about those, and sign up to the student or senior/junior lunches: <a href="https://sites.google.com/view/stocial-2022" rel="nofollow">https://sites.google.com/view/stocial-2022</a></p>



<p>See you next week!</p>



<p>Clément Canonne</p>



<p>*  If someone finds a palindrome instead, let me know. I would love a good pal in Rome.</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2022/06/17/stocial-2022-guest-post-by-clement-canonne/"><span class="datestr">at June 17, 2022 02:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=22882">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2022/06/17/richard-stanley-enumerative-and-algebraic-combinatorics-in-the1960s-and-1970s/">Richard Stanley: Enumerative and Algebraic Combinatorics in the1960’s and 1970’s</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p></p>



<p>In his comment to the previous post by Igor Pak, Jow Malkevich referred us to a <a href="http://Jow Malkevich referred me to a wonderful paper by Richard Stanley on enumerative and algebraic combinatorics in the 1960's and 1970's. https://arxiv.org/abs/2105.07884">wonderful paper by Richard Stanley on enumerative and algebraic combinatorics in the 1960’s and 1970’s</a>. </p>



<p>See also this post on Richard’s memories regarding the proof of the upper bound theorem for spheres <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found</a>.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2022/06/17/richard-stanley-enumerative-and-algebraic-combinatorics-in-the1960s-and-1970s/"><span class="datestr">at June 17, 2022 05:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/2022/06/16/how-i-chose-enumerative-combinatorics/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2022/06/16/how-i-chose-enumerative-combinatorics/">Igor Pak: How I chose Enumerative Combinatorics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class="reblogger-note-content"><blockquote><p>Another great post by Igor Pak</p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img width="32" alt="" src="https://2.gravatar.com/avatar/28ad5e53cacd5f67ae8b4d80bbcff03d?s=32&amp;d=identicon&amp;r=PG" class="avatar avatar-32" height="32" /><a href="https://igorpak.wordpress.com/2022/06/12/how-i-chose-enumerative-combinatorics/">Igor Pak's blog</a></p><div class="reblogged-content">
<p></p>

<p>Apologies for not writing anything for awhile.  After <a href="https://en.wikipedia.org/wiki/2022_Russian_invasion_of_Ukraine">Feb 24</a>, the <em>math </em>part of the “<em></em>” slogan lost a bit of relevance, while the actual events were stupefying to the point when I had nothing to say about the <em>life </em>part.  Now that the shock subsided, let me break the silence by telling an old personal story  which is neither relevant to anything happening right now nor a lesson to anyone.  Sometimes a story is just a story… </p>

<p></p>

<p></p>

<h4>My field</h4>

<p></p>

<p></p>

<p>As the readers of this blog know, I am a <em><strong></strong></em>.  Not a “proud one”.  Just “a combinatorialist”.  To paraphrase a <a href="https://en.wikipedia.org/wiki/Rifleman%27s_Creed">military slogan</a> “there are many fields like this one, but this one is mine”.  While I’ve been <a href="https://wp.me/p211iQ-ds">defending</a> my field <a href="https://wp.me/p211iQ-sq">for years</a>, writing about <a href="https://wp.me/p211iQ-ds">its struggles</a>, and often <a href="https://wp.me/p211iQ-bQ">defining it</a>, it’s not because this field is more important than others. Rather, because it’s so…</p>
</div><p class="reblog-source"><a href="https://igorpak.wordpress.com/2022/06/12/how-i-chose-enumerative-combinatorics/">View original post</a> <span class="more-words">1,095 more words</span></p></div></div></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2022/06/16/how-i-chose-enumerative-combinatorics/"><span class="datestr">at June 16, 2022 11:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07672">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07672">Reconstructing Ultrametric Trees from Noisy Experiments</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arunachaleswaran:Eshwar_Ram.html">Eshwar Ram Arunachaleswaran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kannan:Sampath.html">Sampath Kannan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07672">PDF</a><br /><b>Abstract: </b>The problem of reconstructing evolutionary trees or phylogenies is of great
interest in computational biology. A popular model for this problem assumes
that we are given the set of leaves (current species) of an unknown binary tree
and the results of `experiments' on triples of leaves (a,b,c), which return the
pair with the deepest least common ancestor. If the tree is assumed to be an
ultrametric (i.e., all root-leaf paths have the same length), the experiment
can be equivalently seen to return the closest pair of leaves. In this model,
efficient algorithms are known for tree reconstruction.
</p>
<p>In reality, since the data on which these `experiments' are run is itself
generated by the stochastic process of evolution, these experiments are noisy.
In all reasonable models of evolution, if the branches leading to the leaves in
a triple separate from each other at common ancestors that are very close to
each other in the tree, the result of the experiment should be close to
uniformly random. Motivated by this, we consider a model where the noise on any
triple is just dependent on the three pairwise distances (referred to as
distance based noise).
</p>
<p>Our results are the following: 1. Suppose the length of every edge in the
unknown tree is at least $\tilde{O}(\frac{1}{\sqrt n})$ fraction of the length
of a root-leaf path. Then, we give an efficient algorithm to reconstruct the
topology of the tree for a broad family of distance-based noise models.
Further, we show that if the edges are asymptotically shorter, then topology
reconstruction is information-theoretically impossible.
</p>
<p>2. Further, for a specific distance-based noise model--which we refer to as
the homogeneous noise model--we show that the edge weights can also be
approximately reconstructed under the same quantitative lower bound on the edge
lengths.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07672"><span class="datestr">at June 16, 2022 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07640">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07640">Statistical and Computational Phase Transitions in Group Testing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coja=Oghlan:Amin.html">Amin Coja-Oghlan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gebhard:Oliver.html">Oliver Gebhard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hahn=Klimroth:Max.html">Max Hahn-Klimroth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadik:Ilias.html">Ilias Zadik</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07640">PDF</a><br /><b>Abstract: </b>We study the group testing problem where the goal is to identify a set of k
infected individuals carrying a rare disease within a population of size n,
based on the outcomes of pooled tests which return positive whenever there is
at least one infected individual in the tested group. We consider two different
simple random procedures for assigning individuals to tests: the
constant-column design and Bernoulli design. Our first set of results concerns
the fundamental statistical limits. For the constant-column design, we give a
new information-theoretic lower bound which implies that the proportion of
correctly identifiable infected individuals undergoes a sharp "all-or-nothing"
phase transition when the number of tests crosses a particular threshold. For
the Bernoulli design, we determine the precise number of tests required to
solve the associated detection problem (where the goal is to distinguish
between a group testing instance and pure noise), improving both the upper and
lower bounds of Truong, Aldridge, and Scarlett (2020). For both group testing
models, we also study the power of computationally efficient (polynomial-time)
inference procedures. We determine the precise number of tests required for the
class of low-degree polynomial algorithms to solve the detection problem. This
provides evidence for an inherent computational-statistical gap in both the
detection and recovery problems at small sparsity levels. Notably, our evidence
is contrary to that of Iliopoulos and Zadik (2021), who predicted the absence
of a computational-statistical gap in the Bernoulli design.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07640"><span class="datestr">at June 16, 2022 11:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07633">Sublinear Algorithms for Hierarchical Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Arpit.html">Arpit Agarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Huan.html">Huan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patil:Prathamesh.html">Prathamesh Patil</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07633">PDF</a><br /><b>Abstract: </b>Hierarchical clustering over graphs is a fundamental task in data mining and
machine learning with applications in domains such as phylogenetics, social
network analysis, and information retrieval. Specifically, we consider the
recently popularized objective function for hierarchical clustering due to
Dasgupta. Previous algorithms for (approximately) minimizing this objective
function require linear time/space complexity. In many applications the
underlying graph can be massive in size making it computationally challenging
to process the graph even using a linear time/space algorithm. As a result,
there is a strong interest in designing algorithms that can perform global
computation using only sublinear resources. The focus of this work is to study
hierarchical clustering for massive graphs under three well-studied models of
sublinear computation which focus on space, time, and communication,
respectively, as the primary resources to optimize: (1) (dynamic) streaming
model where edges are presented as a stream, (2) query model where the graph is
queried using neighbor and degree queries, (3) MPC model where the graph edges
are partitioned over several machines connected via a communication channel.
</p>
<p>We design sublinear algorithms for hierarchical clustering in all three
models above. At the heart of our algorithmic results is a view of the
objective in terms of cuts in the graph, which allows us to use a relaxed
notion of cut sparsifiers to do hierarchical clustering while introducing only
a small distortion in the objective function. Our main algorithmic
contributions are then to show how cut sparsifiers of the desired form can be
efficiently constructed in the query model and the MPC model. We complement our
algorithmic results by establishing nearly matching lower bounds that rule out
the possibility of designing better algorithms in each of these models.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07633"><span class="datestr">at June 16, 2022 10:58 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07592">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07592">In-Range Farthest Point Queries and Related Problem in High Dimensions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Ziyun.html">Ziyun Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jinhui.html">Jinhui Xu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07592">PDF</a><br /><b>Abstract: </b>Range-aggregate query is an important type of queries with numerous
applications. It aims to obtain some structural information (defined by an
aggregate function $F(\cdot)$) of the points (from a point set $P$) inside a
given query range $B$. In this paper, we study the range-aggregate query
problem in high dimensional space for two aggregate functions: (1) $F(P \cap
B)$ is the farthest point in $P \cap B$ to a query point $q$ in $\mathbb{R}^d$
and (2) $F(P \cap B)$ is the minimum enclosing ball (MEB) of $P \cap B$. For
problem (1), called In-Range Farthest Point (IFP) Query, we develop a
bi-criteria approximation scheme: For any $\epsilon&gt;0$ that specifies the
approximation ratio of the farthest distance and any $\gamma&gt;0$ that measures
the "fuzziness" of the query range, we show that it is possible to pre-process
$P$ into a data structure of size $\tilde{O}_{\epsilon,\gamma}(dn^{1+\rho})$ in
$\tilde{O}_{\epsilon,\gamma}(dn^{1+\rho})$ time such that given any
$\mathbb{R}^d$ query ball $B$ and query point $q$, it outputs in
$\tilde{O}_{\epsilon,\gamma}(dn^{\rho})$ time a point $p$ that is a
$(1-\epsilon)$-approximation of the farthest point to $q$ among all points
lying in a $(1+\gamma)$-expansion $B(1+\gamma)$ of $B$, where $0&lt;\rho&lt;1$ is a
constant depending on $\epsilon$ and $\gamma$ and the hidden constants in big-O
notations depend only on $\epsilon$, $\gamma$ and $\text{Polylog}(nd)$. For
problem (2), we show that the IFP result can be applied to develop query scheme
with similar time and space complexities to achieve a
$(1+\epsilon)$-approximation for MEB.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07592"><span class="datestr">at June 16, 2022 11:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07571">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07571">Efficient decoding up to a constant fraction of the code length for asymptotically good quantum codes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leverrier:Anthony.html">Anthony Leverrier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Z=eacute=mor:Gilles.html">Gilles Zémor</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07571">PDF</a><br /><b>Abstract: </b>We introduce and analyse an efficient decoder for the quantum Tanner codes of
that can correct adversarial errors of linear weight. Previous decoders for
quantum low-density parity-check codes could only handle adversarial errors of
weight $O(\sqrt{n \log n})$. We also work on the link between quantum Tanner
codes and the Lifted Product codes of Panteleev and Kalachev, and show that our
decoder can be adapted to the latter. The decoding algorithm alternates between
sequential and parallel procedures and converges in linear time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07571"><span class="datestr">at June 16, 2022 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07554">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07554">Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and Space Lower Bounds</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Assadi:Sepehr.html">Sepehr Assadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatziafratis:Vaggos.html">Vaggos Chatziafratis</a>, Jakub Łącki, Vahab Mirrokni, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chen.html">Chen Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07554">PDF</a><br /><b>Abstract: </b>The Hierarchical Clustering (HC) problem consists of building a hierarchy of
clusters to represent a given dataset. Motivated by the modern large-scale
applications, we study the problem in the \streaming model, in which the memory
is heavily limited and only a single or very few passes over the input are
allowed. Specifically, we investigate whether a good hierarchical clustering
can be obtained, or at least whether we can approximately estimate the value of
the optimal hierarchy. To measure the quality of a hierarchy, we use the HC
minimization objective introduced by Dasgupta. Assuming that the input is an
$n$-vertex weighted graph whose edges arrive in a stream, we derive the
following results on space-vs-accuracy tradeoffs:
</p>
<p>* With $O(n\cdot \text{polylog}\,{n})$ space, we develop a single-pass
algorithm, whose approximation ratio matches the currently best offline
algorithm.
</p>
<p>* When the space is more limited, namely, $n^{1-o(1)}$, we prove that no
algorithm can even estimate the value of optimum HC tree to within an
$o(\frac{\log{n}}{\log\log{n}})$ factor, even when allowed
$\text{polylog}{\,{n}}$ passes over the input.
</p>
<p>* In the most stringent setting of $\text{polylog}\,{n}$ space, we rule out
algorithms that can even distinguish between "highly"-vs-"poorly" clusterable
graphs, namely, graphs that have an $n^{1/2-o(1)}$ factor gap between their HC
objective value.
</p>
<p>* Finally, we prove that any single-pass streaming algorithm that computes an
optimal HC tree requires to store almost the entire input even if allowed
exponential time.
</p>
<p>Our algorithmic results establish a general structural result that proves
that cut sparsifiers of input graph can preserve cost of "balanced" HC trees to
within a constant factor. Our lower bound results include a new streaming lower
bound for a novel problem "One-vs-Many-Expanders", which can be of independent
interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07554"><span class="datestr">at June 16, 2022 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07553">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07553">On the fast convergence of minibatch heavy ball momentum</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bollapragada:Raghu.html">Raghu Bollapragada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Tyler.html">Tyler Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Ward:Rachel.html">Rachel Ward</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07553">PDF</a><br /><b>Abstract: </b>Simple stochastic momentum methods are widely used in machine learning
optimization, but their good practical performance is at odds with an absence
of theoretical guarantees of acceleration in the literature. In this work, we
aim to close the gap between theory and practice by showing that stochastic
heavy ball momentum, which can be interpreted as a randomized Kaczmarz
algorithm with momentum, retains the fast linear rate of (deterministic) heavy
ball momentum on quadratic optimization problems, at least when minibatching
with a sufficiently large batch size is used. The analysis relies on carefully
decomposing the momentum transition matrix, and using new spectral norm
concentration bounds for products of independent random matrices. We provide
numerical experiments to demonstrate that our bounds are reasonably sharp.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07553"><span class="datestr">at June 16, 2022 11:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07503">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07503">Balanced Allocations with the Choice of Noise</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Los:Dimitrios.html">Dimitrios Los</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sauerwald:Thomas.html">Thomas Sauerwald</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07503">PDF</a><br /><b>Abstract: </b>We consider the allocation of $m$ balls (jobs) into $n$ bins (servers). In
the standard Two-Choice process, at each step $t=1,2,\ldots,m$ we first sample
two randomly chosen bins, compare their two loads and then place a ball in the
least loaded bin. It is well-known that for any $m \geq n$, this results in a
gap (difference between the maximum and average load) of $\log_2 \log n +
\Theta(1)$ (with high probability).
</p>
<p>In this work, we consider Two-Choice in different models with noisy load
comparisons. One key model involves an adaptive adversary whose power is
limited by some threshold $g \in \mathbb{N}$. In each round, such adversary can
determine the result of any load comparison between two bins whose loads differ
by at most $g$, while if the load difference is greater than $g$, the
comparison is correct.
</p>
<p>For this adversarial model, we first prove that for any $m \geq n$ the gap is
$O(g+\log n)$ with high probability. Then through a refined analysis we prove
that if $g \leq \log n$, then for any $m \geq n$ the gap is $O(\frac{g}{\log g}
\cdot \log \log n)$. For constant values of $g$, this generalizes the heavily
loaded analysis of [BCSV06, TW14] for the Two-Choice process, and establishes
that asymptotically the same gap bound holds even if many (or possibly all)
load comparisons among "similarly loaded" bins are wrong. Finally, we
complement these upper bounds with tight lower bounds, which establishes an
interesting phase transition on how the parameter $g$ impacts the gap.
</p>
<p>We also apply a similar analysis to other noise models, including ones where
bins only update their load information with delay. For example, for the model
of [BCEFN12] where balls are allocated in consecutive batches of size $n$, we
present an improved and tight gap bound of $\Theta(\log n/ \log \log n )$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07503"><span class="datestr">at June 16, 2022 11:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07496">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07496">Normalization, Square Roots, and the Exponential and Logarithmic Maps in Geometric Algebras of Less than 6D</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keninck:Steven_De.html">Steven De Keninck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roelfs:Martin.html">Martin Roelfs</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07496">PDF</a><br /><b>Abstract: </b>Geometric algebras of dimension $n &lt; 6$ are becoming increasingly popular for
the modeling of 3D and 3+1D geometry. With this increased popularity comes the
need for efficient algorithms for common operations such as normalization,
square roots, and exponential and logarithmic maps. The current work presents a
signature agnostic analysis of these common operations in all geometric
algebras of dimension $n &lt; 6$, and gives efficient numerical implementations in
the most popular algebras $\mathbb{R}_{4}$, $\mathbb{R}_{3,1}$,
$\mathbb{R}_{3,0,1}$ and $\mathbb{R}_{4,1}$, in the hopes of lowering the
threshold for adoption of geometric algebra solutions by code maintainers.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07496"><span class="datestr">at June 16, 2022 11:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07416">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07416">Mutual Visibility by Fat Robots with Slim Omnidirectional Camera</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bose:Kaustav.html">Kaustav Bose</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Abhinav.html">Abhinav Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyaya:Krishnendu.html">Krishnendu Mukhopadhyaya</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07416">PDF</a><br /><b>Abstract: </b>In the existing literature of the Mutual Visibility problem for autonomous
robot swarms, the adopted visibility models have some idealistic assumptions
that are not consistent with practical sensing device implementations. This
paper investigates the problem in the more realistic visibility model called
opaque fat robots with slim omnidirectional camera. The robots are modeled as
unit disks, each having an omnidirectional camera represented as a disk of
smaller size. We assume that the robots have compasses that allow agreement in
the direction and orientation of both axes of their local coordinate systems.
The robots are equipped with visible lights which serve as a medium of
communication and also as a form of memory. We present a distributed algorithm
for the Mutual Visibility problem which is provably correct in the
semi-synchronous setting. Our algorithm also provides a solution for Leader
Election which we use as a subroutine in our main algorithm. Although Leader
Election is trivial with two axis agreement in the full visibility model, it is
challenging in our case and is of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07416"><span class="datestr">at June 16, 2022 11:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07358">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07358">The Complexity of Contracting Bipartite Graphs into Small Cycles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>R. Krithika, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Roohani.html">Roohani Sharma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07358">PDF</a><br /><b>Abstract: </b>For a positive integer $\ell \geq 3$, the $C_\ell$-Contractibility problem
takes as input an undirected simple graph $G$ and determines whether $G$ can be
transformed into a graph isomorphic to $C_\ell$ (the induced cycle on $\ell$
vertices) using only edge contractions. Brouwer and Veldman [JGT 1987] showed
that $C_4$-Contractibility is NP-complete in general graphs. It is easy to
verify that $C_3$-Contractibility is polynomial-time solvable. Dabrowski and
Paulusma [IPL 2017] showed that $C_{\ell}$-Contractibility is \NP-complete\ on
bipartite graphs for $\ell = 6$ and posed as open problems the status of the
problem when $\ell$ is 4 or 5. In this paper, we show that both
$C_5$-Contractibility and $C_4$-Contractibility are NP-complete on bipartite
graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07358"><span class="datestr">at June 16, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07286">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07286">Faster Decomposition of Weighted Graphs into Cliques using Fisher's Inequality</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Shweta Jain, Yo Mizutani, Blair Sullivan <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07286">PDF</a><br /><b>Abstract: </b>Mining groups of genes that consistently co-express is an important problem
in biomedical research, where it is critical for applications such as
drug-repositioning and designing new disease treatments. Recently, Cooley et
al. modeled this problem as Exact Weighted Clique Decomposition (EWCD) in
which, given an edge-weighted graph $G$ and a positive integer $k$, the goal is
to decompose $G$ into at most $k$ (overlapping) weighted cliques so that an
edge's weight is exactly equal to the sum of weights for cliques it
participates in. They show EWCD is fixed-parameter-tractable, giving a
$4^k$-kernel alongside a backtracking algorithm (together called cricca) to
iteratively build a decomposition. Unfortunately, because of inherent
exponential growth in the space of potential solutions, cricca is typically
able to decompose graphs only when $k \leq 11$.
</p>
<p>In this work, we establish reduction rules that exponentially decrease the
size of the kernel (from $4^k$ to $k2^k$) for EWCD. In addition, we use
insights about the structure of potential solutions to give new search rules
that speed up the decomposition algorithm. At the core of our techniques is a
result from combinatorial design theory called Fisher's inequality
characterizing set systems with restricted intersections. We deploy our
kernelization and decomposition algorithms (together called DeCAF) on a corpus
of biologically-inspired data and obtain over two orders of magnitude speed-up
over cricca. As a result, DeCAF scales to instances with $k \geq 17$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07286"><span class="datestr">at June 16, 2022 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07250">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07250">Streaming Algorithms for Ellipsoidal Approximation of Convex Polytopes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Makarychev:Yury.html">Yury Makarychev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manoj:Naren_Sarayu.html">Naren Sarayu Manoj</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ovsiankin:Max.html">Max Ovsiankin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07250">PDF</a><br /><b>Abstract: </b>We give efficient deterministic one-pass streaming algorithms for finding an
ellipsoidal approximation of a symmetric convex polytope. The algorithms are
near-optimal in that their approximation factors differ from that of the
optimal offline solution only by a factor sub-logarithmic in the aspect ratio
of the polytope.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07250"><span class="datestr">at June 16, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07234">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07234">Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Whitehouse:Justin.html">Justin Whitehouse</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Zhiwei_Steven.html">Zhiwei Steven Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramdas:Aaditya.html">Aaditya Ramdas</a>, Ryan Rogers <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07234">PDF</a><br /><b>Abstract: </b>There is a disconnect between how researchers and practitioners handle
privacy-utility tradeoffs. Researchers primarily operate from a privacy first
perspective, setting strict privacy requirements and minimizing risk subject to
these constraints. Practitioners often desire an accuracy first perspective,
possibly satisfied with the greatest privacy they can get subject to obtaining
sufficiently small error. Ligett et al. have introduced a "noise reduction"
algorithm to address the latter perspective. The authors show that by adding
correlated Laplace noise and progressively reducing it on demand, it is
possible to produce a sequence of increasingly accurate estimates of a private
parameter while only paying a privacy cost for the least noisy iterate
released. In this work, we generalize noise reduction to the setting of
Gaussian noise, introducing the Brownian mechanism. The Brownian mechanism
works by first adding Gaussian noise of high variance corresponding to the
final point of a simulated Brownian motion. Then, at the practitioner's
discretion, noise is gradually decreased by tracing back along the Brownian
path to an earlier time. Our mechanism is more naturally applicable to the
common setting of bounded $\ell_2$-sensitivity, empirically outperforms
existing work on common statistical tasks, and provides customizable control of
privacy loss over the entire interaction with the practitioner. We complement
our Brownian mechanism with ReducedAboveThreshold, a generalization of the
classical AboveThreshold algorithm that provides adaptive privacy guarantees.
Overall, our results demonstrate that one can meet utility constraints while
still maintaining strong levels of privacy.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07234"><span class="datestr">at June 16, 2022 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07209">On Approximating Total Variation Distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Arnab Bhattacharyya, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gayen:Sutanu.html">Sutanu Gayen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meel:Kuldeep_S=.html">Kuldeep S. Meel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Myrisiotis:Dimitrios.html">Dimitrios Myrisiotis</a>, A. Pavan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinodchandran:N=_V=.html">N. V. Vinodchandran</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07209">PDF</a><br /><b>Abstract: </b>Total variation distance (TV distance) is a fundamental notion of distance
between probability distributions. In this work, we introduce and study the
computational problem of determining the TV distance between two product
distributions over the domain $\{0,1\}^n$. We establish the following results.
</p>
<p>1. Exact computation of TV distance between two product distributions is
$\#\mathsf{P}$-complete. This is in stark contrast with other distance measures
such as KL, Chi-square, and Hellinger which tensorize over the marginals.
</p>
<p>2. Given two product distributions $P$ and $Q$ with marginals of $P$ being at
least $1/2$ and marginals of $Q$ being at most the respective marginals of $P$,
there exists a fully polynomial-time randomized approximation scheme (FPRAS)
for computing the TV distance between $P$ and $Q$. In particular, this leads to
an efficient approximation scheme for the interesting case when $P$ is an
arbitrary product distribution and $Q$ is the uniform distribution.
</p>
<p>We pose the question of characterizing the complexity of approximating the TV
distance between two arbitrary product distributions as a basic open problem in
computational statistics.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07209"><span class="datestr">at June 16, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07172">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07172">Parameterized Complexity Results for Bayesian Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Hans Bodlaender, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Donselaar:Nils.html">Nils Donselaar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwisthout:Johan.html">Johan Kwisthout</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07172">PDF</a><br /><b>Abstract: </b>We present completeness results for inference in Bayesian networks with
respect to two different parameterizations, namely the number of variables and
the topological vertex separation number. For this we introduce the
parameterized complexity classes $\mathsf{W[1]PP}$ and $\mathsf{XLPP}$, which
relate to $\mathsf{W[1]}$ and $\mathsf{XNLP}$ respectively as $\mathsf{PP}$
does to $\mathsf{NP}$. The second parameter is intended as a natural
translation of the notion of pathwidth to the case of directed acyclic graphs,
and as such it is a stronger parameter than the more commonly considered
treewidth. Based on a recent conjecture, the completeness results for this
parameter suggest that deterministic algorithms for inference require
exponential space in terms of pathwidth and by extension treewidth. These
results are intended to contribute towards a more precise understanding of the
parameterized complexity of Bayesian inference and thus of its required
computational resources in terms of both time and space.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07172"><span class="datestr">at June 16, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2206.07052">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2206.07052">Sequential Optimization Numbers and Conjecture about Edge-Symmetry and Weight-Symmetry Shortest Weight-Constrained Path</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Zile Hui <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2206.07052">PDF</a><br /><b>Abstract: </b>This paper defines multidimensional sequential optimization numbers and prove
that the unsigned Stirling numbers of first kind are 1-dimensional sequential
optimization numbers. This paper gives a recurrence formula and an upper bound
of multidimensional sequential optimization numbers. We proof that the
k-dimensional sequential optimization numbers, denoted by O_k (n,m), are almost
in {O_k (n,a)}, where a belong to[1,eklog(n-1)+(epi)^2/6(2^k-1)+M_1], n is the
size of k-dimensional sequential optimization numbers and M_1 is large positive
integer. Many achievements of the Stirling numbers of first kind can be
transformed into the properties of k-dimensional sequential optimization
numbers by k-dimensional extension and we give some examples. Shortest
weight-constrained path is NP-complete problem [1]. In the case of edge
symmetry and weight symmetry, we use the definition of the optimization set to
design 2-dimensional Bellman-Ford algorithm to solve it. According to the fact
that P_1 (n,m&gt;M) less than or equal to e^(-M_1 ), where M=elog(n-1)+e+M_1, M_1
is a positive integer and P_1 (n,m) is the probability of 1-dimensional
sequential optimization numbers, this paper conjecture that the probability of
solving edge-symmetry and weight-symmetry shortest weight-constrained path
problem in polynomial time approaches 1 exponentially with the increase of
constant term in algorithm complexity. The results of a large number of
simulation experiments agree with this conjecture.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2206.07052"><span class="datestr">at June 16, 2022 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://bit-player.org/?p=2477">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hayes.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://bit-player.org/2022/jotto">Jotto</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://bit-player.org" title="bit-player">bit-player</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>A day or two after publishing my <a href="http://bit-player.org/2022/words-for-the-wordle-weary">TL;DR on Wordle algorithms</a>, I stumbled on a remarkable paper that neatly summarizes all the main ideas. The remarkable part is that the paper was written 50 years before Wordle was invented!</p>
<p>The paper is “<a href="https://dspace.mit.edu/handle/1721.1/6192">Information Theory and the Game of Jotto</a>,” issued in August of 1971 as Artificial Intelligence Memo No. 28 from the AI Lab at MIT. The author was Michael D. Beeler, known to me mainly as one of the three principal authors of <a href="https://dspace.mit.edu/bitstream/handle/1721.1/6086/AIM-239.pdf">HAKMEM</a> (the others were Bill Gosper and Rich Schroeppel). Beeler later worked at Bolt, Baranek, and Newman, an MIT spinoff.</p>
<p><a href="https://en.wikipedia.org/wiki/Jotto">Wikipedia</a> tells me that Jotto was invented in 1955 by Morton M. Rosenfeld as a game for two players. As in Wordle, you try to discover a secret word by submitting guess words and getting feedback about how close you have come to the target. The big difference is that JOTTO’s feedback offers only a crude measure of closeness. You learn the number of letters in your guess word that match one of the letters in the target word. You get no indication of <em>which</em> letters match, or whether they are in the correct positions.</p>
<p>The unit of measure for closeness is the jot. Beeler gives the example of playing GLASS against SMILE, which earns a closeness score of two jots, since there are matches for the letter L and for one S. Unlike the Wordle feedback rule, this scoring scheme is symmetric: The score remains the same if you switch the roles of guess and target word.</p>
<p>A defect of the game, in my view, is that you can max out the score at five jots and still not know the target word. For example, when a five-jot score tells you that the letters of the target are {A, E, G, L, R}, the word could be GLARE, LAGER, LARGE, or REGAL. Your only way to pin down the answer is to guess them in sequence.</p>
<p>Beeler’s main topic is not how the game proceeds between human players but how a computer can be programmed to take the role of a player. He reports that “A JOTTO program has existed for a couple of years at MIT’s A.I. Lab,” meaning it was created sometime in the late 1960s. He says nothing about who wrote this program. I’m going to make the wild surmise that Beeler himself might have been the author, particularly given his intimate knowledge of the program’s innards.</p>
<p>Here’s the crucial passage, lifted directly from the memo:</p>
<p><img src="http://bit-player.org/wp-content/uploads/2022/06/Beeler-block-quote-on-JOTTO.png" height="217" width="640" alt="Beeler block quote on JOTTO" border="0" class="centered" /></p>
<p>The strategy described here—maximizing the information gain from each guess—is exactly what’s recommended for Wordle. But where Wordle divvies up the potential target words into \(3^5 = 243\) subsets, the JOTTO scoring rule defines only six categories (0 through 5 jots). As a result, the maximum possible information gain is only about 2.6 bits in JOTTO, compared with almost 8 bits in Wordle. </p>
<p>Beeler also recognized a limitation of this “greedy” strategy. “It is conceivable that the test word with the highest expectation at the current point in the game has a good chance of getting us to a point where we will NOT have any particularly good test words available . . . I am indebted to Bill Gosper for pointing out this possibility; the computation required, however, is impractical, and besides, the program seems to do acceptably as is.”</p>
<p>The JOTTO program was written in the assembly language of the <a href="http://bitsavers.org/pdf/dec/_Books/Bell-ComputerEngineering.pdf">PDP-6 and PDP-10 family of machines</a> from the Digital Equipment Corporation, which were much loved in that era at MIT. (Beeler praises the instruction set as “very symmetrical, complete, powerful and easy to think in.”) But however elegant the architecture, physical resources were cramped, with a maximum memory capacity of about one megabyte. Nevertheless, Beeler found room for the program itself, for a dictionary of about 7,000 words, and for tables of precomputed responses to the first two or three guesses.</p>
<p>Humbling.</p></div>







<p class="date">
by Brian Hayes <a href="http://bit-player.org/2022/jotto"><span class="datestr">at June 15, 2022 05:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/06/15/cryptography-postdoc-at-hebrew-university-apply-by-august-31-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/06/15/cryptography-postdoc-at-hebrew-university-apply-by-august-31-2022/">Cryptography Postdoc at Hebrew University (apply by August 31, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Cryptography Group at the Hebrew University’s School of Computer Science and Engineering invites applications for a post-doc position. Potential applicants are encouraged to visit <a href="http://www.gilsegev.net" rel="nofollow">http://www.gilsegev.net</a> and <a href="http://www.cs.huji.ac.il/~ilank" rel="nofollow">http://www.cs.huji.ac.il/~ilank</a> for an overview of the group’s recent activity.</p>
<p>To apply for the position, please provide us with your CV and research statement.</p>
<p>Website: <a href="https://www.cs.huji.ac.il/page/5087">https://www.cs.huji.ac.il/page/5087</a><br />
Email: crypto@cs.huji.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/06/15/cryptography-postdoc-at-hebrew-university-apply-by-august-31-2022/"><span class="datestr">at June 15, 2022 05:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2022/06/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2022/06/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://thegradient.pub/working-on-the-weekends-an-academic-necessity/">Claas Voelcker on academic work-life balance</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108406720822630002">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=31562264">via</a>). I think we all know that many academics (myself included!) struggle to keep our weekend and evening time free of work-related distractions. Voelcker investigates where this pressure to work comes from (often internally) and suggests that overwork may block creativity; taking time off can make you more productive.</p>
  </li>
  <li>
    <p>From a face-up deck of cards, repeatedly deal off the number of cards showing on the top card (counting Jacks as 11, etc.). What’s the probability that you empty the deck by dealing out exactly the right number of cards in the last step? <a href="https://mathstodon.xyz/@christianp/108401164015456979">Christian Lawson-Perfect’s post</a> inspired a group discussion leading to the result that, for decks with large numbers of suits, the answer should tend to 1/7, and that for a standard 52-card deck it is approximately 0.1420342593977892.</p>
  </li>
  <li>
    <p>Another Wikipedia illustration <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108415828596664345">\(\mathbb{M}\)</a>):</span> empty regions for the <a href="https://en.wikipedia.org/wiki/Euclidean_minimum_spanning_tree">Euclidean minimum spanning tree</a>. If the red vertical segment is to be an MST edge, the outer white lens needs to be empty of other points; this emptiness implies that the edge is part of the relative neighborhood graph. The emptiness of the light blue diameter circle inside the lens defines the Gabriel graph in the same way. The inner rhombus must not only be empty, but disjoint from the rhombi of other edges.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/EMST-empty-regions.svg" style="width: 100%;" alt="Empty regions for the Euclidean minimum spanning tree" /></p>
  </li>
  <li>
    <p><a href="https://somethingorotherwhatever.com/shunting-yard-animation/">Shunting yard animation</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@christianp/108424166828836198">\(\mathbb{M}\)</a>).</span> Cutesy train animation of the <a href="https://en.wikipedia.org/wiki/Shunting_yard_algorithm">shunting yard algorithm</a> for parsing infix expressions.</p>
  </li>
  <li>
    <p><a href="https://beachpackagingdesign.com/boxvox/pseudo-cylindrical-concave-polyhedral-packaging">Pseudo-cylindrical concave polyhedral packaging</a> <span style="white-space: nowrap;">(<a href="MLIhttps://mathstodon.xyz/@11011110/108434883781055479NK">\(\mathbb{M}\)</a>).</span>  This post describes multiple examples of the <a href="https://en.wikipedia.org/wiki/Yoshimura_buckling">Yoshimura buckling pattern</a> or <a href="https://en.wikipedia.org/wiki/Schwarz_lantern">Schwarz lantern</a> in food/drink packaging, not in the obvious way (it happens when you crumple a can end-on) but deliberately by the manufacturer. It doesn’t say why they did, though. Maybe because it looks cool.</p>
  </li>
  <li>
    <p><a href="https://cp4space.hatsya.com/2022/05/25/threelds/">Threelds</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108440193859317506">\(\mathbb{M}\)</a>).</span> I have no idea whether it’s useful for anything, but a threeld is a pair of fields where the multiplication operation on the inner one forms the addition on the outer one. The finite ones have inner order 3 and outer order 2, or inner order a Mersenne prime and outer order the adjacent power of two, but there also exist infinite ones with inner field of characteristic 0 and outer of characteristic 2.</p>
  </li>
  <li>
    <p>Roundup of recent <em>Quanta</em> popularizations and the research they come from <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108442789631056740">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://www.quantamagazine.org/impossible-seeming-surfaces-confirmed-decades-after-conjecture-20220602/">Near-optimal expansion for 2d surfaces</a>, based on “<a href="https://arxiv.org/abs/2107.05292">Near optimal spectral gaps for hyperbolic surfaces</a>”, by Will Hide and Michael Magee.</p>
      </li>
      <li>
        <p><a href="https://www.quantamagazine.org/mathematicians-transcend-geometric-theory-of-motion-20211209/">Inequality between cohomology rank and number of Hamiltonian flow orbits</a>, based on “<a href="https://arxiv.org/abs/2103.01507">Arnold conjecture and Morava K-theory</a>”, by Mohammed Abouzaid and Andrew J. Blumberg.</p>
      </li>
      <li>
        <p><a href="https://www.quantamagazine.org/graduate-students-side-project-proves-prime-number-conjecture-20220606/">Among pairwise-coprime sequences, primes maximize \(\sum 1/n_i\log n_i\)</a>, based on “<a href="https://arxiv.org/abs/2202.02384">A proof of the Erdős primitive set conjecture</a>”, by Jared Duker Lichtman.</p>
      </li>
      <li>
        <p><a href="https://www.quantamagazine.org/researchers-achieve-absurdly-fast-algorithm-for-network-flow-20220608/">Fast maximum flow algorithms</a>, based on “<a href="https://arxiv.org/abs/2203.00671">Maximum flow and minimum-cost flow in almost-linear time</a>”, by Li Chen, Rasmus Kyng, Yang P. Liu, Richard Peng, Maximilian Probst Gutenberg, and Sushant Sachdeva.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Kirk Smith asks Mastodon: “<a href="https://scholar.social/@kirk/108439384108355311">Do people on here edit/write Wikipedia articles related to your field? and what’s your experience/motivation?</a>” There’s a conflict here between desiring academic credit for your work, and maintaining the protection of pseudonymity. But the real-world harassment that pseudonymity prevents is real, whereas I think the possibility of getting much academic credit for this sort of work is largely illusory.</p>
  </li>
  <li>
    <p>New Wikipedia article: <a href="https://en.wikipedia.org/wiki/Staircase_paradox">Staircase paradox</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108454961367151468">\(\mathbb{M}\)</a>),</span> on the familiar example of staircase curves in a unit square that uniformly converge to the diagonal of the square, while their lengths converge to the wrong number (\(2\), rather than \(\sqrt2\)). Somehow we don’t seem to have already had an article on this example. I’m sure there must be many more published sources on this example than the ones I used; if you think I missed something important, please let me know.</p>
  </li>
  <li>
    <p><a href="https://www.math.columbia.edu/~woit/wordpress/?p=12936">Physicists discover never-before seen particle sitting on a tabletop</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108465478766177772">\(\mathbb{M}\)</a>).</span> Peter Woit’s headline for this <em>Not Even Wrong</em> post repeats the breathless hype from the churnalism on a new condensed-matter-physics preprint, which promises applications to dark matter and quantum computing and turns out to be much much less. From the comments, it seems that the condensed matter physicists have been guilty of misapplying the tag “Higgs field” for a long time.</p>
  </li>
  <li>
    <p><a href="https://blogs.ams.org/beyondreviews/2021/07/18/yoshimura-crush-patterns/">Yoshimura crushing patterns on the <em>Inside MathSciNet</em> blog</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108469088531022175">\(\mathbb{M}\)</a>).</span>  I don’t think it’s accurate to say that a crush pattern and a crease pattern are synonyms, though. One is a description of the output of a crushing process; the other is an input to a folding process that guides you to put the folds into their intended places. The similarity of the crushing pattern and the Yoshimura fold is not coincidental but the purpose is different.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1016/j.jclinepi.2022.05.019">Study of all open-access papers on BioMed Central from a month-long window</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108474483987356656">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=31660239">via</a>) finds that although 42% claim their data to be available on reasonable request, only 7% actually responded and provided their data.</p>
  </li>
  <li>
    <p><a href="https://b-mehta.github.io/unit-fractions/">Formalization in Lean of Thomas Bloom’s proof</a> of the density version of the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Graham_problem">Erdős–Graham problem</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108484103209861017">\(\mathbb{M}\)</a>,</span> <a href="https://twitter.com/XenaProject/status/1536099892694859777">via</a>), according to which every set of integers with positive upper density includes the denominators of an Egyptian fraction representation of one. The blueprint appears to show Theorem 2 of <a href="https://arxiv.org/abs/2112.03726">Bloom’s preprint</a> as verified, but Theorem 3 (log density) still to go.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2022/06/15/linkage.html"><span class="datestr">at June 15, 2022 04:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/088">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/088">TR22-088 |  Efficient decoding up to a constant fraction of the code length for asymptotically good quantum codes | 

	Anthony Leverrier, 

	Gilles Zémor</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We introduce and analyse an efficient decoder for the quantum Tanner codes that can correct adversarial errors of linear weight. Previous decoders for quantum low-density parity-check codes could only handle adversarial errors of weight $O(\sqrt{n \log n})$. We also work on the link between quantum Tanner codes and the Lifted Product codes of Panteleev and Kalachev, and show that our decoder can be adapted to the latter. The decoding algorithm alternates between sequential and parallel procedures and converges in linear time.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/088"><span class="datestr">at June 15, 2022 02:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/06/14/lecturer-senior-lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/06/14/lecturer-senior-lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/">Lecturer/Senior Lecturer in Algorithms at University of Sheffield (apply by July 5, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the University of Sheffield UK aims to hire one Lecturer/Senior Lecturer (Assistant/Associate professor) in an area including, but not limited to complexity, algorithm, AI, and AGT. The role is supported with a generous startup package, including funding for conference travel and equipment and a PhD scholarship.</p>
<p>Website: <a href="https://www.jobs.ac.uk/job/CQL118/lecturer-senior-lecturer-in-algorithms">https://www.jobs.ac.uk/job/CQL118/lecturer-senior-lecturer-in-algorithms</a><br />
Email: s.mukhopadhyay@sheffield.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/06/14/lecturer-senior-lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/"><span class="datestr">at June 14, 2022 12:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/06/14/lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/06/14/lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/">Lecturer in Algorithms at University of Sheffield (apply by July 5, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the University of Sheffield UK aims to hire two Lecturers (Assistant professor) in an area including, but not limited to complexity, algorithm, AI, and AGT. The role is supported with a generous startup package, including funding for conference travel and equipment and a PhD scholarship.</p>
<p>Website: <a href="https://www.jobs.ac.uk/job/CQL110/lecturer-in-algorithms-two-posts">https://www.jobs.ac.uk/job/CQL110/lecturer-in-algorithms-two-posts</a><br />
Email: s.mukhopadhyay@sheffield.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/06/14/lecturer-in-algorithms-at-university-of-sheffield-apply-by-july-5-2022/"><span class="datestr">at June 14, 2022 12:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2022/06/14/analysts-minimum-spanning">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2022/06/14/analysts-minimum-spanning.html">The analyst’s minimum spanning tree</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Infinite sets of points in the Euclidean plane, even discrete sets, do not always have <a href="https://en.wikipedia.org/wiki/Euclidean_minimum_spanning_tree">Euclidean minimum spanning trees</a>. For instance, consider the points with coordinates</p>

\[\left(i, \pm\left(1+\frac1i\right)\right),\]

<p>for positive <span style="white-space: nowrap;">integers \(i\).</span> You can connect the <span style="white-space: nowrap;">positive-\(y\)</span> points and the <span style="white-space: nowrap;">negative-\(y\)</span> points into two chains with edges of length less than two, but then you have to pick one edge of length greater than two to span from one chain to the other. Whichever edge you choose, the next edge along would always be a better choice. So a tree that minimizes the multiset of its edge weights (as finite minimum spanning trees do) does not exist for this example. And as the same example shows, the sum of edge weights may be infinite, so how can we use minimization of this sum to define a tree?</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/ladder-no-mst.svg" alt="Discrete infinite set of points with no Euclidean minimum spanning tree" /></p>

<p>Despite that, here’s a construction that works for any <a href="https://en.wikipedia.org/wiki/Compact_space">compact set</a>, even one with infinitely many components, and that generalizes easily to higher-dimensional Euclidean spaces. I think it deserves to be called the Euclidean minimum spanning tree. Given a compact <span style="white-space: nowrap;">set \(C\),</span> consider every partition \(C=A\cup (C\setminus A)\) of \(C\) into two disjoint nonempty compact subsets. For each such partition, find a line segment \(s_A\) of minimum length with endpoints in \(A\) <span style="white-space: nowrap;">and \(C\setminus A\),</span> breaking ties lexicographically by coordinates. By the assumed compactness of \(A\) <span style="white-space: nowrap;">and \(C\setminus A\),</span> such a line segment exists. Let \(T_C\) be the union of \(C\) itself and of all line segments obtained in this way. For example, the union of a triangle, square, and circle shown below has three partitions into two nonempty compact subsets, separating one of these three shapes from the other two. Two of these partitions choose the diagonal pink segment as their shortest connection, and the third partition chooses the horizontal pink segment. So in this case, \(T_C\) consists of the three blue given shapes and two pink segments.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/trisquircle.svg" alt="Minimum spanning tree of a circle, square, and triangle" /></p>

<p>When \(C\) is a finite point set, \(T_C\) is just a Euclidean minimum spanning tree. When \(C\) has finitely many connected components, like the example above, \(T_C\) is again a minimum spanning tree, for the component-component distances. In the general case, \(T_C\) still has many of the familiar properties of Euclidean minimum spanning trees:</p>

<ul>
  <li>
    <p>It consists of the input and a collection of line segments connecting pairs of input points, by construction.</p>
  </li>
  <li>
    <p>It is a <a href="https://en.wikipedia.org/wiki/Connected_space">connected set</a>. Topologically, this means that it cannot be covered by two disjoint open sets that both have a nonempty intersection with it. (This is different from being path-connected, a stronger property.) Any nontrivial open disjoint cover of \(C\) would be spanned by a line segment from one set to the other, and no new disjoint covers can separate these line segments from their endpoints.</p>
  </li>
  <li>
    <p>For any added <span style="white-space: nowrap;">segment \(s_A\),</span> the intersection of two disks with that segment as radius (a “lune”) has no point of \(C\) in its interior. Any interior point would form one end of a shorter connecting segment between \(A\) <span style="white-space: nowrap;">and \(C\setminus A\),</span> with the other end at an endpoint <span style="white-space: nowrap;">of \(s_A\).</span> No two added segments can cross without violating the empty lune property.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/vesica.svg" alt="The empty lune of an edge" /></p>
  </li>
  <li>
    <p>For any added <span style="white-space: nowrap;">segment \(s_A\),</span> the open rhombus with angles \(60^\circ\) and \(120^\circ\) having \(s_A\) as its long diagonal is disjoint from the rhombi formed in the same way from the other segments. Any two overlapping rhombi would allow the longer of the two segments they come from to be replaced by a shorter segment crossing the same compact partition, on a three-segment path connecting its endpoints via the other segment endpoints. Because these non-overlapping rhombi cover a region of bounded area, the squared segment lengths have a bounded sum, and only finitely many segments can be longer than any given length threshold.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/ivy-rhombs.svg" alt="An infinite minimum spanning tree and its empty rhombi" /></p>
  </li>
  <li>
    <p>The union of \(C\) with any subset of added segments is compact. If \(p\) is a limit point of a <span style="white-space: nowrap;">sequence \(\sigma_i\)</span> of points in this union, it must either lie in the empty rhombus of a segment (in which case it can only be a point of the same segment), or it is a limit point of a sequence of points <span style="white-space: nowrap;">in \(C\),</span> obtained by replacing each point in \(\sigma_i\) that is interior to a segment by the nearest segment endpoint. This replacement only increases the distance from the replaced point to \(p\) by a constant factor, which does not affect convergence. By compactness the replaced sequence converges to a point <span style="white-space: nowrap;">in \(C\).</span></p>
  </li>
  <li>
    <p>For <span style="white-space: nowrap;">any \(i\),</span> the set \(T_i\) of the largest \(i\) added segments (with the same tie-breaking order) are edges of a minimum spanning tree for a family of \(i-1\) sets. To construct these sets, find the components of the union of \(C\) with all shorter segments, and intersect each component <span style="white-space: nowrap;">with \(C\).</span> None of these components can cross between \(A\) and \(C\setminus A\) for any <span style="white-space: nowrap;">edge \(s_A\in T_i\).</span> Because adding \(T_i\) connects all these components, there can be at most \(i-1\) components. Each edge in \(T_i\) is shortest (with a consistent tie-breaking rule) across some partition of the components, one of the ways of determining the edges in a finite minimum spanning tree. In particular, \(T_C\) is minimally connected: removing any edge \(s_A\in S_i\) separates some of the components from each other.</p>
  </li>
  <li>
    <p>\(T_C\) has the minimum sum of squared edge lengths of all collections of line segments between points of \(C\) that <span style="white-space: nowrap;">connect \(C\).</span> To see this, consider any other connecting set \(X\) of line segments with a finite sum of squared edge lengths. Truncate the sorted sequence of edges of \(T_C\) to a finite initial <span style="white-space: nowrap;">sequence \(T_i\)</span> such that the rest of the sequence has negligible sum of squares. Because \(T_i\) is a minimum spanning tree of its components, and \(X\) connects those same components (perhaps redundantly), the sequence of edge lengths in \(T_i\) is, step for step, less than or equal to the sorted sequence of lengths <span style="white-space: nowrap;">in \(X\).</span></p>
  </li>
</ul>

<p>There may exist other sets of line segments that connect \(C\) with the same sum of squared edge lengths but they all are minimally connected, with the same sequence of edge lengths, the same empty lune and empty rhombus properties, and the same property that their initial sequences form finite minimum spanning trees of their components.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108476695929961897">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2022/06/14/analysts-minimum-spanning.html"><span class="datestr">at June 14, 2022 08:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=20165">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/06/13/sorting-and-proving/">Sorting and Proving</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>A proof tells us where to concentrate our doubts—Morris Kline</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p>
Tony Hoare is also known informally as Sir Charles Antony Richard Hoare. He has made key contributions to programming languages, algorithms, operating systems, formal verification, and concurrent computing. </p>
<p>
He won the <a href="https://amturing.acm.org/award_winners/hoare_4622167.cfm">1980 Turing Award</a> for <i>“Fundamental contributions to the definition and design of programming languages.”</i> </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/06/13/sorting-and-proving/th-2/" rel="attachment wp-att-20168"><img width="200" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/06/th.png?resize=200%2C200&amp;ssl=1" class="aligncenter wp-image-20168" height="200" /></a></p>
<p>
</p><p></p><h2> Quicksort </h2><p></p>
<p></p><p>
Hoare invented a new sorting algorithm in 1959. It was not later directly cited in his winning of the Turing Award—see above. Back then Hoare was a visiting student at Moscow State University. His student project at the time needed to sort words in Russian sentences before looking them up in a Russian-English dictionary, which was in alphabetical order on a magnetic tape. He tried insertion sort but it was too slow, and so he invented a new sorting algorithm—it is now called <a href="https://en.wikipedia.org/wiki/Quicksort">Quicksort</a>. Amazing. </p>
<p>
On his return to England, he was asked to write code for <a href="https://en.wikipedia.org/wiki/Shellsort">Shellsort</a>. Hoare mentioned to his boss that he knew of a faster algorithm and his boss bet sixpence that he did not. His boss ultimately accepted that he had lost the bet. Quicksort is well named—it is a winner.</p>
<p>
</p><p></p><h2> And Still Champion </h2><p></p>
<p></p><p>
The most amazing thing to me—Ken writing this and the next section—-is that Quicksort has remained the champion sorter. <a href="https://en.wikipedia.org/wiki/Merge_sort">Mergesort</a> was earlier but <a href="https://en.wikipedia.org/wiki/Heapsort">Heapsort</a> came five years later. No one has improved on Hoare’s idea to focus on <em>swaps</em> that improve the sortedness of two elements at once, both jumping over a guiding element called the <em>pivot</em>.</p>
<p>
Mergesort and Heapsort guarantee <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O(n\log n)}" class="latex" /> time to sort <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> items, whereas Quicksort does not. Yet careful implementations of Quicksort almost always evade slow outcomes. Then they beat Mergesort and Heapsort and all other sorting methods cleanly in terms of the constant under the “<img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O}" class="latex" />.” </p>
<p>
The algorithms-and-data-structures course I taught at UB this past term includes sorting algorithms. I have brought together and polished code instances I showed during the term to compare these three algorithms in one <a href="https://cse.buffalo.edu/~regan/cse250/DataStructures/Sorts.scala">code file</a>. It is in the <a href="https://en.wikipedia.org/wiki/Scala_(programming_language)">Scala</a> programming language. The program has options described at the top, such as setting the “tradeoff point” <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m}" class="latex" /> so that on recursive calls to sort pieces of size at most <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m}" class="latex" />, the code uses Insertion Sort instead. It counts comparisons and copies of items separately, as well as report the time in milliseconds. A swap counts as three not two copies. </p>
<p>
Here is an example run on the English <a href="https://cse.buffalo.edu/~regan/cse250/DataStructures/WarAndPeace.txt">text</a> of <em>War and Peace</em> using <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m = 16}" class="latex" /> for both Quicksort and Mergesort. I wanted to salute Hoare’s application by using the original Russian text, but every file of it I found was densely footnoted. The Russian version doesn’t begin in Russian anyway. I’ve edited the output slightly.<br />
<font size="-1"><br />
<code><br />
metallica&lt;~&gt; scala Sorts WarAndPeace.txt 16 medianRandom3 011000<br />
Bits=(randomize)(makeHeap)(part for ==)(use Selsort)(make distinct)(pad len)<br />
Sorting 562,603 items, tradepoint 16 to insertion sort<br />
QuickSort pivot is medianRandom3 for 3-way part; heapSort uses makeHeap</code></font></p><font size="-1">
<p>MergeSort made 8,874,241 comparisons and 9,001,648 copies<br />
plus 1,447,593 comparisons and 2,061,296 copies for insertionSort at bottom<br />
In total: made 10,321,834 comparisons and 11,062,944 copies<br />
Time for mergeSort: 3241 milliseconds</p>
<p>QuickSort made 5,832,042 comparisons and 16,390,570 copies<br />
plus 74,992 comparisons and 108,450 copies for insertionSort at bottom<br />
In total: made 5,907,034 comparisons and 16,499,020 copies<br />
Time for quickSort: 1212 milliseconds</p>
</font><p><font size="-1">HeapSort made 19,977,762 comparisons and 31,494,294 copies<br />
Time for heapSort: 1885 milliseconds<br />
</font></p>
<p></p><p><br />
This used the strategy of selecting the median of three randomly sampled elements of the array piece to be sorted as the pivot. Quicksort runs quickest when the pivot is the median, but it takes too long to find the exact median at each level of recursion. My program has the option “<font size="+1"><tt>ninther</tt></font>” to select the median of three such median-of-3 samples, as <a href="https://www.johndcook.com/blog/2009/06/23/tukey-median-ninther/">proposed</a> by John Tukey. Try my code to see if <font size="+1"><tt>ninther</tt></font> works faster and with fewer comparisons on your system. </p>
<p>
</p><p></p><h2> Empirical Testing and Proving </h2><p></p>
<p></p><p>
The person whose 1975 PhD <a href="https://sedgewick.io/wp-content/themes/sedgewick/papers/1975Quicksort.pdf">dissertation</a> studied the performance of Quicksort implementations with rigor and depth was none other than Bob Sedgewick, whose retirement party Dick recently <a href="https://rjlipton.wpcomstaging.com/2022/05/04/sedgewick-to-emeritus-status/">covered</a>. This led into Bob’s famous textbook <a href="https://sedgewick.io/books/algorithms/"><em>Algorithms</em></a>, which is now in its fourth edition with Kevin Wayne as co-author. Bob’s separate <a href="https://github.com/chrswt/algorithms-sedgewick/blob/master/notes/2.3-quicksort.md">notes</a> accompanying the book point out an aspect vital to running on inputs like <em>War and Peace</em> that have many identical (keys of) items. The simple partition for a pivot <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p}" class="latex" /> into </p>
<p>
<code><br />
               [ elements &lt;= p ][ p ][ elements &gt;= p ]<br />
</code></p>
<p></p><p><br />
winds up doing many extra comparisons of keys equal to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p}" class="latex" />. The extra initial effort to determine a 3-way partition</p>
<p>
<code><br />
               [ elements &lt; p ][ elements == p ][ elements &gt; p ]<br />
</code></p>
<p></p><p><br />
pays off in the recursion, which only needs to be on the outer two segments. Without this trick, Quicksort—on even a relatively high-entropy source like <em>War and Peace</em>—degrades to be worse than the other two algorithms. </p>
<p>
My code allows making all words distinct by setting the fifth bit. Then Quicksort makes more comparisons and copies than Mergesort. Yet it still runs almost 40% faster in my tests. As explained in general <a href="https://www.geeksforgeeks.org/quick-sort-vs-merge-sort">here</a>, this is because the Quicksort gives better cache locality. Heapsort likewise runs in-place, but not with locality. </p>
<p>
The assertions itemized in this section are unimpeachable. But in what sense, and to what degree, are they <b>formally provable</b>? </p>
<p>
There is also a difference from the criterion of <b>reproducibility</b> in the sciences. The environmental conditions for reproducing an experiment are presumed to be closed and given. The primacy of Quicksort, however, applies to processing architectures that were unknown at the time of Sedgewick’s 1975 thesis, let alone Hoare’s 1959 concept. It is a more open-ended prediction that if you run mine or similar code on your system—in machine environments I may know nothing about—it will give much the same time performance.</p>
<p>
Now back to Dick, about Hoare’s take on formally proving properties of programs.</p>
<p>
</p><p></p><h2> Hoare Logic </h2><p></p>
<p></p><p>
Hoare invented a new <a href="https://en.wikipedia.org/wiki/Hoare_logic">logic</a> for reasoning about the correctness of computer programs ten years later in 1969. It was directly counted toward his winning of the Turing Award. It was based on original ideas created by Robert Floyd, who had published a system for flowcharts. The logic is now known as Hoare logic—see <a href="http://sunnyday.mit.edu/16.355/Hoare-CACM-69.pdf">this</a> for details. This is one of the most influential papers on the theory of programming. In this paper Hoare showed how to reason about program execution using logical specifications of statement behavior that has become known as <a href="https://www.cs.cmu.edu/~aldrich/courses/654-sp09/notes/3-hoare-notes.pdf">Hoare triples</a>.</p>
<p>
A Hoare triple has three parts, a precondition <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" />, a program statement or series of statements <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" />, and a postcondition <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Q}" class="latex" />. It’s is usually written in the form 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7BP%5C%7D+S+%5C%7BQ%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \{P\} S \{Q\} " class="latex" /></p>
<p>The meaning is “if <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" /> is true before <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> is executed, and if the execution of <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> terminates, then <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Q}" class="latex" /> is true afterwards”. Note that the triple does not assert that <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> will terminate; that requires a separate proof. As a simple example: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7Bx%2B1%3D43%5C%7Dy%3A%3Dx%2B1%5C%7By%3D43%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \{x+1=43\}y:=x+1\{y=43\} " class="latex" /></p>
<p>
A key motivation for Hoare Logic is to be able to prove the correctness of real systems with real programs. The fact that Hoare Logic is possible is clear. It is possible to use it to <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.1739&amp;rep=rep1&amp;type=pdf">prove</a> Quicksort, for example. But it is less clear whether or not we will be able to apply formal methods to complex practical systems. This is a topic that I have thought about for decades. </p>
<p>
</p><p></p><h2> A Codex </h2><p></p>
<p></p><p>
Saturday’s Washington Post has a tech <a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">article</a>, “The Google engineer who thinks the company’s AI has come to life.” This prompted us to visit a long <a href="https://www.nytimes.com/2022/04/15/magazine/ai-language.html">article</a> in the April 15 New York Times Magazine on Open AI’s <a href="https://en.wikipedia.org/wiki/GPT-3">GPT-3</a> language engine. </p>
<p>
GPT-3 works by playing a game of <em>guess the next word</em> in a phrase. This is akin to <em>guess the next move</em> in chess and other games, and we will have more to say about it. For an example with wider context, suppose we fed it this post up before this section, and then gave it “<b>A Cod-</b>” as the partially completed section title. Since this comes at the end, GPT-3 might guess <b>coda</b>. Or since this is an addendum, maybe <b>codicil</b>. A <b>codex</b>, on the other hand, is a large manuscript book.</p>
<p>
In fact, we do mean <i>codex</i>, or rather <a href="https://en.wikipedia.org/wiki/OpenAI_Codex">Codex</a>, which is an offshoot of GPT-3 for generating code in a wide variety of programming languages. Its emergence creates a new riff on our recent <a href="https://rjlipton.wpcomstaging.com/2022/04/10/discussion-about-proving-again/">discussion</a> on proving and how <a href="https://rjlipton.wpcomstaging.com/2022/05/23/hilberts-lost-problem/">software</a> projects have stayed robust while growing far beyond the scale on which they can be formally proved. Now <a href="https://openai.com/blog/codex-apps/">Codex</a> ventures to write one’s software by gleaning the intent from one’s prose specification—by drawing on millions of available coding projects that give relatable specifications. </p>
<p>
Is program output from Codex <em>proven</em>—or <em>provable</em>? This will be a challenge. It may be more feasible to integrate Codex with projects like the <a href="https://vst.cs.princeton.edu/">Verified Software Toolchain</a> led Andrew Appel, Lennart Beringer, William Mansky, and Qinshi Wang. This is at any rate further grist for discussion.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Take a look at <a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">this</a> for comments about the recent Harry Lewis <a href="https://scp.cc.gatech.edu/2021/05/26/debate-that-changed-programming-living-history/">debate</a>. This was based on our <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a>. </p>
<p>
What do you think?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2022/06/13/sorting-and-proving/"><span class="datestr">at June 13, 2022 04:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-414280661681721253">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2022/06/i-am-surprised-that-shortest-vector.html">I am surprised that the Shortest Vector Problem is not known to be NP-hard, but perhaps I am wrong</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><br /></div><div>A lattice L in R^n is a discrete subgroup of R^n. </div><div><br /></div><div>Let p IN [1,infinty)</div><div><br /></div><div>The<i> p-norm of a vector </i>x=(x_1,...,x_n) IN R^n is</div><div><br /></div><div>                                          ||x||_p=(|x_1|^p + ... + |x_n|^p)^{1/p}.</div><div><br /></div><div>Note that p=2 yields the standard Euclidean distance.</div><div><br /></div><div>If p=infinity  then ||x||_p=max_{1 LE  i LE n} |x_i|.</div><div><br /></div><div>Let p IN [1,infinity]</div><div><br /></div><div>The Shortest Vector Problem in norm p (SVP_p) is as follows:</div><div><br /></div><div>INPUT A lattice L specified by a basis.</div><div><br /></div><div>OUTPUT Output the shortest vector in that basis using the p-norm.</div><div><br /></div><div>I was looking at lower bounds on approximating this problem and just assumed the original problem was NP-hard. Much to my surprise either (a) its not known, or (b) it is known and I missed in in my lit search. I am hoping that comments on this post will either verify (a) or tell me (b) with refs. </div><div><br /></div><div>Here is what I found:</div><div><br /></div><div>Peter van Emde Boas in 1979  showed that SVP_infinity  is NP-hard.   </div><div>(See <a href="https://cs.stackexchange.com/questions/33828/np-completeness-of-closest-vector-problem">here</a> for a page that has a link to the paper.  I was unable to post the link directly. Its where it says <i>I found</i> <i>the original paper.) </i>He conjectured that for all p GE 1 the problem is NP-hard. </div><div><br /></div><div><br /></div><div>Miklos Ajtai in 1998 showed that SVP_2 is NP-hard under randomized reductions.  (See <a href="https://doi.org/10.1145/276698.276705">here</a>)</div><div><br /></div><div>There are other results by Subhash Khot in 2005  (see <a href="https://doi.org/10.1145/1089023.1089027">here</a>)  and Divesh Aggarwal et al. in 2021 (see <a href="https://doi.org/10.1137/1.9781611976465.109">here</a>)  (Also see the references in those two papers.)  about lower bounds on approximation using a variety of assumptions. Aggarwal's paper in unusual in that it shows hardness results for all p except p even; however, this is likely a function of the proof techniques and not of reality. Likely these problems are hard for all p.</div><div><br /></div><div>But even after all of those great papers it seems that the  the statement:</div><div><br /></div><div>                For all p IN [1,infinity] SVP_p is NP-hard</div><div><br /></div><div>is a conjecture, not a theorem. I wonder if van Emde Boas would be surprised. If he reads this blog, maybe I'll find out. If you know him then ask him to comment, or comment yourself. </div><div><br /></div><div>SO is that still a conjecture OR have I missed something?</div><div><br /></div><div>(Oddly enough, my own blog post <a href="https://blog.computationalcomplexity.org/search?q=shortest+vector">here</a> (item 5)  indicates SVP_p  is NP-hard; however, </div><div>I have not been able to track down the reference.)</div><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2022/06/i-am-surprised-that-shortest-vector.html"><span class="datestr">at June 12, 2022 06:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://scottaaronson.blog/?p=6479">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://scottaaronson.blog/?p=6479">Alright, so here are my comments…</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>… on Blake Lemoine, the Google engineer who <a href="https://www.huffpost.com/entry/blake-lemoine-lamda-sentient-artificial-intelligence-google_n_62a5613ee4b06169ca8c0a2e?d_id=3887326&amp;ref=bffbhuffpost&amp;ncid_tag=fcbklnkushpmg00000063&amp;utm_medium=Social&amp;utm_source=Facebook&amp;utm_campaign=us_main&amp;fbclid=IwAR0o5U4wv2cDP8o3XIAekj2Xh5wVPZVzVhyH696N8tnLv_m-YXtUDt0tFNU">became convinced</a> that a machine learning model had become sentient, contacted federal government agencies about it, and was then <s>fired</s> placed on administrative leave for violating Google’s confidentiality policies.</p>



<p>(1) I don’t think Lemoine is right that <a href="https://blog.google/technology/ai/lamda/">LaMDA</a> is at all sentient, but the <a href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917">transcript</a> is so mind-bogglingly impressive that I did have to stop and think for a second! Certainly, if you sent the transcript back in time to 1990 or whenever, even an expert reading it might say, yeah, it looks like by 2022 AGI has more likely been achieved than not (“but can I run my own tests?”).  Read it for yourself, if you haven’t yet.</p>



<p>(2) Reading Lemoine’s <a href="https://cajundiscordian.medium.com/">blog</a> and <a href="https://twitter.com/cajundiscordian">Twitter</a> this morning, he holds many views that I disagree with, not just about the sentience of LaMDA. Yet I’m touched and impressed by how principled he is, and I expect I’d hit it off with him if I met him. I wish that a solution could be found where Google wouldn’t fire him.</p></div>







<p class="date">
by Scott <a href="https://scottaaronson.blog/?p=6479"><span class="datestr">at June 12, 2022 05:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/087">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/087">TR22-087 |  Depth-$d$ Threshold Circuits vs. Depth-$(d + 1)$ AND-OR Trees | 

	Pooya Hatami, 

	William Hoza, 

	Avishay Tal, 

	Roei Tell</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
For $n \in \mathbb{N}$ and $d = o(\log \log n)$, we prove that there is a Boolean function $F$ on $n$ bits and a value $\gamma = 2^{-\Theta(d)}$ such that $F$ can be computed by a uniform depth-$(d + 1)$ $\text{AC}^0$ circuit with $O(n)$ wires, but $F$ cannot be computed by any depth-$d$ $\text{TC}^0$ circuit with $n^{1 + \gamma}$ wires. This bound matches the current state-of-the-art lower bounds for computing explicit functions by threshold circuits of depth $d &gt; 2$, which were previously known only for functions outside $\text{AC}^0$ such as the parity function. Furthermore, in our result, the $\text{AC}^0$ circuit computing $F$ is a monotone *read-once formula* (i.e., an AND-OR tree), and the lower bound holds even in the average-case setting with respect to advantage $n^{-\gamma}$.

Our proof builds on the *random projection* procedure of Håstad, Rossman, Servedio, and Tan, which they used to prove the celebrated average-case depth hierarchy theorem for $\text{AC}^0$ (J. ACM, 2017). We show that under a modified version of their projection procedure, any depth-$d$ threshold circuit with $n^{1 + \gamma}$ wires simplifies to a near-trivial function, whereas an appropriately parameterized AND-OR tree of depth $d + 1$ maintains structure.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/087"><span class="datestr">at June 12, 2022 02:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://grigory.github.io/blog/theory-jobs-2022">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/yaroslavtsev.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="http://grigory.github.io/blog/theory-jobs-2022/">Theory Jobs 2022</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://docs.google.com/spreadsheets/d/1BdHrWYT6F7je4lINqS14Fu0cOlkyrRhy2nkuAtNn2-c/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory hires this year. 
Rules for the spreadsheet have been copied from previous years and all edits to the document are anonymized. Please, feel free to contact me directly or post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>You are welcome to add yourself, or people your department has hired. </li>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>Hires should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are <b>absolutely sure have been offered and accepted</b>. This is not the place for speculation and rumors. Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2022/">Theory Jobs 2022</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on June 11, 2022.</p></div>







<p class="date">
by Grigory Yaroslavtsev (grigory@grigory.us) <a href="http://grigory.github.io/blog/theory-jobs-2022/"><span class="datestr">at June 11, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://scottaaronson.blog/?p=6457">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://scottaaronson.blog/?p=6457">Computer scientists crash the Solvay Conference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Thanks so much to everyone who sent messages of support following my <a href="https://scottaaronson.blog/?p=6444">last post</a>!  I vowed there that I’m going to stop letting online trolls and sneerers occupy so much space in my mental world.  Truthfully, though, while there <em>are</em> many trolls and sneerers who terrify me, there are also some who merely amuse me.  A good example of the latter came a few weeks ago, when an anonymous commenter calling themselves “String Theorist” submitted the following:</p>



<blockquote class="wp-block-quote"><p>It’s honestly funny to me when you [Scott] call yourself a “nerd” or a “prodigy” or whatever <em>[I don’t recall ever calling myself a “prodigy,” which would indeed be cringe, though “nerd” certainly —SA]</em>, as if studying quantum computing, which is essentially nothing more than glorified linear algebra, is such an advanced intellectual achievement. For what it’s worth I’m a theoretical physicist, I’m in a completely different field, and I was still able to learn Shor’s algorithm in about half an hour, that’s how easy this stuff is. I took a look at some of your papers on arXiv and the math really doesn’t get any more advanced than linear algebra. To understand quantum circuits about the most advanced concept is a tensor product which is routinely covered in undergraduate linear algebra. Wheras in my field of string theory grasping, for instance, holographic dualities relating confirmal field theories and gravity requires vastly more expertise (years of advanced study). I actually find it pretty entertaining that you’ve said yourself you’re still struggling to understand QFT, which most people I’m working with in my research group were first exposed to in undergrad <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f609.png" style="height: 1em;" class="wp-smiley" alt="😉" />  The truth is we’re in entirely different leagues of intelligence (“nerdiness”) and any of your qcomputing papers could easily be picked up by a first or second year math major. It’s just a joke that this is even a field (quantum complexity theory) with journals and faculty when the results in your papers that I’ve seen are pretty much trivial and don’t require anything more than undergraduate level maths.</p></blockquote>



<p>Why does this sort of trash-talk, reminiscent of <a href="https://en.wikipedia.org/wiki/Lubo%C5%A1_Motl">Luboš Motl</a>, no longer ruffle me?  Mostly because the boundaries between quantum computing theory, condensed matter physics, and quantum gravity, which were never clear in the first place, have steadily gotten fuzzier.  Even in the 1990s, the field of quantum computing attracted amazing physicists—folks who definitely <em>do</em> know quantum field theory—such as Ed Farhi, John Preskill, and Ray Laflamme.  Decades later, it would be fair to say that the physicists have banged their heads against many of the same questions that we computer scientists have banged <em>our</em> heads against, oftentimes in collaboration with us.  And yes, there were cases where actual knowledge of particle physics gave physicists an advantage—with some famous examples being the algorithms of Farhi and collaborators (the <a href="https://en.wikipedia.org/wiki/Adiabatic_quantum_computation">adiabatic algorithm</a>, the <a href="https://arxiv.org/abs/quant-ph/0209131">quantum walk on conjoined trees</a>, the <a href="https://scottaaronson.blog/?p=207">NAND-tree algorithm</a>).  There were other cases where computer scientists’ knowledge gave <em>them</em> an advantage: I wouldn’t know many details about that, but conceivably shadow tomography, BosonSampling, PostBQP=PP?  Overall, it’s been what you wish <em>every</em> indisciplinary collaboration could be.</p>



<p>What’s new, in the last decade, is that the scientific conversation centered around quantum information and computation has dramatically “metastasized,” to encompass not only a good fraction of all the experimentalists doing quantum optics and sensing and metrology and so forth, and not only a good fraction of all the condensed-matter theorists, but even many leading string theorists and quantum gravity theorists, including Susskind, Maldacena, Bousso, Hubeny, Harlow, and yes, <a href="https://arxiv.org/abs/1805.11965">Witten</a>.  And I don’t think it’s <em>just</em> that they’re too professional to trash-talk quantum information people the way commenter “String Theorist” does.  Rather it’s that, because of the intellectual success of “It from Qubit,” we’re increasingly participating in the same <a href="https://www.youtube.com/watch?v=1CpzigpEJnU">conversations</a> and working on the same technical questions.  One particularly exciting such question, which I’ll have more to say about in a future post, is the truth or falsehood of the Quantum Extended Church-Turing Thesis for observers who jump into black holes.</p>



<p>Not to psychoanalyze, but I’ve noticed a pattern wherein, the more secure a scientist is about their position within their own field, the readier they are to admit ignorance about the <em>neighboring</em> fields, to learn about those fields, and to reach out to the experts in them, to ask simple or (as it usually turns out) not-so-simple questions.</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p>I can’t imagine any better illustration of these tendencies better than the 28th Solvay Conference on the Physics of Quantum Information, which I attended two weeks ago in Brussels on my 41st birthday.</p>



<figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/solvay.jpg"><img width="1024" alt="" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/solvay-1024x578.jpg" class="wp-image-6466" height="578" /></a>As others pointed out, the proportion of women is not as high as we all wish, but it’s higher than in 1911, when there was exactly one: Madame Curie herself.</figure>



<p>It was my first trip out of the US since before COVID—indeed, I’m so out of practice that I nearly missed my flights in <em>both</em> directions, in part because of my lack of familiarity with the COVID protocols for transatlantic travel, as well as the immense lines caused by those protocols.  My former adviser Umesh Vazirani, who was also at the Solvay Conference, was <a href="https://scottaaronson.blog/?p=40">proud</a>.</p>



<p>The Solvay Conference is the venue where, legendarily, the fundamentals of quantum mechanics got hashed out between 1911 and 1927, by the likes of Einstein, Bohr, Planck, and Curie.  (Einstein complained, in a letter, about being called away from his work on general relativity to attend a <a href="https://www.europhysicsnews.org/articles/epn/pdf/2011/05/epn2011425p15.pdf">“witches’ sabbath.”</a>)  Remarkably, it’s still being held in Brussels every few years, and still funded by the same Solvay family that started it.  The once-every-few-years schedule has, we were constantly reminded, been interrupted only three times in its 110-year history: once for WWI, once for WWII, and now once for COVID (this year’s conference was supposed to be in 2020).</p>



<p>This was the first ever Solvay conference organized around the theme of quantum information, and apparently, the first ever that counted computer scientists among its participants (me, Umesh Vazirani, Dorit Aharonov, Urmila Mahadev, and Thomas Vidick).  There were four topics: (1) many-body physics, (2) quantum gravity, (3) quantum computing hardware, and (4) quantum algorithms.  The structure, apparently unchanged since the conference’s founding, is this: everyone attends every session, without exception.  They sit around facing each other the whole time; no one ever stands to lecture.  For each topic, two <a href="https://en.wikipedia.org/wiki/Rapporteur">“rapporteurs”</a> introduce the topic with half-hour prepared talks; then there are short prepared response talks as well as an hour or more of unstructured discussion.  Everything everyone says is recorded in order to be published later.</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p>Daniel Gottesman and I were the two rapporteurs for quantum algorithms: Daniel spoke about quantum error-correction and fault-tolerance, and I spoke about <a href="https://www.scottaaronson.com/talks/aar-solvay.ppt">“How Much Structure Is Needed for Huge Quantum Speedups?”</a>  The link goes to my PowerPoint slides, if you’d like to check them out.  I tried to survey 30 years of history of that question, from Simon’s and Shor’s algorithms, to huge speedups in quantum query complexity (e.g., glued trees and Forrelation), to the recent quantum supremacy experiments based on BosonSampling and Random Circuit Sampling, all the way to the <a href="https://arxiv.org/abs/2204.02063">breakthrough</a> by Yamakawa and Zhandry a couple months ago.  The last slide hypothesizes a “Law of Conservation of Weirdness,” which after all these decades still remains to be undermined: “For every problem that admits an exponential quantum speedup, there must be some weirdness in its detailed statement, which the quantum algorithm exploits to focus amplitude on the rare right answers.”  My title slide also shows <a href="https://openai.com/dall-e-2/">DALL-E2</a>‘s impressionistic take on the title question, “how much structure is needed for huge quantum speedups?”:</p>



<figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/speedups.jpg"><img width="1024" alt="" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/speedups-1024x418.jpg" class="wp-image-6474" height="418" /></a></figure>



<p>The discussion following my talk was largely a debate between me and Ed Farhi, reprising many debates he and I have had over the past 20 years: Farhi urged optimism about the prospect for large, practical quantum speedups via algorithms like <a href="https://arxiv.org/abs/1411.4028">QAOA</a>, pointing out his group’s past successes and explaining how they wouldn’t have been possible without an optimistic attitude.  For my part, I praised the past successes and said that optimism is well and good, but at the same time, companies, venture capitalists, and government agencies are right now pouring billions into quantum computing, in many cases—as I know from talking to them—because of a mistaken impression that QCs are <em>already known</em> to be able to revolutionize machine learning, finance, supply-chain optimization, or whatever other application domains they care about, and to do so <em>soon</em>.  They’re genuinely surprised to learn that the consensus of QC experts is in a totally different place.  And to be clear: among quantum computing theorists, I’m not at all unusually pessimistic or skeptical, just unusually willing to say in public what others say in private.</p>



<p>Afterwards, one of the string theorists said that Farhi’s arguments with me had been a highlight … and I agreed.  What’s the point of a friggin’ Solvay Conference if everyone’s just going to <em>agree</em> with each other?</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p>Besides quantum algorithms, there was naturally lots of animated discussion about the practical prospects for building scalable quantum computers.  While I’d hoped that this discussion might change the impressions I’d come with, it mostly confirmed them.  Yes, the problem is staggeringly hard.  Recent ideas for fault-tolerance, including the use of LDPC codes and bosonic codes, might help.  Gottesman’s talk gave me the insight that, at its core, quantum fault-tolerance is all about <em>testing</em>, <em>isolation</em>, and <em>contact-tracing</em>, just for bit-flip and phase-flip errors rather than viruses.  Alas, we don’t yet have the quantum fault-tolerance analogue of a vaccine!</p>



<p>At one point, I asked the trapped-ion experts in open session if they’d comment on the startup company <a href="https://ionq.com/">IonQ</a>, whose stock price recently fell precipitously in the wake of a scathing analyst report.  Alas, none of them took the bait.</p>



<p>On a different note, I was tremendously excited by the quantum gravity session.  Netta Engelhardt spoke about her and others’ <a href="https://www.quantamagazine.org/netta-engelhardt-has-escaped-hawkings-black-hole-paradox-20210823/">celebrated recent work</a> explaining the Page curve of an evaporating black hole using Euclidean path integrals—and by questioning her and others during coffee breaks, I finally got a handwavy intuition for how it works.  There was also lots of debate, again at coffee breaks, about Susskind’s <a href="https://www.youtube.com/watch?v=1CpzigpEJnU">recent speculations</a> on observers jumping into black holes and the quantum Extended Church-Turing Thesis.  One of my main takeaways from the conference was a dramatically better understanding of the issues involved there—but that’s a big enough topic that it will need its own post.</p>



<p>Toward the end of the quantum gravity session, the experimentalist John Martinis innocently asked what actual experiments, or at least thought experiments, had been at issue for the past several hours.  I got a laugh by explaining to him that, while the gravity experts considered this too obvious to point out, the thought experiments in question all involve forming a black hole in a known quantum pure state, with total control over all the Planck-scale degrees of freedom; then waiting outside the black hole for ~10<sup>70</sup> years; collecting every last photon of Hawking radiation that comes out and routing them all into a quantum computer; doing a quantum computation that might actually require exponential time; <em>and then</em> jumping into the black hole, whereupon you might either die immediately at the event horizon, or else learn something in your last seconds before hitting the singularity, which you could then never communicate to anyone outside the black hole.  Martinis thanked me for clarifying.</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p>Anyway, I had a total blast.  Here I am amusing some of the world’s great physicists by letting them mess around with GPT-3.</p>



<figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/gpt3.jpg"><img width="1024" alt="" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/06/gpt3-1024x768.jpg" class="wp-image-6467" height="768" /></a>Back: Ahmed Almheiri, Juan Maldacena, John Martinis, Aron Wall.  Front: Geoff Penington, me, Daniel Harlow.  Thanks to Michelle Simmons for the photo.</figure>



<p>I also had the following exchange at my birthday dinner:</p>



<p><strong>Physicist:</strong> So I don’t get this, Scott. Are you a physicist who studied computer science, or a computer scientist who studied physics?</p>



<p><strong>Me:</strong> I’m a computer scientist who studied computer science.</p>



<p><strong>Physicist:</strong> But then you…</p>



<p><strong>Me:</strong> Yeah, at some point I learned what a boson was, in order to invent BosonSampling.</p>



<p><strong>Physicist:</strong> And your courses in physics…</p>



<p><strong>Me:</strong> They ended at thermodynamics. I couldn’t handle PDEs.</p>



<p><strong>Physicist:</strong> What are the units of h-bar?</p>



<p><strong>Me:</strong> Uhh, well, it’s a conversion factor between energy and time. (*)</p>



<p><strong>Physicist:</strong> Good.  What’s the radius of the hydrogen atom?</p>



<p><strong>Me:</strong> Uhh … not sure … maybe something like 10<sup>-15</sup> meters?</p>



<p><strong>Physicist:</strong> OK fine, he’s not one of us.</p>



<p>(The answer, it turns out, is more like 10<sup>-10</sup> meters. I’d stupidly substituted the radius of the <em>nucleus</em>—or, y’know, a positively-charged hydrogen <em>ion</em>, i.e. proton. In my partial defense, I was massively jetlagged and at most 10% conscious.)</p>



<p>(*) Actually h-bar is a conversion factor between energy and <em>1/time</em>, i.e. frequency, but the physicist accepted this answer.</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p>Anyway, I look forward to attending more workshops this summer, seeing more colleagues who I hadn’t seen since before COVID, and talking more science … including branching out in some new directions that I’ll blog about soon.  It does beat worrying about online trolls.</p></div>







<p class="date">
by Scott <a href="https://scottaaronson.blog/?p=6457"><span class="datestr">at June 09, 2022 08:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://toc4fairness.org/?p=2188">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/fair.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://toc4fairness.org/toc4fairness-seminar-roland-maio/">TOC4Fairness Seminar – Roland Maio</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Date: </strong>Wednesday, June 15th, 2022<br />9:00 am – 10:00 am Pacific Time<br />12:00 pm – 1:00 pm Eastern Time</p>



<figure class="wp-block-image size-large"><img width="800" alt="" src="https://i0.wp.com/toc4fairness.org/wp-content/uploads/2022/06/bruce-park-roland.jpg?resize=800%2C459&amp;ssl=1" class="wp-image-2190" height="459" /></figure>



<p><strong>Location: </strong>Weekly Seminar, Zoom </p>



<h3 id="title-structural-racism-white-supremacy-and-the-2-edged-sword-of-data-health-inequities-and-the-embodied-truths-sharply-exposed-by-covid-19-in-context"><strong><a href="Title: Allocating Opportunities in a Dynamic WorldAbstract: I  will speak about the need for considering dynamic changes to the  environment in response to allocational policies. As an example, I will  introduce a sequential model for allocating opportunities, such as  higher education, in a society that exhibits bottlenecks in  socio-economic mobility. I will discuss how the problem of optimal  allocation reflects a trade-off between the benefits conferred by the  opportunities in the current generation and the potential to elevate the  socioeconomic status of recipients, shaping the composition of future  generations in ways that can benefit further from the opportunities. Our  results show how optimal allocations in this model arise as solutions  to continuous optimization problems over multiple generations, and in  general, these optimal solutions can favor recipients of low  socioeconomic status over slightly higher-performing individuals of high  socioeconomic status — a form of socioeconomic affirmative action that  the society in our model discovers in the pursuit of purely  payoff-maximizing goals. I will conclude with directions for future  work.Bio: Hoda Heidari is an Assistant  Professor in Machine Learning and Societal Computing at the School of  Computer Science, Carnegie Mellon University. Her research is broadly  concerned with the social, ethical, and economic implications of  Artificial Intelligence. In particular, her research addresses issues of  unfairness and opaqueness through Machine Learning. Her work in this  area has won a best-paper award at the ACM Conference on Fairness,  Accountability, and Transparency (FAccT) and an exemplary track award at  the ACM Conference on Economics and Computation (EC). She has organized  several scholarly events on topics related to Responsible and  Trustworthy AI, including a tutorial at the Web Conference (WWW) and  several workshops at the Neural and Information Processing Systems  (NeurIPS) conference and the International Conference on Learning  Representations (ICLR). Dr. Heidari completed her doctoral studies in  Computer and Information Science at the University of Pennsylvania. She  holds an M.Sc. degree in Statistics from the Wharton School of  Business.  Before joining Carnegie Mellon as a faculty member, she was a  postdoctoral scholar at the Machine Learning Institute of ETH Zürich,  followed by a year at the Artificial Intelligence, Policy, and Practice  (AIPP) initiative at Cornell University.">Title: </a></strong><a href="Title: Allocating Opportunities in a Dynamic WorldAbstract: I  will speak about the need for considering dynamic changes to the  environment in response to allocational policies. As an example, I will  introduce a sequential model for allocating opportunities, such as  higher education, in a society that exhibits bottlenecks in  socio-economic mobility. I will discuss how the problem of optimal  allocation reflects a trade-off between the benefits conferred by the  opportunities in the current generation and the potential to elevate the  socioeconomic status of recipients, shaping the composition of future  generations in ways that can benefit further from the opportunities. Our  results show how optimal allocations in this model arise as solutions  to continuous optimization problems over multiple generations, and in  general, these optimal solutions can favor recipients of low  socioeconomic status over slightly higher-performing individuals of high  socioeconomic status — a form of socioeconomic affirmative action that  the society in our model discovers in the pursuit of purely  payoff-maximizing goals. I will conclude with directions for future  work.Bio: Hoda Heidari is an Assistant  Professor in Machine Learning and Societal Computing at the School of  Computer Science, Carnegie Mellon University. Her research is broadly  concerned with the social, ethical, and economic implications of  Artificial Intelligence. In particular, her research addresses issues of  unfairness and opaqueness through Machine Learning. Her work in this  area has won a best-paper award at the ACM Conference on Fairness,  Accountability, and Transparency (FAccT) and an exemplary track award at  the ACM Conference on Economics and Computation (EC). She has organized  several scholarly events on topics related to Responsible and  Trustworthy AI, including a tutorial at the Web Conference (WWW) and  several workshops at the Neural and Information Processing Systems  (NeurIPS) conference and the International Conference on Learning  Representations (ICLR). Dr. Heidari completed her doctoral studies in  Computer and Information Science at the University of Pennsylvania. She  holds an M.Sc. degree in Statistics from the Wharton School of  Business.  Before joining Carnegie Mellon as a faculty member, she was a  postdoctoral scholar at the Machine Learning Institute of ETH Zürich,  followed by a year at the Artificial Intelligence, Policy, and Practice  (AIPP) initiative at Cornell University."> </a>Secrets, Adversaries, Incentives, and Composition in Algorithmic Fairness</h3>



<h3 id="abstract"><strong>Abstract:</strong></h3>



<p>A central goal of algorithmic fairness is to build systems with fairness properties that compose gracefully. A major effort towards this goal in fair machine learning has been the development of <em>fair representations</em> which guarantee demographic parity under sequential composition by removing group membership information from the data (i.e. by imposing a <em>demographic secrecy</em> constraint). This approach models all data consumers as utterly malicious adversaries whose sole objective is to be as unfair as possible (i.e. maximally violate demographic parity)—any other possible objective (i.e. incentive) that a data consumer may have is dismissed and ignored. In this talk, I describe joint work with Augustin Chaintreau, in which we elucidate limitations of demographically secret fair representations and propose a fresh approach to potentially overcome them by incorporating information about parties’ incentives into fairness interventions. We show that in a stylized model, it is possible to relax demographic secrecy to obtain <em>incentive-compatible representations</em>, where rational parties obtain exponentially greater utilities vis-à-vis any demographically secret representation and satisfy demographic parity. These substantial gains are recovered not from the well-known <em>cost of fairness</em>, but rather from a <em>cost of demographic secrecy</em> which we formalize and quantify for the first time. We further show that the sequential composition property of demographically secret representations is not robust to aggregation. Our results contribute to further understanding the challenges of fair composition while simultaneously suggesting that incentives may be an important and flexible tool for addressing or even overcoming those challenges.</p>



<h3 id="bio"><strong>Bio:</strong></h3>



<p>Roland Maio is a fourth year Computer Science PhD student at Columbia University advised by Augustin Chaintreau. Roland works on algorithmic fairness and CS ethics. His work has been supported by an NSF fellowship.<br /></p></div>







<p class="date">
by jubaziani <a href="https://toc4fairness.org/toc4fairness-seminar-roland-maio/"><span class="datestr">at June 09, 2022 04:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/086">TR22-086 |  Extremely Efficient Constructions of Hash Functions, with Applications to Hardness Magnification and PRFs | 

	Jiatu Li, 

	Tianqi Yang, 

	Lijie Chen</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a recent work, Fan, Li, and Yang (STOC 2022) constructed a family of almost-universal hash functions such that each function in the family is computable by $(2n + o(n))$-gate circuits of fan-in $2$ over the $B_2$ basis. Applying this family, they established the existence of pseudorandom functions computable by circuits of the same complexity, under the standard assumption that OWFs exist. However, a major disadvantage of the hash family construction by Fan, Li, and Yang (STOC 2022) is that it requires a seed length of $\text{poly}(n)$, which limits its potential applications. 
        
We address this issue by giving an improved construction of almost-universal hash functions with seed length $\text{polylog}(n)$, such that each function in the family is computable with $\text{POLYLOGTIME}$-uniform $(2n + o(n))$-gate circuits. Our new construction has the following applications in both complexity theory and cryptography.
        
* ($\textbf{Hardness magnification}$). Let $\alpha : \mathbb{N} \rightarrow \mathbb{N}$ be any function such that $\alpha(n) \leq \log n / \log \log n$. We show that if there is an $n^{\alpha(n)}$-sparse $\textbf{NP}$ language that does not have probabilistic circuits of $2n + O(n/\log\log n)$ gates, then we have (1) $\textbf{NTIME}[2^n] \not\subseteq \textbf{SIZE} \left[2^{n^{1/5}}\right]$ and (2) $\textbf{NP} \not\subseteq \textbf{SIZE}[n^k]$ for every constant $k$. Complementing this magnification phenomenon, we present an $O(n)$-sparse language in $\textbf{P}$ which requires probabilistic circuits of size at least $2n - 2$. This is the first result in hardness magnification showing that even a \emph{sub-linear additive} improvement on known circuit size lower bounds would imply $\textbf{NEXP} \not\subseteq \textbf{P}_{/\text{poly}}$. 

Following Chen, Jin, and Williams (STOC 2020), we also establish a sharp threshold for \textbf{explicit obstructions}: we give an explict obstruction against $(2n-2)$-size circuits, and prove that a sub-linear additive improvement on the circuit size would imply (1) $\textbf{DTIME}[2^n] \not\subseteq \textbf{SIZE} \left[2^{n^{1/5}}\right]$ and (2) $\textbf{P} \not\subseteq \textbf{SIZE}[n^k]$ for every constant $k$.

* ($\textbf{Extremely efficient construction of pseudorandom functions}$). Assuming that one of integer factoring, decisional Diffie-Hellman, or ring learning-with-errors is sub-exponentially hard, we show the existence of pseudorandom functions computable by $\text{POLYLOGTIME}$-uniform $\textbf{AC}^0[2]$ circuits with $2n + o(n)$ wires, with key length $\text{polylog}(n)$. We also show that PRFs computable by $\text{POLYLOGTIME}$-uniform $B_2$ circuits of $2n + o(n)$ gates follows from the existence of sub-exponentially secure one-way functions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/086"><span class="datestr">at June 09, 2022 12:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4635">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2022/06/09/workshop-in-milan-next-week/">Workshop in Milan Next Week</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>As <a href="https://lucatrevisan.wordpress.com/2022/05/10/stoc-2022-and-other-theory-events/">previously announced</a>, next week Alon Rosen and I are organizing a workshop at Bocconi, which will actually be the union of two  workshops, one on <em>Recent Advances in Cryptography</em> and one on <em>Spectral and Convex Optimization Techniques in Graph Algorithms</em>. Here is the <a href="https://lucatrevisan.github.io/mtw.html">program</a>. In short:</p>



<ul><li>where: Bocconi University’s <a href="https://goo.gl/maps/TmBQg7g43CiKeNb18">Roentgen Building</a> (via Roentgen 1, Milano), Room AS01</li><li>when: June 15-18</li><li>what: <a href="https://lucatrevisan.github.io/mtw.html">talks</a> on cryptography and graph algorithms, including two hours devoted to Max Flow in nearly-linear time</li><li>how: <a href="https://events.unibocconi.eu/index.php?key=ev2022050043">register</a> for free</li></ul></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2022/06/09/workshop-in-milan-next-week/"><span class="datestr">at June 09, 2022 12:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2022-06-09-phase-king-via-gradecast/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2022-06-09-phase-king-via-gradecast/">Phase-King through the lens of Gradecast: A simple unauthenticated synchronous Byzantine Agreement protocol</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this post we overview a simple unauthenticated synchronous Byzantine Agreement protocol that is based on the Phase-King protocol of Berman, Garay, and Perry 1989-92. We refer also to Jonathan Katz’s excellent write-up on this same protocol from 2013. We offer a modern approach that decomposes the Phase-King protocol into...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2022-06-09-phase-king-via-gradecast/"><span class="datestr">at June 09, 2022 11:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/085">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/085">TR22-085 |  A Note on Lower Bounds for Monotone Multilinear Boolean Circuits | 

	Andrzej Lingas</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A monotone Boolean circuit is a restriction of a Boolean circuit
  allowing for the use of disjunctions, conjunctions, the Boolean
  constants, and the input variables.  A monotone Boolean circuit is
  multilinear if for any AND gate the two input functions have no
  variable in common.  We show that the known lower bounds on the size
  of monotone arithmetic circuits for multivariate polynomials that
  are sums of monomials consisting of $k$ distinct variables yield the
  analogous lower bounds divided by $O(k^2)$ on the size of monotone
  multilinear Boolean circuits computing the Boolean functions
  represented by the corresponding multivariate Boolean polynomials.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/085"><span class="datestr">at June 09, 2022 09:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1679">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/2022/06/news-for-may-2022/">News for May 2022</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The crazy numbers from last month are not quite gone: we have five papers this month, not bad at all! </p>



<p>Codes! Distributed computing! Probability distributions!</p>



<p><strong>Improved local testing for multiplicity codes</strong>, by Dan Karliner and Amnon Ta-Shma (<a href="https://arxiv.org/abs/2204.14137">ECCC</a>). Take the Reed–Muller code with parameters \(m, d\), whose codewords are the evaluation tables of all degree-\(m\) polynomials over \(\mathbb{F}^d\). RM codes are great, they are everywhere, and they are<em> locally testable</em>: one can test whether a given input \(x\) is a valid codeword (or far from every codeword) with only very few queries to \(x\). Now, take the <em>multiplicity code</em>: instead of just the evaluation table of the polynomial themselves, a codeword includes the evaluations of all its derivatives, up to order \(s\). These beasts generalize RM codes: are they <em>also</em> locally testable? Yes they are! And this work improves on our understanding of this aspect, by providing better bounds on the locality (how few queries are necessary to test), and simplifies the argument from previous work by Karliner, Salama, and Ta-Shma (2022).</p>



<p><strong>Overcoming Congestion in Distributed Coloring,</strong> by Magnús M. Halldórsson, Alexandre Nolin, Tigran Tonoyan (<a href="https://arxiv.org/abs/2205.14478">arXiv</a>). Two of the main distributed computing models, LOCAL and CONGEST, differ in how they model the bandwidth constraints. In the former, nodes can send messages of arbitrary size, and the limiting quantity is the number of rounds of communications; while in the latter, each node can only send a logarithmic number of bits at each round. This paper introduces a new technique that allows for communication-efficient distributed (coordinated) sampling, which as a direct applications enables porting several LOCAL algorithms to the CONGEST model at a small cost: for instance, \((\Delta+1)\)-List Coloring. This new technique also has applications beyond these distributed models, to graph property testing – in a slightly non-standard setting where we define farness from the property in a “local” sense (detect vertices or edges which contribute to many violations, i.e., are “locally far” from the property considered).</p>



<p><strong>Robust Testing in High-Dimensional Sparse Models,</strong> by Anand Jerry George and Clément L. Canonne (<a href="https://arxiv.org/abs/2205.07488">arXiv</a>). In the Gaussian mean testing problem, you are given samples from a high-dimensional Gaussian \(N(\mu, I_d)\), where \(\mu\) is either zero or has \(\ell_2\) norm greater than \(\varepsilon\), and you want to decide which of the two holds. This “mean testing” equivalent (due to, erm, “standard facts”) to testing in total variation distance, and captures the setting where one wantss to figure out whether an underlying signal \(\mu\), subject to white noise, is null or significant. Now, what if this $\mu$ was promised to be \(s\)-sparse? Can we test more efficiently? But what if a small fraction of the samples were arbitrarily corrupted — how much harder does the testing task become? For some related tasks, it is known that being robust against adversarial corruptions makes testing as hard as learning… This paper addresses this “robust sparse mean testing” question, providing matching upper and lower bounds; as well as the related question of (robust, sparse) linear regression.</p>



<p><strong>Sequential algorithms for testing identity and closeness of distributions,</strong> by Omar Fawzi, Nicolas Flammarion, Aurélien Garivier, and Aadil Oufkir (<a href="https://arxiv.org/abs/2205.06069">arXiv</a>). Consider the two “usual suspects” of distribution testing, <em>identity</em> and <em>closeness</em> testing, where we must test if an unknown distribution is equal to some reference one or \(\varepsilon\)-far (in total variation distance) from it; or, the same thing, but with two unknown distributions (no reference one). These are, by now, quite well understood… but the algorithms for them take a worst-case number of samples, function of the distance parameter \(\varepsilon\). But if the two distributions are much further apart than \(\varepsilon\), fewer samples should be required! This is the focus of this paper, showing that with a sequential test one can achieve this type of guarantees: a number of samples which, in the “far” case, depends on the actual distance, not on its worst-case lower bound \(\varepsilon\). One could achieve this by combining known algorithms with a “doubling search;” however, this still would lose some constant factors in the sample complexity. The authors provide sequential tests which improve on this “doubling search technique” by constant factors, and back this up with empirical evaluations of their algorithms.</p>



<p><strong>Estimation of Entropy in Constant Space with Improved Sample Complexity,</strong> by Maryam Aliakbarpour, Andrew McGregor, Jelani Nelson, and Erik Waingarten (<a href="https://arxiv.org/abs/2205.09804">arXiv</a>). Suppose that, given samples from an unknown distribution \(p\) over \(n\) elements, your task is to estimate its (Shannon) entropy \(H(p)\) up to \(\pm\Delta\). You’re in luck! We know that \(\Theta(n/(\Delta\log n)+ (\log^2 n)/\Delta^2)\) samples are necessary and efficient. <em>But what if you had to do that under strict memory constraints? </em>Say, using only a <em>constant</em> number of words of memory? Previous work by Acharya, Bhadane, Indyk, and Sun (2019) shows that it is still possible, but the number of samples required shoots up, with their algorithm now requiring (up to polylog factors) \(n/\Delta^3\) samples. This works improves upon the dependence on \(\Delta\), providing a constant-memory algorithm with sample complexity \(O(n/\Delta^2 \cdot \log^4(1/\Delta))\); they further conjecture this to be optimal, up to the polylog factors.</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/2022/06/news-for-may-2022/"><span class="datestr">at June 07, 2022 05:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
