<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 15, 2020 11:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.07030">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.07030">A Polynomial-Time Algorithm for Optimization of Quadratic Pseudo-Boolean Functions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Juan Ignacio Mulero-Martínez <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.07030">PDF</a><br /><b>Abstract: </b>We develop a polynomial-time algorithm to minimize pseudo-Boolean functions.
The computational complexity is $O\left( n^{\frac{15}{2}}\right) $, although
very conservative, it is sufficient to prove that this minimization problem is
in the class $P$. A direct application of the algorithm is the 3-SAT problem,
which is also guaranteed to be in the class $P$ with a computational complexity
of order $O\left( n^{\frac{45}{2}}\right) $. The algorithm was implemented in
MATLAB and checked by generating one million matrices of arbitrary dimension up
to 24 with random entries in the range $\left[ -50,50\right] $. All the
experiments were successful.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.07030"><span class="datestr">at May 15, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06998">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06998">Plane-Activated Mapped Microstructure</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Youngquist:Jeremy.html">Jeremy Youngquist</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peters:J=ouml=rg.html">Jörg Peters</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sitharam:Meera.html">Meera Sitharam</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06998">PDF</a><br /><b>Abstract: </b>Querying and interacting with models of massive material micro-structure
requires localized on-demand generation of the micro-structure since the
full-scale storing and retrieving is cost prohibitive. When the micro-structure
is efficiently represented as the image of a canonical structure under a
non-linear space deformation to allow it to conform to curved shape, the
additional challenge is to relate the query of the mapped micro-structure back
to its canonical structure. This paper presents an efficient algorithm to pull
back a mapped micro-structure to a partition of the canonical domain structure
into boxes and only activates boxes whose image is likely intersected by a
plane. The active boxes are organized into a forest whose trees are traversed
depth first to generate mapped micro-structure only of the active boxes. The
traversal supports, for example, 3D print slice generation in additive
manufacturing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06998"><span class="datestr">at May 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06827">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06827">Shortest Distances as Enumeration Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casel:Katrin.html">Katrin Casel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friedrich:Tobias.html">Tobias Friedrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neubert:Stefan.html">Stefan Neubert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Markus_L=.html">Markus L. Schmid</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06827">PDF</a><br /><b>Abstract: </b>We investigate the single source shortest distance (SSSD) and all pairs
shortest distance (APSD) problems as enumeration problems (on unweighted and
integer weighted graphs), meaning that the shortest distances are produced and
listed one by one without repetition. The performance is measured in the RAM
model of computation with respect to preprocessing time and delay, i.e., the
maximum time that elapses between two consecutive outputs. This point of view
reveals that specific types of output (e.g., excluding non-reachability
information, excluding the self-distances) and the order of enumeration (e.g.,
sorted by distance, row-wise w.r.t. the distance matrix) have a huge impact on
the complexity of APSD while they appear to have no effect on SSSD.
</p>
<p>In particular, we show for APSD that enumeration without output restrictions
is possible with delay in the order of the average degree. Excluding
non-reachability information, or requesting the output to be sorted by
distance, increases this delay to the order of the maximum degree. Further, for
weighted graphs, a delay in the order of the average degree is also not
possible without preprocessing or considering self-distances as output. In
contrast, for SSSD we find that a delay in the order of the maximum degree
without preprocessing is attainable and unavoidable for any of these
requirements.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06827"><span class="datestr">at May 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06672">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06672">Approximating p-Mean Curve of Large Data-Sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aghamolaei:Sepideh.html">Sepideh Aghamolaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghodsi:Mohammad.html">Mohammad Ghodsi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06672">PDF</a><br /><b>Abstract: </b>Given $p$, $k$ and a set of polygonal curves $P_1,\ldots,P_L$, the $p$-mean
curve $M$ of $P_1,\ldots,P_L$ is the curve with at most $k$ vertices that
minimizes the $L_p$ norm of the vector of Fr\'echet distances between each
$P_i$ and $M$. Also, the $p$-mean curve is the cluster representative (center)
of $L_p$-based clusterings such as $k$-center, $k$-medians, and $k$-means.
</p>
<p>For $p\rightarrow \infty$, this problem is known to be NP-hard, with lower
bound $2.25-\epsilon$ on its approximation factor for any $\epsilon&gt;0$.
</p>
<p>By relaxing the number of vertices to $O(k)$, we were able to get constant
factor approximation algorithms for $p$-mean curve with $p=O(1)$ and
$p\rightarrow\infty$, for curves with few changes in their directions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06672"><span class="datestr">at May 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06665">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06665">Scaling Blockchains Without Giving up Decentralization and Security</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Gianmaria Del Monte, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pennino:Diego.html">Diego Pennino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pizzonia:Maurizio.html">Maurizio Pizzonia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06665">PDF</a><br /><b>Abstract: </b>Public blockchains should be able to scale with respect to the number of
nodes and to the transactions load. Despite the large research and experimental
effort, all known approaches turn out to be tradeoffs that sacrifice security
or decentralization to achieve scalability. Actually, the blockchain
scalability trilemma has been informally proposed. This is related to
scalability, security and decentralization, stating that any improvement in one
of these aspects should negatively impact on at least one of the other two
aspects.
</p>
<p>We introduce a new blockchain architecture that scales to arbitrarily high
transactions workload provided that a corresponding proportional increment of
nodes is provided. In this scalability process, no tradeoff on security or
decentralization is required. To the best of our knowledge, this is the first
result of this kind. While our result is currently only theoretic, we believe
that our approach could stimulate significant practical contributions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06665"><span class="datestr">at May 15, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06528">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06528">Distance-2 Coloring in the CONGEST Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Magnus M. Halldorsson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06528">PDF</a><br /><b>Abstract: </b>We give efficient randomized and deterministic distributed algorithms for
computing a distance-$2$ vertex coloring of a graph $G$ in the CONGEST model.
In particular, if $\Delta$ is the maximum degree of $G$, we show that there is
a randomized CONGEST model algorithm to compute a distance-$2$ coloring of $G$
with $\Delta^2+1$ colors in $O(\log\Delta\cdot\log n)$ rounds. Further if the
number of colors is slightly increased to $(1+\epsilon)\Delta^2$ for some
$\epsilon&gt;1/{\rm polylog}(n)$, we show that it is even possible to compute a
distance-$2$ coloring deterministically in polylog$(n)$ time in the CONGEST
model. Finally, we give a $O(\Delta^2 + \log^* n)$-round deterministic CONGEST
algorithm to compute distance-$2$ coloring with $\Delta^2+1$ colors.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06528"><span class="datestr">at May 15, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=435">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/05/14/tcs-talk-wednesday-may-20-mark-bun-boston-university/">TCS+ talk: Wednesday, May 20 — Mark Bun, Boston University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, May 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Mark Bun</strong> from Boston University will speak about “<em>An Equivalence between Private Classification and Online Predictability</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We prove that every concept class with finite Littlestone dimension can be learned by an (approximate) differentially-private algorithm. The converse direction was shown in recent work of Alon, Livni, Malliaris, and Moran, STOC ’19. Together these two results show that a class of functions is privately learnable if and only if it is learnable in the mistake-bound model of online learning. To establish our result, we introduce “global stability,” a new notion of algorithmic stability for learning algorithms that we show can always be satisfied when learning classes of finite Littlestone dimension.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/05/14/tcs-talk-wednesday-may-20-mark-bun-boston-university/"><span class="datestr">at May 14, 2020 06:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-05-14-streamlet/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-05-14-streamlet/">Streamlet: A Simple Textbook Blockchain Protocol</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Guest post by Benjamin Chan and Elaine Shi In this post, we describe an extraordinarily simple blockchain protocol called Streamlet. Consensus is a complex problem and has been studied since the 1980s. More recently, blockchain research has spawned many new works aiming for performance and ease-of-implementation. However, simple, understandable protocols...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-05-14-streamlet/"><span class="datestr">at May 14, 2020 05:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1688">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/05/14/pride-and-prejudice-from-research-to-practice/">Pride and Prejudice: From Research to Practice</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Despite (or because of) being a devoted theoretician, I truly enjoy every occasion when theory influences practice. I therefore felt quite a bit of satisfaction when our <a href="https://arxiv.org/abs/1711.08513">rather recent work</a>, in the context of algorithmic fairness (with Úrsula Hébert-Johnson, Michael P. Kim and Guy N. Rothblum), found an application for predicting COVID-19 complications. Researchers in Israel, in collaboration with Israel’s biggest health-care provider, adapted a refined model for predicting flu complications to a model for predicting COVID-19 complications.  At the time, only very limited data from China were available (marginal statistics).  This is where our work came in (following several past empiric studies of the method):  the team applied our algorithm to improve the accuracy of predictions across various subpopulations (as part of an immense research and engineering effort). Now that there is (unfortunately) more data, it seems that the predictor exhibited surprisingly good performance (surprising, due to the poor training data).  See a <a href="https://www.medrxiv.org/content/10.1101/2020.04.23.20076976v1">manuscript</a> here, an interview <a href="https://www.youtube.com/watch?v=r_alyuZULYI">here</a> and a more technical talk <a href="https://www.youtube.com/watch?v=weaRmSVA3yM">here</a> (starting at minute 36 roughly). The predictor was applied with the appropriate cautiousness to inform and advise patients.</p>
<p>But this is also an example of the gravity of decisions by researchers and software developers. Taking it to extreme, imagine a predictor that is used to determine which patients are denied treatment in an overwhelmed hospital. The booming research area of algorithmic fairness sees a very short turnover from research ideas (in many areas) to deployment. In an ideal world, it would have been much better to first have a couple of decades to develop the computational foundations of algorithmic fairness, before the practical need arose. But in the real world, the huge scale of algorithmic decision making creates immense demand for solutions. Industry, as well as policy and law makers are unlikely to wait decades or even years, nor is it clear that they should. From my perspective, this reality underscores the urgency for <em>principled</em> and <em>deliberate</em> research – rather than <em>hasty</em> research – continuously developing the foundations of algorithmic fairness and offering answers to real-world challenges.</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/05/14/pride-and-prejudice-from-research-to-practice/"><span class="datestr">at May 14, 2020 05:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1307">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2020/05/14/cra-and-ccc-announce-computing-innovation-fellows-2020/">CRA and CCC announce Computing Innovation Fellows 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Computing Research Association (CRA) and Computing Community Consortium (CCC) have announced a new CI Fellows program that will offer 2 year postdoctoral opportunities in computing starting Fall’20.</p>
<p>The deadline for application is yet to be announced but will be around <strong>mid-June 2020</strong>, with decisions being made around mid-July 2020 for positions beginning this fall or winter. We will update this post once a deadline is announced. In the meantime, further details can be found at <a href="https://cifellows2020.org/" rel="nofollow">https://cifellows2020.org/</a>.</p></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2020/05/14/cra-and-ccc-announce-computing-innovation-fellows-2020/"><span class="datestr">at May 14, 2020 04:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1304">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2020/05/14/call-for-nominations-for-talg-new-editor-in-chief/">Call for Nominations for TALG new Editor-in-Chief</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Prof. <span class="il">David</span> <span class="il">Shmoys</span> is chairing the committee to identify a new Editor-in-Chief for ACM Trans. on Algorithms.  The deadline for nominations is <strong>Jun 8th</strong>. Please see details below.</p>
<p>ACM TALG (webpage: <a href="http://talg.acm.org/" rel="nofollow">http://talg.acm.org/</a>) publishes original research of the highest quality dealing with algorithms. It is a peer-reviewed journal, appearing quarterly. Specific areas of computation covered by the journal are listed at <a href="http://talg.acm.org/Aims.html" rel="nofollow">http://talg.acm.org/Aims.html</a>.</p>
<p>We are looking for a well-established person with a strong record of research achievements and service, and with a vision for the future of the field. The term of appointment is three years, to begin late summer 2020, with the possibility of renewal for a second term. The editor-in-chief is responsible for faithfully executing the editorial charter of the journal yet should be proactive in adapting the journal and its charter to changes in the field. A description of the duties of the EiC and evaluation criteria can be found at <a href="http://www.acm.org/publications/policies/evaluation" rel="nofollow">http://www.acm.org/publications/policies/evaluation</a>.</p>
<p>The Search Committee members are:<br />
David Eppstein – University of California, Irvine<br />
Anna Karlin – University of Washington<br />
Chris Hankin – Imperial College London – ACM Publications Board Liaison<br />
Dana Randall – Georgia Institute of Technology<br />
David Shmoys – Cornell University – Committee Chair.</p>
<p>All nominees, including self-nominees, should send a CV and a Vision Statement for TALG (at least one page), with subject header “EiC nomination” to the committee chair – david.shmoys@cornell.edu .</p>
<p>The deadline for nominations is Monday, June 8, 2020 at 11:59 p.m. (EST).</p></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2020/05/14/call-for-nominations-for-talg-new-editor-in-chief/"><span class="datestr">at May 14, 2020 04:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4389">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/05/14/spectral-sparsification-of-hypergraphs/">Spectral Sparsification of Hypergraphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 In this post we will construct a “spectral sparsifier” of a given hypergraph in a way that is similar to how Spielman and Srivastava construct spectral graph sparsifiers. We will assign a probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> to each hyperedge, we will sample each hyperedge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" />, and we will weigh it by <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" /> if selected. We will then bound the “spectral error” of this construction in terms of the supremum of a Gaussian process using Talagrand’s comparison inequality and finally bound the supremum of the Gaussian process (which will involve matrices) using matrix Chernoff bounds. This is <a href="https://arxiv.org/abs/1905.01495">joint work with Nikhil Bansal and Ola Svensson</a>.</p>
<p>
<span id="more-4389"></span></p>
<p>
</p><p><b>1. Hypergraph Sparsifiers </b></p>
<p></p><p>
An (undirected) hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%3D+%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H= (V,E)}" class="latex" title="{H= (V,E)}" /> is a collection <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> of subsets <img src="https://s0.wp.com/latex.php?latex=%7Be+%5Csubseteq+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e \subseteq V}" class="latex" title="{e \subseteq V}" />, called hyperedges. A graph is the special case in which each set <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> has cardinality 2. For simplicity we will talk only about <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />-uniform hypergraphs, that is hypergraphs in which all hyperedges have the same cardinality <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> (the arguments below would work also in the non-uniform case in which all hyperedges have cardinality <em>at most</em> <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />). Hyperedges may have weights.</p>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> is a subset of vertices, a hyperedge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is <em>cut</em> by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> if <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> has non-empty intersection with both <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BV-S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V-S}" class="latex" title="{V-S}" />. We call <img src="https://s0.wp.com/latex.php?latex=%7Bcut_H%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{cut_H(S)}" class="latex" title="{cut_H(S)}" /> the number of hyperedges of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> cut by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, or the total weight of such hyperedges if <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is a weighted hypergraph.</p>
<p>
We can then generalize the notion of Benczur-Karger sparsification, and say that <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> is a cut sparsifier of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> with error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> if <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> have the same vertex set <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> and</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+S%5Csubseteq+V%3A+%5C+%5C+%5C+1-%5Cepsilon+%5Cleq+%5Cfrac%7Bcut_%7BH%27%7D%28S%29%7D%7Bcut_%7BH%7D%28S%29%7D+%5Cleq+1+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall S\subseteq V: \ \ \ 1-\epsilon \leq \frac{cut_{H'}(S)}{cut_{H}(S)} \leq 1 + \epsilon " class="latex" title="\displaystyle  \forall S\subseteq V: \ \ \ 1-\epsilon \leq \frac{cut_{H'}(S)}{cut_{H}(S)} \leq 1 + \epsilon " /></p>
<p>
Kogan and Krauthgamer show that every <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />-uniform hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> admits a cut sparsifier of error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> with only <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n+%28r+%2B+%5Clog+n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n (r + \log n))}" class="latex" title="{O(\epsilon^{-2} n (r + \log n))}" /> weighted hyperedges. They are able to extend the argument of Benczur and Karger to hypergraphs, including arguing that there are few sparse cuts. They assign a probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> to each hyperedge, sample it with that probability, weighing it <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" /> if selected, and then use a union bound and Chernoff bounds to argue that all cuts are preserved.</p>
<p>
Anand Louis has introduced a <a href="https://dl.acm.org/doi/abs/10.1145/2746539.2746555">notion of hypergraph Laplacian</a> in the following way. The Laplacian quadratic form of a hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is a function <img src="https://s0.wp.com/latex.php?latex=%7BQ_H+%3A+%7B%5Cmathbb+R%7D%5EV+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_H : {\mathbb R}^V \rightarrow {\mathbb R}}" class="latex" title="{Q_H : {\mathbb R}^V \rightarrow {\mathbb R}}" /> defined as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_H%28x%29+%3D+%5Csum_%7Be%5Cin+E%7D+w%28e%29+%5C+%5Cmax_%7Ba%2Cb%5Cin+e%7D+%5C+%28x_a+-+x_b%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  Q_H(x) = \sum_{e\in E} w(e) \ \max_{a,b\in e} \ (x_a - x_b)^2 " class="latex" title="\displaystyle  Q_H(x) = \sum_{e\in E} w(e) \ \max_{a,b\in e} \ (x_a - x_b)^2 " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bw%28e%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w(e)}" class="latex" title="{w(e)}" /> is the weight of the hyperedge <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" />, or 1 if the hypergraph is unweighted.</p>
<p>
This definition has the motivation that it recovers the Laplacian quadratic form <img src="https://s0.wp.com/latex.php?latex=%7BQ_G%28x%29+%3D+x%5ET+L_Gx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_G(x) = x^T L_Gx}" class="latex" title="{Q_G(x) = x^T L_Gx}" /> in the case of graphs, and that if <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is the indicator of a set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> then <img src="https://s0.wp.com/latex.php?latex=%7BQ_H%28x%29+%3D+cut_H%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_H(x) = cut_H(S)}" class="latex" title="{Q_H(x) = cut_H(S)}" />. Furthermore, one can define “eigenvalues” and “eigenvectors” of this hypergraph Laplacian and recover a Cheeger inequality and even <a href="https://dl.acm.org/doi/abs/10.1145/3178123">higher-order Cheeger inequalities</a>.</p>
<p>
So it seems interesting to consider the following notion of sparsification: a hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> is a spectral sparsifier of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> with error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> if <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> have the same vertex set and</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%5Cin+%7B%5Cmathbb+R%7D%5EV+%5C+%5C+%5C+1-%5Cepsilon+%5Cleq+%5Cfrac%7BQ_%7BH%27%7D%28x%29%7D%7BQ_%7BH%7D%28x%29%7D+%5Cleq+1+%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall x\in {\mathbb R}^V \ \ \ 1-\epsilon \leq \frac{Q_{H'}(x)}{Q_{H}(x)} \leq 1 + \epsilon " class="latex" title="\displaystyle  \forall x\in {\mathbb R}^V \ \ \ 1-\epsilon \leq \frac{Q_{H'}(x)}{Q_{H}(x)} \leq 1 + \epsilon " /></p>
<p> where, as before, the convention is that <img src="https://s0.wp.com/latex.php?latex=%7B0%2F0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0/0 = 1}" class="latex" title="{0/0 = 1}" />.</p>
<p>
Soma and Yoshida <a href="https://dl.acm.org/doi/10.5555/3310435.3310594">studied this question</a> and gave a construction with <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n%5E3%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n^3\log n)}" class="latex" title="{O(\epsilon^{-2} n^3\log n)}" /> hyperedges. In the rest of this post we will discuss the construction by Nikhil Bansal, Ola Svensson and me, which uses <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+r%5E3+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} r^3 n \log n)}" class="latex" title="{O(\epsilon^{-2} r^3 n \log n)}" /> hyperedges.</p>
<p>
</p><p><b>2. Choosing Probabilities </b></p>
<p></p><p>
Given a hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%3D%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H=(V,E)}" class="latex" title="{H=(V,E)}" />, we can construct a multigraph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> by taking each hyperedge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> and then constructing, in <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, a clique between the vertices of <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" />. Thus, in <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, the edge <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> is repeated as many times (possibly, zero times) as the number of hyperedges <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> that contain both <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />. Another way to think about it is that the Laplacian of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is given by</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_G+%3D+%5Csum_%7Be%5Cin+E%7D+%5Csum_%7Ba%2Cb%5Cin+e%7D+L_%7Ba%2Cb%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_G = \sum_{e\in E} \sum_{a,b\in e} L_{a,b} " class="latex" title="\displaystyle  L_G = \sum_{e\in E} \sum_{a,b\in e} L_{a,b} " /></p>
<p>
where the inner sum is over the <img src="https://s0.wp.com/latex.php?latex=%7B%7Br+%5Cchoose+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{r \choose 2}}" class="latex" title="{{r \choose 2}}" /> unordered pairs <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{a,b\}}" class="latex" title="{\{a,b\}}" />. This graph relates in several interesting ways with <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />. For example, if <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> is a subset of vertices and <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is a hyperedge that is cut by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, then between <img src="https://s0.wp.com/latex.php?latex=%7Br-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r-1}" class="latex" title="{r-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7Br+%5Cchoose+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{r \choose 2}}" class="latex" title="{{r \choose 2}}" /> of the edges of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> derived from <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> are cut by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is not cut by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, then none of the edges derived from <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is cut by <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, so we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+S%5Csubseteq+V%3A+%5C+%5C+%5C+%28r-1%29+%5C+cut_H%28S%29+%5Cleq+cut_G%28S%29+%5Cleq+%7Br+%5Cchoose+2%7D+cut_H%28S%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall S\subseteq V: \ \ \ (r-1) \ cut_H(S) \leq cut_G(S) \leq {r \choose 2} cut_H(S) " class="latex" title="\displaystyle  \forall S\subseteq V: \ \ \ (r-1) \ cut_H(S) \leq cut_G(S) \leq {r \choose 2} cut_H(S) " /></p>
<p>
and, with a bit more work, it is possible to prove similar bounds for the Laplacian quadratic forms</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%5Cin+%7B%5Cmathbb+R%7D%5E+V%3A+%5C+%5C+%5C+%5Cfrac+r2+%5C+Q_H%28x%29+%5Cleq+x%5ET+L_G+x+%5Cleq+%7Br+%5Cchoose+2%7D+Q_H%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall x\in {\mathbb R}^ V: \ \ \ \frac r2 \ Q_H(x) \leq x^T L_G x \leq {r \choose 2} Q_H(x) " class="latex" title="\displaystyle  \forall x\in {\mathbb R}^ V: \ \ \ \frac r2 \ Q_H(x) \leq x^T L_G x \leq {r \choose 2} Q_H(x) " /></p>
<p> This means that if we sparsify <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, say with the Spielman-Srivastava construction, we obtain information about <img src="https://s0.wp.com/latex.php?latex=%7BQ_H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_H}" class="latex" title="{Q_H}" />, up to multiplicative error <img src="https://s0.wp.com/latex.php?latex=%7BO%28r%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(r)}" class="latex" title="{O(r)}" />. Now suppose that, as we sample edges of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> to sparsify it in the Spielman-Srivastava way, we will also pick hyperedges of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> (for example we pick <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> if at least one of its corresponding edges in <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is picked), and we weigh them by the inverse of the probability of being selected. Then we may hope that if the Spielman-Srivastava sparsification of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is tuned to achieve error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2Fr%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon/r^2}" class="latex" title="{\epsilon/r^2}" />, the hypergraph that we obtain will have error at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />. Indeed, this is roughly what happens, and we will be able to prove it by showing that the error in the hypergraph sparsification is dominated by the error in the “Gaussian version” of Spielman-Srivastava described in the previous post.</p>
<p>
So we are going to assign to each hyperedge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> a probability </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_e+%3D+%5Cmin+%5Cleft%5C%7B+1+%2C+B+%5Ccdot+%5Csum_%7Ba%2Cb+%5Cin+e%7D+%7C%7C+L%5E%7B-1%2F2%7D_G+L_%7Ba%2Cb%7D+L%5E%7B-1%2F2%7D+%7C%7C+%5Cright%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p_e = \min \left\{ 1 , B \cdot \sum_{a,b \in e} || L^{-1/2}_G L_{a,b} L^{-1/2} || \right\} " class="latex" title="\displaystyle  p_e = \min \left\{ 1 , B \cdot \sum_{a,b \in e} || L^{-1/2}_G L_{a,b} L^{-1/2} || \right\} " /></p>
<p> where the factor <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> will be chosen later to get the construction to work and <img src="https://s0.wp.com/latex.php?latex=%7BR_%7Ba%2Cb%7D+%3A%3D+%7C%7C+L%5E%7B-1%2F2%7D_G+L_%7Ba%2Cb%7D+L%5E%7B-1%2F2%7D+%7C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R_{a,b} := || L^{-1/2}_G L_{a,b} L^{-1/2} ||}" class="latex" title="{R_{a,b} := || L^{-1/2}_G L_{a,b} L^{-1/2} ||}" /> is the effective resistance of the edge <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />.</p>
<p>
 In fact, as before, it will be helpful to have probabilities that are non-positive powers of two, so we will choose <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> to be a power of two such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin+%5Cleft%5C%7B+1+%2C+B+%5Ccdot+%5Csum_%7Ba%2Cb+%5Cin+e%7D+R_%7Ba%2Cb%7D+%5Cright%5C%7D+%5Cleq+p_e+%5Cleq+%5Cmin+%5Cleft%5C%7B+1+%2C+2B+%5Ccdot+%5Csum_%7Ba%2Cb+%5Cin+e%7D+R_%7Ba%2Cb%7D+%5Cright%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \min \left\{ 1 , B \cdot \sum_{a,b \in e} R_{a,b} \right\} \leq p_e \leq \min \left\{ 1 , 2B \cdot \sum_{a,b \in e} R_{a,b} \right\} " class="latex" title="\displaystyle  \min \left\{ 1 , B \cdot \sum_{a,b \in e} R_{a,b} \right\} \leq p_e \leq \min \left\{ 1 , 2B \cdot \sum_{a,b \in e} R_{a,b} \right\} " /></p>
<p>
We have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_e+p_e+%5Cleq+2+B+%5Csum_%7Be%5Cin+E%7D+%5Csum_%7Ba%2Cb%5Cin+e%7D+R_%7Ba%2Cb%7D+%5Cleq+2B+%5Ccdot+%28n-1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_e p_e \leq 2 B \sum_{e\in E} \sum_{a,b\in e} R_{a,b} \leq 2B \cdot (n-1) " class="latex" title="\displaystyle  \sum_e p_e \leq 2 B \sum_{e\in E} \sum_{a,b\in e} R_{a,b} \leq 2B \cdot (n-1) " /></p>
<p>
Another fact that will become useful later (it will save us a factor of the order of <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> in the number of hyperedges in the construction) is that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax_%7Ba%2Cb+%5Cin+e%7D+R_%7Ba%2Cb%7D+%5Cleq+%5Cfrac+2r+%5Csum_%7Ba%2Cb+%5Cin+e%7D+R_%7Ba%2Cb%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \max_{a,b \in e} R_{a,b} \leq \frac 2r \sum_{a,b \in e} R_{a,b} " class="latex" title="\displaystyle  \max_{a,b \in e} R_{a,b} \leq \frac 2r \sum_{a,b \in e} R_{a,b} " /></p>
<p>
</p><p><b>3. A Discrete Random Process </b></p>
<p></p><p>
Our construction of a hypergraph sparsifier <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> will be to select each <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> independently with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> and, if selected, weigh it by <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" />. Our goal is to find an upper bound in probability, or even in expectation, on </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx+%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+%5C+%5Cleft+%7C+1+-+%5Cfrac%7BQ_%7BH%27%7D%28x%29%7D%7BQ_H%28x%29%7D+%5Cright+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x \in {\mathbb R}^n} \ \ \left | 1 - \frac{Q_{H'}(x)}{Q_H(x)} \right | " class="latex" title="\displaystyle  \sup_{x \in {\mathbb R}^n} \ \ \left | 1 - \frac{Q_{H'}(x)}{Q_H(x)} \right | " /></p>
<p> Recalling that <img src="https://s0.wp.com/latex.php?latex=%7Bx%5ET+L_G+x+%5Cleq+%5Cfrac%7Br%5E2%7D2+Q_H%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^T L_G x \leq \frac{r^2}2 Q_H(x)}" class="latex" title="{x^T L_G x \leq \frac{r^2}2 Q_H(x)}" />, we will study</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx+%3A+x%5ET+L_G+x+%3D+1%7D+%7C+Q_H%28x%29+-+Q_%7BH%27%7D+%28x%29+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x : x^T L_G x = 1} | Q_H(x) - Q_{H'} (x) | " class="latex" title="\displaystyle  \sup_{x : x^T L_G x = 1} | Q_H(x) - Q_{H'} (x) | " /></p>
<p> Because if we can show that the above quantity is at most <img src="https://s0.wp.com/latex.php?latex=%7B2%5Cepsilon+%2Fr%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2\epsilon /r^2}" class="latex" title="{2\epsilon /r^2}" />, then, for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C+Q_H%28x%29+-+Q_%7BH%27%7D+%28x%29+%7C+%5Cleq+%5Cfrac%7B2%5Cepsilon%7D%7Br%5E2%7D+%5C+x%5ET+L_G+x+%5Cleq+%5Cepsilon+Q_H%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  | Q_H(x) - Q_{H'} (x) | \leq \frac{2\epsilon}{r^2} \ x^T L_G x \leq \epsilon Q_H(x) " class="latex" title="\displaystyle  | Q_H(x) - Q_{H'} (x) | \leq \frac{2\epsilon}{r^2} \ x^T L_G x \leq \epsilon Q_H(x) " /></p>
<p> as desired.</p>
<p>
If we define </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_e%28x%29+%3D+%5Cmax_%7Ba%2Cb+%5Cin+E%7D+x%5ET+L_%7Ba%2Cb%7D+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  Q_e(x) = \max_{a,b \in E} x^T L_{a,b} x " class="latex" title="\displaystyle  Q_e(x) = \max_{a,b \in E} x^T L_{a,b} x " /></p>
<p> then we are interested in the supremum in <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5C%7B+x+%3A+x%5ET+L_G+x+%3D+1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = \{ x : x^T L_G x = 1 \}}" class="latex" title="{T = \{ x : x^T L_G x = 1 \}}" /> of </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%29+%3D+Q_H%28x%29+-+Q_%7BH%27%7D+%28x%29+%3D+%5Csum_e+z_e+Q_e+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(x) = Q_H(x) - Q_{H'} (x) = \sum_e z_e Q_e (x) " class="latex" title="\displaystyle  F(x) = Q_H(x) - Q_{H'} (x) = \sum_e z_e Q_e (x) " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bz_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_e}" class="latex" title="{z_e}" /> is a random variable that is equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e-1}" class="latex" title="{1/p_e-1}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> and is equal to <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p_e}" class="latex" title="{1-p_e}" />.</p>
<p>
As before, we will do the construction in rounds. If the smallest probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{-\ell}}" class="latex" title="{2^{-\ell}}" />, then we will have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> rounds. We start with <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%280%29%7D+%3D+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(0)} = H}" class="latex" title="{H^{(0)} = H}" /> and then, at round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, we take all hyperedges <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e \leq 2^{k-1-\ell}}" class="latex" title="{p_e \leq 2^{k-1-\ell}}" /> and, independently for each such hyperedge, we either delete it or we double its weight (with probability 1/2 in each case). The final hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28%5Cell%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(\ell)}}" class="latex" title="{H^{(\ell)}}" /> is distributed like <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" />. We have the processes</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%5E%7B%28k%29%7D%28x%29+%3D+Q_%7BH%5E%7B%28k-1%29%7D%7D%28x%29+-+Q_%7BH%5E%7B%28k%29%7D%7D+%28x%29+%3D+%5Csum_%7Be%5Cin+E_k%7D+r%5E%7B%28k%29%7D_e+w%5E%7B%28k-1%29%7D_e+Q_e+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F^{(k)}(x) = Q_{H^{(k-1)}}(x) - Q_{H^{(k)}} (x) = \sum_{e\in E_k} r^{(k)}_e w^{(k-1)}_e Q_e (x) " class="latex" title="\displaystyle  F^{(k)}(x) = Q_{H^{(k-1)}}(x) - Q_{H^{(k)}} (x) = \sum_{e\in E_k} r^{(k)}_e w^{(k-1)}_e Q_e (x) " /></p>
<p> where the random variables <img src="https://s0.wp.com/latex.php?latex=%7Br%5E%7B%28k%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r^{(k)}_e}" class="latex" title="{r^{(k)}_e}" /> are Rademacher, the weights <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k-1%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k-1)}_e}" class="latex" title="{w^{(k-1)}_e}" /> are either 0 or <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bk-1-%5Cell%7D+%2F+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{k-1-\ell} / p_e}" class="latex" title="{2^{k-1-\ell} / p_e}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BE_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_k}" class="latex" title="{E_k}" /> is the set of edges that are “active” in round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, that is, the set of hyperedges <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e \leq 2^{k-1-\ell}}" class="latex" title="{p_e \leq 2^{k-1-\ell}}" />.</p>
<p>
For each hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(k)}}" class="latex" title="{H^{(k)}}" />, we will also consider its associated graph <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(k)}}" class="latex" title="{G^{(k)}}" />, obtained by replacing each hyperedge with a clique. The Laplacian of <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(k)}}" class="latex" title="{G^{(k)}}" /> is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7BG%5E%7B%28k%29%7D%7D+%3D+%5Csum_e+w%5E%7B%28k%29%7D_e+%5Csum_%7Ba%2Cb%5Cin+e%7D+L_%7Ba%2Cb%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_{G^{(k)}} = \sum_e w^{(k)}_e \sum_{a,b\in e} L_{a,b} " class="latex" title="\displaystyle  L_{G^{(k)}} = \sum_e w^{(k)}_e \sum_{a,b\in e} L_{a,b} " /></p>
<p>
We have the following lemma</p>
<blockquote><p><b>Lemma 1</b> <em> For every outcome of the first <img src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k-1}" class="latex" title="{k-1}" /> rounds such that <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%5E%7B%28k-1%29%7D%7D+%5Cpreceq+2+L_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G^{(k-1)}} \preceq 2 L_G}" class="latex" title="{L_{G^{(k-1)}} \preceq 2 L_G}" />, there is a probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-1/n}" class="latex" title="{1-1/n}" /> over the randomness of the <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />-th round that </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1%7D+%7C+F%5E%7B%28k%29%7D+%28x%29+%7C+%5Cleq+O+%5Cleft%28+%5Csqrt%7B2%5E%7Bk-%5Cell%7D+%5Cfrac+%7B+%5Clog+n%7D%7BBr%7D+%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1} | F^{(k)} (x) | \leq O \left( \sqrt{2^{k-\ell} \frac { \log n}{Br} } \right) " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1} | F^{(k)} (x) | \leq O \left( \sqrt{2^{k-\ell} \frac { \log n}{Br} } \right) " /></p>
<p> and that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D+%7D+%5Cpreceq+O+%5Cleft%28+%5Csqrt%7B2%5E%7Bk-%5Cell%7D+%5Cfrac+%7B+%5Clog+n%7D%7BB%7D+%7D+%5C+%5Cright%29+%5Ccdot+L_G+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_{G^{(k)}} - L_{G^{(k-1)} } \preceq O \left( \sqrt{2^{k-\ell} \frac { \log n}{B} } \ \right) \cdot L_G " class="latex" title="\displaystyle  L_{G^{(k)}} - L_{G^{(k-1)} } \preceq O \left( \sqrt{2^{k-\ell} \frac { \log n}{B} } \ \right) \cdot L_G " /></p>
</em><p><em> </em></p></blockquote>
<p> This means that we can take <img src="https://s0.wp.com/latex.php?latex=%7BB+%3D+O%28%5Cepsilon%5E%7B-2%7D+r%5E3%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B = O(\epsilon^{-2} r^3\log n)}" class="latex" title="{B = O(\epsilon^{-2} r^3\log n)}" /> and apply the above lemma inductively to argue that we have a high probability that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csup_%7Bx%5Cin+T%7D+%7CF%28x%29+%7C+%5Cleq+2%5Cepsilon+%2Fr%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sup_{x\in T} |F(x) | \leq 2\epsilon /r^2}" class="latex" title="{\sup_{x\in T} |F(x) | \leq 2\epsilon /r^2}" />, and so we get a hypergraph spectral sparsifier with error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+r%5E3+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} r^3 n \log n)}" class="latex" title="{O(\epsilon^{-2} r^3 n \log n)}" /> hyperedges. </p>
<p>
To prove the Lemma we will define the Gaussian process</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+F%5E%7B%28k%29%7D+%28x%29+%3D+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%5Cin+e%7D+g%5E%7B%28k%29%7D_%7Be%2Ca%2Cb%7D+%5C+x%5ET+L_%7Ba%2Cb%7D+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \hat F^{(k)} (x) = \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ x^T L_{a,b} x " class="latex" title="\displaystyle  \hat F^{(k)} (x) = \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ x^T L_{a,b} x " /></p>
<p> where the <img src="https://s0.wp.com/latex.php?latex=%7Bg%5E%7B%28k%29%7D_%7Be%2Ca%2Cb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g^{(k)}_{e,a,b}}" class="latex" title="{g^{(k)}_{e,a,b}}" /> are Gaussian. Notice the two differences between <img src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F^{(k)}}" class="latex" title="{F^{(k)}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F^{(k)}}" class="latex" title="{\hat F^{(k)}}" />: we replaced the Rademacher choices with Gaussian choices, and we replaced </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_e%28x%29+%3D+%5Cmax+_%7Ba%2Cb%5Cin+e%7D+%5C+%28x_a+-+x_b%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  Q_e(x) = \max _{a,b\in e} \ (x_a - x_b)^2 " class="latex" title="\displaystyle  Q_e(x) = \max _{a,b\in e} \ (x_a - x_b)^2 " /></p>
<p> with </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Ba%2Cb%5Cin+e%7D+x%5ET+L_%7Ba%2Cb%7D+x+%3D+%5Csum_%7Ba%2Cb+%5Cin+e%7D+%28x_a+-+x_b%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{a,b\in e} x^T L_{a,b} x = \sum_{a,b \in e} (x_a - x_b)^2 " class="latex" title="\displaystyle  \sum_{a,b\in e} x^T L_{a,b} x = \sum_{a,b \in e} (x_a - x_b)^2 " /></p>
<p> Furthermore, we are doing a random choice for each pair within each hyperedge instead of just one random choice per hyperedge.</p>
<blockquote><p><b>Fact 2</b> <em> The random processes <img src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B%28k%29%7D+%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F^{(k)} (x)}" class="latex" title="{F^{(k)} (x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-F%5E%7B%28k%29%7D+%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-F^{(k)} (x)}" class="latex" title="{-F^{(k)} (x)}" /> are <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />-dominated by <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F(x)}" class="latex" title="{\hat F(x)}" />. </em></p></blockquote>
<p></p><p>
<em>Proof:</em>  For every <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y}" class="latex" title="{x,y}" /> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%5E%7B%28k%29%7D+%28x%29+-+F%5E%7B%28k%29%7D%28y%29+%7C%7C%5E2_%7B%5CPsi_2%7D+%3D+O%281%29+%5Ccdot+%5Csum_%7Be%5Cin+E_k%7D+%28+w%5E%7B%28k-1%29%7D_e+Q_e+%28x%29+%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || F^{(k)} (x) - F^{(k)}(y) ||^2_{\Psi_2} = O(1) \cdot \sum_{e\in E_k} ( w^{(k-1)}_e Q_e (x) )^2 " class="latex" title="\displaystyle  || F^{(k)} (x) - F^{(k)}(y) ||^2_{\Psi_2} = O(1) \cdot \sum_{e\in E_k} ( w^{(k-1)}_e Q_e (x) )^2 " /></p>
<p> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%28%5Chat+F%5E%7B%28k%29%7D+%28x%29+-+%5Chat+F%5E%7B%28k%29%7D+%28y%29%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} (\hat F^{(k)} (x) - \hat F^{(k)} (y))^2" class="latex" title="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} (\hat F^{(k)} (x) - \hat F^{(k)} (y))^2" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_%7Be%5Cin+E_k%7D+%28w%5E%7B%28k-1%29%7D_e%29%5E2+%5Csum_%7Ba%2Cb%5Cin+e%7D+%28%28x_a-x_b%29%5E2+-+%28y_a-y_b%29%5E2%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_{e\in E_k} (w^{(k-1)}_e)^2 \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2 " class="latex" title="\displaystyle  = \sum_{e\in E_k} (w^{(k-1)}_e)^2 \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2 " /></p>
<p> To complete the proof, we argue that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28Q_e+%28x%29+-+Q_e+%28y%29%29%5E2+%5Cleq+%5Csum_%7Ba%2Cb%5Cin+e%7D+%28%28x_a-x_b%29%5E2+-+%28y_a-y_b%29%5E2%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (Q_e (x) - Q_e (y))^2 \leq \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2" class="latex" title="\displaystyle  (Q_e (x) - Q_e (y))^2 \leq \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2" /></p>
<p> To verify the above inequality, assume <img src="https://s0.wp.com/latex.php?latex=%7BQ_e%28x%29+%5Cgeq+Q_e%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_e(x) \geq Q_e(y)}" class="latex" title="{Q_e(x) \geq Q_e(y)}" />, otherwise the argument will be symmetric, and call <img src="https://s0.wp.com/latex.php?latex=%7Ba%27%2Cb%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a',b'}" class="latex" title="{a',b'}" /> the maximizer for <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Ba%27%27%2Cb%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a'',b''}" class="latex" title="{a'',b''}" /> the maximizer for <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. Then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28Q_e+%28x%29+-+Q_e+%28y%29%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (Q_e (x) - Q_e (y))^2" class="latex" title="\displaystyle  (Q_e (x) - Q_e (y))^2" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%28%28x_%7Ba%27%7D+-+x_%7Bb%27%7D%29%5E2+-+%28y_%7Ba%27%27%7D+-+y_%7Bb%27%27%7D%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = ((x_{a'} - x_{b'})^2 - (y_{a''} - y_{b''})^2 " class="latex" title="\displaystyle  = ((x_{a'} - x_{b'})^2 - (y_{a''} - y_{b''})^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%28%28x_%7Ba%27%7D+-+x_%7Bb%27%7D%29%5E2+-+%28y_%7Ba%27%7D+-+y_%7Bb%27%7D%29%5E2%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq ((x_{a'} - x_{b'})^2 - (y_{a'} - y_{b'})^2)^2 " class="latex" title="\displaystyle  \leq ((x_{a'} - x_{b'})^2 - (y_{a'} - y_{b'})^2)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csum_%7Ba%2Cb%5Cin+e%7D+%28%28x_a-x_b%29%5E2+-+%28y_a-y_b%29%5E2%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2" class="latex" title="\displaystyle  \leq \sum_{a,b\in e} ((x_a-x_b)^2 - (y_a-y_b)^2)^2" /></p>
<p> <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
It remains to estimate the expected sup </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5C+%5Csup_%7Bx%5Cin+T%7D+%5C+%5Chat+F%5E%7B%28k%29%7D+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \ \sup_{x\in T} \ \hat F^{(k)} (x) " class="latex" title="\displaystyle  \mathop{\mathbb E} \ \sup_{x\in T} \ \hat F^{(k)} (x) " /></p>
<p> and the diameter </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%5Cin+T%7D+%5Csqrt%7B+%5Cmathop%7B%5Cmathbb+E%7D+%28+%5Chat+F%5E%7B%28k%29%7D+%28x%29+-+%5Chat+F%5E%7B%28k%29%7D+%28y%29%29%5E2+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y \in T} \sqrt{ \mathop{\mathbb E} ( \hat F^{(k)} (x) - \hat F^{(k)} (y))^2 } " class="latex" title="\displaystyle  \sup_{x,y \in T} \sqrt{ \mathop{\mathbb E} ( \hat F^{(k)} (x) - \hat F^{(k)} (y))^2 } " /></p>
<p> where, recall, <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5C%7B+x+%3A+x%5ET+L_G+x+%3D+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = \{ x : x^T L_G x = 1\}}" class="latex" title="{T = \{ x : x^T L_G x = 1\}}" />.</p>
<p>
With the usual change of variable we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx+%5Cin+T%7D+%5C+%5Chat+F%5E%7B%28k%29%7D+%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x \in T} \ \hat F^{(k)} (x)" class="latex" title="\displaystyle  \sup_{x \in T} \ \hat F^{(k)} (x)" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csup_%7By%3A+%7C%7Cy%7C%7C%3D+1%7D+%5C+%5Chat+F%5E%7B%28k%29%7D+%28L_G%5E%7B-1%2F2%7D+y%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sup_{y: ||y||= 1} \ \hat F^{(k)} (L_G^{-1/2} y) " class="latex" title="\displaystyle  = \sup_{y: ||y||= 1} \ \hat F^{(k)} (L_G^{-1/2} y) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Cleft%5C%7C+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%5Cin+e%7D+g%5E%7B%28k%29%7D_%7Be%2Ca%2Cb%7D+%5C+L_%7BG%7D%5E%7B-1%2F2%7D+L_%7Ba%2Cb%7D+L_G%5E%7B-1%2F2%7D+%5Cright+%5C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ L_{G}^{-1/2} L_{a,b} L_G^{-1/2} \right \| " class="latex" title="\displaystyle  = \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ L_{G}^{-1/2} L_{a,b} L_G^{-1/2} \right \| " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Cleft%5C%7C+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%5Cin+e%7D+g%5E%7B%28k%29%7D_%7Be%2Ca%2Cb%7D+%5C+M_%7Ba%2Cb%7D+%5Cright+%5C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ M_{a,b} \right \| " class="latex" title="\displaystyle  = \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ M_{a,b} \right \| " /></p>
<p> where, as before, we use the notation <img src="https://s0.wp.com/latex.php?latex=%7BM_%7Ba%2Cb%7D+%3A%3D+L_%7BG%7D%5E%7B-1%2F2%7D+L_%7Ba%2Cb%7D+L_G%5E%7B-1%2F2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_{a,b} := L_{G}^{-1/2} L_{a,b} L_G^{-1/2} }" class="latex" title="{M_{a,b} := L_{G}^{-1/2} L_{a,b} L_G^{-1/2} }" />, <img src="https://s0.wp.com/latex.php?latex=%7BM%5E%7B%28k%29%7D+%3D+L_%7BG%7D%5E%7B-1%2F2%7D+L_%7BG%5E%7B%28k%29%7D+%7D+L_G%5E%7B-1%2F2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M^{(k)} = L_{G}^{-1/2} L_{G^{(k)} } L_G^{-1/2} }" class="latex" title="{M^{(k)} = L_{G}^{-1/2} L_{G^{(k)} } L_G^{-1/2} }" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM+%3A%3D+L_%7BG%7D%5E%7B-1%2F2%7D+L_G+L_G%5E%7B-1%2F2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M := L_{G}^{-1/2} L_G L_G^{-1/2} }" class="latex" title="{M := L_{G}^{-1/2} L_G L_G^{-1/2} }" />.</p>
<p>
By matrix Chernoff bounds for Gaussian sums of matrices,</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft%5C%7C+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%5Cin+e%7D+g%5E%7B%28k%29%7D_%7Be%2Ca%2Cb%7D+%5C+M_%7Ba%2Cb%7D+%5Cright+%5C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ M_{a,b} \right \| " class="latex" title="\displaystyle  \mathop{\mathbb E} \left\| \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b\in e} g^{(k)}_{e,a,b} \ M_{a,b} \right \| " /></p>
<p> <a name="eq.after.chernoff"></a></p><a name="eq.after.chernoff">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cleq+O%28%5Csqrt%7B%5Clog+n%7D%29+%5Ccdot+%5Csqrt%7B%5Cmax_%7Be%5Cin+E_k%2C+a%2Cb%5Cin+e%7D+%5Cleft%5C%7C+w%5E%7B%28k-1%29%7D_e+M_%7Ba%2Cb%7D+%5Cright%5C%7C%7D+%5Csqrt%7B+%5Cleft%5C%7C+%5Csum_%7Be%5Cin+E_k%7D+%5Csum_%7Ba%2Cb%5Cin+e%7D+w%5E%7B%28k-1%29%7D_e+%5C+M_%7Ba%2Cb%7D+%5Cright+%5C%7C+%7D+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \leq O(\sqrt{\log n}) \cdot \sqrt{\max_{e\in E_k, a,b\in e} \left\| w^{(k-1)}_e M_{a,b} \right\|} \sqrt{ \left\| \sum_{e\in E_k} \sum_{a,b\in e} w^{(k-1)}_e \ M_{a,b} \right \| } \ \ \ \ \ (1)" class="latex" title="\displaystyle   \leq O(\sqrt{\log n}) \cdot \sqrt{\max_{e\in E_k, a,b\in e} \left\| w^{(k-1)}_e M_{a,b} \right\|} \sqrt{ \left\| \sum_{e\in E_k} \sum_{a,b\in e} w^{(k-1)}_e \ M_{a,b} \right \| } \ \ \ \ \ (1)" /></p>
</a><p><a name="eq.after.chernoff"></a></p>
<p>
Recall that if <img src="https://s0.wp.com/latex.php?latex=%7Be%5Cin+E_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e\in E_k}" class="latex" title="{e\in E_k}" /> is a hyperedge that is active at round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e \leq 2^{k-1-\ell}}" class="latex" title="{p_e \leq 2^{k-1-\ell}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k-1%29%7D_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D+%2F+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k-1)}_e \leq 2^{k-1-\ell} / p_e}" class="latex" title="{w^{(k-1)}_e \leq 2^{k-1-\ell} / p_e}" />, and we also have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_e+%5Cgeq+B+%5Csum_%7Ba%2Cb%5Cin+e%7D+%7C%7CM_%7Ba%2Cb%7D%7C%7C+%5Cgeq+B+%5Cfrac+r2+%5Cmax_%7Ba%2Cb%5Cin+e%7D+%7C%7CM_%7Ba%2Cb%7D%7C%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p_e \geq B \sum_{a,b\in e} ||M_{a,b}|| \geq B \frac r2 \max_{a,b\in e} ||M_{a,b}||" class="latex" title="\displaystyle  p_e \geq B \sum_{a,b\in e} ||M_{a,b}|| \geq B \frac r2 \max_{a,b\in e} ||M_{a,b}||" /></p>
<p> so that we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax_%7Be%5Cin+E_k%2C+a%2Cb%5Cin+e%7D+w%5E%7B%28k-1%29%7D_e+%7C%7CM_%7Ba%2Cb%7D+%7C%7C+%5Cleq+%5Cfrac%7B2%5E%7Bk-1-%5Cell%7D%7D+%7BBr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \max_{e\in E_k, a,b\in e} w^{(k-1)}_e ||M_{a,b} || \leq \frac{2^{k-1-\ell}} {Br}" class="latex" title="\displaystyle  \max_{e\in E_k, a,b\in e} w^{(k-1)}_e ||M_{a,b} || \leq \frac{2^{k-1-\ell}} {Br}" /></p>
<p> The last term of <a href="https://lucatrevisan.wordpress.com/feed/#eq.after.chernoff">(1)</a> is the spectral norm of <img src="https://s0.wp.com/latex.php?latex=%7BM%5E%7B%28k-1%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M^{(k-1)}}" class="latex" title="{M^{(k-1)}}" />, which is at most 2 by the assumption of the Lemma.</p>
<p>
Collecting all the pieces, we have proved that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5C+%5Csup_%7Bx%5Cin+T%7D+%5C+%5Chat+F%5E%7B%28k%29%7D+%28x%29+%5Cleq+O+%5Cleft%28+%5Csqrt%7B%5Clog+n+%5Ccdot+%5Cfrac+%7B2%5E%7Bk-%5Cell%7D%7D%7BB+r%7D%7D%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \ \sup_{x\in T} \ \hat F^{(k)} (x) \leq O \left( \sqrt{\log n \cdot \frac {2^{k-\ell}}{B r}}\right) " class="latex" title="\displaystyle  \mathop{\mathbb E} \ \sup_{x\in T} \ \hat F^{(k)} (x) \leq O \left( \sqrt{\log n \cdot \frac {2^{k-\ell}}{B r}}\right) " /></p>
<p>
We also need to bound the diameter of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, that is</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%5Cin+T%7D+%5Csqrt%7B%5Cmathop%7B%5Cmathbb+E%7D+%28%5Chat+F%5E%7B%28k%29%7D%28x%29+-%5Chat+F%5E%7B%28k%29%7D+%28y%29+%29%5E2+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y \in T} \sqrt{\mathop{\mathbb E} (\hat F^{(k)}(x) -\hat F^{(k)} (y) )^2 } " class="latex" title="\displaystyle  \sup_{x,y \in T} \sqrt{\mathop{\mathbb E} (\hat F^{(k)}(x) -\hat F^{(k)} (y) )^2 } " /></p>
<p> under the usual change of basis, for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y}" class="latex" title="{x,y}" /> of length 1 we want to bound the square root of </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D%5Cleft+%28+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%7D+g_%7Ba%2Ce%2Cb%7D+x%5ET+%28M_%7Ba%2Cb%7D+x+-+y%5ET+M_%7Ba%2Cb%7D+y%29%5Cright%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E}\left ( \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b} g_{a,e,b} x^T (M_{a,b} x - y^T M_{a,b} y)\right)^2 " class="latex" title="\displaystyle  \mathop{\mathbb E}\left ( \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b} g_{a,e,b} x^T (M_{a,b} x - y^T M_{a,b} y)\right)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_%7Be%5Cin+E_k%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e%5Cright%29%5E2+%5Csum_%7Ba%2Cb%7D+%28x%5ET+M_%7Ba%2Cb%7D+x+-+y%5ET+M_%7Ba%2Cb%7D+y%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \sum_{a,b} (x^T M_{a,b} x - y^T M_{a,b} y)^2 " class="latex" title="\displaystyle  = \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \sum_{a,b} (x^T M_{a,b} x - y^T M_{a,b} y)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csum_%7Be%5Cin+E_k%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e%5Cright%29%5E2+%5Csum_%7Ba%2Cb%7D+%28x%5ET+M_%7Ba%2Cb%7D+x%29%5E2+%2B+%28y%5ET+M_%7Ba%2Cb%7D+y%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \sum_{a,b} (x^T M_{a,b} x)^2 + (y^T M_{a,b} y)^2 " class="latex" title="\displaystyle  \leq \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \sum_{a,b} (x^T M_{a,b} x)^2 + (y^T M_{a,b} y)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csum_%7Be%5Cin+E_k%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e%5Cright%29%5E2+%5Cmax_%7Ba%2Cb+%5Cin+e%7D+%7C%7CM_%7Ba%2Cb%7D+%7C%7C+%5Csum_%7Ba%2Cb%7D+%28x%5ET+M_%7Ba%2Cb%7D+x+%2B+y%5ET+M_%7Ba%2Cb%7D+y%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \max_{a,b \in e} ||M_{a,b} || \sum_{a,b} (x^T M_{a,b} x + y^T M_{a,b} y) " class="latex" title="\displaystyle  \leq \sum_{e\in E_k} \left( w^{(k-1)}_e\right)^2 \max_{a,b \in e} ||M_{a,b} || \sum_{a,b} (x^T M_{a,b} x + y^T M_{a,b} y) " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k-1%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k-1)}_e}" class="latex" title="{w^{(k-1)}_e}" /> is either zero or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%5E%7Bk-%5Cell-1%7D%7D%7BB+%5Csum_%7Ba%2Cb%5Cin+e%7D+%7C%7CM_e%7C%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{2^{k-\ell-1}}{B \sum_{a,b\in e} ||M_e||}}" class="latex" title="{\frac{2^{k-\ell-1}}{B \sum_{a,b\in e} ||M_e||}}" /> and we can continue our chain of inequalities with </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Cfrac%7B2%5E%7Bk-%5Cell%7D%7D%7BBr%7D+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb%7D+%28x%5ET+M_%7Ba%2Cb%7D+x+%2B+y%5ET+M_%7Ba%2Cb%7D+y+%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \frac{2^{k-\ell}}{Br} \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b} (x^T M_{a,b} x + y^T M_{a,b} y )" class="latex" title="\displaystyle  \leq \frac{2^{k-\ell}}{Br} \sum_{e\in E_k} w^{(k-1)}_e \sum_{a,b} (x^T M_{a,b} x + y^T M_{a,b} y )" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Cfrac%7B2%5E%7Bk-%5Cell%7D%7D%7BBr%7D+%28x%5ET+M%5E%7B%28k-1%29%7D+x+%2B+y%5ET+M%5E%7B%28k-1%29%7D+y+%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \frac{2^{k-\ell}}{Br} (x^T M^{(k-1)} x + y^T M^{(k-1)} y ) " class="latex" title="\displaystyle  = \frac{2^{k-\ell}}{Br} (x^T M^{(k-1)} x + y^T M^{(k-1)} y ) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+4+%5Ccdot+%5Cfrac%7B2%5E%7Bk-%5Cell%7D%7D%7BBr%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq 4 \cdot \frac{2^{k-\ell}}{Br} " class="latex" title="\displaystyle  \leq 4 \cdot \frac{2^{k-\ell}}{Br} " /></p>
<p> where we used again the assumption of the Lemma <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+M%5E%7B%28k-1%29%7D+%7C%7C+%5Cleq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| M^{(k-1)} || \leq 2}" class="latex" title="{|| M^{(k-1)} || \leq 2}" />.</p>
<p>
To prove the last part of the lemma, we have to prove that with high probability</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+M%5E%7B%28k%29%7D+-+M%5E%7B%28k-1%29%7D+%7C%7C+%5Cleq+O%5Cleft%28+%5Csqrt%7B+%5Cfrac+%7B2%5E%7Bk-%5Cell%7D+%5Clog+n%7D%7BB%7D%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || M^{(k)} - M^{(k-1)} || \leq O\left( \sqrt{ \frac {2^{k-\ell} \log n}{B}} \right) " class="latex" title="\displaystyle  || M^{(k)} - M^{(k-1)} || \leq O\left( \sqrt{ \frac {2^{k-\ell} \log n}{B}} \right) " /></p>
<p> We see that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7B%28k%29%7D+-+M%5E%7B%28k-1%29%7D+%3D+%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k-1%29%7D_e+r%5E%7B%28k%29%7D_e+%5Csum_%7Ba%2Cb+%5Cin+e%7D+M_%7Ba%2Cb%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{(k)} - M^{(k-1)} = \sum_{e\in E_k} w^{(k-1)}_e r^{(k)}_e \sum_{a,b \in e} M_{a,b} " class="latex" title="\displaystyle  M^{(k)} - M^{(k-1)} = \sum_{e\in E_k} w^{(k-1)}_e r^{(k)}_e \sum_{a,b \in e} M_{a,b} " /></p>
<p> as noted before, each <img src="https://s0.wp.com/latex.php?latex=%7B+w%5E%7B%28k-1%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ w^{(k-1)}_e}" class="latex" title="{ w^{(k-1)}_e}" /> is either zero or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+%7B2%5E%7Bk-1-%5Cell%7D%7D%7BB%5Csum_%7Ba%2Cb%5Cin+e%7D+%7C%7CM_%7Ba%2Cb%7D%7C%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac {2^{k-1-\ell}}{B\sum_{a,b\in e} ||M_{a,b}||}}" class="latex" title="{\frac {2^{k-1-\ell}}{B\sum_{a,b\in e} ||M_{a,b}||}}" />, so </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft+%5C%7C+w%5E%7B%28k-1%29%7D_e+%5Csum_%7Ba%2Cb+%5Cin+e%7D+M_%7Ba%2Cb%7D+%5Cright+%5C%7C+%5Cleq+%5Cfrac+%7B2%5E%7Bk-1-%5Cell%7D%7D%7BB%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left \| w^{(k-1)}_e \sum_{a,b \in e} M_{a,b} \right \| \leq \frac {2^{k-1-\ell}}{B} " class="latex" title="\displaystyle  \left \| w^{(k-1)}_e \sum_{a,b \in e} M_{a,b} \right \| \leq \frac {2^{k-1-\ell}}{B} " /></p>
<p> and the final claim follows from matrix Chernoff bounds.</p>
<p>
Now we can put everything together. Applying our lemma inductively, we can say that with high probability</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1%7D+%7CF%28x%29%7C+%5Cleq+%5Csum_%7Bk%3D1%7D%5E%5Cell+%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1%7D+%7CF%5E%7B%28k%29%7D+%28x%29%7C+%5Cleq+%5Csum_%7Bk%3D1%7D%5E%5Cell+O%5Cleft%28+%5Csqrt%7B+2%5E%7Bk-%5Cell%7D+%5Cfrac%7B%5Clog+n%7D%7BBr%7D+%7D+%5Cright%29+%5Cleq+O+%5Cleft%28+%5Csqrt%7B+%5Cfrac%7B%5Clog+n%7D%7BBr%7D+%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1} |F(x)| \leq \sum_{k=1}^\ell \sup_{x: x^T L_G x = 1} |F^{(k)} (x)| \leq \sum_{k=1}^\ell O\left( \sqrt{ 2^{k-\ell} \frac{\log n}{Br} } \right) \leq O \left( \sqrt{ \frac{\log n}{Br} } \right) " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1} |F(x)| \leq \sum_{k=1}^\ell \sup_{x: x^T L_G x = 1} |F^{(k)} (x)| \leq \sum_{k=1}^\ell O\left( \sqrt{ 2^{k-\ell} \frac{\log n}{Br} } \right) \leq O \left( \sqrt{ \frac{\log n}{Br} } \right) " /></p>
<p> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+k%3A+L%5E%7B%28k%29%7D+_G+%5Cpreceq+O+%5Cleft%28+%5Csum_%7Bi%3D1%7D%5Ek+%5Csqrt%7B+2%5E%7Bi-%5Cell%7D+%5Cfrac%7B%5Clog+n%7D%7BB%7D+%7D+%5Cright%29+%5Ccdot+L_G+%5Cpreceq+2+L_G+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall k: L^{(k)} _G \preceq O \left( \sum_{i=1}^k \sqrt{ 2^{i-\ell} \frac{\log n}{B} } \right) \cdot L_G \preceq 2 L_G " class="latex" title="\displaystyle  \forall k: L^{(k)} _G \preceq O \left( \sum_{i=1}^k \sqrt{ 2^{i-\ell} \frac{\log n}{B} } \right) \cdot L_G \preceq 2 L_G " /></p>
<p> provided that we choose <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> at least at absolute constant times <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" />.</p>
<p>
In particular, we can choose <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> to be an absolute constant times <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%5E%7B-2%7D+r%5E3+%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon^{-2} r^3 \log n}" class="latex" title="{\epsilon^{-2} r^3 \log n}" /> and have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1%7D+%7CF%28x%29%7C+%5Cleq+%5Cfrac%7B2%7D%7Br%5E2%7D+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1} |F(x)| \leq \frac{2}{r^2} \epsilon " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1} |F(x)| \leq \frac{2}{r^2} \epsilon " /></p>
<p> which is the same as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%3A+%5C+%5C+%7CQ_%7BH%7D+%28x%29+-+Q_%7BH%27%7D+%28x%29+%7C+%5Cleq+%5Cfrac%7B2%7D%7Br%5E2%7D+%5Cepsilon+%5Ccdot+x%5ET+L_G+x+%5Cleq+%5Cepsilon%5C+Q_H%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall x: \ \ |Q_{H} (x) - Q_{H'} (x) | \leq \frac{2}{r^2} \epsilon \cdot x^T L_G x \leq \epsilon\ Q_H(x) " class="latex" title="\displaystyle  \forall x: \ \ |Q_{H} (x) - Q_{H'} (x) | \leq \frac{2}{r^2} \epsilon \cdot x^T L_G x \leq \epsilon\ Q_H(x) " /></p>
<p>
So, with high probability, <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> is a spectral sparsifier of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> with error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />, and it has <img src="https://s0.wp.com/latex.php?latex=%7BO%28Bn%29+%3D+O%28%5Cepsilon%5E%7B-2%7D+r%5E3+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(Bn) = O(\epsilon^{-2} r^3 n \log n)}" class="latex" title="{O(Bn) = O(\epsilon^{-2} r^3 n \log n)}" /> hyperedges</p>
<p>
</p><p><b>4. Some Additional Thoughts </b></p>
<p></p><p>
The dependence on <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> is definitely not optimal, particularly because when <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> is order of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> we know from the work of Soma and Yoshida that we can do better. One place where we seem to lose is that, although we know</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_e%28x%29+%5Cleq+O+%5Cleft%28+%5Cfrac+1r+%5Cright%29+%5C+%5Csum_%7Ba%2Cb%5Cin+%7D+x%5ET+L_%7Ba%2Cb%7D+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  Q_e(x) \leq O \left( \frac 1r \right) \ \sum_{a,b\in } x^T L_{a,b} x " class="latex" title="\displaystyle  Q_e(x) \leq O \left( \frac 1r \right) \ \sum_{a,b\in } x^T L_{a,b} x " /></p>
<p> we are only able to show that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Be%5Cin+E_k%7D+r%5E%7B%28k%29%7D_e+w%5E%7B%28k%29%7D_e+Q_e%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{e\in E_k} r^{(k)}_e w^{(k)}_e Q_e(x) " class="latex" title="\displaystyle  \sum_{e\in E_k} r^{(k)}_e w^{(k)}_e Q_e(x) " /></p>
<p> is <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />-dominated by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Be%5Cin+E_k%7D+g%5E%7B%28k%29%7D_e+w%5E%7B%28k%29%7D_e+%5Csum_%7Ba%2Cb+%5Cin+e+%7D+x%5ET+L_%7Bab%7D+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{e\in E_k} g^{(k)}_e w^{(k)}_e \sum_{a,b \in e } x^T L_{ab} x " class="latex" title="\displaystyle  \sum_{e\in E_k} g^{(k)}_e w^{(k)}_e \sum_{a,b \in e } x^T L_{ab} x " /></p>
<p> rather than, as we could have hoped, <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2Fr%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/r)}" class="latex" title="{O(1/r)}" />-dominated. The difficulty is that the bound</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28Q_e%28x%29+-+Q_e%28y%29%29%5E2+%5Cleq+%5Csum_%7Ba%2Cb%5Cin+e%7D+%28x%5ET+L_%7Bab%7D+x+-+y%5ET+L_%7Bab%7D+y%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (Q_e(x) - Q_e(y))^2 \leq \sum_{a,b\in e} (x^T L_{ab} x - y^T L_{ab} y)^2 " class="latex" title="\displaystyle  (Q_e(x) - Q_e(y))^2 \leq \sum_{a,b\in e} (x^T L_{ab} x - y^T L_{ab} y)^2 " /></p>
<p> is sometimes tight. In order to do better, it seems necessary to do something a bit differently from what we do here. </p>
<p>
The effective resistance of an edge <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> in a graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> can be written as</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+%5C+%5Cfrac%7Bx%5ET+L_%7Ba%2Cb%7D+x%7D%7Bx%5ET+L_G+x%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x\in {\mathbb R}^n} \ \ \frac{x^T L_{a,b} x}{x^T L_G x} " class="latex" title="\displaystyle  \sup_{x\in {\mathbb R}^n} \ \ \frac{x^T L_{a,b} x}{x^T L_G x} " /></p>
<p>
with the convention that <img src="https://s0.wp.com/latex.php?latex=%7B0%2F0+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0/0 = 0}" class="latex" title="{0/0 = 0}" />. So it seems reasonable that a good definition of effective resistance for an hyperedge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> in a hypergraph <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> would be</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+%5C+%5Cfrac%7BQ_e%28x%29%7D%7BQ_H%28x%29+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x\in {\mathbb R}^n} \ \ \frac{Q_e(x)}{Q_H(x) } " class="latex" title="\displaystyle  \sup_{x\in {\mathbb R}^n} \ \ \frac{Q_e(x)}{Q_H(x) } " /></p>
<p> One can argue that these “effective resistances” add up to <img src="https://s0.wp.com/latex.php?latex=%7BO%28nr%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(nr)}" class="latex" title="{O(nr)}" />, but perhaps they add up to <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n)}" class="latex" title="{O(n)}" />? If we sample according to those “effective resitances,” can we apply generic chaining directly to <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Be%5Cin+E_k%7D+w%5E%7B%28k%29%7D_e+g%5E%7B%28k%29%7D_e+Q_e%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_{e\in E_k} w^{(k)}_e g^{(k)}_e Q_e(x)}" class="latex" title="{\sum_{e\in E_k} w^{(k)}_e g^{(k)}_e Q_e(x)}" /> without having to rely on a Gaussian process on matrices, for which we have Chernoff bounds?</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/05/14/spectral-sparsification-of-hypergraphs/"><span class="datestr">at May 14, 2020 04:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1082301538511422857">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/05/awesome-video-from-women-in-theory.html">Awesome Video from Women In Theory!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Below is an <a href="https://www.youtube.com/watch?v=4Wl-3kadvgw">awesome video</a> made by WIT (Women In Theory) on May 10, 2020 to celebrate the women in our field and in place of the Women in Theory Workshop that was supposed to take place<br />
<div>
@Simons in June. ENJOY:</div>
<div>
<br /></div>
<div>
<br /></div>
<div>
<br />

</div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/05/awesome-video-from-women-in-theory.html"><span class="datestr">at May 14, 2020 01:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/14/6-year-postdoc-at-tu-wien-vienna-austria-apply-by-may-28-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/14/6-year-postdoc-at-tu-wien-vienna-austria-apply-by-may-28-2020/">6-year postdoc at TU Wien, Vienna, Austria (apply by May 28, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A 6-Year Postdoc Position in Algorithms is available at TU Wien, Vienna, Austria. Research experience in one of the following areas is of advantage: parameterized complexity, algorithmic applications of graph decompositions, SAT and CSP.</p>
<p>Website: <a href="https://www.ac.tuwien.ac.at/jobs/#junprof">https://www.ac.tuwien.ac.at/jobs/#junprof</a><br />
Email: sz@ac.tuwien.ac.at</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/14/6-year-postdoc-at-tu-wien-vienna-austria-apply-by-may-28-2020/"><span class="datestr">at May 14, 2020 10:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/14/postdoc-at-university-of-haifa-israel-apply-by-december-30-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/14/postdoc-at-university-of-haifa-israel-apply-by-december-30-2020/">Postdoc at University of Haifa (Israel) (apply by December 30, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We invite applications for a postdoc position, hosted by Or Meir, at the university of Haifa in Israel. We are especially looking for candidates who are interested in working on communication complexity and circuit complexity, but we will also consider candidates who are interested in other areas of complexity theory and algorithms. For details, please e-mail Or Meir directly.</p>
<p>Website: <a href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxub2dhcm9uemV3aTF8Z3g6Nzc2ZjU5ZjIwY2QwNzJhMg&amp;urp=gmail_link">https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxub2dhcm9uemV3aTF8Z3g6Nzc2ZjU5ZjIwY2QwNzJhMg&amp;urp=gmail_link</a><br />
Email: ormeir@cs.haifa.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/14/postdoc-at-university-of-haifa-israel-apply-by-december-30-2020/"><span class="datestr">at May 14, 2020 09:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06441">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06441">Testing Positive Semi-Definiteness via Random Submatrices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bakshi:Ainesh.html">Ainesh Bakshi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chepurko:Nadiia.html">Nadiia Chepurko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06441">PDF</a><br /><b>Abstract: </b>We study the problem of testing whether a matrix $A \in \mathbb{R}^{n \times
n}$ with bounded entries ($\|A\|_\infty \leq 1$) is positive semi-definite
(PSD), or $\epsilon$-far in $\ell_2^2$-distance from the PSD cone, i.e. $\min_{
B \succeq 0} \| A - B\|_F^2 = \sum_{i : \lambda_i(A) &lt; 0} \lambda_i^2(A) &gt;
\epsilon n^2$. Our main algorithmic contribution is a non-adaptive tester which
distinguishes between these cases using only $\tilde{O}(1/\epsilon^4)$ queries
to the entries of $A$. For the related "$\ell_\infty$-gap problem", where $A$
is either PSD or has an eigenvalue satisfying $\lambda_i(A) &lt; - \epsilon n$,
our algorithm only requires $\tilde{O}(1/\epsilon^2)$ queries, which is optimal
up to $\log(1/\epsilon)$ factors. Our testers randomly sample a collection of
principle sub-matrices and check whether these sub-matrices are PSD.
Consequentially, our algorithms achieve one-sided error: whenever they output
that $A$ is not PSD, they return a certificate that $A$ has negative
eigenvalues.
</p>
<p>We complement our upper bound for PSD testing with $\ell_2^2$-gap by giving a
$\tilde{\Omega}(1/\epsilon^2)$ lower bound for any non-adaptive algorithm. Our
lower bound construction is general, and can be used to derive lower bounds for
a number of spectral testing problems. As an example of the applicability of
our construction, we obtain a new $\tilde{\Omega}(1/\epsilon^4)$ sampling lower
bound for testing the Schatten-$1$ norm with a $\epsilon^{1.5}$ gap, extending
a result of Balcan, Li, Woodruff, and Zhang [SODA'19]. In addition, our hard
instance results in new sampling lower bounds for estimating the Ky-Fan Norm,
and the cost of rank-$k$ approximations, i.e. $\|A - A_k\|_F^2 = \sum_{i &gt; k}
\sigma_i^2(A)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06441"><span class="datestr">at May 14, 2020 10:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06436">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06436">Fundamentals of Computing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Leonid_A=.html">Leonid A. Levin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06436">PDF</a><br /><b>Abstract: </b>These are notes for a Theory of Computation course. The goal is to introduce
the undergraduates to basic concepts of Theory of Computation and to provoke
their interest in further study. Model-dependent effects are systematically
ignored. Concrete computational problems are considered only as illustrations
of general principles. The notes can be used by an instructor designing a
course or by students who either know the material and want to refresh the
memory or are exceptionally bright and have access to an instructor for
questions. Each subsection takes about a week of the course.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06436"><span class="datestr">at May 14, 2020 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06419">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06419">Time Space Optimal Algorithm for Computing Separators in Bounded Genus Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Chetan.html">Chetan Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tewari:Raghunath.html">Raghunath Tewari</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06419">PDF</a><br /><b>Abstract: </b>A graph separator is a subset of vertices of a graph whose removal divides
the graph into small components. Computing small graph separators for various
classes of graphs is an important computational task. In this paper, we present
a polynomial time algorithm that uses $O(g^{1/2}n^{1/2}\log n)$-space to find
an $O(g^{1/2}n^{1/2})$-sized separator of a graph having $n$ vertices and
embedded on a surface of genus $g$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06419"><span class="datestr">at May 14, 2020 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06344">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06344">A remark on approximating permanents of positive definite matrices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Alexander Barvinok <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06344">PDF</a><br /><b>Abstract: </b>Let $A$ be an $n \times n$ positive definite Hermitian matrix with all
eigenvalues between 1 and 2. We represent the permanent of $A$ as the integral
of some explicit log-concave function on ${\Bbb R}^{2n}$. Consequently, there
is a fully polynomial randomized approximation scheme (FPRAS) for the permanent
of $A$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06344"><span class="datestr">at May 14, 2020 10:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06329">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06329">k-Approximate Quasiperiodicity under Hamming and Edit Distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Aleksander Kędzierski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radoszewski:Jakub.html">Jakub Radoszewski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06329">PDF</a><br /><b>Abstract: </b>Quasiperiodicity in strings was introduced almost 30 years ago as an
extension of string periodicity. The basic notions of quasiperiodicity are
cover and seed. A cover of a text $T$ is a string whose occurrences in $T$
cover all positions of $T$. A seed of text $T$ is a cover of a superstring of
$T$. In various applications exact quasiperiodicity is still not sufficient due
to the presence of errors. We consider approximate notions of quasiperiodicity,
for which we allow approximate occurrences in $T$ with a small Hamming,
Levenshtein or weighted edit distance.
</p>
<p>In previous work Sip et al. (2002) and Christodoulakis et al. (2005) showed
that computing approximate covers and seeds, respectively, under weighted edit
distance is NP-hard. They, therefore, considered restricted approximate covers
and seeds which need to be factors of the original string $T$ and presented
polynomial-time algorithms for computing them. Further algorithms, considering
approximate occurrences with Hamming distance bounded by $k$, were given in
several contributions by Guth et al. They also studied relaxed approximate
quasiperiods that do not need to cover all positions of $T$.
</p>
<p>In case of large data the exponents in polynomial time complexity play a
crucial role. We present more efficient algorithms for computing restricted
approximate covers and seeds. In particular, we improve upon the complexities
of many of the aforementioned algorithms, also for relaxed quasiperiods. Our
solutions are especially efficient if the number (or total cost) of allowed
errors is bounded. We also show NP-hardness of computing non-restricted
approximate covers and seeds under Hamming distance.
</p>
<p>Approximate covers were studied in three recent contributions at CPM over the
last three years. However, these works consider a different definition of an
approximate cover of $T$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06329"><span class="datestr">at May 14, 2020 10:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06311">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06311">Fully Online Matching II: Beating Ranking and Water-filling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06311">PDF</a><br /><b>Abstract: </b>Karp, Vazirani, and Vazirani (STOC 1990) initiated the study of online
bipartite matching, which has held a central role in online algorithms ever
since. Of particular importance are the Ranking algorithm for integral matching
and the Water-filling algorithm for fractional matching. Most algorithms in the
literature can be viewed as adaptations of these two in the corresponding
models. Recently, Huang et al.~(STOC 2018, SODA 2019) introduced a more general
model called \emph{fully online matching}, which considers general graphs and
allows all vertices to arrive online. They also generalized Ranking and
Water-filling to fully online matching and gave some tight analysis: Ranking is
$\Omega \approx 0.567$-competitive on bipartite graphs where the
$\Omega$-constant satisfies $\Omega e^\Omega = 1$, and Water-filling is
$2-\sqrt{2} \approx 0.585$-competitive on general graphs.
</p>
<p>We propose fully online matching algorithms strictly better than Ranking and
Water-filling. For integral matching on bipartite graphs, we build on the
online primal dual analysis of Ranking and Water-filling to design a
$0.569$-competitive hybrid algorithm called Balanced Ranking. To our knowledge,
it is the first integral algorithm in the online matching literature that
successfully integrates ideas from Water-filling. For fractional matching on
general graphs, we give a $0.592$-competitive algorithm called Eager
Water-filling, which may match a vertex on its arrival. By contrast, the
original Water-filling algorithm always matches vertices at their deadlines.
Our result for fractional matching further shows a separation between fully
online matching and the general vertex arrival model by Wang and Wong (ICALP
2015), due to an upper bound of $0.5914$ in the latter model by Buchbinder,
Segev, and Tkach (ESA 2017).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06311"><span class="datestr">at May 14, 2020 10:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06225">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06225">An improved solution approach for the Budget constrained Fuel Treatment Scheduling problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Croce:Federico_Della.html">Federico Della Croce</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghirardi:Marco.html">Marco Ghirardi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scatamacchia:Rosario.html">Rosario Scatamacchia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06225">PDF</a><br /><b>Abstract: </b>This paper considers the budget constrained fuel treatment scheduling (BFTS)
problem where, in the context of wildfire mitigation, the goal is to inhibit
the potential of fire spread in a landscape by proper fuel treatment
activities. Given a time horizon represented by consecutive unit periods, the
landscape is divided into cells and represented as a grid graph where each cell
has a fuel age that increases over time and becomes old if no treatment is
applied in the meantime: this induces a potential high fire risk whenever two
contiguous cells are old. Cells fuel ages can be reset to zero under
appropriate fuel treatments but there is a limited budget for treatment in each
period. The problem calls for finding a suitable selection of cells to be
treated so as to minimize the presence of old contiguous cells over the whole
time horizon. We prove that problem BFTS is strongly NP-complete on paths and
thus on grid graphs and show that no polynomial time approximation algorithm
exists unless P = NP. We provide an enhanced integer linear programming
formulation of the problem with respect to the relevant literature that shows
up to be efficiently solved by an ILP solver on reasonably large size
instances. Finally, we consider a harder periodic variant of the problem with
the aim of finding a cyclic treatment plan with cycles of length T and propose
a matheuristic approach capable of efficiently tackling those instances where
an ILP solver applied to the ILP formulation runs into difficulties.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06225"><span class="datestr">at May 14, 2020 10:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06156">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06156">A robust multi-dimensional sparse Fourier transform in the continuous setting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yaonan.html">Yaonan Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Daogao.html">Daogao Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06156">PDF</a><br /><b>Abstract: </b>Sparse Fourier transform (Sparse FT) is the problem of learning an unknown
signal, whose frequency spectrum is dominated by a small amount of $k$
individual frequencies, through fast algorithms that use as few samples as
possible in the time domain. The last two decades have seen an extensive study
on such problems, either in the one-/multi-dimensional discrete setting
[Hassanieh, Indyk, Katabi, and Price STOC'12; Kapralov STOC'16] or in the
one-dimensional continuous setting [Price and Song FOCS'15]. Despite this rich
literature, the most general multi-dimensional continuous case remains
mysterious.
</p>
<p>This paper initiates the study on the Sparse FT problem in the
multi-dimensional continuous setting. Our main result is a randomized
non-adaptive algorithm that uses sublinear samples and runs in sublinear time.
In particular, the sample duration bound required by our algorithm gives a
non-trivial improvement over [Price and Song FOCS'15], which studies the same
problem in the one-dimensional continuous setting.
</p>
<p>The dimensionality in the continuous setting, different from both the
discrete cases and the one-dimensional continuous case, turns out to incur many
new challenges. To overcome these issues, we develop a number of new techniques
for constructing the filter functions, designing the permutation-then-hashing
schemes, sampling the Fourier measurements, and locating the frequencies. We
believe these techniques can find their applications in the future studies on
the Sparse FT problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06156"><span class="datestr">at May 14, 2020 10:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06100">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06100">Structure and Algorithm for Path of Solutions to a Class of Fused Lasso Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Cheng.html">Cheng Lu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06100">PDF</a><br /><b>Abstract: </b>We study a class of fused lasso problems where the estimated parameters in a
sequence are regressed toward their respective observed values (fidelity loss),
with $\ell_1$ norm penalty (regularization loss) on the differences between
successive parameters, which promotes local constancy. In many applications,
there is a coefficient, often denoted as $\lambda$, on the regularization term,
which adjusts the relative importance between the two losses.
</p>
<p>In this paper, we characterize how the optimal solution evolves with the
increment of $\lambda$. We show that, if all fidelity loss functions are convex
piecewise linear, the optimal value for \emph{each} variable changes at most
$O(nq)$ times for a problem of $n$ variables and total $q$ breakpoints. On the
other hand, we present an algorithm that solves the path of solutions of
\emph{all} variables in $\tilde{O}(nq)$ time for all $\lambda \geq 0$.
Interestingly, we find that the path of solutions for each variable can be
divided into up to $n$ locally convex-like segments. For problems of arbitrary
convex loss functions, for a given solution accuracy, one can transform the
loss functions into convex piecewise linear functions and apply the above
results, giving pseudo-polynomial bounds as $q$ becomes a pseudo-polynomial
quantity.
</p>
<p>To our knowledge, this is the first work to solve the path of solutions for
fused lasso of non-quadratic fidelity loss functions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06100"><span class="datestr">at May 14, 2020 10:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.06046">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.06046">Red-Blue Point Separation for Points on a Circle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Neeldhara.html">Neeldhara Misra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Harshil.html">Harshil Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sethia:Aditi.html">Aditi Sethia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06046">PDF</a><br /><b>Abstract: </b>Given a set R of red points and a set B of blue points in the plane, the
Red-Blue point separation problem asks if there are at most k lines that
separate R from B, that is, each cell induced by the lines of the solution is
either empty or monochromatic (containing points of only one color). A common
variant of the problem is when the lines are required to be axis-parallel. The
problem is known to be NP-complete for both scenarios, and W[1]-hard
parameterized by k in the former setting and FPT in the latter. We demonstrate
a polynomial-time algorithm for the special case when the points lie on a
circle. Further, we also demonstrate the W-hardness of a related problem in the
axis-parallel setting, where the question is if there are p horizontal and q
vertical lines that separate R from B. The hardness here is shown in the
parameter p.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.06046"><span class="datestr">at May 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.05490">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.05490">Monotone Boolean Functions, Feasibility/Infeasibility, LP-type problems and MaxCon</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suter:David.html">David Suter</a>, Ruwan Tennakoon, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Erchuan.html">Erchuan Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chin:Tat=Jun.html">Tat-Jun Chin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bab=Hadiashar:Alireza.html">Alireza Bab-Hadiashar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.05490">PDF</a><br /><b>Abstract: </b>This paper outlines connections between Monotone Boolean Functions, LP-Type
problems and the Maximum Consensus Problem. The latter refers to a particular
type of robust fitting characterisation, popular in Computer Vision (MaxCon).
Indeed, this is our main motivation but we believe the results of the study of
these connections are more widely applicable to LP-type problems (at least
'thresholded versions', as we describe), and perhaps even more widely. We
illustrate, with examples from Computer Vision, how the resulting perspectives
suggest new algorithms. Indeed, we focus, in the experimental part, on how the
Influence (a property of Boolean Functions that takes on a special form if the
function is Monotone) can guide a search for the MaxCon solution.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.05490"><span class="datestr">at May 14, 2020 10:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/13/lecturer-at-university-of-illinois-chicago-apply-by-may-20-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/13/lecturer-at-university-of-illinois-chicago-apply-by-may-20-2020/">Lecturer at University of Illinois Chicago (apply by May 20, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Mathematics, Statistics, and Computer Science at UIC is accepting applications for Lecturer positions beginning in Fall 2020 to teach computer science and statistics courses. Please see the full ad at the link for more details.</p>
<p>Website: <a href="https://jobs.uic.edu/job-board/job-details?jobID=131035&amp;job=lecturer-mathematics-statistics-and-computer-science">https://jobs.uic.edu/job-board/job-details?jobID=131035&amp;job=lecturer-mathematics-statistics-and-computer-science</a><br />
Email: willp@uic.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/13/lecturer-at-university-of-illinois-chicago-apply-by-may-20-2020/"><span class="datestr">at May 13, 2020 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7728">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/05/13/resources-for-the-upcoming-job-market-crunch/">Resources for the upcoming job market crunch</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Aside from its devastating death toll, the COVID-19 pandemic has had severe economic implications. The impact on universities is particularly substantial, including disruptions to our physical campuses and student residences, as well as to the sources of income for private and public universities such as endowments and state budgets.</p>



<p>All this means that the academic job market is likely going to be tough in the near future, and computer  science will not be immune. During the last recession, the CCC started a <a href="https://cra.org/ccc/leadership-development/cifellows/">computing innovation fellows</a> program which was very successful, and I hope that something similar will occur this time as well. But it won’t be enough.</p>



<p>If you are aware of any postdoc positions (or better yet, can create one) please do make sure to post it on the <a href="https://cstheory-jobs.org/">CS theory job board</a>. If you know of any teaching position that could potentially be applicable for theorists, please post it there too.  This crisis can also be an opportunity to get fantastic people for such positions. If you have any ideas on how we as the theoretical CS community can support graduating students  and postdocs, please do share these in the comments or on <a href="https://twitter.com/boazbaraktcs">Twitter</a>.</p>



<p>If anything, this crisis has taught us that the world needs more science, not less. Moreover, computer science has been and will continue to be a crucial component in fighting this epidemic, including not just modeling but also tracing applications using crypto, load balancing that ensures the Internet doesn’t crush, and more. I am thus hopeful that within a couple of years, the academic job market for theoretical computer scientists will recover. However we should try to do all we can to help our junior colleagues get through this period.</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/05/13/resources-for-the-upcoming-job-market-crunch/"><span class="datestr">at May 13, 2020 04:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/13/postdoc-at-university-of-salzburg-apply-by-june-14-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/13/postdoc-at-university-of-salzburg-apply-by-june-14-2020/">Postdoc at University of Salzburg (apply by June 14, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A postdoc position is available in the project “Distributed Algorithms for Fundamental Graph Problems” led by Sebastian Forster at the University of Salzburg, Austria. Research experience in efficient graph algorithms is required, but not specifically in the distributed setting. The position is for one year with the possibility of extension by another year.</p>
<p>Website: <a href="https://www.cs.sbg.ac.at/~forster/openings.html">https://www.cs.sbg.ac.at/~forster/openings.html</a><br />
Email: sebastian.forster@sbg.ac.at</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/13/postdoc-at-university-of-salzburg-apply-by-june-14-2020/"><span class="datestr">at May 13, 2020 02:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4794">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4794">Four striking papers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>In the past week or two, four striking papers appeared on quant-ph.  Rather than doing my usual thing—envisioning a huge, meaty blog post about each paper, but then procrastinating on writing them until the posts are no longer even relevant—I thought I’d just write a paragraph about each paper and then open things up for discussion.</p>



<p>(1) Matt Hastings has <a href="https://arxiv.org/abs/2005.03791">announced</a> the first provable superpolynomial black-box speedup for the quantum adiabatic algorithm (in its original, stoquastic version).  The speedup is only quasipolynomial (n<sup>log(n)</sup>) rather than exponential, and it’s for a contrived example (just like in the <a href="https://arxiv.org/abs/1302.5733">important earlier work</a> by Freedman and Hastings, which separated the adiabatic algorithm from Quantum Monte Carlo), and there are no obvious near-term practical implications.  But still!  Twenty years after Farhi and his collaborators wrote the first paper on the quantum adiabatic algorithm, and 13 years after D-Wave made its first hype-laden announcement, this is (to my mind) the first strong theoretical indication that adiabatic evolution with no sign problem can <em>ever</em> get a superpolynomial speedup over not only simulated annealing, not only Quantum Monte Carlo, but <em>all</em> possible classical algorithms.  (This had previously been shown only for a variant of the adiabatic algorithm that jumps up to the first excited state, by <a href="https://arxiv.org/abs/1202.6257">Nagaj, Somma, and Kieferova</a>.)  As such, assuming the result holds up, Hastings resolves a central question that I (for one) had repeatedly asked about for almost 20 years.  Indeed, if memory serves, at an Aspen quantum algorithms meeting a few years ago, I strongly urged Hastings to work on the problem.  Congratulations to Matt!</p>



<p>(2) In my 2009 paper “<a href="https://arxiv.org/abs/1110.5353">Quantum Copy-Protection and Quantum Money</a>,” I introduced the notion of copy-protected quantum software: a state |ψ<sub>f</sub>⟩ that you could efficiently use to evaluate a function f, but not to produce more states (whether |ψ<sub>f</sub>⟩ or anything else) that would let others evaluate f.  I gave candidate constructions for quantumly copy-protecting the simple class of “point functions” (e.g., recognizing a password), and I sketched a proof that quantum copy-protection of <em>arbitrary</em> functions (except for those efficiently learnable from their input/output behavior) was possible relative to a quantum oracle.  Building on an idea of Paul Christiano, a couple weeks ago my PhD student Jiahui Liu, Ruizhe Zhang, and I put a <a href="https://arxiv.org/abs/2004.09674">preprint</a> on the arXiv improving that conclusion, to show that quantum copy-protection of arbitrary unlearnable functions is possible relative to a <em>classical</em> oracle.  But my central open problem remained unanswered: is quantum copy-protection of arbitrary (unlearnable) functions possible in the real world, with no oracle?  A couple days ago, Ananth and La Placa put up a <a href="https://arxiv.org/abs/2005.05289">preprint</a> where they claim to show that the answer is no, assuming that there’s secure quantum Fully Homomorphic Encryption (FHE) of quantum circuits.  I haven’t yet understood the construction, but it looks plausible, and indeed closely related to Barak et al.’s <a href="https://www.iacr.org/archive/crypto2001/21390001.pdf">seminal proof</a> of the impossibility of <em>obfuscating</em> arbitrary programs in the classical world.  If this holds up, it (conditionally) resolves <em>another</em> of my favorite open problems—indeed, one that I recently mentioned in the Ask-Me-Anything session!</p>



<p>(3) Speaking of Boaz Barak: he, Chi-Ning Chou, and Xun Gao have a new <a href="https://arxiv.org/abs/2005.02421">preprint</a> about a fast classical way to spoof Google’s linear cross-entropy benchmark for <em>shallow</em> random quantum circuits (with a bias that degrades exponentially with the depth, remaining detectable up to a depth of say ~√log(n)).  As the authors point out, this by no means refutes Google’s supremacy experiment, which involved a larger depth.  But along with other recent results in the same direction (e.g. <a href="https://arxiv.org/abs/2001.00021">this one</a>), it does show that <em>some</em> exploitable structure is present even in random quantum circuits.  Barak et al. achieve their result by simply looking at the marginal distributions on the individual output qubits (although the analysis to show that this works gets rather hairy).  Boaz had told me all about this work when I saw him in person—back when traveling and meeting people in person was a thing!—but it’s great to see it up on the arXiv.</p>



<p>(4) Peter and Raphaël Clifford have <a href="https://arxiv.org/abs/2005.04214">announced</a> a faster classical algorithm to simulate BosonSampling.  To be clear, their algorithm is still exponential-time, but for the special case of a Haar-random scattering matrix, n photons, and m=n input and output modes, it runs in only ~1.69<sup>n</sup> time, as opposed to the previous bound of ~2<sup>n</sup>.  The upshot is that, if you want to achieve quantum supremacy using BosonSampling, then either you need more photons than previously thought (maybe 90 photons? 100?), or else you need a lot of modes (in our <a href="https://arxiv.org/abs/1011.3245">original paper</a>, Arkhipov and I recommended at least m~n<sup>2</sup> modes for several reasons, but naturally the experimentalists would like to cut any corners they can).</p>



<p>And what about my own “research program”?  Well yesterday, having previously challenged my 7-year-old daughter Lily with instances of comparison sorting, Eulerian tours, undirected connectivity, bipartite perfect matching, stable marriage, factoring, graph isomorphism, unknottedness, 3-coloring, subset sum, and traveling salesman, I finally introduced her to the P vs. NP problem!  Even though Lily can’t yet formally define “polynomial,” let alone “algorithm,” I’m satisfied that she understands <em>something</em> of what’s being asked.  But, in an unintended echo of one of my <a href="https://www.scottaaronson.com/blog/?p=4476">more controversial recent posts</a>, Lily insists on pronouncing NP as “nip.”</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4794"><span class="datestr">at May 13, 2020 05:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4385">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/05/12/spielman-srivastava-sparsification-a-la-talagrand/">Spielman-Srivastava Sparsification à la Talagrand</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 This is the second in a series of posts explaining a <a href="https://arxiv.org/abs/1905.01495">result on hypergraph sparsification</a> that uses Talagrand’s work on Gaussian processes. </p>
<p>
In the <a href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/">previous post</a> we talked about Gaussian and sub-Gaussian processes and generic chaining. </p>
<p>
In this post we talk about the Spielman-Srivastava probabilistic construction of graph sparsifiers. Their analysis requires a bound on the largest eigenvalue of a certain random matrix, that can be derived from matrix Chernoff bounds. </p>
<p>
We will then make our life harder and we will also derive an analysis of the Spielman-Srivastava construction by casting the largest eigenvalue of that random matrix as the sup of a sub-Gaussian process, and then we will apply the machinery from the previous post.</p>
<p>
This will be more complicated than it needs to be, but the payoff will be that, as will be shown in the next post, this more complicated proof will also apply, with some changes, to the setting of hypergraphs.</p>
<p>
<span id="more-4385"></span></p>
<p>
</p><p><b>1. Graph Sparsifiers </b></p>
<p></p><p>
For a graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> having vertex set <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />, if <img src="https://s0.wp.com/latex.php?latex=%7BS%5Csubseteq+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S\subseteq V}" class="latex" title="{S\subseteq V}" /> is a subset of vertices, we denote by <img src="https://s0.wp.com/latex.php?latex=%7Bcut_G%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{cut_G(S)}" class="latex" title="{cut_G(S)}" /> the number of edges that cross the cut <img src="https://s0.wp.com/latex.php?latex=%7B%28S%2CV-S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(S,V-S)}" class="latex" title="{(S,V-S)}" />, that is, that have one endpoint in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and one endpoint outside <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. If <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is a weighted graph, <img src="https://s0.wp.com/latex.php?latex=%7Bcut_G%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{cut_G(S)}" class="latex" title="{cut_G(S)}" /> is the sum of the weights of such edges.</p>
<p>
A graph <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> is a <em>cut sparsifier</em> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> with error at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> if <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> have the same vertex set <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> and, for every <img src="https://s0.wp.com/latex.php?latex=%7BS%5Csubseteq+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S\subseteq V}" class="latex" title="{S\subseteq V}" />, we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Cepsilon+%5Cleq+%5Cfrac%7Bcut_G%28S%29%7D%7Bcut_%7BG%27%7D+%28S%29+%7D+%5Cleq+1%2B%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\epsilon \leq \frac{cut_G(S)}{cut_{G'} (S) } \leq 1+\epsilon " class="latex" title="\displaystyle  1-\epsilon \leq \frac{cut_G(S)}{cut_{G'} (S) } \leq 1+\epsilon " /></p>
<p>
that is, if all cuts in <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> are the same, up to a multiplicative error <img src="https://s0.wp.com/latex.php?latex=%7B1%5Cpm+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1\pm \epsilon}" class="latex" title="{1\pm \epsilon}" />. (We use the convention that <img src="https://s0.wp.com/latex.php?latex=%7B0%2F0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0/0 = 1}" class="latex" title="{0/0 = 1}" />.) This definition was introduced by Benczur and Karger who showed that every graph has a cut sparsifier with at most <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n \log n)}" class="latex" title="{O(\epsilon^{-2} n \log n)}" /> edges, where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the number of vertices, and that such a sparsifier can be constructed by an efficient probabilistic algorithm.</p>
<p>
This is a useful construction because if one wants to run on <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> an algorithm that approximately solves a problem that depends on the cut structure of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (for example min cut, min st-cut, max flow, or an algorithm for a clustering problem), then one may alternatively run such algorithm on <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" />, and an approximate solution for <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> will also be an approximate solution for <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />. The advantage is that one runs the algorithm on a graph that has fewer edges, and so one needs less time and less memory to run the algorithm.</p>
<p>
The approach of Benczur and Karger is to assign to each edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> a probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" />, in a certain careful way that we will not describe. Then they generate <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> by doing the following independently for every edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" />: with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> we put the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" />, and give it weight <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" />, and with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p_e}" class="latex" title="{1-p_e}" /> we do not put the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" />. For every cut <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, we have that <img src="https://s0.wp.com/latex.php?latex=%7Bcut_%7BG%27%7D%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{cut_{G'}(S)}" class="latex" title="{cut_{G'}(S)}" /> is a random variable with expectation <img src="https://s0.wp.com/latex.php?latex=%7Bcut_G%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{cut_G(S)}" class="latex" title="{cut_G(S)}" />, and Benczur and Karger are able to use Chernoff bounds and a union bound to show that there is a setting of those probabilities such that it is likely that all cuts will be preserved with multiplicative error at <img src="https://s0.wp.com/latex.php?latex=%7B1%5Cpm+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1\pm \epsilon}" class="latex" title="{1\pm \epsilon}" /> and such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_e+p_e+%3D+O%28%5Cepsilon%5E%7B-2%7D+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_e p_e = O(\epsilon^{-2} n \log n)}" class="latex" title="{\sum_e p_e = O(\epsilon^{-2} n \log n)}" />. The union bound has to be done very carefully and, in particular, one has to use the fact that there can be few sparse cuts.</p>
<p>
Spielman and Teng introduced the stronger definition of <em>spectral sparsifier</em>: according to their definition, a graph <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> is a spectral sparsifier of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> with error at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> if, for every vector <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%7B%5Cmathbb+R%7D%5EV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in {\mathbb R}^V}" class="latex" title="{x\in {\mathbb R}^V}" /> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Cepsilon+%5Cleq+%5Cfrac%7B+x%5ET+L_G+x%7D%7Bx%5ET+L_%7BG%27%7D+x%7D+%5Cleq+1%2B+%5Cepsilon+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\epsilon \leq \frac{ x^T L_G x}{x^T L_{G'} x} \leq 1+ \epsilon " class="latex" title="\displaystyle  1-\epsilon \leq \frac{ x^T L_G x}{x^T L_{G'} x} \leq 1+ \epsilon " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7BL_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_G}" class="latex" title="{L_G}" /> is the Laplacian matrix of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> and, as before, we take the convention that <img src="https://s0.wp.com/latex.php?latex=%7B0%2F0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0/0 = 1}" class="latex" title="{0/0 = 1}" />. This is a stronger condition because, if <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is the indicator vector of a set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bx%5ET+L_G+x+%3D+cut_G%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^T L_G x = cut_G(S)}" class="latex" title="{x^T L_G x = cut_G(S)}" />, so the Benczur-Karger condition is equivalent to the special case of the Spielman-Teng condition in which we only quantify over Boolean vectors <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%5C%7B+0%2C1%5C%7D%5EV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in \{ 0,1\}^V}" class="latex" title="{x\in \{ 0,1\}^V}" />.</p>
<p>
Spielman and Teng gave an efficient construction of spectral sparsifiers with <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n+%5Clog%5E%7BO%281%29%7D+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n \log^{O(1)} n)}" class="latex" title="{O(\epsilon^{-2} n \log^{O(1)} n)}" /> edges. </p>
<p>
Later, Spielman and Srivastava reduced the number of edges to <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n \log n)}" class="latex" title="{O(\epsilon^{-2} n \log n)}" />, with a proof similar to that of Benczur and Karger’s: they attribute a probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> to each edge, and then sample each edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" />, weighing it <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" /> if selected. The Laplacian <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G'}}" class="latex" title="{L_{G'}}" /> of the resulting weighted graph satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+L_%7BG%27%7D+%3D+L_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} L_{G'} = L_G}" class="latex" title="{\mathop{\mathbb E} L_{G'} = L_G}" />, and so one has to study the concentration of the random matrix <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G'}}" class="latex" title="{L_{G'}}" /> around its average, which is doable using matrix Chernoff bounds.</p>
<p>
More recently, Batson, Spielman and Srivastava gave a construction of spectral sparsifiers with <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%5E%7B-2%7D+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon^{-2} n)}" class="latex" title="{O(\epsilon^{-2} n)}" /> edges. Their construction is deterministic, and it proceeds by choosing one edge at a time, in a process that is driven by a certain potential function. Allen-Zhu, Liao and Orecchia have presented an interpretation of Batson-Spielman-Srivastava as an online optimization game played using a Follow-the-Regularized-Leader strategy. As my sequence of posts on online optimization will continue after the current hiatus, I plan to present the results of Allen-Zhu, Liao and Orecchia.</p>
<p>
</p><p><b>2. The Spielman-Srivastava Construction </b></p>
<p></p><p>
We will assume that the graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is connected, otherwise we can apply the construction below to each connected component.</p>
<p>
In the Spielman-Srivastava construction, we assign a probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> to each edge, and then we want to say that the event</p>
<p>
<a name="eq.ss"></a></p><a name="eq.ss">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cforall+x+%5Cin+%7B%5Cmathbb+R%7D%5En%3A+%5C+%5C+%5C+-+%5Cepsilon+x%5ET+L_G+x+%5Cleq+x%5ET+L_%7BG%27%7D+x+-+x%5ET+L_G+x+%5Cleq+%5Cepsilon+x%5ET+L_G+x+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \forall x \in {\mathbb R}^n: \ \ \ - \epsilon x^T L_G x \leq x^T L_{G'} x - x^T L_G x \leq \epsilon x^T L_G x \ \ \ \ \ (1)" class="latex" title="\displaystyle   \forall x \in {\mathbb R}^n: \ \ \ - \epsilon x^T L_G x \leq x^T L_{G'} x - x^T L_G x \leq \epsilon x^T L_G x \ \ \ \ \ (1)" /></p>
</a><p><a name="eq.ss"></a> holds with high probability, where <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> is the random graph obtained by sampling each edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> independently with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" />, and weighing it <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e}" class="latex" title="{1/p_e}" /> if selected, and <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G'}}" class="latex" title="{L_{G'}}" /> is the Laplacian of <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" />. </p>
<p>
Actually, Spielman and Srivastava sample from a slightly different distribution. Namely they repeatedly sample from a distribution on all edges, in which edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> has probability proportional to <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" />, because this distribution is easier to analyze with matrix Chernoff bounds, but we will proceed to analyze the distribution described in the above paragraph.</p>
<p>
<a href="https://en.wikipedia.org/wiki/Matrix_Chernoff_bound">Matrix Chernoff bounds</a> give upper bounds to the probability that a sum of independent random matrices deviates in operator norm from its average, and take the form of</p>
<p>
<a name="eq.matrixc"></a></p><a name="eq.matrixc">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5CPr+%5Cleft%5B+%5Cleft%5C%7C+%5Csum_e+%28M_e+-+%5Cmathop%7B%5Cmathbb+E%7D+M_e+%29+%5Cright%5C%7C+%5Cgeq+%5Cell+%5Cright%5D+%5Cleq+%5Ccdots+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \Pr \left[ \left\| \sum_e (M_e - \mathop{\mathbb E} M_e ) \right\| \geq \ell \right] \leq \cdots \ \ \ \ \ (2)" class="latex" title="\displaystyle   \Pr \left[ \left\| \sum_e (M_e - \mathop{\mathbb E} M_e ) \right\| \geq \ell \right] \leq \cdots \ \ \ \ \ (2)" /></p>
</a><p><a name="eq.matrixc"></a> where the <img src="https://s0.wp.com/latex.php?latex=%7BM_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_e}" class="latex" title="{M_e}" /> are independent random matrices. If the matrices are <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\times n}" class="latex" title="{n\times n}" /> Hermitian, the most general case is given by the <em>matrix Bernstein</em> bound</p>
<p>
<a name="eq.matrix.bern"></a></p><a name="eq.matrix.bern">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5CPr+%5Cleft%5B+%5Cleft%5C%7C+%5Csum_e+%28M_e+-+%5Cmathop%7B%5Cmathbb+E%7D+M_e+%29+%5Cright%5C%7C+%5Cgeq+%5Cell+%5Cright%5D+%5Cleq+2n+%5Ccdot+%5Cexp+%5Cleft%28+%5Cfrac%7B-%5Cell%5E2%7D%7B2%5Csigma%5E2+%2B+%5Cfrac+23+B%5Cell%7D+%5Cright%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \Pr \left[ \left\| \sum_e (M_e - \mathop{\mathbb E} M_e ) \right\| \geq \ell \right] \leq 2n \cdot \exp \left( \frac{-\ell^2}{2\sigma^2 + \frac 23 B\ell} \right) \ \ \ \ \ (3)" class="latex" title="\displaystyle   \Pr \left[ \left\| \sum_e (M_e - \mathop{\mathbb E} M_e ) \right\| \geq \ell \right] \leq 2n \cdot \exp \left( \frac{-\ell^2}{2\sigma^2 + \frac 23 B\ell} \right) \ \ \ \ \ (3)" /></p>
</a><p><a name="eq.matrix.bern"></a> where </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csigma%5E2+%3A%3D+%5Cleft%5C%7C+%5Csum_e+%5Cmathop%7B%5Cmathbb+E%7D+%28M_e+-+%5Cmathop%7B%5Cmathbb+E%7D+M_e+%29%5E2+%5Cright%5C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sigma^2 := \left\| \sum_e \mathop{\mathbb E} (M_e - \mathop{\mathbb E} M_e )^2 \right\| " class="latex" title="\displaystyle  \sigma^2 := \left\| \sum_e \mathop{\mathbb E} (M_e - \mathop{\mathbb E} M_e )^2 \right\| " /></p>
<p> is the “variance” of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_e+M_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_e M_e}" class="latex" title="{\sum_e M_e}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is an upper bound such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+e%5C+%5C+%7C%7CM_e%7C%7C+%5Cleq+B&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall e\ \ ||M_e|| \leq B" class="latex" title="\displaystyle  \forall e\ \ ||M_e|| \leq B" /></p>
<p> holds with probability one.</p>
<p>
It remains to reformulate <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss">(1)</a> in a form like <a href="https://lucatrevisan.wordpress.com/feed/#eq.matrixc">(2)</a>. We first note that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_G+%3D+%5Csum_%7Be+%5Cin+E%7D+L_e+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_G = \sum_{e \in E} L_e " class="latex" title="\displaystyle  L_G = \sum_{e \in E} L_e " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7BL_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_e}" class="latex" title="{L_e}" /> is the Laplacian matrix of the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" />. That is, if <img src="https://s0.wp.com/latex.php?latex=%7Be+%3D+%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e = (u,v)}" class="latex" title="{e = (u,v)}" />, then <img src="https://s0.wp.com/latex.php?latex=%7BL_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_e}" class="latex" title="{L_e}" /> is the rank-1 matrix whose quadratic form is <img src="https://s0.wp.com/latex.php?latex=%7Bx%5ET+L_e+x+%3D+%28x_u+-+x_v%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^T L_e x = (x_u - x_v)^2}" class="latex" title="{x^T L_e x = (x_u - x_v)^2}" />.</p>
<p>
So we can write </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5ET+L_%7BG%27%7D+x+-+x%5ET+L_G+x+%3D+%5Csum_e+z_e+L_e+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^T L_{G'} x - x^T L_G x = \sum_e z_e L_e " class="latex" title="\displaystyle  x^T L_{G'} x - x^T L_G x = \sum_e z_e L_e " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bz_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_e}" class="latex" title="{z_e}" /> is a random variable that is equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fp_e+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/p_e - 1}" class="latex" title="{1/p_e - 1}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> and to <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p_e}" class="latex" title="{1-p_e}" />. </p>
<p>
We also note that all the terms in <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss">(1)</a> are invariant under shifts in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, so we can rewrite the event <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss">(1)</a> as</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%5Cin+%7B%5Cmathbb+R%7D%5En_%5Cperp+%3A+%5C+%5C+-+%5Cepsilon+x%5ET+L_G+x+%5Cleq+%5Csum_e+z_e+x%5ET+L_e+x+%5Cleq+%5Cepsilon+x%5ET+L_G+x+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall x\in {\mathbb R}^n_\perp : \ \ - \epsilon x^T L_G x \leq \sum_e z_e x^T L_e x \leq \epsilon x^T L_G x \ \ \ \ \ (4)" class="latex" title="\displaystyle  \forall x\in {\mathbb R}^n_\perp : \ \ - \epsilon x^T L_G x \leq \sum_e z_e x^T L_e x \leq \epsilon x^T L_G x \ \ \ \ \ (4)" /></p>
<p>
Where <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En+_%5Cperp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n _\perp}" class="latex" title="{{\mathbb R}^n _\perp}" /> is the set of vectors <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in {\mathbb R}^n}" class="latex" title="{x\in {\mathbb R}^n}" /> that are orthogonal to <img src="https://s0.wp.com/latex.php?latex=%7B%281%5Ccdots+1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1\cdots 1)}" class="latex" title="{(1\cdots 1)}" />. If we apply the change of variable <img src="https://s0.wp.com/latex.php?latex=%7By+%3D+L_G%5E%7B1%2F2%7D+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y = L_G^{1/2} x}" class="latex" title="{y = L_G^{1/2} x}" />, which is bijective on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En_%5Cperp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n_\perp}" class="latex" title="{{\mathbb R}^n_\perp}" />, the previous event becomes</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+y%5Cin+%7B%5Cmathbb+R%7D%5En_%5Cperp+%3A+%5C+%5C+-+%5Cepsilon+%7C%7Cy%7C%7C%5E2+%5Cleq+%5Csum_e+z_e+y%5ET+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+y+%5Cleq+%5Cepsilon%7C%7Cy%7C%7C%5E2+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall y\in {\mathbb R}^n_\perp : \ \ - \epsilon ||y||^2 \leq \sum_e z_e y^T L_{G}^{-1/2} L_e L^{-1/2}_G y \leq \epsilon||y||^2 \ \ \ \ \ (5)" class="latex" title="\displaystyle  \forall y\in {\mathbb R}^n_\perp : \ \ - \epsilon ||y||^2 \leq \sum_e z_e y^T L_{G}^{-1/2} L_e L^{-1/2}_G y \leq \epsilon||y||^2 \ \ \ \ \ (5)" /></p>
<p>
which is implied by (and actually equivalent to):</p>
<p>
<a name="eq.ss.spec"></a></p><a name="eq.ss.spec">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5C%7C+%5Csum_e+z_e+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%5Cright+%5C%7C+%5Cleq+%5Cepsilon+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left\| \sum_e z_e L_{G}^{-1/2} L_e L^{-1/2}_G \right \| \leq \epsilon \ \ \ \ \ (6)" class="latex" title="\displaystyle  \left\| \sum_e z_e L_{G}^{-1/2} L_e L^{-1/2}_G \right \| \leq \epsilon \ \ \ \ \ (6)" /></p>
</a><p><a name="eq.ss.spec"></a></p>
<p>
Looking at the matrix Bernstein bound, we want to choose the <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> so that, say,</p>
<p>
<a name="eq.ss.var"></a></p><a name="eq.ss.var">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cleft%5C%7C+%5Csum_e+%5Cmathop%7B%5Cmathbb+E%7D+%28z_e+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%29%5E2%5Cright+%5C%7C+%3C+%5Cfrac+%7B%5Cepsilon%5E2%7D%7B4%5Clog+n%7D+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \left\| \sum_e \mathop{\mathbb E} (z_e L_{G}^{-1/2} L_e L^{-1/2}_G )^2\right \| &lt; \frac {\epsilon^2}{4\log n} \ \ \ \ \ (7)" class="latex" title="\displaystyle   \left\| \sum_e \mathop{\mathbb E} (z_e L_{G}^{-1/2} L_e L^{-1/2}_G )^2\right \| &lt; \frac {\epsilon^2}{4\log n} \ \ \ \ \ (7)" /></p>
</a><p><a name="eq.ss.var"></a> and also so that <a name="eq.ss.max"></a></p><a name="eq.ss.max">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cforall+e+%5C+%5C+%5C+%7C%7Cz_e+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G%7C%7C+%3C+%5Cfrac%7B%5Cepsilon%7D%7B4%5Clog+n%7D+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \forall e \ \ \ ||z_e L_{G}^{-1/2} L_e L^{-1/2}_G|| &lt; \frac{\epsilon}{4\log n} \ \ \ \ \ (8)" class="latex" title="\displaystyle   \forall e \ \ \ ||z_e L_{G}^{-1/2} L_e L^{-1/2}_G|| &lt; \frac{\epsilon}{4\log n} \ \ \ \ \ (8)" /></p>
</a><p><a name="eq.ss.max"></a> holds with probability 1. </p>
<p>
The variance term <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss.var">(7)</a> is the spectral norm of </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_e+%28+%5Cmathop%7B%5Cmathbb+E%7D+z_e%5E2+%29+%5Ccdot+%28+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_e ( \mathop{\mathbb E} z_e^2 ) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2" class="latex" title="\displaystyle  \sum_e ( \mathop{\mathbb E} z_e^2 ) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_e+%5Cleft%28+%5Cfrac+1+%7Bp_e%7D+-+1+%5Cright%29+%5Ccdot+%28+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_e \left( \frac 1 {p_e} - 1 \right) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2 " class="latex" title="\displaystyle  = \sum_e \left( \frac 1 {p_e} - 1 \right) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_e+%5Cleft%28+%5Cfrac+1+%7Bp_e%7D+-+1+%5Cright%29+%5Ccdot+%7C%7C+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%7C%7C+%5Ccdot+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \cdot L_{G}^{-1/2} L_e L^{-1/2}_G " class="latex" title="\displaystyle  = \sum_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \cdot L_{G}^{-1/2} L_e L^{-1/2}_G " /></p>
<p> where we computed <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+z_e%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} z_e^2}" class="latex" title="{\mathop{\mathbb E} z_e^2}" /> and we used the fact that if <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is a rank-1 real-valued symmetric matrix then <img src="https://s0.wp.com/latex.php?latex=%7BM%5E2+%3D+%7C%7CM%7C%7C+%5Ccdot+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M^2 = ||M|| \cdot M}" class="latex" title="{M^2 = ||M|| \cdot M}" />.</p>
<p>
So we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_e+%28+%5Cmathop%7B%5Cmathbb+E%7D+z_e%5E2+%29+%5Ccdot+%28+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_e ( \mathop{\mathbb E} z_e^2 ) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2" class="latex" title="\displaystyle  \sum_e ( \mathop{\mathbb E} z_e^2 ) \cdot ( L_{G}^{-1/2} L_e L^{-1/2}_G )^2" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq+%5Cleft%28+%5Cmax_e+%5Cleft%28+%5Cfrac+1+%7Bp_e%7D+-+1+%5Cright%29+%5Ccdot+%7C%7C+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%7C%7C+%5Cright%29+%5Ccdot+%5Csum_e+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq \left( \max_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \right) \cdot \sum_e L_{G}^{-1/2} L_e L^{-1/2}_G " class="latex" title="\displaystyle  \preceq \left( \max_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \right) \cdot \sum_e L_{G}^{-1/2} L_e L^{-1/2}_G " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq+%5Cleft%28+%5Cmax_e+%5Cleft%28+%5Cfrac+1+%7Bp_e%7D+-+1+%5Cright%29+%5Ccdot+%7C%7C+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%7C%7C+%5Cright%29+%5Ccdot+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq \left( \max_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \right) \cdot I " class="latex" title="\displaystyle  \preceq \left( \max_e \left( \frac 1 {p_e} - 1 \right) \cdot || L_{G}^{-1/2} L_e L^{-1/2}_G || \right) \cdot I " /></p>
<p>
If we set </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_e+%3D+%5Cmin+%5Cleft%5C%7B+4+%5Cfrac%7B%5Clog+n%7D%7B%5Cepsilon%5E2%7D+%7C%7CL_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%7C%7C+%2C+1+%5Cright%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p_e = \min \left\{ 4 \frac{\log n}{\epsilon^2} ||L_{G}^{-1/2} L_e L^{-1/2}_G || , 1 \right\} " class="latex" title="\displaystyle  p_e = \min \left\{ 4 \frac{\log n}{\epsilon^2} ||L_{G}^{-1/2} L_e L^{-1/2}_G || , 1 \right\} " /></p>
<p> then we see that we satisfy both <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss.var">(7)</a> and <a href="https://lucatrevisan.wordpress.com/feed/#eq.ss.max">(8)</a>.</p>
<p>
The term <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7C+L_%7BG%7D%5E%7B-1%2F2%7D+L_e+L%5E%7B-1%2F2%7D_G+%7C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ || L_{G}^{-1/2} L_e L^{-1/2}_G ||}" class="latex" title="{ || L_{G}^{-1/2} L_e L^{-1/2}_G ||}" /> is the <em>effective resistance</em> of the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> and it is usually denoted as <img src="https://s0.wp.com/latex.php?latex=%7BR_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R_e}" class="latex" title="{R_e}" />. It is known that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_eR_e+%3D+n-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_eR_e = n-1}" class="latex" title="{\sum_eR_e = n-1}" /> for connected graphs. Thus we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_e+p_e+%3D+O%28%5Cepsilon%5E%7B-2%7D+n+%5Clog+n%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_e p_e = O(\epsilon^{-2} n \log n) " class="latex" title="\displaystyle  \sum_e p_e = O(\epsilon^{-2} n \log n) " /></p>
<p> as promised.</p>
<p>
</p><p><b>3. Analysing the Construction as a Sub-Gaussian Process </b></p>
<p></p><p>
Now we would like to provide an analysis of the Spielman-Srivastava construction in terms of bounding the sup of a sub-Gaussian process via the Talagrand comparison inequality. Indeed we can think of our goal as showing that the following two random variables are both <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq \epsilon}" class="latex" title="{\leq \epsilon}" /> with high probability:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Csum_e+z_e+x%5ET+L_e+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \sum_e z_e x^T L_e x " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \sum_e z_e x^T L_e x " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Csum_e+-z_e+x%5ET+L_e+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \sum_e -z_e x^T L_e x " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \sum_e -z_e x^T L_e x " /></p>
<p>
where the <img src="https://s0.wp.com/latex.php?latex=%7Bz_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_e}" class="latex" title="{z_e}" /> are the random variables defined in the previous section. Unfortunately, while random processes that involve weighted sums of Rademacher random variables are well suited to such an analysis, random processes that involve highly biased Boolean random variables do not work very well in this framework.</p>
<p>
To avoid this problem, we will think of performing the Spielman-Srivastava sampling in phases, such that each phase involves unbiased Boolean random variables.</p>
<p>
To avoid having to deal with too many constants, we will think of setting <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%3D+%5Cmin+%5C%7B+1%2C+%5Cepsilon%5E%7B-2%7D+R_e+%5Clog+n+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e = \min \{ 1, \epsilon^{-2} R_e \log n \}}" class="latex" title="{p_e = \min \{ 1, \epsilon^{-2} R_e \log n \}}" />, with a goal of achieving sparsification with error <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\epsilon)}" class="latex" title="{O(\epsilon)}" />. We will want to think of the process of sampling an edge as a sequence of unbiased Boolean choices, so it will be convenient to round up probabilities to non-positive powers of 2. So we will set edge probabilities such that <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%3D+2%5E%7B-j_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e = 2^{-j_e}}" class="latex" title="{p_e = 2^{-j_e}}" /> for some integer <img src="https://s0.wp.com/latex.php?latex=%7Bj_e+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e \geq 0}" class="latex" title="{j_e \geq 0}" /> and such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin+%5C%7B+1%2C+%5Cepsilon%5E%7B-2%7D+R_e+%5Clog+n+%5C%7D+%5Cleq+p_e+%5Cleq+%5Cmin+%5C%7B+1%2C+2+%5Cepsilon%5E%7B-2%7D+R_e+%5Clog+n+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \min \{ 1, \epsilon^{-2} R_e \log n \} \leq p_e \leq \min \{ 1, 2 \epsilon^{-2} R_e \log n \} " class="latex" title="\displaystyle  \min \{ 1, \epsilon^{-2} R_e \log n \} \leq p_e \leq \min \{ 1, 2 \epsilon^{-2} R_e \log n \} " /></p>
<p>
If we let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmin_e+p_e+%3D+2%5E%7B-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\min_e p_e = 2^{-\ell}}" class="latex" title="{\min_e p_e = 2^{-\ell}}" />, we will think of the process of sampling <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> as proceeding in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> rounds. If <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%3D+2%5E%7B-j_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e = 2^{-j_e}}" class="latex" title="{p_e = 2^{-j_e}}" /> then, in each of the last <img src="https://s0.wp.com/latex.php?latex=%7Bj_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e}" class="latex" title="{j_e}" /> round (that is, in round <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+-j_e+%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell -j_e +1}" class="latex" title="{\ell -j_e +1}" /> through <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" />), we choose with probability 1/2 to delete the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> and with probability 1/2 to double its weight.</p>
<p>
(Why do we do it in the last <img src="https://s0.wp.com/latex.php?latex=%7Bj_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e}" class="latex" title="{j_e}" /> rounds and not in the first <img src="https://s0.wp.com/latex.php?latex=%7Bj_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e}" class="latex" title="{j_e}" /> rounds? This issue confused me a lot at some point. Hold on to this question until later.)</p>
<p>
Let us call <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(k)}}" class="latex" title="{G^{(k)}}" /> the graph obtained after round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, so that <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%280%29%7D+%3D+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(0)} = G}" class="latex" title="{G^{(0)} = G}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%28%5Cell%29%7D+%3D+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(\ell)} = G'}" class="latex" title="{G^{(\ell)} = G'}" />. We see that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Cleft+%7C+%5Csum_e+z_e+x%5ET+L_G+x+%5Cright%7C+%5Cleq+%5Csum_%7Bk%3D1%7D%5E%5Cell+%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Cleft+%7C+x%5ET+%28L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D%7D+%29+x+%5Cright%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | \sum_e z_e x^T L_G x \right| \leq \sum_{k=1}^\ell \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | \sum_e z_e x^T L_G x \right| \leq \sum_{k=1}^\ell \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| " /></p>
<p>
Let us now understand the quadratic form in each of the above term. If we let <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k)}_e}" class="latex" title="{w^{(k)}_e}" /> be the weight of edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> in graph <img src="https://s0.wp.com/latex.php?latex=%7BG%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G^{(k)}}" class="latex" title="{G^{(k)}}" />, we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5ET+%28L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D%7D+%29+x+%3D+%5Csum_e+%28w%5E%7B%28k%29%7D_e+-+w%5E%7B%28k-1%29%7D_e+%29+%5C+x%5ET+L_e+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x = \sum_e (w^{(k)}_e - w^{(k-1)}_e ) \ x^T L_e x " class="latex" title="\displaystyle  x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x = \sum_e (w^{(k)}_e - w^{(k-1)}_e ) \ x^T L_e x " /></p>
<p> Regarding the weights, if we consider an edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bp_e+%3D+2%5E%7B-j_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e = 2^{-j_e}}" class="latex" title="{p_e = 2^{-j_e}}" />, we have that the edge <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is left untouched in round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+-+j_e+%2B1+%3E+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell - j_e +1 &gt; k}" class="latex" title="{\ell - j_e +1 &gt; k}" />, that is, if <img src="https://s0.wp.com/latex.php?latex=%7Bj_e+%5Cleq+%5Cell+-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e \leq \ell -k}" class="latex" title="{j_e \leq \ell -k}" />. In that case, <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k%29%7D_e+-+w%5E%7B%28k-1%29%7D_e%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k)}_e - w^{(k-1)}_e=0}" class="latex" title="{w^{(k)}_e - w^{(k-1)}_e=0}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Bj_e+%5Cgeq+%5Cell+-k%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_e \geq \ell -k+1}" class="latex" title="{j_e \geq \ell -k+1}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k)}_e}" class="latex" title="{w^{(k)}_e}" /> is equally likely to be <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B+2w%5E%7B%28k-1%29%7D_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2w^{(k-1)}_e}" class="latex" title="{ 2w^{(k-1)}_e}" />. In other words, <img src="https://s0.wp.com/latex.php?latex=%7Bw%5E%7B%28k%29%7D_e+-+w%5E%7B%28k-1%29%7D_e+%3D+r_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w^{(k)}_e - w^{(k-1)}_e = r_e^{(k)} w^{(k-1)}}" class="latex" title="{w^{(k)}_e - w^{(k-1)}_e = r_e^{(k)} w^{(k-1)}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Br_e%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_e^{(k)}}" class="latex" title="{r_e^{(k)}}" /> is a Rademacher random variable. </p>
<p>
Putting everything together, we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5ET+%28L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D%7D+%29+x+%3D+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5C+r_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D+%5C+x%5ET+L_e+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x = \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_e x " class="latex" title="\displaystyle  x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x = \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_e x " /></p>
<p> and now we are in good shape because Rademacher sums are well suited to be analyzed as sub-Gaussian processes. In particular, we will able to prove the following lemma.</p>
<blockquote><p><b>Lemma 1</b> <em> There are bounds <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_k+%3D+O%28%5Cepsilon+%5Ccdot+2%5E%7B%28k-%5Cell%29%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon_k = O(\epsilon \cdot 2^{(k-\ell)/2})}" class="latex" title="{\epsilon_k = O(\epsilon \cdot 2^{(k-\ell)/2})}" /> such that for every outcome of the first <img src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k-1}" class="latex" title="{k-1}" /> steps that satisfies <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%5E%7B%28k-1%29%7D%7D+%5Cpreceq+2+L_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G^{(k-1)}} \preceq 2 L_G}" class="latex" title="{L_{G^{(k-1)}} \preceq 2 L_G}" />, we have </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5Cleft%5B+%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Cleft+%7C+x%5ET+%28L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D%7D+%29+x+%5Cright%7C+%3E+%5Cepsilon_k+%5Cright%5D+%5Cleq+%5Cfrac+1n+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \Pr \left[ \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| &gt; \epsilon_k \right] \leq \frac 1n " class="latex" title="\displaystyle  \Pr \left[ \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| &gt; \epsilon_k \right] \leq \frac 1n " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
Applying the lemma inductively, we see that we have probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cell%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\ell/n}" class="latex" title="{1-\ell/n}" /> that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Cleft+%7C+%5Csum_e+z_e+x%5ET+L_G+x+%5Cright%7C+%5Cleq+%5Csum_%7Bk%3D1%7D%5E%5Cell+%5Cepsilon_k+%5Cleq+O%28%5Cepsilon%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | \sum_e z_e x^T L_G x \right| \leq \sum_{k=1}^\ell \epsilon_k \leq O(\epsilon) " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | \sum_e z_e x^T L_G x \right| \leq \sum_{k=1}^\ell \epsilon_k \leq O(\epsilon) " /></p>
<p> as desired, and it remains to observe that in every undirected graph every edge has effective resistance at least <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/n^{O(1)}}" class="latex" title="{1/n^{O(1)}}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+O%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell = O(\log n)}" class="latex" title="{\ell = O(\log n)}" />.</p>
<p>
It will be convenient to do a change of variables and write</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5C+%5C+%5Cleft+%7C+x%5ET+%28L_%7BG%5E%7B%28k%29%7D%7D+-+L_%7BG%5E%7B%28k-1%29%7D%7D+%29+x+%5Cright%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| " class="latex" title="\displaystyle  \sup_{x: x^T L_G x = 1 } \ \ \left | x^T (L_{G^{(k)}} - L_{G^{(k-1)}} ) x \right| " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csup_%7Bx%3A+x%5ET+L_G+x+%3D+1+%7D+%5Cleft+%7C+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5C+r_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D+%5C+x%5ET+L_e+x+%5Cright+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sup_{x: x^T L_G x = 1 } \left | \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_e x \right | " class="latex" title="\displaystyle  = \sup_{x: x^T L_G x = 1 } \left | \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_e x \right | " /></p>
<p> <a name="eq.termk"></a></p><a name="eq.termk">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%3D+%5Csup_%7By%3A+%7C%7Cy%7C%7C%3D1+%7D+%5Cleft+%7C+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5C+r_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D+%5C+x%5ET+L_G%5E%7B-1%2F2%7D+L_e+L_G%5E%7B-1%2F2%7D+x+%5Cright+%7C+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   = \sup_{y: ||y||=1 } \left | \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_G^{-1/2} L_e L_G^{-1/2} x \right | \ \ \ \ \ (9)" class="latex" title="\displaystyle   = \sup_{y: ||y||=1 } \left | \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)} \ x^T L_G^{-1/2} L_e L_G^{-1/2} x \right | \ \ \ \ \ (9)" /></p>
</a><p><a name="eq.termk"></a> To lighten up the notation in our subsequent arguments, it will be convenient to give names to the matrices that we obtain after this change of basis, and call </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M_e+%3A%3D+L_G%5E%7B-1%2F2%7D+L_e+L_G%5E%7B-1%2F2%7D+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M_e := L_G^{-1/2} L_e L_G^{-1/2} \ \ \ \ \ (10)" class="latex" title="\displaystyle  M_e := L_G^{-1/2} L_e L_G^{-1/2} \ \ \ \ \ (10)" /></p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3A%3D+L_G%5E%7B-1%2F2%7D+L_G+L_G%5E%7B-1%2F2%7D+%3D+%5Csum_e+M_e+%5Cpreceq+I+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M := L_G^{-1/2} L_G L_G^{-1/2} = \sum_e M_e \preceq I \ \ \ \ \ (11)" class="latex" title="\displaystyle  M := L_G^{-1/2} L_G L_G^{-1/2} = \sum_e M_e \preceq I \ \ \ \ \ (11)" /></p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7B%28k%29%7D+%3A%3D+L_G%5E%7B-1%2F2%7D+L_%7BG%5E%7B%28k%29%7D%7D+L_G%5E%7B-1%2F2%7D%3D+%5Csum_e+w%5E%7B%28k%29%7D+_e+M_e+%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{(k)} := L_G^{-1/2} L_{G^{(k)}} L_G^{-1/2}= \sum_e w^{(k)} _e M_e \ \ \ \ \ (12)" class="latex" title="\displaystyle  M^{(k)} := L_G^{-1/2} L_{G^{(k)}} L_G^{-1/2}= \sum_e w^{(k)} _e M_e \ \ \ \ \ (12)" /></p>
<p> In this notation, we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin+%5C%7B+1%2C+%5Cepsilon%5E%7B-2%7D+%7C%7CM_e%7C%7C+%5Clog+n+%5C%7D+%5Cleq+p_e+%5Cleq+%5Cmin+%5C%7B+1%2C+2+%5Cepsilon%5E%7B-2%7D+%7C%7CM_e%7C%7C+%5Clog+n+%5C%7D+%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \min \{ 1, \epsilon^{-2} ||M_e|| \log n \} \leq p_e \leq \min \{ 1, 2 \epsilon^{-2} ||M_e|| \log n \} \ \ \ \ \ (13)" class="latex" title="\displaystyle  \min \{ 1, \epsilon^{-2} ||M_e|| \log n \} \leq p_e \leq \min \{ 1, 2 \epsilon^{-2} ||M_e|| \log n \} \ \ \ \ \ (13)" /></p>
<p> and recall that we assumed </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7B%28k-1%29%7D+%5Cpreceq+2+M+%5Cpreceq+2I+%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{(k-1)} \preceq 2 M \preceq 2I \ \ \ \ \ (14)" class="latex" title="\displaystyle  M^{(k-1)} \preceq 2 M \preceq 2I \ \ \ \ \ (14)" /></p>
<p>
With this notation, the quantity in <a href="https://lucatrevisan.wordpress.com/feed/#eq.termk">(9)</a> that we want to bound becomes </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7By%3A+%7C%7Cy%7C%7C%3D1+%7D+%7C+F%28y%29+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{y: ||y||=1 } | F(y) | " class="latex" title="\displaystyle  \sup_{y: ||y||=1 } | F(y) | " /></p>
<p> where </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28y%29+%3D+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5C+r_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D_e+%5C+y%5ET+M_e+y+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(y) = \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)}_e \ y^T M_e y " class="latex" title="\displaystyle  F(y) = \sum_{e : p_e \leq 2^{k-1-\ell}} \ r_e^{(k)} w^{(k-1)}_e \ y^T M_e y " /></p>
<p> is a centered random process.</p>
<p>
Define the centered Gaussian process </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+F%28y%29+%3A%3D+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5C+g_e%5E%7B%28k%29%7D+w%5E%7B%28k-1%29%7D_e+%5C+y%5ET+M_e+y+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \hat F(y) := \sum_{e : p_e \leq 2^{k-1-\ell}} \ g_e^{(k)} w^{(k-1)}_e \ y^T M_e y " class="latex" title="\displaystyle  \hat F(y) := \sum_{e : p_e \leq 2^{k-1-\ell}} \ g_e^{(k)} w^{(k-1)}_e \ y^T M_e y " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bg_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_e}" class="latex" title="{g_e}" /> are independent standard normal random variables. Then we immediately see that both <img src="https://s0.wp.com/latex.php?latex=%7B-F%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-F(\cdot)}" class="latex" title="{-F(\cdot)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(\cdot)}" class="latex" title="{F(\cdot)}" /> are <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />-dominated by <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F(\cdot)}" class="latex" title="{\hat F(\cdot)}" />, because </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%28x%29+-+F%28y%29+%7C%7C%5E2_%7B%5CPsi_2%7D+%3D+O%281%29+%5Ccdot+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D+_e%5C+x%5ET+M_e+x+%5Cright%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} = O(1) \cdot \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)} _e\ x^T M_e x \right)^2 " class="latex" title="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} = O(1) \cdot \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)} _e\ x^T M_e x \right)^2 " /></p>
<p> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%28%5Chat+F%28x%29+-+%5Chat+F%28y%29+%29%5E2+%3D+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e+%5C+x%5ET+M_e+x+%5Cright%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} (\hat F(x) - \hat F(y) )^2 = \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ x^T M_e x \right)^2 " class="latex" title="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} (\hat F(x) - \hat F(y) )^2 = \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ x^T M_e x \right)^2 " /></p>
<p>
In order to deduce the lemma from the Talagrand comparison inequality it suffices to show that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bx%3A+%7C%7Cx%7C%7C%3D1%7D+%5Chat+F%28x%29+%5Cleq+O%28%5Cepsilon_k%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\epsilon_k) " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\epsilon_k) " /></p>
<p> and to have a bound on the diameter </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+d%28x%2Cy%29+%5Cleq+O+%5Cleft%28+%5Cfrac+%7B%5Cepsilon_k%7D+%7B%5Csqrt+%7B%5Clog+n%7D%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y: ||x||=||y||=1} d(x,y) \leq O \left( \frac {\epsilon_k} {\sqrt {\log n}} \right) " class="latex" title="\displaystyle  \sup_{x,y: ||x||=||y||=1} d(x,y) \leq O \left( \frac {\epsilon_k} {\sqrt {\log n}} \right) " /></p>
<p>
To bound the average supremum of the Gaussian process we could use generic chaining, but fortunately there is a a matrix Chernoff bound that say that if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+A_e%5C%7D_%7Be%5Cin+E%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ A_e\}_{e\in E}}" class="latex" title="{\{ A_e\}_{e\in E}}" /> are real-valued symmetric matrices and <img src="https://s0.wp.com/latex.php?latex=%7Bg_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_e}" class="latex" title="{g_e}" /> are independent standard normal random variables then </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+_%7Bx+%3A+%7C%7Cx%7C%7C%3D1%7D+%5Csum_e+g_e+x%5ET+A_e+x+%5Cleq+%5Csqrt%7B2%5Cleft+%5C%7C+%5Csum_e+A_e%5E2+%5Cright+%5C%7C+%5Clog+2n%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup _{x : ||x||=1} \sum_e g_e x^T A_e x \leq \sqrt{2\left \| \sum_e A_e^2 \right \| \log 2n} " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup _{x : ||x||=1} \sum_e g_e x^T A_e x \leq \sqrt{2\left \| \sum_e A_e^2 \right \| \log 2n} " /></p>
<p>
Applied to our setting,</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bx%3A+%7C%7Cx%7C%7C%3D1%7D+%5Chat+F%28x%29+%5Cleq+O%28%5Csqrt+%7B%5Clog+n%7D%29+%5Ccdot+%5Csqrt%7B%5Cleft+%5C%7C+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e+%5C+M_e+%5Cright%29%5E2+%5Cright+%5C%7C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\sqrt {\log n}) \cdot \sqrt{\left \| \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ M_e \right)^2 \right \|} " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\sqrt {\log n}) \cdot \sqrt{\left \| \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ M_e \right)^2 \right \|} " /></p>
<p> where </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5Cleft%28+w%5E%7B%28k-1%29%7D_e+%5C+M_e+%5Cright%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ M_e \right)^2 " class="latex" title="\displaystyle  \sum_{e : p_e \leq 2^{k-1-\ell}} \left( w^{(k-1)}_e \ M_e \right)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq+%5Cmax_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+w%5E%7B%28k-1%29%7D_e+%5C%7C+M_e+%5C%7C+%5Ccdot+%5Csum_%7Be+%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+w%5E%7B%28k-1%29%7D_e+%5C+M_e+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq \max_{e : p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e \| M_e \| \cdot \sum_{e : p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e \ M_e " class="latex" title="\displaystyle  \preceq \max_{e : p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e \| M_e \| \cdot \sum_{e : p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e \ M_e " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq+2%5E%7Bk-1-%5Cell%7D+%5Cfrac+1+%7Bp_e%7D+%5C%7C+M_e+%5C%7C+%5Ccdot+M%5E%7B%28k-1%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq 2^{k-1-\ell} \frac 1 {p_e} \| M_e \| \cdot M^{(k-1)} " class="latex" title="\displaystyle  \preceq 2^{k-1-\ell} \frac 1 {p_e} \| M_e \| \cdot M^{(k-1)} " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq+2%5E%7Bk-1-%5Cell%7D+%5Ccdot+%5Cfrac%7B%5Cepsilon%5E2%7D%7B%7C%7CM_e%7C%7C+%5Clog+n%7D+%5Ccdot+%7C%7CM_e%7C%7C+%5Ccdot+M%5E%7B%28k-1%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq 2^{k-1-\ell} \cdot \frac{\epsilon^2}{||M_e|| \log n} \cdot ||M_e|| \cdot M^{(k-1)} " class="latex" title="\displaystyle  \preceq 2^{k-1-\ell} \cdot \frac{\epsilon^2}{||M_e|| \log n} \cdot ||M_e|| \cdot M^{(k-1)} " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpreceq2%5E%7Bk-1-%5Cell%7D+%5Ccdot+%5Cfrac%7B%5Cepsilon%5E2%7D%7B%5Clog+n%7D+%5Ccdot+2+%5C+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \preceq2^{k-1-\ell} \cdot \frac{\epsilon^2}{\log n} \cdot 2 \ I " class="latex" title="\displaystyle  \preceq2^{k-1-\ell} \cdot \frac{\epsilon^2}{\log n} \cdot 2 \ I " /></p>
<p> so indeed </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bx%3A+%7C%7Cx%7C%7C%3D1%7D+%5Chat+F%28x%29+%5Cleq+O%28%5Cepsilon_k%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\epsilon_k) " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{x: ||x||=1} \hat F(x) \leq O(\epsilon_k) " /></p>
<p>
Now we can return to the question about the order in which we process the edges. By starting from the lowest-probability edges, we are also starting from the edges for which <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7CM_e%7C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{||M_e||}" class="latex" title="{||M_e||}" /> is smallest. When we bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+%5Csum_e+%28w_e%5E%7B%28k%29%7D+M_e%29%5E2+%7C%7C+%5Cleq+%5Cleft%28+%5Cmax_e+w_e%5E%7B%28k%29%7D+%7C%7CM_e%7C%7C+%5Cright%29+%5Ccdot+%7C%7C%5Csum_e+w_e%5E%7B%28k%29%7D+M_e%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || \sum_e (w_e^{(k)} M_e)^2 || \leq \left( \max_e w_e^{(k)} ||M_e|| \right) \cdot ||\sum_e w_e^{(k)} M_e|| " class="latex" title="\displaystyle  || \sum_e (w_e^{(k)} M_e)^2 || \leq \left( \max_e w_e^{(k)} ||M_e|| \right) \cdot ||\sum_e w_e^{(k)} M_e|| " /></p>
<p> and the sum is over the edges <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> that are processed at round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, it is convenient to be able to say that <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%5E%7B%28k%29%7D+%7C%7CM_e%7C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e^{(k)} ||M_e||}" class="latex" title="{w_e^{(k)} ||M_e||}" /> has a round-dependent upper bound. Indeed, if <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" /> is processed at round <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%5E%7B%28k%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e^{(k)}}" class="latex" title="{w_e^{(k)}}" /> is either zero or <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bk-1-%5Cell%7D+%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{k-1-\ell} /p_e}" class="latex" title="{2^{k-1-\ell} /p_e}" />, so that <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%5E%7B%28k%29%7D+%7C%7CM_e%7C%7C+%5Cleq+2%5E%7Bk-1-%5Cell%7D+%5Ccdot+%7C%7CM_e%7C%7C%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e^{(k)} ||M_e|| \leq 2^{k-1-\ell} \cdot ||M_e||/p_e}" class="latex" title="{w_e^{(k)} ||M_e|| \leq 2^{k-1-\ell} \cdot ||M_e||/p_e}" />, and the terms <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bk-1-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{k-1-\ell}}" class="latex" title="{2^{k-1-\ell}}" /> add up to <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" /> when summed over rounds. If we had proceeded in the opposite direction, we would have only been able to bound <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%5E%7B%28k%29%7D+%7C%7CM_e%7C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e^{(k)} ||M_e||}" class="latex" title="{w_e^{(k)} ||M_e||}" /> as an absolute constant times <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7CM_e%7C%7C%2Fp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{||M_e||/p_e}" class="latex" title="{||M_e||/p_e}" />, and we would have lost a factor of the order of the number of rounds in the analysis.</p>
<p>
The diameter is bounded by analogous considerations. The square of the diameter </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+%28d%28x%2Cy%29%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y : ||x||=||y||=1} (d(x,y))^2" class="latex" title="\displaystyle  \sup_{x,y : ||x||=||y||=1} (d(x,y))^2" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_%7Be%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+%5Cleft%28w%5E%7B%28k-1%29%7D_e+%5Cright%29%5E2+%5Cleft%28+x%5ET+M_e+x+-+y%5ETM_ey+%5Cright%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_{e: p_e \leq 2^{k-1-\ell}} \left(w^{(k-1)}_e \right)^2 \left( x^T M_e x - y^TM_ey \right)^2 " class="latex" title="\displaystyle  = \sum_{e: p_e \leq 2^{k-1-\ell}} \left(w^{(k-1)}_e \right)^2 \left( x^T M_e x - y^TM_ey \right)^2 " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Cleft%28+%5Csup_%7Bx%2Cy%2Ce+%3A+%7C%7Cu%7C%7C%3D%7C%7Cv%7C%7C%3D1%2Cp_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D+%7D+w%5E%7B%28k-1%29%7D_e+%7C+x%5ET+M_e+x+-+y%5ETM_ey%7C+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \left( \sup_{x,y,e : ||u||=||v||=1,p_e \leq 2^{k-1-\ell} } w^{(k-1)}_e | x^T M_e x - y^TM_ey| \right) " class="latex" title="\displaystyle  \leq \left( \sup_{x,y,e : ||u||=||v||=1,p_e \leq 2^{k-1-\ell} } w^{(k-1)}_e | x^T M_e x - y^TM_ey| \right) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ccdot+%5Cleft%28+%5Csup_%7Bx%2Cy+%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+%5Csum_%7Be%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+w%5E%7B%28k-1%29%7D_e+%7C+x%5ET+M_e+x+-+y%5ETM_ey+%7C+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \cdot \left( \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e | x^T M_e x - y^TM_ey | \right) " class="latex" title="\displaystyle \cdot \left( \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e | x^T M_e x - y^TM_ey | \right) " /></p>
<p> and we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy%2Ce+%3A+%7C%7Cu%7C%7C%3D%7C%7Cv%7C%7C%3D1%2Cp_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D+%7D+w%5E%7B%28k-1%29%7D_e+%7C+x%5ET+M_e+x+-+y%5ETM_ey+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y,e : ||u||=||v||=1,p_e \leq 2^{k-1-\ell} } w^{(k-1)}_e | x^T M_e x - y^TM_ey | " class="latex" title="\displaystyle  \sup_{x,y,e : ||u||=||v||=1,p_e \leq 2^{k-1-\ell} } w^{(k-1)}_e | x^T M_e x - y^TM_ey | " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+2%5E%7Bk-%5Cell-1%7D+%5Cfrac%7B%5Cepsilon%5E2%7D%7B%7C%7CM_e%7C%7C+%5Clog+n%7D+2+%7C%7CM_e%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq 2^{k-\ell-1} \frac{\epsilon^2}{||M_e|| \log n} 2 ||M_e|| " class="latex" title="\displaystyle  \leq 2^{k-\ell-1} \frac{\epsilon^2}{||M_e|| \log n} 2 ||M_e|| " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+O%5Cleft+%28+%5Cfrac+%7B%5Cepsilon_k%5E2%7D%7B%5Clog+n%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq O\left ( \frac {\epsilon_k^2}{\log n} \right) " class="latex" title="\displaystyle  \leq O\left ( \frac {\epsilon_k^2}{\log n} \right) " /></p>
<p> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+%5Csum_%7Be%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+w%5E%7B%28k-1%29%7D_e+%7C+x%5ET+M_e+x+-+y%5ETM_ey+%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e | x^T M_e x - y^TM_ey |" class="latex" title="\displaystyle  \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e | x^T M_e x - y^TM_ey |" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+%5Csum_%7Be%3A+p_e+%5Cleq+2%5E%7Bk-1-%5Cell%7D%7D+w%5E%7B%28k-1%29%7D_e+%28x%5ET+M_e+x+%2B+y%5ETM_ey+%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e (x^T M_e x + y^TM_ey ) " class="latex" title="\displaystyle  \sup_{x,y : ||x||=||y||=1} \sum_{e: p_e \leq 2^{k-1-\ell}} w^{(k-1)}_e (x^T M_e x + y^TM_ey ) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csup_%7Bx%2Cy%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+x%5ET+M%5E%7B%28k-1%29%7D+x+%2B+y%5ET+M%5E%7B%28k-1%29%7D+y+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \sup_{x,y: ||x||=||y||=1} x^T M^{(k-1)} x + y^T M^{(k-1)} y " class="latex" title="\displaystyle  \leq \sup_{x,y: ||x||=||y||=1} x^T M^{(k-1)} x + y^T M^{(k-1)} y " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+4+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq 4 " class="latex" title="\displaystyle  \leq 4 " /></p>
<p>
Which gives the desired bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx%2Cy+%3A+%7C%7Cx%7C%7C%3D%7C%7Cy%7C%7C%3D1%7D+d%28x%2Cy%29+%3D+O%28%5Cepsilon_k+%2F+%5Csqrt%7B%5Clog+n%7D+%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x,y : ||x||=||y||=1} d(x,y) = O(\epsilon_k / \sqrt{\log n} )" class="latex" title="\displaystyle  \sup_{x,y : ||x||=||y||=1} d(x,y) = O(\epsilon_k / \sqrt{\log n} )" /></p>
<p>
Now the Talagrand comparison inequality gives us the lemma, and hence the analysis of the Spielman-Srivastava construction.</p>
<p>
</p><p><b>4. A Final Comment </b></p>
<p></p><p>
There was a point that confused me for a while about this argument. Namely, we are not able to study </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csup_%7Bx+%3A+x%5ET+L_G+x%3D1%7D+x%5ET%28L_G+-+L_%7BG%27%7D%29+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sup_{x : x^T L_G x=1} x^T(L_G - L_{G'}) x " class="latex" title="\displaystyle  \sup_{x : x^T L_G x=1} x^T(L_G - L_{G'}) x " /></p>
<p> by showing that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5ET%28L_G+-+L_%7BG%27%7D%29+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^T(L_G - L_{G'}) x " class="latex" title="\displaystyle  x^T(L_G - L_{G'}) x " /></p>
<p> is dominated by a Gaussian process, because <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G'}}" class="latex" title="{L_{G'}}" /> involves biased Boolean random variables which yield poor bounds when we try to dominate them by a Gaussian distribution. Instead we write</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5ET%28L_G+-+L_%7BG%27%7D%29+x+%3D+%5Csum_k+x%5ET%28L_%7BG%5E%7B%28k-1%29%7D%7D+-+L_%7BG%5E%7B%28k%29%7D%7D%29+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^T(L_G - L_{G'}) x = \sum_k x^T(L_{G^{(k-1)}} - L_{G^{(k)}}) x " class="latex" title="\displaystyle  x^T(L_G - L_{G'}) x = \sum_k x^T(L_{G^{(k-1)}} - L_{G^{(k)}}) x " /></p>
<p> and then we show how to dominate each term on the right-hand side by a Gaussian process. But then won’t the sum of those Gaussian processes dominate <img src="https://s0.wp.com/latex.php?latex=%7Bx%5ET%28L_G+-+L_%7BG%27%7D%29+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^T(L_G - L_{G'}) x}" class="latex" title="{x^T(L_G - L_{G'}) x}" />, which was not supposed to be possible?</p>
<p>
But the point is that in the analysis of <img src="https://s0.wp.com/latex.php?latex=%7B+x%5ET%28L_%7BG%5E%7B%28k-1%29%7D%7D+-+L_%7BG%5E%7B%28k%29%7D%7D%29+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x^T(L_{G^{(k-1)}} - L_{G^{(k)}}) x}" class="latex" title="{ x^T(L_{G^{(k-1)}} - L_{G^{(k)}}) x}" /> we throw away the low-probability case that, in the previous processes, we ended with <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BG%5E%7B%28k-1%29%7D%7D+%5Cnot%5Cpreceq+2+L_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{G^{(k-1)}} \not\preceq 2 L_G}" class="latex" title="{L_{G^{(k-1)}} \not\preceq 2 L_G}" />. These low-probability events that we remove from consideration are enough to cut off the problematic tail of the discrete distribution that does not have a good Gaussian domination.</p>
<p>
To get a better sense of what is happening, suppose that we are looking at the real-valued random variable </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S+%3D+%5Csum_%7Bi%3D1%7D%5En+s_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S = \sum_{i=1}^n s_i " class="latex" title="\displaystyle  S = \sum_{i=1}^n s_i " /></p>
<p> where each <img src="https://s0.wp.com/latex.php?latex=%7Bs_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_i}" class="latex" title="{s_i}" /> is a independent random variable that is equal to 1 with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and equal to zero with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p}" class="latex" title="{1-p}" />. Suppose that <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+2%5E%7B-%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = 2^{-\ell}}" class="latex" title="{p = 2^{-\ell}}" /> is a negative power of two and that <img src="https://s0.wp.com/latex.php?latex=%7Bpn+%3E+n%5E%7B-%5COmega%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{pn &gt; n^{-\Omega(1)}}" class="latex" title="{pn &gt; n^{-\Omega(1)}}" />, let’s say <img src="https://s0.wp.com/latex.php?latex=%7Bpn+%3E+%5Csqrt+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{pn &gt; \sqrt n}" class="latex" title="{pn &gt; \sqrt n}" />.</p>
<p>
We would like to say that there is a <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+O%28%5Csqrt%7Bnp+%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t = O(\sqrt{np \log n})}" class="latex" title="{t = O(\sqrt{np \log n})}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5B+S+-%5Cmathop%7B%5Cmathbb+E%7D+S+%3E+t+%5D+%5Cleq+%5Cfrac+1%7Bn%5E%7B%5COmega%281%29%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \Pr [ S -\mathop{\mathbb E} S &gt; t ] \leq \frac 1{n^{\Omega(1)}} " class="latex" title="\displaystyle  \Pr [ S -\mathop{\mathbb E} S &gt; t ] \leq \frac 1{n^{\Omega(1)}} " /></p>
<p>
Also, we have made a vow to only bound the tail of discrete random variables by showing that they are sub-Gaussian and then using the tail of the dominating Gaussian.</p>
<p>
If we try to argue about the sub-Gaussianity of <img src="https://s0.wp.com/latex.php?latex=%7BS-%5Cmathop%7B%5Cmathbb+E%7D+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S-\mathop{\mathbb E} S}" class="latex" title="{S-\mathop{\mathbb E} S}" />, we are in trouble, because there is probability <img src="https://s0.wp.com/latex.php?latex=%7Bp%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^n}" class="latex" title="{p^n}" /> that <img src="https://s0.wp.com/latex.php?latex=%7BS%3Dpn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S=pn}" class="latex" title="{S=pn}" />, so that <img src="https://s0.wp.com/latex.php?latex=%7BS-%5Cmathop%7B%5Cmathbb+E%7D+S+%5Cgeq+%5Cfrac+n2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S-\mathop{\mathbb E} S \geq \frac n2}" class="latex" title="{S-\mathop{\mathbb E} S \geq \frac n2}" />. This is problematic because, in a Gaussian distribution, a deviation that occurs with probability <img src="https://s0.wp.com/latex.php?latex=%7Bp%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^n}" class="latex" title="{p^n}" /> can only be <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+%7Bn+%5Clog+1%2Fp%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt {n \log 1/p})}" class="latex" title="{O(\sqrt {n \log 1/p})}" /> times the standard deviation, so the standard deviation has to be <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega+%28%5Csqrt%7B+n+%2F+%5Clog+1%2Fp%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega (\sqrt{ n / \log 1/p})}" class="latex" title="{\Omega (\sqrt{ n / \log 1/p})}" /> and a deviation that is achieved with probability <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fn%5E%7B%5CTheta%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/n^{\Theta(1)}}" class="latex" title="{1/n^{\Theta(1)}}" /> is of the order at least <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega+%5Cleft%28+%5Csqrt+%7B%5Cfrac%7Bn%5Clog+n%7D+%7B%5Clog+1%2Fp%7D%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega \left( \sqrt {\frac{n\log n} {\log 1/p}} \right)}" class="latex" title="{\Omega \left( \sqrt {\frac{n\log n} {\log 1/p}} \right)}" /> which is much more than the <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bnp+%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt{np \log n})}" class="latex" title="{O(\sqrt{np \log n})}" /> that we were hoping for. </p>
<p>
The problem is that a Gaussian distribution with standard deviation of the order of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7Bpn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt {pn}}" class="latex" title="{\sqrt {pn}}" /> dominates our distribution in the regime we are interested in, but not in all regimes.</p>
<p>
To overcome this problem, we write</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S+-+%5Cmathop%7B%5Cmathbb+E%7D+S+%3D+%5Csum_%7Bk%3D1%7D%5E%5Cell+S%5E%7B%28k%29%7D+-+S%5E%7B%28k-1%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S - \mathop{\mathbb E} S = \sum_{k=1}^\ell S^{(k)} - S^{(k-1)} " class="latex" title="\displaystyle  S - \mathop{\mathbb E} S = \sum_{k=1}^\ell S^{(k)} - S^{(k-1)} " /></p>
<p> where </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%5E%7B%28k%29%7D+%3D+%5Csum_i+s%5E%7B%28k%29%7D_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S^{(k)} = \sum_i s^{(k)}_i " class="latex" title="\displaystyle  S^{(k)} = \sum_i s^{(k)}_i " /></p>
<p> and the random variables <img src="https://s0.wp.com/latex.php?latex=%7Bs%5E%7B%28k%29%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s^{(k)}_i}" class="latex" title="{s^{(k)}_i}" /> are constructed in the following way: <img src="https://s0.wp.com/latex.php?latex=%7Bs_i%5E%7B%280%29%7D+%3D+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_i^{(0)} = p}" class="latex" title="{s_i^{(0)} = p}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bs%5E%7B%28k%29%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s^{(k)}_i}" class="latex" title="{s^{(k)}_i}" /> is equally likely to be either 0 or <img src="https://s0.wp.com/latex.php?latex=%7B2+s_i%5E%7B%28k-1%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2 s_i^{(k-1)}}" class="latex" title="{2 s_i^{(k-1)}}" />. In this way, <img src="https://s0.wp.com/latex.php?latex=%7BS%5E%7B%280%29%7D+%3D+%5Cmathop%7B%5Cmathbb+E%7D+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S^{(0)} = \mathop{\mathbb E} S}" class="latex" title="{S^{(0)} = \mathop{\mathbb E} S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BS%5E%7B%28%5Cell%29%7D+%3D+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S^{(\ell)} = S}" class="latex" title="{S^{(\ell)} = S}" />.</p>
<p>
For every choice of the <img src="https://s0.wp.com/latex.php?latex=%7Bs%5E%7B%28k-1%29%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s^{(k-1)}_i}" class="latex" title="{s^{(k-1)}_i}" />, we can write </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%5E%7B%28k%29%7D+-+S%5E%7B%28k-1%29%7D+%3D+%5Csum_i+r%5E%7B%28k%29%7D_i+s%5E%7B%28k-1%29%7D_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S^{(k)} - S^{(k-1)} = \sum_i r^{(k)}_i s^{(k-1)}_i " class="latex" title="\displaystyle  S^{(k)} - S^{(k-1)} = \sum_i r^{(k)}_i s^{(k-1)}_i " /></p>
<p> where the <img src="https://s0.wp.com/latex.php?latex=%7Br%5E%7B%28k%29%7D_i+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r^{(k)}_i }" class="latex" title="{r^{(k)}_i }" /> are independent Rademacher random variable. Over the randomness of the <img src="https://s0.wp.com/latex.php?latex=%7Br%5E%7B%28k%29%7D_i+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r^{(k)}_i }" class="latex" title="{r^{(k)}_i }" />, the random variable <img src="https://s0.wp.com/latex.php?latex=%7BS%5E%7B%28k%29%7D+-+S%5E%7B%28k-1%29%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S^{(k)} - S^{(k-1)} }" class="latex" title="{S^{(k)} - S^{(k-1)} }" /> has a sub-Gaussian distribution dominated by a Gaussian of variance </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_i+%5Cleft%28+s%5E%7B%28k-1%29%7D_i+%5Cright%29%5E2+%5Cleq+2%5Ek+p+%5Ccdot+%5Csum_i+s%5E%7B%28k-1%29%7D_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_i \left( s^{(k-1)}_i \right)^2 \leq 2^k p \cdot \sum_i s^{(k-1)}_i " class="latex" title="\displaystyle  \sum_i \left( s^{(k-1)}_i \right)^2 \leq 2^k p \cdot \sum_i s^{(k-1)}_i " /></p>
<p> Now, without breaking our vow, we can inductively get a high-probability estimate that for each <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%5E%7B%28k%29%7D+-+S%5E%7B%28k-1%29%7D+%5Cleq+O%28%5Csqrt%7B+2%5Ek+p%5E2+n+%5Clog+n%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S^{(k)} - S^{(k-1)} \leq O(\sqrt{ 2^k p^2 n \log n}) " class="latex" title="\displaystyle  S^{(k)} - S^{(k-1)} \leq O(\sqrt{ 2^k p^2 n \log n}) " /></p>
<p> while maintaining the invariant that, say, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+s%5E%7B%28k-1%29%7D_i+%5Cleq+2pn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_i s^{(k-1)}_i \leq 2pn}" class="latex" title="{ \sum_i s^{(k-1)}_i \leq 2pn}" /> for each <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. When we sum up the error bounds, the whole sum is of the order of the last term, which is <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+%7Bpn+%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt {pn \log n})}" class="latex" title="{O(\sqrt {pn \log n})}" />.</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/05/12/spielman-srivastava-sparsification-a-la-talagrand/"><span class="datestr">at May 12, 2020 03:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blog.simons.berkeley.edu/?p=260">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/simons.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blog.simons.berkeley.edu/2020/05/lattice-blog-reduction-part-ii-slide-reduction/">Lattice Blog Reduction – Part II: Slide Reduction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>This is the second entry in a series of posts about lattice block reduction. See <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/" class="uri">here</a> for the first part. In this post I will assume you have read the first one, so if you haven’t, continue at your own risk. (I suggest reading at least the first part for context, notations and disclaimers.)</p>
<p>Last time we focused on BKZ which applies SVP reduction to successive projected subblocks. In this post we consider slide reduction, which allows for a much cleaner and nicer analysis. But before we can do that, we need a little more background.</p>
<h4 id="a-new-tool-dual-svp-reduction">A New Tool: Dual SVP Reduction</h4>
<p>As you hopefully know, duality is a very useful concept in lattice theory (and in mathematics more generally). It allows to pair up lattices, which are related in a well defined way. Similarly, we can pair up the different bases of two dual lattices to obtain dual bases. I’ll skip the definition of these two concepts since we will not need them. It is sufficient to know that we can compute the dual basis from the primal basis efficiently. One very cool feature of dual bases is that the last vector in the dual basis has a length that is inverse to the length of the last GSO vector of the primal basis. In math: if <span class="math inline">\({\mathbf{B}}\)</span> and <span class="math inline">\({\mathbf{D}}\)</span> are dual bases, then <span class="math inline">\(\| {\mathbf{b}}_n^* \| = \| {\mathbf{d}}_n \|^{-1}\)</span>. (If you want to see why this is true at least for full rank lattices, use the fact that in this case <span class="math inline">\({\mathbf{D}} = {\mathbf{B}}^{-T}\)</span>, and the QR-factorization.) It follows that if <span class="math inline">\({\mathbf{d}}_n\)</span> happens to be the shortest vector in the dual lattice, then <span class="math inline">\({\mathbf{b}}_n^*\)</span> is as long as possible, since the existence of any basis <span class="math inline">\(\bar{{\mathbf{B}}}\)</span> where <span class="math inline">\(\|\bar{{\mathbf{b}}}_n^*\| &gt; \|{\mathbf{b}}_n^*\|\)</span> would imply that there exists a dual basis <span class="math inline">\(\bar {{\mathbf{D}}}\)</span> such that <span class="math inline">\(\| \bar{{\mathbf{d}}}_n\| &lt; \| {\mathbf{d}}_n\| \)</span>. By analogy to SVP reduction, we call a basis, where <span class="math inline">\(\| {\mathbf{b}}^*_n \|\)</span> is maximized, dual SVP reduced (DSVP reduced). This gives us a new tool to control the size of the GSO vectors: we can apply an SVP algorithm to the dual basis of a projected subblock <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span>. This will yield a shortest vector in the dual of this projected sublattice. Then we can compute a dual basis, which contains this shortest vector in the last position and finally compute a new primal basis for this projected subblock, which now locally maximizes <span class="math inline">\(\|{\mathbf{b}}_j^* \|\)</span>. As we did for primal SVP reduction in the last post, we will assume access to an algorithm that, given a basis <span class="math inline">\({\mathbf{B}}\)</span> and indices <span class="math inline">\(i,j\)</span>, will return a basis such that <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> is DSVP reduced and the rest of the basis is unchanged. We will call such an algorithm a DSVP oracle. It may sound like this should be somewhat less efficient than SVP reduction, since we have to switch between the dual and the primal bases (which, when done explicitly, requires matrix inversion), but this is not actually the case. In fact, one can implement a DSVP reduction entirely without having to explicitly compute (any part of) the dual basis as shown in [GN08,MW16].</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/05/dsvp.png" alt="" class="wp-image-262" />Effect of a call to the DSVP oracle. GSO log norms of the input in black, of the output in blue. Note that the sum of the GSO log norms is a constant, so increasing the length of the last vector, decreases the (average of the) remaining vectors.</figure></div>



<p>I hope this figure provides some intuition that such an oracle can be useful. Now let us quantify how much this DSVP oracle helps us. Recall that in the primal SVP reduction we used Minkowski’s theorem to bound the length of the first vector. Since we are now applying the SVP algorithm to the dual, it should come as no surprise that we will use Minkowski’s theorem on the dual lattice, which tells us that <span class="math display">\[\lambda_1(\widehat{\Lambda}) \leq \sqrt{\gamma_n} \det(\widehat{\Lambda})^{1/n} = \sqrt{\gamma_n} \det(\Lambda)^{-1/n}\]</span> where <span class="math inline">\(\widehat{\Lambda}\)</span> is the dual lattice, i.e. the lattice generated by the dual basis. Furthermore, by exploiting above fact that for basis <span class="math inline">\({\mathbf{B}}\)</span> and its dual <span class="math inline">\({\mathbf{D}}\)</span> we have <span class="math inline">\(\| {\mathbf{b}}_n^* \| = \|{\mathbf{d}}_n \|^{-1}\)</span>, this shows that if <span class="math inline">\({\mathbf{B}}\)</span> is DSVP reduced, i.e. <span class="math inline">\({\mathbf{d}}_n\)</span> is a shortest vector in the dual lattice, then <span class="math display">\[\| {\mathbf{b}}_n^* \| = \|{\mathbf{d}}_n \|^{-1} = \lambda_1(\widehat{\Lambda})^{-1} \geq \frac{\det(\Lambda)^{1/n}}{\sqrt{\gamma_n}}.\]</span> So after we’ve applied the DSVP oracle to a projected block <span class="math inline">\({\mathbf{B}}_{[i-k+1,i]}\)</span>, we have <span class="math display">\[\|{\mathbf{b}}^*_i \| \geq  \frac{\left(\prod_{j = i-k+1}^{i} \|{\mathbf{b}}_j^* \| \right)^{1/k}}{\sqrt{\gamma_{k}}}.\]</span></p>
<h1 id="sec:slide">Slide Reduction</h1>
<p>Now we have all the tools we need to describe slide reduction [GN08]. One of the major hurdles to apply an LLL-style running time analysis to BKZ seems to be that the projected subblocks considered in that algorithm are maximally overlapping. So slide reduction takes a different route: it applies primal and dual SVP reduction to minimally overlapping subblocks, which allows to still prove nice bounds on the output quality (in fact, even better than BKZ), but also on the running time via a generalization of the LLL analysis. More specifically, let <span class="math inline">\({\mathbf{B}}\)</span> be the given lattice basis of an <span class="math inline">\(n\)</span>-dimensional lattice and <span class="math inline">\(k\)</span> be the blocksize. We require that <span class="math inline">\(k\)</span> divides <span class="math inline">\(n\)</span>. (We’ll come back to that restriction later.) Instead of applying our given SVP oracle to successive projected subblocks, we apply it to <em>disjoint</em> projected subblocks, i.e. to the blocks <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span>, <span class="math inline">\({\mathbf{B}}_{[k+1,2k]}\)</span>, etc. So we locally minimize the GSO vectors <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> for <span class="math inline">\(i \in \{0,\cdots,n/k – 1\}\)</span>. (Technically, we iterate this step with a subsequent LLL reduction until there is no more change, which is important for the runtime analysis, but let’s ignore this for now). So now we have a basis where these disjoint projected subblocks are SVP-reduced. In the next step we shift the blocks by 1 and apply our DSVP oracle to them. (Note that the last block now extends beyond the basis, so we ignore this block.) This has the effect of locally maximizing the vectors <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> for <span class="math inline">\(i \in \{1,\cdots,n/k – 1\}\)</span>. This might seem counter-intuitive at first, but note that the optimization context for <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> changes between the SVP reduction and the DSVP reduction: <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> is first minimized with respect to the block <span class="math inline">\({\mathbf{B}}_{[ik+1,(i+1)k]}\)</span> and then maximized with respect to the block <span class="math inline">\({\mathbf{B}}_{[(i-1)k+1,ik+1]}\)</span>. So one can view this as using the block <span class="math inline">\({\mathbf{B}}_{[ik+2, (i+1)k]}\)</span> as a pivot to lower the ratio between the lengths of the GSO vectors <span class="math inline">\({\mathbf{b}}^*_{ik+1}\)</span> and <span class="math inline">\({\mathbf{b}}^*_{(i+1)k+1}\)</span>. This view is reminiscent of the proof of Mordell’s inequality <span class="math inline">\(\gamma_n^{\frac{1}{n-1}} \leq \gamma_{n-1}^{\frac{1}{n-2}}\)</span>, which explains the title of the paper [GN08]. The idea of slide reduction is to simply iterate these two steps until there is no more change.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/05/slide-1024x910.png" alt="" class="wp-image-265" />Slide reduction in one picture: apply the SVP oracle to the disjoint projected blocks in parallel, then shift the blocks by 1 and apply the DSVP oracle. Repeat.</figure></div>



<p>Let’s dive into the analysis.</p>
<h4 id="the-good">The Good</h4>
<p>When the algorithm terminates, we are guaranteed that the following conditions hold simultaneously:</p>
<ol>
<li><p>The blocks <span class="math inline">\({\mathbf{B}}_{[ik+1, (i+1)k]}\)</span> are SVP reduced for all <span class="math inline">\(i \in \{0,\cdots,n/k – 1\}\)</span> (the <em>primal conditions</em>), which implies <span class="math display">\[\|{\mathbf{b}}^*_{ik+1} \|^{k-1} \leq \gamma_k^{k/2} \prod_{j=ik+2}^{(i+1)k} \|{\mathbf{b}}^*_j \|\]</span> (Note that we raised Minowski’s bound to the <span class="math inline">\(k\)</span>-th power and canceled one the <span class="math inline">\(\|{\mathbf{b}}^*_{ik+1} \|\)</span> on both sides.)</p></li>
<li><p>The blocks <span class="math inline">\({\mathbf{B}}_{[ik+2, (i+1)k+1]}\)</span> are DSVP reduced for all <span class="math inline">\(i \in \{0,\cdots,n/k – 2\}\)</span> (the <em>dual conditions</em>), which implies <span class="math display">\[\gamma_{k}^{k/2} \|{\mathbf{b}}^*_{(i+1)k+1} \|^{k-1} \geq \prod_{j = ik+2}^{(i+1)k} \|{\mathbf{b}}_j^* \|\]</span></p></li>
</ol>
<p>(Technically, there is a constant slack factor <span class="math inline">\(&gt;1\)</span> involved, which can be set arbitrarly close to 1, but is important for running time. We’ll sweep under the rug for simplicity.)</p>
<p>Just by staring at the two inequalities, you will notice that they can easily be combined to yield: <span class="math display">\[\|{\mathbf{b}}^*_{ik+1} \| \leq \gamma_k^{\frac{k}{k-1}} \|{\mathbf{b}}^*_{(i+1)k+1} \|\]</span> for all <span class="math inline">\(i \in \{0,\dots,n/k-2\}\)</span> and in particular <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{k}{k-1} (\frac{n}{k}-1)} \|{\mathbf{b}}^*_{n-k+1} \|
= \gamma_k^{\frac{n-k}{k-1}} \|{\mathbf{b}}^*_{n-k+1} \|\]</span> By a similar trick as last time we can assume that <span class="math inline">\(\lambda_1({\mathbf{B}}) \geq \|{\mathbf{b}}^*_{n-k+1} \|\)</span>, because the last block is SVP-reduced, which shows that slide reduction achieves an approximation factor <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{n-k}{k-1}} \lambda_1({\mathbf{B}}).\]</span> Done! Yes, it is really that simple. With (very) little more work one can similarly show a bound on the Hermite factor <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{n-1}{2(k-1)}} \det({\mathbf{B}})^{\frac1n}.\]</span> Simply reuse the bounds on the ratios of <span class="math inline">\(\| {\mathbf{b}}^*_1 \|\)</span> and <span class="math inline">\(\| {\mathbf{b}}^*_{ik+1} \|\)</span> in combination with Minkowski’s bound for each block. (You guessed it: Homework!) Note that both of them are better than what we were able to obtain for BKZ in our last blog post. And in contrast to BKZ one can easily bound the number of calls to the SVP oracle by a polynomial in <span class="math inline">\(n, k\)</span> and the bit size of the original basis. The analysis is similar to the one of LLL with a modified potential function: we let <span class="math inline">\(P({\mathbf{B}}) = \prod_{i=0}^{n/k-2} \det({\mathbf{B}}_{[1,ik]})^2\)</span>. If the basis <span class="math inline">\({\mathbf{B}}\)</span> consists of integer coefficients only, this potential is also integral. Furthermore, one can show that if an iteration of slide reduction modifies the basis, it will decrease this potential by at least a constant factor (by using the slack factor we brushed over). This shows that while the basis is modified, the potential decreases exponentially, which results in a polynomial number of calls to the (D)SVP oracle.</p>
<h4 id="the-bad">The Bad</h4>
<p>We just sketched a complete and elegant analysis of the entire algorithm and it checks all the boxes: best known approximation factor, best known Hermite factor, a polynomial number of calls to its (D)SVP oracle. So what could possibly be bad about it? Remember that we required that the blocksize <span class="math inline">\(k\)</span> divides the dimension <span class="math inline">\(n\)</span>. It seems like it should be easy to get rid of this restriction, for example one could artificially increase the dimension of the lattice to assure that the blocksize divides it. Unfortunately, this and similar approaches will degrade the bound on the output quality – there will be a rounding-up operator in the exponent [LW13]. For small <span class="math inline">\(k\)</span> this might not be too much of an issue, but as <span class="math inline">\(k\)</span> grows, this results in a significant performance hit. Luckily, a recent work [ALNS19] shows that one can avoid this degradation by combining slide reduction with yet another block reduction algorithm: SDBKZ, which will be the topic of the next post.</p>
<h4 id="the-ugly">The Ugly</h4>
<p>Slide reduction is beautiful and there is little one can find ugly about it in theory. Unfortunately, experimental studies so far concluded that this algorithm is significantly inferior to BKZ, which (at least to me) is puzzling. This is often attributed to the fact that BKZ uses maximally overlapping blocks, which seems to allow it to obtain stronger reduction notions (even though we cannot prove it). So, one could wonder if there is an algorithm that uses maximally overlapping blocks (and is thus hopefully competetive in practice), but allows for a clean analysis. It turns out that the topic of the next post (SDBKZ) is such an algorithm.</p>
<ul>
<li><p>Gama, Nguyen. Finding short lattice vectors within Mordell’s inequality. STOC 2008</p></li>
<li><p>Li, Wei. Slide reduction, successive minima and several applications. Bulletin of the Australian Mathematical Society 2013</p></li>
<li><p>Micciancio, Walter. Practical, predictable lattice basis reduction. EUROCRYPT 2016</p></li>
<li><p>Aggarwal, Li, Nguyen, Stephens-Davidowitz. Slide Reduction, Revisited—Filling the Gaps in SVP Approximation. <a href="https://arxiv.org/abs/1908.03724" class="uri">https://arxiv.org/abs/1908.03724</a></p></li>
</ul></div>







<p class="date">
by Michael Walter <a href="https://blog.simons.berkeley.edu/2020/05/lattice-blog-reduction-part-ii-slide-reduction/"><span class="datestr">at May 12, 2020 10:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/">IDEAL Workshop on Estimation of Network Processes and Information Diffusion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
May 14, 2020 Virtual https://www.ideal.northwestern.edu/events/estimation-of-network-processes-and-information-diffusion/?fbclid=IwAR3HRiqCz8zTQfHt46hF-VF9PHE2F1v4uvQ6V_ggxmzKqFvromZXhVOOygY Many important dynamic processes are determined by an underlying network structure. Examples include the spread of epidemics, the dynamics of public opinions, the diffusion of information about social programs, and biological processes such as neural spike trains. Data about these processes is becoming increasingly available which has lead to a … <a href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/" class="more-link">Continue reading <span class="screen-reader-text">IDEAL Workshop on Estimation of Network Processes and Information Diffusion</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/"><span class="datestr">at May 12, 2020 03:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/05/12/inbox-of-triangle">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/05/12/inbox-of-triangle.html">The inbox of a triangle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In affine geometry, the minimum-area ellipse surrounding a given triangle and the maximum-area ellipse within it (its two <a href="https://en.wikipedia.org/wiki/Steiner_inellipse">Steiner ellipses</a>) are concentric and similar. This can be seen easily by performing an affine transformation to an equilateral triangle, observing that in this case these ellipses are concentric circles (the circumcircle and incircle), and that the extreme ellipses of the transformed shape are the transforms of the extreme ellipses of the original shape. In <a href="https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers.html">Cartesian geometry</a>, where the Cartesian coordinates can be independently linearly transformed or swapped, something similar turns out to happen. In this case, the minimum-area axis-parallel rectangle surrounding a given triangle (its bounding box) and the maximum-area rectangle within it (let’s call it the <em>inbox</em>) are always similar, though not concentric.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/inbox.svg" alt="Bounding boxes and inboxes of two triangles" /></p>

<p>The inbox always touches all three sides of its triangle. For if it missed any one of the sides, it could be made larger, while staying within the triangle, by a dilation centered at the opposite vertex. It turns out that for triangles in general position (no two vertex coordinates equal) there are two cases, shown above. If the two median coordinates belong to different triangle vertices (as is true for all acute triangles) then the inbox touches all three sides at separate points, and has a fourth vertex interior to the triangle, as shown on the left. If there is one triangle vertex with both median coordinates (necessarily an obtuse vertex), then the inbox touches that vertex and the opposite side, with two other vertices free, as shown on the right.
Let’s call these the acute and obtuse cases, even though the triangle in the acute case might actually be obtuse.</p>

<p>In the obtuse case, we can apply a Cartesian transformation to make the bounding box square. The inbox lies within an isosceles right triangle formed by axis-parallel lines through the obtuse vertex and by the opposite side of the triangle. By the symmetry of this isosceles right triangle, the inbox is also square. Just as in the Steiner ellipse argument, this implies that the inbox of the untransformed triangle is similar to its bounding box.</p>

<p>In the acute case, let’s again draw axis-parallel lines through the median coordinates. Each line crosses one triangle side, and the line segment between these two crossings cuts the triangle into a smaller triangle (light blue below) and an <a href="https://en.wikipedia.org/wiki/Orthodiagonal_quadrilateral">orthodiagonal quadrilateral</a> (dark blue), with the property that any rectangle that touches the three sides of the triangle also touches the fourth side of the quadrilateral. In this case, the rectangle formed by the four midpoints of the quadrilateral (its <a href="https://en.wikipedia.org/wiki/Varignon%27s_theorem">Varignon rectangle</a>) must be the one with maximum area. For, this rectangle has exactly half the area of the orthodiagonal quadrilateral, as the four triangular flaps surrounding it can be folded over to exactly cover the rectangle. Any other rectangle would have two longer flaps and two shorter flaps, which when folded would overlap near the middle of the rectangle, showing that the total flap area is larger than the rectangle area.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/envelope.svg" alt="Construction of an orthodiagonal quadrilateral in which the inbox is inscribed in the acute case" /></p>

<p>The inbox has half the width and half the height of the bounding box of the orthodiagonal quadrilateral, so they both are similar. I have a coordinate-based proof that they are also both similar to the bounding box of the original triangle, but not a nice synthetic proof. Suppose we perform a Cartesian transformation of the triangle so that its cut-off vertex (the one not part of the orthodiagonal quadrilateral) is at the origin and so that its bounding box is the unit square. Let the median coordinates of the triangle vertices be  and . Then the vertex of the bounding box of the orthodiagonal quadrilateral that is closest to the origin has coordinates , on the diagonal of the unit square, and its farthest vertex has coordinates , so it is a square too.</p>

<p>The center of the Steiner ellipses is the centroid of the triangle, the only affine-equivariant triangle center. Both the center of the inbox and the center of its similarity with the bounding box appear to be Cartesian triangle centers in the sense of <a href="https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers.html">my previous post</a>: they are continuous Cartesian-equivariant functionals from triangles to points. Unlike the centroid or the bounding-box center, they cannot be calculated separately in the two coordinates, as can be seen from the first example, where the median -coordinate is halfway between the other two but the inbox center and center of similarity -coordinates are not. However, they differ from the equal-box-area center of my previous post, which is outside the triangle in the obtuse case while these centers are always inside.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104156395479629486">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/05/12/inbox-of-triangle.html"><span class="datestr">at May 12, 2020 12:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1023884907351872604">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/05/and-winners-are.html">And the winners are ....</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Computational Complexity Conference has announced the <a href="https://computationalcomplexity.org/Archive/2020/accept.php">accepted papers</a> for the 2020 now virtual conference. Check them out!<div>
<br /></div>
<div>
Speaking of the complexity conference, my former PhD student Dieter van Melkebeek will <a href="https://sigact.org/prizes/service/2020.html">receive the ACM SIGACT Distinguished Service award</a> for his leadership in taking the conference independent. They grow up so fast! </div>
<div>
<br /></div>
<div>
Robin Moser and Gábor Tardos <a href="https://sigact.org/prizes/g%C3%B6del/citation2020.html">will receive the Gödel Prize</a> for their work giving a constructive proof of the Lovász Local Lemma, one of my truly <a href="https://blog.computationalcomplexity.org/2014/07/favorite-theorems-compressing-local.html">favorite theorems</a> as it gave a far stronger bound, a shockingly simple and efficient algorithm and an incredibly beautiful proof. Back in 2009 Moser gave my all-time favorite STOC talk on an early version of the paper. I (and <a href="https://rjlipton.wordpress.com/2009/06/02/mosers-method-of-bounding-a-program-loop/">others</a>) sat amazed as his algorithm and proof came alive. During the talk I asked Eric Allender sitting next to me "Are we really seeing a Kolmogorov complexity proof of the Lovász Local Lemma?" Yes, <a href="https://blog.computationalcomplexity.org/2009/06/kolmogorov-complexity-proof-of-lov.html">we did</a>.</div>
<div>
<br /></div>
<div>
Cynthia Dwork will receive the <a href="https://sigact.org/prizes/knuth/citation2020.pdf">Knuth prize</a> given for her life's work. The prize would be justified by her work on distributed computing alone but it is her leadership in formalizing Differential Privacy, one of the coolest concepts to come out of the theoretical computer science community this century, that will leave her mark in theory history. </div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/05/and-winners-are.html"><span class="datestr">at May 11, 2020 02:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17029">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/">Consistency and P=NP</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Can we at least show that <img src="https://s0.wp.com/latex.php?latex=%7BP%5Cneq+NP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P\neq NP}" class="latex" title="{P\neq NP}" /> is consistent?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/unknown-140/" rel="attachment wp-att-17032"><img src="https://rjlipton.files.wordpress.com/2020/05/unknown.jpeg?w=600" alt="" class="alignright size-full wp-image-17032" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ From personal page ]</font></td>
</tr>
</tbody>
</table>
<p>
Jan Krajicek is an expert on linking computational complexity and mathematical logic. He has authored four books on this area including the often cited <a href="https://www.cambridge.org/core/books/bounded-arithmetic-propositional-logic-and-complexity-theory/899C8FF084B3EB2430EDEBC27921D635">text</a> <em>Bounded Arithmetic and Complexity Theory</em>. Moreover, he has studied the consistency of various of theories and whether they can prove <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq NP}}" class="latex" title="{\mathsf{P \neq NP}}" /> and related questions. </p>
<p>
Today I thought we would discuss consistency proofs in general.</p>
<p>
Lately I have been thinking about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P=NP}}" class="latex" title="{\mathsf{P=NP}}" /> and logic, with emphasis on consistency results. Thanks to Kurt Gödel’s famous Second Incompleteness Theorem we know that consistency theorems are difficult to prove. In particular he showed that</p>
<blockquote><p><b>Theorem 1 (Informally)</b> <em> Any sufficiently powerful consistent theory cannot prove that it is consistent. </em>
</p></blockquote>
<p></p><p>
In order to prove that some theory <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is consistent we need a stronger theory say <img src="https://s0.wp.com/latex.php?latex=%7BT%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T^{*}}" class="latex" title="{T^{*}}" />. But to prove this theory is itself consistent we need an even stronger theory <img src="https://s0.wp.com/latex.php?latex=%7BT%5E%7B%2A%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T^{**}}" class="latex" title="{T^{**}}" /> and so on. As they <a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down">say</a>:</p>
<blockquote><p><b> </b> <em> Its turtles all the way down. </em>
</p></blockquote>
<p></p><p>
It is not clear who first said this, but an 1854 <a href="https://books.google.com/books?id=SGtYAAAAMAAJ&amp;pg=PA48#v=onepage&amp;q&amp;f=false">transcript</a> of debates between a mainline and maverick minister records the former (Joseph Berg) saying of the latter (Joseph Barker):</p>
<blockquote><p><b> </b> <em> My opponent’s reasoning reminds me of the heathen, who, being asked on what the world stood, replied, “On a tortoise.” But on what does the tortoise stand? “On another tortoise.” With Mr. Barker, too, there are tortoises all the way down. </em>
</p></blockquote>
<p></p><p>
Recall a logical theory is consistent provided it never proves <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\neg A}" class="latex" title="{\neg A}" /> where as usual <img src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\neg A}" class="latex" title="{\neg A}" /> means “not” <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. Thus a theory is consistent provided it will never prove both <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\neg A}" class="latex" title="{\neg A}" />. This means that once a statement is proved we are done. There will be no surprise in the future. </p>
<p>
Bluntly: I would hate if my paper showing that <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is true, was followed by your paper showing that <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is also false. Besides pride I would hate this because, then any statement is true. This would certainly reduce any interest in my theorem proving <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and also in your theorem proving <img src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\neg X}" class="latex" title="{\neg X}" />. This is “ex contradictione quodlibet”.</p>
<p>
The rule 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%5Ctext%7B+and+%7D+%5Cneg+X+%5Cimplies+%5Ctext%7B%60%60Pigs+can+fly%27%27%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X \text{ and } \neg X \implies \text{``Pigs can fly''} " class="latex" title="\displaystyle  X \text{ and } \neg X \implies \text{``Pigs can fly''} " /></p>
<p>must be true. Right. Or must it? In a moment, but first some examples of consistency issues.</p>
<p>
</p><p></p><h2> Failure of Consistency </h2><p></p>
<p></p><p>
Since David Hilbert explicitly, and before implicitly, there has been interest in showing that our math theories are consistent. It may seem strange that consistency could ever be an issue, but read on.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A theory that was thought to be inconsistent:</i><br />
The creation of non-Euclidean geometries asked could these geometries be consistent? The answer is yes. It is possible to show that they are as consistent as Euclidean geometries. This done by building models of their new geometry by using Eucildean geometries in clever ways.</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/models2/" rel="attachment wp-att-17033"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/05/models2.jpg?w=300&amp;h=282" class="aligncenter size-medium wp-image-17033" height="282" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"></font>
</td>
</tr>
</tbody></table>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A theory that was thought to be consistent:</i> <br />
The famous Russell paradox destroyed early formulations of set theory. Bertrand Russell noted that the formulations allowed defining the following as a set: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S+%3D+%5C%7B+x+%5Cmid+x+%5Cnot%5Cin+x+%5C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S = \{ x \mid x \not\in x \}. " class="latex" title="\displaystyle  S = \{ x \mid x \not\in x \}. " /></p>
<p>But this is a problem, since it creates logical statements that are equivalent to their negations: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%5Cin+S+%5Ciff+x+%5Cnot%5Cin+S.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x \in S \iff x \not\in S. " class="latex" title="\displaystyle  x \in S \iff x \not\in S. " /></p>
<p>Fixing this led to the creation of modern set theory <a href="https://plato.stanford.edu/entries/set-theory/#AxiZFC">ZF</a>. It is named Zermelo-Fraenkel set theory, after Ernst Zermelo and Abraham Fraenkel.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A theory that was thought to be—still unclear:</i> <br />
Willard Quine’s theory “New Foundations” (<a href="https://en.wikipedia.org/wiki/New_Foundations">NF</a>) of set theory remains a problem. There are some possible relative proofs that show that it is as consistent as normal set theory. See this for the <a href="https://arxiv.org/abs/1503.01406">claim</a> by Randall Holmes that NF is as consistent as ZF—see <a href="https://math.boisestate.edu/~holmes/nfproof/sorted_at_last_maybe.pdf">this</a>.</p>
<p>
</p><p></p><h2> Length-based Immunity </h2><p></p>
<p></p><p>
The sentences used by Krajicek and his co-authors Jan Bydzovsky and Igor Oliveira in a recent <a href="https://arxiv.org/abs/1905.12935">paper</a> deal with forms of <em>length-based immunity</em>. The complexity-theoretic definition is this:</p>
<blockquote><p><b>Definition 2</b> <em><a name="lbimmune"></a> A language <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is <b>length-based immune</b> (LBI) to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> if for every polynomial-time program <img src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{P_i}" class="latex" title="{P_i}" />, there are only finitely many <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{P_i}" class="latex" title="{P_i}" /> is correct on strings of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. That is, </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+P_i%29%28%5Cexists+%5Cell%29%28%5Cforall+n+%3E+%5Cell%29%28%5Cexists+x+%5Cin+%5CSigma%5En%29%3A+P_i%28x%29+%5Cneq+B%28x%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  (\forall P_i)(\exists \ell)(\forall n &gt; \ell)(\exists x \in \Sigma^n): P_i(x) \neq B(x). " class="latex" title="\displaystyle  (\forall P_i)(\exists \ell)(\forall n &gt; \ell)(\exists x \in \Sigma^n): P_i(x) \neq B(x). " /></p>
</em><p><em></em>
</p></blockquote>
<p></p><p>
This property is akin to <em>immunity</em>: not having an infinite easy subset. The known <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />-complete sets are <em>not</em> immune: for instance there are many easy cases of SAT. Under the <a href="https://en.wikipedia.org/wiki/Berman-Hartmanis_conjecture">Isomorphism Conjecture</a>, no <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />-complete set is immune. Whether SAT can be length-based immune might depend on details of how formulas are encoded, but under a “natural” encoding one might expect length-based immunity to hold.</p>
<p>
Of course, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> has a length-based immune set then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq NP}}" class="latex" title="{\mathsf{P \neq NP}}" />. Say a theory <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is “adequate” if it is consistent and proves basic facts about complexity classes such as that one. Then for an adequate theory <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />:</p>
<blockquote><p><b> </b> <em> Suppose we prove it is consistent with <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> has an LBI set. Then <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> cannot prove that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> does not have an LBI set. Since <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P = NP}}" class="latex" title="{\mathsf{P = NP}}" /> imples that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> does not have an LBI set, this yields the simple and notable conclusion that <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> cannot prove <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P = NP}.}" class="latex" title="{\mathsf{P = NP}.}" /> That is, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq NP}}" class="latex" title="{\mathsf{P \neq NP}}" /> is consistent with <img src="https://s0.wp.com/latex.php?latex=%7BT.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T.}" class="latex" title="{T.}" /></em>
</p></blockquote>
<p></p><p>
Krajicek, as we said before, has tried to prove that complexity statements like <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq NP}}" class="latex" title="{\mathsf{P \neq NP}}" /> are consistent. The trouble is that such questions are difficult. So he and others have worked on showing that these questions are at least consistent with theories <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> of arithmetic. It seems too hard to handle Peano arithmetic yet, so they work with theories <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> that are weaker than Peano arithmetic—but still adequate. For these theories, Krajicek and company have results for some variations of Definition~<a href="https://rjlipton.wordpress.com/feed/#lbimmune">2</a>, albeit ones that seem not to have a direct relation to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P = NP}}" class="latex" title="{\mathsf{P = NP}}" />. The two main ways to vary the Definition~<a href="https://rjlipton.wordpress.com/feed/#lbimmune">2</a> are:</p>
<ul>
<li>
Change the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{C}}" class="latex" title="{\mathcal{C}}" /> that has—or may not have—a length-based immune set to something else, for instance <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D+%3D+%5Cmathsf%7BP%5E%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{C} = \mathsf{P^{NP}}}" class="latex" title="{\mathcal{C} = \mathsf{P^{NP}}}" />. <p></p>
</li><li>
Change the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{Q}}" class="latex" title="{\mathcal{Q}}" /> of programs the sets are immune to from polynomial-time programs to something else.
</li></ul>
<p>
</p><p></p><h2> Fixed Polynomial Size Circuits </h2><p></p>
<p></p><p>
They fix a constant exponent <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> and take <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{Q}}" class="latex" title="{\mathcal{Q}}" /> to be families of <em>circuits</em> <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" /> of fixed polynomial size <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />. The circuits can be non-uniform, and indeed the unprovable statements are defined by a process that is not constructive. </p>
<p>
Circuits of linear or other fixed polynomial size are a fascinating and important topic in themselves. We have <a href="https://rjlipton.wordpress.com/2010/03/31/a-problem-with-proving-problems-are-hard/">posted</a> about Ravi Kannan’s famous theorem that for every fixed <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, the second level of the polynomial hierarchy has languages without <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-sized circuits. The upper bound has since been pushed lower but not all the way to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%5E%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P^{NP}}}" class="latex" title="{\mathsf{P^{NP}}}" />. It is of course believed that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> has languages without <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-sized circuits, since SAT is believed to require super-polynomial size. But the question of whether <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> has sets that lack such circuits—let alone being immune—is currently not known to have implications about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P = NP}}" class="latex" title="{\mathsf{P = NP}}" />. </p>
<p>
Note that the easy instances of SAT that we alluded to above are easy for linear-size circuits. Moreover, whether <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> itself has—or doesn’t have—sets that are length-based immune to <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-size circuits is a statement that can be plausibly argued either way. Krajicek and Oliveira had earlier <a href="https://arxiv.org/abs/1605.00263">proved</a> that a particular theory called PV—which we will discuss next—cannot prove for any <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> that every language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> has <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-sized circuits. This unprovable statement, without the LBI condition, strikes us as less plausible—hence less surprising that a weaker theory like PV cannot prove it. What they prove now is:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="thm1a"></a> For any fixed <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, PV cannot prove that every language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> allows circuits of size <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" /> to get the right answers on infinitely many input lengths. That is, it is consistent with PV that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> has sets that are LBI to <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-size circuits.</em></p><em>
</em><p><em>
Moreover, for some particular theories called <img src="https://s0.wp.com/latex.php?latex=%7BS%5E1_2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S^1_2}" class="latex" title="{S^1_2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BT%5E1_2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T^1_2}" class="latex" title="{T^1_2}" /> that extend PV, it is consistent that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />, respectively <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bp%5E%7BNP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{p^{NP}}}" class="latex" title="{\mathsf{p^{NP}}}" /> has sets that are LBI to <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-sized circuits. </em>
</p></blockquote>
<p></p><p>
We will talk a little more about these theories.</p>
<p>
</p><p></p><h2> PV and Related Theories </h2><p></p>
<p></p><p>
What are the candidate theories for <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />? One is PV, a theory created by Steve Cook. For every polynomial-time program <img src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_i}" class="latex" title="{P_i}" />, PV has a symbol <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varphi_i}" class="latex" title="{\varphi_i}" /> for the function that <img src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_i}" class="latex" title="{P_i}" /> computes. Then add all the equations that these functions satisfy and you have PV. For example, 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7Bx%2B1%7D+%3D+2+%5Ctimes+2%5E%7Bx%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  2^{x+1} = 2 \times 2^{x}, " class="latex" title="\displaystyle  2^{x+1} = 2 \times 2^{x}, " /></p>
<p>for the exponential function <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+2%5E%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \rightarrow 2^{x}}" class="latex" title="{x \rightarrow 2^{x}}" />. </p>
<p>
PV can formalize and prove properties of program-building constructs like composition and bounded for-loops that preserve running in polynomial time. It can formalize the concept of polynomial-size Boolean circuits and establish basic facts about them. It can prove deep results like the PCP theorem and more. </p>
<p>
Thus showing that your favorite statement is at least consistent with PV would be neat. It is critical that PV only allows equations as axioms. Thus PV does not axiomatize the statement 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x+%5Cexists+y%3Ex+%5C+2%5E%7By%7D-1+%5Ctext%7B+is+a+prime%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall x \exists y&gt;x \ 2^{y}-1 \text{ is a prime} " class="latex" title="\displaystyle  \forall x \exists y&gt;x \ 2^{y}-1 \text{ is a prime} " /></p>
<p>even if it is true. The more-formal statement of their theorem for PV is:</p>
<blockquote><p><b>Theorem 4</b> <em><a name="thm1b"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, there is a formula <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\varphi(x)}" class="latex" title="{\varphi(x)}" /> in the language of PV such that the statement </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CUpsilon_%7B%5Cvarphi%7D+%3D+%28%5Cforall+%5Cell%29%28%5Cexists+n+%3E+%5Cell%29%28%5Cexists+C_n+%5Ctext%7B+of+size+%7D+%5Cleq+n%5Ek%29%28%5Cforall+x%5Cin+%5CSigma%5En%29%3A+%5Cvarphi%28x%29+%3D+C_n%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \Upsilon_{\varphi} = (\forall \ell)(\exists n &gt; \ell)(\exists C_n \text{ of size } \leq n^k)(\forall x\in \Sigma^n): \varphi(x) = C_n(x) " class="latex" title="\displaystyle  \Upsilon_{\varphi} = (\forall \ell)(\exists n &gt; \ell)(\exists C_n \text{ of size } \leq n^k)(\forall x\in \Sigma^n): \varphi(x) = C_n(x) " /></p>
</em><p><em>is not provable in PV, and such that the function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\varphi(x)}" class="latex" title="{\varphi(x)}" /> is polynomial-time computable. </em>
</p></blockquote>
<p></p><p>
The theorem is not diminished if we restrict attention to yes/no formulas and circuit outputs. Thus it is not provable that every language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> has infinitely many input lengths at which it is easy for <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-sized circuits. Put another way, it is consistent with PV to assert (for any <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />) that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> has a language that lacks size-<img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" /> circuits <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" /> in the strong sense of <em>every</em> <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" /> making an error on some string of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, beyond a finite number of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. This is stronger than saying the language lacks <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^k}" class="latex" title="{n^k}" />-size circuits, which makes the consistency more notable.</p>
<p>
Where PV lacks power is with the unrestricted induction enjoyed by Peano Arithmetic. The other theories <img src="https://s0.wp.com/latex.php?latex=%7BS_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S_2^1}" class="latex" title="{S_2^1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BT_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_2^1}" class="latex" title="{T_2^1}" />, which were named and studied by Sam Buss in the 1980s, add more induction—by limiting the kind of formulas on which it is allowed.</p>
<p>
Here is where we point to the papers for details. The devil in those details is that the exceptional formulas <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varphi}" class="latex" title="{\varphi}" /> are not expressly constructed. For one, the proofs of their theorems use a disjunction about whether the polynomial hierarchy collapses at a certain level. Note that something similar is already at work in our <a href="https://rjlipton.wordpress.com/2010/03/31/a-problem-with-proving-problems-are-hard/">post</a> on Kannan’s theorem. </p>
<p>
Second, their proofs exploit a quirk of PV and the other theories that they have symbols for all polynomial-time programs without having commensurate command of the semantics of what these programs represent. The induction and axioms available to <img src="https://s0.wp.com/latex.php?latex=%7BS_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S_2^1}" class="latex" title="{S_2^1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BT_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_2^1}" class="latex" title="{T_2^1}" /> bridge some but not all of these gaps. </p>
<p>
Third and most particular, their theorem uses a self-referential strategy. It starts building <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varphi'}" class="latex" title="{\varphi'}" /> but branches according to whether the theory <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> can prove <img src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon_%7B%5Cvarphi%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Upsilon_{\varphi'}}" class="latex" title="{\Upsilon_{\varphi'}}" />. If not it keeps going, if yes it does something else. Thus the proof does not tell what <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varphi(x)}" class="latex" title="{\varphi(x)}" /> is, nor identify a particular language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{C}}" class="latex" title="{\mathcal{C}}" /> for which the LBI property is consistent.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Another way of saying “Statement <img src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Upsilon}" class="latex" title="{\Upsilon}" /> is consistent with <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />” is that one can build a <em>model</em> of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> in which <img src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Upsilon}" class="latex" title="{\Upsilon}" /> is true. What do those models look like? Do they relate to the notion of <em>oracles</em> <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> relative to which certain statements—such as <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}^A}" class="latex" title="{\mathsf{NP}^A}" /> having languages that are (length-based-) immune to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}^A}" class="latex" title="{\mathsf{P}^A}" />—are true?</p>
<p>
[William–&gt;Willard Quine]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/"><span class="datestr">at May 11, 2020 12:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3481">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2020/05/11/special-issue-of-jaamas-on-fair-division/">Special Issue of JAAMAS on Fair Division</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Dear all,</p>
<p>We are happy to announce that the Journal of Autonomous Agents and Multiagent Systems will host a special issue on Fair Division. We welcome full versions of papers on fair division that have appeared in recent editions of AAMAS, IJCAI, AAAI, ECAI, ACM EC, WINE, SAGT, and other relevant conferences, as well as papers that have not been published in conference proceedings.</p>
<p><a href="https://www.springer.com/journal/10458/updates/17851836">Call for Papers</a></p>
<p>Please note that there will be a rolling review process: submissions accepted before the completion of the issue will be available on the journal website shortly after acceptance. Deadline: March 1, 2021.</p>
<p>Guest Editors<br />
Edith Elkind<br />
Nicolas Maudet<br />
Warut Suksompong</p></div>







<p class="date">
by felixbrandt <a href="https://agtb.wordpress.com/2020/05/11/special-issue-of-jaamas-on-fair-division/"><span class="datestr">at May 11, 2020 11:05 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19844">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/05/11/to-cheer-you-up-in-difficult-times-4-wit-presents-i-will-survive/">To cheer you up in difficult times 4: Women In Theory present — I will survive</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>An amazing video</p>
<p></p>
<p><span id="more-19844"></span></p>
<p>The original 1978 version is also quite good.<br />
</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/05/11/to-cheer-you-up-in-difficult-times-4-wit-presents-i-will-survive/"><span class="datestr">at May 10, 2020 09:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1693">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/05/10/weve-got-wit-and-they-got-talent/">We’ve got WIT and they got Talent</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The wonderful <a href="https://theorydish.blog/2020/01/09/women-in-theory-2018-call-for-application-2/">Women in Theory</a> is, like so many other events this year, virtual in 2020 (physical meeting <a href="https://womenintheory.wordpress.com/">postponed to 2021)</a>. And it is happening today! The virtual meeting lets our WIT show that their talents go beyond science. <a href="https://www.youtube.com/watch?v=4Wl-3kadvgw">Highly recommended clip</a>! I’ve been watching on loop <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /></p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/05/10/weve-got-wit-and-they-got-talent/"><span class="datestr">at May 10, 2020 05:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/10/visiting-professor-at-university-of-tyumen-school-of-advanced-studies-apply-by-june-30-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/10/visiting-professor-at-university-of-tyumen-school-of-advanced-studies-apply-by-june-30-2020/">Visiting Professor at University of Tyumen, School of Advanced Studies (apply by June 30, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Visiting Professors of Computer Science, 2-10 months appointments during 2020-2021 academic year. No knowledge of Russian is required.</p>
<p>Please send a CV, two letters of reference (to be sent separately), and a cover letter describing your professional background, including the description of courses you have taught or would like to teach, to job.sas@utmn.ru.</p>
<p>Website: <a href="https://sas.utmn.ru/en/">https://sas.utmn.ru/en/</a><br />
Email: d.kontowski@utmn.ru</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/10/visiting-professor-at-university-of-tyumen-school-of-advanced-studies-apply-by-june-30-2020/"><span class="datestr">at May 10, 2020 06:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
