<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 07, 2021 10:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/05/07/ph-d-student-at-idsia-usi-supsi-lugano-switzerland-apply-by-june-30-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/05/07/ph-d-student-at-idsia-usi-supsi-lugano-switzerland-apply-by-june-30-2021/">Ph.D. Student at IDSIA, USI-SUPSI, Lugano, Switzerland (apply by June 30, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>IDSIA opens two 4-year Ph.D. positions, starting on November 2021, in the area of algorithms and complexity, with a focus on approximation algorithms.<br />
The gross year salary is around 50K CHF. Candidates should hold a Master Degree in Computer Science or related areas.<br />
The interested candidates should email Prof. Fabrizio Grandoni a detailed CV and contact details of 2-3 references.</p>
<p>Website: <a href="https://people.idsia.ch//~grandoni/">https://people.idsia.ch//~grandoni/</a><br />
Email: fabrizio@idsia.ch</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/05/07/ph-d-student-at-idsia-usi-supsi-lugano-switzerland-apply-by-june-30-2021/"><span class="datestr">at May 07, 2021 09:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21716">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/05/06/alef-corner-icm2022/">Alef Corner: ICM2022</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><img width="2100" alt="icm2022" src="https://gilkalai.files.wordpress.com/2021/05/icm2022.jpg" class="alignnone size-full wp-image-21717" height="2100" /><strong><span style="color: #ff0000;">Alef’s new piece for ICM 2022 will surely cheer you up!</span> </strong></p>


<p></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/05/06/alef-corner-icm2022/"><span class="datestr">at May 06, 2021 07:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.let-all.com/blog/?p=51">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/letall.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.let-all.com/blog/2021/05/06/alt-highlights-a-report-on-the-first-alt-mentoring-workshop/">ALT Highlights – A Report on the First ALT Mentoring Workshop</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fifth post in the series, coverage of the first <a href="https://www.let-all.com/alt.html">ALT Mentoring Workshop</a> organized by the Learning Theory Alliance, written by <a href="https://www.let-all.com/blog/feed/knaggita@ttic.edu">Keziah Naggita</a> and <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a>.</p>



<hr class="wp-block-separator" />



<h2><strong>1 Introduction</strong></h2>



<p class="has-text-align-left has-text-align-justify">The Learning Theory Alliance (Let-All) is an online initiative aimed at developing a supportive learning theory community, founded by (1) <a href="https://www.cs.utexas.edu/~surbhi/" target="_blank" rel="noopener noreferrer">Surbhi Goel</a>, a postdoctoral researcher at Microsoft Research New York, (2) <a href="https://people.eecs.berkeley.edu/~nika/" target="_blank" rel="noopener noreferrer">Nika Haghtalab</a>, an assistant professor at UC Berkeley EECS, (3) and <a href="https://vitercik.github.io" target="_blank" rel="noopener noreferrer">Ellen Vitercik</a>, a Ph.D. Student at CMU; and advised by <a href="https://www.stat.berkeley.edu/~bartlett/" target="_blank" rel="noopener noreferrer">Peter Bartlett</a>, <a href="https://home.ttic.edu/~avrim/" target="_blank" rel="noopener noreferrer">Avrim Blum</a>, <a href="https://people.csail.mit.edu/stefje/" target="_blank" rel="noopener noreferrer">Stefanie Jegelka</a>, <a href="https://www.dpmms.cam.ac.uk/%7Epll28/" target="_blank" rel="noopener noreferrer">Po-Ling Loh</a>, and <a href="http://www.jennwv.com" target="_blank" rel="noopener noreferrer">Jenn Wortman Vaughan</a>. The goal of the alliance is to ensure healthy community growth by fostering inclusive community engagement and encouraging active contributions from researchers at all stages of their careers. Let-All’s efforts towards realizing these goals include a series of ongoing and future activities, such as the first ALT mentoring workshop, coordinating the ALT Highlights blog series, and other upcoming community initiatives. This article reports on  Let-All’s <a href="https://let-all.com/alt.html" target="_blank" rel="noopener noreferrer">first Mentoring Workshop</a>, which was affiliated with the 32<sup>nd</sup> International Conference on Algorithmic Learning Theory.</p>



<p class="has-text-align-left has-text-align-justify">The workshop had two main sessions to cater to the time zone differences of the participants.  These sessions had three main components: an academic program, which included how-to-talks, Ask Me Anythings (AMAs), and presentation dissections; a technical program, which included research talks; and a social program, which included discussion tables and other activities.</p>



<p class="has-text-align-left has-text-align-justify">The workshop participants included students, researchers, and industry professionals, all at different levels of familiarity with learning theory. Because of the ongoing COVID-19 pandemic, the workshop was virtual. It was held on the online platforms Zoom and Gather town, a virtual interactive environment that mimics an in-person workshop setting. For accessibility, the workshop organizers opened up the workshop free of cost to all registered participants. </p>



<h2><strong>2 Program Highlights</strong></h2>



<h3><strong>2.1 Academic Program</strong></h3>



<p class="has-text-align-left has-text-align-justify">To kick off the workshop, one of the organizers began with a welcome lecture: Surbhi in session one and Nika in session two.  They read out the code of conduct and who to contact in case of issues, outlined the workshop’s purpose, and gave attendees demographic information. They explained how participants could navigate the workshop-themed Gather town workspace and then ended the introduction with encouragement for participants to mingle. </p>



<p class="has-text-align-left has-text-align-justify">The <strong><em>How-to-Talks</em></strong> sessions covered writing papers, giving talks, and networking. In Session 1, <a href="https://www.cs.cmu.edu/~praveshk/" target="_blank" rel="noopener noreferrer">Pravesh Kothari</a> talked in great detail about the dos and don’ts of what to add in the abstract, overview, introduction, and appendix when advising participants on how to best structure research papers. He told attendees to always put effort into understanding their intended reader or talk audience.  Pravesh encouraged attendees to consider the expertise and interests of the reader or listener to capture their attention since these highly determine the attention span and interest in the information presented to them.  He strongly recommended attendees watch the <em><a href="https://www.youtube.com/watch?v=vtIzMaLkCaM" target="_blank" rel="noopener noreferrer">Leadership Lab: The Craft of Writing Effectively</a></em> by Larry McEnerney , Director of the University of Chicago Writing Program.<em> </em>In session 2 of the workshop, <a href="https://home.cs.colorado.edu/~raf/" target="_blank" rel="noopener noreferrer">Rafael Frongillo</a>, similar to Pravesh, discussed how to capture the intended audience when one writes a paper, reviews, and talks.</p>



<p class="has-text-align-left has-text-align-justify">In the first <strong><em>networking session</em></strong>, <a href="https://www.cc.gatech.edu/~jabernethy9/" target="_blank" rel="noopener noreferrer">Jacob Abernethy</a> encouraged participants to seek out horizontal and vertical networking, for example, through collaborations, talks, and reach outs. He said that currently, in academia, Ph.D. admissions, faculty hiring, and tenure appointments are heavily risk-averse. Therefore, people seek out candidates based on their network. For this reason, it is crucial for students to network from early on in their careers. He gave great examples of how junior researchers can reach out and forge relationships with other researchers. For example, when you meet academics, faculty/postdocs at events, ask to give a talk at their lab. Jacob also candidly talked about his earlier failures at MIT and how they shaped his journey. He talked about luck and how <a href="https://www.microsoft.com/en-us/research/people/jcl/" target="_blank" rel="noopener noreferrer">John Langford</a>, who was at Toyota Technological Institute at Chicago at the time, took a chance on him that forever changed his life. Jacob, therefore, advised academics to take chances on people as this would change the course of the field. </p>



<p class="has-text-align-left has-text-align-justify"><a href="https://jamiemorgenstern.com" target="_blank" rel="noopener noreferrer">Jamie Morgenstern</a> discussed different networking methods in the <strong><em>second How-to-talks session</em></strong>. She emphasized that for junior researchers, it’s important to attend conferences and to network with others, to advertise their research through talks, and to reach out to faculty for collaboration. To introduce oneself and capture the listener’s attention, Jamie said, for conferences, prepare to do so in two minutes, for social four minutes, bar 12 minutes, and faculty interview 25 minutes. Senior grad students may help introduce the juniors during lunch/poster sessions. Finally, when emailing faculty about research, she said one should avoid discussion about other people’s work and instead should stick to the recipient’s work – “showing deep understanding and possibly open questions which might lead to collaboration.” </p>



<p class="has-text-align-left has-text-align-justify">In both workshop sessions, there were<strong><em> two parallel talk dissections, </em></strong>in which senior faculty members gave both positive and constructive feedback on talks junior researchers presented. In the first session, <a href="https://www.cs.cornell.edu/~rdk/" target="_blank" rel="noopener noreferrer">Bobby Kleinberg</a> discussed <a href="https://www.emilyruthdiana.com" target="_blank" rel="noopener noreferrer">Emily Diana</a>‘s talk titled “Minimax and Lexicographically Fair Learning: Algorithms, Experiments, and Generalization”. He highlighted parts that were impressive, those that needed improvement, and gave general advice on structuring an audience-based presentation. When Bobby suggested including more diagrams than text, a few people made suggestions of free tools including tikz, matcha.io, PowerPoint, and draw.io. In parallel, <a href="http://cseweb.ucsd.edu/~kamalika/" target="_blank" rel="noopener noreferrer">Kamalika Chaudhuri</a> dissected a talk on “Efficient, Noise-Tolerant, and Private Learning via Boosting” by <a href="https://marco.ntime.org" target="_blank" rel="noopener noreferrer">Marco Carmosino</a>. Two main takeaways of this talk dissection were the balance of technical and nontechnical content (e.g., explaining ideas with fun pictures, etc.) and having one main and clear idea as the talk’s takeaway. </p>



<p class="has-text-align-left has-text-align-justify">In the second session, <a href="https://sites.google.com/site/acmonsterqiao/" target="_blank" rel="noopener noreferrer">Mingda Qiao</a> gave a talk titled: “Stronger Calibration Lower Bounds via Sidestepping” which <a href="https://praneethnetrapalli.org" target="_blank" rel="noopener noreferrer">Praneeth Netrapalli</a> dissected. Praneeth remarked that theory folks often jump into the problem straight away without covering much background. In conferences, this might be fine due to time pressure and specific interests. However, in broader settings such as departmental seminars, he advised the speaker to allocate more time to introduce the problem lucidly and concisely. In parallel, <a href="https://sites.google.com/site/marywootters/" target="_blank" rel="noopener noreferrer">Mary Wootters</a> dissected a talk titled “List-Decodable Subspace Recovery: Dimension Independent Error in Polynomial Time” that <a href="http://aineshbakshi.com" target="_blank" rel="noopener noreferrer">Ainesh Bakshi</a> presented. </p>



<p class="has-text-align-left has-text-align-justify">In the first <strong><em>AMA session</em></strong> moderated by <a href="https://www.stat.cmu.edu/~aramdas/" target="_blank" rel="noopener noreferrer">Aaditya Ramdas</a>, <a href="https://web.stanford.edu/~lmackey/" target="_blank" rel="noopener noreferrer">Lester Mackey</a> refreshingly answered several of the attendees’ well-curated questions about what makes strong collaborations, how to get into grad school, and whether or not he ever felt like quitting his Ph.D., among others.  He encouraged students to take classes with professors they are interested in as it makes it easy to ask for a mentorship opportunity. Lester talked about collaborations and imposter syndrome and encouraged attendees to look on the brighter side of things, to remember that we all are working towards one big goal, creating positive changes in the world. Therefore if someone discovers a result before us, we should applaud them, collaborate if possible, and move onto new problems. He said he did not necessarily plan to do a Ph.D. but got into it towards the end of his undergraduate degree due to an internship that made him fall in love with doing research. </p>



<p class="has-text-align-left has-text-align-justify">In the evening, there was an AMA session with <a href="http://people.csail.mit.edu/shafi/" target="_blank" rel="noopener noreferrer">Shafi Goldwasser</a> moderated by Nika. Shafi gave thoughtful and candid answers to attendees’ captivating questions about research, life in academia, collaborations, among others. Shafi told attendees that healthy competition, trust, and overlap of research interest, is crucial for successful research in the early stage of the career. She also asserted that fundamental science is always impactful. She mentioned that the high points of her career were working on problems she was curious about: cryptography, pseudo-randomness, and zero-knowledge proofs. Finally, when asked about what advice she wished she had during the early stage of her career, interestingly Shafi replied: “having good colleagues, good friends at work, very important, most important – having a listening, promoting and supportive cohort of friends rather than an individualistic path as a scholar is priceless.” </p>



<h3><strong>2.2 Technical Program</strong></h3>



<p class="has-text-align-left has-text-align-justify"><strong><em>Two research talks</em></strong> happened in the first session. First, Po-Ling Loh gave a talk titled “Mean estimation for entangled single-sample distributions.” Then <a href="https://web.stanford.edu/~vsharan/" target="_blank" rel="noopener noreferrer">Vatsal Sharan</a> talked about “Sample Amplification: Increasing Dataset Size even when Learning is Impossible”.<br />Similarly in the second session, <a href="https://www.cohennadav.com" target="_blank" rel="noopener noreferrer">Nadav Cohen</a> gave the first talk about tensor and matrix completion problems and the importance of understanding the theory behind deep learning from theoretical and practical perspectives. After, <a href="https://i.cs.hku.hk/~zhiyi/" target="_blank" rel="noopener noreferrer">Zhiyi Huang</a> gave a talk titled “Setting the Sample Complexity of Single-parameter Revenue Maximization.” </p>



<h3><strong>2.3 Social Program</strong></h3>



<p class="has-text-align-left has-text-align-justify">In both sessions, during the social hours, <a href="https://sites.google.com/view/sumegha-garg/home" target="_blank" rel="noopener noreferrer">Sumegha Garg</a>, <a href="http://sgunasekar.github.io" target="_blank" rel="noopener noreferrer">Suriya Gunasekar</a>, and <a href="https://teddlyk.github.io" target="_blank" rel="noopener noreferrer">Thodoris Lykouris</a> organized the <strong><em>table topics</em></strong> to help attendees meet and interact with senior researchers and professors on different topics. The table topics included the following; starting on ML research, research agendas, ML+X: multidisciplinary research, advisor-advisee relationships, collaborators, communicating research and networking, beyond your institution: internships and research visits, planning after grad school: academia versus industry, Grad school applications, Work ethics, and Open research discussion. </p>



<p class="has-text-align-left has-text-align-justify">The table topics were chaired by; Jacob Abernethy, <a href="https://www.shivani-agarwal.net" target="_blank" rel="noopener noreferrer">Shivani Agarwal</a>, <a href="https://ericbalkanski.com" target="_blank" rel="noopener noreferrer">Eric Balkanski</a>, Peter Bartlett, Avrim Blum, <a href="http://sbubeck.com/" target="_blank" rel="noreferrer noopener">Sébastien Bubeck</a>, Kamalika Chaudhuri, Nadav Cohen, Sumegha Garg, Surbhi Goel, Suriya Gunasekar, Nika Haghtalab,  <a href="https://www.cs.columbia.edu/~djhsu/" target="_blank" rel="noopener noreferrer">Daniel Hsu</a>, <a href="https://www.prateekjain.org" target="_blank" rel="noopener noreferrer">Prateek Jain</a>, <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/jordan.html" target="_blank" rel="noopener noreferrer">Mike Jordan</a>, <a href="https://homes.cs.washington.edu/~sham/" target="_blank" rel="noopener noreferrer">Sham Kakade</a>, <a href="https://www.microsoft.com/en-us/research/people/adum/" target="_blank" rel="noopener noreferrer">Adam Kalai</a>, Pravesh Kothari, <a href="https://people.cs.umass.edu/~akshay/" target="_blank" rel="noopener noreferrer">Akshay Krishnamurthy</a>, <a href="https://jerryzli.github.io" target="_blank" rel="noopener noreferrer">Jerry Li</a>, Po-Ling Loh, Thodoris Lykouris, <a href="https://www.tau.ac.il/~mansour/" target="_blank" rel="noopener noreferrer">Yishay Mansour</a>, <a href="https://pasin30055.github.io" target="_blank" rel="noopener noreferrer">Pasin Manurangsi</a>, <a href="https://vmuthukumar.ece.gatech.edu" target="_blank" rel="noopener noreferrer">Vidya Muthukumar</a>, Praneeth Netrapalli, <a href="https://wensun.github.io" target="_blank" rel="noopener noreferrer">Wen Sun</a>, <a href="https://www.bowaggoner.com" target="_blank" rel="noopener noreferrer">Bo Waggoner</a>, <a href="https://mzampet.com" target="_blank" rel="noopener noreferrer">Manolis Zampetakis</a>, and <a href="https://cyrilzhang.com/">Cyril Zhang</a>. </p>



<p class="has-text-align-left has-text-align-justify">Lastly, at the end of the two general research talks in sessions one and two of the workshop, attendees assembled on Gather town to close the workshop. The social event included 1:1 social interactions with other attendees, an attempt at forging relationships, and activities like dancing.</p>



<h2><strong>3 Attendance Statistics, Testimonials and Feedback</strong></h2>



<h3><strong>3.1 Participants Statistics</strong></h3>



<p class="has-text-align-left has-text-align-justify">ALT mentoring workshop welcomed talented academics, researchers, and professionals from a wide array of backgrounds. Of the 438 registered to attend the workshop, 197 were new to the learning theory community, 37 attended at least one ALT/COLT conference in the past, and 146 hadn’t attended ALT/COLT but had attended machine learning conferences (STOC, NeurIPS, etc.) as shown in Figure 1. </p>



<p class="has-text-align-left has-text-align-justify">The workshop participants came from different parts of the world, were of different genders, races, and seniority levels. We use Figures 2, 3b, 4a, and 4b to highlight this demographic information about the participants. Some participants chose session one, and others chose session two, a choice driven by their schedules and time zones. The attendance composition is as shown in figure 3a.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="515" alt="" src="https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.28-AM.png?resize=515%2C310&amp;ssl=1" class="wp-image-58" height="310" />Figure 1: Registrants familiarity with the community</figure></div>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="678" alt="" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.11-AM-2.png?resize=678%2C401&amp;ssl=1" class="wp-image-61" height="401" />Figure 2: Career stages of participants</figure></div>



<figure class="wp-block-gallery columns-2 is-cropped"><ul class="blocks-gallery-grid"><li class="blocks-gallery-item"><figure><img width="678" alt="" src="https://i2.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.33.54-AM-1.png?resize=678%2C414&amp;ssl=1" class="wp-image-70" height="414" /></figure></li><li class="blocks-gallery-item"><figure><img width="678" alt="" src="https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.35.25-AM-1.png?resize=678%2C406&amp;ssl=1" class="wp-image-71" height="406" /></figure></li></ul>Figure 3: Session preferences (a) and locations of participants (b)</figure>



<figure class="wp-block-gallery aligncenter columns-2 is-cropped"><ul class="blocks-gallery-grid"><li class="blocks-gallery-item"><figure><img width="678" alt="" src="https://i2.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.57-AM.png?resize=678%2C404&amp;ssl=1" class="wp-image-75" height="404" /></figure></li><li class="blocks-gallery-item"><figure><img width="678" alt="" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.34.42-AM-1.png?resize=678%2C404&amp;ssl=1" class="wp-image-77" height="404" /></figure></li></ul>Figure 4: Race (a) and Gender (b) distribution of participants</figure>



<p></p>



<h3><strong>3.2 Testimonials and Feedback</strong></h3>



<p class="has-text-align-left has-text-align-justify">In this section, we give a recount of testimonials from participants who we interviewed after the workshop. We also highlight some of the common themes in feedback from participants.</p>



<p class="has-text-align-left has-text-align-justify">In general, participants loved the content delivered in the sessions. They said it was informative, intuitive, and rare to find. Several participants loved interacting with peers and senior members and wished they had more time and activities to do it. The How-to-talks session (focused on networking skills, structuring papers, talks, and reviews) was the most popular session among attendees. 76.7% of the survey respondents said the session helped them gain new technical skills or hone existing skills, see opportunities in academia and how to use them, and see barriers in academia and ways to overcome them. Figure 5 highlights attendees’ ratings of the skills acquired from the workshop. </p>



<figure class="wp-block-image size-large is-resized is-style-default"><img width="678" alt="" src="https://i0.wp.com/www.let-all.com/blog/wp-content/uploads/2021/05/Screen-Shot-2021-05-04-at-4.35.11-AM.png?resize=678%2C404&amp;ssl=1" class="wp-image-80" height="404" />Figure 5: Usefulness ratings of skills gained from the workshop</figure>



<p><strong>Below is a recount of the workshop experiences of the interviewed attendees.</strong></p>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My highlight was the How-to-Talks since they provided a lot of more personal information/inputs that you cannot easily find online and which was very valuable. The event helped me to remember and reflect upon which qualities are crucial to becoming a good researcher. I even made a list in a place that I see every day to keep them in mind.” – <em><a href="https://www.michaelaerni.com" target="_blank" rel="noopener noreferrer">Michael Aerni</a>, MSc student at ETH Zurich.</em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“The workshop highlights for me were the How-to-talks, the AMA session with Lester, and the social tables. The How-to-talks were extremely valuable as they discussed topics such as structuring papers and networking in the community. These are subtle aspects that are not often explicitly talked about in the community. I, therefore, learned a lot from them. The AMA session was refreshingly honest and open. Finally, the social tables were also great as I got to meet and talk to some well-established senior community members like Sebastien Bubeck, Shivani Agarwal, and Akshay Krishnamurthy.” – <em><a href="https://people.eecs.berkeley.edu/~tgautam23/" target="_blank" rel="noopener noreferrer">Tanmay Gautam</a>, a second-year Ph.D. student at UC Berkeley. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“It was awesome to have Lester Mackey answer my questions, indubitably. I learned about staying true to the research questions I genuinely believe in regardless of external opinions and rewards. As an NYU AI School organizer, I can appreciate how much effort went into organizing the workshop. The organizers did a stellar job! I think a version of the same event again would be perfect.” – <em><a href="https://swapneelm.github.io" target="_blank" rel="noopener noreferrer">Swapneel Mehta</a>, a Data Science Ph.D. student at New York University. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My highlights were getting to talk with senior members of the community. These opportunities rarely come by for someone who lives in a foreign country. For a timid person like myself, I am also thankful for the senior members for helping me (and other participants) breaking the ice and easing us into the conversations. Thanks to this event, I am now more confident in engaging with other researchers.”- <em><a href="http://www.donlapark.cmustat.com" target="_blank" rel="noopener noreferrer">Donlapark Ponnoprat</a>, a Statistics lecturer at Chiang Mai University. </em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My main highlights were Dr. Goldwasser’s session with Dr. Haghtalab and the socials. In the socials, I was able to ask professors and senior researchers for advice on varied topics based on the tables. Insights from Dr. Cohen’s lecture on tensor rank and implicit regularisation gave me several pointers to ideas in the literature that I was not aware of as a junior researcher from a slightly different AI specialty. These ideas might be beneficial for my research in the long term. </p><p class="has-text-align-left has-text-align-justify"> I send a sincere thank you to all the organizers. The mentorship workshop was a great event, and it models concrete actions, what it means to foster a welcoming community. It is clear how kind and dedicated folks are here as some researchers even stayed beyond midnight in their time zones to answer questions that attendees had. If an event like this happens again, I am most definitely signing up to come.” – <em><a href="https://github.com/esraa-saleh" target="_blank" rel="noopener noreferrer">Esra’a Saleh</a>, a Masters in Computer Science student at the University of Alberta, affiliated with AMII and RLAI.</em></p></blockquote>



<blockquote class="wp-block-quote"><p class="has-text-align-left has-text-align-justify">“My main takeaway from the event was an inside look at academia. As an undergrad, my only experience in academia has been the little experience I have with my advisory professors. While this is an invaluable experience, this event was nice as it was one of the very few that cater to students, including undergrads, with the intent of bringing them into the academia fold. Getting to know new people and talking to them was extremely interesting, especially during lockdown when connecting with others is a much more valuable commodity.” – <em><a href="https://pages.cs.wisc.edu/~shrey/" target="_blank" rel="noopener noreferrer">Shrey Shah</a>, a penultimate year undergraduate student at the University of Wisconsin-Madison. 
</em></p></blockquote>



<p class="has-text-align-left has-text-align-justify">Several participants enjoyed the workshop sessions and hoped that Let-All holds more similar themed workshops in conferences. Attendees suggested ways for attendees to interact more with each other. Some of the suggestions included the following: ‘beginner-friendly open problems sessions where attendees can collaborate’ – Esra’a Saleh, ‘an icebreaker session at the beginning that encourages attendees to mingle’ – Michael Aerni, and ‘a poster session for participants to present their work’ – Shrey Shah. </p>



<h2><strong>4 Conclusion</strong></h2>



<p class="has-text-align-left has-text-align-justify">The ALT mentorship workshop organized by the Learning Theory Alliance brought together many academics and researchers. It was, and we hope it continues to be, an opportunity for the budding researchers to learn about research and meta-research, forge collaborations, and be inspired. Kudos to the organizers and the Alliance in general for dreaming such a positive vision and then striving to make it a great success! </p>



<p class="has-text-align-left has-text-align-justify"><em>Thanks to <a href="http://www.gautamkamath.com" target="_blank" rel="noreferrer noopener">Gautam Kamath</a>, <a href="https://web.stanford.edu/~mglasgow/" target="_blank" rel="noreferrer noopener">Margalit Glasgow</a>, Surbhi Goel, Nika Haghtalab</em> <em>and Ellen Vitercik for helpful conversations and comments.</em></p></div>







<p class="date">
by Keziah <a href="https://www.let-all.com/blog/2021/05/06/alt-highlights-a-report-on-the-first-alt-mentoring-workshop/"><span class="datestr">at May 06, 2021 03:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-21129445.post-4927313116100787313">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/pizza.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mysliceofpizza.blogspot.com/2021/05/scaling-research-training.html">Scaling Research Training</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>There is a lot of need in the Industry for engineers who know the art (edited to <i>craft</i>)of research (pursue and find the right literature and algorithms, understand prior art, adopt and modify for a specific context with domain awareness, interpret results,  dive deeper into the unique insights), or researchers who can apply this art with engineering finesse. I wondered yesterday in a meeting if our technological lessons from COVID times have helped us identify a way to train many more in the ways of research, more than what we produce as PhDs in universities (the MS programs seem to train advanced engineers more than padawan researchers). <br /></p></div>







<p class="date">
by metoo (noreply@blogger.com) <a href="http://mysliceofpizza.blogspot.com/2021/05/scaling-research-training.html"><span class="datestr">at May 06, 2021 01:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6832816500979478899">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/05/negotiations.html">Negotiations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>So you got an offer to be an assistant professor in the computer science department at Prestigious U. Congratulations! </p><p>Time to negotiate your offer with the chair. Don't be nervous. This shouldn't be adversarial. Both of you have the same goal in mind--for you to come to Prestigious and be successful. </p><p>Let's discuss the different aspects of each package.</p><p><b>Research </b></p><p>Funds for supporting your research such as equipment, graduate student support, travel and postdocs. Here you should explain what you need to be successful. This will vary by subdiscipline, a systems researcher will need more equipment and students than a theorist. Keep in mind the university is giving you funds for 2-4 years to start your research, after which you are expected to fund your own research via grants.</p><p>I don't recommend taking on a postdoc right at the start of your first academic appointment. Postdocs require good mentoring while you need to spend the first year getting your research up and running. If you do ask for postdoc money, ask to have a flexible start time.</p><p>Many departments give course reductions to get your research going. I'd suggest asking to spend your first semester teaching a graduate topics course based on your thesis research to pick up some PhD students followed by a semester with no classes to get you research program going.</p><p><b>Salary</b></p><p>This includes actual salary, which is also the base for future raises, and summer salary in the first couple of years. Feel free to ask for more salary, but often these numbers are fixed for new assistant professors. There is more give if you take an academic job later in your career. You could also say something like, "Well if you can't give me more salary maybe you could give me another semester of grad student support?"</p><p><b>Partner</b></p><p>It seems 80% of the time, a job candidate has a partner that needs accommodating. Don't wait until the end of negotiations, bring it up early. The more time we have, the better we can help. Doesn't matter what job they want--we know people and we know people who know people.</p><p><b>Thesis</b></p><p>Many schools won't hire you as an assistant professor if you haven't finished your thesis. Has to do with college rankings work. Don't worry--they will generally give you some other role with the same package until you finish. This might delay your tenure clock though.</p><p><b>Delayed start time</b></p><p>A January start is usually fine with good reason but if you weren't planning to start until the fall of 2022 why are you on the market this year? If you do get the department to hold a position for you, remember you are also making a commitment--this is not an opportunity to try again for something better.</p><p><b>Overall</b></p><p>You may not get all that you want after a negotiation--don't take it personally. You shouldn't necessarily choose the place that gives you the biggest package. It's far more important in the long run that you pick a place where you can best succeed both professionally and personally, and the package is just a small piece of that puzzle.</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/05/negotiations.html"><span class="datestr">at May 06, 2021 01:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://toc4fairness.org/?p=1628">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/fair.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://toc4fairness.org/self-fulfilling-and-self-negating-predictions-a-short-tale-of-performativity-in-machine-learning/">Self-fulfilling and self-negating predictions: a short tale of performativity in machine learning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<blockquote class="wp-block-quote has-text-align-center"><p><em>This post is based on results and discussions from a series of joint works with Moritz Hardt, Celestine Mendler-Dünner, John Miller, and Juan C. Perdomo.</em></p></blockquote>



<p>In 1998, Michel Callon wrote what would be the first in an ongoing series of controversial publications in economic sociology [1]. He was the first to propose the idea that “the economy is not embedded in society but in economics”. With this, he challenged the conventional view that economic theories and models passively observe markets and infer their behavior, just like laws of physics passively describe the principles governing natural phenomena. Instead, Callon argued that economic theories are <em>performative:</em> they induce the economy, creating the phenomena they aim to describe.</p>



<p>One example that is often cited in support of Callon’s claims is the impact of the celebrated Black-Scholes-Merton options pricing model [2, 3]. MacKenzie and Millo [4] investigated the role of this model in the economy and found that it “made itself true”. In their words,</p>



<p class="has-text-align-center"><em>“Black, Scholes, and Merton’s model did not describe an already existing world: when first formulated, its assumptions were quite unrealistic, and empirical prices differed systematically from the model. Gradually, though, the financial markets changed in a way that fitted the model”.</em></p>



<p>Indeed, participants in the market started making decisions assuming the market obeys the mathematical laws implied by the Black-Scholes-Merton model. As MacKenzie and Millo put it, “pricing models came to shape the very way participants thought and talked about options”.</p>



<p>This phenomenon — whereby models and predictions inform decision-making and thus alter the target of prediction itself — is by no means special to economic forecasts.</p>



<p>Predictive policing, for example, develops algorithms that use historical data to estimate the likelihood of crime at a given location. Those locations where criminal behavior is deemed likely by the system typically get more police patrols and surveillance in general. In a kind of self-fulfilling prophecy [5], these actions resulting from prediction might further increase the <em>perceived</em> crime rate at the patrolled locations, thus biasing the data used for future decisions.</p>



<p>A similar feedback loop arises in traffic predictions, when drivers decide which route to take based on the estimated time of arrival (ETA) calculated by a traffic prediction system. If the predictive system estimates low ETA for a given route, many drivers take the route, potentially leading to an overflow of traffic and making the ETA prediction inaccurate as a result. Contrary to the previous example, traffic predictions arguably exhibit a self-negating prophecy: low ETA might imply a longer travel time, and vice versa.</p>



<p>While the previous examples deal with qualitatively different feedback mechanisms, the interplay of predictions and decision-making is similar. First, one uses historical data to build a predictive model. Then, the predictions of the model feed into and inform consequential decisions. Finally, these decisions trigger changes in the environment, making future observations differ from those in the initial dataset.</p>



<p class="has-text-align-center"><img width="624" src="https://lh3.googleusercontent.com/C3qD-SK6AD4gDpkJznllugJS8OZaJwGvXSNi96qYKPu2ALr5vSxPMhteCScLq-CCdKOvh8bZ8KB-gvTRVkbZALVEuML0WhSV0pX8YM1MHupTLPjZ8PKEydiNu_h3iUdlVAYUcFDT" height="81" /></p>



<p>We refer to prediction problems that exhibit this feedback-loop behavior as <em>performative prediction</em> problems.</p>



<p>In the language of machine learning, such a change in patterns would often be called <em>distribution shift</em>. Notably, however, performative distribution shift is not due to external factors independent of the model, such as, say, when traffic patterns change due to seasonal effects. Rather, the distribution shift is triggered directly by the choice of predictive model. (Of course, distribution shifts can also be caused by a combination of external factors and model choice.)</p>



<p>To formalize performative prediction mathematically, it is instructive to contrast performative prediction problems with supervised learning problems. In supervised learning, the decision-maker observes pairs of features and outcomes <img width="72" src="https://lh5.googleusercontent.com/2U92MhGBO6DJqe607HL2T4uWicPXKFgrU2PoSaeymNLxbOteL6r_dhkuuFo91W2AXoAzrhxt8Ndg1jfhf8KVqZMbID1koi01cpGcXz-CTACfH_b54DohHMqpO2hJ5bEtfdE6v6Ag" height="15" /> drawn from a <em>fixed</em> distribution <img width="14" src="https://lh6.googleusercontent.com/Rj1cE6eMb1304KzXnhY0e_dxrgXvPNd9q-IzgZLuKKxFYfn3q82FIiQUwb0_DO8G-xyuGdp8T5Y-EN5bKYPPxSd5QaMMO1irMwSeI6O5sy08Ubriy2cFliObESx_XOoFzPwZy6Wi" height="13" />. The key difference in performative prediction is that there is no longer an unknown static distribution generating observations; rather, data is drawn from a <em>model-dependent distribution</em> <img width="32" src="https://lh5.googleusercontent.com/F3-xnNlZ_3rgUWEAAGQu5mVaxNF0xbZ2WYw-7ngo-2XVG2D5Ru1YfSAHKXhr_IxvU0E4REBQEm7YWPjKMVo6y2-ln9CNmazsQQjq2fc7O7UlKnuVE8IvDIXHg6HS3G8ZzeMHkd3g" height="17" />, where <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="12" /> is a parameter vector specifying the deployed model. For example, <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="13" /> could be the weights of a neural network, or a vector of linear regression coefficients. For a given choice of parameters <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="13" />, <img width="32" src="https://lh5.googleusercontent.com/F3-xnNlZ_3rgUWEAAGQu5mVaxNF0xbZ2WYw-7ngo-2XVG2D5Ru1YfSAHKXhr_IxvU0E4REBQEm7YWPjKMVo6y2-ln9CNmazsQQjq2fc7O7UlKnuVE8IvDIXHg6HS3G8ZzeMHkd3g" height="17" /> should be thought of as the distribution over features and outcomes that results from making decisions according to the model specified by <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="13" />. In the context of the traffic prediction example, <img width="32" src="https://lh4.googleusercontent.com/HDm0VWvPNAUIdPfMSLc0ptEDS7Tph1p00WbC6TlSbQ8oYjK2nJSuSMiLuKN8IAA89L2H8rDLRPf9GWwc37Zb_0_qLxN-UuVVsz_hkBB43hQcTOtV4HUg30BtsHel_hpCFHfYJa6E" height="17" /> could be a distribution over traffic conditions and travel times, given that drivers make routing decisions in response to ETA forecasts by model <img width="8" src="https://lh3.googleusercontent.com/TkPLvHJ9t0soCQkx43reFppYsx4b0sJrNUBWd_Yx_rarIU4nS92GpBFBn-D_jhvDNAU04Aee4NMsVzHEozOLxXN11DMl4h1O2TvHfNih9IqHi0R3wM1otXYEp1MbkZlbI0faSV1i" height="13" />.</p>



<p>In supervised learning, the quality of a model <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="13" /> is typically measured by its <em>risk</em>, namely, the expected loss of the model on instances from distribution <img width="14" src="https://lh6.googleusercontent.com/Rj1cE6eMb1304KzXnhY0e_dxrgXvPNd9q-IzgZLuKKxFYfn3q82FIiQUwb0_DO8G-xyuGdp8T5Y-EN5bKYPPxSd5QaMMO1irMwSeI6O5sy08Ubriy2cFliObESx_XOoFzPwZy6Wi" height="13" /> as measured via a loss function <img width="9" src="https://lh5.googleusercontent.com/iLwCF0E2qkddKEmiLhziUoOB171Na3z6aLjqWSYTPykfGKIx5PBtNT9qsZXIMPLc3hVXkkupbpqILbC4Fx9p_h5G8a1GmlYVL3rcx787SVO-24HKrL39LxAwPGaQ2i8wuPURBoyS" height="16" />:</p>



<p class="has-text-align-center"><img width="153" src="https://lh5.googleusercontent.com/vP7Ll-u4VopJmW24L2lMvqwf8N9bOrKaoLFDDlmcZgmML4CM8bM53_lMEG--5Om2mTYOQ5uNqUBkzlp2Hgd9i3EO8Y8bzC8kvkFgQKSfqOgHoWiMpK2MVasGJmdFTdERwIUg0RzK" height="26" /></p>



<p>Since performative prediction does not admit one true data-generating distribution, but rather a family of distributions <img width="58" src="https://lh6.googleusercontent.com/un2s0qA36MFKtNGHoDb7sQdPfToUoZjYy45nbwmSy2jQhSDJbiouNjATQWsSwDlpUF-PfOk1ElFPDb8Rsr_TAAB0GUemVV5Y_bG1EISEUD7M9N5RGxug1gGdvpXa-D70ATQSafzT" height="18" />, evaluating a model <img width="8" src="https://lh4.googleusercontent.com/zJsapVnRoEAmwRciJFyPDFM3pc3YOuB_6gM71GJX1Aa_9Tm09RLD4mj_DOEkH0CzKHFPV93LesWVf1AUH9QlwQoU0x07xusBHiT8-EeAApf2qMsufNc8Vuzc77LWu4bxEuYwgxXp" height="13" /> calls for a new risk concept. Arguably the most natural counterpart of the risk in supervised learning is the expected loss on the distribution that arises once the model is deployed and feeds into consequential decisions. This leads to the notion of <em>performative risk</em>, defined as:</p>



<p class="has-text-align-center"><img width="181" src="https://lh5.googleusercontent.com/zWCmnf2uG6j8LZG7w68p8y4I2wHcKc82ZULfh_MUmGc3YI6UByQP8dB3nBDugFmg8t0VybMz6RV4tzviUsIyHmVY1uUH1Xjv2XKTSEQGpFW3-o0e50-rxKeouEula7UNdqC6HYHr" height="30" /></p>



<p>Adopting the performative risk as the single overarching measure of quality, a model would be optimal if it minimizes the performative risk. While an appealing solution concept, performative optimality is difficult to achieve, seeing the double dependence of the risk function on <img width="8" src="https://lh3.googleusercontent.com/ywU1sy8RfVug9ZI2C0ETvBvXg7_gqi_Xx9a1-nILxAhSafCu1OvR5095fDFr3PJN9bmBa6qoPoLzz0bFrjPtTEw5-BX3vvKHqTUyvDFaDwt7mc0B41XPpPgZZ_T4gb72PAFMDwAK" height="13" />. One of the main computational difficulties is the fact that, even if the loss <img width="9" src="https://lh5.googleusercontent.com/WZWkgjmj0CvaBREmhCbwBw1i5JfL1Tviq96JbXG1SePOG-BXJ8uv_fUUE2KKJCw2qvd5zpA_GUhHZ9azV6AUENm0qVsKnTPMg6WzLvT5QGGLNwcLyhRU0iOhYtRy6Fylx66uMGRS" height="16" /> is convex in <img width="8" src="https://lh3.googleusercontent.com/ywU1sy8RfVug9ZI2C0ETvBvXg7_gqi_Xx9a1-nILxAhSafCu1OvR5095fDFr3PJN9bmBa6qoPoLzz0bFrjPtTEw5-BX3vvKHqTUyvDFaDwt7mc0B41XPpPgZZ_T4gb72PAFMDwAK" height="13" />, <img width="43" src="https://lh4.googleusercontent.com/-syiEeOCPlb5lZOfPAK063xD0s6EraAKMtHoPUR8cIfpnP0AdkrnINBFw6Ejb8nr1jF3G7QO7v5K7o28nSnnI74SPxaJH7apiBu7Bpd7DiWnZ6Hx79Yi4v3iwJQR8j0eUJh2Qzfk" height="17" /> need not be convex. Prior work on strategic classification [6] implies a set sufficient conditions for <img width="43" src="https://lh4.googleusercontent.com/-syiEeOCPlb5lZOfPAK063xD0s6EraAKMtHoPUR8cIfpnP0AdkrnINBFw6Ejb8nr1jF3G7QO7v5K7o28nSnnI74SPxaJH7apiBu7Bpd7DiWnZ6Hx79Yi4v3iwJQR8j0eUJh2Qzfk" height="17" /> to be convex in a binary classification context, and in recent work [7] we identified a complementary set of conditions when the family of distributions <img width="58" src="https://lh4.googleusercontent.com/Ti5C4ibszTKUqTM5evbcuaHojWHAN_Rq20XcnDlunJNG1M4lBKsjB7nJOKEN4lTSdWNmgKkcxqAwPPRahQcZ4uL8kCZHn_AuaB_Z9T35eztMk2CZzMcK50GMGnH69Jdjd0euwDtI" height="18" /> forms an appropriate location-scale family. That said, in many practical settings convexity might be an unrealistic and unnecessarily strong guarantee to aim for. As we know from present-day machine learning, even non-convex problems can sometimes be amenable to simple optimization algorithms. Understanding the optimization landscape of the performative risk beyond convex settings is a fruitful direction going forward.</p>



<p>A seemingly less ambitious target is to find a model that is <em>locally</em> optimal in some appropriate sense. For example, one could optimize for models that are optimal on the distribution that they induce:</p>



<p class="has-text-align-center"><img width="233" src="https://lh6.googleusercontent.com/ENuLNHEI7mNEDONR7rUA2FzwbkvqbINkwHJfO7jiiODrZ3_Ko9NZmJAt4Qv0cPNF4-_C68yI3CE4UMcFjzP8v5UHdu_LgBkdrCnUj4A-E6uccXlclWWZef2onVzsd5X2sHq5tTlh" height="22" /></p>



<p>We call a model that satisfies the fixed-point equation above <em>performatively stable</em>. Performative stability arises naturally when the decision-maker applies the heuristic of myopically updating the model based on the distribution resulting from the previous deployment:</p>



<p class="has-text-align-center"><img width="248" src="https://lh4.googleusercontent.com/RlZ0ZmF3E0VHyj_ktWb3QtAxsXTY_WjoGS29Jss3v_5cXnDVsWbeEvaTAA4l4tUYa5ccYvJPWcPXy5oLa3BnBT0Yqws89mNind-2UT8IA2ip3_pt3PbFhiNVcgIhgMS1omjfgzI1" height="20" /></p>



<p>If this retraining strategy converges, then it necessarily converges to a performatively stable solution. This is an appealing property, since it says that stability eliminates the need for retraining. Several existing works [8, 9, 10] have identified necessary and sufficient conditions for the above retraining heuristic, and some of its efficient approximations, to converge to a stable point. Roughly speaking, retraining converges to a stable solution if the loss is well-behaved and the performative feedback effects are not too strong. If either of those two conditions is violated, there is no guarantee of convergence.</p>



<p>In the language of game theory, one can think of performative prediction as a two-player game between a decision-maker, who decides which predictive model to deploy, and the model’s environment, which generates observations according to <img width="32" src="https://lh5.googleusercontent.com/F3-xnNlZ_3rgUWEAAGQu5mVaxNF0xbZ2WYw-7ngo-2XVG2D5Ru1YfSAHKXhr_IxvU0E4REBQEm7YWPjKMVo6y2-ln9CNmazsQQjq2fc7O7UlKnuVE8IvDIXHg6HS3G8ZzeMHkd3g" height="16" />. If <img width="32" src="https://lh5.googleusercontent.com/F3-xnNlZ_3rgUWEAAGQu5mVaxNF0xbZ2WYw-7ngo-2XVG2D5Ru1YfSAHKXhr_IxvU0E4REBQEm7YWPjKMVo6y2-ln9CNmazsQQjq2fc7O7UlKnuVE8IvDIXHg6HS3G8ZzeMHkd3g" height="16" /> is thought of as the “best response” (according to some underlying utility) of the model’s environment to the deployment of model <img width="8" src="https://lh5.googleusercontent.com/04N5kfodbA5qOBQcA_TM6UP8ebiTodk6WUAUxAQ2fP2kQ1bYnrF0JGVYLtPG4-Xu_gE7s0ZvqA0URG3Q1iT4mlmvqrIJblikhbq42prczmRFp93QX_iRvD0XEfNINQSTktlPQpDZ" height="13" />, then a performatively stable solution corresponds to a <em>Nash</em> equilibrium, while a performatively optimal solution corresponds to a <em>Stackelberg</em> equilibrium with the decision-maker acting as the leader.</p>



<p>Only in special cases, such as in well-behaved zero-sum games, it is known that Nash equilibria coincide with Stackelberg equilibria. Therefore, whenever performative prediction is a well-behaved zero-sum game, all stable solutions are also performatively optimal. However, <em>performative prediction is typically not a zero-sum game</em>. For example, if the decision-maker’s loss simply measures predictive accuracy, it seems odd that the environment’s primary objective is to hurt the model’s accuracy. Indeed, a typical performative prediction problem is a general-sum game without much structure. This implies that stable solutions and performative optima can be <em>very different</em>. And, since naive retraining strategies only converge to stability, this means that such myopic updates can be an inadequate method of overcoming performative distribution shifts and achieving low performative risk. This observation further motivates understanding the optimization landscape of the performative risk, as well as developing efficient algorithms for optimizing it. Recent work has explored several algorithmic solutions [11, 7], appropriate in convex settings.</p>



<p>Performative prediction relates to many other areas beyond game theory, including bandits, reinforcement learning, control theory. These frameworks are flexible enough to capture performative prediction as a special case, however performativity arises via distinctive feedback mechanisms and as such deserves its own specialized analysis. There is a long way to go in understanding the properties of performative distribution shifts, how they connect to feedback mechanisms in other disciplines, and how to tackle these shifts in practice. Furthermore, it is unclear whether a single distribution <img width="32" src="https://lh6.googleusercontent.com/a-1tKaIQT9pJwi6WQ4eV4ZO3xcFy1e_joEh0tz1QdG-cj7x-60nDwfRyyztRSzjEaL-0xbImihmV5LDB8njPUhSlsIeyJABtowIBOktz79sRW7hAY8B75CePuDxp47xEFOZ68gSA" height="16" /> is expressive enough to describe the observations after model deployment; in practice there are different kinds of memory effects [12] and self-reinforcing loops that make the data distribution evolve with time, even when the model is kept fixed. Finally, to make the existing theoretical insights actionable, going forward we need to think about what is the right solution concept — both statistically and ethically — to optimize for in performative settings.</p>



<p><br />[1] M. Callon. Introduction: the embeddedness of economic markets in economics. <em>The Sociological Review</em>, 1998<br />[2] F. Black, M. Scholes. The pricing of options and corporate liabilities. <em>The Journal of Political Economy</em>, 1973<br />[3] R. C. Merton. Theory of rational option pricing. <em>The Bell Journal of Economics and Management Science</em>, 1973<br />[4] D. MacKenzie, Y. Millo. Constructing a market, performing theory: The historical sociology of a financial derivatives exchange. <em>American Journal of Sociology</em>, 2003<br />[5] D. Ensign, S. A. Friedler, S. Neville, C. Scheidegger, S. Venkatasubramanian. Runaway feedback loops in predictive policing. <em>ACM Conference on Fairness, Accountability and Transparency</em>, 2018<br />[6] J. Dong, A. Roth, Z. Schutzman, B. Waggoner, Z. S. Wu. Strategic classification from revealed preferences. <em>ACM Conference on Economics and Computation</em>, 2018<br />[7] J. Miller, J. C. Perdomo, T. Zrnic. Outside the echo chamber: Optimizing the performative risk. <em>arXiv preprint</em>, 2021<br />[8] J. C. Perdomo, T. Zrnic, C. Mendler-Dünner, M. Hardt. Performative prediction. <em>International Conference on Machine Learning</em>, 2020<br />[9] C. Mendler-Dünner, J. C. Perdomo, T. Zrnic, M. Hardt. Stochastic optimization for performative prediction. <em>Conference on Neural Information Processing Systems</em>, 2020<br />[10] D. Drusvyatskiy, L. Xiao. Stochastic optimization with decision-dependent distributions. <em>arXiv preprint</em>, 2020<br />[11] Z. Izzo, L. Ying, J. Zou. How to learn when data reacts to your model: Performative gradient descent. <em>arXiv preprint</em>, 2021<br />[12] G. Brown, S. Hod, I. Kalemaj. Performative prediction in a stateful world. <em>arXiv preprint</em>, 2020</p></div>







<p class="date">
by tijanazrnic <a href="https://toc4fairness.org/self-fulfilling-and-self-negating-predictions-a-short-tale-of-performativity-in-machine-learning/"><span class="datestr">at May 06, 2021 12:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.02110">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.02110">Essentiality of the Non-stoquastic Hamiltonians and Driver Graph Design in Quantum Optimization Annealing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choi:Vicky.html">Vicky Choi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.02110">PDF</a><br /><b>Abstract: </b>One of the distinct features of quantum mechanics is that the probability
amplitude can have both positive and negative signs, which has no classical
counterpart as the classical probability must be positive. Consequently, one
possible way to achieve quantum speedup is to explicitly harness this feature.
Unlike a stoquastic Hamiltonian whose ground state has only positive amplitudes
(with respect to the computational basis), a non-stoquastic Hamiltonian can be
eventually stoquastic or properly non-stoquastic when its ground state has both
positive and negative amplitudes. In this paper, we describe that, for some
hard instances which are characterized by the presence of an anti-crossing (AC)
in a stoquastic quantum annealing (QA) algorithm, how to design an appropriate
XX-driver graph (without knowing the prior problem structure) with an
appropriate XX-coupler strength such that the resulting non-stoquastic QA
algorithm is proper-non-stoquastic with two bridged anti-crossings (a
double-AC) where the spectral gap between the first and second level is large
enough such that the system can be operated diabatically in polynomial time.
The speedup is exponential in the original AC-distance, which can be
sub-exponential or exponential in the system size, over the stoquastic QA
algorithm, and possibly the same order of speedup over the state-of-the-art
classical algorithms in optimization. This work is developed based on the novel
characterizations of a modified and generalized parametrization definition of
an anti-crossing in the context of quantum optimization annealing introduced in
[4].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.02110"><span class="datestr">at May 06, 2021 11:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.02084">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.02084">Local Algorithms for Bounded Degree Sparsifiers in Sparse Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Shay.html">Shay Solomon</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.02084">PDF</a><br /><b>Abstract: </b>In graph sparsification, the goal has almost always been of {global} nature:
compress a graph into a smaller subgraph ({sparsifier}) that maintains certain
features of the original graph. Algorithms can then run on the sparsifier,
which in many cases leads to improvements in the overall runtime and memory.
This paper studies sparsifiers that have bounded (maximum) degree, and are thus
{locally} sparse, aiming to improve local measures of runtime and memory. To
improve those local measures, it is important to be able to compute such
sparsifiers {locally}.
</p>
<p>We initiate the study of local algorithms for bounded degree sparsifiers in
unweighted sparse graphs, focusing on the problems of vertex cover, matching,
and independent set. Let $\epsilon &gt; 0$ be a slack parameter and $\alpha \ge 1$
be a density parameter. We devise local algorithms for computing: (1) A
$(1+\epsilon)$-vertex cover sparsifier of degree $O(\alpha / \epsilon)$, for
any graph of {arboricity} $\alpha$. (2) A $(1+\epsilon)$-maximum matching
sparsifier and also a $(1+\epsilon)$-maximal matching sparsifier of degree
$O(\alpha / \epsilon)$, for any graph of arboricity $\alpha$. (3) A
$(1+\epsilon)$-independent set sparsifier of degree $O(\alpha^2 / \epsilon)$,
for any graph of average degree $\alpha$.
</p>
<p>Our algorithms require only a single communication round in the standard
message passing models of distributed computing, and moreover, they can be
simulated locally in a trivial way. As an immediate application we can extend
results from distributed computing and local computation algorithms that apply
to graphs of degree bounded by $d$ to graphs of arboricity $O(d / \epsilon)$ or
average degree $O(d^2 / \epsilon)$, at the expense of increasing the
approximation guarantee by a factor of $(1+\epsilon)$. In particular, we can
extend the plethora of recent local computation algorithms [...]
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.02084"><span class="datestr">at May 06, 2021 10:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.02052">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.02052">Scheduling with Testing on Multiple Identical Parallel Machines</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckl:Alexander.html">Alexander Eckl</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.02052">PDF</a><br /><b>Abstract: </b>Scheduling with testing is a recent online problem within the framework of
explorable uncertainty motivated by environments where some preliminary action
can influence the duration of a task. Jobs have an unknown processing time that
can be explored by running a test. Alternatively, jobs can be executed for the
duration of a given upper limit. We consider this problem within the setting of
multiple identical parallel machines and present competitive deterministic
algorithms and lower bounds for the objective of minimizing the makespan of the
schedule. In the non-preemptive setting, we present the SBS algorithm whose
competitive ratio approaches $3.1016$ if the number of machines becomes large.
We compare this result with a simple greedy strategy and a lower bound which
approaches $2$. In the case of uniform testing times, we can improve the SBS
algorithm to be $3$-competitive. For the preemptive case we provide a
$2$-competitive algorithm and a tight lower bound which approaches the same
value.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.02052"><span class="datestr">at May 06, 2021 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.02022">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.02022">Deep Multilevel Graph Partitioning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gottesb=uuml=ren:Lars.html">Lars Gottesbüren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heuer:Tobias.html">Tobias Heuer</a>, Peter Sanders, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seemaier:Daniel.html">Daniel Seemaier</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.02022">PDF</a><br /><b>Abstract: </b>Partitioning a graph into blocks of "roughly equal" weight while cutting only
few edges is a fundamental problem in computer science with a wide range of
applications. In particular, the problem is a building block in applications
that require parallel processing. While the amount of available cores in
parallel architectures has significantly increased in recent years,
state-of-the-art graph partitioning algorithms do not work well if the input
needs to be partitioned into a large number of blocks. Often currently
available algorithms compute highly imbalanced solutions, solutions of low
quality, or have excessive running time for this case. This is because most
high-quality general-purpose graph partitioners are multilevel algorithms which
perform graph coarsening to build a hierarchy of graphs, initial partitioning
to compute an initial solution, and local improvement to improve the solution
throughout the hierarchy. However, for large number of blocks, the smallest
graph in the hierarchy that is used for initial partitioning still has to be
large.
</p>
<p>In this work, we substantially mitigate these problems by introducing deep
multilevel graph partitioning and a shared-memory implementation thereof. Our
scheme continues the multilevel approach deep into initial partitioning --
integrating it into a framework where recursive bipartitioning and direct k-way
partitioning are combined such that they can operate with high performance and
quality. Our approach is stronger, more flexible, arguably more elegant, and
reduces bottlenecks for parallelization compared to other multilevel
approaches. For example, for large number of blocks our algorithm is on average
an order of magnitude faster than competing algorithms while computing balanced
partitions with comparable solution quality. For small number of blocks, our
algorithms are the fastest among competing systems with comparable quality.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.02022"><span class="datestr">at May 06, 2021 11:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01963">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01963">One-way communication complexity and non-adaptive decision trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mande:Nikhil_S=.html">Nikhil S. Mande</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sanyal:Swagato.html">Swagato Sanyal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01963">PDF</a><br /><b>Abstract: </b>We study the relationship between various one-way communication complexity
measures of a composed function with the analogous decision tree complexity of
the outer function. We consider two gadgets: the AND function on 2 inputs, and
the Inner Product on a constant number of inputs. Let $IP$ denote Inner Product
on $2b$ bits.
</p>
<p>1) If $f$ is a total Boolean function that depends on all of its inputs, the
bounded-error one-way quantum communication complexity of $f \circ IP$ equals
$\Omega(n(b-1))$.
</p>
<p>2) If $f$ is a partial Boolean function, the deterministic one-way
communication complexity of $f \circ IP$ is at least $\Omega(b \cdot
D_{dt}^{\rightarrow}(f))$, where $D_{dt}^{\rightarrow}(f)$ denotes the
non-adaptive decision tree complexity of $f$.
</p>
<p>For our quantum lower bound, we show a lower bound on the VC-dimension of $f
\circ IP$, and then appeal to a result of Klauck [STOC'00]. Our deterministic
lower bound relies on a combinatorial result due to Frankl and Tokushige
[Comb.'99].
</p>
<p>It is known due to a result of Montanaro and Osborne [arXiv'09] that the
deterministic one-way communication complexity of $f \circ XOR_2$ equals the
non-adaptive parity decision tree complexity of $f$. In contrast, we show the
following with the gadget $AND_2$.
</p>
<p>1) There exists a function for which even the randomized non-adaptive AND
decision tree complexity of $f$ is exponentially large in the deterministic
one-way communication complexity of $f \circ AND_2$.
</p>
<p>2) For symmetric functions $f$, the non-adaptive AND decision tree complexity
of $f$ is at most quadratic in the (even two-way) communication complexity of
$f \circ AND_2$.
</p>
<p>In view of the first bullet, a lower bound on non-adaptive AND decision tree
complexity of $f$ does not lift to a lower bound on one-way communication
complexity of $f \circ AND_2$. The proof of the first bullet above uses the
well-studied Odd-Max-Bit function.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01963"><span class="datestr">at May 06, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01961">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01961">Stitch Fix for Mapper and Information Gains</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Youjia.html">Youjia Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saul:Nathaniel.html">Nathaniel Saul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Safarli:Ilkin.html">Ilkin Safarli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnamoorthy:Bala.html">Bala Krishnamoorthy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Bei.html">Bei Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01961">PDF</a><br /><b>Abstract: </b>The mapper construction is a powerful tool from topological data analysis
that is designed for the analysis and visualization of multivariate data. In
this paper, we investigate a method for stitching a pair of univariate mappers
together into a bivariate mapper and study topological notions of information
gains during such a process. We further provide implementations that visualize
such information gains.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01961"><span class="datestr">at May 06, 2021 11:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01864">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01864">Tree Path Minimum Query Oracle via Boruvka Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Tianqi.html">Tianqi Yang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01864">PDF</a><br /><b>Abstract: </b>Tree path minimum query problem is a fundamental problem while processing
trees, and is used widely in minimum spanning tree verification and randomized
minimum spanning tree algorithms. In this paper, we study the possibility of
building an oracle in advance, which is able to answer the queries efficiently.
We present an algorithm based on Boruvka trees. Our algorithm is the first to
achieve a near-optimal bound on query time, while matching the currently
optimal trade-off between construction time and the number of comparisons
required at query. Particularly, in order to answer each query within $2k$
comparisons, our algorithm requires $O(n \log \lambda_k(n))$ time and space to
construct the oracle, and the oracle can answer queries in $O(k + \log
\lambda_k(n))$ time. Here $\lambda_k(n)$ is the inverse of the Ackermann
function along the $k$-th column. This algorithm not only is simpler than the
previous ones, but also gives a completely different method of solving this
problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01864"><span class="datestr">at May 06, 2021 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01856">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01856">Identity testing under label mismatch</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wimmer:Karl.html">Karl Wimmer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01856">PDF</a><br /><b>Abstract: </b>Testing whether the observed data conforms to a purported model (probability
distribution) is a basic and fundamental statistical task, and one that is by
now well understood. However, the standard formulation, identity testing, fails
to capture many settings of interest; in this work, we focus on one such
natural setting, identity testing under promise of permutation. In this
setting, the unknown distribution is assumed to be equal to the purported one,
up to a relabeling (permutation) of the model: however, due to a systematic
error in the reporting of the data, this relabeling may not be the identity.
The goal is then to test identity under this assumption: equivalently, whether
this systematic labeling error led to a data distribution statistically far
from the reference model.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01856"><span class="datestr">at May 06, 2021 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01833">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01833">The Complexity of Symmetry Breaking in Massive Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konrad:Christian.html">Christian Konrad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pemmaraju:Sriram_V=.html">Sriram V. Pemmaraju</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Riaz:Talal.html">Talal Riaz</a>, Peter Robinson <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01833">PDF</a><br /><b>Abstract: </b>The goal of this paper is to understand the complexity of symmetry breaking
problems, specifically maximal independent set (MIS) and the closely related
$\beta$-ruling set problem, in two computational models suited for large-scale
graph processing, namely the $k$-machine model and the graph streaming model.
We present a number of results. For MIS in the $k$-machine model, we improve
the $\tilde{O}(m/k^2 + \Delta/k)$-round upper bound of Klauck et al. (SODA
2015) by presenting an $\tilde{O}(m/k^2)$-round algorithm. We also present an
$\tilde{\Omega}(n/k^2)$ round lower bound for MIS, the first lower bound for a
symmetry breaking problem in the $k$-machine model. For $\beta$-ruling sets, we
use hierarchical sampling to obtain more efficient algorithms in the
$k$-machine model and also in the graph streaming model. More specifically, we
obtain a $k$-machine algorithm that runs in $\tilde{O}(\beta
n\Delta^{1/\beta}/k^2)$ rounds and, by using a similar hierarchical sampling
technique, we obtain one-pass algorithms for both insertion-only and
insertion-deletion streams that use $O(\beta \cdot n^{1+1/2^{\beta-1}})$ space.
The latter result establishes a clear separation between MIS, which is known to
require $\Omega(n^2)$ space (Cormode et al., ICALP 2019), and $\beta$-ruling
sets, even for $\beta = 2$. Finally, we present an even faster 2-ruling set
algorithm in the $k$-machine model, one that runs in
$\tilde{O}(n/k^{2-\epsilon} + k^{1-\epsilon})$ rounds for any $\epsilon$, $0
\le \epsilon \le 1$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01833"><span class="datestr">at May 06, 2021 11:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01818">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01818">Dynamic Enumeration of Similarity Joins</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Xiao.html">Xiao Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sintos:Stavros.html">Stavros Sintos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Jun.html">Jun Yang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01818">PDF</a><br /><b>Abstract: </b>This paper considers enumerating answers to similarity-join queries under
dynamic updates: Given two sets of $n$ points $A,B$ in $\mathbb{R}^d$, a metric
$\phi(\cdot)$, and a distance threshold $r &gt; 0$, report all pairs of points
$(a, b) \in A \times B$ with $\phi(a,b) \le r$. Our goal is to store $A,B$ into
a dynamic data structure that, whenever asked, can enumerate all result pairs
with worst-case delay guarantee, i.e., the time between enumerating two
consecutive pairs is bounded. Furthermore, the data structure can be
efficiently updated when a point is inserted into or deleted from $A$ or $B$.
</p>
<p>We propose several efficient data structures for answering similarity-join
queries in low dimension. For exact enumeration of similarity join, we present
near-linear-size data structures for $\ell_1, \ell_\infty$ metrics with
$\log^{O(1)} n$ update time and delay. We show that such a data structure is
not feasible for the $\ell_2$ metric for $d \ge 4$. For approximate enumeration
of similarity join, where the distance threshold is a soft constraint, we
obtain a unified linear-size data structure for $\ell_p$ metric, with
$\log^{O(1)} n$ delay and update time. In high dimensions, we present an
efficient data structure with worst-case delay-guarantee using locality
sensitive hashing (LSH).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01818"><span class="datestr">at May 06, 2021 10:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01785">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01785">An Optimal Algorithm for Triangle Counting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kallaugher:John.html">John Kallaugher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01785">PDF</a><br /><b>Abstract: </b>We present a new algorithm for approximating the number of triangles in a
graph $G$ whose edges arrive as an arbitrary order stream. If $m$ is the number
of edges in $G$, $T$ the number of triangles, $\Delta_E$ the maximum number of
triangles which share a single edge, and $\Delta_V$ the maximum number of
triangles which share a single vertex, then our algorithm requires space: \[
\widetilde{O}\left(\frac{m}{T}\cdot \left(\Delta_E +
\sqrt{\Delta_V}\right)\right) \] Taken with the $\Omega\left(\frac{m
\Delta_E}{T}\right)$ lower bound of Braverman, Ostrovsky, and Vilenchik (ICALP
2013), and the $\Omega\left( \frac{m \sqrt{\Delta_V}}{T}\right)$ lower bound of
Kallaugher and Price (SODA 2017), our algorithm is optimal up to log factors,
resolving the complexity of a classic problem in graph streaming.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01785"><span class="datestr">at May 06, 2021 11:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01784">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01784">Sampling Colorings and Independent Sets of Random Regular Bipartite Graphs in the Non-Uniqueness Region</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, Daniel Štefankovič, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01784">PDF</a><br /><b>Abstract: </b>For spin systems, such as the $q$-colorings and independent-set models,
approximating the partition function in the so-called non-uniqueness region,
where the model exhibits long-range correlations, is typically computationally
hard for bounded-degree graphs. We present new algorithmic results for
approximating the partition function and sampling from the Gibbs distribution
for spin systems in the non-uniqueness region on random regular bipartite
graphs. We give an $\mathsf{FPRAS}$ for counting $q$-colorings for even
$q=O\big(\tfrac{\Delta}{\log{\Delta}}\big)$ on almost every $\Delta$-regular
bipartite graph. This is within a factor $O(\log{\Delta})$ of the sampling
algorithm for general graphs in the uniqueness region and improves
significantly upon the previous best bound of
$q=O\big(\tfrac{\sqrt{\Delta}}{(\log\Delta)^2}\big)$ by Jenssen, Keevash, and
Perkins (SODA'19). Analogously, for the hard-core model on independent sets
weighted by $\lambda&gt;0$, we present an $\mathsf{FPRAS}$ for estimating the
partition function when $\lambda=\Omega\big(\tfrac{\log{\Delta}}{\Delta}\big)$,
which improves upon previous results by an $\Omega(\log \Delta)$ factor. Our
results for the colorings and hard-core models follow from a general result
that applies to arbitrary spin systems. Our main contribution is to show how to
elevate probabilistic/analytic bounds on the marginal probabilities for the
typical structure of phases on random bipartite regular graphs into efficient
algorithms, using the polymer method. We further show evidence that our result
for colorings is within a constant factor of best possible using current
polymer-method approaches.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01784"><span class="datestr">at May 06, 2021 11:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01782">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01782">Streaming approximation resistance of every ordering CSP</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singer:Noah.html">Noah Singer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sudan:Madhu.html">Madhu Sudan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velusamy:Santhoshini.html">Santhoshini Velusamy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01782">PDF</a><br /><b>Abstract: </b>An ordering constraint satisfaction problem (OCSP) is given by a positive
integer $k$ and a constraint predicate $\Pi$ mapping permutations on
$\{1,\ldots,k\}$ to $\{0,1\}$. Given an instance of OCSP$(\Pi)$ on $n$
variables and $m$ constraints, the goal is to find an ordering of the $n$
variables that maximizes the number of constraints that are satisfied, where a
constraint specifies a sequence of $k$ distinct variables and the constraint is
satisfied by an ordering on the $n$ variables if the ordering induced on the
$k$ variables in the constraint satisfies $\Pi$. Natural ordering constraint
satisfaction problems include "Maximum acyclic subgraph (MAS)" and
"Betweenness". In this work we consider the task of approximating the maximum
number of satisfiable constraints in the (single-pass) streaming setting, where
an instance is presented as a stream of constraints.
</p>
<p>We show that for every $\Pi$, algorithms using $o(\sqrt{n})$ space cannot
distinguish streams where almost every constraint is satisfiable from streams
where no ordering beats the random ordering by a noticeable amount. In the case
of MAS our result shows that for every $\epsilon&gt;0$, MAS is not
$1/2+\epsilon$-approximable. The previous best inapproximability result only
ruled out a $3/4$ approximation.
</p>
<p>Our results build on a recent work of Chou, Golovnev, Sudan, and Velusamy who
show tight inapproximability results for some constraint satisfaction problems
over arbitrary (finite) alphabets. We show that the hard instances from this
earlier work have the property that in every partition of the hypergraph formed
by the constraints into small blocks, most of the hyperedges are incident on
vertices from distinct blocks. By exploiting this combinatorial property, in
combination with a natural reduction from CSPs over large finite alphabets to
OCSPs, we give optimal inapproximability results for all OCSPs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01782"><span class="datestr">at May 06, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01780">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01780">Approximation schemes for bounded distance problems on fractionally treewidth-fragile graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Zdeněk Dvořák, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lahiri:Abhiruk.html">Abhiruk Lahiri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01780">PDF</a><br /><b>Abstract: </b>We give polynomial-time approximation schemes for monotone maximization
problems expressible in terms of distances (up to a fixed upper bound) and
efficiently solvable in graphs of bounded treewidth. These schemes apply in all
fractionally treewidth-fragile graph classes, a property that is true for many
natural graph classes with sublinear separators. We also provide
quasipolynomial-time approximation schemes for these problems in all classes
with sublinear separators.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01780"><span class="datestr">at May 06, 2021 11:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01778">Thinking Inside the Ball: Near-Optimal Minimization of the Maximal Loss</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmon:Yair.html">Yair Carmon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jambulapati:Arun.html">Arun Jambulapati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01778">PDF</a><br /><b>Abstract: </b>We characterize the complexity of minimizing $\max_{i\in[N]} f_i(x)$ for
convex, Lipschitz functions $f_1,\ldots, f_N$. For non-smooth functions,
existing methods require $O(N\epsilon^{-2})$ queries to a first-order oracle to
compute an $\epsilon$-suboptimal point and $\tilde{O}(N\epsilon^{-1})$ queries
if the $f_i$ are $O(1/\epsilon)$-smooth. We develop methods with improved
complexity bounds of $\tilde{O}(N\epsilon^{-2/3} + \epsilon^{-8/3})$ in the
non-smooth case and $\tilde{O}(N\epsilon^{-2/3} + \sqrt{N}\epsilon^{-1})$ in
the $O(1/\epsilon)$-smooth case. Our methods consist of a recently proposed
ball optimization oracle acceleration algorithm (which we refine) and a careful
implementation of said oracle for the softmax function. We also prove an oracle
complexity lower bound scaling as $\Omega(N\epsilon^{-2/3})$, showing that our
dependence on $N$ is optimal up to polylogarithmic factors.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01778"><span class="datestr">at May 06, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01751">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01751">Reconstruction Algorithms for Low-Rank Tensors and Depth-3 Multilinear Circuits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhargava:Vishwas.html">Vishwas Bhargava</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saraf:Shubhangi.html">Shubhangi Saraf</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Volkovich:Ilya.html">Ilya Volkovich</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01751">PDF</a><br /><b>Abstract: </b>We give new and efficient black-box reconstruction algorithms for some
classes of depth-$3$ arithmetic circuits. As a consequence, we obtain the first
efficient algorithm for computing the tensor rank and for finding the optimal
tensor decomposition as a sum of rank-one tensors when then input is a
constant-rank tensor. More specifically, we provide efficient learning
algorithms that run in randomized polynomial time over general fields and in
deterministic polynomial time over the reals and the complex numbers for the
following classes:
</p>
<p>(1) Set-multilinear depth-$3$ circuits of constant top fan-in
$\Sigma\Pi\Sigma\{\sqcup_j X_j\}(k)$ circuits). As a consequence of our
algorithm, we obtain the first polynomial time algorithm for tensor rank
computation and optimal tensor decomposition of constant-rank tensors. This
result holds for $d$ dimensional tensors for any $d$, but is interesting even
for $d=3$.
</p>
<p>(2) Sums of powers of constantly many linear forms ($\Sigma\wedge\Sigma$
circuits). As a consequence we obtain the first polynomial-time algorithm for
tensor rank computation and optimal tensor decomposition of constant-rank
symmetric tensors.
</p>
<p>(3) Multilinear depth-3 circuits of constant top fan-in (multilinear
$\Sigma\Pi\Sigma(k)$ circuits). Our algorithm works over all fields of
characteristic 0 or large enough characteristic. Prior to our work the only
efficient algorithms known were over polynomially-sized finite fields (see.
Karnin-Shpilka 09').
</p>
<p>Prior to our work, the only polynomial-time or even subexponential-time
algorithms known (deterministic or randomized) for subclasses of
$\Sigma\Pi\Sigma(k)$ circuits that also work over large/infinite fields were
for the setting when the top fan-in $k$ is at most $2$ (see Sinha 16' and Sinha
20').
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01751"><span class="datestr">at May 06, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01738">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01738">Priority Promotion with Parysian Flair</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Benerecetti:Massimo.html">Massimo Benerecetti</a>, Daniele Dell'Erba, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mogavero:Fabio.html">Fabio Mogavero</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schewe:Sven.html">Sven Schewe</a>, Dominik Wojtczak Università di Napoli Federico II, University of Liverpool) <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01738">PDF</a><br /><b>Abstract: </b>We develop an algorithm that combines the advantages of priority promotion -
the leading approach to solving large parity games in practice - with the
quasi-polynomial time guarantees offered by Parys' algorithm. Hybridising these
algorithms sounds both natural and difficult, as they both generalise the
classic recursive algorithm in different ways that appear to be irreconcilable:
while the promotion transcends the call structure, the guarantees change on
each level. We show that an interface that respects both is not only effective,
but also efficient.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01738"><span class="datestr">at May 06, 2021 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2105.01699">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2105.01699">Determining 4-edge-connected components in linear time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nadara:Wojciech.html">Wojciech Nadara</a>, Mateusz Radecki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smulewicz:Marcin.html">Marcin Smulewicz</a>, Marek Sokołowski <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2105.01699">PDF</a><br /><b>Abstract: </b>In this work, we present the first linear time deterministic algorithm
computing the 4-edge-connected components of an undirected graph. First, we
show an algorithm listing all 3-edge-cuts in a given 3-edge-connected graph,
and then we use the output of this algorithm in order to determine the
4-edge-connected components of the graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2105.01699"><span class="datestr">at May 06, 2021 10:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/066">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/066">TR21-066 |  Dimension-free Bounds and Structural Results in Communication Complexity | 

	Lianna Hambardzumyan, 

	Hamed Hatami, 

	Pooya Hatami</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The purpose of this article is to initiate a systematic study of dimension-free relations between basic communication and query complexity measures  and various  matrix norms.  In other words, our goal is to obtain    inequalities that bound a parameter   solely as a function of another parameter. This is in contrast to perhaps the more common framework in communication complexity  where  poly-logarithmic dependencies on the number of input bits are   tolerated. 


Dimension-free bounds are also closely related to structural results, where one seeks to describe the structure of Boolean matrices and functions that have low complexity.  We prove such  theorems for several communication and query complexity measures as well as various matrix and operator norms. In several other cases we show that such bounds do not exist. 


We propose several conjectures, and establish that, in addition to applications in complexity theory, these   problems are central to  characterization of the idempotents of the algebra of Schur multipliers, and could lead to new extensions of  Cohen's celebrated idempotent theorem regarding the Fourier algebra.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/066"><span class="datestr">at May 05, 2021 06:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/tpdp21-cfp/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/tpdp21-cfp/">Call for Papers - Workshop on the Theory and Practice of Differential Privacy (TPDP 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Work on differential privacy spans a number of different research communities, including theoretical computer science, machine learning, statistics, security, law, databases, cryptography, programming languages, social sciences, and more.
Each of these communities may choose to publish their work in their own community’s venues, which could result in small groups of differential privacy researchers becoming isolated.
To alleviate these issues, we have the Workshop on the <a href="https://tpdp.journalprivacyconfidentiality.org/">Theory and Practice of Differential Privacy</a> (TPDP), which is intended to bring these subcommunities together under one roof (well, a virtual one at least for 2020 and 2021).</p>

<p>We have just posted the <a href="https://tpdp.journalprivacyconfidentiality.org/2021/TPDP2021CfP.pdf">Call for Papers</a> for <a href="https://tpdp.journalprivacyconfidentiality.org/2021/">TPDP 2021</a>, which will be a workshop affiliated with <a href="https://icml.cc/Conferences/2021/">ICML 2021</a>.
The submission deadline is Friday, May 28, 2021, Anywhere on Earth (conveniently, two days after the deadline for NeurIPS 2021).
Submissions are extended abstracts of up to four pages in length, and will undergo a lightweight review process, based mostly on relevance and interest to the differential privacy community.
The workshop is non-archival, so feel free to submit recent work at any stage of publication.
Submissions will be on <a href="https://openreview.net/group?id=ICML.cc/2021/Workshop/TPDP">OpenReview</a>, but since submitted work may be preliminary, the process will be “closed” similar to traditional review processes.
One goal of the workshop is to be inclusive and welcoming to newcomers to the differential privacy community, so please consider participating even if you are new to the field.</p>

<p>Most papers will be presented as posters at a (virtual) poster session, while a few papers will be selected for spotlight talks.
There will also be plenary talks by <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a> (Hebrew University of Jerusalem) and <a href="https://www2.math.upenn.edu/~ryrogers/">Ryan Rogers</a> (LinkedIn).
The program co-chairs are <a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a> and <a href="http://www.gautamkamath.com/">myself</a>.
Please submit your best work on differential privacy, and hope to see you there!</p>
<p align="center">
  <img src="https://differentialprivacy.org/images/Ligett.png" />
  <img src="https://differentialprivacy.org/images/Rogers.png" /> <br />
    <i>Invited speakers Katrina Ligett and Ryan Rogers</i>
</p></div>







<p class="date">
by Gautam Kamath <a href="https://differentialprivacy.org/tpdp21-cfp/"><span class="datestr">at May 05, 2021 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18701">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/05/05/how-to-teach-math/">How to Teach Math?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>The only way to learn mathematics is to do mathematics—Paul Halmos</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/05/how-to-teach-math/an/" rel="attachment wp-att-18704"><img width="150" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/an-150x150.jpg?resize=150%2C150&amp;ssl=1" class="alignright size-thumbnail wp-image-18704" height="150" /></a></p>
<p>
Angie Hodge is an Associate Professor of mathematics at Northern Arizona University. Her interests as stated on her <a href="https://directory.nau.edu/person/amh952">website</a> are focused mainly on education, mentoring, and equity in the STEM disciplines. </p>
<p>
Today I thought we would discuss the issue of teaching and learning math and complexity theory.</p>
<p>
I am now retired from Georgia Tech. But I continue to be interested in how we can teach math. Dually how we can learn math. I still try to learn math—not for formal classes, nor in formal classes—but to help advance my own research. Even now I find that I need to learn some topics to help write a post or to solve a problem. </p>
<p>
On this blog with Ken I am also interested in still helping others learn. Some call that teaching. This is therefore the topic for today.</p>
<p>
</p><p></p><h2> First An Issue </h2><p></p>
<p></p><p>
One thing that drives me nuts about learning new math is what I will call the </p>
<blockquote><p><b> </b> <em> <i>“It is too obvious to state” principle.</i> </em>
</p></blockquote>
<p>What I mean is that when you start to learn material from some corner of math you get the key definitions and the main results. What I do not always get is some totally obvious ideas. Does this make any sense?</p>
<p>
Here is an example. Consider the class of sequences that are defined by linear <a href="https://en.wikipedia.org/wiki/Recurrence_relation">recurrences</a>. That is: a recursion that defines a sequence as a linear combination of earlier terms. One of the most famous is the Fibonacci numbers: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F_n+%3D+F_%7Bn-1%7D+%2B+F_%7Bn-2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  F_n = F_{n-1} + F_{n-2}. " class="latex" /></p>
<p>And <img src="https://s0.wp.com/latex.php?latex=%7BF_0%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{F_0=0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF_1%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{F_1=1}" class="latex" />.</p>
<p>
The property we are interested in is: </p>
<blockquote><p><b> </b> <em> <i>Is a product of two such sequences also of the same form?</i> </em>
</p></blockquote>
<p>This is a basic question, but it is not trivial to find the <a href="https://reader.elsevier.com/reader/sd/pii/0012365X79901869?token=C0E36B1EE6735F9AB6140E86924EB1A19F236C9507028E02CB912D21952F2438487C78DDBB68CC1541D2E9CF5754B8C1&amp;originRegion=us-east-1&amp;originCreation=20210415000540">answer</a>. </p>
<p>
</p><p></p><h2> How To Teach? </h2><p></p>
<p></p><p>
This is an ancient question that we all probably have thought about from time to time. It is complicated by the recent issue of most classes being done via online. Hodge has some nice stuff on teaching, especially on Inquiry-Based Learning (IBL). </p>
<ul>
<li>
See her <a href="https://www.artofmathematics.org/blogs/cvonrenesse/guest-blog-by-angie-hodge">blog</a>. <p></p>
</li><li>
See <a href="http://math.uchicago.edu/~boller/IBL/">this</a> for her comments on <em>Inquiry-Based Learning</em>. <p></p>
</li><li>
See her thoughts on <a href="https://www.maa.org/sites/default/files/Programs/MathFest2018_IPS_Hodge2.pdf">IBL</a>.
</li></ul>
<p>
</p><p></p><h2> Ken’s Similar Question </h2><p></p>
<p></p><p>
Ken writes: I am interested in manipulating logistic curves. Such curves not only undergird the chess rating system and the theory of standardized tests, they relate directly to the design of chess programs which I use to take my data. This decade’s neural chess-playing programs, following on from AlphaZero, express values directly in terms of the likelihood of winning, as numbers between 0 and 1, rather than traditional evaluation schemes built on counting 1.00 for a pawn, 3–3.5 for a knight or bishop, and so on. </p>
<p>
The new likelihood numbers follow a logistic curve. I especially want to convert from the evaluation numbers to them. After doing this conversion for various major chess programs, I would like to average their values as input to my predictive model. This involves taking averages of logistic curves. The curves can be generalized to the <a href="https://en.wikipedia.org/wiki/Generalised_logistic_function">form</a> named for Francis Richards: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+A+%2B+%5Cfrac%7BK-A%7D%7B%28C+%2B+Qe%5E%7B-Bx%7D%29%5E%7B1%2F%5Cnu%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  f(x) = A + \frac{K-A}{(C + Qe^{-Bx})^{1/\nu}} " class="latex" /></p>
<p>for constant parameters <img src="https://s0.wp.com/latex.php?latex=%7BA%2CK%2CB%2CC%2CQ%2C%5Cnu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A,K,B,C,Q,\nu}" class="latex" />. The standard family has <img src="https://s0.wp.com/latex.php?latex=%7BA%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A=0}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7BK%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K=1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7BC%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{C=1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cnu%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\nu=1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7BQ%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Q=1}" class="latex" />, with <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> the central parameter determining the slope of the curve <img src="https://s0.wp.com/latex.php?latex=%7Bf%28t%29+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-Bx%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f(t) = \frac{1}{1+e^{-Bx}}}" class="latex" /> at <img src="https://s0.wp.com/latex.php?latex=%7Bx%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x=0}" class="latex" />. We can ask the basic question about intermediate families between the standard family and the most general kind:</p>
<blockquote><p><b> </b> <em> When does a linear combination of logistic curves belong to the same family? And if it doesn’t belong, how close to a member of the family does it come? </em>
</p></blockquote>
<p></p><p>
My point is that I have not been able to find an easy source for answers. This strikes me as exactly the kind of question for which sites like MathOverflow and StackExchange exist. But it is also a nice instructional exercise for training students in both the grit and adventure of mathematical research. </p>
<p>
One can also pose literally the same as Dick’s question above: how about a product of two curves <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%28x%29%2Cf_2%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f_1(x),f_2(x)}" class="latex" /> from the family? The product still has values that run from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" /> goes from <img src="https://s0.wp.com/latex.php?latex=%7B-%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{-\infty}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%2B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{+\infty}" class="latex" />. If we want the curves all to have value <img src="https://s0.wp.com/latex.php?latex=%7Bf%280%29+%3D+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f(0) = 0.5}" class="latex" /> then we can compose the product with a square root, viz. <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+%5Csqrt%7Bf_1%28x%29+f_2%28x%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f(x) = \sqrt{f_1(x) f_2(x)}}" class="latex" />, thus taking a geometric rather than arithmetic mean. I mentioned other nuts-and-bolts problems about logistic curves in this <a href="https://rjlipton.wpcomstaging.com/2018/08/25/do-you-want-to-know-a-secret/">post</a> and its longer <a href="https://rjlipton.wpcomstaging.com/2018/09/07/sliding-scale-problems/">followup</a>.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
The following video shows how not to teach math: <a href="https://www.youtube.com/watch?v=vU5LoCLGMdQ&amp;t=109s">The Kettles</a> do math.</p>
<p></p><p><br />
[some format and word tweaks]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2021/05/05/how-to-teach-math/"><span class="datestr">at May 05, 2021 01:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/065">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/065">TR21-065 |  One-way communication complexity and non-adaptive decision trees | 

	Nikhil Mande, 

	Swagato Sanyal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the relationship between various one-way communication complexity measures of a composed function with the analogous decision tree complexity of the outer function. We consider two gadgets: the AND function on 2 inputs, and the Inner Product on a constant number of inputs. Let $IP$ denote Inner Product on $2b$ bits.

1) If $f$ is a total Boolean function that depends on all of its inputs, the bounded-error one-way quantum communication complexity of $f \circ IP$ equals $\Omega(n(b-1))$.

2) If $f$ is a partial Boolean function, the deterministic one-way communication complexity of $f \circ IP$ is at least $\Omega(b \cdot D_{dt}^{\rightarrow}(f))$, where $D_{dt}^{\rightarrow}(f)$ denotes the non-adaptive decision tree complexity of $f$.

For our quantum lower bound, we show a lower bound on the VC-dimension of $f \circ IP$, and then appeal to a result of Klauck [STOC'00].
Our deterministic lower bound relies on a combinatorial result due to Frankl and Tokushige [Comb.'99].

It is known due to a result of Montanaro and Osborne [arXiv'09] that the deterministic one-way communication complexity of $f \circ XOR_2$ equals the non-adaptive parity decision tree complexity of $f$.
In contrast, we show the following with the gadget $AND_2$.

1) There exists a function for which even the randomized non-adaptive AND decision tree complexity of $f$ is exponentially large in the deterministic one-way communication complexity of $f \circ AND_2$.

2) For symmetric functions $f$, the non-adaptive AND decision tree complexity of $f$ is at most quadratic in the (even two-way) communication complexity of $f \circ AND_2$.

In view of the first point, a lower bound on non-adaptive AND decision tree complexity of $f$ does not lift to a lower bound on one-way communication complexity of $f \circ AND_2$.
The proof of the first point above uses the well-studied Odd-Max-Bit function.
For the second bullet, we first observe a connection between the one-way communication complexity of $f$ and the M\"obius sparsity of $f$, and then use a known lower bound on the M\"obius sparsity of symmetric functions. An upper bound on the non-adaptive AND decision tree complexity of symmetric functions follows implicitly from prior work on combinatorial group testing; for the sake of completeness, we include a proof of this result.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/065"><span class="datestr">at May 05, 2021 01:16 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3524">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2021/05/05/netecon-2021/">NetEcon 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>NetEcon’21,</strong> the 16th Workshop on the Economics of Networks, Systems and Computation, will take place on July 23, 2021. NetEcon’21 is a workshop of EC’21, the 22nd ACM Conference on Economics and Computation, which will be held on July 19-23, 2021, co-located with the 6th World Congress of the Game Theory Society. The aim of NetEcon is to foster discussions on the application of economic and game-theoretic models and principles to address challenges in the development of networks and network-based applications and services.</p>



<p>Details regarding submission rules and dates can be found at <a href="https://netecon21.gametheory.online/" target="_blank" rel="noreferrer noopener">https://netecon21.gametheory.online/</a>. A novelty compared with prior editions of the workshop is that papers that were already formatted for and submitted to EC’21 or SIGMETRICS’21 may retain this format (for submission) if submitted together with all the reviews (see submission guidelines for details).</p></div>







<p class="date">
by Kevin Leyton-Brown <a href="https://agtb.wordpress.com/2021/05/05/netecon-2021/"><span class="datestr">at May 05, 2021 01:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/064">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/064">TR21-064 |  Streaming approximation resistance of every ordering CSP | 

	Santhoshini Velusamy, 

	Noah Singer, 

	Madhu Sudan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
An ordering constraint satisfaction problem (OCSP) is given by a positive integer $k$ and a constraint predicate $\Pi$ mapping permutations on $\{1,\ldots,k\}$ to $\{0,1\}$. Given an instance of OCSP$(\Pi)$ on $n$ variables and $m$ constraints, the goal is to find an ordering of the $n$ variables that maximizes the number of constraints that are satisfied, where a constraint specifies a sequence of $k$ distinct variables and the constraint is satisfied by an ordering on the $n$ variables if the ordering induced on the $k$ variables in the constraint satisfies $\Pi$. Ordering constraint satisfaction problems capture natural problems including ''Maximum acyclic subgraph (MAS)'' and ''Betweenness''. 

In this work we consider the task of approximating the maximum number of satisfiable constraints in the (single-pass) streaming setting, where an instance is presented as a stream of constraints. We show that for every $\Pi$, OCSP$(\Pi)$ is approximation-resistant to $o(\sqrt{n})$-space streaming algorithms, i.e., algorithms using $o(\sqrt{n})$ space cannot distinguish streams where almost every constraint is satisfiable from streams where no ordering beats the random ordering by a noticeable amount. In the case of MAS our result shows that for every $\epsilon&gt;0$, MAS is not $1/2+\epsilon$-approximable. The previous best inapproximability result only ruled out a $3/4$ approximation.

Our results build on a recent work of Chou, Golovnev, Sudan, and Velusamy who show tight inapproximability results for some constraint satisfaction problems over arbitrary (finite) alphabets. We show that the hard instances from this earlier work have the following ''small-set expansion'' property: in every partition of the hypergraph formed by the constraints into small blocks, most of the hyperedges are incident on vertices from distinct blocks. By exploiting this combinatorial property, in combination with a natural reduction from CSPs over large finite alphabets to OCSPs, we give optimal inapproximability results for all OCSPs.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/064"><span class="datestr">at May 04, 2021 09:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.let-all.com/blog/?p=55">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/letall.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/">ALT Highlights – An Interview with the PC Chairs of ALT 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fourth post in the series, an interview with ALT 2021 PC Chairs <a href="http://vtaly.net/">Vitaly Feldman</a> and <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>, written by <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a> and <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>.</p>



<hr class="wp-block-separator" />



<p>We had the great opportunity to attend <em>The 32nd International Conference on Algorithmic Learning Theory</em>, held online between March 16-19, 2021, and co-chaired by Vitaly Feldman and Katrina Ligett. Vitaly is a research scientist at Apple AI Research and has done foundational works in machine learning and privacy-preserving data analysis. Katrina is an Associate Professor of Computer Science at the Hebrew University of Jerusalem and has done pivotal works in data privacy, algorithmic fairness, algorithmic game theory, and online algorithms. We asked for an interview with them about their experiences and perspectives as co-chairs, to which they kindly agreed. We are happy to share with the readers the excerpts of this interview.</p>



<p class="has-text-align-center"><img src="https://lh4.googleusercontent.com/7RUOfC-v06amphwIhfCYsQNH4jUg82AVsePZcbWO0D40DhSRk-Cf_wnXx9y5RI-qVYz6D-IRAxRzsQ9lWBpraofuggrTYC_sG40GehOCvSrQyZfj1khlMTVqK23NKOZueGcbK_xa" style="width: 225px;" />           <img width="194" src="https://lh4.googleusercontent.com/lUMmpb6Bcfq3bPljS7jYaF2TFaXRks64--IeslcdR3WzqnCtUETu-ymoOSxm7ys_6eyRFb2mGmd1mCe1boNHdxii0d1_UCthAEJy_eTsWsGQsFKpsV5snZe3Nm9g-QDy0JTnzPKx" height="252" /></p>



<p><strong>How it started</strong></p>



<p>How are chairs and program committees chosen? </p>



<p style="color: #0000ff;" class="has-text-color">Katrina: The chairs are selected by the Association for Algorithmic Learning Theory (AALT) Steering Committee (<a href="http://algorithmiclearningtheory.org/alt-steering-committee/">http://algorithmiclearningtheory.org/alt-steering-committee/</a>), and the chairs then select the program committee members. Vitaly and I brainstormed potential PC member names, solicited additional suggestions, and also considered the lists of people who have served on recent ALT and COLT PCs. In building the PC, we had many considerations in mind, including coverage of research areas, and various metrics of diversity.</p>



<p><strong>The chairs’ role</strong></p>



<p>What are the different tasks a chair has? What is the most difficult task?</p>



<p style="color: #0000ff;" class="has-text-color">Katrina: At a high level, the roles of the PC chairs are to build the PC, oversee the reviewing process and create the conference program. Practically, though, there are a lot of decisions that need to be discussed, emails to be sent, and a lot of organizational aspects to tend to—configuring the reviewing platform, sending reminders, chasing down late reviews, and so on. Vitaly and I have a very, very long joint “to do” list—and luckily, it’s now almost all crossed off! We also had additional responsibilities this year because of the move to the virtual conference format, including selecting the technologies, overseeing the pre-recording process, and much more.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I think the hardest and probably the most time-consuming is making the accept/reject decisions on papers.  For a large fraction of the papers arriving at the decision requires getting a sense of the results; understanding the main points in reviews, author responses and discussion (while calibrating them to the PC members and reviewers); ensuring that each paper is properly discussed by chasing reviewers, asking questions and often soliciting additional opinions. We also needed to come up with a set of criteria for deciding on borderline cases and make sure that these criteria are applied as consistently as possible. At the end it is a rather long and iterative process that luckily for us has converged to a program we are happy with.</p>



<p>How much time do you spend doing chair tasks? How do you balance chairing a conference (a massive amount of work) with all your other commitments? Do you turn down other service items you would generally accept, etc.?</p>



<p style="color: #0000ff;" class="has-text-color">Katrina: It’s difficult to estimate the number of hours, but I think we have been meeting regularly since early June 2020, and we’re only wrapping up our work now, in late March 2021. It’s a much longer-timeframe commitment than serving as a PC member. I actually am chairing a second conference this year, FORC, and together it makes for a pretty serious load. As a result, I have been declining all other conference-related service. I also have a couple of other pretty substantial service commitments, as well, so I just don’t have bandwidth this year for additional PC and Area Chair-type roles.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s hard to tell how much time we spent in total. My rough estimate is that it’s about a month of full-time work. I also had to decline most other service commitments during that period some of which I’d normally accept. Naturally, it also slows down other work so I definitely had to lean more on my collaborators in some of the ongoing projects <img src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /></p>



<p>Can chairs bring their own personality into the conference? How? </p>



<p style="color: #0000ff;" class="has-text-color">Katrina: One area where the chairs enjoy freedom is in selecting the keynote and tutorial speakers. I’m biased, of course, but I think we chose very well, and all of these speakers (Joelle Pineau, Shay Moran, and Costis Daskalakis) gave excellent talks (they were recorded—check them out if you missed them)! We also were fortunate to be able to work with amazing partners who organized the mentoring workshop (Surbhi Goel, Nika Hagtalab, and Ellen Vitercik) and the Women in ML Theory event (Tosca Lechner and Ruth Urner). These aspects of the conference beyond the papers are a way for the chairs to express their priorities.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: The chairs have a lot of freedom in choosing how to run the review process, design the conference program and who else will be involved. So, inevitably, the chairs’ personalities and tastes end up being reflected in the final results. </p>



<p>Does the online conference impact the chair job? How? </p>



<p style="color: #0000ff;" class="has-text-color">Katrina: Typically, the PC chairs build the program, and then many details of organizing and running the conference get handed off to local organization chairs. But this year, since ALT was held virtually, there were many unusual tasks that fell to the PC chairs—not just the obvious ones like choosing the technologies and format and negotiating those contracts, but smaller things like chasing down authors who failed to upload their recordings, and developing instructions for people in various roles to interact with the conference platform.</p>



<p style="color: #0000ff;" class="has-text-color">In addition, COVID times placed strains on many people, which made it more challenging to recruit PC members, and resulted in a higher than usual rate of late reviews and PC drop-outs, which of course left us scrambling.</p>



<p>What motivates you to spend time on a conference service?</p>



<p style="color: #0000ff;" class="has-text-color">Katrina: We all rely on the conference system for our personal professional advancement, and for the advancement of our field as a whole. So we all owe that system our service, of course, according to our abilities, availability, and seniority. Also, it’s fun to get this different perspective on the conference review process and on the field. And it’s an honor to be entrusted with shepherding a conference for a year and hopefully nurturing its growth.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s a mix of (1) contribution to the community I’m a member of and, perhaps, an opportunity to improve some of its processes (2) a learning experience that gives one a higher-level view of the research that is happening and people who do it (3) honor and recognition that come with the job.</p>



<p><strong>Awards </strong></p>



<p>How do you decide which papers were chosen as awards? </p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: A necessary condition for a paper to receive an award is that at least one of the PC members/reviewers assigned to the paper is excited about the results.  So we start by looking at papers with the highest scores (typically all papers that received at least one “strong accept”) and reading their reviews. This allowed us to narrow down the list to a set of 5-6 candidates. From those we selected the winners by learning more about the results and selecting those, we found the most significant and interesting for the community.</p>



<p><strong>The review process</strong></p>



<p>What are your thoughts about the current peer review process in ALT? What are the downsides and advantages? Do you have suggestions for improvement?</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: It is common that confidence in correctness of the results in a conference submission is based on higher-level sanity checks and general intuition of the reviewers. Naturally, the more interesting and important result the more likely it is to be scrutinized. At this ALT we did not run into a situation where the authors’ reputation affected our confidence in the correctness of the results. In case of concerns about correctness of an interesting result we would ask either an expert on the PC or an external expert to try to verify the result.</p>



<p class="has-luminous-vivid-orange-color has-text-color">ALT currently relies on a traditional theory conference model of reviewing and for a typical submission has several PC members who are experts in the subarea. The reviewing load is also relatively light (8 papers per PC member). So I think that the overall reviewing quality is pretty much as good as it gets in ML (and is similar to COLT). Naturally, the model is not perfect and there is still variation in the quality of individual reviews. This year many more reviewers and PC members were under unusual time pressure due to the pandemic so perhaps the variation was higher than usual.</p>



<p><strong>The future</strong></p>



<p>What are your suggestions for the next chair? </p>



<p style="color: #0000ff;" class="has-text-color">Katrina: Make sure you have a good co-chair. <img src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /> Vitaly has been a great partner for this process—fun to work with, reliable, always willing to pitch in even on the less-fun tasks, and I have great respect for his technical perspective.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that diversity of perspectives and expertise is useful in several ways. Most notably, it gives the chairs a wider network of people to select the PC from. But I completely agree with Katrina, that the most important thing is the ability of co-chairs to work well together: after all, it’s a lot of work and complicated decisions that need to be made jointly. Here, I couldn’t have asked for more: Katrina is amazing both professionally and personally. Working with her was definitely the highlight of being the ALT co-chair and learned a lot from her in the process as well.</p></div>







<p class="date">
by Gautam Kamath <a href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/"><span class="datestr">at May 04, 2021 04:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=559">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2021/05/04/tcs-talk-wednesday-may-12-santhoshini-velusamy-harvard-university/">TCS+ talk: Wednesday, May 12 — Santhoshini Velusamy, Harvard University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, May 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://scholar.harvard.edu/santhoshiniv/home"><strong>Santhoshini Velusamy</strong></a> from Harvard University will speak about “<em>Classification of the approximability of all finite Max-CSPs in the dynamic streaming setting</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A maximum constraint satisfaction problem, Max-CSP(F), is specified by a finite family of constraints F, where each constraint is of arity k. An instance of the problem on n variables is given by m applications of constraints from F to length-k subsequences of the n variables, and the goal is to find an assignment to the n variables that satisfies the maximum number of constraints. The class of Max-CSP(F) includes optimization problems such as Max-CUT, Max-DICUT, Max-3SAT, Max-q-Coloring, Unique Games, etc.</p>
<p>In this talk, I will present our recent dichotomy theorem on the approximability of Max-CSP(F) for every finite family F, in the single-pass dynamic streaming setting. In this setting, at each time step, a constraint is either added to or deleted from the stream. In the end, the streaming algorithm must estimate the maximum number of constraints that can be satisfied using space that is only polylogarithmic in n. No background in streaming algorithms or constraint satisfaction problems will be needed to enjoy this talk!</p>
<p>The talk will be based on <a href="https://eccc.weizmann.ac.il/report/2021/011/">this paper</a>, and <a href="https://eccc.weizmann.ac.il/report/2021/063/">this paper</a> with Chi-Ning Chou, Alexander Golovnev, and Madhu Sudan.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2021/05/04/tcs-talk-wednesday-may-12-santhoshini-velusamy-harvard-university/"><span class="datestr">at May 04, 2021 06:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/">Postdoc at UC Irvine (apply by June 4, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>One Post-doctoral position is available under the guidance of Ioannis Panageas. The appointment is for one year and may be renewable if funding permits. Requirement is a Ph.D. in TCS/Theory of ML, or related field. Expertise can be demonstrated by 3 top-tier publications in venues like ICML, NeurIPS, AISTATS, STOC, FOCS, SODA, ICALP, EC. Anticipated starting date is October 1 2021 (negotiable).</p>
<p>Website: <a href="https://recruit.ap.uci.edu/JPF06615">https://recruit.ap.uci.edu/JPF06615</a><br />
Email: ipanagea@ics.uci.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/"><span class="datestr">at May 03, 2021 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/063">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/063">TR21-063 |  Approximability of all finite CSPs in the dynamic streaming setting | 

	Chi-Ning  Chou, 

	Alexander Golovnev, 

	Madhu Sudan, 

	Santhoshini Velusamy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A constraint satisfaction problem (CSP), Max-CSP$({\cal F})$, is specified by a finite set of constraints ${\cal F} \subseteq \{[q]^k \to \{0,1\}\}$ for positive integers $q$ and $k$. An instance of the problem on $n$ variables is given by $m$ applications of constraints from ${\cal F}$ to subsequences of the $n$ variables, and the goal is to find an assignment to the variables that satisfies the maximum number of constraints. In the $(\gamma,\beta)$-approximation version of the problem for parameters $0 \leq \beta &lt; \gamma \leq 1$, the goal is to distinguish instances where at least $\gamma$ fraction of the constraints can be satisfied from instances where at most $\beta$ fraction of the constraints can be satisfied. 

In this work we consider the approximability of this problem in the context of streaming algorithms and give a dichotomy result in the dynamic setting, where constraints can be inserted or deleted. Specifically,  for every family ${\cal F}$ and every $\beta &lt; \gamma$,  we show that either the approximation problem is solvable with polylogarithmic space in the dynamic setting, or not solvable with $o(\sqrt{n})$ space. We also establish tight inapproximability results for a broad subclass in the streaming insertion-only setting. Our work builds on, and significantly extends previous work by the authors who consider the special case of Boolean variables ($q=2$), singleton families ($|{\cal F}| = 1$) and where constraints may be placed on variables or their negations. Our framework extends non-trivially the previous work allowing us to appeal to richer norm estimation algorithms to get our algorithmic results. For our negative results we introduce new variants of the communication problems studied in the previous work, build new reductions for these problems, and extend the technical parts of previous works. In particular, previous works used Fourier analysis over the Boolean cube to prove their results and the results seemed particularly tailored to functions on Boolean literals (i.e., with negations). Our techniques surprisingly allow us to get to general $q$-ary CSPs without negations by appealing to the same Fourier analytic starting point over Boolean hypercubes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/063"><span class="datestr">at May 03, 2021 08:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-7474459772601125760">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html">The Mythical Man-Month, Hen-Day, and Cat-Minute (Fred Brooks Turned 90)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><i> The Mythical Man-Month </i>is a great book which talks about the (obvious in retrospect) fact that putting more people on a project may slow it down. It was by Fred Brooks who turned 90 in April (he is still alive). It's a good read. I actually read it many years ago when I exchanged books with a Software Engineer I was dating- She lent me <i>The Mythical Man Month </i>which I found interesting, and I lent her <i>What is the name of this book by Smullyan </i>which she found amusing. Did this exchange of books help our relationship? We have now been married for many years, though its not clear if we can trace this to the exchange of books OR to the fact that she had KNUTH Volumes 1 and 3, and I had KNUTH Volume 2. </p><p> Fred Brooks: You have my thanks and of course Happy Birthday!</p><p>When I read The Mythical Man-Month  I was reminded of a math problem I heard as a kid: </p><p>If a hen-and-half lays an egg-and-a-half in a day-and-a-half then how many eggs can seven hen lay in seven days? </p><p>My answer: if (3/2) hens lay (3/2) eggs in (3/2) days then that's 2/3 of an egg per hen-day, so the answer is </p><p>49* 2/3 = 32 and 2/3 eggs.</p><p>It did not bother me one whit that (1) you can't have 2/3 of an egg, and (2) Just like adding more people might slow down a project, adding more hens might end up being a bad idea-- especially if they are all crowded into the same chicken-coop and hence don't feel much like laying eggs.</p><p>Who was the first person to note that adding <i>more</i> people or hens might be a bad idea? I do not know, but here is an amusing, yet realistic, article by Mark Twain on what I would call <i>The mythical</i> <i>cat-minute. </i>My advisor Harry Lewis send it to me in the midst of an email exchange about <i>The Mythical</i> <i>Man-Month.</i> He got it from a student of his, Larry Denenberg. Here it is: </p><p><br /></p><p>CATS AND RATS</p><pre>The following piece first appeared in ``The Monthly Packet'' of February
1880 and is reprinted in _The_Magic_of_Lewis_Carroll_, edited by John
Fisher, Bramhall House, 1973.


   If 6 cats kill 6 rats in 6 minutes, how many will be needed to kill
   100 rats in 50 minutes?

   This is a good example of a phenomenon that often occurs in working
   problems in double proportion; the answer looks all right at first, but,
   when we come to test it, we find that, owing to peculiar circumstances in
   the case, the solution is either impossible or else indefinite, and needing
   further data.  The 'peculiar circumstance' here is that fractional cats or
   rats are excluded from consideration, and in consequence of this the
   solution is, as we shall see, indefinite.

   The solution, by the ordinary rules of Double Proportion, is 12 cats.
   [Steps of Carroll's solution, in the notation of his time, omitted.]

   But when we come to trace the history of this sanguinary scene through all
   its horrid details, we find that at the end of 48 minutes 96 rats are dead,
   and that there remain 4 live rats and 2 minutes to kill them in: the
   question is, can this be done?

   Now there are at least *four* different ways in which the original feat,
   of 6 cats killing 6 rats in 6 minutes, may be achieved.  For the sake of
   clearness let us tabulate them:
      A.  All 6 cats are needed to kill a rat; and this they do in one minute,
          the other rats standing meekly by, waiting for their turn.
      B.  3 cats are needed to kill a rat, and they do it in 2 minutes.
      C.  2 cats are needed, and do it in 3 minutes.
      D.  Each cat kills a rat all by itself, and takes 6 minutes to do it.

   In cases A and B it is clear that the 12 cats (who are assumed to come
   quite fresh from their 48 minutes of slaughter) can finish the affair in
   the required time; but, in case C, it can only be done by supposing that 2
   cats could kill two-thirds of a rat in 2 minutes; and in case D, by
   supposing that a cat could kill one-third of a rat in two minutes.  Neither
   supposition is warranted by the data; nor could the fractional rats (even
   if endowed with equal vitality) be fairly assigned to the different cats.
   For my part, if I were a cat in case D, and did not find my claws in good
   working order, I should certainly prefer to have my one-third-rat cut off
   from the tail end.

   In cases C and D, then, it is clear that we must provide extra cat-power.
   In case C *less* than 2 extra cats would be of no use.  If 2 were supplied,
   and if they began killing their 4 rats at the beginning of the time, they
   would finish them in 12 minutes, and have 36 minutes to spare, during which
   they might weep, like Alexander, because there were not 12 more rats to
   kill.  In case D, one extra cat would suffice; it would kill its 4 rats in
   24 minutes, and have 26 minutes to spare, during which it could have killed
   another 4.  But in neither case could any use be made of the last 2
   minutes, except to half-kill rats---a barbarity we need not take into
   consideration.

   To sum up our results.  If the 6 cats kill the 6 rats by method A or B,
   the answer is 12; if by method C, 14; if by method D, 13.

   This, then, is an instance of a solution made `indefinite' by the
   circumstances of the case.  If an instance of the `impossible' be desired,
   take the following: `If a cat can kill a rat in a minute, how many would be
   needed to kill it in the thousandth part of a second?'  The *mathematical*
   answer, of course, is `60,000,' and no doubt less than this would *not*
   suffice; but would 60,000 suffice?  I doubt it very much.  I fancy that at
   least 50,000 of the cats would never even see the rat, or have any idea of
   what was going on.

   Or take this: `If a cat can kill a rat in a minute, how long would it be
   killing 60,000 rats?'  Ah, how long, indeed!  My private opinion is that
   the rats would kill the cat.
</pre><div><br /></div><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html"><span class="datestr">at May 02, 2021 07:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/062">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/062">TR21-062 |  Improved Hitting Set for Orbit of ROABPs | 

	Vishwas Bhargava, 

	Sumanta Ghosh</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The orbit of an $n$-variate polynomial $f(\mathbf{x})$ over a field $\mathbb{F}$ is the set $\{f(A \mathbf{x} +  b)\,\mid\, A\in \mathrm{GL}({n,\mathbb{F}})\mbox{ and }\mathbf{b} \in \mathbb{F}^n\}$, and the orbit of a polynomial class is the union of orbits of all the polynomials in it. In this paper, we give improved constructions of hitting-sets for the orbit of read-once oblivious algebraic branching programs (ROABPs) and a related model. Over field with characteristic zero or greater than $d$, we construct a hitting set of size  $(ndw)^{O(w^2\log n\cdot \min\{w^2, d\log w\})}$  for the orbit of ROABPs in unknown variable order where $d$ is the individual degree and $w$ is the width of ROABPs. We also give hitting set of size $(ndw)^{O(\min\{w^2,d\log w\})}$ for the orbit of polynomials  computed by $w$-width ROABPs in any variable order. Our hitting sets improve upon the results of Saha and Thankey \cite{Saha-Thankey'21} who gave an $(ndw)^{O(d\log w)}$ size hitting set for the orbit of commutative ROABPs (a subclass of \textit{any-order} ROABPs) and $(nw)^{O(w^6\log n)}$ size hitting set for the orbit of multilinear ROABPs. Designing better hitting sets in large individual degree regime, for instance $d&gt;n$, was asked as an open problem by \cite{Saha-Thankey'21} and this work solves it in  small width setting. 

We prove some new rank concentration results by establishing \emph{low-cone concentration} for the polynomials over vector spaces, and they strengthen some previously known \emph{low-support} based rank concentrations shown in \cite{FSS14}. These new low-cone concentration results are crucial in our hitting set construction, and may be of independent interest. To the best of our knowledge, this is the first time when low-cone rank concentration has been used for designing hitting sets.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/062"><span class="datestr">at May 02, 2021 07:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18674">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/">Test of Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>Time is the ultimate critic. What future generations think of us and our work ultimately determines our standing or lack of it— Stewart Stafford</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/bk/" rel="attachment wp-att-18676"><img width="150" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/bk-150x150.png?resize=150%2C150&amp;ssl=1" class="alignright size-thumbnail wp-image-18676" height="150" /></a></p>
<p>
Bobby Kleinberg just reached out to those of us who post from time to time. He wanted some help in announcing a new STOC Test of Time Award. </p>
<p>
So today, Ken and I put this together. </p>
<p>Bobby said: </p>
<blockquote><p><b> </b> <em> As with FOCS, three awards will be given: one for papers from approximately 10 years ago, one for approximately 20 years ago, and one for approximately 30 years ago. The selection committee for this year’s award will be Joe Halpern, Mihalis Yannakakis, and Salil Vadhan. </em>
</p></blockquote>
<p></p><p>
I would suggest that one of Bobby’s papers could fit this award: </p>
<p>Group-theoretic algorithms for matrix multiplication <br />
Henry Cohn, Robert Kleinberg, Balazs Szegedy, Christopher Umans </p>
<p>
Well, I can say that without being out of order <em>here</em> because that paper was in FOCS, not STOC.</p>
<p>
</p><p></p><h2> Criteria </h2><p></p>
<p>
</p><li>
<i>Area</i>: Opening up a new area of research <p></p>
</li><li>
<i>Proof</i>: Introducing new proof techniques <p></p>
</li><li>
<i>Use</i>: Solving a problem of lasting importance <p></p>
</li><li>
<i>Else</i>: Stimulating advances in other areas of computer science or in other disciplines. <p></p>
<p>
Go here for details on how to <a href="https://sigact.org/prizes/stoc_tot.html">nominate</a>. By the way: Another test of Time is that the nominations are due relatively soon—May 24. So if you wish to nominate some paper please act soon. </p>
<p>
Ken notes that the first criterion could also be called <i>Leadership</i>, the second always comes with an element of <i>Surprise</i>, and the last two have aspects of <i>Applicability</i> and <i>Practicality</i>.  Adding those to my terms makes a double acronym <i>APPLAUSE</i>.</p>
<p>
</p><p></p><h2> Early Early Years </h2><p></p>
<p></p><p>
I have been around long enough to fit the a 30++ years category, and Ken almost <a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/">ditto</a>. Here are some opinions on the early days. Those papers with<br />
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1" alt="" class="alignleft  wp-image-18682" /></a><br />
are an absolute must include—I hope you agree.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc81.html">1981</a>:</p>
<p>
Space-Bounded Probabilistic Turing Machine Complexity Classes Are Closed under Complement <br />
<i>Use</i>.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc82.html">1982</a>:</p>
<p>
Shafi Goldwasser, Silvio Micali <br />
Probabilistic Encryption and How to Play Mental Poker Keeping Secret All Partial Information <br />
<i>Area</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800061">1983</a>:</p>
<p>
Miklós Ajtai, Janos Komlós, and Endre Szemerédi <br />
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1" alt="" class="alignleft  wp-image-18682" /></a>An <img src="https://s0.wp.com/latex.php?latex=%7B0%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0(n \log n)}" class="latex" /> sorting network <br />
<i>Use</i> and <i>Proof</i>.</p>
<p>
Larry Stockmeyer <br />
The complexity of approximate counting <br />
<i>Use</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800057">1984</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1" alt="" class="alignleft  wp-image-18682" /></a>Les Valiant <br />
A theory of the learnable <br />
<i>Area</i> and <i>Else</i>.</p>
<p>
Narendra Karmarkar <br />
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1" alt="" class="alignleft  wp-image-18682" /></a>A new polynomial-time algorithm for linear programming <br />
<i>Use</i> and <i>Proof</i>.</p>
<p>
Of course, these are my own opinions (with concurrence from Ken) and do not reflect those of organizations we belong to.</p>
<p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Ken thinks that one way not to be asked here about my own papers is to mention one, so here goes:</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc80.html">1980</a></p>
<p>
Ravindran Kannan, Richard Lipton <br />
The Orbit Problem is Decidable <br />
<i>Proof</i>.  Ken adds: Could also be <i>Surprise</i> because we not only showed decidable but in polynomial time.  But the real test of time here may be whether (despite some technical limitations) it proves useful to the great recent interest in adjacent kinds of orbit problems in <a href="https://rjlipton.wpcomstaging.com/2018/06/06/princeton-is-invariant/">invariant</a> and <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">reachability</a> theory.</p></li></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/"><span class="datestr">at April 30, 2021 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-3713824207379370168">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2021/04/polyconc-online-collaboration-to.html">PolyConc: Online collaboration to improve on a result on the equational theory of CCS modulo bisimilarity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The aim of this post is to try and start an online collaboration to improve the solution to a problem in the equational logic of processes that I posed in a <a href="https://www.brics.dk/NS/03/2/BRICS-NS-03-2.pdf" target="_blank">survey paper in 2003</a>, namely    </p><blockquote>  Can one obtain a finite axiomatisation of the parallel composition operator in bisimulation semantics by adding only one binary operator to the signature of (recursion, restriction, and relabelling free) CCS? </blockquote><p>     Valentina Castiglioni, Wan Fokkink, Anna Ingólfsdóttir, Bas Luttik and I published a partial, negative answer to the above question in a <a href="https://doi.org/10.4230/LIPIcs.CSL.2021.8" target="_blank">paper at CSL 2021</a>. (See the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">arXiv version</a> for details and for the historical context for the above question.) Our solution is based on three simplifying assumptions that are described in detail in Section 3 of the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">above-mentioned paper</a>. We'd be very interested in hearing whether any member of the research community in process algebra, universal algebra and equational logic can relax or remove any of our simplifying assumptions. In particular, one can start with assumptions 3 and 2. </p><p>We would also welcome any comments and suggestions on whether some version of that problem can be solved using existing results from equational logic and universal algebra. In particular, are there any general results guaranteeing that, under certain conditions, the reduct of a finitely based algebra is also finitely based? Or, conversely, that if some algebra is not finitely based, then so its expansion with a new operator?</p><p>To start with, add any contributions you might have as comments to this post. If ever we make substantial enough progress on the above question, anyone who has played a positive role in extending our results will be a co-author of the resulting paper. </p><p>Let PolyConc begin!<br /></p><p></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2021/04/polyconc-online-collaboration-to.html"><span class="datestr">at April 30, 2021 08:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/04/30/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/04/30/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea">The EFF on FLoC</a> (<a href="https://mathstodon.xyz/@11011110/106079326968515725">\(\mathbb{M}\)</a>), Google’s plan for browsers to aggregate your browsing habits and make them public for ad-personalization. Short summary: it’s a bad idea and if you care about privacy you should switch to a non-Chrome browser. Technical summary: it’s based on <a href="https://en.wikipedia.org/wiki/K-anonymity">k-anonymity</a>, known as <a href="https://doi.org/10.1109/CASoN.2010.139">inadequate at protecting individual privacy in social networks</a>. If you use Chrome, assume all bad guys on the web can see all your browsing.</p>
  </li>
  <li>
    <p>Relevant to my recent post on Pick’s theorem: <a href="https://www.youtube.com/watch?v=osF2JhrVHxc">Chris Staecker on the dot planimeter</a> (<a href="https://mathstodon.xyz/@11011110/106090366361151274">\(\mathbb{M}\)</a>), a device for <a href="https://en.wikipedia.org/wiki/Dot_planimeter">approximating area by counting grid points</a>.</p>
  </li>
  <li>
    <p><a href="https://www.peeta.net/">Anamorphic street art by Peeta transforms building shapes into 3d geometric abstractions</a> (<a href="https://mathstodon.xyz/@11011110/106100758800338449">\(\mathbb{M}\)</a>, <a href="https://weburbanist.com/2019/07/12/anamorphic-street-art-new-abstract-murals-by-peeta-pop-off-the-wall/">via</a>).</p>
  </li>
  <li>
    <p><a href="https://lore.kernel.org/linux-nfs/YH+zwQgBBGUJdiVK@unreal/">Students of University of Minnesota assistant professor Kangjie Lu caught allegedly deliberately sending buggy patches to Linux kernel as some kind of breaching experiment</a>, resulting in <a href="https://lore.kernel.org/linux-nfs/YH%2FfM%2FTsbmcZzwnX@kroah.com/">the whole university being banned from Linux kernel development</a> (<a href="https://mathstodon.xyz/@11011110/106104208447478044">\(\mathbb{M}\)</a>, <a href="https://lobste.rs/s/3qgyzp/they_introduce_kernel_bugs_on_purpose">via</a>). They claim to have been declared IRB-exempt but this appears to be a mistake by the IRB. See also <a href="https://cse.umn.edu/cs/statement-cse-linux-kernel-research-april-21-2021">department reaction</a> and <a href="https://www.metafilter.com/191207/How-to-get-your-University-banned-in-1-easy-step">metafilter discussion</a>.</p>
  </li>
  <li>
    <p><a href="https://mastodon.social/@joshmillard/106109652170356976">Josh Millard plays with algorithmically-generated pen-plotter art</a>; <a href="https://www.patreon.com/posts/50677186">more</a>.</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/a-pretty-puzzle/">You could prove that the number of integer solutions to \(x^2+xy+y^2=a\) is a multiple of six for positive \(a\) by finding a hidden group structure</a> (<a href="https://mathstodon.xyz/@11011110/106113101236984677">\(\mathbb{M}\)</a>). Or, you could recognize that it’s the norm of the Eisenstein integers under a small change of basis from the usual one and that they have six-fold rotational symmetry.</p>
  </li>
  <li>
    <p><a href="https://www.origamitessellations.com/2018/03/paper-engineering-from-the-bauhaus-josef-albers-to-the-modern-day/">Paper engineering from the Bauhaus</a> and <a href="https://www.origamitessellations.com/2018/04/reverse-engineering-bauhaus-paper-designs-part-two/">reverse-engineering Bauhaus paper designs</a> (<a href="https://mathstodon.xyz/@11011110/106118829181433597">\(\mathbb{M}\)</a>). These designs are more curved kirigami than origami, producing smooth-looking 3d shapes from cut sheets of flat paper.</p>
  </li>
  <li>
    <p><a href="https://www.scientificamerican.com/article/the-art-of-mathematics-in-chalk/">The art of mathematics in chalk</a> (<a href="https://mathstodon.xyz/@11011110/106124866673951925">\(\mathbb{M}\)</a>, <a href="https://whatsonmyblackboard.wordpress.com/">see also</a>). Teaser for the forthcoming book <em>Do Not Erase: Mathematicians and Their Chalkboards</em>, featuring several photographic spreads of chalkboard illustrations and formulas and their explanations. They appear to be mostly set-ups rather than captured from active research, but still pretty and interesting. <a href="https://11011110.github.io/blog/2019/09/30/linkage.html">I linked an earlier post on this in 2019</a> but with fewer photos and no explanations.</p>
  </li>
  <li>
    <p><a href="https://coq.discourse.group/t/renaming-coq/1264">The Coq theorem prover brainstorms a name change</a> (<a href="https://mathstodon.xyz/@11011110/106127971601789143">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191240/Not-every-woman-is-offended-by-this-name-but-enough-people-are">via</a>), after too many women get harrassed for saying they work on Coq.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Tetrad_(geometry_puzzle)">Tetrad puzzle</a> (<a href="https://mathstodon.xyz/@11011110/106136227486814000">\(\mathbb{M}\)</a>). It’s possible to arrange four congruent hexagons so they tile a disk with each pair sharing a length of boundary, but the known pentagons with four pairwise-touching copies leave a hole in the region they tile. Is the hole necessary?</p>
  </li>
  <li>
    <p><a href="https://github.andrewt.net/mercator-rotator/">Mercator Rotator</a> (<a href="https://mastodon.social/@andrewt/105950778379233419">\(\mathbb{M}\)</a>), a tool for drawing Mercator-projection world maps with different viewpoints than the usual one. Set the pole on a place you don’t like to see the map of a world without it.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/138752/440">Tetrahedra passing through a hole</a> (<a href="https://mathstodon.xyz/@11011110/106152970915208525">\(\mathbb{M}\)</a>). This is from eight years ago, but was active again recently. The question is: what’s the smallest-area hole in a plane through which you can push a unit tetrahedron? DPKR has a very pretty animated answer, but sadly it’s not optimal: there’s a triangular hole with smaller area \(1/\sqrt{8}\), known <a href="https://doi.org/10.1016/j.comgeo.2011.07.004">minimal for translational motion</a>. The problem for more general motion seems to be still open.</p>
  </li>
  <li>
    <p><a href="http://arxiv.org/abs/1112.4205v2">Lagarias’s survey on the Takagi Function</a> and <a href="https://www.jstor.org/stable/2324028">Mallows’ survey on Conway’s $10,000 sequence</a> (<a href="https://mathstodon.xyz/@11011110/106153079186577081">\(\mathbb{M}\)</a>, <a href="https://mathstodon.xyz/@esoterica/106152848486538030">via</a>, <a href="https://en.wikipedia.org/wiki/Blancmange_curve">see also</a>) have very similar-looking figures, but little or no overlap in references. Maybe someone knows of an explanation for the similarity?</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/04/30/linkage.html"><span class="datestr">at April 30, 2021 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8108">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/">ALT Highlights – Equilibrium Computation and the Foundations of Deep Learning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>[Guest post by Kush Bhatia and Cyrus Rashtchian, foreword by Gautam Kamath]</p>



<p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. Boaz has kindly agreed to host a post in this series. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the third post in the series, an interview with <a href="http://people.csail.mit.edu/costis/">Constantinos Daskalakis</a> and coverage of his ALT 2021 <a href="https://www.youtube.com/watch?v=GpaCWKlOMig">keynote talk</a>, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>.</p>



<hr class="wp-block-separator" />



<p>To make a decision for ourselves, we need to think about the impact of our actions to our objectives. But, when our actions affect other people and their actions affect our objectives, we also need to consider their incentives, and choose our actions in anticipation of theirs. This increase in complexity also occurs in situations involving multiple decision-making machines (e.g., self-driving cars), automated systems (e.g., algorithmic stock trading), or living organisms (e.g., groups of cells).</p>



<p>Studying decision-making in so-called multi-agent environments has been a question of interest to mathematicians and economists for centuries. In the 1830s, Antoine Augustin Cournot developed a theory of competition to model oligopolies, inspired by observing competition in a spring water duopoly. Jumping forward to the 20th century, researchers converged that a fruitful approach to analyzing multi-agent systems is studying them at “equilibrium”, that is, in situations where the system is stable in the sense that all parties are satisfied with their actions. A fundamental concept of equilibrium, studied by John von Neumann, and later by von Neumann and Oskar Morgenstern is a collection of actions, one per agent, such that no agent has an incentive to deviate from their choice given the actions of the other agents. While a nice proposal, they could only show that such equilibrium is guaranteed to exist in situations conforming to what is called a “two-player zero-sum game”. In such games, two agents are in exact competition with each other; whatever one player wins the other loses.<sup><a href="https://windowsontheory.org/feed/#fn1">1</a></sup> In 1950, John F. Nash showed that this notion of equilibrium, named Nash equilibrium in his honor, indeed exists for most naturally occurring multi-agent problems.<sup><a href="https://windowsontheory.org/feed/#fn2">2</a></sup></p>



<p>While Nash established the existence of equilibrium, one question bothered economists and computer scientists alike: “<em>Is it possible to efficiently find the Nash equilibrium of a game</em>?”</p>



<p>Throughout the rest of the 20th century, many people proposed algorithms for computing Nash equilibrium, but none of them succeeded in showing that it can be done efficiently (i.e., in polynomial time in the size of the game). During his early graduate school days at UC Berkeley, Constantinos (a.k.a. Costis) Daskalakis obsessed over this question. Then, in 2006, Costis, along with co-authors Paul Goldberg and Christos Papadimitriou, who was also his PhD advisor, showed a surprising result: finding a Nash equilibrium is computationally intractable!</p>



<figure class="wp-block-image size-large"><img src="https://kamathematics.files.wordpress.com/2021/04/fig1-1.png?w=643" alt="" class="wp-image-311" /><strong>Figure 1.</strong> Utility functions encode the value an agent gets from a particular decision. (a) In classical Economics and Game Theory literature, these trade off benefits and costs of actions. For e.g., consider an agent deciding on the quantity <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> of basic material to procure while the other agent sets the price <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="y" class="latex" /> per unit of this material. If we let <img src="https://s0.wp.com/latex.php?latex=g%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="g(x)" class="latex" /> denote the revenue from selling the product produced using <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> units of basic material, where <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="g" class="latex" /> is a concave function of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> (capturing diminishing returns), then the overall utility of the agent choosing <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+g%28x%29+-+x+%5Ccdot+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x,y) = g(x) - x \cdot y" class="latex" />, an overall concave function. (b) Modern multi-agent problems involve agents choosing parameters of deep neural networks. This quickly leads to non-concave agent utilities.</figure>



<p>A central concept in analyzing multi-agent systems is the <em>utility function</em> of each interacting agent. This is  a function that captures the value that the agent derives as a function of their own action as well as those of the other agents. A common assumption is that the utility function of each agent is a concave function of their own action for any collection of actions committed by the others. Concavity often arises when agents trade off benefits and costs from their actions taking into account properties like diminishing returns and risk-aversion (see Figure 1 for an illustration). It is also crucial in guaranteeing that equilibria exist.</p>



<h3>From Game Theory and Economics to Deep Learning</h3>



<p>Recently, Costis has shifted his attention to the more general setting where the underlying utilities can be arbitrary non-concave functions of the agents’ actions. “Earlier, I was interested in the problem of equilibrium computation for its fundamental applications in Game Theory and Economics and its intimate connections to duality theory, topology and complexity theory. As Machine Learning is now moving towards multi-agent learning, studying more general setups arising from nonconcave agent utilities becomes increasingly relevant,” says Costis. He elaborates that the recent success of deep learning methods has largely been in single-agent setups and that the next frontier is to replicate this success in multi-agent settings. It is at this intersection of deep learning and multi-agent learning that non-concave utility functions arise — when actions correspond to setting the parameters of deep neural networks, agent utilities quickly become non-concave in the space of these parameters(see Figure 1).</p>



<p>The focus of Costis’ <a href="https://www.youtube.com/watch?v=GpaCWKlOMig" target="_blank" rel="noreferrer noopener">keynote talk</a>, on joint work with Stratis Skoulakis and Manolis Zampetakis [<a href="https://windowsontheory.org/feed/#DSZ21">DSZ21</a>] was on the simplest multi-agent problem: two-player zero-sum games. In these games, two players, the <em>min</em> and the <em>max</em> player, choose actions <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="y" class="latex" /> respectively, which are constrained to lie in some compact and convex set <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="S" class="latex" />, i.e., <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29+%5Cin+S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x,y) \in S" class="latex" />. The agents share some objective function <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x,y)" class="latex" /> that <em>min</em> wants to minimize and <em>max</em> wants to maximize. Classical studies, going back to von Neumann’s celebrated work [<a href="https://windowsontheory.org/feed/#vN28">vN28</a>] focus on when this objective is a convex function of the <em>min</em> player’s action and a concave function of the <em>max</em> player’s action, the so-called “convex-concave setting”. For any function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" /> which is convex-concave, there exists a Nash equilibrium, i.e., a point <img src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x^*, y^*)" class="latex" /> satisfying</p>



<p class="has-text-align-center" id="eq-nash"><img src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%29+%5Cleq+f%28x%5E%2A%2C+y%5E%2A%29+%5Cleq+f%28x%2C+y%5E%2A%29+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x%2C+y+%5Ctext%7B+such+that+%7D+%28x%2C+y%5E%2A%29%2C+%28x%5E%2A%2C+y%29+%5Cin+S.%5Cqquad+%281%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x^*, y) \leq f(x^*, y^*) \leq f(x, y^*) \quad \text{for all}\; x, y \text{ such that } (x, y^*), (x^*, y) \in S.\qquad (1)" class="latex" /></p>



<p>Thus the <em>min</em> (<em>max</em>) player has no incentive to deviate from <img src="https://s0.wp.com/latex.php?latex=x%5E%2A+%28y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x^* (y^*)" class="latex" /> as long as the other player remains fixed. The existence of such <img src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x^*, y^*)" class="latex" /> follows from von Neumann’s minimax theorem and Rosen’s generalization of this theorem to the case that agents actions are jointly constrained [<a href="https://windowsontheory.org/feed/#Ros65">Ros65</a>]. However, when <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" /> is not convex-concave, the minimax theorem fails, and we lose the existence of Nash equilibrium. For a simple example, consider <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+%28x-y%29%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x,y) = (x-y)^2" class="latex" /> over the space <img src="https://s0.wp.com/latex.php?latex=S%3D%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="S=[0,1]^2" class="latex" />. Given any decision choice <img src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x, y)" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=x%5Cneq+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x\neq y" class="latex" />, the <em>min</em> player should move <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> towards <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="y" class="latex" />. Otherwise, if <img src="https://s0.wp.com/latex.php?latex=x+%3D+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x = y" class="latex" />, the <em>max</em> player wants to move away from <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" />. Thus, no pair <img src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x^*, y^*)" class="latex" /> satisfies equation <a href="https://windowsontheory.org/feed/#eq-nash">(1)</a>.</p>



<p>Nonconvex-nonconcave utility functions naturally arise in adversarial training applications, such as Generative Adversarial Network (GAN) training, where the goal is to learn how to generate new data, such as images, from the same distribution that generated a collection of given data. Specifically, GANs are trained by trying to identify the equilibrium of a two-player zero-sum game between a generator model (the <em>min</em> player) and a discriminator model (the <em>max</em> player). Each of these models are viewed as agents, choosing parameters in deep neural networks, and the objective, capturing how close the generated distribution is to the target distribution, amounts to a nonconvex-nonconcave function of the underlying network parameters, which the <em>min</em> player aims to minimize and the <em>max</em> player aims to maximize.</p>



<p>Given that Nash equilibria may not exist when the objective is not convex-concave, what type of solutions should we target when studying two player zero-sum games with such objectives? “One property that we would like our target solutions to possess is that they are universal, i.e. they are guaranteed to exist for any objective function. We can take them to a practitioner and tell them that they are always plausible targets for their computations,” says Costis. With this in mind, Costis and his co-authors consider a relaxed equilibrium concept, called <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon, \delta)" class="latex" />-Nash equilibrium. This is a pair <img src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x^*, y^*)" class="latex" /> satisfying</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3C+f%28x%2C+y%5E%2A%29+%2B+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x+%5Ctext%7B+such+that+%7D+%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%2Cy%5E%2A%29%5Cin+S%3B&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x^*, y^*) &lt; f(x, y^*) + \epsilon \quad \text{for all}\; x \text{ such that } \|x - x^*\| \leq \delta \text{ and } (x,y^*)\in S;" class="latex" /><br /><img src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3E+f%28x%5E%2A%2C+y%29+-+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+y+%5Ctext%7B+such+that+%7D+%5C%7Cy+-+y%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%5E%2A%2Cy%29%5Cin+S.&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x^*, y^*) &gt; f(x^*, y) - \epsilon \quad \text{for all}\; y \text{ such that } \|y - y^*\| \leq \delta \text{ and } (x^*,y)\in S." class="latex" /></p>



<p>This relaxes Nash equilibrium: given strategy <img src="https://s0.wp.com/latex.php?latex=y%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="y^*" class="latex" /> for the <em>max</em> player, the <em>min</em> player can improve by at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\epsilon" class="latex" /> by changing their action in a ball of radius <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta" class="latex" /> around <img src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x^*" class="latex" />, and a symmetric condition holds for the <em>max</em> player, given strategy <img src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x^*" class="latex" /> for the <em>min</em> player. One of the main insights of their paper is that such local Nash equilibria <em>are guaranteed to</em> exist as long as <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta" class="latex" /> is a small enough function of <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\epsilon" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" />’s smoothness, namely whenever <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="L" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" />’s smoothness. This non-trivial result is established via an application of Brouwer’s fixed point theorem.</p>



<h3>Can algorithms find a local Nash equilibrium?</h3>



<p>The next question, pertaining to computational complexity, is to determine whether finding an <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon, \delta)" class="latex" />-Nash equilibrium is algorithmically tractable in the regime of parameters (small enough <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta" class="latex" />) where it is guaranteed to exist. As a first step, Costis and his co-authors focus on first-order algorithms, which have access to the gradient of the objective function. Examples include gradient descent and variants thereof, which have been the main computational engine behind the success of deep learning in single-agent problems. A classical result known for these methods in minimization settings is that they are efficient in computing <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon,\delta)" class="latex" />-minima of non-convex, smooth objectives <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" />. These are points <img src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x^*" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%29+%3C+f%28x%29+%2B+%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x^*) &lt; f(x) + \epsilon" class="latex" /> for all feasible <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\|x - x^*\| \leq \delta" class="latex" />. Namely, given query access to the gradient <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\nabla f" class="latex" /> of some <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="L" class="latex" />-smooth objective <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" /> with values normalized to <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="[0,1]" class="latex" />, it is possible to compute <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon,\delta)" class="latex" />-minima in polynomially many, in <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="L" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1/\epsilon" class="latex" />, steps and queries to <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\nabla f" class="latex" />, as long as <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" />. In contrast to minimization, a main contribution of Costis’ work is to establish an intractability result for min-maximization, showing that the number of gradient queries for any first-order algorithm to compute <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon,\delta)" class="latex" />-Nash equilibria must be exponential in at least one of <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1/\epsilon" class="latex" />, the dimension <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="d" class="latex" />, or the smoothness <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="L" class="latex" /> of the objective.</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<blockquote class="wp-block-quote"><p>Theorem 1 (informal). First-order methods need a number of queries to <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\nabla f" class="latex" /> that is exponential in at least one of <img src="https://s0.wp.com/latex.php?latex=1+%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1 /\epsilon" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="L" class="latex" />, or the dimension to find <img src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(\epsilon,\delta)" class="latex" />-Nash equilibria, even when <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" />, i.e. in the regime in which they are guaranteed to exist.</p></blockquote>



<p>This theorem tells us that there exist objective functions for which the min-maximization problem can be computationally intractable for any first-order algorithm. Requiring many queries is one way to say that the problem is hard in practice. Indeed, practitioners have found it notoriously hard to get the discriminator-generator neural networks to converge to good solutions for generative modelling problems using gradient-based methods.</p>



<p>From a technical perspective, this work represents a new approach for proving lower bounds in optimization. Classical lower bounds in the optimization literature, going back to Nemirovsky and Yudin [<a href="https://windowsontheory.org/feed/#NY83">NY83</a>] target the black-box setting: an algorithm is given access to an oracle which outputs some desired information about a function when presented with a query. For example, a first-order oracle outputs the gradient of a function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" /> at a given input. Costis shared that he and his co-authors first tried to construct a black-box lower bound for local Nash equilibria directly. However, they were unsuccessful. Any direct construction they tried ended up introducing spurious local Nash equilibria, which first-order algorithms might find in polynomial time. Their direct attempts at a lower bound failed to capture the computational hardness of the problem. They quickly realized that they needed a deeper understanding of the problem at hand, better insight on what made it harder than minimization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="581" alt="" src="https://kamathematics.files.wordpress.com/2021/04/fig2.png?w=1011" class="wp-image-310" height="331" /><strong>Figure 2. </strong>(a) Black-box models work with an oracle which an algorithm queries to obtain information. White-box models provide algorithms access to functions which can compute the desired information. (b) Architecture of black-box intractability results (focus of the optimization literature): first show computational hardness results in the white-box model (focus of computational complexity); then compose those with black-box lower bounds for any problem in the class for which hardness results were established.</figure></div>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<p>That insight came when they switched to studying the complexity of the white-box version of the problem, wherein the optimization algorithm can look inside the oracle that computes <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\nabla f(x)" class="latex" /> and possibly <img src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x)" class="latex" /> as well. One might wonder why one would want to consider such white-box models over black-box ones if their goal is to prove intractability results for methods that have limited access to <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f" class="latex" />. Indeed, proving an intractability result in the white-box model is much harder because the set of algorithms that use white-box access to the objective is strictly bigger than those using only black-box access. However, the key difference is that we are not looking for the same kind of hardness in the two models. In the black-box model, we are looking for unconditional computational hardness, that is, showing that any algorithm will require exponentially many queries to the gradient oracle. On the other hand, in the white-box model, we would like to show complexity-theoretic hardness, i.e., show that solving the problem at hand is at least as hard (or exactly as hard) as solving the hardest problems in some complexity class. Such a complexity-theoretic hardness result is conditional; it says that solving this problem will be computationally intractable as long as some computational complexity conjecture, such as P <img src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\neq" class="latex" /> NP, holds. Importantly, showing hardness (or completeness) of a problem in some complexity class typically entails a fine-grained understanding of the nature of the problem and how that enables it to encode other problems in the target complexity class.</p>
</div></div>



<p>In the white-box model, the authors show that the problem of computing local Nash equilibria is PPAD-complete. In other words, computing this local equilibrium concept in zero-sum games with nonconvex-nonconcave objectives is exactly as hard as computing Nash equilibria in general-sum games with concave agent utilities.<sup><a href="https://windowsontheory.org/feed/#fn3">3</a></sup> This result is established by exhibiting a reduction from a variant of the Sperner coloring problem,<sup><a href="https://windowsontheory.org/feed/#fn4">4</a></sup> which is a PPAD-complete problem, to a discrete nonconvex-nonconcave min-maximization problem, where the two agents choose points on a hypergrid.</p>



<h3>Unexpected challenges in high dimensions</h3>



<p>Having established this result, Costis and his coauthors presumed that the hardest part of the problem was behind them. However, another challenge awaited them. They still had to construct a continuous interpolation of their discrete function to satisfy the desired Lipschitz and smoothness properties in a computationally efficient manner. To understand the challenge with this, consider a simple two-dimensional example with two actions per agent. Suppose we are given prescribed values for <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x,y)" class="latex" /> on all four vertices of <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\{0,1\}^2" class="latex" /> and our goal is to construct a continuous and smooth function on <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="[0,1]^2" class="latex" />, which matches the prescribed function values at the corners. A simple approach is to define <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(x,y)" class="latex" /> at any point <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(x,y)" class="latex" /> using a smooth interpolation of all four corners of <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\{0,1\}^2" class="latex" />. This works, but does not scale to high dimensions. An approach that would scale computationally in high dimensions is to first triangulate <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="[0,1]^2" class="latex" /> by chopping it along its main diagonal and then interpolate the function on each triangle separately. However, this simple approach fails since the gradient of the interpolated function can be discontinuous when crossing the diagonal. “This part turned out to be more technically challenging than we had thought in high dimensions,” says Costis. He and his coauthors overcame the issue by proposing a new <em>smooth and computationally efficient interpolation</em> scheme, which they expect will have more applications in transferring hardness results from discrete problems to continuous problems.</p>



<p>To obtain Theorem 1, the authors show that one can translate their complexity-theoretic hardness in the white-box model to an unconditional intractability result in the black-box model. This follows immediately from their reduction from Sperner to local Nash equilibrium. Indeed, finding local Nash equilibria in the min-max instance at the output of their reduction provides solutions to the Sperner instance at its input. Moreover, a single query (function value or gradient value) to the min-max objective requires <img src="https://s0.wp.com/latex.php?latex=O%28d%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="O(d)" class="latex" /> queries to the Sperner coloring circuit in order to be computed. Finally, it is known that, with black-box queries to the Sperner coloring circuit, exponentially many queries are necessary to compute a solution [<a href="https://windowsontheory.org/feed/#HPV89">HPV89</a>, <a href="https://windowsontheory.org/feed/#Pap94">Pap94</a>]. An exponential black-box lower bound for local Nash equilibrium thus follows.</p>



<p>This proof architecture can be used more generally to prove intractability results for optimization problems involving smooth objectives. First, ignore the black-box model and focus on identifying the complexity class that captures the complexity of the problem in the white-box model. Then, focus on obtaining a hardness result for a discrete version of the problem. Once this is established, one can use the techniques presented in this work to lift this intractability from the discrete to the continuous problem. If there are black-box lower bounds for any problem residing in the complexity class for which the white-box version of the problem is hard, then these lower bounds can be composed with hardness reductions to establish lower bounds for the black-box version of the problem. As an aside, Costis mentions that it would be interesting if one could establish the lower bound of Theorem 1 in the black-box model directly, i.e., without going through the PPAD machinery.</p>



<h3>Looking forward</h3>



<p>Costis ends on an optimistic note: “While this might appear as a negative result, it really is a positive one.” Explaining further, he says that a philosophical consequence of his intractability results is that the multi-agent future of deep learning is going to have a lot of interesting “texture” — it will involve a large breadth of communities and motivate a plethora of problems at the interface of theoretical computer science, game theory, economics and machine learning. Costis envisions a change in balance in the multi-agent world: while recent successes of deep learning in single-agent problems capitalize on access to large data, unprecedented computational power, and effective inductive biases, multi-agent problems will demand much stronger inductive biases, invoking domain expertise in order to develop effective models and useful learning targets, as well as to discover algorithms that attain those targets.</p>



<p>Indeed, domain expertise has been crucial in some recent high-profile machine learning achievements in multi-agent settings: the AlphaGo agent for playing the game of Go and the Libratus agent for playing Texas Hold’em. For these, a game-theoretic understanding has been infused into the structure and training of the learning algorithm. In addition to using deep neural networks, AlphaGo uses a Monte Carlo tree search procedure to determine the best next move as well as to collect data for the training of the neural networks during self play, while Libratus uses counterfactual regret minimization to approximate the equilibrium of the game. The success of both algorithms required combining machine learning expertise with game-theoretic expertise about how to solve the games at hand.</p>



<p>More broadly, Costis urges young researchers to move beyond the classical statistical paradigm which assumes independent and identically distributed observations, and embrace learning challenges that are motivated from learning problems with state, incomplete or biased data, data with dependencies, and multi-agent learning applications. In particular, he would like to see more activity in obtaining new models and algorithms for reinforcement and multi-agent learning, better tools for high-dimensional learning problems with data bias and dependencies, as well as deeper connections to causal inference and econometrics. <em>“There is a lot of beautiful mathematics to be done and new continents to explore motivated by these challenges.”</em></p>



<h4>Acknowledgements </h4>



<p>We are thankful to Margalit Glasgow, Gautam Kamath, Praneeth Netrapalli, Arun Sai Suggala, and Manolis Zampetakis for providing valuable feedback on the blog. We would like to especially thank Costis Daskalakis for helpful conversations related to the technical and philosophical aspects of this work, and valuable comments throughout the writing of this article.</p>
</div></div>



<p><strong>Notes</strong></p>



<p id="fn1"><sup>1 </sup> As we discuss later, this existence only holds when the gains of each player are a concave function of their own actions.</p>



<p id="fn2"><sup>2</sup> This led to Nash winning the Nobel prize in Economics in 1994 with John Harsanyi and Reinhard Selten.</p>



<p id="fn3"><sup>3</sup> PPAD is the complexity class that exactly captures the complexity of computing Nash equilibria in general-sum games, computing fixed points of Lipschitz functions in convex and compact domains, and many other equilibrium and fixed point computation problems.</p>



<p id="fn4"><sup>4</sup> In Sperner, we are given white-box access to a circuit that computes colors for the vertices of some canonical simplicization of the <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="d" class="latex" />-dimensional simplex. Each vertex receives one of the colors in <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C%5Cldots%2Cd%2B1%5C%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\{1,\ldots,d+1\}" class="latex" /> and each color <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="i" class="latex" /> does not appear on any vertex of the triangulation lying on facet <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002" alt="i" class="latex" /> of the simplex. The goal is to find a simplex of the triangulation with all vertices colored differently.</p>



<p><strong>Bibliography</strong></p>



<p id="DSZ21">[DSZ21] Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis. The complexity of constrained min-max optimization. Symposium on Theory of Computing, 2021</p>



<p id="HPV89">[HPV89] Michael D Hirsch, Christos H Papadimitriou, and Stephen A Vavasis. Exponential lower bounds for finding brouwer fixed points. Journal of Complexity, 1989.</p>



<p id="NY83">[NY83] Arkadi S. Nemirovsky and David B. Yudin. Problem complexity and method efficiency in optimization. Wiley, 1983.</p>



<p id="Pap94">[Pap94] Christos H. Papadimitriou. On the complexity of the parity argument and other inefficient proofs of existence. Journal of Computer and System Sciences, 1994.</p>



<p id="Ros65">[Ros65] J. Ben Rosen. Existence and uniqueness of equilibrium points for concave n-person games. Econometrica, 1965.</p>



<p id="vN28">[vN28] John von Neumann. Zur Theorie der Gesellschaftsspiele. In Mathematische annalen, 1928.</p></div>







<p class="date">
by Gautam <a href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/"><span class="datestr">at April 30, 2021 02:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
