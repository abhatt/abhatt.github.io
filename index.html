<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" class="message" title="http status 503">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="internal server error">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CG">arXiv.org: Data structures and Algorithms</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A> &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at January 01, 2019 01:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11896">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11896">Approximately Optimal Mechanism Design</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Talgam=Cohen:Inbal.html">Inbal Talgam-Cohen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11896">PDF</a><br /><b>Abstract: </b>Optimal mechanism design enjoys a beautiful and well-developed theory, and
also a number of killer applications. Rules of thumb produced by the field
influence everything from how governments sell wireless spectrum licenses to
how the major search engines auction off online advertising. There are,
however, some basic problems for which the traditional optimal mechanism design
approach is ill-suited---either because it makes overly strong assumptions, or
because it advocates overly complex designs. This survey reviews several common
issues with optimal mechanisms, including exorbitant communication,
computation, and informational requirements; and it presents several examples
demonstrating that passing to the relaxed goal of an approximately optimal
mechanism allows us to reason about fundamental questions that seem out of
reach of the traditional theory.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11896"><span class="datestr">at January 01, 2019 02:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11774">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11774">Tighter bounds for online bipartite matching</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feige:Uriel.html">Uriel Feige</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11774">PDF</a><br /><b>Abstract: </b>We study the online bipartite matching problem, introduced by Karp, Vazirani
and Vazirani [1990]. For bipartite graphs with matchings of size $n$, it is
known that the Ranking randomized algorithm matches at least $(1 -
\frac{1}{e})n$ edges in expectation. It is also known that no online algorithm
matches more than $(1 - \frac{1}{e})n + O(1)$ edges in expectation, when the
input is chosen from a certain distribution that we refer to as $D_n$. This
upper bound also applies to fractional matchings. We review the known proofs
for this last statement. In passing we observe that the $O(1)$ additive term
(in the upper bound for fractional matching) is $\frac{1}{2} - \frac{1}{2e} +
O(\frac{1}{n})$, and that this term is tight: the online algorithm known as
Balance indeed produces a fractional matching of this size. We provide a new
proof that exactly characterizes the expected cardinality of the (integral)
matching produced by Ranking when the input graph comes from the support of
$D_n$. This expectation turns out to be $(1 - \frac{1}{e})n + 1 - \frac{2}{e} +
O(\frac{1}{n!})$, and serves as an upper bound on the performance ratio of any
online (integral) matching algorithm.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11774"><span class="datestr">at January 01, 2019 02:34 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11772">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11772">Complexity of Linear Operators</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulikov:Alexander.html">Alexander Kulikov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mikhailin:Ivan.html">Ivan Mikhailin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mokhov:Andrey.html">Andrey Mokhov</a>, Vladimir Podolskii <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11772">PDF</a><br /><b>Abstract: </b>Let $A \in \{0,1\}^{n \times n}$ be a matrix with $z$ zeroes and $u$ ones and
$x$ be an $n$-dimensional vector of formal variables over a semigroup $(S,
\circ)$. How many semigroup operations are required to compute the linear
operator $Ax$?
</p>
<p>As we observe in this paper, this problem contains as a special case the
well-known range queries problem and has a rich variety of applications in such
areas as graph algorithms, functional programming, circuit complexity, and
others. It is easy to compute $Ax$ using $O(u)$ semigroup operations. The main
question studied in this paper is: can $Ax$ be computed using $O(z)$ semigroup
operations? We prove that in general this is not possible: there exists a
matrix $A \in \{0,1\}^{n \times n}$ with exactly two zeroes in every row (hence
$z=2n$) whose complexity is $\Theta(n\alpha(n))$ where $\alpha(n)$ is the
inverse Ackermann function. However, for the case when the semigroup is
commutative, we give a constructive proof of an $O(z)$ upper bound. This
implies that in commutative settings, complements of sparse matrices can be
processed as efficiently as sparse matrices (though the corresponding
algorithms are more involved). Note that this covers the cases of Boolean and
tropical semirings that have numerous applications, e.g., in graph theory.
</p>
<p>As a simple application of the presented linear-size construction, we show
how to multiply two $n\times n$ matrices over an arbitrary semiring in $O(n^2)$
time if one of these matrices is a 0/1-matrix with $O(n)$ zeroes (i.e., a
complement of a sparse matrix).
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11772"><span class="datestr">at January 01, 2019 02:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11712">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11712">On the Complexity of the Inverse Semivalue Problem for Weighted Voting Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavlou:Chrystalla.html">Chrystalla Pavlou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11712">PDF</a><br /><b>Abstract: </b>Weighted voting games are a family of cooperative games, typically used to
model voting situations where a number of agents (players) vote against or for
a proposal. In such games, a proposal is accepted if an appropriately weighted
sum of the votes exceeds a prespecified threshold. As the influence of a player
over the voting outcome is not in general proportional to her assigned weight,
various power indices have been proposed to measure each player's influence.
The inverse power index problem is the problem of designing a weighted voting
game that achieves a set of target influences according to a predefined power
index. In this work, we study the computational complexity of the inverse
problem when the power index belongs to the class of semivalues. We prove that
the inverse problem is computationally intractable for a broad family of
semivalues, including all regular semivalues. As a special case of our general
result, we establish computational hardness of the inverse problem for the
Banzhaf indices and the Shapley values, arguably the most popular power
indices.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11712"><span class="datestr">at January 01, 2019 02:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11685">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11685">Choosability in bounded sequential list coloring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gama:Simone.html">Simone Gama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freitas:Rosiane_de.html">Rosiane de Freitas</a>, Mário Salvatierra <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11685">PDF</a><br /><b>Abstract: </b>The list coloring problem is a variation of the classical vertex coloring
problem, extensively studied in recent years, where each vertex has a
restricted list of allowed colors, and having some variations as the
$(\gamma,\mu)$-coloring, where the color lists have sequential values with
known lower and upper bounds. This work discusses the choosability property,
that consists in determining the least number $k$ for which it has a proper
list coloring no matter how one assigns a list of $k$ colors to each vertex.
This is a $\Pi_2^P$-complete problem, however, we show that
$k$-$(\gamma,\mu)$-choosability is an $NP$-problem due to its relation with the
$k$-coloring of a graph and application of methods of proof in choosability for
some classes of graphs, such as complete bipartite graph, which is $ 3
$-choosable, but $ 2 $-$(\gamma,\mu)$-choosable.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11685"><span class="datestr">at January 01, 2019 02:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11594">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11594">Joint Overlap Analysis of Multiple Genomic Interval Sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b>Burcak Otlu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Can:Tolga.html">Tolga Can</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11594">PDF</a><br /><b>Abstract: </b>Next-generation sequencing (NGS) technologies have produced large volumes of
genomic data. One common operation on heterogeneous genomic data is genomic
interval intersection. Most of the existing tools impose restrictions such as
not allowing nested intervals or requiring intervals to be sorted when finding
overlaps in two or more interval sets. We proposed segment tree (ST) and
indexed segment tree forest (ISTF) based solutions for intersection of multiple
genomic interval sets in parallel. We developed these methods as a tool, Joint
Overlap Analysis (JOA), which takes n interval sets and finds overlapping
intervals with no constraints on the given intervals. The proposed indexed
segment tree forest is a novel composite data structure, which leverages on
indexing and natural binning of a segment tree. We also presented construction
and search algorithms for this novel data structure. We compared JOA ST and JOA
ISTF with each other, and with other interval intersection tools for
verification of its correctness and for showing that it attains comparable
execution times. We implemented JOA in Java using the fork/join framework which
speeds up parallel processing by taking advantage of all available processor
cores. We compared JOA ST with JOA ISTF and showed that segment tree and
indexed segment tree forest methods are comparable with each other in terms of
execution time and memory usage. We also carried out execution time comparison
analysis for JOA and other tools and demonstrated that JOA has comparable
execution time and is able to further reduce its running time by using more
processors per node. JOA can be run using its GUI or as a command line tool.
JOA is available with source code at https://github.com/burcakotlu/JOA/. A user
manual is provided at https://joa.readthedocs.org
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11594"><span class="datestr">at January 01, 2019 02:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11564">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11564">Spectral methods for testing cluster structure of graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silwal:Sandeep.html">Sandeep Silwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tidor:Jonathan.html">Jonathan Tidor</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11564">PDF</a><br /><b>Abstract: </b>In the framework of graph property testing, we study the problem of
determining if a graph admits a cluster structure. We say that a graph is $(k,
\phi)$-clusterable if it can be partitioned into at most $k$ parts such that
each part has conductance at least $\phi$. We present an algorithm that accepts
all graphs that are $(2, \phi)$-clusterable with probability at least
$\frac{2}3$ and rejects all graphs that are $\epsilon$-far from $(2,
\phi^*)$-clusterable for $\phi^* \le \mu \phi^2 \epsilon^2$ with probability at
least $\frac{2}3$ where $\mu &gt; 0$ is a parameter that affects the query
complexity. This improves upon the work of Czumaj, Peng, and Sohler by removing
a $\log n$ factor from the denominator of the bound on $\phi^*$ for the case of
$k=2$. Our work was concurrent with the work of Chiplunkar et al.\@ who
achieved the same improvement for all values of $k$. Our approach for the case
$k=2$ relies on the geometric structure of the eigenvectors of the graph
Laplacian and results in an algorithm with query complexity $O(n^{1/2+O(1)\mu}
\cdot \text{poly}(1/\epsilon, 1/\phi,\log n))$.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11564"><span class="datestr">at January 01, 2019 02:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11476">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11476">Inference under Information Constraints I: Lower Bounds from Chi-Square Contraction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Acharya:Jayadev.html">Jayadev Acharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tyagi:Himanshu.html">Himanshu Tyagi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11476">PDF</a><br /><b>Abstract: </b>We consider a distributed inference problem where only limited information is
allowed from each sample. We present a general framework where multiple players
are given one independent sample each about which they can only provide limited
information to a central referee. Motivated by important instances of
communication and privacy constraints, in our abstraction we allow each player
to describe its observed sample to the referee using a channel from a
prespecified family of channels $\cal W$. This family $\cal W$ can be
instantiated to capture both the communication- and privacy-constrained
settings and beyond. The central referee uses the messages from players to
solve an inference problem for the unknown underlying distribution that
generated samples of the players. We derive lower bounds for sample complexity
of learning and testing discrete distributions in this information-constrained
setting.
</p>
<p>Underlying our lower bounds is a quantitative characterization of the
contraction in chi-square distances between the observed distributions of the
samples when an information constraint is placed. This contraction is captured
in a local neighborhood in terms of chi-square and decoupled chi-square
fluctuations of a given channel, two quantities we introduce in this work. The
former captures the average distance between two product distributions and the
latter the distance of a product distribution to a mixture of product
distributions. These quantities may be of independent interest. As a corollary,
we quantify the sample complexity blow-up in the learning and testing settings
when enforcing the corresponding local information constraints. In addition, we
systematically study the role of randomness and consider both private- and
public-coin protocols.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11476"><span class="datestr">at January 01, 2019 02:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11332">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11332">Convex Polygons in Cartesian Products</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carufel:Jean=Lou_De.html">Jean-Lou De Carufel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dumitrescu:Adrian.html">Adrian Dumitrescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meulemans:Wouter.html">Wouter Meulemans</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ophelders:Tim.html">Tim Ophelders</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pennarun:Claire.html">Claire Pennarun</a>, Csaba Toth, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verdonschot:Sander.html">Sander Verdonschot</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11332">PDF</a><br /><b>Abstract: </b>We study several problems concerning convex polygons whose vertices lie in a
Cartesian product (for short, grid) of two sets of n real numbers. First, we
prove that every such grid contains a convex polygon with $\Omega$(log n)
vertices and that this bound is tight up to a constant factor. We generalize
this result to d dimensions (for a fixed d $\in$ N), and obtain a tight lower
bound of $\Omega$(log d--1 n) for the maximum number of points in convex
position in a d-dimensional grid. Second, we present polynomial-time algorithms
for computing the largest convex chain in a grid that contains no two points of
the same x-or y-coordinate. We show how to efficiently approximate the maximum
size of a supported convex polygon up to a factor of 2. Finally, we present
exponential bounds on the maximum number of convex polygons in these grids, and
for some restricted variants. These bounds are tight up to polynomial factors.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11332"><span class="datestr">at January 01, 2019 02:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11258">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11258">Distributions of Matching Distances in Topological Data Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b>So Mang Han, Taylor Okonek, Nikesh Yadav, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Xiaojun.html">Xiaojun Zheng</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11258">PDF</a><br /><b>Abstract: </b>In topological data analysis, we want to discern topological and geometric
structure of data, and to understand whether or not certain features of data
are significant as opposed to simply random noise. While progress has been made
on statistical techniques for single-parameter persistence, the case of
two-parameter persistence, which is highly desirable for real-world
applications, has been less studied. This paper provides an accessible
introduction to two-parameter persistent homology and presents results about
matching distance between 2-D persistence modules obtained from families of
point clouds. Results include observations of how differences in geometric
structure of point clouds affect the matching distance between persistence
modules. We offer these results as a starting point for the investigation of
more complex data.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11258"><span class="datestr">at January 01, 2019 02:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11257">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11257">Approximate Nearest Neighbors in the Space of Persistence Diagrams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fasy:Brittany_Terese.html">Brittany Terese Fasy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Xiaozhou.html">Xiaozhou He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Zhihui.html">Zhihui Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Micka:Samuel.html">Samuel Micka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Millman:David_L=.html">David L. Millman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Binhai.html">Binhai Zhu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11257">PDF</a><br /><b>Abstract: </b>Persistence diagrams are important tools in the field of topological data
analysis that describe the presence and magnitude of features in a filtered
topological space. However, current approaches for comparing a persistence
diagram to a set of other persistence diagrams is linear in the number of
diagrams or do not offer performance guarantees. In this paper, we apply
concepts from locality-sensitive hashing to support approximate nearest
neighbor search in the space of persistence diagrams. Given a set $\Gamma$ of
$n$ $(M,m)$-bounded persistence diagrams, each with at most $m$ points, we
snap-round the points of each diagram to points on a cubical lattice and
produce a key for each possible snap-rounding. Specifically, we fix a grid over
each diagram at several resolutions and consider the snap-roundings of each
diagram to the four nearest lattice points. Then, we propose a data structure
with $\tau$ levels $\bigds$ that stores all snap-roundings of each persistence
diagram in $\Gamma$ at each resolution. This data structure has size
$O(n5^m\tau)$ to account for varying lattice resolutions as well as
snap-roundings and the deletion of points with low persistence. To search for a
persistence diagram, we compute a key for a query diagram by snapping each
point to a lattice and deleting points of low persistence. Furthermore, as the
lattice parameter decreases, searching our data structure yields a
six-approximation of the nearest diagram in $\Gamma$ in
$O((m\logn+m^2)\log\tau)$ time and a constant factor approximation of the $k$th
nearest diagram in $O((m\logn+m^2+k)\log\tau)$ time.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11257"><span class="datestr">at January 01, 2019 02:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11254">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11254">A Dynamically Turbo-Charged Greedy Heuristic for Graph Coloring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abu=Khzam:Faisal_N=.html">Faisal N. Abu-Khzam</a>, Bachir M. Chahine <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11254">PDF</a><br /><b>Abstract: </b>We introduce a dynamic version of the graph coloring problem and prove its
fixed-parameter tractability with respect to the edit-parameter. This is used
to present a {\em turbo-charged} heuristic for the problem that works by
combining the turbo-charging technique with other standard heuristic tools,
including greedy coloring. The recently introduced turbo-charging idea is
further enhanced in this paper by introducing a dynamic version of the so
called {\em moment of regret} and {\em rollback points}. Experiments comparing
our turbo-charging algorithm to other heuristics demonstrate its effectiveness.
Our algorithm often produced results that were either exact or better than all
the other available heuristics.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11254"><span class="datestr">at January 01, 2019 02:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11249">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11249">A Compact Representation for Trips over Networks built on self-indexes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fari=ntilde=a:Antonio.html">Antonio Fariña</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galaktionov:Daniil.html">Daniil Galaktionov</a>, M. Andrea Rodriguez <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11249">PDF</a><br /><b>Abstract: </b>Representing the movements of objects (trips) over a network in a compact way
while retaining the capability of exploiting such data effectively is an
important challenge of real applications. We present a new Compact Trip
Representation (CTR) that handles the spatio-temporal data associated with
users' trips over transportation networks. Depending on the network and types
of queries, nodes in the network can represent intersections, stops, or even
street segments.
</p>
<p>CTR represents separately sequences of nodes and the time instants when users
traverse these nodes. The spatial component is handled with a data structure
based on the well-known Compressed Suffix Array (CSA), which provides both a
compact representation and interesting indexing capabilities. The temporal
component is self-indexed with either a Hu-Tucker-shaped Wavelet-tree or a
Wavelet Matrix that solve range-interval queries efficiently. We show how CTR
can solve relevant counting-based spatial, temporal, and spatio-temporal
queries over large sets of trips. Experimental results show the space
requirements (around 50-70% of the space needed by a compact non-indexed
baseline) and query efficiency (most queries are solved in the range of 1-1000
microseconds) of CTR.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11249"><span class="datestr">at January 01, 2019 02:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11244">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11244">Using Compressed Suffix-Arrays for a Compact Representation of Temporal-Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caro:Diego.html">Diego Caro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fari=ntilde=a:Antonio.html">Antonio Fariña</a>, M. Andrea Rodriguez <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11244">PDF</a><br /><b>Abstract: </b>Temporal graphs represent binary relationships that change along time. They
can model the dynamism of, for example, social and communication networks.
Temporal graphs are defined as sets of contacts that are edges tagged with the
temporal intervals when they are active. This work explores the use of the
Compressed Suffix Array (CSA), a well-known compact and self-indexed data
structure in the area of text indexing, to represent large temporal graphs. The
new structure, called Temporal Graph CSA (TGCSA), is experimentally compared
with the most competitive compact data structures in the state-of-the-art,
namely, EDGELOG and CET. The experimental results show that TGCSA obtains a
good space-time trade-off. It uses a reasonable space and is efficient for
solving complex temporal queries. Furthermore, TGCSA has wider expressive
capabilities than EDGELOG and CET, because it is able to represent temporal
graphs where contacts on an edge can temporally overlap.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11244"><span class="datestr">at January 01, 2019 02:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.11177">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.11177">Degree Bounded Bottleneck Spanning Trees in Three Dimensions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Andersen:Patrick_J=.html">Patrick J. Andersen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ras:Charl_J=.html">Charl J. Ras</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11177">PDF</a><br /><b>Abstract: </b>The geometric $\delta$-minimum spanning tree problem ($\delta$-MST) is the
problem of finding a minimum spanning tree for a set of points in a normed
vector space, such that no vertex in the tree has a degree which exceeds
$\delta$, and the sum of the lengths of the edges in the tree is minimum. The
similarly defined geometric $\delta$-minimum bottleneck spanning tree problem
($\delta$-MBST), is the problem of finding a degree bounded spanning tree such
that the length of the longest edge is minimum. For point sets that lie in the
Euclidean plane, both of these problems have been shown to be NP-hard for
certain specific values of $\delta$. In this paper, we investigate the
$\delta$-MBST problem in $3$-dimensional Euclidean space and $3$-dimensional
rectilinear space. We show that the problems are NP-hard for certain values of
$\delta$, and we provide inapproximability results for these cases. We also
describe new approximation algorithms for solving these $3$-dimensional
variants, and then analyse their worst-case performance.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.11177"><span class="datestr">at January 01, 2019 02:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/31/linkage.html">Linkage for the end of the year</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://twitter.com/trannosaurusma/status/959423514485841925?s=21">LaTeX, the game</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101252368314388741"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/BAwHG7Tnc2N">G+</a>, <a href="https://mathstodon.xyz/@ejk/101201955004129570">via</a>). It should be an even higher level to get the commutative diagram to format in Wikipedia’s lobotomized version of LaTeX.</p>
  </li>
  <li>
    <p><a href="http://aperiodical.com/2018/12/byrnes-euclid-recreated-for-the-web/">Byrne’s Euclid recreated for the web</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101259384727886209"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/4Z1pWdmcWui">G+</a>, <a href="https://plus.google.com/+Aperiodical/posts/KdfBH9YMFMV">via</a>, <a href="https://www.metafilter.com/178260/Byrnes-Euclid">also via</a>. Beautiful three-color figures, hard-to-read old-faſhioned orthography, and all. I have the Taſchen reprint in my office, but I prefer the Dover Heath edition for actually uſing the books rather than looking pretty.</p>
  </li>
  <li>
    <p><a href="https://www.theengineer.co.uk/electric-eel-hydrogel-battery/">Electric eel inspires biocompatible hydrogel battery</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101264841241151850"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/EioURA7NEmH">G+</a>, <a href="https://www.nature.com/articles/nature24670">original paper</a>, <a href="https://news.umich.edu/electricity-eel-style-soft-power-cells-could-run-tomorrow-s-implantables/">see also</a>). The part that caught my attention is that they’re using a Miura fold to simultaneously align and press together many pairs of droplets of four types (salty, fresh water, or two kinds of charge-selective hydrogel), creating an origami-activated electrical discharge.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/in-the-universe-of-equations-virtually-all-are-prime-20181210/">In the universe of equations, virtually all are prime</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101270526352782325"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/d7hvGtho5FJ">G+</a>, <a href="https://plus.google.com/+QuantamagazineOrgNews/posts/9e2bRyNfyeF">via</a>, <a href="https://arxiv.org/abs/1810.13360">original paper</a>). Choose a polynomial’s coefficients randomly and independently from your favorite nontrivial distribution. Then it should be irreducible with high probability for polynomials of high enough degree. This was previously conjectured for the uniform distribution on  by Odlyzko and Poonen; now Breuillard and Varjú have proven that it follows from a form of the Riemann hypothesis.</p>
  </li>
  <li>
    <p>A tricky Sudoku (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101277538292220348"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/NDeATkTyEKT">G+</a>):</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/sudoku.svg" alt="A sudoku puzzle" /></p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/In-Talks-With-Elsevier-UCLA/245311">UCLA suggests that its faculty refrain from publishing with or reviewing for Elsevier while negotiations are ongoing</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101281900329465390"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/E4KAhwXct6y">G+</a>). For those willing to take a longer-term stand, there’s always <a href="http://thecostofknowledge.com/">thecostofknowledge.com</a>.</p>
  </li>
  <li>
    <p><a href="https://suomela.github.io/snowflake/">A161330 Snowflake</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101293131395532694"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/N1gsDwSmjrX">G+</a>, <a href="https://plus.google.com/+JukkaSuomela/posts/b7rngpsTaVc">via</a>). An animated holiday greeting from <a href="https://twitter.com/JukkaSuomela">Jukka Suomela</a> based on <a href="https://oeis.org/A161330">integer sequence A161330</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@unknown/101273978649098365">Festive two-to-one star dissection</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101298812633911915"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Bf3kWzhc9Yh">G+</a>). A Christmas greeting from <a href="https://mathstodon.xyz/@unknown/">@unknown@mathstodon.xyz</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=uNJ7riiPHOY">Journeys of women in mathematics</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101311027456154189"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/5CXnPF36FMz">G+</a>, <a href="https://blogs.scientificamerican.com/roots-of-unity/women-mathematicians-in-their-own-words/">via</a>). A 20-minute documentary profiling three women mathematicians from developing countries: Neela Nataraj of IIT Bombay in India, Aminatou Pecha Nijahouo from Cameroon, and Carolina Araujo at IMPA in Brazil, with brief quotes from many more.</p>
  </li>
  <li>
    <p><a href="https://wikiedu.org/blog/2018/12/20/three-things-i-learned-as-a-wiki-scholar/">Three things i learned as a Wiki scholar</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101314727270253883"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/hmWXq3eDTqf">G+</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_Women_in_Red">via</a>). Historian Rachel Boyle on some cultural differences between academia and Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:Mendocino_Beacon_Building.jpg">Mendocino Beacon Building</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101320263516053157"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/ik4GHTux6wN">G+</a>). It feels like I haven’t been taking and posting enough photos. So here’s a cell phone shot that I took to illustrate the Wikipedia article on the <em><a href="https://en.wikipedia.org/wiki/Mendocino_Beacon">Mendocino Beacon</a></em>. The <em>Beacon</em> hasn’t actually lived there for nearly 20 years, but their old sign still hangs on the building.</p>
  </li>
  <li>
    <p><em><a href="http://algorithms.wtf/">Algorithms</a></em> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101327166193790839"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Vsin2Hxwpaj">G+</a>, <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">via</a>). Jeff Erickson’s open-licensed algorithms text is finally more-or-less complete and available in prepublication form.</p>
  </li>
  <li>
    <p><a href="https://wyss.harvard.edu/studying-aliens-of-the-deep/">Using unfolded polyhedra to catch and later release deep-sea creatures without harming them</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101332999043783606"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/j42xnNxs7nW">G+</a>, <a href="https://news.ycombinator.com/item?id=18769435">via</a>).</p>
  </li>
  <li>
    <p><a href="https://plus.google.com/100003628603413742554/posts/WSizeQTqrZH">In which I say goodbye to Google+</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101338372532836995"></a>).</span></p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/31/linkage.html"><span class="datestr">at December 31, 2018 04:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4045">Incompleteness ex machina</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I have a treat with which to impress your friends at New Year’s Eve parties tomorrow night: a <a href="https://www.scottaaronson.com/incompleteness.pdf">rollicking essay</a> graciously contributed by a reader named Sebastian Oberhoff, about a unified and simplified way to prove all of Gödel’s Incompleteness Theorems, as well as Rosser’s Theorem, directly in terms of computer programs.  In particular, this improves over my treatments in <em>Quantum Computing Since Democritus</em> and my <a href="https://www.scottaaronson.com/blog/?p=710">Rosser’s Theorem via Turing machines</a> post.  While there won’t be anything new here for the experts, I loved the style—indeed, it brings back wistful memories of how <em>I</em> used to write, before I accumulated too many imaginary (and non-imaginary) readers tut-tutting at crass jokes over my shoulder.  May 2019 bring us all the time and the courage to express ourselves authentically, even in ways that might be sneered at as incomplete, inconsistent, or unsound.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4045"><span class="datestr">at December 31, 2018 02:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:typepad.com,2003:post-6a00d83452383469e2022ad3ca27b2200b">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/erickson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">Steal This Book!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup" class="asset-img-link"><img src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" alt="BookCover" style="display: block; margin-left: auto; margin-right: auto;" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" title="BookCover" /></a><br />Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>







<p class="date">
by Jeff Erickson <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html"><span class="datestr">at December 29, 2018 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:typepad.com,2003:post-6a00d83452383469e2022ad3aa81e9200d">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/erickson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book.html">Steal This Book!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup" class="asset-img-link"><img src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" alt="BookCover" style="display: block; margin-left: auto; margin-right: auto;" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" title="BookCover" /></a><br />Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>







<p class="date">
by Jeff Erickson <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book.html"><span class="datestr">at December 29, 2018 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3371">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/">SIGecom Test of Time Award</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation.</div>
<div></div>
<p></p>
<div>To be eligible, a paper or series of papers must be on a topic in the intersection of economics and computation, including topics in electronic commerce, and must have been first published, in preliminary or final form, in an archival journal or conference proceedings no less than ten years and no more than twenty-five years before the year the award is conferred. Papers for which all authors are deceased at the time the Award Committee makes its decision are not eligible for the award.</div>
<div></div>
<p></p>
<div>The 2019 SIGecom Test of Time Award will be given for papers published no earlier than 1994 and no later than 2009. Nominations are due by February 20th, 2019, and must be made by email to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a>) with “ACM SIGecom Test of Time Award” in the subject.</div>
<div></div>
<p></p>
<div>Any member of SIGecom may submit a nomination. Self-nomination is not allowed. Nominations must include the following, preferably in a single PDF file:</div>
<div></div>
<p></p>
<div>1. Bibliographic data for the paper or series of papers demonstrating publication, in preliminary or final form, at least ten years and at most twenty-five years before the award year.</div>
<div></div>
<p></p>
<div>2. An endorsement letter by the nominator of no more than two pages describing the content of the paper or series of papers and the lasting contribution, significance, and impact of the work.</div>
<div></div>
<p></p>
<div>3. The names, email addresses, and affiliations of at least two and at most three other endorsers. Endorsers, like the nominator, may not be authors of the paper or papers under consideration.</div>
<div></div>
<p></p>
<div>4. A one-sentence statement that describes the contribution of the paper or series of papers.</div>
<div></div>
<p></p>
<div>The additional endorsers should send letters directly to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a>) by the same deadline. Each letter should specify the relationship of the endorser to nominees and describe, in 500 words or fewer, the lasting contribution, significance, and impact of the paper or papers.</div>
<div></div>
<p></p>
<div>An unsuccessful nomination can be reconsidered for three award cycles, with the option of updating the original nomination to reflect additional impact. Subsequently, a new nomination must be provided. All matters relating to the selection process that are not specified here are left to the discretion of the Award Committee.</div>
<div></div>
<p></p>
<div>The award, conferred annually at the ACM Conference on Economics and Computation, includes a plaque and complimentary conference registration for each winner and an honorarium of $1,000 to be shared among the winners. The award may not be given if the nominations are judged not to meet the standards of the award.</div>
<div></div>
<p></p>
<div>It is expected that at least one of the nominated authors, if selected for the award, will attend the next ACM Conference on Economics and Computation on June 24-28, 2019, in Phoenix, AZ, USA, to accept the award and give a presentation on the work. The award includes complimentary registration but does not cover travel expenses to attend the conference.</div>
<div></div>
<p></p>
<div>The Award Committee welcomes questions from anyone considering or intending to submit a nomination. The Award Committee is happy to provide feedback on informal proposals for potential nominees, should it be needed.</div>
<div></div>
<p></p>
<div>On behalf of the 2019 Award Committee:</div>
<div></div>
<p></p>
<div>Nikhil Devanur</div>
<div>Robert Kleinberg</div>
<div>Tim Roughgarden (Chair)</div>
<div><a href="mailto:sigecom-awards-tot@acm.org" target="_blank" rel="noopener">sigecom-awards-tot@acm.org</a></div></div>







<p class="date">
by timroughgarden <a href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/"><span class="datestr">at December 28, 2018 08:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/213">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/213">TR18-213 |  The Power of Distributed Verifiers in Interactive Proofs | 

	Eylon Yogev, 

	Moni Naor, 

	Merav Parter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We explore the power of interactive proofs with a distributed verifier. In this setting, the verifier consists of $n$ nodes and a graph $G$ that defines their communication pattern. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ belongs to some language in a small number of rounds, and with small communication bound, i.e., the proof size.

This interactive model was introduced by Kol, Oshman and Saxena (PODC 2018) as a generalization of non-interactive distributed proofs. They demonstrated the power of interaction in this setting by constructing protocols for problems as Graph Symmetry and Graph Non-Isomorphism -- both of which require proofs of $\Omega(n^2)$-bits without interaction.

In this work, we provide a new general framework for distributed interactive proofs that allows one to translate standard interactive protocols (i.e., with a centralized verifier) to ones where the verifier is distributed with a proof size that depends on the computational complexity of the verification algorithm run by the centralized verifier.
We show the following:

* Every (centralized) computation that can be performed in time $O(n)$ can be translated into three-round distributed interactive protocol with $O(\log n)$ proof size. This implies that many graph problems for sparse graphs have succinct proofs (e.g., testing planarity).

* Every (centralized) computation implemented by either a small space or by uniform NC circuit can be translated into a distributed protocol with $O(1)$ rounds and $O(\log n)$ bits proof size for the low space case and $polylog(n)$ many rounds and proof size for NC.

* We also demonstrate the power of our compilers for problems not captured by the above families. We show that for Graph Non-Isomorphism, one of the striking demonstrations of the power of interaction, there is a 4-round protocol with $O(\log n)$ proof size, improving upon the $O(n \log n)$ proof size of Kol et al.

* For many problems we show how to reduce proof size below the naturally seeming barrier of $\log n$. By employing our RAM compiler, we get a 5-round protocols with proof size $O(\log \log n)$ for a family of problems including Fixed Automorphism, Clique and Leader Election (for the later two problems we actually get $O(1)$ proof size).

* Finally we discuss how to make these proofs non-interactive arguments via random oracles.

Our compilers capture many natural problems and demonstrates the difficultly in showing lower bounds in these regimes.<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/213"><span class="datestr">at December 28, 2018 08:02 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15551">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/">ACM Great Results</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A Puck-ish take on promised technological advances</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg?w=189&amp;h=189" alt="" height="189" class="alignright wp-image-15552" width="189" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Das_festliche_Jahr_img398_(Ruprecht).jpg">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. <a href="https://en.wikipedia.org/wiki/Puck_(folklore)">Puck</a>. The Simpsons’ <a href="https://en.wikipedia.org/wiki/Santa's_Little_Helper">dog</a> “Santa’s Little Helper” is named “Knecht Ruprecht” in the show’s German edition.</p>
<p>
Today we do a nice-or-naughty riff on technological gifts suggested by yesterday’s ACM TechNews mailing.</p>
<p>
The ACM mailings highlight the achievements of the whole field: from quantum to everything else. We thought it might be fun to be a bit puckish ourselves and deliver some “coal” to ACM. The stories can be sometimes a bit much. We hope that all involved are in good spirits and accept the “coal” as a holiday-inspired gift—with some echo of the general discussion about naughty-or-nice effects of tech advances.</p>
<p>
</p><p></p><h2> Our Versions of the Stories </h2><p></p>
<p>
</p><p>
Here are some that could be reported in the near future. The originals are <a href="https://technews.acm.org/archives.cfm?fo=2018-12-dec/dec-26-2018.html">here</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>Real-Time Readouts of Thinking in Faculty</i>. <br />
Mighty News<br />
December 19, 2018<br />
Researchers from a university consortium have developed an open source system delivering fast, precise neural decoding and real-time readouts of where CS faculty think they are. The neural decoding software decrypts hippocampal spatiotemporal patterns detected from tetrode recordings without requiring spike sorting, an error-prone computational process. Implementing this software on a graphical processing unit (GPU) chip demonstrated a 20- to 50-fold upgrade in decoding and analysis speed over conventional multicore central processing unit (CPU) chips. This builds on work previous done on rats as reported by ACM previously. The lab director says that the CS faculty work presented many challenges beyond that required for rats. The applications—she says—are immense. Faculty currently cannot always tell where they are, and the new system could help them get to classes on time.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A Robotic Hand Able To Type At Desktop Keyboard At 20 Words Per Minute</i>.<br />
New Yolk Times<br />
December 19, 2018 <br />
Researchers at Can’t-Abridge University have for the first time taught a robotic hand to type on a normal keyboard. The researchers claim that their system can type at rates in excess of 20 words per minute. They say, “this could change the way that computers interact with others.” The system, which now weighs about 500 pounds, could be reduced in size and cost in the future. That the robot sometimes destroys the keys by hitting them too hard continues to be a challenge.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>How AI Spotted Every Solar Panel in the U.S.</i><br />
Pretty Big Solar NewsHour<br />
December 19, 2018<br />
Engineers at the University of St. Anford have located every solar panel in the contiguous U.S. via a network built around a deep learning computer model called Inception. The network completed this task in less than a month, ascertaining that regions with more sun exposure had greater solar panel adoption than areas with less average sunlight. DeepSolar also learned that adoption was higher in locations of increasing average household income. Unbelievable—who would have guessed this?</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>An Amoeba Just Found an Entirely New Way to Write Articles</i>. <br />
ScienceAlarm <br />
December 21, 2018<br />
Researchers at Knockout University in Japan gave an assistant professorship to a “true slime mold” amoeba, and found as the papers-per-year target increased from four to eight, the single-celled organism only needed a linear amount of more time to generate minimum publishable units. This is part of an ongoing project on using lower-level organisms to do research. The project previously used graduate students. The leader of the multiple institution project said that using amoebae could reduce the costs of writing up research by up to 50%. He also said that the amoeba sometimes made various grammar errors, but that the project was attempting to fix this issue.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <i>A Quantum Computer Just Found an Entirely Old Way to Visit Cities</i>. <br />
ScienceAllure <br />
December 21, 2018<br />
Researchers at TKO University in Japan gave the Traveling Salesman Problem (TPS) to a vast array of noisy astronomical scale quantum (NASQ) processors, and found that as the cities increased from four to eight, the system only needed a linear amount of more time to determine a single reasonable route. This was fresh off its success at factoring numbers higher than 291,311 = 523*557 that it didn’t even <a href="https://en.wikipedia.org/wiki/Integer_factorization_records#Records_for_efforts_by_quantum_computers">know</a> it was factoring. TPS is an optimization problem requiring a computer to look at a list of cities and determine the shortest route in which each city is visited exactly once. The team said their results “may lead to the development of quantum algorithms for problems on as many as ten cities.” </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg?w=300&amp;h=148" alt="" height="148" class="aligncenter size-medium wp-image-15555" width="300" /></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Modified from <a href="https://www.flickr.com/photos/jared422/11839818825">source</a><br />
</font>
</td>
</tr>
</tbody></table>
<p><img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Programming Proteins to Pair Precisely</i>.<br />
C++ News<br />
December 19, 2018<br />
The <b>std::pair</b> construct in C++ is a common annoyance because human programmers frequently forget its implicit presence when iterating over maps or inserting into sets. This necessitates the re-typing of millions of lines of source code per annum. Absent the development of a robotic hand able to type at a desktop keyboard at 20 words per minute, software companies can improve productivity by optimizing the nutritional intake of programmers. Nanosoft has partnered with CodeURIKA to provide protein-rich drinks worldwide, after a study of electronic sweatshops found that proteins minimize both syntactic and semantic bugs better over the long term than sugars and PEDs. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Room for Improvement? New Hotelier Tests an Algorithmic System</i>.<br />
Wallbanger Street Journal<br />
December 19, 2018<br />
The Lite House hotelier is experimenting with an algorithmic pricing system to set different room rates for guests who arrive in self-driving cars. Once customers book for the first time at a standard rate, they fill out a questionnaire of 200 questions to specify how often they will need the car, how frequently they visit the hotel bar, and other details. The hotelier then activates a key to drive the car into an appropriate space. The optimized use of vertical space and savings from not hiring car valets will enable conference participants who are not staying at the hotel to park there at a rate low enough to include in the conference registration fee. A spokesman said, “Most of the big hotel operating companies are not focused on their conference guests,” while Lite House’s algorithmic rate-setting “is next-generation.”</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>Companies Use VR to Train Employees for Difficult Customers</i>.<br />
ESPN Technology Review<br />
December 20, 2018.<br />
Major corporations like Wallstore, ChippedPot, and Horizon are using virtual reality (VR) to prepare employees for potentially difficult situations on the job. For example, Horizon has more than 1,600 stores in the U.S. whose front-line employees participate in a digital scenario in which a customer asks to use the bathroom. In a “Harry Potter-Style Photos for Muggles” twist, researchers have developed software that can animate the central character in a photograph while leaving the rest of the image untouched. Its skeleton can then be animated to create the sense of movement, solving the problem of pose estimation for a limited set of circumstances in which bathroom requests occur. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <i>New Attack Intercepts Keystrokes Via Digital Watches</i>.<br />
TubeNet<br />
December 19, 2018<br />
A team of researchers from Burning Man University has developed a new side-channel attack that exploits the heat generated by people wearing Orange Digital Watches while working on their PCs. Heat amplifies the watches’ ability to detect keystrokes from both hands. Videos known to generate large amounts of heat include comic videos and videos on carpet cleaning. The attack becomes more adept at guessing correct keys as the user gets hotter, as it amasses more key presses from graphic libraries. </p>
<p></p><p><br />
There are some other items, including one particularly chilling, that we chose not to parody.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Will the next year’s advances in AI and other areas of tech be anything like we imagine? Will they bring humanity more gifts than lumps of coal?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/"><span class="datestr">at December 28, 2018 01:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html">Motorcycle graphs and the eventual fate of sparse Life</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The <a href="http://jeffe.cs.illinois.edu/open/cycles.html">motorcycle graph</a> is a geometric structure devised by Jeff Erickson as a simplified model for the behavior of <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>, motivated by the light cycle game in the movie Tron. Its initial data consists of a set of points in the plane (the motorcycles), each with an initial velocity. The motorcycles leave a trail behind them as they move, and a motorcycle crashes (stopping the growth of its trail) when it hits the trail of another motorcycle.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/motorcycle-graph.svg" alt="A motorcycle graph" /></p>

<p>The motorcycles can be constrained in various ways, and one of these constrained variants is much older. It’s the <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>, a motorcycle graph in which the motorcycles start out in pairs traveling in opposite directions, all at the same speed, with a random initial placement for the pairs. Edgar Gilbert wrote about it in 1967, as a model for the growth of <a href="https://en.wikipedia.org/wiki/Acicular_(crystal_habit)">acicular (needle-shaped) crystals</a> and similar systems.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation.svg"><img src="https://11011110.github.io/blog/assets/2018/Gilbert-tessellation.svg" alt="A Gilbert tessellation, by Claudio Rocchini" /></a></p>

<p>One obvious difference between the Gilbert tessellation and more general types of motorcycle graph is that all the Gilbert tessellation cells are convex polygons. More general motorcycle graphs leave degree-one vertices at the starting position of each motorcycle, but this is hidden by the way the Gilbert graph starts motorcycles in pairs. If we constrain the motorcycles even more, to travel in axis-parallel directions, the polygons become rectangles.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation_axis.svg"><img src="https://11011110.github.io/blog/assets/2018/Gilbert-rectangles.svg" alt="Axis-aligned Gilbert tessellation subdivides the plane into rectangles, by Claudio Rocchini" /></a></p>

<p>In my paper “<a href="https://arxiv.org/abs/0911.2890">Growth and decay in life-like cellular automata</a>” I noticed that the <a href="https://en.wikipedia.org/wiki/Life-like_cellular_automaton">Life-like cellular automaton</a> rule B017/S1 has a very simple <a href="https://en.wikipedia.org/wiki/Replicator_(cellular_automaton)">replicator</a> consisting of two orthogonally-adjacent live cells, and that initial fields consisting of very sparse randomly placed live cells become dominated by rows and columns of these replicators. Here’s an example for an initial random fill density of 1%, the lowest I can go in <a href="http://golly.sourceforge.net/">Golly</a>.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/b017s1.png" alt="Replicator chaos in B017/S1" /></p>

<p>Although I didn’t notice it at the time, this looks very similar to the rectangular Gilbert tessellation! I think that’s not a coincidence. With a fill density of , the most common constellation (connected group of live cells) of the initial configuration will be a single live cell, with density (number of constellations per unit area) approximately  . But the isolated cells all die off immediately. The second most common constellations,  with density , have two live cells. If the two cells are diagonally adjacent, they form a small oscillator, and if they are orthogonally adjacent, they form a replicator. The replicators will then grow either horizontally or vertically in both directions until they run into something, usually (but not always) another replicator. When two replicators collide, they tend to form a stable blob that blocks both of them. The one that was there first will usually (but not always) have copies of itself on both sides of the blob, so its line of copies stays more or less unchanged in place. The replicator that arrives second will usually (but not always) be blocked by the first replicator, and stay on one side of the collision point. And when replicators are bounded on both sides by stable blobs, they usually (but not always) turn into stable oscillators, continuing to fill the line they have already marked out. If all of the usual things always happened, we would get a Gilbert tessellation; instead, we get something that looks a lot like a Gilbert tessellation but with typically a constant number of oscillators in its rectangles and with occasional other differences from the expected behavior.</p>

<p>Could this happen for sparse initial conditions of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a>? Maybe!</p>

<p>In a sequence of papers from 1998 to his 2010 “<a href="https://doi.org/10.1007/978-1-84996-217-9_20">Emergent Complexity in Conway’s Game of Life</a>”, Nick Gotts has explored the behavior of random Life initial conditions, in the limit as the fill density  goes to zero. We don’t know what happens to these patterns in the long term, but we can say something rigorous about their behavior in the short and medium terms. Here, by “short term” I mean what happens after a constant number of steps, and by “medium term” I mean a number of steps that’s polynomial in  with a small-enough exponent.</p>

<p>Initially, near most points of the plane, the nearest objects will be isolated cells, spaced  units from each other (the inverse square root of their density). However, these immediately die off. So in the short term, the nearest objects will usually be “blonks” (blinkers and blocks, generated from initial constellations of three live cells), with density  and spacing . More widely scattered are gliders, either generated directly from constellations of five initial live cells, or from <a href="http://www.conwaylife.com/wiki/R-pentomino">R pentominos</a> which create a bounded number of gliders before stabilizing. Both possibilities give the gliders density . Even more widely scattered, at density , are the simplest patterns that produce infinite growth rather than stability or simple motion: the <a href="http://www.conwaylife.com/wiki/Block-laying_switch_engine">block-laying switch engines</a>, generated from initial constellations of ten live cells. These are puffer trains rather than replicators: they have a single live head that lays down a trail of blocks as it moves.</p>

<p>If the field stayed like this throughout the medium term, things would be boring. The gliders and switch engines would typically crash into blonks in  steps, in most cases stopping their motion. And so one might expect that at numbers of steps with higher exponents, most points would have only stable or low-period debris as their nearest live pattern. Occasionally there would be a trail of a crashed and dead switch engine but these would be very far apart, at a typical distance , compared to their typical length of . So from a high-level point of view, these trails would just look like randomly placed line segments rather than forming anything like a motorcycle graph or Gilbert tessellation.</p>

<p>However, what Gotts discovered is that something much more complicated and confusing happens. The gliders (with short-term density ) start crashing into blonks, but when they do they sometimes produce one or more new gliders. Those gliders, in turn, might crash into something else and produce even more gliders, perhaps including some that return to the previous crash site. Gotts defines a “standard collision sequence” to be a sequence of events of this type, involving a single initial glider and a widely scattered collection of blonks. There are finitely many different standard collision sequences that involve a given number  of initial blonks. Any one of these sequences can happen to a given glider with a probability that tends to a constant as the number of time steps goes to , the expected time for any glider to complete its collision sequence in the absence of interactions with the crash debris of other gliders.</p>

<p>But the crash debris starts to add up, preventing this analysis from actually staying valid all the way to that limiting point. In particular, some standard collision sequences can produce infinite growth patterns like the block-laying switch engine. If we ignored interactions with other gliders and just considered standard collision sequences, it would appear that the density of switch engines constructed in this way would approach  as the number of time steps went to , and therefore that the density of blocks in switch engine trails would approach , much more dense than the density of initial blonks. That can’t happen, and our analysis breaks down. What’s less clear and not rigorously proven is exactly how it breaks down.</p>

<p>One possibility for the breakdown is the following. Switch engines or other puffer engines start being produced in increasing density by standard collision sequences, and they start growing trails of blocks behind them. As their trails grow and the typical distance between the puffers shrinks, at some point these two distances cross over, and the trails become longer than the typical distance. This crossover distance is well below the  distance one would expect a puffer to travel before hitting an initial blonk. Once this happens, most puffers will crash into the trail of another puffer, and their trails will divide up space into something resembling a motorcycle graph. (It’s not a Gilbert tessellation, because each puffer starts out moving in a single direction.) The cells of this graph prevent anything else from moving across it, leading to eventual stabilization.</p>

<p>Another possibility is that some other pattern (perhaps initial or perhaps produced by a standard collision sequence) does something quickly enough to disrupt the creation of a motorcycle graph before it happens, or breaks through it after it is constructed. We don’t know what these patterns might look like, but we also don’t know that they don’t exist. Life patterns can do complicated things. Because so much is still unknown, what Gotts actually proves is more cautious: either infinite-growth patterns created from collision sequences eventually cause the total population to be significantly denser than its original density, or the infinite-growth patterns created through standard collision sequences will themselves become more dense than they were in the initial field.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101316148318254282"></a>, <a href="https://plus.google.com/100003628603413742554/posts/ehARHPdEkde">G+</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html"><span class="datestr">at December 27, 2018 05:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4043">Announcements</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I’m planning to be in Australia soon—in Melbourne January 4-10 for a friend’s wedding, then in Sydney January 10-11 to meet colleagues and give a talk.  It will be my first trip down under for 12 years (and Dana’s first ever).  If there’s interest, I might be able to do a <em>Shtetl-Optimized</em> meetup in Melbourne the evening of Friday the 4th (or the morning of Saturday the 5th), and/or another one in Sydney the evening of Thursday the 10th.  Email me if you’d go, and then we’ll figure out details.</p>



<p>The <a href="https://www.congress.gov/bill/115th-congress/house-bill/6227/text">National Quantum Initiative Act</a> is now law.  Seeing the photos of Trump signing it, I felt … well, whatever emotions you might imagine I felt.</p>



<p>Frank Verstraete asked me to announce that the University of Vienna is seeking a full professor in quantum algorithms; <a href="https://personalwesen.univie.ac.at/jobs-recruiting/professuren/detail-seite/news/quantum-algorithms-1/">see here</a> for details.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4043"><span class="datestr">at December 27, 2018 08:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/212">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/212">TR18-212 |  Constructing Faithful Homomorphisms over Fields of Finite Characteristic | 

	Prerona Chatterjee, 

	Ramprasad Saptharishi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the question of algebraic rank or transcendence degree preserving homomorphisms over finite fields. This concept was first introduced by Beecken, Mittmann and Saxena (Information and Computing, 2013), and exploited by them, and Agrawal, Saha, Saptharishi and Saxena (Journal of Computing, 2016) to design algebraic independence based identity tests using the Jacobian criterion over characteristic zero fields. An analogue of such constructions over finite characteristic fields was unknown due to the failure of the Jacobian criterion over finite characteristic fields.
Building on a recent criterion of Pandey, Sinhababu and Saxena (MFCS, 2016), we construct explicit faithful maps for some natural classes of polynomials in the positive characteristic field setting, when a certain parameter called the inseparable degree of the underlying polynomials is bounded (this parameter is always 1 in fields of characteristic zero). This presents the first generalisation of some of the results of Beecken et al. and Agrawal et al. in the positive characteristic setting.<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/212"><span class="datestr">at December 26, 2018 02:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16645">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">Amazing: Karim Adiprasito proved the g-conjecture for spheres!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg"><img src="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg?w=640&amp;h=853" alt="" height="853" class="alignnone size-full wp-image-12390" width="640" /></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Karim in his youth with a fan</span></p>
<p>Congratulations, Karim!</p>
<p><strong>Update</strong>: <a href="https://arxiv.org/abs/1812.10454">Here is the link to the paper</a></p>
<p><em>From the arXive, Dec 26, 2018. (Link will be added tomorrow.)</em></p>
<p>COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY</p>
<p>by Karim Adiprasito</p>
<p><strong>Abstract:</strong> Consider a simplicial complex that allows for an embedding into <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^d" class="latex" title="\mathbb R^d" />. How many faces of dimension <img src="https://s0.wp.com/latex.php?latex=d%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d/2" class="latex" title="d/2" /> or higher can it have? How dense can they be?</p>
<p>This basic question goes back to Descartes. Using it and other fundamental combinatorial<br />
problems, we will introduce a version of the Kähler package beyond positivity,<br />
allowing us to prove the Lefschetz theorem for toric varieties even when the ample<br />
cone is empty. A particular focus lies on replacing the Hodge-Riemann relations by a<br />
non-degeneracy relation at torus-invariant subspaces, allowing us to state and prove a<br />
generalization of the theorems of Hall and Laman in the setting of toric varieties. Of<br />
the many applications, we highlight two main applications, one because it is the most<br />
well-known, the other because it provided the most guiding light.</p>
<p>(1) We fully characterize the possible face numbers of simplicial spheres, resolving the<br />
so called <em>g</em>-conjecture of McMullen in full generality and generalizing Stanley’s<br />
earlier proof for simplicial polytopes.</p>
<p>(2) We prove that for a simplicial complex <em>K</em> that embeds into <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5E%7B2d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^{2d}" class="latex" title="\mathbb R^{2d}" />, the number of <em>d</em>-dimensional simplices exceeds the number of <em>(d − 1)</em>-dimensional simplices by a factor of at most <em>d + 2</em>. This generalizes a result of Descartes, and resolves the Grünbaum-Kalai-Sarkaria conjecture.</p>
<p>_______</p>
<p>(GK:) A few further comments. Probably the <em>g</em>-conjecture for spheres is the single problem I knock my head against the most. It is great to see it settled and it is even greater to see it settled by my friend and colleague Karim Adiprasito.</p>
<p>To the three ingredients of the standard conjectures (See also the <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">previous post</a>), Poincare duality <strong>(PD</strong>), Hard Lefschetz (<strong>HL</strong>) and Hodge-Riemann (<strong>HR</strong>), Karim adds the <strong>Hall-Laman relations</strong>. Very roughly, the Hall-Laman relations  substitute<strong> (HR)</strong> and apply genericity (rather than definiteness) toward <strong>(HL)</strong>.</p>
<p>(We still need a good acronym for Hall-Laman, maybe <strong>(AHL)</strong>.)</p>
<p>One very nice feature of Karim’s proof is that <strong>vertex decomposable</strong> spheres play a special role in the path toward the proof. Those were introduced by Provan and Billera in the context of the Hirsch conjecture.</p>
<p>We have devoted <a href="https://gilkalai.wordpress.com/tag/g-conjecture/">plenty of posts</a> to the <em>g</em>-conjecture for spheres, and mentioned it in <a href="https://gilkalai.wordpress.com/page/2/?s=g-conjecture">even more posts</a>.  For an introduction to the conjecture see <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">Eran Nevo introductory post</a>, and the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/" rel="bookmark">How the g-Conjecture Came About</a>. There is also plenty left to be done <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">beyond the g-conjecture</a>.</p>
<p><span style="color: #0000ff;">Merry X-mas and Happy new year 2019 to all our readers.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/"><span class="datestr">at December 25, 2018 02:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16429">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">ICM 2018 Rio (4): Huh; Balog &amp; Morris; Wormald</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p> </p>
<p>This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures related to combinatorics. I also met quite a few combinatorialists. As I mentioned in my <a href="https://gilkalai.wordpress.com/2012/11/17/a-few-mathematical-snapshots-from-india-icm2010/">ICM 2010 post</a>, one thing that I enjoyed was to unexpectedly meet some old friends and this also happened in Rio (maybe a little less compared to Hyderabad as I learned to expect the unexpected). I also had an irrational expectation to unexpectedly meet the <em>same</em> people that I met unexpectedly in India. It was a pleasure meeting  Tadeusz Januszkiewicz again   but I was irrationally disappointed not to bump again into <a href="http://www-ma4.upc.edu/~oserra">Oriol Serra</a> and Anna Llado whom I had met  by surprise in Hyderabad.</p>
<p>This post will be about the Monday afternoon Session in combinatorics. Let me mention that the <a href="https://www.youtube.com/channel/UCnMLdlOoLICBNcEzjMLOc7w">ICM 2018 You Tube channel</a> now contains high quality videos for plenary and invited talks (as well as discussion panels, public lectures, and various other activities). This is a valuable resource! Here is the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmVE7DUBxr4CFu4TNhiJM8Hj">combinatorics session playlist</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWQ9pIGF1ObG4Ag472sg2hm">CS session</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmXn3FrOaMN7ZVNqsY_fWDHw">probability and statistics</a> session, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmW5F1S9OGR6esa9XpTOTq6e">plenary lectures</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWTsHKdFtIP7H2zsvwI0Uq4">public lectures</a>. Also, here is the most recent version of my ICM paper <a href="https://gilkalai.files.wordpress.com/2018/12/icm-draft-Dec-2018.pdf">THREE PUZZLES ON MATHEMATICS, COMPUTATION, AND GAMES</a>. Last minute corrections and comments are most welcome.</p>
<h1>Monday’s afternoon combinatorics</h1>
<p>The Monday afternoon combinatorics session featured three lectures that knocked my socks off. The talks were great and I was in a perfect position to enjoy them as I knew something about the problems and some related results  and yet each lecture surprised me.  The three talks were <span id="eow-title" class="watch-title" dir="ltr" title="Combinatorial applications of the Hodge–Riemann relations – June Huh – ICM2018"><a href="https://youtu.be/ceGEZdjnxRw">Combinatorial applications of the Hodge–Riemann relations</a> </span>by June Huh, <span class="watch-title" dir="ltr" title="The method of hypergraph containers – József Balogh &amp; Robert Morris – ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> by József Balogh &amp; Robert Morris,  </span><span id="eow-title" class="watch-title" dir="ltr" title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a> by Nicholas Wormald. Bella Bollobas chaired the session and gave a very nice and thoughtful introduction to each of the four speakers.</span></p>
<p><span id="eow-title" class="watch-title" dir="ltr" title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018"> </span></p>
<h2>June Huh, and the Lefschetz package in combinatorics</h2>
<p></p>
<blockquote><p><strong><span style="color: #ff0000;">June Huh: The standard conjectures are both ubiquitous and fundamental</span></strong></p></blockquote>
<p class="watch-title-container"><a href="https://youtu.be/ceGEZdjnxRw"><span id="eow-title" class="watch-title" dir="ltr" title="Combinatorial applications of the Hodge–Riemann relations – June Huh – ICM2018">Combinatorial applications of the Hodge–Riemann relations</span></a></p>
<p>June Huh talked about a mysterious package of conjectures (PD), (HL) and (HR), referred to as the standard conjectures,  for certain algebras associated with geometric and combinatorial objects. PD stands for the Poincare Duality, and it asserts that certain vector spaces <img src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i" class="latex" title="A_i" /> and <img src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{d-i}" class="latex" title="A_{d-i}" /> are dual. HD stands for Hard Lefschetz and it asserts that certain linear maps <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi_k" class="latex" title="\phi_k" /> from <img src="https://s0.wp.com/latex.php?latex=A_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k" class="latex" title="A_k" /> to <img src="https://s0.wp.com/latex.php?latex=A_k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k+1" class="latex" title="A_k+1" />  have the property that their composition from <img src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i" class="latex" title="A_i" /> all the way to <img src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{d-i}" class="latex" title="A_{d-i}" /> is an injection. (HR) stands for Hodge Riemann relations. (PD) and (HD) imply that a certain bilinear form  is nondegenerate and (HR) is a stronger statement that this form is definite!</p>
<p>June started with some startling applications of the Hard-Lefschetz theorem in combinatorics pioneered by Stanley. He then mentioned a startling new application with Wang: Consider <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points spanning a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional space.  Let <img src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_i" class="latex" title="w_i" /> be the number of flats of dimension <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> spanned by the point.  Motzkin  conjectured in 1936 and proved over the reals that  <img src="https://s0.wp.com/latex.php?latex=w_1+%5Cle+w_d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_1 \le w_d" class="latex" title="w_1 \le w_d" />. The planar case follows from the classic Erdos deBruijn theorem. Hu and Wang used {HL} to prove <img src="https://s0.wp.com/latex.php?latex=w_i+%5Cle+w_d-i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_i \le w_d-i" class="latex" title="w_i \le w_d-i" />, <img src="https://s0.wp.com/latex.php?latex=i+%5Cle+%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \le [d/2]" class="latex" title="i \le [d/2]" /> which was conjectured by Dowling and Wilson.</p>
<p>Next came applications of (HR), starting with Huh’s proof of the log concavity of coefficients of chromatic polynomials for graphs (Read conjecture ) and the far-reaching extension by Adiprasito-Huh-Kats to general matroids (Rota’s conjecture). We mentioned the Adiprasito-Huh-Katz solution of the Rota-Heron conjecture in <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">the previous post</a> and in <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">this one</a>.</p>
<p>Here is the link to the ICM paper by June Huh: <a href="https://arxiv.org/abs/1711.11176">Combinatorial applications of the Hodge-Riemann relations</a>.</p>
<p> </p>
<h2>József Balogh and Rob Morris and the container method</h2>
<p></p>
<p><span class="watch-title" dir="ltr" title="The method of hypergraph containers – József Balogh &amp; Robert Morris – ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> </span></p>
<p>The container theorem for hypergraphs is one of the most important tools in extremal combinatorics with many applications also to random graphs and hypergraphs, additive combinatorics, discrete geometry, and more.</p>
<p>Rob Morris explained the container theorem for triangle-free graphs. It asserts that there is a collection <img src="https://s0.wp.com/latex.php?latex=%5Ccal+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cal C" class="latex" title="\cal C" /> of graphs on <img src="https://s0.wp.com/latex.php?latex=n+vertices&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n vertices" class="latex" title="n vertices" /> with the following three properties:</p>
<p>(1) Every graph in the collection contains <img src="https://s0.wp.com/latex.php?latex=o%28n%5E3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="o(n^3)" class="latex" title="o(n^3)" /> triangles,</p>
<p>(2) The number of graphs in the collection is <img src="https://s0.wp.com/latex.php?latex=n%5E%7BC+%5Ccdot+3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^{C \cdot 3/2}" class="latex" title="n^{C \cdot 3/2}" />,</p>
<p>(3) Each triangle free graph is contained in a graph in the collection.</p>
<p>Rob explained the origins of this theorem, how it follows from a container theorem for 3-uniform hypergraphs,   and how the later extends to the very general and important container theorem for <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-uniform hypergraphs that was achieved in 2012 independently by Saxton and Thomason (Here is the link to <a href="https://arxiv.org/abs/1204.6595">their paper</a>), and by Balogh, Morris, and Samotij (Here is a link to <a href="https://arxiv.org/abs/1204.6530">their paper</a>).</p>
<p>Jozsef Balogh described two consequences of the container theorem to additive combinatorics and to discrete geometry. Let me describe the result in discrete geometry by Balogh and Solymosi. The (4,3) problem ask for the size $\alpha (n)$ of the largest subset of points in general position (no three on a line) that can always be found in a planar configuration of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points with the property that no four points lie on a line. The container method is used to show (surprisingly!) that <img src="https://s0.wp.com/latex.php?latex=%5Calpha%28n%29%3Dn%5E%7B5%2F6%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha(n)=n^{5/6+o(1)}" class="latex" title="\alpha(n)=n^{5/6+o(1)}" /> .</p>
<p>For a recent beautiful application to <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(p,q)" class="latex" title="(p,q)" />-Helly type theorems see <a href="https://arxiv.org/abs/1809.06451">A new lower bound on Hadwiger-Debrunner numbers in the plane</a> by Chaya Keller and Shakhar Smorodinsky.</p>
<p>Here is a link to the ICM survey paper: <a href="https://arxiv.org/abs/1801.04584">The method of hypergraph containers</a>, by József Balogh, Robert Morris, and Wojciech Samotij</p>
<p>(In a previous post  <a href="https://gilkalai.wordpress.com/2015/01/20/midrasha-mathematicae-18-in-and-around-combinatorics/" rel="bookmark">Midrasha Mathematicae #18: In And Around Combinatorics, </a>we gave links to a series of lectures Wojiech Samotij: Toward the hypergraph “container” theorem (4 lectures) <a href="https://www.youtube.com/watch?v=SpAyBN4rccU">Video 1, </a><a href="http://youtu.be/N6rP1yUcE0M">video 2</a> <a href="https://www.youtube.com/watch?v=cSFfKhcyN14">video 3</a> <a href="https://www.youtube.com/watch?v=efVlsmiws-I">video 4</a>.)</p>
<h2>Nick Wormald and counting regular graphs.</h2>
<p></p>
<p><span id="eow-title" class="watch-title" dir="ltr" title="Asymptotic enumeration of graphs with given degree sequence – Nicholas Wormald – ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a></span></p>
<p>How many <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-regular graphs are there? This is a very central problem in combinatorics and Nick Wormald was quite interested in its solution ever since his Ph. D.  The talk describes the early history of the problem, the early works by Wormald and McKay from the 90s,  the recent breakthrough by Antia Liebenau and Nick Wormald,  the techniques involved in the old and new proofs and some related results.</p>
<p>A good place to start is with Read’s 1958 formula for the number <img src="https://s0.wp.com/latex.php?latex=g_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_3(n)" class="latex" title="g_3(n)" /> of 3-regular graphs with n labelled vertices</p>
<p><img src="https://s0.wp.com/latex.php?latex=g_3%28n%29+%5Csim+%283n%29%21+e%5E%7B-2%7D%2F%283n%2F2%29%21288%5E%7Bn%2F2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." class="latex" title="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." /></p>
<p>Following an important model of Bollobas for creating regular graphs, general formulas were developed for low degrees, By McKay, McKay and Wormald, and others that depend on the probability of a random graph in Bollobas’ model to be simple. (See pictures below). Some results were proven also for the high degree regime and McKay and Wormald gave in 1990 and 1997 unified conjectural formulas for the number of <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular graphs for a wide range of parameters. Moreover these conjectures extend to a large range of vectors of degree sequences.</p>
<p>In 2017 Anita Liebenau and Nick Wormald proved all these conjectures!!! (<a href="https://arxiv.org/abs/1702.08373">Here is a link to the paper</a>.)</p>
<p>The formula for the behavior of the number of <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular graphs with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vertices is remarkably elegant</p>
<p><img src="https://s0.wp.com/latex.php?latex=e%5E%7B1%2F4%7D%5Csqrt%7B2%7Dd%5Ed%28n-1-d%29%5E%7Bn-1-d%7D%28n-1%29%5E%7B-%28n-1%29%7D%7B%7Bn-1%7D+%5Cchoose+%7Bd%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" class="latex" title="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" />.</p>
<p>The full result is very general, and the method extends further in various directions.</p>
<p>Here is the link to paper: <a href="https://arxiv.org/abs/1702.08373">Asymptotic enumeration of graphs by degree sequence, and the degree sequence of a random graph</a>, by Anita Liebenau and Nick Wormald.</p>
<h3>A bit psychedelic pictures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg"><img src="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg?w=300&amp;h=225" alt="" height="225" class="alignnone size-medium wp-image-16681" width="300" /></a>    <a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg"><img src="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg?w=300&amp;h=225" alt="" height="225" class="alignnone size-medium wp-image-16682" width="300" /></a></p>
<p>With Nick Wormald and Yoshi Kohayakawa just before my lecture.</p>
<h2>Some important pictures from the Session</h2>
<h3>Bela Bollobas</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/bela.png"><img src="https://gilkalai.files.wordpress.com/2018/12/bela.png?w=640" alt="" class="alignnone size-full wp-image-16650" /></a></p>
<p><span style="color: #ff0000;">Bela Bollobas served as the session chair</span></p>
<h3>Nick Wormald on enumeration of regular graphs</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W2.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W2.png?w=640&amp;h=406" alt="" height="406" class="alignnone size-full wp-image-16660" width="640" /></a></p>
<p><span style="color: #ff0000;">Read’s formula and Bollobas model.</span></p>
<p><img src="https://gilkalai.files.wordpress.com/2018/12/W3.png?w=640&amp;h=368" alt="" height="368" class="alignnone size-full wp-image-16661" width="640" /></p>
<p><span style="color: #ff0000;">Formulas by McKay and McKay-Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W4.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W4.png?w=640&amp;h=352" alt="" height="352" class="alignnone size-full wp-image-16662" width="640" /></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W5.png?w=640&amp;h=370" alt="" height="370" class="alignnone size-full wp-image-16663" width="640" /></a></p>
<p><span style="color: #ff0000;">General conjectures (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W6.png?w=640&amp;h=365" alt="" height="365" class="alignnone size-full wp-image-16664" width="640" /></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W7.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W7.png?w=640&amp;h=353" alt="" height="353" class="alignnone size-full wp-image-16665" width="640" /></a></p>
<p><span style="color: #ff0000;">The Theorem by Liebenau and Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W8.png"><img src="https://gilkalai.files.wordpress.com/2018/12/W8.png?w=640&amp;h=356" alt="" height="356" class="alignnone size-full wp-image-16666" width="640" /></a></p>
<p> </p>
<h3>Balogh and Morris on containers</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers1.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers1.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16614" width="640" /></a></p>
<p><span style="color: #ff0000;">The Container theorem for triangle-free graphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers2.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers2.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16615" width="640" /></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem for 3-uniform hypergraphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container3.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container3.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16616" width="640" /></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem in full generality.</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container4.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container4.png?w=640&amp;h=371" alt="" height="371" class="alignnone size-full wp-image-16653" width="640" /></a></p>
<p><span style="color: #ff0000;">An application for the number of subsets of integers without k-term arithmetic progressions.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers5.png?w=640&amp;h=348" alt="" height="348" class="alignnone size-full wp-image-16654" width="640" /></a></p>
<p><span style="color: #ff0000;">What was known and expected on the (4,3) problem (above) and the new breakthrough (below)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers6.png?w=640&amp;h=368" alt="" height="368" class="alignnone size-full wp-image-16655" width="640" /></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers7.png"><img src="https://gilkalai.files.wordpress.com/2018/12/containers7.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16656" width="640" /></a></p>
<p><span style="color: #ff0000;">Applications of the container method</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container8.png"><img src="https://gilkalai.files.wordpress.com/2018/12/container8.png?w=640&amp;h=332" alt="" height="332" class="alignnone size-full wp-image-16690" width="640" /></a></p>
<h3>June Huh on the standard conjectures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16607" width="640" /></a></p>
<p><span style="color: #ff0000;">Five seemingly unrelated mathematical objects</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16609" width="640" /></a></p>
<p><span style="color: #ff0000;">Poincare duality (PD), Hard Lefschetz (HL), and Hodge Riemann (HR).</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16610" width="640" /></a></p>
<p><span style="color: #ff0000;">A 1964 letter from Serre to Grothendieck on young Bombieri</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16611" width="640" /></a></p>
<p><span style="color: #ff0000;">The algebraic setting for the standard conjectures. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png"><img src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png?w=640&amp;h=360" alt="" height="360" class="alignnone size-full wp-image-16612" width="640" /></a></p>
<p><span style="color: #ff0000;">Five cases were the standard conjectures are known and the original open case.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/"><span class="datestr">at December 24, 2018 08:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7021">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/">Introduction to Quantum Walks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<hr class="wp-block-separator" />



<p>author: Beatrice Nash</p>



<p>Abstract</p>



<p>In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks based algorithms for certain applications.</p>



<h1>Continuous time quantum walks</h1>



<p>We begin our discussion of quantum walks by introducing the quantum analog of the continuous random walk. First, we review the behavior of the classical continuous random walk in order to develop the definition of the continuous quantum walk.</p>



<p>Take a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> with vertices <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and edges <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" />. The adjacency matrix <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is defined as follows:</p>



<p><img src="https://s0.wp.com/latex.php?latex=A_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" title="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" /></p>



<p>And the Laplacian <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> is given by:</p>



<p><img src="https://s0.wp.com/latex.php?latex=L_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+-%5Ctext%7Bdegree%7D%28i%29+%5Cquad+%26%5Ctext%7Bif+++%7D++i+%3D+j+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" title="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" /></p>



<p>The Laplacian determines the behavior of the classical continuous random walk, which is described by a length <img src="https://s0.wp.com/latex.php?latex=%7CV%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|V|" class="latex" title="|V|" /> vector of probabilities, <strong>p</strong>(t). The <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th entry of <strong>p</strong>(t) represents the probability of being at vertex <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. <strong>p</strong>(t) is given by the following differential equation:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Ctext%7Bp%7D_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Ctext%7Bp%7D_%7Bj%7D%28%5Ctext%7Bt%7D%29%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" class="latex" title="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" /></p>



<p>which gives the solution <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bp%7D%28t%29+%3D+e%5E%7BLt%7D%5Ctextbf%7Bp%7D%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" class="latex" title="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" />.</p>



<p>Recalling the Schrödinger equation <img src="https://s0.wp.com/latex.php?latex=i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cleft%7C%5Cpsi%5Cright%3E%3D+H+%5Cleft%7C%5Cpsi%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" class="latex" title="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" />, one can see that by inserting a factor of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> on the left hand side of the equation for <strong>p</strong>(t) above, the Laplacian can be treated as a Hamiltonian. One can see that the Laplacian preserves the normalization of the state of the system. Then, the solution to the differential equation:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cpsi_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Cpsi_%7Bj%7D%28%5Ctext%7Bt%7D%29%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" class="latex" title="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" />,</p>



<p>which is <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%28t%29%5Cright%3E+%3D+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" class="latex" title="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" />, determines the behavior of the quantum analog of the continuous random walk defined previously. A general quantum walk does not necessarily have to be defined by the Laplacian; it can be defined by any operator which “respects the structure of the graph,” that is, only allows transitions to between neighboring vertices in the graph or remain stationary [7]. To get a sense of how the behavior of the quantum walk differs from the classical one, we first discuss the example of the continuous time quantum walk on the line, before moving on to the discrete case.</p>



<h2>Continuous time quantum walk on the line</h2>



<p>An important example of the continuous time quantum walk is that defined on the infinite line. The eigenstates of the Laplacian operator for the graph representing the infinite line are the momentum states with eigenvalues <img src="https://s0.wp.com/latex.php?latex=2%28%5Ctext%7Bcos%7D%28p%29+-+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2(\text{cos}(p) - 1)" class="latex" title="2(\text{cos}(p) - 1)" />, for <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> in range <img src="https://s0.wp.com/latex.php?latex=%5B-%5Cpi%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-\pi,\pi]" class="latex" title="[-\pi,\pi]" />. This can be seen by representing the momentum states in terms of the position states and applying the Laplacian operator:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+L%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%2B1%5Cright%3E%2B+e%5E%7Bipx%7D+%5Cleft%7Cx-1%5Cright%3E+-+2e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+%28e%5E%7Bip%7D+%2B+e%5E%7B-ip%7D+-+2%29+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+2%28%5Ctext%7Bcos%7D%28p%29+-+1%29+%5Cleft%7Cp%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" /></p>



<p>Hence the probability distribution at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, <img src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%7C+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" class="latex" title="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" />, with initial position <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \left|0\right&gt;" /> is given by:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C0%5Cright%3E+%7C+%5E%7B2%7D+%26%3D++%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+%5Cleft%3C+x%7Cp%5Cright%3E+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+e%5E%7Bipx%7D+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%7C+J_%7Bx%7D%282t%29+%7C%5E%7B2%7D.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" class="latex" title="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" /></p>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/quantum-1.png?w=451" alt="" class="wp-image-7071" width="451" />Figure 1.a) Probability distribution for continuous time quantum walk on the infinite line at time <img src="https://s0.wp.com/latex.php?latex=t+%3D+80&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 80" class="latex" title="t = 80" />.</figure>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/classical-1.png?w=451&amp;h=300" alt="" height="300" class="wp-image-7073" width="451" /><br />Figure 1.b) Approximate probability<br /> distribution of the continuous time random walk on the infinite line at<br /> time <img src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=30" class="latex" title="t=30" />.<br /></figure>



<p>While the probability distribution for the classical continuous time<br /> random walk on the same graph approaches, for large <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B4%5Cpi+t%7D%7D+e%5E%7B%5Cfrac%7B-x%5E%7B2%7D%7D%7B4t%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" class="latex" title="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" />, or a Gaussian of width <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\sqrt{t}" class="latex" title="2\sqrt{t}" />. One can see that the quantum walk has its largest peaks at the extrema, with oscillations in between that decrease in amplitude as one approaches the starting position at <img src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=0" class="latex" title="x=0" />. This is due to the destructive interference between states of different phases that does not occur in the classical case. The probability distribution of the classical walk, on the other hand, has no oscillations and instead a single peak centered at <img src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=0" class="latex" title="x=0" />, which widens and flattens as <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> increases.</p>



<h2>Walk on the glued trees graph</h2>



<p>A <em>glued tree</em> is a graph obtained by taking two binary trees of equal height and connecting each of the leaves of one of the trees to exactly two leaves of the other tree so that each node that was a leaf in one of the original trees now has degree exactly <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />. An example of such a graph is shown in Figure 2.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/glued-1.png?w=1024" alt="" class="wp-image-7077" />Figure 2: An example of a glued tree graph, from [2].</figure>



<p>The time for the quantum walk on this graph to reach the right root from the left one is exponentially faster than in the classical case. Consider the classical random walk on this graph. While in the left tree, the probability of transitioning to a node in the level one to the right is twice that of transitioning to a node in the level one to the left. However, while in the right tree, the opposite is true. Therefore, one can see that in the middle of the graph, the walk will get lost, as, locally, there is no way to determine which node is part of which tree. It will instead get stuck in the cycles of identical nodes and will have exponentially small probability of reaching the right node.</p>



<p>To construct a continuous time quantum walk on this graph, we consider the graph in terms of <em>columns</em>. One can visualize the columns of Figure 2 as consisting of all the nodes equidistant from the entrance and exit nodes. If each tree is height <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, then we label the columns <img src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Ctext%7B...%7D%2C2n%2C2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0,1,\text{...},2n,2n+1" class="latex" title="0,1,\text{...},2n,2n+1" />, where column <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> contains the nodes with shortest path of length <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> from the leftmost root node. We describe the state of each column as a superposition of the states of each node in that column. The number of nodes in column <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, <img src="https://s0.wp.com/latex.php?latex=N_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N_{i}" class="latex" title="N_{i}" />, will be <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{i}" class="latex" title="2^{i}" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B0%2Cn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [0,n]" class="latex" title="i \in [0,n]" /> and <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%2B1-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2n+1-i}" class="latex" title="2^{2n+1-i}" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B1%2C2n%2B1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n+1,2n+1]" class="latex" title="i \in [n+1,2n+1]" />. Then, we can define the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\text{col} \; i\right&gt;" class="latex" title="\left|\text{col} \; i\right&gt;" /> as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cunderset%7Bj+%5Cin+%5Ctext%7Bcol%7D+%5C%3B+i%7D%7B%5Csum%7D+%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" /></p>



<p>The factor of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{N_{i}}} " class="latex" title="\frac{1}{\sqrt{N_{i}}} " />latex  ensures that the state is normalized. Since the adjacency matrix <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of the glued tree is Hermitian, then we can treat <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> as the Hamiltonian of the system determining the behavior of the quantum walk. By acting on this state with the adjacency matrix operator <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />, we get the result (for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B1%2Cn-1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [1,n-1]" class="latex" title="i \in [1,n-1]" />):</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E++%26%3D+2%5Cfrac%7B%5Csqrt%7BN_%7Bi-1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Cfrac%7B%5Csqrt%7BN_%7Bi%2B1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E+%5C%5C+%26%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" /><br /></p>



<p>Then for <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B2%2C2n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n+2,2n]" class="latex" title="i \in [n+2,2n]" />, we get the same result, because of symmetry.<br /></p>



<p>For <img src="https://s0.wp.com/latex.php?latex=i+%3D+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = n" class="latex" title="i = n" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E+%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3Bn-1%5Cright%3E+%2B+2+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" /></p>



<p>The case of <img src="https://s0.wp.com/latex.php?latex=i+%3D+n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = n+1" class="latex" title="i = n+1" /> is symmetric. One can see that the walk on this graph is equivalent to the quantum walk on the finite line with nodes corresponding to the columns. All of the edges, excluding that between columns <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" />, have weight <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sqrt{2}" class="latex" title="\sqrt{2}" />. The edge between column <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" /> has weight <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />.</p>



<p>The probability distribution of the quantum walk on this line can be roughly approximated using the infinite line. In the case of the infinite line, the probability distribution can be seen as a wave propagating with speed linear in the time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. Thus, in time linear in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, the probability that the state is measured at distance <img src="https://s0.wp.com/latex.php?latex=2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2n+1" class="latex" title="2n+1" /> from the starting state is <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D+%5C%3B+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\text{poly} \; n}" class="latex" title="\frac{1}{\text{poly} \; n}" />. In [3] it is shown that the fact that the line is finite and has a single differently weighted edge from the others (that between <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" />) does not change the fact that in polynomial time, the quantum walk will travel from the left root node to the right one, although in this case there is no limiting distribution as the peaks oscillate. This was the first result that gives an exponential speed up over the classical case using quantum walks.</p>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/glued-tree-1.png?w=451&amp;h=291" alt="" height="291" class="wp-image-7082" width="451" />Figure 3: Although the quantum walk on the glued trees graph does not have a limiting distribution, this is an example of the resulting probability distribution at time <img src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=30" class="latex" title="t=30" /> for a <img src="https://s0.wp.com/latex.php?latex=n%3D4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n=4" class="latex" title="n=4" /> column glued tree graph.  The x-axis corresponds to the columns.  One can see that the probability of being at the columns at either extremes is significantly larger than that of being in the middle of the graph. In contrast, the classical random walk takes exponential time to ever reach the exit root node.</figure>



<h1>Discrete time quantum walks</h1>



<p>In this section, we will first give an introduction to the discrete quantum walk, including the discrete quantum walk on the line and the Markov chain quantum walk, as defined in [7]. Next, we discuss how Grover search can be viewed as a quantum walk algorithm, which leads us into Ambainis’s quantum-walks based algorithm from [1] for the element distinctness problem, which gives a speed up over classical and other quantum non-walks based algorithms.</p>



<p>The discrete time quantum walk is defined by two operators: the <em>coin flip</em> operator, and the <em>shift</em> operator. The coin flip operator <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> determines the direction of the walk, while the shift operator <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> makes the transition to the new state conditioned on the result of the coin flip. The Hilbert space governing the walk is <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D%7BC%7D+%5Cotimes+%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" class="latex" title="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}{C}" class="latex" title="\mathcal{H}{C}" /> corresponds to the space associated with the result of the coin flip operator, and <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}{S}" class="latex" title="\mathcal{H}{S}" /> corresponds to the locations in the graph on which the walk is defined.</p>



<p>For example, consider the discrete time walk on the infinite line. Since there are two possible directions (left or right), then the Hilbert space associated with the coin flip operator is two dimensional. In the unbiased case, the coin flip is the Hadamard operator,</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bbmatrix%7D+1+%26+1+%5C%5C+1+%26+-1++%5Cend%7Bbmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" class="latex" title="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" /></p>



<p>and shift operator that produces the transition from state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j\right&gt;" class="latex" title="\left|j\right&gt;" /> to <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j+1\right&gt;" class="latex" title="\left|j+1\right&gt;" /> or <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|j-1\right&gt;" class="latex" title="\left|j-1\right&gt;" />,<br /> conditioned on the result of the coin flip, is <img src="https://s0.wp.com/latex.php?latex=S+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%3C+0%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj%2B1%5Cright%3E+%5Cleft%3C+j%5Cright%7C+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%3C+1%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj+-+1%5Cright%3E+%5Cleft%3C+j%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" class="latex" title="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" />.</p>



<p>Each step of the walk is determined by an application of the unitary<br /> operator <img src="https://s0.wp.com/latex.php?latex=U+%3D+S+%5Ccdot+%28H+%5Cotimes+I%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = S \cdot (H \otimes I)" class="latex" title="U = S \cdot (H \otimes I)" />. If the walk starts at position<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x\right&gt;" class="latex" title="\left|x\right&gt;" />, then measuring the state after one application of <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> gives <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x+1\right&gt;" class="latex" title="\left|x+1\right&gt;" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2}" class="latex" title="\frac{1}{2}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|x-1\right&gt;" class="latex" title="\left|x-1\right&gt;" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2}" class="latex" title="\frac{1}{2}" />. This is exactly the same as the case of the classical random walk on the infinite line; the difference between the two walks becomes apparent after a few steps.</p>



<p>For example, the result of the walk starting at state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" /> after 4 steps gives:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+3%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E-%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" title="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" /></p>



<p>One can see that the distribution is becoming increasingly skewed<br /> towards the right, while in the classical case the distribution will be<br /> symmetric around the starting position. This is due to the destructive<br /> interference discussed earlier. The distribution after <img src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 20" class="latex" title="t = 20" /> time<br /> steps is shown in Figure 4.</p>



<figure class="wp-block-image is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/discrete.png?w=451&amp;h=291" alt="" height="291" class="wp-image-7090" width="451" />Figure 4: Distribution at time <img src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = 20" class="latex" title="t = 20" />, with <img src="https://s0.wp.com/latex.php?latex=20&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="20" class="latex" title="20" /> on the x-axis corresponding to position <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />.</figure>



<p>Now, consider the walk starting at state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-3%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" title="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" /></p>



<p><br /> This distribution given by this walk is the mirror image of the first.<br /> To generate a symmetric distribution, consider the start state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%5Cleft%7C0%5Cright%3E+-i%5Cleft%7C1%5Cright%3E%29%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" class="latex" title="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" />. The resulting distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps will be <img src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%5Cfrac%7B1%7D%7B2%7D+p_%7B0%7D%28x%2Ct%29+%2B+%5Cfrac%7B1%7D%7B2%7D+p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" class="latex" title="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" />, where <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}(x,t)" class="latex" title="p_{0}(x,t)" /> is the probability distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps resulting from the start state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi(0) = \left|0\right&gt;\left|0\right&gt;" class="latex" title="\psi(0) = \left|0\right&gt;\left|0\right&gt;" /> and <img src="https://s0.wp.com/latex.php?latex=p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{1}(x,t)" class="latex" title="p_{1}(x,t)" /> is the probability distribution after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps resulting from the start state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" class="latex" title="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" />. The result will be symmetric, with peaks near the extrema, as we saw in the continuous case.</p>



<h2>Markov chain quantum walk</h2>



<p>A reversible, ergodic Markov chain with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> states can be represented by a <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \times n" class="latex" title="n \times n" /> transition matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> with <img src="https://s0.wp.com/latex.php?latex=P_%7Bj%2Ci%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{j,i}" class="latex" title="P_{j,i}" /> equal to the probability of transitioning from state <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> to state <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=P+%3D+P%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P = P^{*}" class="latex" title="P = P^{*}" />. Then, <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}P" class="latex" title="p_{0}P" />, where <img src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{0}" class="latex" title="p_{0}" /> is an initial probability distribution over the states, gives the distribution after one step.<br />Since <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bj%7D+P_%7Bi%2Cj%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{j} P_{i,j} = 1" class="latex" title="\sum_{j} P_{i,j} = 1" /> for all <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is stochastic and thus preserves normalization.</p>



<p>There are multiple ways to define a discrete quantum walk, depending on the properties of the transition matrix and the graph on which it is defined (overview provided in [4]). Here we look at the quantum walk on a Markov chain as given in [2]. For the quantum walk on this graph, we define state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|i\right&gt;\left|j\right&gt;" class="latex" title="\left|i\right&gt;\left|j\right&gt;" /> as the state that represents currently being at position <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and facing in the direction of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />. Then, we define the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi_%7Bj%7D%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi_{j}\right&gt;" class="latex" title="\left|\psi_{j}\right&gt;" /> as a superposition of the states associated with position <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E+%3D+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Csqrt%7BP_%7Bj%2Ci%7D%7D+%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" class="latex" title="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" /></p>



<p>The unitary operator,</p>



<p><img src="https://s0.wp.com/latex.php?latex=D+%3D+2+%5Cunderset%7Bi%7D%7B%5Csum%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E%5Cleft%3C+%5Cpsi_%7Bi%7D%5Cright%7C+-+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" class="latex" title="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" />,</p>



<p>acts as a coin flip for the walk on this graph. Since <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is reversible, we can let the shift operator be the unitary <img src="https://s0.wp.com/latex.php?latex=SWAP&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SWAP" class="latex" title="SWAP" /> operator:</p>



<p><img src="https://s0.wp.com/latex.php?latex=SWAP+%3D+%5Cunderset%7Bi%2Cj%7D%7B%5Csum%7D+%5Cleft%7Ci%2Cj%5Cright%3E%5Cleft%3C+j%2Ci%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" class="latex" title="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" />.</p>



<p>A quantum walk can also be defined for a non-reversible Markov chain using a pair of reflection operators (the coin flip operator is an example of a reflection operator). This corresponds to the construction given in [7].</p>



<h2>Search as a quantum walk algorithm</h2>



<p>Given a black box function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> and a set of inputs <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> with <img src="https://s0.wp.com/latex.php?latex=%7CS%7C+%3D+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|S| = N" class="latex" title="|S| = N" />, say we want to find whether an input <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in S" class="latex" title="x \in S" /> exists for which <img src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x)" class="latex" title="f(x)" /> equals some output value. We refer to the set of inputs <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> for which this is true as marked. Classically, this requires <img src="https://s0.wp.com/latex.php?latex=O%28N%2F%7CM%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N/|M|)" class="latex" title="O(N/|M|)" /> queries, for nonempty <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" />. Using the Grover search algorithm, this problem requires <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" /> quantum queries. In this section, we give a quantum walks based algorithm that also solves this problem in <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" /> time. If we define a doubly stochastic matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> with uniform transitions, then we can construct a new transition matrix <img src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P'" class="latex" title="P'" /> from <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=P_%7Bi%2Cj%7D%27+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B1%7D%7BN-1%7D+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cin+M+%5C%5C+0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cin+M.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" class="latex" title="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" /></p>



<p>Then, when the state of the first register is unmarked, the operator <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> defined in the previous section acts as a diffusion over its neighbors. When the state in the first register is marked, then <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> will act as the operator <img src="https://s0.wp.com/latex.php?latex=-I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-I" class="latex" title="-I" />, and the walk stops, as a marked state has been reached. This requires two queries to the black box function: one to check whether the input is marked, and then another to uncompute. By rearranging the order of the columns in <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> so that the columns corresponding to the non-marked elements come before the columns corresponding to the marked elements, we get:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%27+%3D+%5Cbegin%7Bpmatrix%7D+P_%7B0%7D+%26+0+%5C%5C+P_%7B1%7D+%26+I+%5Cend%7Bpmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" class="latex" title="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" /></p>



<p>where <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" /> gives the transitions between non-marked elements and <img src="https://s0.wp.com/latex.php?latex=P_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{1}" class="latex" title="P_{1}" /> gives the transitions from non-marked to marked elements.</p>



<p>We now look at the hitting time of the classical random walk. Assume<br /> that there is zero probability of starting at a marked vertex. Then, we<br /> can write the starting distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, where the last <img src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|M|" class="latex" title="|M|" /> elements of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, corresponding to the marked elements, are zero, as<br /> <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5Cunderset%7B%5Clambda%7D%7B%5Csum%7D+%5Calpha_%7B%5Clambda%7D+%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" class="latex" title="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" />, where <img src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda" class="latex" title="\lambda" /> are the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" />, and <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\lambda\right&gt;" class="latex" title="\left|\lambda\right&gt;" /> are the corresponding eigenvectors, with the last <img src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|M|" class="latex" title="|M|" /> entries zero. Let <img src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda^{}" class="latex" title="\lambda^{}" /> be the principal (largest) eigenvalue. Then, the probability that, after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> steps, a marked element has not yet been reached will be <img src="https://s0.wp.com/latex.php?latex=%5Csum+%28P_%7B0%7D%5E%7Bt%7Dp%29_%7Bi%7D+%5Cleq+%5Clambda%5E%7B%2At%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" class="latex" title="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" />. Then, the<br /> probability that a marked element has been reached in that time will be<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+1+-+%5Clambda%5E%7Bt%7D+%5Cgeq+1+-+t+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" class="latex" title="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" />. Setting<br /> <img src="https://s0.wp.com/latex.php?latex=t+%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t = \frac{1}{1-\lambda^{*}}" class="latex" title="t = \frac{1}{1-\lambda^{*}}" /> gives probability <img src="https://s0.wp.com/latex.php?latex=%5COmega%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega(1)" class="latex" title="\Omega(1)" /> that a marked element will be reached in that time.</p>



<p>The eigenvalues of <img src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_{0}" class="latex" title="P_{0}" /> will be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{N-|M|-1}{N-1}" class="latex" title="\frac{N-|M|-1}{N-1}" /> and<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B-1%7D%7BN-%7CM%7C-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{-1}{N-|M|-1}" class="latex" title="\frac{-1}{N-|M|-1}" />. Then, the classical hitting time will be:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t+%26%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B1-%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D%7D+%5C%5C+%26%3D+O%5Cleft%28%5Cfrac%7BN%7D%7B%7CM%7C%7D%5Cright%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" class="latex" title="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" /></p>



<p>It can be showed that for a walk defined by a Markov chain, the<br /> classical hitting time will be <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{1}{\delta \epsilon})" class="latex" title="O(\frac{1}{\delta \epsilon})" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3D+1+-+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta = 1 - \lambda^{*}" class="latex" title="\delta = 1 - \lambda^{*}" />, the <em>spectral gap</em>, and <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cleq+%5Cfrac%7B%7CM%7C%7D%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon \leq \frac{|M|}{N}" class="latex" title="\epsilon \leq \frac{|M|}{N}" /> [2].</p>



<p>Magniez <em>et al</em> proved in [6] that for a reversible, ergodic<br /> Markov chain, the quantum hitting time for a walk on this chain is<br /> within a factor of the square root of the classical hitting time. Since<br /> the walk on this input acts as a walk on a reversible Markov chain until<br /> a marked element is reached, then this is also true for a walk defined<br /> by our transition matrix <img src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P'" class="latex" title="P'" />. This arises from the fact that the<br /> spectral gap of the matrix describing the quantum walk corresponding to<br /> stochastic matrix <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is quadratically larger than the spectral gap of<br /> the matrix describing the classical random walk corresponding to <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />, the proof of which is given in [2]. Thus, the quantum hitting time<br /> is <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{N/|M|})" class="latex" title="O(\sqrt{N/|M|})" />, which exactly matches the quantum query complexity of Grover search.</p>



<h2>Element distinctness problem</h2>



<p>Now, we describe Ambainis’s algorithm given in [1] for solving<br /> the <em>element distinctness problem</em> in <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{2}{3}})" class="latex" title="O(N^{\frac{2}{3}})" /> time, which<br /> produces a speed up over the classical algorithm, which requires <img src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N)" class="latex" title="O(N)" /> queries, and also over other known quantum algorithms that do not make use of quantum walks, which require <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B3%7D%7B4%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{3}{4}})" class="latex" title="O(N^{\frac{3}{4}})" /> queries. The element distinctness problem is defined as follows: given a function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> on a size <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N" class="latex" title="N" /> set of inputs</p>



<p><img src="https://s0.wp.com/latex.php?latex=S%3D%5C%7Bx_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S=\{x_{1}" class="latex" title="S=\{x_{1}" />,…,<img src="https://s0.wp.com/latex.php?latex=x_%7BN%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{N}\}" class="latex" title="x_{N}\}" />,</p>



<p>determine whether there exists a pair <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2C%5C%3B+x_%7B2%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1},\; x_{2} \in S" class="latex" title="x_{1},\; x_{2} \in S" /> for which <img src="https://s0.wp.com/latex.php?latex=f%28x_%7B1%7D%29+%3D+f%28x_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x_{1}) = f(x_{2})" class="latex" title="f(x_{1}) = f(x_{2})" />.  As in the search problem defined in the previous section, this is a decision problem; we are not concerned with finding the values of these pairs, only whether at least one exists.</p>



<p>The algorithm is similar to the search algorithm described in the previous section, except we define the walk on a <em>Hamming graph</em>. A Hamming graph <img src="https://s0.wp.com/latex.php?latex=H%28N%2Cm%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(N,m)" class="latex" title="H(N,m)" /> is defined as follows: each vertex <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> corresponds to an <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />-tuple, (<img src="https://s0.wp.com/latex.php?latex=i_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{1}" class="latex" title="i_{1}" />,…,<img src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{m}" class="latex" title="i_{m}" />), where <img src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{k} \in S" class="latex" title="i_{k} \in S" /> for all <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> and repetition is allowed (that is, <img src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{k}" class="latex" title="i_{k}" /> may equal <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j}" class="latex" title="i_{j}" /> for <img src="https://s0.wp.com/latex.php?latex=k+%5Cneq+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \neq j" class="latex" title="k \neq j" />), and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> is a parameter we will choose. Edges will exist between vertices that differ in exactly one coordinate (order matters in this graph). We describe the state of each vertex as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci+%5Cright%3E%3D%7C+i_%7B1%7D%2Ci_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|i \right&gt;=| i_{1},i_{2}" class="latex" title="\left|i \right&gt;=| i_{1},i_{2}" />,…,<img src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D%2Cf%28i_%7B1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{m},f(i_{1})" class="latex" title="i_{m},f(i_{1})" />,…,<img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bm%7D%29%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{m})&gt;" class="latex" title="f(i_{m})&gt;" /></p>



<p>Then, moving along each edge that replaces the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th coordinate with <img src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{k}" class="latex" title="x_{k}" /> such that <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j} \neq x_{k}" class="latex" title="i_{j} \neq x_{k}" />  requires two queries to the black box function to erase <img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{j})" class="latex" title="f(i_{j})" /> and compute <img src="https://s0.wp.com/latex.php?latex=f%28x_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x_{k})" class="latex" title="f(x_{k})" />. In the case, the marked vertices will be those that contain some <img src="https://s0.wp.com/latex.php?latex=f%28i_%7Bk%7D%29+%3D+f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(i_{k}) = f(i_{j})" class="latex" title="f(i_{k}) = f(i_{j})" /> for <img src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i_{j} \neq i_{k}" class="latex" title="i_{j} \neq i_{k}" />. Since the function values are stored in the description of the state, then no additional queries to the black box are required to check if in a marked state.</p>



<p>The transition matrix is given by <img src="https://s0.wp.com/latex.php?latex=P+%3D+%5Cfrac%7B1%7D%7Bm%28n-1%29%7D+%5Cunderset%7Bi+%5Cin+%5B1%2Cm%5D%7D%7B%5Csum%7D+%28J+-+I%29%5E%7B%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" class="latex" title="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" />. <img src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J" class="latex" title="J" /> is the <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \times n" class="latex" title="n \times n" /> all one matrix, and the superscript <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> denotes the operator acting on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th coordinate. The factor of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{m(n-1)}" class="latex" title="\frac{1}{m(n-1)}" /> normalizes the degree, since the graph is regular. We can compute the spectral gap of this graph to be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bn%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{n}{m(n-1)}" class="latex" title="\frac{n}{m(n-1)}" /> (for details of this computation, see [2]). Then, noting that that the fraction of marked vertices, <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, is<br /> <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Cfrac%7Bm%28m-1%29%28n-2%29%5E%7Bm-2%7D%7D%7Bn%5E%7Bm%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" class="latex" title="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" />, classically, the query complexity is <img src="https://s0.wp.com/latex.php?latex=m+%2B+O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29+%3D+m+%2B+O%28%5Cfrac%7Bn%5E%7B2%7D%7D%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" class="latex" title="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" />, where <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> is the queries required to construct the initial state. Setting the parameters equal to minimize with respect to <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> gives classical query complexity <img src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N)" class="latex" title="O(N)" />, as expected.</p>



<p>Then in the quantum case, <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> queries are still required to set up the state. <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7B%5Csqrt%7Bm%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{n}{\sqrt{m}})" class="latex" title="O(\frac{n}{\sqrt{m}})" /> queries are required to perform the walk until a marked state is reached, by [6]. Setting parameters equal gives <img src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(N^{\frac{2}{3}})" class="latex" title="O(N^{\frac{2}{3}})" /> queries, as desired.</p>



<p>[1] Ambainis, A. Quantum walk algorithm for element distinctness, SIAM Journal on Computing 37(1):210-239 (2007). arXiv:quant-ph/0311001</p>



<p>[2] Childs, A. Lecture Notes on Quantum Algorithms (2017). <a href="https://www.cs.umd.edu/ amchilds/qa/qa.pdf" rel="nofollow">https://www.cs.umd.edu/ amchilds/qa/qa.pdf</a></p>



<p>[3] Childs, A., Farhi, E. Gutmann, S. An example of the difference between<br /> quantum and classical random walks. Journal of Quantum Information<br /> Processing, 1:35, 2002. Also quant-ph/0103020.</p>



<p>[4] Godsil, C., Hanmeng, Z. Discrete-Time Quantum Walks and Graph Structures<br /> (2018). arXiv:1701.04474</p>



<p>[5] Kempe, J. Quantum random walks: an introductory overview, Contemporary<br /> Physics, Vol. 44 (4) (2003) 307:327. arXiv:quant-ph/0303081</p>



<p>[6] Magniez, F., Nayak, A., Richter, P.C. et al. On the hitting times of<br /> quantum versus random walks, Algorithmica (2012) 63:91.<br /> <a href="https://doi.org/10.1007/s00453-011-9521-6" rel="nofollow">https://doi.org/10.1007/s00453-011-9521-6</a></p>



<p>[7] Szegedy, M. Quantum Speed-up of Markov Chain Based Algorithms, 45th<br /> Annual IEEE Symposium on Foundations of Computer Science (2004).<br /> <a href="https://ieeexplore.ieee.org/abstract/document/1366222" rel="nofollow">https://ieeexplore.ieee.org/abstract/document/1366222</a></p></div>







<p class="date">
by beanash <a href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/"><span class="datestr">at December 23, 2018 05:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/23/postdoc-in-cs-focused-on-sat-solving-at-kth-royal-institute-of-technology-apply-by-february-4-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/23/postdoc-in-cs-focused-on-sat-solving-at-kth-royal-institute-of-technology-apply-by-february-4-2019/">Postdoc in CS focused on SAT solving at KTH Royal Institute of Technology (apply by February 4, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The TCS Group at KTH invites applications for postdoc positions focusing on algorithms for solving the Boolean satisfiability problem (SAT) very efficiently for large classes of instances, and on analyzing and understanding such algorithms. The application deadline is February 4, 2019. Informal enquiries are welcome and may be sent to jakobn@kth.se .</p>
<p>Website: <a href="http://www.csc.kth.se/~jakobn/openings/J-2018-3178-Eng.php">http://www.csc.kth.se/~jakobn/openings/J-2018-3178-Eng.php</a><br />
Email: jakobn@kth.se</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/23/postdoc-in-cs-focused-on-sat-solving-at-kth-royal-institute-of-technology-apply-by-february-4-2019/"><span class="datestr">at December 23, 2018 10:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/23/postdoc-positions-in-tcs-at-kth-royal-institute-of-technology-apply-by-february-4-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/23/postdoc-positions-in-tcs-at-kth-royal-institute-of-technology-apply-by-february-4-2019/">Postdoc positions in TCS at KTH Royal Institute of Technology (apply by February 4, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The TCS Group at KTH Royal Institute of Technology invites applications for postdoc positions in TCS. The application deadline is February 4, 2019. See <a href="https://apc.eecs.kth.se/J-2018-3169-Eng.php">https://apc.eecs.kth.se/J-2018-3169-Eng.php</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to apc@eecs.kth.se .</p>
<p>Website: <a href="https://apc.eecs.kth.se/J-2018-3169-Eng.php">https://apc.eecs.kth.se/J-2018-3169-Eng.php</a><br />
Email: apc@eecs.kth.se</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/23/postdoc-positions-in-tcs-at-kth-royal-institute-of-technology-apply-by-february-4-2019/"><span class="datestr">at December 23, 2018 10:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6939">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/">Towards Quantum PCP: A Proof of the NLETS Theorem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By Abhijit Mudigonda, Richard Wang, and Lisa Yang</p>



<p><i>This is part of a series of blog posts for <a href="https://www.boazbarak.org/fall18seminar/">CS 229r: Physics and Computation</a>. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the NLETS theorem, and then settle on providing a proof of the NLETS theorem. This new proof, due to Nirkhe, Vazirani, and Yuen, makes it clear that the Hamiltonian family used to resolve the NLETS theorem cannot help us in resolving the NLTS conjecture.</i></p>



<h2>Introduction</h2>
<p>We are all too familiar with <b>NP</b> problems. Consider now an upgrade to <b>NP</b> problems, where an omniscient prover (we’ll call this prover Merlin) can send a polynomial-sized proof to a <b>BPP</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#BPP">bounded-error probabilistic polynomial-time</a>) verifier (and we’ll call this verifier Arthur). Now, we have more decision problems in another complexity class, <b>MA</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#MA">Merlin-Arthur</a>). Consider again, the analogue in the quantum realm where now the prover sends over qubits instead and the verifier is in <b>BQP</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:B#bqp">bounded-error quantum polynomial-time</a>). And now we have <b>QMA</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qma">quantum Merlin-Arthur</a>).</p>

<p>We can show that there is a hierarchy to these classes, where <b>NP</b> <img src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\subseteq " class="latex" title="\subseteq " /> <b>MA</b> <img src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\subseteq " class="latex" title="\subseteq " /> <b>QMA</b>.</p>

<p>Our goal is to talk about progress towards a <b>quantum PCP theorem</b> (and since nobody has proved it in the positive or negative, we’ll refer to it as a quantum PCP <i>conjecture</i> for now), so it might be a good idea to first talk about the PCP theorem. Suppose we take a Boolean formula, and we want to verify that it is satisfiable. Then someone comes along and presents us with a certificate — in this case, a satisfying assignment — and we can check in polynomial time that either this is indeed a satisfying assignment to the formula (a correct certificate) or it is not (an incorrect certificate).</p>

<p>But this requires that we check the entire certificate that is presented to us. Now, in comes the <b>PCP Theorem</b> (for <i>probabilistically checkable proofs</i>), which tells us that a certificate can be presented to us such that we can read a constant number of bits from the certificate, and have two things guaranteed: one, if this certificate is correct, then we will never think that it is incorrect even if we are not reading the entire certificate, and two, if we are presented with an incorrect certificate, we will reject it with high probability [<a href="https://windowsontheory.org/feed/#arora2009computational">1</a>].</p>

<p>In short, one formulation of the PCP theorem tells us that, puzzingly, we might not need to read the entirety of a proof in order to be convinced with high probability that it is a good proof or a bad proof. But a natural question arises, which is to ask: is there a quantum analogue of the PCP theorem?</p>

<h2>Progress</h2>

<p>The answer is, we’re still not sure. But to make progress towards resolving this question, we will present the work of <a href="https://arxiv.org/pdf/1802.07419.pdf">Nirkhe, Vazirani, and Yuen</a> in providing an alternate proof of an earlier result of <a href="https://arxiv.org/pdf/1510.02082.pdf">Eldar and Harrow</a> on the NLETS theorem.

</p><p>Before we state the quantum PCP conjecture, it would be helpful to review information about local Hamiltonians and the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem. <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">A previous blog post by Ben Edelman</a> covers these topics. Now, let’s state the quantum PCP conjecture:</p>

<p><b>(<i>Quantum PCP Conjecture</i>)</b>: It is QMA-hard to decide whether a given local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+%3D+H_%7B1%7D+%2B+...+%2B+H_%7Bm%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = H_{1} + ... + H_{m} " class="latex" title="H = H_{1} + ... + H_{m} " /> (where each <img src="https://s0.wp.com/latex.php?latex=%7C%7CH_%7Bi%7D%7C%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="||H_{i}|| \leq 1" class="latex" title="||H_{i}|| \leq 1" />) has ground state energy at most <img src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a " class="latex" title="a " /> or at least <img src="https://s0.wp.com/latex.php?latex=b+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b " class="latex" title="b " /> when <img src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b-a \geq c||H|| " class="latex" title="b-a \geq c||H|| " /> for some universal constant <img src="https://s0.wp.com/latex.php?latex=c+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c &gt; 0" class="latex" title="c &gt; 0" />.</p>

<p>Recall that MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-SAT being NP-hard corresponds to the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem being QMA-hard when <img src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+1%2Fpoly%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b-a \geq 1/poly(n)" class="latex" title="b-a \geq 1/poly(n)" />. (We can refer to <a href="https://www.cs.cmu.edu/~odonnell/quantum15/lecture24.pdf">Theorem 4.1 in these scribed notes of Ryan O’Donnell’s lecture</a>, and more specifically to  <a href="https://arxiv.org/pdf/quant-ph/0406180.pdf">Kempe-Kitaev-Regev’s original paper</a> for proof of this fact.) The quantum PCP conjecture asks if this is still the case when the gap is <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H||" class="latex" title="c||H||" />.</p>

<p>Going back to the PCP theorem, an implication of the PCP theorem is that it is NP-hard to approximate certain problems to within some factor. Just like its classical analogue, the qPCP conjecture can be seen as stating that it is QMA-hard to approximate the ground state energy to a factor better than <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H||" class="latex" title="c||H||" />.</p>

<h3>Reformulation: NLTS conjecture</h3>
<p>Let’s make the observation that, taking <img src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a " class="latex" title="a " /> to be the ground state energy, the qPCP conjecture sort of says that there exists a family of Hamiltonians for which there is no trivial state (a state generated by a low depth circuit) such that the energy is at most <img src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c||H|| " class="latex" title="c||H|| " /> above the ground state energy.</p>

<p>Freedman and Hastings came up with an easier goal called the <b>No Low-Energy Trivial States conjecture</b>, or <b>NLTS conjecture</b>. We expect that ground states of local Hamiltonians are sufficiently hard to describe (if NP <img src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq " class="latex" title="\neq " /> QMA). So low-energy states might not be generated by a quantum circuit of constant depth. More formally:</p>

<p><b>(<i>NLTS Conjecture</i>)</b>: <i>There exists a universal constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon &gt; 0 " class="latex" title="\epsilon &gt; 0 " /> and a family of local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" title="\{H^{(n)}\}_{n=1}^{\infty} " /> where <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> acts on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles and consists of <img src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m_{n} " class="latex" title="m_{n} " /> local terms, s.t. any family of states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi_{n}\rangle\} " class="latex" title="\{|\psi_{n}\rangle\} " /> satisfying <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " /> requires circuit depth that grows faster than any constant.</i></p>

<p>To reiterate, if we did have such a family of NLTS Hamiltonians, then it we wouldn’t be able to give “easy proofs” for the minimal energy of a Hamiltonian, because we couldn’t just give a small circuit which produced a low energy state.</p>

<h2>Progress: NLETS theorem</h2>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " />-error states are states that differ from the ground state in at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon n " class="latex" title="\epsilon n " /> qubits. Now, consider <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states (which “agree” with the ground state on most qubits). Then for bounded-degree local Hamiltonians (analogously in the classical case, those where each variable participates in a bounded number of clauses), these states are also low energy. So any theorem which applies to low energy states (such as the NLTS conjecture), should also apply to states with <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error (as in the NLETS theorem).</p>

<p>To define low-error states more formally:</p>

<p><b>Definition 2.1</b> (<img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " />-error states): <i>Let <img src="https://s0.wp.com/latex.php?latex=%5Crho%2C+%5Csigma+%5Cin+D%28%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " class="latex" title="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " /> (the space of positive semidefinite operators of trace norm equal to 1 on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" title="(\mathbb{C}^{d})^{\otimes n}" />). Let <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> be a local Hamiltonian acting on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" title="(\mathbb{C}^{d})^{\otimes n}" />. Then:</i></p>

<p></p><ul>
    <li><img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state of <img src="https://s0.wp.com/latex.php?latex=%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho " class="latex" title="\rho " /> if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exists S \subseteq [n] " class="latex" title="\exists S \subseteq [n] " /> of size at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon n " class="latex" title="\epsilon n " /> s.t. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D%28%5Crho%29+%3D+%5Ctext%7BTr%7D_%7BS%7D%28%5Csigma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" class="latex" title="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" />.</li>
    <li><img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state for <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> if <img src="https://s0.wp.com/latex.php?latex=%5Cexists+%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exists \rho " class="latex" title="\exists \rho " /> s.t. <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28H%5Crho%29+%3D+%5Clambda_%7Bmin%7D%28H%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(H\rho) = \lambda_{min}(H) " class="latex" title="\text{Tr}(H\rho) = \lambda_{min}(H) " /> and <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> is an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state for <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />.</li>
</ul><p></p>

<p>Here, see that <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_{S} " class="latex" title="\text{Tr}_{S} " /> is just the partial trace on some subset of integers <img src="https://s0.wp.com/latex.php?latex=S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S " class="latex" title="S " />, like we’re tracing out or “disregarding” some subset of <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits.</p>

<p>In 2017, Eldar and Harrow showed the following result which is the NLETS theorem.</p>

<p><b>Theorem 1</b> (NLETS Theorem): <i>There exists a family of 16-local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> s.t. any family of <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5CPhi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\Phi_{n}\rangle\} " class="latex" title="\{|\Phi_{n}\rangle\} " /> for <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> requires circuit depth <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega(\log n) " class="latex" title="\Omega(\log n) " /> where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+10%5E%7B-9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon = 10^{-9}" class="latex" title="\epsilon = 10^{-9}" />.</i></p>

<p>In the next two sections, we will provide background for an alternate proof of the NLETS theorem due to Nirkhe, Vazirani, and Yuen. After this, we will explain why the proof of NLETS cannot be used to prove NLTS, since the local Hamiltonian family we construct for NLETS can be linearized. Nirkhe, Vazirani, and Yuen’s proof of NLETS makes use of the Feynman-Kitaev clock Hamiltonian corresponding to the circuit generating the cat state (Eldar and Harrow make use of the Tillich-Zemor hypergraph product construction; refer to section 8 of <a href="https://arxiv.org/pdf/1510.02082.pdf">their paper</a>). What is this circuit? It is this one:</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/cat_state.png?w=326&amp;h=210" alt="" height="210" class="wp-image-6977" width="326" />Image from [2]</figure></div>



<p>First, we apply the Hadamard gate (drawn as <img src="https://s0.wp.com/latex.php?latex=%5Cboxed%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boxed{H}" class="latex" title="\boxed{H}" />) which maps the first qubit <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle+%5Crightarrow+%5Cfrac%7B%7C0%5Crangle+%2B+%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" class="latex" title="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" />. Then we can think of the CNOT gates (drawn as <img src="https://s0.wp.com/latex.php?latex=%5Cbullet-%5Coplus&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bullet-\oplus" class="latex" title="\bullet-\oplus" />) as propagating whatever happens to the first qubit to the rest of the qubits. If we had the first qubit mapping to 0, then the rest of the qubits map to 0, and likewise for 1. This generates the cat state <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bn%7D%5Crangle+%3D+%5Cfrac%7B%7C0%5Crangle%5E%7B%5Cotimes+n%7D+%2B+%7C1%5Crangle%5E%7B%5Cotimes+n%7D%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" class="latex" title="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" />, which is highly entangled.</p>

<p>Why do we want a highly entangled state? Roughly our intuition for using the cat state is this: if the ground state of a Hamiltonian is highly entangled, then any quantum circuit which generates it has non-trivial depth. So if our goal is to show the existence of local Hamiltonians which have low energy or low error states that need deep circuits to generate, it makes sense to use a highly entangled state like the cat state.</p>

<h2>Quantum circuits</h2>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img src="https://windowsontheory.files.wordpress.com/2018/12/operators.png?w=446&amp;h=221" alt="" height="221" class="wp-image-6978" width="446" />Image from [2]</figure></div>



<p>(We’ll write that the state of a qudit – a generalization of a qubit to more than two dimensions, and in this case <img src="https://s0.wp.com/latex.php?latex=q+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q " class="latex" title="q " /> dimensions – is a vector in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5E%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{C}^{q}" class="latex" title="\mathbb{C}^{q}" />. In our diagram above, we’ll see 4 qudits, labelled appropriately.)</p>

<p>Let’s briefly cover the definitions for the quantum circuits we’ll be using.</p>

<p>Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a unitary operator acting on a system of <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qudits (in other words, acting on <img src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bq%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\mathbb{C}^{q})^{\otimes n}" class="latex" title="(\mathbb{C}^{q})^{\otimes n}" />), where <img src="https://s0.wp.com/latex.php?latex=U+%3D+U_%7Bm%7D+%5Chdots+U_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = U_{m} \hdots U_{1}" class="latex" title="U = U_{m} \hdots U_{1}" />. Here, each <img src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{i} " class="latex" title="U_{i} " /> is a unitary operator (a gate) acting on at most two qudits, and <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is a product of <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> such operators.</p>

<p>If there exists a partition <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> into products of non-overlapping two-qudit unitaries (we call these layers and denote them as <img src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D+%3D+%5Cbigotimes_%7Bj%7DU_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i} = \bigotimes_{j}U_{ij}" class="latex" title="L_{i} = \bigotimes_{j}U_{ij}" />, where each <img src="https://s0.wp.com/latex.php?latex=U_%7Bj%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{j} " class="latex" title="U_{j} " /> here is in layer <img src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_{i}" class="latex" title="L_{i}" />) such that <img src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = L_{d} \hdots L_{1} " class="latex" title="U = L_{d} \hdots L_{1} " /> then we say <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> has <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> layers.</p>

<p>In other words, <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> has size <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> and circuit depth <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />.</p>

<h3>Lightcones, effect zones, shadow zones</h3>
<p>Consider <img src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = L_{d} \hdots L_{1} " class="latex" title="U = L_{d} \hdots L_{1} " /> and <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> an operator.</p>

<p>For <img src="https://s0.wp.com/latex.php?latex=j+%3C+d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j &lt; d " class="latex" title="j &lt; d " /> define <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j)} " class="latex" title="K^{(j)} " /> as the gates in layer <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> whose supports overlap that of any gate in <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j+1)}" class="latex" title="K^{(j+1)}" />, …, <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28d%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(d)} " class="latex" title="K^{(d)} " /> or with <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />.</p>

<p><b>Definition 3.1</b> (lightcone): <i>The <i>lightcone</i> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the union of <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(j)}" class="latex" title="K^{(j)}" />: <img src="https://s0.wp.com/latex.php?latex=K_%7BU%7D+%5Ctriangleq+%5Cbigcup_%7Bj%7D+K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K_{U} \triangleq \bigcup_{j} K^{(j)}" class="latex" title="K_{U} \triangleq \bigcup_{j} K^{(j)}" />.</i></p>

<p>So we can think of the lightcone as the set of gates spreading out of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> all the way to the first layer of the circuit. In our diagram, the lightcone of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> is the dash-dotted region. We have <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%283%29%7D+%3D+%5Cvarnothing&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(3)} = \varnothing" class="latex" title="K^{(3)} = \varnothing" />, <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(2)} = \{U_{21}\}" class="latex" title="K^{(2)} = \{U_{21}\}" />, and <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K^{(1)} = \{U_{11}, U_{12}\}" class="latex" title="K^{(1)} = \{U_{11}, U_{12}\}" />.</p>

<p>We also want a definition for what comes back from the lightcone: the set of gates from the first layer (the widest part of the cone) back to the last layer.</p>

<p>Define <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+K%5E%7B%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(1)} = K^{(1)}" class="latex" title="E^{(1)} = K^{(1)}" />. For <img src="https://s0.wp.com/latex.php?latex=j+%5Cgeq+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j \geq 2" class="latex" title="j \geq 2" />, let <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(j)} " class="latex" title="E^{(j)} " /> be the set of gates whose supports overlap with any gate in <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(j-1)}" class="latex" title="E^{(j-1)}" />.</p>

<p><b>Definition 3.2</b> (effect zone): <i>The <i>effect zone</i> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the union <img src="https://s0.wp.com/latex.php?latex=E_%7BU%7D%28A%29+%5Ctriangleq+%5Cbigcup_%7Bj%7D+E%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" class="latex" title="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" />.</i></p>

<p>In our diagram, see that <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(1)} = \{U_{11}, U_{12}\}" class="latex" title="E^{(1)} = \{U_{11}, U_{12}\}" />, <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(2)} = \{U_{21}\}" class="latex" title="E^{(2)} = \{U_{21}\}" />, and <img src="https://s0.wp.com/latex.php?latex=E%5E%7B%283%29%7D+%3D+%5C%7BU_%7B31%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E^{(3)} = \{U_{31}\}" class="latex" title="E^{(3)} = \{U_{31}\}" />. The effect zone of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> is the dotted region.</p>

<p><b>Definition 3.3</b> (shadow of the effect zone): <i>The <i>shadow of the effect zone</i> <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A) " class="latex" title="W_{U}(A) " /> of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> with respect to <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> is the set of qudits acted on by the gates in the effect zone.</i></p>

<p>In our diagram, the first three qudits are effected by gates in the effect zone. So <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+%3D+%5C%7B1%2C+2%2C+3%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A) = \{1, 2, 3\}" class="latex" title="W_{U}(A) = \{1, 2, 3\}" />.</p>

<p>Given all of these definitions, we make the following claim which will be important later, in a proof of a generalization of NLETS.</p>

<p><b><a id="claim3"></a>Claim 3.1</b> (Disjoint lightcones): <i>Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a circuit and <img src="https://s0.wp.com/latex.php?latex=A%2C+B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A, B " class="latex" title="A, B " /> operators. If the qudits <img src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B " class="latex" title="B " /> acts on are disjoint from <img src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_{U}(A)" class="latex" title="W_{U}(A)" />, then the lightcones of <img src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A " class="latex" title="A " /> and <img src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B " class="latex" title="B " /> in <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> are disjoint.</i></p>

<h2>Toward the Feynman-Kitaev clock</h2>
<p>Now we’ll give some definitions that will become necessary when we make use of the Feynman-Kitaev Hamiltonian in our later proofs.</p>

<p>Let’s define a unary clock. It will basically help us determine whatever happened at any time little <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> along the total time big <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. Let <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle+%3D+%7C0%5Crangle%5E%7B%5Cotimes%28T-t%29%7D+%5Cotimes+%7C1%5Crangle%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" class="latex" title="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" />. For our purposes today, we won’t worry about higher dimensional clocks. So we’ll write <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{clock}_{k}(t, T)\rangle" class="latex" title="|\textsf{clock}_{k}(t, T)\rangle" />, but we’ll really only consider the case where <img src="https://s0.wp.com/latex.php?latex=k+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 1" class="latex" title="k = 1" />, which corresponds to <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t, T)\rangle" class="latex" title="|\textsf{unary}(t, T)\rangle" />. For simplicity’s sake, we will henceforth just write <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{unary}(t)\rangle" class="latex" title="|\textsf{unary}(t)\rangle" />.</p>

<p>Our goal is to construct something a little similar to the tableaux in the Cook-Levin theorem, so we also want to define a history state:</p>

<p><b>Definition 4.1</b> (History state): <i>Let <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> be a quantum circuit that acts on a witness register and an ancilla register. Let <img src="https://s0.wp.com/latex.php?latex=C_%7B1%7D%2C+...%2C+C_%7BT%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{1}, ..., C_{T} " class="latex" title="C_{1}, ..., C_{T} " /> denote the sequence of two-local gates in <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. Then for all <img src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \in \mathbb{N}" class="latex" title="k \in \mathbb{N}" />, a state <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle " class="latex" title="|\Psi\rangle " /> is a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-dimensional history state of <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> if:</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BT%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5E%7BT%7D%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle+%5Cotimes+%7C%5Cpsi_%7Bt%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " /></p></div>

<p>where we have the clock state to keep track of time and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_{t} " class="latex" title="\psi_{t} " /> is some state such that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7Bt%7D%5Crangle+%3D+C_%7Bt%7D%7C%5Cpsi_%7Bt-1%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " class="latex" title="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7B0%7D%5Crangle+%3D+%7C%5Cxi%5Crangle_%7Bwitness%7D+%5Cotimes+%7C0%5Crangle_%7Bancilla%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" class="latex" title="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" />. With this construction, we should be able to make a measurement to get back the state at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />.</p>

<h2>Proof of NLETS</h2>
<p>We provide a proof of (a simplified case of) the NLETS theorem proved by Nirkhe, Vazirani, and Yuen in [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>].</p>

<p><b>Theorem 2</b> (NLETS): <i>There exists a family of <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\} " class="latex" title="\{H^{(n)}\} " /> on a line (Each Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> can be defined on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles arranged on a line such that each local Hamiltonian acts on a particle and its two neighbors) such that for all <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \in \mathbb{N}" class="latex" title="n \in \mathbb{N}" />, the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error ground state for <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> is at least logarithmic in <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " />.</i></p>

<p>First, we’ll show the circuit lower bound.  Then we’ll explain why these Hamiltonians can act on particles on a line and what this implies about the potential of these techniques for proving NLTS.</p>

<p><i>Proof</i>: We will use the <b>Feynman-Kitaev clock construction</b> to construct a <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H}^{(n)} " class="latex" title="\mathcal{H}^{(n)} " /> for the circuit <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />: <img src="https://s0.wp.com/latex.php?latex=%7C0%5En%5Crangle+%5Cto+%7C%5Ctextsf%7BCAT%7D_n%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0^n\rangle \to |\textsf{CAT}_n\rangle " class="latex" title="|0^n\rangle \to |\textsf{CAT}_n\rangle " />.</p>

<p>Fix <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \in \mathbb{N} " class="latex" title="n \in \mathbb{N} " /> and let <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> have size <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />.  The Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> acts on <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubits and consists of several local terms depending on <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />:</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t+%2B+H_%7Bout%7D+%2B+H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " class="latex" title="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " /></p></div>

<p>We can think of a <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state as representing a <img src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T " class="latex" title="T " /> step computation on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits (i.e. for each time <img src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B0%2CT%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t \in [0,T]" class="latex" title="t \in [0,T]" />, we have a <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> bit computation state <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_t " class="latex" title="\textsf{state}_t " /> of <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />).  Intuitively, a <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state has energy <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> with respect to <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> iff it is the history state of <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />.  This is because <img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> checks that at time <img src="https://s0.wp.com/latex.php?latex=t%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=0" class="latex" title="t=0" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_0 " class="latex" title="\textsf{state}_0 " /> consists of the input <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5En+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle^n " class="latex" title="|0\rangle^n " /> to <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />.  Each <img src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_t " class="latex" title="H_t " /> checks that <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_{t} " class="latex" title="\textsf{state}_{t} " /> proceed correctly from <img src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt-1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textsf{state}_{t-1} " class="latex" title="\textsf{state}_{t-1} " /> (i.e. that the <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />th gate of <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> is applied correctly).  Then <img src="https://s0.wp.com/latex.php?latex=H_%7Bout%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{out} " class="latex" title="H_{out} " /> checks that at time <img src="https://s0.wp.com/latex.php?latex=t%3DT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=T" class="latex" title="t=T" />, the output is <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />.  Finally, <img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> checks that the <img src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T+n " class="latex" title="T+n " /> qubit state is a superposition only over states where the first <img src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T " class="latex" title="T " /> qubits represent “correct times” (i.e. a unary clock state where time <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> is represented by <img src="https://s0.wp.com/latex.php?latex=T-t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T-t " class="latex" title="T-t " /> zeros followed by <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> ones).</p>

<p>Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> has a unique ground state, the history state of <img src="https://s0.wp.com/latex.php?latex=C_n%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n|0^n\rangle" class="latex" title="C_n|0^n\rangle" />, with energy <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />:</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes+%7C%5Cpsi_t%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes+%7C0%5Crangle%5E%7B%5Cotimes+%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " /></p></div>

<p>Later we will show how to transform <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> into a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qutrits on a line.  Intuitively, the structure of <img src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n " class="latex" title="C_n " /> allows us to fuse the <img src="https://s0.wp.com/latex.php?latex=T%3Dn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T=n " class="latex" title="T=n " /> time qubits and <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> state qubits and represent unused state qubits by <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />.  For the Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />, the ground state becomes</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Cpsi_t%5Crangle+%3D+%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes%7C2%5Crangle%5E%7B%5Cotimes%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " class="latex" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " /></p></div>

<p>For the rest of this proof, we work with respect to <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.</p>

<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> be an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state and let <img src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S \subseteq [n] " class="latex" title="S \subseteq [n] " /> be the subset of qutrits such that <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_S%28%5Csigma%29+%3D+%5Ctext%7BTr%7D_S%28%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" class="latex" title="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" />.  We define two projection operators which, when applied to <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> alone, produce nontrivial measurements, but when applied to <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> together, produce trivial measurements.</p>

<p><b>Definition 5.1</b>: <i>For any <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\in[n]" class="latex" title="i\in[n]" />, the projection operator</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DA_i+%3D+%7C0%5Crangle%5Clangle+0%7C_i+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " class="latex" title="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " /></p></div>

<p><i>projects onto the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit.</i></p>

<p><i>For any <img src="https://s0.wp.com/latex.php?latex=j%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j\in[n]" class="latex" title="j\in[n]" />, the projection operator</i></p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+B_j+%3D+%7C1%5Crangle%5Clangle+1%7C_i%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " class="latex" title="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " /></p></div>

<p><i>projects onto the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 " class="latex" title="1 " /> on the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrit.</i></p>

<p><b>Claim 5.1</b>:
<i>For <img src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\not\in S" class="latex" title="i\not\in S" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" title="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" />.  For <img src="https://s0.wp.com/latex.php?latex=j%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j\not\in S" class="latex" title="j\not\in S" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" />.  Note that these values are positive for any <img src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j\in [n]" class="latex" title="i,j\in [n]" />.</i></p>

<p><i>Proof</i>: If <img src="https://s0.wp.com/latex.php?latex=i+%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \not\in S" class="latex" title="i \not\in S" />, then measurements on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit are the same for <img src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma " class="latex" title="\sigma " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle\langle\Psi|" class="latex" title="|\Psi\rangle\langle\Psi|" />.</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29%5C%5C+++++%26%3D+%5Ctext%7BTr%7D%5Cleft%28A_i+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%5Cright%29%5C%5C+++++%26%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%29+++%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " class="latex" title="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=t%3Dt%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=t'" class="latex" title="t=t'" />, then any <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qutrit pure state cannot have nonzero weight in both <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%27%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_{t'} " class="latex" title="\psi_{t'} " /> (every pure state ends in some number of <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />s which tells which <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> (if any) it can be a part of). Therefore,</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%7D%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle+%5Cpsi_t%7CA_i%7C%5Cpsi_t%5Crangle+%5Censpace.+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " class="latex" title="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=i+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \le t" class="latex" title="i \le t" />, then projecting onto the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit gives <img src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0 " class="latex" title="0 " /> with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" />. Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Cleft%28%5Cfrac%7Bn-i%2B1%7D%7B2%7D%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" title="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" />.</p>

<p>Similarly, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p><b>Claim 5.2</b>: <i>For <img src="https://s0.wp.com/latex.php?latex=i%2Cj+%5Cnot%5Cin+S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j \not\in S " class="latex" title="i,j \not\in S " /> such that <img src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i &lt; j" class="latex" title="i &lt; j" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(A_i \otimes B_j \sigma) = 0" class="latex" title="\text{Tr}(A_i \otimes B_j \sigma) = 0" />.</i></p>

<p><i>Proof</i>:
As before, we can calculate</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle%5Cpsi_t%7CA_i%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " class="latex" title="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " /></p></div>

<p>If <img src="https://s0.wp.com/latex.php?latex=j+%3E+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j &gt; t" class="latex" title="j &gt; t" />, then the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrit of <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi_t " class="latex" title="\psi_t " /> is <img src="https://s0.wp.com/latex.php?latex=2+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2 " class="latex" title="2 " /> so <img src="https://s0.wp.com/latex.php?latex=B_j%7C%5Cpsi_t%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B_j|\psi_t\rangle = 0" class="latex" title="B_j|\psi_t\rangle = 0" />. If <img src="https://s0.wp.com/latex.php?latex=j+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j \le t" class="latex" title="j \le t" />, then <img src="https://s0.wp.com/latex.php?latex=A_i+%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%3D+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i \otimes B_j|\psi_t\rangle = 0 " class="latex" title="A_i \otimes B_j|\psi_t\rangle = 0 " /> because the first <img src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t " class="latex" title="t " /> qutrits of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_t%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_t\rangle " class="latex" title="|\psi_t\rangle " /> contain the <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{CAT}_{t}\rangle " class="latex" title="|\textsf{CAT}_{t}\rangle " /> state so under any measurement, the <img src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i " class="latex" title="i " /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" />th qutrits must be the same. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p>Now we use these claims to prove a circuit lower bound.  Let <img src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U " class="latex" title="U " /> be a circuit generating (a state with density matrix) <img src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma" class="latex" title="\sigma" />.  Let <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> be the depth of <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" />.</p>

<p>Consider some <img src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\not\in S" class="latex" title="i\not\in S" />.  For any operator acting on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit, its lightcone consists of at most <img src="https://s0.wp.com/latex.php?latex=2%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^d " class="latex" title="2^d " /> gates so its effect zone consists of at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d} " class="latex" title="2^{2d} " /> gates which act on at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} " class="latex" title="2^{2d+1} " /> qudits (called the shadow of the effect zone).</p>

<p>Assume towards contradiction that <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%3C+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} &lt; n-\epsilon n" class="latex" title="2^{2d+1} &lt; n-\epsilon n" />. Then the shadow of any operator acting only on the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />th qutrit has size at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cle+n+-+%7CS%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} \le n - |S| " class="latex" title="2^{2d+1} \le n - |S| " /> since <img src="https://s0.wp.com/latex.php?latex=%7CS%7C+%5Cle+%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|S| \le \epsilon n" class="latex" title="|S| \le \epsilon n" />.  So there is some <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> outside of the shadow which is in the complement of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" />.  By <a href="https://windowsontheory.org/feed/#claim3">Claim 3.1</a>, we have found two indices <img src="https://s0.wp.com/latex.php?latex=i%2Cj+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j " class="latex" title="i,j " /> such that any pair of operators acting on <img src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i " class="latex" title="i " /> and <img src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j " class="latex" title="j " /> have disjoint lightcones in <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" />. WLOG let <img src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i &lt; j" class="latex" title="i &lt; j" />.  The lightcones of <img src="https://s0.wp.com/latex.php?latex=A_i%2CB_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i,B_j " class="latex" title="A_i,B_j " /> are disjoint which implies
<img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+%5Ctext%7BTr%7D%28A_i+%5Csigma%29%5Ccdot%5Ctext%7BTr%7D%28B_j+%5Csigma%29.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " class="latex" title="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " /></p>

<p>By the two claims above, we get a contradiction.</p>

<p>Therefore, <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cge+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2d+1} \ge n-\epsilon n" class="latex" title="2^{2d+1} \ge n-\epsilon n" />.  We can take any constant epsilon: letting <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon = 1/2" class="latex" title="\epsilon = 1/2" />, we get</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7Dd+%5Cge+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28%5Clog+%5Cfrac%7Bn%7D%7B2%7D+-+1%5Cright%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " class="latex" title="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " /></p></div>

<p><img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<p>This analysis relies crucially on the fact that any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error state matches the groundstate on most qudits.  However, NLTS is concerned with states which may differ from the groundstate on many qudits, as long as they have low energy.</p>

<p><b>Remark 2.1</b>: <i>The paper of Nirkhe, Vazirani, and Yuen [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>] actually proves more:
</i></p><ul><i>
    </i><li><i>A more general lower bound: logarithmic lower bound on the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta" class="latex" title="\delta" />-approximate (<img src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta " class="latex" title="\delta " /> far in L1 norm) <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-noisy state (probability distribution over <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-error states).</i></li><i>
    </i><li><i>Assuming QCMA <img src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq " class="latex" title="\neq " /> QMA (QCMA takes a <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> bit witness string instead of a <img src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m " class="latex" title="m " /> qubit state as witness), they show a superpolynomial lower bound (on the circuit depth of any <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta" class="latex" title="\delta" />-approximate <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />-noisy state).</i></li><i>
    </i><li><i>“Approximate qLWC codes”, using techniques from their superpolynomial lower bound.</i></li><i>
</i></ul><p></p>

<h2>Back to NLTS – Tempering our Optimism</h2>

<p>So far, we’ve shown a local Hamiltonian family for which all low-error (in “Hamming distance”) states require logarithmic quantum circuit depth to compute, thus resolving the NLETS conjecture. Now, let’s try to tie this back into the NLTS conjecture. Since it’s been a while, let’s recall the statement of the conjecture:</p>

<p><b>Conjecture</b> (NLTS): <i>There exists a universal constant <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon &gt; 0 " class="latex" title="\epsilon &gt; 0 " /> and a family of local Hamiltonians <img src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" title="\{H^{(n)}\}_{n=1}^{\infty} " /> where <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> acts on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> particles and consists of <img src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m_{n} " class="latex" title="m_{n} " /> local terms, s.t. any family of states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi_{n}\rangle\} " class="latex" title="\{|\psi_{n}\rangle\} " /> satisfying <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " /> requires circuit depth that grows faster than any constant.</i></p>

<p>In order to resolve the NLTS conjecture, it thus suffices to exhibit a local Hamiltonian family for which all low-energy states require logarithmic quantum circuit depth to compute. We might wonder if the local Hamiltonian family we used to resolve NLETS, which has “hard ground states”, might also have hard low-energy states. Unfortunately, as we shall show, this cannot be the case. We will start by showing that Hamiltonian families that lie on constant-dimensional lattices (in a sense that we will make precise momentarily) cannot possibly be used to resolve NLTS,  and then show that the Hamiltonian family we used to prove NLTS can be linearized (made to lie on a one-dimensional lattice!).</p>

<h3>The Woes of Constant-Dimensional Lattices</h3>
<p><b>Definition 6.1</b>: <i>A local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> acting on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits is said to <b>lie on a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /></b> if there is an injection of qubits into vertices of the graph such that the set of qubits in any interaction term correspond to a connected component in the graph</i>.</p>

<p><b>Theorem 2</b>: <i>If <img src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H^{(n)}) " class="latex" title="(H^{(n)}) " /> is a local Hamiltonian family that lies on an <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" />-dimensional lattice, then <img src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H^{(n)}) " class="latex" title="(H^{(n)}) " /> has a family of low-energy states with low circuit complexity. In particular, if <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> is a local Hamiltonian on a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice acting on <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> qubits for large enough <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, then for any <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, there exists a state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle " class="latex" title="|\psi\rangle " /> that can be generated by a circuit of constant depth and such that <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle+%5Cleq+H_0+%2B+%5Cepsilon+%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " class="latex" title="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " /> where <img src="https://s0.wp.com/latex.php?latex=H_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_0 " class="latex" title="H_0 " /> is the ground-state energy.</i></p>

<p><i>Proof</i>: In what follows, we’ll omit some of the more annoying computational details in the interest of communicating the high-level idea.</p>

<p>Start by partitioning the <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice (the one that <img src="https://s0.wp.com/latex.php?latex=H%5E%28n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^(n) " class="latex" title="H^(n) " /> lives on) into hypercubes of side length <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" />. We can “restrict” <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> to a given hypercube (let’s call it <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />) by throwing away all local terms containing a qubit not in <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />. This gives us a well-defined Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{\rho} " class="latex" title="H_{\rho} " /> on the qubits in <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />. Define <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi_{\rho}\rangle " class="latex" title="|\phi_{\rho}\rangle " /> to be the <img src="https://s0.wp.com/latex.php?latex=L%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L^d" class="latex" title="L^d" />-qubit ground state of <img src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{\rho}" class="latex" title="H_{\rho}" />, and define</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cphi%5Crangle+%3A%3D+%5Cbigotimes_%7B%5Ctext%7Bhypercubes+%7D+%5Crho%7D+%7C%5Cphi_%7B%5Crho%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " class="latex" title="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " /></p></div>

<p>where <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> is an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit state. Each <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi_{\rho}\rangle " class="latex" title="|\phi_{\rho}\rangle " /> can be generated by a circuit with at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d} " class="latex" title="2^{L^d} " /> gates, hence at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d} " class="latex" title="2^{L^d} " /> depth. Then, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by putting all of these individual circuits in parallel – this doesn’t violate any sort of no-cloning condition because the individual circuits act on disjoint sets of qubits. Therefore, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by a circuit of depth at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{L^d}" class="latex" title="2^{L^d}" />. <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> and <img src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d " class="latex" title="d " /> are both constants, so <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> can be generated by a constant-depth circuit.</p>

<p>We claim that, for the right choice of <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" />, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi\rangle " class="latex" title="|\phi\rangle " /> is also a low-energy state. Intuitively, this is true because <img src="https://s0.wp.com/latex.php?latex=%5Cphi+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi " class="latex" title="\phi " /> can only be “worse” than a true ground state of <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)} " class="latex" title="H^{(n)} " /> on local Hamiltonian terms that do not lie entirely within a single hypercube (i.e. the boundary terms), and by choosing <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> appropriately we can make this a vanishingly small fraction of the local terms of <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{(n)}" class="latex" title="H^{(n)}" />. Let’s work this out explicitly.</p>

<p>Each hypercube has surface area <img src="https://s0.wp.com/latex.php?latex=2dL%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2dL^{d-1}" class="latex" title="2dL^{d-1}" />, and there are <img src="https://s0.wp.com/latex.php?latex=n%2FL%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n/L^d " class="latex" title="n/L^d " /> hypercubes in the lattice. Thus, the total number of qubits on boundaries is at most <img src="https://s0.wp.com/latex.php?latex=2d%5Cfrac%7Bn%7D%7BL%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2d\frac{n}{L}" class="latex" title="2d\frac{n}{L}" />. The number of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-connected components containing a given point in a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-dimensional lattice is a function of <img src="https://s0.wp.com/latex.php?latex=k+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k " class="latex" title="k " /> and <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />. Both of these are constants. Therefore, the number of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-connected components containing a given vertex, and hence the number of local Hamiltonian terms containing a given qubit, is constant. Thus, the total number of violated local Hamiltonian terms is at most <img src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7BL%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\frac{n}{L})" class="latex" title="O(\frac{n}{L})" />. Taking <img src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L " class="latex" title="L " /> to be <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\epsilon}" class="latex" title="\frac{1}{\epsilon}" />, we get the desired bound. Note that to be fully rigorous, we need to justify that the boundary terms don’t blow up the energy, but this is left as an exercise for the reader. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>

<h3>Linearizing the Hamiltonian</h3>
<p>Now that we have shown that Hamiltonians that live on constant-dimensional lattices cannot be used to prove NLTS, we will put the final nail in the coffin by showing that our NLETS Hamiltonian (the Feynman-Kitaev clock Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> on the circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />) can be made to lie on a line (a <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />-dimensional lattice). To do so, we will need to understand the details of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> a bit better.</p>

<p><b><a id="prop6">Proposition 6.1</a></b>: <i><img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> for the circuit <img src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C " class="latex" title="C " /> is <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local.</i></p>

<p><i>Proof</i>: Recall that we defined</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3A%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t%2B++H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " class="latex" title="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " /></p></div>

<p>Let’s go through the right-hand-side term-by-term. We will use <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Btime%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathsf{time}(t)\rangle " class="latex" title="|\mathsf{time}(t)\rangle " /> to denote the <img src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t^{\text{th}} " class="latex" title="t^{\text{th}} " /> qubit of the time register and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Bstate%7D%28s%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathsf{state}(s)\rangle " class="latex" title="|\mathsf{state}(s)\rangle " /> to denote the <img src="https://s0.wp.com/latex.php?latex=s%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s^{\text{th}} " class="latex" title="s^{\text{th}} " /> qubit of the state register.</p>

<p>
  </p><ul>
    <li><img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> needs to serially access the qubit pairs

    <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cmathsf%7Btime%7D%280%29%5Crangle%5Cotimes%5Ctextsf%7Bstate%7D%28s%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " class="latex" title="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " />

    for all <img src="https://s0.wp.com/latex.php?latex=s+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s " class="latex" title="s " /> and ensure that they are all set to <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle" class="latex" title="|0\rangle" />. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{in} " class="latex" title="H_{in} " /> is <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />-local.</li>
    <li>Each <img src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_t " class="latex" title="H_t " /> term needs to access the states <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t-1%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle%2C+%7C%5Ctextsf%7Bstate%7D%28s%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" class="latex" title="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" />, and  <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{state}(t)\rangle " class="latex" title="|\textsf{state}(t)\rangle " /> and ensure that the state transitions are correct. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{t} " class="latex" title="H_{t} " /> is <img src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="5" class="latex" title="5" />-local.</li>
    <li><img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> needs to access the states

    <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " class="latex" title="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " />

    and ensure that the progression of the time register is correct. Thus, <img src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_{stab} " class="latex" title="H_{stab} " /> is <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />-local. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></li>
  </ul>
<p></p>


<p>Now, we follow an approach of [<a href="https://windowsontheory.org/feed/#aharonov2017">3</a>] to embed <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> into a line.</p>

<p><b>Theorem 3</b>: <i>The Feynman-Kitaev clock Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H " class="latex" title="H " /> can be manipulated into a <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local Hamiltonian acting on qutrits on a line.</i></p>

<p><i>Proof</i>: Rather than having <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> act on <img src="https://s0.wp.com/latex.php?latex=2n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2n " class="latex" title="2n " /> total qubits (<img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> time qubits and <img src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n " class="latex" title="n " /> state qubits), let’s fuse each <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(i)\rangle " class="latex" title="|\textsf{time}(i)\rangle " /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{state}(i)\rangle " class="latex" title="|\textsf{state}(i)\rangle " /> pair into a single qudit of dimension <img src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="4" class="latex" title="4" />. If we view <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> as acting on the space of particles <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" class="latex" title="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" />, we observe that, following <a href="https://windowsontheory.org/feed/#prop6">Proposition 6.1</a>, each local term needs to check at most the particles corresponding to times <img src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t-1" class="latex" title="t-1" />, <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, and <img src="https://s0.wp.com/latex.php?latex=t%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t+1" class="latex" title="t+1" />. Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> is <img src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3" class="latex" title="3" />-local and on a line, as desired.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/qutrits.png?w=600" alt="" class="wp-image-6979" />Image from [2]</figure>



<p>To see that we can have <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{H} " class="latex" title="\mathcal{H} " /> act on particles of dimension <img src="https://s0.wp.com/latex.php?latex=3+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3 " class="latex" title="3 " /> (qutrits) rather than particles of dimension <img src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="4" class="latex" title="4" />, note that the degree of freedom corresponding to <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+%3D+%7C0%5Crangle+%5Cotimes+%7C1%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " class="latex" title="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " /> is unused, as the <img src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t^{\text{th}} " class="latex" title="t^{\text{th}} " /> qubit of the state is never nonzero until timestamp <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. Thus, we can take the vectors</p>

<div style="text-align: center;"><p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C0%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C0%5Crangle%2C+%7C1%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C1%5Crangle%2C+%7C2%5Crangle+%3A%3D+%7C0%5Crangle%5Cotimes%7C0%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " class="latex" title="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " /></p></div>

<p>as a basis for each qutrit.</p>

<p>Even though we’ve shown that the clock Hamiltonian for our original circuit cannot be used to prove NLTS (which is still weaker than the original Quantum PCP conjecture) this does not necessarily rule out the use of this approach for other “hard” circuits which might then allow us to prove NLTS. Furthermore, NLETS is independently interesting, as the notion of being low “Hamming distance” away from vectors is exactly what is used in error-correcting codes.</p>

<h1>References</h1>
<ul>
<li><a id="arora2009computational">[1]</a> Sanjeev Arora and Boaz Barak. <i>Computational complexity: a modern approach.</i> Cambridge University Press, 2009.</li>
<li><a id="nirkhe2018approximate">[2]</a> Chinmay Nirkhe, Umesh Vazirani,  and Henry Yuen. Approximate low-weight check codes and circuit lower bounds for noisy ground states. <i>arXiv preprint arXiv:1802.07419</i>, 2018.</li>
<li><a id="aharonov2017">[3]</a> Dorit Aharonov, Wim van Dam, Julia Kempe, Zeph Landau, Seth Lloyd, and Oded Regev. Adiabatic quantum computation is equivalent to standard quantum computation. <i>SIAM J. Comput.</i>, 2007.</li></ul></div>







<p class="date">
by richardmwang <a href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/"><span class="datestr">at December 23, 2018 01:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6948">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/">Quantum Approximate Optimization Algorithm and Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2>Motivation</h2>
<p> </p>
<p>Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers outperforming classical computers) has been explored for three general groups of problems:</p>
<ol>
<li>Structured problems, such as factoring and discrete logarithm. Out quantum computer takes advantage of the structure of these classes of problems to offer an exponential speedup compared to the best known classical alternative. While these speedups are the most promising, they require a large number of resources and are cannot be feasibly implemented in the near future.</li>
<li>Quantum Simulations, originally proposed by Richard Feynman in the late 80s was thought to be the first motivation behind exploring quantum computation. Due to the fact that the space of all possible states of the system scales exponentially with the addition of a new element (eg. an atom), complex systems are very difficult to simulate classically. It has been shown that we can use a quantum computer to tackle interesting problems in quantum chemistry and chemical engineering. Furthermore, there are results on sampling the output of random quantum circuits which have been used for “quantum supremacy experiments”.</li>
<li>General constraint satisfaction and optimization problems. Since these problems are NP-hard it is widely believed that we cannot gain an exponential speedup using a quantum computer, however, we can obtain quadratic speedup but utilizing a variation of Grover’s algorithm.</li>
</ol>
<p>While these quantum algorithms are very exciting, they are beyond the capabilities of our near-term quantum computers; for example, any useful application of Shor’s factoring algorithm requires anywhere between tens of thousands to millions of qubits with error correction compared to quantum devices with hundreds of qubits that we might have available in the next few years.</p>
<p>Recently there has been increasing interest in hybrid classical-quantum algorithms among the community. The general idea behind this approach is to supplement the noisy intermediate-scale quantum (NISQ) devices with classical computers. In this blog post, we discuss the Quantum Approximate Optimization Algorithm (QAOA), which is a hybrid algorithm, alongside some of its applications.</p>
<h2>Introduction</h2>
<p>QAOA is used for optimizing combinatorial problems. Let’s assume a problem with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> bits and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> clauses. Each clause is a constraint on a subset of the bits which satisfies a certain assignment. We can define a cost function as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C%28z%29%3D%5Csum_%7B%5Calpha%3D1%7D%5Em+C_%5Calpha+%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " class="latex" title="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=z%3Dz_1z_2...z_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z=z_1z_2...z_n" class="latex" title="z=z_1z_2...z_n" /> is the bit string. In this article we consider a minimization problem, therefore we want <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha%28z%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha(z)=0" class="latex" title="C_\alpha(z)=0" /> if <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" /> satisfies clause <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> and 1 otherwise. Note that in the case of a maximization problem we only need to switch the value assigned to a satisfactory clause to 1. Our objective is to find a (qu)bit string that minimizes (or maximizes) our cost function.</p>
<p>At a higher level, we start with a quantum state in a uniform superposition of all possible inputs <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" />. This can be accomplished with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits which span a space of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" />. Our goal is to come up with a series of operations that would evolve our initial quantum state into a superposition of states in which the valid solutions would have a significantly higher probability than other states. In manner, upon sampling the quantum state we are likely to get the correct solution with high probability. QAOA uses the cost function to construct a set of operations that would be able to efficiently map the unifrom superposition state into the desired quantum state. These operators involve single qubits rotations around the x-axis, and multiqubit rotations around the z-axis of our qubits.</p>
<p>Now let’s discuss the details of QAOA. For this algorithm we assume that our quantum computer works in the computation basis of <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C0+%5Cright+%3E+%2C+%5Cleft+%7C+1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |0 \right &gt; , \left | 1 \right &gt; " class="latex" title="\left |0 \right &gt; , \left | 1 \right &gt; " />. We start by setting our initial state to a uniform superposition over computational basis states:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7Cs+%5Cright+%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5En%7D%7D%5Csum_%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%5Cleft+%7Cz+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " class="latex" title="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " /></p>
<p>Next, we define a unitary operator using the cost function as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U%28%5Chat%7BC%7D%2C%5Cgamma%29+%3D+e%5E%7Bi%5Cgamma+%5Chat%7BC%7D%7D%3D+%5Cprod_%7B%5Calpha+%3D+1%7D%5Em+e%5E%7B-i%5Cgamma+%5Chat%7BC%7D_%5Calpha%7D%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha} " class="latex" title="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha} " /></p>
<p>Here we convert every clause <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha" class="latex" title="C_\alpha" /> to a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}" class="latex" title="\hat{C_\alpha}" /> consisting of Pauli Z ($\sigma^z$) operators. Just as a review, the two Pauli operators (X and Z) used in this blog post are representated as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ex+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+0+%26+1+%5C%5C%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%5Cend%7Bpmatrix%7D+%5C%3A+%5C%3A+%5C%3A+%5C%3A++%5Csigma%5Ez+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%C2%A0%C2%A0%C2%A0+0+%26+-1+%5C%5C%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^x = \begin{pmatrix}    0 &amp; 1 \\    1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}    1 &amp; 0 \\    0 &amp; -1 \\\end{pmatrix} " class="latex" title="\sigma^x = \begin{pmatrix}    0 &amp; 1 \\    1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}    1 &amp; 0 \\    0 &amp; -1 \\\end{pmatrix} " /></p>
<p>For example if <img src="https://s0.wp.com/latex.php?latex=C_%5Calpha%3Dx+%5Coplus+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_\alpha=x \oplus y" class="latex" title="C_\alpha=x \oplus y" /> we can map the clause to <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D%3D%5Cfrac%7B1%7D%7B2%7D%281%2B%5Csigma%5Ez_x+%5Csigma%5Ez_y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" class="latex" title="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" /> for a minimization problem. If <img src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C0+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=\left |0 \right &gt;  " class="latex" title="x=\left |0 \right &gt;  " /> , then <img src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ez_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^z_x" class="latex" title="\sigma^z_x" /> will return a value of 1, and if <img src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=\left |1 \right &gt; " class="latex" title="x=\left |1 \right &gt; " /> the operator will return -1. The same applies to qubit <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> as well. Therefore it is not hard to see that if <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> have the same value, then the operator <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C_\alpha}" class="latex" title="\hat{C_\alpha}" /> as defined above will result in a 1, and it’ll result in 0 otherwise. Furthermore, since <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C}" class="latex" title="\hat{C}" /> has integer eigenvalues we can restrict the angle <img src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\gamma" class="latex" title="\gamma" /> to lie in <img src="https://s0.wp.com/latex.php?latex=%5B0%2C2%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[0,2\pi]" class="latex" title="[0,2\pi]" />.</p>
<p>Next, we define the admixing Hamiltonian:</p>
<p><img src="https://s0.wp.com/latex.php?latex=B%3D%5Csum_%7Bj%3D1%7D%5En+%5Csigma%5Ex_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B=\sum_{j=1}^n \sigma^x_j " class="latex" title="B=\sum_{j=1}^n \sigma^x_j " /></p>
<p>and use it to define a unitary operator which consists of a product of commuting one qubit operations:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29+%3D+e%5E%7B-i%5Cbeta+B%7D%3D+%5Cprod_%7Bj%3D1%7D%5En+e%5E%7B-i+%5Cbeta+%5Csigma_j%5Ex%7D%C2%A0%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}  " class="latex" title="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cin+%5B0%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta \in [0,\pi]" class="latex" title="\beta \in [0,\pi]" />. It’s easy to see that <img src="https://s0.wp.com/latex.php?latex=U%28%5CHat%7BC%7D%2C%5Cgamma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(\Hat{C},\gamma)" class="latex" title="U(\Hat{C},\gamma)" /> couples 2 or more qubits, while <img src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(B,\beta)" class="latex" title="U(B,\beta)" /> performs a single qubit rotation on the qubits in our system. Using these unitaries and our initial state we define a QAOA angle-dependent “ansatz” state as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%C2%A0%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E%3D+U%28B%2C%5Cbeta_p%29U%28%5CHat%7BC%7D%2C%5Cgamma_p%29...U%28B%2C%5Cbeta_1%29U%28%5CHat%7BC%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left |  \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " class="latex" title="\left |  \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 1" class="latex" title="p\geq 1" /> is the “depth” of our QAOA circuit, and <img src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cgamma%7D%3D%28%5Cgamma_p%2C...%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" class="latex" title="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" />, <img src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cbeta%7D%3D%28%5Cbeta_p%2C...%2C%5Cbeta_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" class="latex" title="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" /> are each a vector of length <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> controlling the angles for each layer. In the worst case scenario this state can be produce by a quantum circuit of depth <img src="https://s0.wp.com/latex.php?latex=mp%2Bp&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="mp+p" class="latex" title="mp+p" />, however by taking advantage of the structure of the instance we can further reduce the number of layers required. Let <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> be the expectation of <img src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hat{C}" class="latex" title="\hat{C}" /> in our ansatz:</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29%3D%5Cleft+%3C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%7C+%5Chat%7BC%7D+%5Cleft+%7C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " class="latex" title="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " /></p>
<p>and let <img src="https://s0.wp.com/latex.php?latex=M_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p" class="latex" title="M_p" /> be the minimum of <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> over angles,</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_p%3D%5Cmin_%7B%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%7D+F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " class="latex" title="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " /></p>
<p>Note that minimization at <img src="https://s0.wp.com/latex.php?latex=p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p-1" class="latex" title="p-1" /> layers can be viewed as a constrained minimization at <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> layers, therefore</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_p+%5Cleq+M_%7Bp-1%7D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_p \leq M_{p-1}  " class="latex" title="M_p \leq M_{p-1}  " /></p>
<p>Using an adiabatic approach [1] We can show that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bp+%5Crightarrow+%5Cinfty%7D+M_p+%3D+%5Cmin_z+C%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " class="latex" title="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " /></p>
<p>Based on these results our QAOA algorithm will look like the following:</p>
<ul>
<li> c: pick a <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /></li>
<li>c: choose a set of angles <img src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D_0%2C%5CVec%7B%5Cbeta%7D_0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\Vec{\gamma}_0,\Vec{\beta}_0)" class="latex" title="(\Vec{\gamma}_0,\Vec{\beta}_0)" /></li>
<li>q: prepare <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " /></li>
<li>q: compute <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /></li>
<li>c: perform gradient descend/ascend on <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> and get a new set of angles <img src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\Vec{\gamma},\Vec{\beta})" class="latex" title="(\Vec{\gamma},\Vec{\beta})" /></li>
<li>repeat from step 3 till convergence</li>
<li>report the measurement result of <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " /> in computational basis</li>
</ul>
<p>If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> does not asymptotically grow with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> <img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})" class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})" /> can be efficiently computed in <img src="https://s0.wp.com/latex.php?latex=O%28m%5E2%2Bmn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(m^2+mn)" class="latex" title="O(m^2+mn)" /></p>
<h2>Application: MaxCut</h2>
<p>In this section we apply the QAOA algorithm to the MaxCut problem with bounded degree. MaxCut is an NP-hard problem that asks for a subset <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> of the vertex set such that the number of edges between <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> and the complementary subset is as large as possible. While QAOA does not offer a theoretical guarantee to solve MaxCut in polynomial time, it offers a path to utilizing NISQ devices for tackling such optimization problems and discuss patterns in such problems that can be used for reducing the number of steps required.</p>
<p>For this section, let’s assume <img src="https://s0.wp.com/latex.php?latex=p%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p=O(1)" class="latex" title="p=O(1)" />, and we have a graph with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vertices and an edge set <img src="https://s0.wp.com/latex.php?latex=%5C%7B%3Cjk%3E%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{&lt;jk&gt;\}" class="latex" title="\{&lt;jk&gt;\}" /> of size <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />. We can construct a cost function to be maximized as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C+%3D+%5Csum_%7B%3Cjk%3E%7D+C_%7B%3Cjk%3E%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " class="latex" title="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%281-%5Csigma%5Ez_j+%5Csigma%5Ez_k%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " class="latex" title="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " /></p>
<p>We can the compute the angle dependent cost of our ansatz as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_%7B%3Cjk%3E%7D%5Cleft+%3C%7Bs%7D+%5Cright+%7C+U%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " /></p>
<p>Let’s consider the operation associated with some edge <img src="https://s0.wp.com/latex.php?latex=%3Cjk%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="&lt;jk&gt;" class="latex" title="&lt;jk&gt;" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=U+%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " class="latex" title="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " /></p>
<p>Since QAOA consists of local operations, we may take advantage by thinking about the problem in terms of subproblems (or subgraphs) involving certain nodes. This property will allow us to simplify our clauses even further depending on the desired depth <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> of our quantum circuit, therefore decreasing the amount of resources necessary to implement the algorithm.</p>
<p>The operator <img src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{&lt;jk&gt;}" class="latex" title="C_{&lt;jk&gt;}" /> includes qubits (nodes) <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />, therefore the sequence of operators above will only involve qubits that are at most distance <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> away from qubits <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> and <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. Let’s consider the example of <img src="https://s0.wp.com/latex.php?latex=p%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p=1" class="latex" title="p=1" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crightarrow+U%5E%5Cdagger%28C%2C%5Cgamma_1%29e%5E%7Bi%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+C_%7B%3Cjk%3E%7D+e%5E%7B-i%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+U%28C%2C%5Cgamma_1%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " class="latex" title="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " /></p>
<p>It’s easy to see that any factor of <img src="https://s0.wp.com/latex.php?latex=U%28C%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(C,\gamma_1)" class="latex" title="U(C,\gamma_1)" /> that does not depend on <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> or <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> will commute through and cancel out. Since the degree is bounded, each subgraph contains a number of qubits that is independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, which allows for the evaluation of <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> in terms of subsystems of size independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />.</p>
<p>For an subgraph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> define:</p>
<p><img src="https://s0.wp.com/latex.php?latex=C_G%3D%5Csum_%7B%3Cl+l%5E%5Cprime%3E%7D+C_%7B%3Cl+l%5E%5Cprime%3E%7D%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28C_G%2C%5Cgamma%29%3De%5E%7B-i+%5Cgamma+C_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}  \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " class="latex" title="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}  \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=B_G+%3D+%5Csum_%7Bj+%5Cin+G%7D+%5Csigma%5Ex_j%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28B_G%2C%5Cbeta%29+%3D+e%5E%7B-i+%5Cbeta+B_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B_G = \sum_{j \in G} \sigma^x_j  \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " class="latex" title="B_G = \sum_{j \in G} \sigma^x_j  \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+s%2CG+%5Cright+%3E+%C2%A0%C2%A0%3D+%5Cprod_%7Bl+%5Cin+G%7D+%5Cleft+%7C%2B+%5Cright+%3E+_l++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | s,G \right &gt;   = \prod_{l \in G} \left |+ \right &gt; _l  " class="latex" title="\left | s,G \right &gt;   = \prod_{l \in G} \left |+ \right &gt; _l  " /></p>
<p>We can define our total cost as a sum over the cost of each subgraph:</p>
<p><img src="https://s0.wp.com/latex.php?latex=f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Cleft+%3C+s%2Cg%28j%2Ck%29+%5Cright+%7C%C2%A0+U+%5E%5Cdagger%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29...U%5E%5Cdagger%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+...+U%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs%2Cg%28j%2Ck%29+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |  U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " class="latex" title="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |  U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=g%28j%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g(j,k)" class="latex" title="g(j,k)" /> is a subgraph of type <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> and “…” is used to omit the sequence of angle depending unitaries constructed using the elements of <img src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Vec{\gamma}" class="latex" title="\Vec{\gamma}" /> and <img src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Vec{\beta}" class="latex" title="\Vec{\beta}" />. <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> is then</p>
<p><img src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_g+w_g+f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " class="latex" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_g" class="latex" title="w_g" /> is the number of occurrence of the subgraph <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> in the original edge sum. The function <img src="https://s0.wp.com/latex.php?latex=f_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_g" class="latex" title="f_g" /> does not depend on <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />, and the only dependence on these variables comes through the weights <img src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_g" class="latex" title="w_g" /> from the original graph. The maximum number of qubits that can appear in our sequence of operators comes when the subgraph is a tree. For a graph with maximum degree <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" />, the number of qubits in this tree is</p>
<p><img src="https://s0.wp.com/latex.php?latex=q_%7Btree%7D%3D2%5B%5Cfrac%7B%28v-1%29%5E%7Bp%2B1%7D-1%7D%7B%28v-1%29-1%7D%5D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " class="latex" title="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " /></p>
<p>(or <img src="https://s0.wp.com/latex.php?latex=2p%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2p+2" class="latex" title="2p+2" /> if <img src="https://s0.wp.com/latex.php?latex=v%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v=2" class="latex" title="v=2" />), which is independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />. Therefore we can see that for constant <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> <img src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p" class="latex" title="F_p" /> can be efficiently computed.</p>
<p>Next, let’s consider the spread of C measured in the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " class="latex" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt;  " />.</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft+%3C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C%5E2%5Cleft+%7C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%5Cright+%3E+%C2%A0-%5Cleft+%3C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C+%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%5E2+%5Cleq+2%5B%5Cfrac%7B%28v-1%29%5E%7B2p%2B2%7D-1%7D%7B%28v-1%29-1%7D%5D.m++&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt;  -\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " class="latex" title="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt;  -\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " /></p>
<p>For fixed <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" /> and <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> we see that the standard deviation of <img src="https://s0.wp.com/latex.php?latex=C%28z%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(z)" class="latex" title="C(z)" /> is upper-bounded by <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\sqrt{m})" class="latex" title="O(\sqrt{m})" />. Using this fact and the appropriate probability bounds we can see that the result of measuring the cost function of the state <img src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2Cvec%7B%5Cbeta_%7Bopt%7D%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt;  " class="latex" title="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt;  " /> will be very close to the intended value of <img src="https://s0.wp.com/latex.php?latex=F_p%28%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2C%5Cvec%7B%5Cbeta_%7Bopt%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" class="latex" title="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" /> which bounds the uncertainty present in quantum measurement.</p>
<h2>Bibliography</h2>
<p>[1] E. Farhi, J. Goldstone, and S. Gutmann, “A Quantum Approximate Optimization Algorithm,” 2014.</p>
<p>[2] J. S. Otterbach, et. al, “Unsupervised Machine Learning on a Hybrid Quantum Computer,” 2017.</p></div>







<p class="date">
by karamlou <a href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/"><span class="datestr">at December 22, 2018 11:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html">Circles crossing at equal angles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Let , , , and  be four circles, with pairs , , , and  crossing at equal angles (and no crossings among the other two pairs). Then it turns out that the two curvy quadrilaterals forming the inside and outside boundaries of the union of disks each have a circle through their four vertices:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-45.svg" alt="Four circles crossing at equal angles, and the two circles through their crossing points" /></p>

<p>The proof of the theorem is not difficult, once you notice that it’s invariant under Möbius transformations: the four given circles and their crossing angles transform to another four circles with the same crossing angles, preserving any cocircularities among the eight crossing points.
So start by finding a Möbius transformation that makes two opposite circles  and  become the same size as each other. Because of the equality of crossing angles, both of the other two circles must have centers on the perpendicular bisector to line . There’s still a one-dimensional family of Möbius transformations remaining that preserves the position of  and  but moves the other circles along this bisector; use this remaining degree of freedom to move the other two circles so that their centers are equidistant from line . Then, because of the equality of crossing angles, circles  and  must have the same radii. So we have transformed the input to a position where the circles are centered at the vertices of a rhombus with opposite pairs having the same radius. By symmetry, the crossing points must lie on two rectangles, and the four corners of each rectangle are cocircular.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-rect.svg" alt="Four circles crossing at equal angles at the corners of a rhombus, and the two rectangles through their crossing points" /></p>

<p>This can be extended to some configurations of circles where the opposite pairs cross each other rather than staying disjoint, but you have to be more careful about what happens when more than two circles cross at one point, and about determining which of the two supplementary angles at each crossing to use as the crossing angle of the two circles. If you’re not careful, you get situations like the one below  where two degenerate circles (the coordinate axes) are crossed at equal angles by two more circles, but where the eight crossings do not form another two circles.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-bad.svg" alt="Two degenerate circles (the coordinate axes) and two circles that cross them at equal angles, without forming two more sets of four cocircular points" /></p>

<p>Maybe the easiest way to state the more general result is that if a non-self-crossing quadrilateral with circular-arc sides has four equal interior angles at its vertices, then it is <a href="https://en.wikipedia.org/wiki/Cyclic_quadrilateral">cyclic</a>.
I used a special case of this, for right-angled quadrilaterals, in my paper “A Möbius-invariant power diagram and its applications to soap bubbles and planar Lombardi drawing” (<a href="https://doi.org/10.1007/s00454-014-9627-0"><em>Discrete Comput. Geom.</em> 2014</a>).
This formulation also works for the special case when all four angles are zero, which was used in a mesh generation algorithm by Bern, Mitchell, and Ruppert (“Linear-size nonobtuse triangulation of polygons”, <a href="https://doi.org/10.1007/BF02570715"><em>Discrete Comput. Geom.</em> 1995</a>).</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/4circle-cusp.svg" alt="A chain of four tangent circles and a fifth circle through their four points of tangency" /></p>

<p>I don’t know whether this theorem has appeared previously, but it’s obviously related to <a href="https://11011110.github.io/blog/2006/03/22/miquels-six-circles.html">Miquel’s six-circle theorem</a>, which takes five circles (without assumption about angles) and produces a sixth in a configuration closely resembling what you get from the four given circles and two produced circles of this theorem.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101287137001551762"></a>, <a href="https://plus.google.com/100003628603413742554/posts/9p3Hza4hGE1">G+</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html"><span class="datestr">at December 22, 2018 02:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15529">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/">Explanations and Explorations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Comparing proofs for the Jaccard metric</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg?w=142&amp;h=158" alt="" height="158" class="alignright wp-image-15530" width="142" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">BetterExplained <a href="https://betterexplained.com/about/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Kalid Azad is the founder of the <a href="https://betterexplained.com/">website</a> <em>Better Explained</em>. It is devoted to explaining mathematical concepts. He also has written <a href="https://betterexplained.com/ebook/math/">two</a> <a href="https://www.amazon.com/gp/product/B017ZXWY3U/">books</a>. </p>
<p>
Today we discuss how some proofs provide a concise <em>explanation</em> whereas others promote <em>exploration</em> of related concepts.<br />
<span id="more-15529"></span></p>
<p>
Azad’s site has a rich <a href="https://betterexplained.com/articles/proofs-vs-explanations/">page</a> titled, “Math Proofs vs. Explanations (aka Nutrition vs. Taste).” It argues that the best <em>explanations</em> start with an analogy to a relation that readers already understand. Even if the connection is not sharp, it can be refined once the reader’s attention is solid. This is opposed to a formal proof in which every step is sharp and correct but intuition is wanting.</p>
<p>
To this we add the role proofs can play in <em>exploration</em>. If you have one proof of a theorem that you understand, there is value in seeking other proofs that use other ideas. Usually we think of ideas as coming first—as thoughts we refine into a proof. The advantage of starting with a proof is already having certitude and sharpness—you know a recipe that works and now can try varying and augmenting it. </p>
<p>
</p><p></p><h2> Jaccard Distance as Example </h2><p></p>
<p></p><p>
Azad’s page gives examples of proofs for the Pythagorean Theorem and for <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%7D+%3D+%5Ccos%28%5Ctheta%29+%2B+i%5Csin%28%5Ctheta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" class="latex" title="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" />. It then quotes from William Thurston’s <a href="http://arxiv.org/abs/math/9404236">essay</a> “On Proofs and Progress in Mathematics,” which we once <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">mentioned</a>. We will use the example of Jaccard distance <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta}" class="latex" title="{J_\delta}" /> from our previous <a href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/">post</a>. We start with this definition: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CB%29+%3D+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " class="latex" title="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " /></p>
<p>now using <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> for the symmetric difference <img src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Ccup+B%29+%5Csetminus+%28A+%5Ccap+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A \cup B) \setminus (A \cap B)}" class="latex" title="{(A \cup B) \setminus (A \cap B)}" />. So the triangle inequality becomes, for any finite sets <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" />: <a name="triangle"></a></p><a name="triangle">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cleq+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" class="latex" title="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" /></p>
</a><p><a name="triangle"></a> We think the proof we gave in the last post is simple and direct and intuitive but maybe not explorative. It first connects the solid understanding that without the denominators this would be the well-known triangle inequality for Hamming distance. To reprise, it considers <img src="https://s0.wp.com/latex.php?latex=%7BA%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,C}" class="latex" title="{A,C}" /> fixed and varies <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> to arrive at that simpler fact in three steps:</p>
<ol>
<li>
If <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> contains <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> elements not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> then removing them subtracts <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> from both right-hand numerators and both right-hand denominators. Since those fractions are each <img src="https://s0.wp.com/latex.php?latex=%7B%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt; 1}" class="latex" title="{&lt; 1}" /> (else <a href="https://rjlipton.wordpress.com/feed/#triangle">1</a> would be immediately true), the right-hand side goes down. <p></p>
</li><li>
Then we have <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> and can replace the denominators by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> without increasing the right-hand side. <p></p>
</li><li>
Now we have a common denominator and a statement equivalent to the known truth about Hamming distance. Since undoing the first two steps to restore the original <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> can only increase the right-hand side, (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is proved in all cases.
</li></ol>
<p>
This reasoning readily extends to nonnegative measures <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> on <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" /> besides simple counting, provided the removal of elements from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> makes the same additive-or-proportional change to <img src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5C%3B%5CDelta%5C%3B+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(A \;\Delta\; B)}" class="latex" title="{f(A \;\Delta\; B)}" /> as it does to <img src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5Ccup+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(A \cup B)}" class="latex" title="{f(A \cup B)}" />, and likewise for the other fraction. </p>
<p>
</p><p></p><h2> Three Snapshot Proofs </h2><p></p>
<p></p><p>
The first short proof should join the pantheon of half-page journal papers. Under fair use, here it is in one screenshot:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png"><img src="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png?w=295&amp;h=410" alt="" height="410" class="aligncenter wp-image-15547" width="295" /></a></p>
<p>
Perhaps this is <i>too</i> short. We think this proof would have been more satisfying if a few more lines of calculation had been added. Let us divide the region <img src="https://s0.wp.com/latex.php?latex=%7BT_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_1}" class="latex" title="{T_1}" /> into its inner part <img src="https://s0.wp.com/latex.php?latex=%7BT_%7B1i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{1i}}" class="latex" title="{T_{1i}}" /> and outer part <img src="https://s0.wp.com/latex.php?latex=%7BT_%7B1o%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{1o}}" class="latex" title="{T_{1o}}" /> and do likewise for <img src="https://s0.wp.com/latex.php?latex=%7BT_2%2CT_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_2,T_3}" class="latex" title="{T_2,T_3}" />. Then it seems the intent was: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++d%28S_1%2CS_3%29+%26%3D%26+1+-+%5Cfrac%7B%7CS_1+%5Ccap+S_3%7C%7D%7B%7CS_1+%5Ccup+S_3%7C%7D++%3D+1+-+%5Cfrac%7B%7CT_%7B2i%7D%7C+%2B+%7CV%7C%7D%7B%7CU%7C+-+%7CT_%7B2o%7D%7C%7D%5C%5C+%26%5Cleq%26+1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CU%7C+-+%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C+-+%7CT_%7B3o%7D%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C+-+%7CT_%7B1o%7D%7C%7D+%3D+d%28S_1%2CS_2%29+%2B+d%28S_2%2CS_3%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " /></p>
<p>The end uses the symmetric-difference definition of <img src="https://s0.wp.com/latex.php?latex=%7BJ_%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_{\delta}}" class="latex" title="{J_{\delta}}" />, so perhaps fully expanding this paper’s intent would have been longer. One can also begin with that definition to get a shorter calculation, but it skips over the <img src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 - \frac{|V|}{|U|}}" class="latex" title="{1 - \frac{|V|}{|U|}}" /> step. Indeed, it does not mention <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> at all, so it was not intended. The proof by Artur Grygorian and Ionut Iacob in a short <a href="https://www.tandfonline.com/doi/abs/10.1080/07468342.2018.1526020">paper</a> in last October’s <em>College J. Math.</em> strikes us as a similar-style proof. </p>
<p>
The second proof comes from a MathOverflow <a href="https://mathoverflow.net/q/315845">thread</a>. It assigns a variable to each region of the Venn diagram, forms the fractions, and cross-multiplies to obtain “the following monstrosity”:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg"><img src="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg?w=400&amp;h=232" alt="" height="232" class="aligncenter wp-image-15532" width="400" /></a></p>
<p>
The fact that no coefficient is negative completes the proof. This is clear from a computer algebra system, but what about <em>why</em> no negative term appears? </p>
<p>
We have realized since the last post that the second of two proofs given in the 2016 <a href="https://arxiv.org/pdf/1612.02696.pdf">paper</a> by Sven Kosub, which we linked in that post, is really equivalent to ours. This is easier to see if one just presumes <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(\emptyset) = 0}" class="latex" title="{f(\emptyset) = 0}" /> in the following:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png"><img src="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png?w=500&amp;h=360" alt="" height="360" class="aligncenter wp-image-15533" width="500" /></a></p>
<p>
Here <em>sub-modularity</em> is a standard property for which Kosub cites the equivalent condition that whenever <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq D}" class="latex" title="{B \subseteq D}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cnotin+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \notin D}" class="latex" title="{x \notin D}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28B+%5Ccup%5C%7Bx%5C%7D%29+-+f%28B%29+%5Cgeq+f%28D+%5Ccup+%5C%7Bx%5C%7D%29+-+f%28D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " class="latex" title="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " /></p>
<p>This suffices for step 1 of our earlier proof, first taking <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+A+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = A \cup B}" class="latex" title="{D = A \cup B}" /> then <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+B+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = B \cup C}" class="latex" title="{D = B \cup C}" />; the rest of that proof needs only that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is monotone (and implicitly <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(\emptyset) = 0}" class="latex" title="{f(\emptyset) = 0}" />). </p>
<p>
</p><p></p><h2> A Magical Proof </h2><p></p>
<p></p><p>
Now we look at proofs that add ideas. The first one still strikes us as clean and magical. We are computer scientists so it is natural to think of finite sets as binary-valued vectors of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. They have a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in position <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> precisely when <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> is in the set. Of course <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the size of the “universe.” </p>
<p>
Now let <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> be such a non-zero vector. The key is to use a probabilistic proof. We will show that we can relate the Jaccard distance to the outcome of a simple random experiment. The experiment once selected leads to a simple proof—it only requires the union bound. Recall this is the fact that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%5BE_%7B1%7D+%5Cvee+E_%7B2%7D%5D+%5Cle+P%5BE_%7B1%7D%5D+%2BP%5BE_%7B2%7D%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " class="latex" title="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " /></p>
<p>for any two events <img src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{1}}" class="latex" title="{E_{1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BE_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{2}}" class="latex" title="{E_{2}}" />. </p>
<p>
The cool idea is to look at the permutations of the vector <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. For a permutation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" /> let us define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(X)}" class="latex" title="{\pi(X)}" /> to be 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_%7B%5Cpi%281%29%7D%2C%5Ccdots%2Cx_%7B%5Cpi%28n%29%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " class="latex" title="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28X%29%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(X)=i}" class="latex" title="{\mathsf{first}(X)=i}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i}}" class="latex" title="{x_{i}}" /> is the first value that is equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Of course since <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is non-empty it follows that this is well defined. </p>
<p>
Note <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X))}" class="latex" title="{\mathsf{first}(\pi(X))}" /> is a random variable that depends on the choice of the permutation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" />. The key is to see that the probability that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%3D%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" class="latex" title="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" /> when we average over all permutations uniformly is equal to 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CX+%5Ccap+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " class="latex" title="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " /></p>
<p>This follows by noting that there are <img src="https://s0.wp.com/latex.php?latex=%7B%7CXY%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|XY|}" class="latex" title="{|XY|}" /> ways to select the same <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and there are <img src="https://s0.wp.com/latex.php?latex=%7B%7CX+%5Ccup+Y%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|X \cup Y|}" class="latex" title="{|X \cup Y|}" /> total ways to select an <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. Complementing gives us that the probability of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" class="latex" title="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta(X,Y)}" class="latex" title="{J_\delta(X,Y)}" />.</p>
<p>
Now hark back to our sets <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" />. The event </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " class="latex" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " /></p>
<p>is subsumed by the disjunction of events </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cvee+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " class="latex" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " /></p>
<p>regardless of what <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is. By the simple union bound, the probability of the first event is at most the sum of the probabilities of the latter two events. We have thus proved </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CC%29+%5Cleq+J_%5Cdelta%28A%2CB%29+%2B+J_%5Cdelta%28B%2CC%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " class="latex" title="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " /></p>
<p>
The last step is the same as in the proof that Hamming distance is a metric. What does the randomized view gain us? It gains a nice interpretation of <img src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J_\delta(A,B)}" class="latex" title="{J_\delta(A,B)}" /> as the probability that <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> hash to different values under the <em>min-hash</em> function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%5Ccirc%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{first}\circ\pi}" class="latex" title="{\mathsf{first}\circ\pi}" /> for random <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" />. Min-hashing is used all the time—see this <a href="http://infolab.stanford.edu/~ullman/mmds/ch3.pdf">book chapter</a> by Jure Leskovec, Anand Rajaraman, and Jeffrey Ullman, with this proof in section 3.3.3. 		 </p>
<p></p><h2> A Gradient Idea </h2><p></p>
<p></p><p>
Atri Rudra suggested to us the “game” of adjusting <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> one element at a time to walk it toward an extreme value. The sets <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> can be adjusted too. We start by assuming the triangle inequality (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is false and make moves that can only keep it that way, until we reach a case where it is obviously true. </p>
<p>
Step 1 of our proof already plays this game by removing from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> any elements not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. So we really start the game with <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> and we want to walk it to <img src="https://s0.wp.com/latex.php?latex=%7BB+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B = A \cup C}" class="latex" title="{B = A \cup C}" />. Simply replacing the denominators <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup B|}" class="latex" title="{|A \cup B|}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \cup C|}" class="latex" title="{|B \cup C|}" /> in (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> was good in step 2 of the proof but is not a legal move in this game. </p>
<p>
What we can do legally is add elements from <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cap C}" class="latex" title="{A \cap C}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />: those leave the denominators unchanged but lower the numerators <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \;\Delta\; B|}" class="latex" title="{|A \;\Delta\; B|}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \;\Delta\; C|}" class="latex" title="{|B \;\Delta\; C|}" />. The interesting case is when we want to add to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> an element from <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Csetminus+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \setminus C}" class="latex" title="{A \setminus C}" /> or from <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Csetminus+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \setminus A}" class="latex" title="{C \setminus A}" />. The former add decreases the numerator <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \;\Delta\; B|}" class="latex" title="{|A \;\Delta\; B|}" /> and increases the denominator <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \cup C|}" class="latex" title="{|B \cup C|}" /> while leaving <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup B}" class="latex" title="{A \cup B}" /> unchanged, but it <em>increases</em> the numerator <img src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|B \;\Delta\; C|}" class="latex" title="{|B \;\Delta\; C|}" />. Let us abstract the right-hand side of (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{q} + \frac{r}{s}}" class="latex" title="{\frac{p}{q} + \frac{r}{s}}" />. Then the former add converts it to </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+%5Cqquad%5Ctext%7Band+the+latter+add+to%7D%5Cqquad+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " class="latex" title="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " /></p>
<p>If <em>both</em> moves increase the right-hand side, then we must have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D%2C+%5Cquad%5Ctext%7Bso%7D%5Cquad+%5Cfrac%7B1%7D%7Bq%7D+%3C+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+-+%5Cfrac%7Br%7D%7Bs%7D+%3D+%5Cfrac%7Bs-r%7D%7Bs%28s%2B1%29%7D+%3C+%5Cfrac%7B1%7D%7Bs%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " class="latex" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " /></p>
<p>And from </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D%2C+%5Cquad%5Ctext%7Bwe+get%7D%5Cquad+%5Cfrac%7B1%7D%7Bs%7D+%3C+%5Cfrac%7B1%7D%7Bq%2B1%7D%5C%3B.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " class="latex" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " /></p>
<p>But cross-multiplying gives the contradiction <img src="https://s0.wp.com/latex.php?latex=%7Bq%2B+1+%3C+s+%3C+s%2B1+%3C+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q+ 1 &lt; s &lt; s+1 &lt; q}" class="latex" title="{q+ 1 &lt; s &lt; s+1 &lt; q}" />. So one or both moves must always be possible. This grows <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> to include either all of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> or all of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The rest of the argument to gobble up all of <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> we leave to you, dear readers.</p>
<p>
Compared to the above proofs, this is tedious. But it captures some tensions among the sizes of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> that may inform intuitions about Jaccard similarity under changes in the sets. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Which proof do you like best for explanation and which for creative impulse? </p>
<p>
This is our <img src="https://s0.wp.com/latex.php?latex=%7B801%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{801^{st}}" class="latex" title="{801^{st}}" /> post. We intended this discussion as number 800 but were surprised to find the simple proof by reduction to triangle for Hamming distance (steps numbered 1-2-3 above). Are we really the first to write it down, with acknowledgment also to Kosub?</p>
<p>
[some typo fixes]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/"><span class="datestr">at December 22, 2018 01:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6524">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">Tensor Networks, Matrix Product States and Density Matrix Renormalization Group</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>by Fred Zhang</strong></p>
<p><em>This is the second installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given by the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. For the basic definitions of local Hamiltonians, see <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">Ben’s first post</a>. Also check out <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">Boriana and Prayaag’s followup note</a> on area laws.</em></p>
<p>This post introduces tensor networks and matrix product states (MPS). These are useful linear-algebraic objects for describing quantum states of low entanglement.</p>
<p>We then discuss how to efficiently compute the ground states of the Hamiltonians of <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{1}" class="latex" title="{1}" />D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.</p>
<p><b>1. Introduction </b></p>
<p class="p1">We are interested in computing the ground state—the minimum eigenvector—of a quantum Hamiltonian, a <img src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n \times 2^n" class="latex" title="2^n \times 2^n" /> complex matrix that governs the evolution of a quantum system of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits. We restrict our attention to the local Hamiltonian, where the matrix is a sum of Hamiltonians each acting only on <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> qubits.  In the previous article, we discussed some hardness results. Namely, a local Hamiltonian can be used to encode SAT instances, and we further gave a proof that computing the ground state is QMA-Complete.</p>
<p>Despite the hardness results, physicists have come up with a variety of heuristics for solving this problem. If quantum interactions occur locally, we would hope that its ground state has low entanglement and thus admits a succinct classical representation. Further, we hope to find such a representation efficiently, using classical computers.</p>
<p>In this note, we will see <i>tensor networks</i> and <i>matrix product states</i> that formalize the idea of succinctly representing quantum states of low entanglement. As a side remark for the theoretical computer scientists here, one motivation to study tensor network is that it provides a powerful visual tool for thinking about linear algebra. It turns indices into edges in a graph and summations over indices into contractions of edges. In particular, we will soon see that the most useful inequality in TCS and mathematics can be drawn as a cute tensor network.</p>
<p></p><div style="width: 276px;" id="attachment_6535" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note0x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600" alt="" class="wp-image-6535 size-full" /></a><p class="wp-caption-text">Guess what this is?</p></div><p></p>
<p>In the end, we will discuss the density matrix renormalization group (DMRG), which has established itself as “the most powerful tool for treating 1D quantum systems” over the last decade [<a href="https://windowsontheory.org/feed/#Xfehske2007computational">FSW07</a>]. For many 1D systems that arise from practice, the heuristic efficiently finds an (approximate) ground state in its matrix product state, specified only by a small number of parameters.</p>
<p><b>2. Tensor Networks </b></p>
<p>Now let us discuss our first subject, <i>tensor networks</i>. If you have not seen <i>tensors</i> before, it is a generalization of matrices. In computer scientists’ language, a matrix is a two-dimensional array, and a tensor is a multi-dimensional array. In other words, if we think of a matrix as a square, then a 3 dimensional tensor looks like a cube. Formally, a (complex) n dimensional tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{T}" class="latex" title="{T}" /> maps <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> indices to complex values, namely, to its entries:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T+%3A+%5Bd_1%5D+%5Ctimes+%5Bd_2%5D+%5Ctimes+%5Ccdots+%5Ctimes+%5Bd_n%5D+%5Crightarrow+%5Cmathbb%7BC%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." class="latex" title="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." /></p>
<p>The simplest tensor network is a graphical notation for a tensor. For an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{n}" class="latex" title="{n}" />-dimensional tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, we draw a star graph and label the center as <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> and the edges as the indices. To evaluate this tensor network, we put values on the edges, <i>i.e.</i>, indices, and then the tensor network would spit out its entry specified by the indices.</p>
<p></p><div style="width: 170px;" id="attachment_6550" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note2x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note2x.png?w=600" alt="" class="wp-image-6550 size-full" /></a><p class="wp-caption-text">A simple tensor network of 4 dimensions <a name="figsimp-1"></a></p></div><p></p>
<p></p><div style="width: 354px;" id="attachment_6551" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note3x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note3x.png?w=600" alt="" class="wp-image-6551 size-full" /></a><p class="wp-caption-text">Evaluating a simple tensor network, <img src="https://s0.wp.com/latex.php?latex=%7BT%281%2C5%2C3%2C1%29%3D1%2F%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(1,5,3,1)=1/\sqrt{2}}" class="latex" title="{T(1,5,3,1)=1/\sqrt{2}}" />. The numbers are chosen arbitrarily.<a name="figsimp-2"></a></p></div><p></p>
<p>Notice that the degree of the center is the number of indices. Hence, a tensor network of degree <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> is a vector, and that of degree <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> is a matrix, and so forth.<a name="figsimple-tn"></a></p>
<p></p><div style="width: 34px;" id="attachment_6574" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note6x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note6x.png?w=600" alt="" class="wp-image-6574 size-full" /></a><p class="wp-caption-text">A vector</p></div><p></p>
<p></p><div style="width: 106px;" id="attachment_6575" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note7x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note7x.png?w=600" alt="" class="wp-image-6575 size-full" /></a><p class="wp-caption-text">A matrix</p></div><p></p>
<p></p><div style="width: 158px;" id="attachment_6576" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note8x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note8x.png?w=600" alt="" class="wp-image-6576 size-full" /></a><p class="wp-caption-text">A 3d tensor</p></div><p></p>
<p>How is this related to quantum information? For the sake of genearlity we will deal with qudits in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb{C}^d}" class="latex" title="{\mathbb{C}^d}" />, instead of qubits in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb{C}^2}" class="latex" title="{\mathbb{C}^2}" />. Now recall that a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi_n%5Crangle%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{|\psi_n\rangle}" class="latex" title="{|\psi_n\rangle}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{n}" class="latex" title="{n}" /> qudits can be encoded as an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> dimensional tensor. It can be written as</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_n%5Crangle+%3D+%5Cdisplaystyle%5Csum_%7Bi_1%2C%5Ccdots%2Ci_n+%3D+0%7D%5E%7Bd-1%7D+T%28i_1%2C%5Ccdots%2C+i_n%29+%7Ci_1%2C%5Ccdots%2C+i_n+%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." class="latex" title="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." /></p>
<p>It is easy to see that all the information, namely, the amplitudes, is just the tensor <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. In the later sections, we will see more powerful examples of using tensor networks to represent a quantum state.</p>
<p>So far our discussion is focused merely on these little pictures. The power of tensor networks come from its composition rules, which allow us to join two simple tensor networks together and impose rich internal structures.</p>
<p><b> 2.1. Composition Rules </b></p>
<p>We introduce two ways of joining two simple tensor networks. Roughly speaking, they correspond to multiplication and summation, and I will give the definitions by showing examples, instead of stating them in the full formalism</p>
<p><strong>Rule #1: Tensor Product.</strong> The product rule allows us to put two tensor networks together and view them as a whole. The resulting tensor is the tensor product of the two if we think of them as vectors. More concretely, consider the following picture.</p>
<p></p><div style="width: 364px;" id="attachment_6564" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note10x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note10x.png?w=600" alt="" class="wp-image-6564 size-full" /></a><p class="wp-caption-text">This is viewed as a single tensor network <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> of 7 edges<span> </span>.<a name="figtp"></a></p></div><p></p>
<p>The definition of this joint tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{T}" class="latex" title="{T}" /> is</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=T%28i_1%2Ci_2%2C%5Ccdots%2C+i_7%29+%3D+T_1%28i_1%2Ci_2%2Ci_3%2Ci_4%29+T_2%28i_5%2Ci_6%2Ci_7%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." class="latex" title="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." /></p>
<p><strong>Rule #2: Edge Contractions</strong>. At this moment, we can only make up disconnected tensor networks. Edge contractions allow us to link two tensor networks. Suppose we have two <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" /> dimensional tensor networks. Contracting two edges, one from each, gives us a tensor network of <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> <i>free edges</i>. This now corresponds a tensor of <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> dimensions.</p>
<p></p><div style="width: 310px;" id="attachment_6579" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note12x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note12x.png?w=300&amp;h=116" alt="" height="116" class="size-medium wp-image-6579" width="300" /></a><p class="wp-caption-text">Two 3d tensors</p></div><p></p>
<p></p><div style="width: 310px;" id="attachment_6563" class="wp-caption aligncenter"><a href="https://windowsontheory.files.wordpress.com/2018/12/note13x.png"><img src="https://windowsontheory.files.wordpress.com/2018/12/note13x.png?w=300&amp;h=116" alt="" height="116" class="size-medium wp-image-6563" width="300" /></a><p class="wp-caption-text">Join two tensor networks by contracting an edge</p></div><p></p>
<p>We name the contracted edge as <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. The definition of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T%28i_1%2Ci_2%2Cj_1%2Cj_2%29+%3D%5Csum_k+T_1%28i_1%2Ci_2%2C+k%29+T_2%28j_1%2Cj_2%2C+k%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." class="latex" title="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." /></p>
<p><b> 2.2. Useful Examples </b></p>
<p>Before we move on, let’s take some examples. Keep in mind that the degree of the vertex determines the number of indices (dimensions of this tensor).</p>
<p></p><div style="width: 127px;" id="attachment_6584" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note15x.png?w=600" alt="note15x" class="alignnone size-full wp-image-6584" /><p class="wp-caption-text">vector inner product <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle u,v \rangle}" class="latex" title="{\langle u,v \rangle}" /></p></div><p></p>
<p></p><div style="width: 178px;" id="attachment_6585" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note16x.png?w=600" alt="note16x" class="alignnone size-full wp-image-6585" /><p class="wp-caption-text">Matrix inner product</p></div><p></p>
<p>Here, one needs to remember that an edge between two tensor nodes is a summation over the index corresponding to the edge. For example, in the vector inner product picture, <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv%5Crangle+%3D+%5Csum_i+u_i+%5Ccdot+v_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" class="latex" title="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" />, where edge is labeled as <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. Now you would realize that this picture</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600" alt="" class="wp-image-6535 size-full aligncenter" /></p>
<p>is the famous</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Clangle+u%2Cv+%5Crangle%5E2+%5Cleq+%5C%7Cu%5C%7C%5E2+%5C%7Cv%5C%7C%5E2.+%5Cquad%5Cquad+%28%5Ctext%7BCauchy-Schwarz+inequality%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " class="latex" title="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " /></p>
<p>For us, the most important building block is matrix multiplication. Let <img src="https://s0.wp.com/latex.php?latex=%7BH%3DMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H=MN}" class="latex" title="{H=MN}" />. By definition</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=H%28i%2Cj%29+%3D+%5Csum_k+M%28i%2Ck%29+N%28k%2C+j%29.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(i,j) = \sum_k M(i,k) N(k, j). " class="latex" title="H(i,j) = \sum_k M(i,k) N(k, j). " /></p>
<p>This is precisely encoded in the picture below.</p>
<p></p><div style="width: 276px;" id="attachment_6587" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note20x.png?w=600" alt="note20x.png" class="alignnone size-full wp-image-6587" /><p class="wp-caption-text">Matrix multiplication, <img src="https://s0.wp.com/latex.php?latex=%7BMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{MN}" class="latex" title="{MN}" />.<span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span><a style="color: #3d596d; font-size: 16px;" name="figmat-mul"></a><span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span></p></div><p></p>
<p>We are ready to talk about matrix product states. In the language of tensor network, a matrix product state is the following picture.</p>
<p></p><div style="width: 590px;" id="attachment_6588" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600" alt="note21x" class="alignnone size-full wp-image-6588" /><p class="wp-caption-text">A matrix product state.</p></div><p></p>
<p>As the degrees indicate, the two boundary vertices <img src="https://s0.wp.com/latex.php?latex=%7BA_1%2CA_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1,A_n}" class="latex" title="{A_1,A_n}" /> represent matrices and the internal vertices represent <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" />-dimensional tensors. We can view each matrix as a set of (column) vectors and each <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" />-dimensional tensor as a stack of matrices. Then each one of the free edges picks out a vector or a matrix, and the contracted edges multiply them together which gives out a scalar. If this confused you, move on to the next section. I will introduce the formal definition of matrix product states, and you will see that it is just the picture above.</p>
<p><b>3. Matrix Product States </b></p>
<p>Before giving the definition, let’s talk about how matrix product state (MPS) naturally arises from the study of quantum states with low entanglement. Matrix product state can be viewed as a generalization of <i>product state</i>—(pure) quantum state with no entanglement. Let’s consider a simple product state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> qubits. It can be factorized: <a name="eqnmps0"></a></p>
<p align="center"><a name="eqnmps0"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cpsi%5Crangle+%3D+%5Cleft%28%5Csum_%7Bi%3D0%7D%5E1+%5Calpha_1%5Ei%5C+%7Ci%5Crangle+%5Cright%29%5Cleft%28%5Csum_%7Bj%3D0%7D%5E1+%5Calpha_2%5Ej+%5C+%7Cj%5Crangle%5Cright%29%5Cnonumber+%3D+%5Csum_%7Bi%2Cj%3D0%7D%5E1+%5Calpha_1%5Ei+%5Calpha_2%5Ej%5C+%7Cij%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" class="latex" title="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" /></p>
<p><a name="eqnmps0"></a><br />
<a name="eqnmps0"></a> This state is described by <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> complex scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B%5Calpha_1%5E0%2C%5Calpha_1%5E1%2C%5Calpha_2%5E0%2C%5Calpha_2%5E1%5Cright%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" class="latex" title="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" />, and there is nothing quantum about it. However, if the state has entanglement among its qubits, then we know that it is impossible to be factorized and thereby written as (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>). MPS generalizes the form of (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>) by replacing the scalars with matrices and vectors.</p>
<p>More formally, a matrix product state starts with the following setup. For an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qudit system, we associate</p>
<ul>
<li>a qudit in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,n\}}" class="latex" title="{\{1,n\}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> vectors <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_1%5E%7Bj_1%7D%5Cright%5C%7D%2C+%5Cleft%5C%7BA_n%5E%7Bj_n%7D%5Cright%5C%7D+%5Cin+%5Cmathbb%7BR%7D%5ED%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" class="latex" title="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" />; and</li>
<li>a qudit <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B2%2C3%2C%5Ccdots%2C+n-1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{2,3,\cdots, n-1\}}" class="latex" title="{\{2,3,\cdots, n-1\}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> matrices <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D%5Cin+%5Cmathbb%7BR%7D%5E%7BD%5Ctimes+D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" class="latex" title="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" />.</li>
</ul>
<p>Here, <img src="https://s0.wp.com/latex.php?latex=%7Bj_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_i}" class="latex" title="{j_i}" /> range from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d-1}" class="latex" title="{d-1}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is called <i>bond dimension</i>. One can think of the set of vectors as a <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> matrix and the set of matrices as a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> three-dimensional tensor. Then let them correspond to the vertices in MPS picture. With this setup, a quantum state is in matrix product state if it can be written as</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj_1%2C%5Ccdots%2Cj_n%3D1%7D%5En+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D+%7Cj_1+j_2%5Ccdots+j_n%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." class="latex" title="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." /></p>
<p>It is important to keep in mind that <img src="https://s0.wp.com/latex.php?latex=%7BA_1%5E%7Bj_1%7D%2CA_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1^{j_1},A_n^{j_n}}" class="latex" title="{A_1^{j_1},A_n^{j_n}}" /> are two vectors, and the other inner terms are matrices, and we get a scalar from the product. Thus, this represents the tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%28j_1%2Cj_2%2C%5Ccdots%2C+j_n%29+%3D+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" title="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" />.</p>
<p>Now back to the picture,</p>
<p></p><div style="width: 590px;" id="attachment_6588" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600" alt="note21x" class="alignnone size-full wp-image-6588" /><p class="wp-caption-text">MPS</p></div><p></p>
<p>notice that each amplitude <img src="https://s0.wp.com/latex.php?latex=%7B+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" title="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" /> from the equation above is an output of the tensor in the picture, where the free edges take values <img src="https://s0.wp.com/latex.php?latex=%7Bj_1%2C+j_2+%2C%5Ccdots%2C+j_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j_1, j_2 ,\cdots, j_n}" class="latex" title="{j_1, j_2 ,\cdots, j_n}" />. Also, as discussed earlier, the contracted edges in MPS tensor network correspond to matrix and vector multiplications, so the tensor <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is precisely represented by the picture.</p>
<p>The complexity of the MPS is closely related to the bond dimension <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />. In particular, the number of parameters in this model is <img src="https://s0.wp.com/latex.php?latex=%7BO%28ndD%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(ndD^2)}" class="latex" title="{O(ndD^2)}" />. We would expect that with higher <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />, we may describe quantum states of more entanglement. In other words, the representation power of an MPS increases with <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />. In principle, one can represent any quantum state as an MPS; however, <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> can be exponentially large. See, <i>e.g.</i>, Section 4.1.3 of~\cite{schollwock2011density} for a proof. On the other extreme, the product state example shows that if <img src="https://s0.wp.com/latex.php?latex=%7BD%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D=1}" class="latex" title="{D=1}" />, one can represent and <i>only</i> represent unentangled states. To summarize, here is the picture you should keep in mind.</p>
<p></p><div style="width: 776px;" id="attachment_6594" class="wp-caption alignnone"><img src="https://windowsontheory.files.wordpress.com/2018/12/note33x.png?w=600" alt="note33x" class="alignnone size-full wp-image-6594" /><p class="wp-caption-text">Representation power of MPS increases with bond dimension D.</p></div><p></p>
<p><a name="figpower"></a></p>
<p> </p>
<p><b>4. Density Matrix Renormalization Group </b></p>
<p>We are now ready to describe Density Matrix Renormalization Group, proposed originally in [<a href="https://windowsontheory.org/feed/#XPhysRevLett.69.2863">Whi92</a>, <a href="https://windowsontheory.org/feed/#XPhysRevB.48.10345">Whi93</a>]. As mentioned earlier, it does not come with provable guarantees. In fact, one can construct artificial hard instances such that the algorithm get stuck at certain local minima [<a href="https://windowsontheory.org/feed/#Xschuch2008computational">SCV08</a>]. However, it has remained one of the most successful heuristics for <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D systems. We refer the readers to [<a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>] for a complete survey.</p>
<p>DMRG is a simple alternating minimization scheme for computing the ground state of a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D Hamiltonian. We start with an arbitrary MPS. Then each step we optimize over the set of matrices <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D_%7Bj_i%3D0%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" class="latex" title="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" /> associated with site <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, while fixing everything else, and iterate until convergence. (You may wonder if one can simultaneously optimize over multiple sites. It turns out that it is an NP-hard problem<span class="LinLibertineT-tlf-ot-1x-x-90"> </span><span class="cite"><span class="LinLibertineT-tlf-ot-1x-x-90">[</span><a href="https://windowsontheory.org/feed/#XPhysRevLett.97.260501">Eis06</a><span class="LinLibertineT-tlf-ot-1x-x-90">]</span></span>.)</p>
<p>Formally, the Hamiltonian problem can be phrased as a eigenvalue problem given a Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />, and thus we want to optimize over all <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> in MPS of a fixed bond dimension <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> <a name="eqnham"></a></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5Cfrac%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " class="latex" title="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " /></p>
<p>Here, we assume that the input Hamiltonian is in the product form. In particular, it means that it can be written as a tensor network as</p>
<p></p><div style="width: 430px;" id="attachment_6596" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note36x.png?w=600" alt="note36x" class="alignnone size-full wp-image-6596" /><p class="wp-caption-text">Input <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D Hamiltonian is of the particular product form.</p></div><p></p>
<p>so the numerator of the optimization objective looks like</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note37x.png?w=600" alt="note37x" class=" size-full wp-image-6597 aligncenter" /><a name="figdmrg1"></a></p>
<p>The DMRG works with the Langrangian of the objective. For some <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda&gt;0}" class="latex" title="{\lambda&gt;0}" />, we will consider <a name="eqndmrg2"></a></p>
<p align="center"><a name="eqndmrg2"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5C%2C%5C%2C+%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" class="latex" title="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" /></p>
<p><a name="eqndmrg2"></a><br />
<a name="eqndmrg2"></a>DMRG optimizes over the set of matrices associated with one qudit. Both terms in (<a href="https://windowsontheory.org/feed/#eqndmrg2">2</a>) are quadratic in this set of matrices.</p>
<p></p><div style="width: 919px;" id="attachment_6598" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/note39x.png?w=600" alt="note39x" class="alignnone size-full wp-image-6598" /><p class="wp-caption-text">The Langrangian <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" class="latex" title="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" /> as a tensor network.</p></div><p></p>
<p>Now to optimize over the set of parameters associated with one site, calculus tells you to set the (partial) derivative to <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />, and the derivative of a quadratic thing is linear. Without going through any algebra, we can guess that the derivative of  with respect to a particular site, say the second one, is the same picture except removing the second site on one side.</p>
<p></p><div style="width: 919px;" id="attachment_6599" class="wp-caption alignnone"><img src="https://windowsontheory.files.wordpress.com/2018/12/note40x.png?w=600" alt="note40x" class="alignnone size-full wp-image-6599" /><p class="wp-caption-text">The derivative that we set to <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and solve.</p></div><p></p>
<p>Notice that the unknown is still there, on the bottom side of each term. The trick of DMRG is to view the rest of the network as a linear map applied to the unknown.</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/note41x.png?w=600" alt="note41x" class="alignnone size-full wp-image-6600" /></p>
<p>Given <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />, we now have a clean numerical linear algebra problem of solving</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H%27x+%3D+%5Clambda+Bx.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" class="latex" title="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" /></p>
<p>This is called a generalized eigenvalue problem, and it is well studied. Importantly, for <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />D systems, <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> is typically very sparse, which enables very fast solvers in practice. Finally, DMRG sweeps over the sites one after another and stops until convergence is achieved.</p>
<p><b>5. Concluding Remarks </b></p>
<p class="noindent">Our presentation of tensor networks and MPS roughly follows <span class="cite">[<a href="https://windowsontheory.org/feed/#Xgharibian2015quantum">GHLS15</a>]</span>, a nice introductory survey on quantum Hamiltonian complexity.</p>
<p>The notion of tensor networks extends well beyond 1D systems, and a generalization of MPS is called tensor product state. It leads to algorithms for higher dimensional quantum systems. One may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcirac2009renormalization">CV09</a>]</span> for a comprehensive survey.</p>
<p>Tensor network has been interacting with other concepts. Within physics, it has been used in quantum error correction <span class="cite">[<a href="https://windowsontheory.org/feed/#Xferris2014tensor">FP14</a>, <a href="https://windowsontheory.org/feed/#Xpastawski2015holographic">PYHP15</a>]</span>, conformal field theory <span class="cite">[<a href="https://windowsontheory.org/feed/#Xorus2014advances">Orú14</a>]</span>, and statistical mechanics <span class="cite">[<a href="https://windowsontheory.org/feed/#XPhysRevLett.115.180405">EV15</a>]</span>. In TCS , we have found its connections with Holographic algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xvaliant2008holographic">Val08</a>, <a href="https://windowsontheory.org/feed/#Xcai2016complete">CGW16</a>]</span>, arithmetic complexity <span class="cite">[<a href="https://windowsontheory.org/feed/#Xbeaudry2007complexity">BH07</a>, <a href="https://windowsontheory.org/feed/#Xcapelli2016arithmetic">CDM16</a>, <a href="https://windowsontheory.org/feed/#Xaustrin19">AKK19</a>]</span>, and spectral algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xmoitra2018spectral">MW18</a>]</span>. In machine learning, it has been applied to probabilistic graphical models <span class="cite">[<a href="https://windowsontheory.org/feed/10.1093/imaiai/iay009">RS18</a>]</span>, tensor decomposition <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcichocki2016low">CLO16</a>]</span>, and quantum machine learning <span class="cite">[<a href="https://windowsontheory.org/feed/#X10.1088/2058-9565/aaea94">HPM18</a>]</span>.</p>
<p>For DMRG, we have only given a rough outline, with many details omitted, such as how to set <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> and how to obtain the Hamiltonian in the matrix product form, and how to compute the linear maps <img src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H'}" class="latex" title="{H'}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> for each iteration. An interested reader may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xschollwock2005density">Sch05</a>, <a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>]</span>.</p>
<p><strong>References</strong></p>
<p class="bibitem"><span class="biblabel">[AKK19] <span class="bibsp">   </span></span><a id="Xaustrin19"></a>Per Austrin, Peeri Kaski, and Kaie Kubjas. Tensor network complexity of multilinear maps. In <span class="LinLibertineTI-tlf-ot-1x-x-109">Proceedings of the 2019 Conference on Innovations in Theoretical Computer Science</span>. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">[BH07] <span class="bibsp">   </span></span><a id="Xbeaudry2007complexity"></a>Martin Beaudry and Markus Holzer. The complexity of tensor circuit evaluation. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Complexity</span>, 16(1):60, 2007.</p>
<p class="bibitem"><span class="biblabel">[CDM16] <span class="bibsp">   </span></span><a id="Xcapelli2016arithmetic"></a>Florent Capelli, Arnaud Durand, and Stefan Mengel. e arithmetic complexity of tensor contraction. <span class="LinLibertineTI-tlf-ot-1x-x-109">eory of Computing Systems</span>, 58(4):506{527, 2016.</p>
<p class="bibitem"><span class="biblabel">[CGW16] <span class="bibsp">   </span></span><a id="Xcai2016complete"></a>Jin-Yi Cai, Heng Guo, and Tyson Williams. A complete dichotomy rises from the capture of vanishing signatures. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 45(5):1671{1728, 2016.</p>
<p class="bibitem"><span class="biblabel">[CLO16] <span class="bibsp">   </span></span><a id="Xcichocki2016low"></a>Andrzej Cichocki, Namgil Lee, Ivan V Oseledets, A-H Phan, Qibin Zhao, and D Mandic. Low-rank tensor networks for dimensionality reduction and large-scale optimization problems: Perspectives and challenges part 1. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint arXiv:1609.00893</span>, 2016.</p>
<p class="bibitem"><span class="biblabel">[CV09] <span class="bibsp">   </span></span><a id="Xcirac2009renormalization"></a>J Ignacio Cirac and Frank Verstraete. Renormalization and tensor product states in spin chains and laices. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of Physics A: Mathematical and Theoretical</span>, 42(50):504004, 2009.</p>
<p class="bibitem"><span class="biblabel">[Eis06] <span class="bibsp">   </span></span><a id="XPhysRevLett.97.260501"></a>Jens Eisert. Computational difficulty of global variations in the density matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 97:260501, Dec 2006.</p>
<p class="bibitem"><span class="biblabel">[EV15] <span class="bibsp">   </span></span><a id="XPhysRevLett.115.180405"></a>G. Evenbly and G. Vidal. Tensor network renormalization. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 115:180405, Oct 2015.</p>
<p class="bibitem"><span class="biblabel">[FP14] <span class="bibsp">   </span></span><a id="Xferris2014tensor"></a>Andrew J Ferris and David Poulin. Tensor networks and quantum error correction. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 113(3):030501, 2014.</p>
<p class="bibitem"><span class="biblabel">[FSW07] <span class="bibsp">   </span></span><a id="Xfehske2007computational"></a>Holger Fehske, Ralf Schneider, and Alexander Weie. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational Many-Particle Physics</span>. Springer, 2007.</p>
<p class="bibitem"><span class="biblabel">[GHLS15] <span class="bibsp">   </span></span><a id="Xgharibian2015quantum"></a>Sevag Gharibian, Yichen Huang, Zeph Landau, and Seung Woo Shin. Quantum Hamiltonian complexity. <span class="LinLibertineTI-tlf-ot-1x-x-109">Foundations and Trends in Theoretical Computer Science</span>, 10(3):159, 2015.</p>
<p class="bibitem"><span class="biblabel">[HPM18]<span class="bibsp">   </span></span><a id="X10.1088/2058-9565/aaea94"></a>William James Huggins, Piyush Patil, Bradley Mitchell, K Birgia Whaley, and Miles Stoudenmire. Towards quantum machine learning with tensor networks. Qu<span class="LinLibertineTI-tlf-ot-1x-x-109">antum Science and</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Technology</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[MW18] <span class="bibsp">   </span></span><a id="Xmoitra2018spectral"></a>Ankur Moitra and Alexander S Wein. Spectral methods from tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv:1811.00944</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Orú14] <span class="bibsp">   </span></span><a id="Xorus2014advances"></a>Román Orús. Advances on tensor network theory: symmetries, fermions, entanglement, and holography. <span class="LinLibertineTI-tlf-ot-1x-x-109">e European Physical Journal B</span>, 87(11):280, 2014.</p>
<p class="bibitem"><span class="biblabel">[PYHP15] <span class="bibsp">   </span></span><a id="Xpastawski2015holographic"></a>Fernando Pastawski, Beni Yoshida, Daniel Harlow, and John Preskill. Holographic quantum error-correcting codes: Toy models for the bulk/boundary correspondence. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of High Energy</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Physics</span>, 2015(6):149, 2015.</p>
<p class="bibitem"><span class="biblabel">[RS18] <span class="bibsp">   </span></span><a id="Xdoi:10.1093/imaiai/iay009"></a>Elina Robeva and Anna Seigal. Duality of graphical models and tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">Information</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">and Inference: A Journal of the IMA</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Sch05] <span class="bibsp">   </span></span><a id="Xschollwock2005density"></a>Ulrich Schollwöck. The density-matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Rev. Mod. Phys.</span>, 77(1):259, 2005.</p>
<p class="bibitem"><span class="biblabel">[Sch11] <span class="bibsp">   </span></span><a id="Xschollwock2011density"></a>Ulrich Schollwöck. The density-matrix renormalization group in the age of matrix product states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Annals of Physics</span>, 326(1):96, 2011.</p>
<p class="bibitem"><span class="biblabel">[SCV08] <span class="bibsp">   </span></span><a id="Xschuch2008computational"></a>Norbert Schuch, Ignacio Cirac, and Frank Verstraete. Computational difficulty of finding matrix product ground states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 100(25):250501, 2008.</p>
<p class="bibitem"><span class="biblabel">[Val08] <span class="bibsp">   </span></span><a id="Xvaliant2008holographic"></a>Leslie G Valiant. Holographic algorithms. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 37(5):1565, 2008.</p>
<p class="bibitem"><span class="biblabel">[Whi92] <span class="bibsp">   </span></span><a id="XPhysRevLett.69.2863"></a>Steven R. White. Density matrix formulation for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 69:2863, Nov 1992.</p>
<p class="bibitem"><span class="biblabel">[Whi93] <span class="bibsp">   </span></span><a id="XPhysRevB.48.10345"></a>Steven R. White. Density-matrix algorithms for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">B</span>, 48:10345, Oct 1993.</p></div>







<p class="date">
by Fred Zhang <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/"><span class="datestr">at December 20, 2018 09:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6720">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/">Efficient preparation of thermal states of quantum systems: natural or artificial</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<article class="post-content"><p>Cross-posted from <a href="https://wsmoses.com/blog/2018/12/18/boaz/">https://wsmoses.com/blog/2018/12/18/boaz/</a></p><p>Lecturer: Aram Harrow</p><p>Scribes: Sinho Chewi, <a href="http://wsmoses.com">William S. Moses,</a> Tasha Schoenstein, Ary Swaminathan</p><p>November 9, 2018</p></article><p><br /></p><article class="post-content"><h3 id="outline">Outline</h3><p>Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We will then discuss Markov chains that have Gibbs distributions as stationary distributions. This leads into a discussion of the equivalence of mixing in time (i.e. the Markov chain quickly equilibrates over time) and mixing in space (i.e. sites that are far apart have small correlation). For the classical case, this equivalence is known. After discussing what is known classically, we will discuss difficulties that arise in the quantum case, including (approximate) Quantum Markov states and the equivalence of mixing in the quantum case.</p><h1 id="gibbs-distributions">Gibbs distributions</h1><p>We have already learned about phase transitions in a <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">previous blog post</a>, but they are important, so we will review them again. The <strong>Gibbs</strong> or <strong>thermal distribution</strong> is defined as follows: Suppose that we have an <strong>energy function</strong> <img src="https://s0.wp.com/latex.php?latex=E+%3A+%7B%5C%7B0%2C1%5C%7D%7D%5En+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E : {\{0,1\}}^n \to {\mathbb R}" class="latex" title="E : {\{0,1\}}^n \to {\mathbb R}" /> , which takes <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> -bit strings to real numbers. Usually, <img src="https://s0.wp.com/latex.php?latex=E+%3D+%5Csum_%7Bi%3D1%7D%5Em+E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E = \sum_{i=1}^m E_i" class="latex" title="E = \sum_{i=1}^m E_i" /> , where each <img src="https://s0.wp.com/latex.php?latex=E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_i" class="latex" title="E_i" /> term depends only on a few bits. For example, the energy might be the number of unsatisfied clauses in a 3-SAT formula, or it may arise from the Ising model. The Gibbs distribution is</p><p><span style="display: block;"> <img src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%5Cfrac%7B%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" class="latex" title="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" /> </span></p><p>where the normalization factor in the denominator, also called the <strong>partition function</strong>, is <img src="https://s0.wp.com/latex.php?latex=Z+%3D+%5Csum_%7Bx+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En%7D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" class="latex" title="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" /> . Another, perhaps more operational, way to define the Gibbs distribution is:</p><p><span style="display: block;"> <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%3B%5Cmathrm%7Barg%5C%2Cmax%7D_%7Bq+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29%7D+H%28q%29%7E%5Ctext%7Bsubject+to+the+constraint%7D%7E+%5Clangle%7Bq%2CE%7D%5Crangle+%3D+%5Cbar%7BE%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." class="latex" title="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." /> </span></p><p>In this expression, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{P}}({\{0,1\}}^n)" class="latex" title="{\mathcal{P}}({\{0,1\}}^n)" /> is the set of probability distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\{0,1\}}^n" class="latex" title="{\{0,1\}}^n" /> , <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is the Shannon entropy, and <img src="https://s0.wp.com/latex.php?latex=%5Cbar+E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bar E" class="latex" title="\bar E" /> is a constant representing the average energy. We are thinking of probability distributions and <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> as vectors of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" /> . It turns out that if we solve this optimization problem, then the Gibbs distribution is the unique solution.</p><h2 id="uses-of-gibbs-distributions">Uses of Gibbs distributions</h2><p>Why is it useful to work with Gibbs distributions?</p><ul><li><p>Gibbs distributions arise naturally in statistical physics systems, such as constraint satisfaction problems (CSPs), the Ising model, and spin glasses. One approach to deal with Gibbs distributions is through <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">belief propagation</a> (BP), which yields exact inference on tree graphical models and sometimes phase transition predictions on loopy graphs. Instead, we will focus on a different approach, namely, <em>sampling</em> from the Gibbs distribution.</p></li><li><p>If we want to minimize <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> (say, to find a 3-SAT solution), we can use <strong>simulated annealing</strong>. The idea of annealing is that we want to produce a crystal; a crystal is the lowest energy configuration of molecules. If we heat up the substance to a liquid and then cool it quickly, we will not get a nice crystal, because little bits of the material will point in different directions. In order to form a crystal, we need to cool the system slowly.</p><p>In computer science terms, we take a sample from a high temperature because sampling is generally easier at a higher temperature than at a lower temperature. We then use that sample as the starting point for an equilibration process at a slightly lower temperature, and repeat this procedure. If we reach zero temperature, then we are sampling from the minimizers of <img src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E" class="latex" title="E" /> . In practice, the system will usually stop mixing before we get to zero temperature, but this is a good heuristic. You can think of this process as gradient descent, with some additional randomness.</p></li><li><p>Gibbs distributions are used to simulate physical systems.</p></li><li><p>Gibbs distributions are used in Bayesian inference due to the Hammersley-Clifford theorem, which will be discussed next.</p></li><li><p>Gibbs distributions are also connected to multiplicative weights for linear programming (not discussed in this blog post).</p></li></ul><h2 id="bayesian-inference--the-hammersley-clifford-theorem">Bayesian inference &amp; the Hammersley-Clifford theorem</h2><p>In order to present the Hammersley-Clifford theorem, we must first discuss Markov networks. For this part, we will generalize our setup to a finite alphabet <img src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma" class="latex" title="\Sigma" /> , so the energy function is now a function <img src="https://s0.wp.com/latex.php?latex=%5CSigma%5En+%5Cto+%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma^n \to \mathbb R" class="latex" title="\Sigma^n \to \mathbb R" /> .</p><h3 id="markov-chains">Markov chains</h3><p>First, let us recall the idea of a <strong>Markov chain</strong> with variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> .</p></article>


<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p1.png?w=600" alt="" class="wp-image-6784" /></figure>



<p>The random variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> form a Markov chain if their joint distribution can be written in a factored way: <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B1%2C2%7D%28x_1%2Cx_2%29p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" class="latex" title="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" /> . For example, imagine that <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> , <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> , <img src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_3" class="latex" title="X_3" /> represent the weather on Monday, Tuesday, and Wednesday respectively. These random variables form a Markov chain if, conditioned on the weather on Tuesday, we have all of the information we need to forecast the weather on Wednesday. Another way to say this is that conditioned on the weather on Tuesday, then the weather on Monday and the weather on Wednesday are <strong>conditionally independent</strong>. Note that the weather on Monday and the weather on Wednesday are <em>not</em> independent; there can be correlations, but these correlations are mediated through the weather on Tuesday. It is important to note that the definition of a Markov chain is symmetric with respect to going forwards or backwards in time, so we can also write the conditional independence condition as <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B2%2C3%7D%28x_2%2Cx_3%29+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" class="latex" title="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" /> .</p>



<p>The conditional independence condition can also be written as <img src="https://s0.wp.com/latex.php?latex=p_%7B1%2C3+%5Cmid+2%7D%28x_1%2C+x_3+%5Cmid+x_2%29+%3D+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29+p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." class="latex" title="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." /> Recall that for two random variables <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> and <img src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_2" class="latex" title="X_2" /> with joint distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> , they are independent, i.e., <img src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%29+%3D+p_1%28x_1%29+p_2%28x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x_1,x_2) = p_1(x_1) p_2(x_2)" class="latex" title="p(x_1,x_2) = p_1(x_1) p_2(x_2)" /> , if and only if <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_2%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1; X_2) = 0" class="latex" title="I(X_1; X_2) = 0" /> , where <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" /> here denotes the mutual information. Similarly, conditional independence is equivalent to the <strong>conditional mutual information</strong> <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1; X_3 \mid X_2)" class="latex" title="I(X_1; X_3 \mid X_2)" /> equaling zero. This quantity is defined as <img src="https://s0.wp.com/latex.php?latex=I%28X_1%3BX_3+%5Cmid+X_2%29+%3D+H%28X_1+%5Cmid+X_2%29+%2B+H%28X_3+%5Cmid+X_2%29+-+H%28X_1%2C+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" class="latex" title="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" /> .</p>



<p>Keep in mind that conditional independence is characterized in two equivalent ways: via an algebraic condition on the distributions, and via mutual information.</p>



<h3 id="markov-networks">Markov networks</h3>



<p>A <strong>Markov network</strong> is like a Markov chain, but with more random variables and a more interesting structure. Imagine that we have a graph, where each node is associated with a random variable and the edges encode possible correlations. A Markov network has the property that if we take any disjoint collection of nodes <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> such that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> are fully separated by <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> (that is, any path from <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> to <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> must go through <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , or alternatively, removing <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> leaves <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> disconnected), then <img src="https://s0.wp.com/latex.php?latex=I%28X_A%3B+X_C+%5Cmid+X_B%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(X_A; X_C \mid X_B) = 0" class="latex" title="I(X_A; X_C \mid X_B) = 0" /> . The notation <img src="https://s0.wp.com/latex.php?latex=X_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_A" class="latex" title="X_A" /> here means the collection of random variables associated with the nodes in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> .</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p2.png?w=600" alt="" class="wp-image-6785" /></figure>



<p>For example:</p>



<p>Here, if <img src="https://s0.wp.com/latex.php?latex=A%3D%5C%7B1%2C5%2C6%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A=\{1,5,6\}" class="latex" title="A=\{1,5,6\}" /> , <img src="https://s0.wp.com/latex.php?latex=B%3D%5C%7B2%2C7%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B=\{2,7\}" class="latex" title="B=\{2,7\}" /> , and <img src="https://s0.wp.com/latex.php?latex=C%3D%5C%7B3%2C4%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C=\{3,4\}" class="latex" title="C=\{3,4\}" /> , then <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> separates <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> .</p>



<p>A Markov network is also called a <strong>graphical model</strong> or a <strong>Markov random field</strong>; and yet another name for them is <em>Gibbs distribution</em>, which is the content of the following theorem:</p>



<p><strong>Theorem 1</strong> (Hammersley-Clifford Theorem): <em>Let <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> be a strictly positive distribution on <img src="https://s0.wp.com/latex.php?latex=%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Sigma^n" class="latex" title="\Sigma^n" /> . Then, <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> can be represented as a Markov network with respect to a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> if and only if <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> can be expressed as a Gibbs distribution <img src="https://s0.wp.com/latex.php?latex=p%28x%29+%5Cpropto+%5Cexp%5C%7B-%5Csum_%7BC+%5Cin+%7B%5Cmathcal%7BC%7D%7D%28G%29%7D+E_C%28x_C%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" class="latex" title="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" /> , where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{C}}(G)" class="latex" title="{\mathcal{C}}(G)" /> is the set of cliques (fully connected subsets) of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> . </em></p>



<p>This theorem says that Markov networks are the same as Gibbs states, <em>with the same notion of locality</em>.</p>



<p>The Hammersley-Clifford theorem implies an area law for mutual information; we will explain what this is and sketch why this is true. Divide a system into two disjoint pieces <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . We want to know about the mutual information between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , <img src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A;B)" class="latex" title="I(A;B)" /> . The Hammersley-Clifford theorem gives us a bound which depends only on the size of the boundary <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> between these sets. For simplicity, assume <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial \subseteq B" class="latex" title="\partial \subseteq B" /> . Also, assume that the interactions have bounded range; then, the Hammersley-Clifford theorem tells us that <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B \mid \partial) = 0" class="latex" title="I(A; B \mid \partial) = 0" /> .</p>



<p>Now, we will use the fact <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+I%28A%3B+B%2C%5Cpartial%29+-+I%28A%3B+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" class="latex" title="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" /> . We can see this by writing out the expressions, but the intuition is that the term on the left asks about how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , having already known about <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> . This equals how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> combined, minus how much <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> knows about <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> alone. In this case, since we said <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial \subseteq B" class="latex" title="\partial \subseteq B" /> , then <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B)" class="latex" title="I(A; B)" /> is the same as <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%2C+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; B, \partial)" class="latex" title="I(A; B, \partial)" /> . In general, however, we have an upper bound:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29+%5Cle+I%28A%3B+B%2C+%5Cpartial%29+%3D+I%28A%3B+%5Cpartial%29+%2B+I%28A%3BB+%5Cmid+%5Cpartial%29+%5Cle+H%28%5Cpartial%29+%5Cle+%7C%5Cpartial%7C+%5Clog+%7C%5CSigma%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" class="latex" title="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" /> </p>



<p>In this calculation, we have used <img src="https://s0.wp.com/latex.php?latex=I%28A%3B+%5Cpartial%29+%3D+H%28%5Cpartial%29+-+H%28%5Cpartial+%5Cmid+A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(A; \partial) = H(\partial) - H(\partial \mid A)" class="latex" title="I(A; \partial) = H(\partial) - H(\partial \mid A)" /> (the information between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> is the amount by which the entropy of <img src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial" class="latex" title="\partial" /> gets reduced once we know <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> ) and <img src="https://s0.wp.com/latex.php?latex=H%28%5Cpartial+%5Cmid+A%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(\partial \mid A) \ge 0" class="latex" title="H(\partial \mid A) \ge 0" /> (which is true classically).</p>



<p>Since the mutual information only scales with the <em>surface area</em> of the boundary and not with the area of the two regions <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , this is known as an <em>area law</em> <a href="https://windowsontheory.org/feed/#gharibian">[1]</a>.</p>



<h3 id="relationship-to-bayesian-inference">Relationship to Bayesian inference</h3>



<p>In Bayesian inference, we have a model for a system which can be very complicated. The model represents our assumptions on how parts of the system are causally related to the rest of the system. We have some observations, and we want to sample from a distribution conditionally on the fixed observations. Sampling from a conditional distribution is not the same as sampling from the original distribution, but we can still formally represent the conditional distribution as a Markov network. Therefore, sampling from Markov networks is a broadly useful task.</p>



<p>As an example of a complicated Bayesian model, consider a <em>hierarchical Bayesian model</em> <a href="https://windowsontheory.org/feed/#keener">[2]</a>. Bayesian statistics requires choosing a prior distribution, and when there is a natural parameterized family of priors that a statistician can use, it may make sense to introduce a distribution over the priors; this is known as <em>introducing a hyperparameter</em>, and inference in the resulting hierarchical model (including computation of the posterior distribution) is frequently intractable. However, it is still desirable to work with these models because they are often more accurate than models in which the prior is handpicked by a statistician.</p>



<h1 id="sampling-from-gibbs-distributions">Sampling from Gibbs distributions</h1>



<p>The task of sampling from an arbitrary Gibbs distribution is MA-complete <a href="https://windowsontheory.org/feed/#crosson_making_2010">[3]</a>, and it is not hard to see that at low enough temperatures this problem is at least NP-hard. So, how do we sample from these distributions?</p>



<p>This section will discuss Monte Carlo Markov chain (MCMC) methods, namely the Metropolis-Hastings algorithm and Glauber dynamics. Readers familiar with these methods may wish to skip to the discussion of <a href="https://windowsontheory.org/feed/#scn_mixing_in_time">mixing in time</a>. For readers who wish to build more intuition about Markov chains before proceeding, see the <a href="https://windowsontheory.org/feed/#scn_appendix">Appendix</a>, where the simple example of the random walk on a cycle is treated in detail.</p>



<h2 id="monte-carlo-markov-chain-mcmc-methods">Monte Carlo Markov chain (MCMC) methods</h2>



<p>The general approach is to use a Markov chain. Let <img src="https://s0.wp.com/latex.php?latex=%5COmega%3D%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega=\Sigma^n" class="latex" title="\Omega=\Sigma^n" /> be the possible states of the system. Effectively, a Markov chain is a way of doing a random walk over <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> .</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p3.png?w=600" alt="" class="wp-image-6786" /></figure>



<p>The transition probabilities of the Markov chain are<sup><a href="https://windowsontheory.org/feed/#fn_1">1</a></sup> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%28t%2B1%29+%3D+y+%5Cmid+X%28t%29+%3D+x%5C%7D+%3D+T_%7By%2Cx%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." class="latex" title="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." /> Here, <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is the <strong>transition probability matrix</strong>. The column at index <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is the probability distribution of the next state of the Markov chain, if the current state is <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . The row at index <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a row of probability values which give the probabilities of jumping into state <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> from every other state. It has the properties that its entries are non-negative and for every <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7By+%5Cin+%5COmega%7D+T_%7By%2Cx%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{y \in \Omega} T_{y,x} = 1" class="latex" title="\sum_{y \in \Omega} T_{y,x} = 1" /> . These properties say that <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is a (column) <strong>stochastic matrix</strong>.</p>



<p>Suppose we start at a state <img src="https://s0.wp.com/latex.php?latex=x%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x(0)" class="latex" title="x(0)" /> ; or, more generally, we will start with a distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> over <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> . If we move according to the chain once, the distribution will be <img src="https://s0.wp.com/latex.php?latex=Tp&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tp" class="latex" title="Tp" /> . If we move agian, the distribution will be <img src="https://s0.wp.com/latex.php?latex=T%5E2+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^2 p" class="latex" title="T^2 p" /> . In general, after <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> movements, the distribution is <img src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t p" class="latex" title="T^t p" /> . So, we can express the dynamics of the chain as matrix-vector multiplication.</p>



<p>It is worth mentioning that if we are simulating the chain on a computer and we are manipulating <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> -bit numbers, then these probability vectors are of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" /> so it becomes impractical to store the entire probability distributions.</p>



<p>The justification for our algorithms is the following theorem.</p>



<p><strong>Theorem 2</strong> (Perron-Frobenius Theorem): <em>If <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is a stochastic aperiodic matrix, then one of the eigenvalues is <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> , and all other eigenvalues have magnitude strictly less than <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . There is a unique probability distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> such that <img src="https://s0.wp.com/latex.php?latex=T%5Cpi+%3D+%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T\pi = \pi" class="latex" title="T\pi = \pi" /> . </em></p>



<p>The theorem implies that <img src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t p" class="latex" title="T^t p" /> will converge to the stationary distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> as <img src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\to\infty" class="latex" title="t\to\infty" /> . So, if we want to sample from a distribution, this provides a method of doing so: cook up a Markov chain that equilibrates to the desired distribution, and then run the Markov chain until convergence. <em>A priori</em>, it is not obvious how we can design the Markov chain. At first, our problem was to sample from a probability distribution (a vector), and now we have changed the problem to designing an entire matrix, which does not appear to make our task easier.</p>



<p>Now, the question becomes: how does one come up with Markov chains that give you the desired stationary distribution?</p>



<h2 id="metropolis-hastings-algorithm">Metropolis-Hastings algorithm</h2>



<p>The first algorithm we will introduce is the <strong>Metropolis-Hastings algorithm</strong>. One more desirable feature of a Markov chain is that it satisfies <strong>detailed balance</strong>, which says <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x+T_%7By%2Cx%7D+%3D+%5Cpi_y+T_%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x T_{y,x} = \pi_y T_{x,y}" class="latex" title="\pi_x T_{y,x} = \pi_y T_{x,y}" /> for all <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> . This condition says that if we pick a point with probability according to the stationary distribution and transition, the probability of picking <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and then moving to <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> should be the same as picking <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> and then moving to <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> .</p>



<p>For a Markov chain in equilibrium, the total amount of probability flowing out of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> must equal the total amount of probability flowing into <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . For example, the United States might export products to Europe and import from China. Detailed balance says that the flow along each edge must balance, which is a more demanding condition. In the example with country trade deficits, we are requiring that all bilateral trade deficits must be zero.</p>



<p>Mathematically, detailed balance implies that <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> can be transformed, via similarity transformations, into a symmetric matrix. The Metropolis-Hastings algorithm says that we should choose <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> with the property <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BT_%7Bx%2Cy%7D%7D%7BT_%7By%2Cx%7D%7D+%3D+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." class="latex" title="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." /> Suppose that we have an underlying graph on our state space, and suppose that we are at a state <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . The algorithm chooses a random neighbor, say <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> , and then accepts or rejects this move with some probability. If the move is accepted, then we move to <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> and continue the algorithm from there. Otherwise, if the move is rejected, then we stay at <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> . We are free to choose any underlying graph (as long as it is connected and has a self-loop), and then we will tune the acceptance probability so that detailed balance holds.</p>



<p>Look at the trial move <img src="https://s0.wp.com/latex.php?latex=x%5Cto+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\to y" class="latex" title="x\to y" /> . One way we can accomplish detailed balance is by looking at the ratio <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x" class="latex" title="\pi_y/\pi_x" /> . If <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%5Cge+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x \ge 1" class="latex" title="\pi_y/\pi_x \ge 1" /> , then always accept the move. If <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%3C+1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x &lt; 1 " class="latex" title="\pi_y/\pi_x &lt; 1 " /> , then accept the move with probability <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x%2F%5Cpi_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x/\pi_y" class="latex" title="\pi_x/\pi_y" /> .</p>



<p>To get an idea for how the algorithm works, suppose that our underlying graph is <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> -regular. Then, for neighbors <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> ,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DT_%7By%2Cx%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%2C+%5C%5C+T_%7Bx%2Cy%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%5C%3B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " class="latex" title="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " /> </p>



<p><strong>Claim</strong>: <img src="https://s0.wp.com/latex.php?latex=T_%7By%2Cx%7D+%5Cpi_x+%3D+%5Cfrac%7B1%7D%7Bd%7D+%5Cmin%5C%7B%5Cpi_x%2C%5Cpi_y%5C%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," class="latex" title="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," /> which is manifestly symmetric in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> ; thus, we have reversibility. This is the basic idea of the Metropolis-Hastings algorithm.</p>



<p>How does it work for a Gibbs distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x+%3D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%2FZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x = \exp\{-E(x)/T\}/Z" class="latex" title="\pi_x = \exp\{-E(x)/T\}/Z" /> , where the energy function might, for example, count the number of violated clauses in a 3-SAT formula? In this case, we might be a little worried. The numerator of <img src="https://s0.wp.com/latex.php?latex=%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_x" class="latex" title="\pi_x" /> is pretty easy to compute (we can count how many violated constraints there are), but the denominator is hard to compute. In general, it is #P-hard to compute the denominator, because as <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> drops to <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> , the partition function in this case approaches the number of 3-SAT solutions. So, how do we calculate the ratios <img src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_y/\pi_x" class="latex" title="\pi_y/\pi_x" /> that the algorithm requires? We’re able to do this because the ratio does not depend on <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> :</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D+%3D+%5Cexp+%5Cfrac%7BE%28x%29-E%28y%29%7D%7BT%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." class="latex" title="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." /> </p>



<p>Suppose that the energy is a sum of local terms, and the underlying graph corresponds to modifying one site at at a time. What this means is that the graph is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%3D+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega = {\{0,1\}}^n" class="latex" title="\Omega = {\{0,1\}}^n" /> and the edges in the graph correspond to flipping exactly one bit. In this case, it becomes very easy to evaluate the computations needed for the algorithm; in fact, we can even do them in parallel.</p>



<p>How do we choose the underlying graph? The key idea is that we do not want the majority of our moves to be rejected. A good example to keep in mind is the <strong>Ising model</strong>, where the configurations are <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in {\{0,1\}}^n" class="latex" title="x \in {\{0,1\}}^n" /> and the energy is <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+-%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" title="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" /> . If <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} \ge 0" class="latex" title="J_{i,j} \ge 0" /> for all <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> , <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> , then we say that the model is <strong>ferromagnetic</strong> (we obtain lower energy by making the sites agree with each other). Of course, an <strong>antiferromagnetic</strong> model is just the opposite of this.</p>



<p>Assume that the bits are laid out in a square and <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} = J" class="latex" title="J_{i,j} = J" /> if <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> are neighbors on the square, and <img src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_{i,j} = 0" class="latex" title="J_{i,j} = 0" /> if they are not. As we vary the quantity <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> , we observe a <em>phase transition</em>. If <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> is small, then the coupling between the random variables is weak and the different parts of the system are almost independent; we call this the <strong>disordered phase</strong>. If <img src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J/T" class="latex" title="J/T" /> is large, then the spins want to align in the same direction and the Gibbs distribution will look almost like the following: with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> , all spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> , and with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> , all spins are <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> ; we call this the <strong>ordered phase</strong>.</p>



<p>In the disordered phase, when the spins do not need to align so closely, the Metropolis-Hastings algorithm will work well. In the ordered phase, the algorithm is doomed. Indeed, suppose that most of the spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . As time proceeds, any <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> s will switch to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . There may be islands of <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> spins initially, but it will be energetically favorable for these islands to shrink over time. Therefore, there will be an exponentially small chance for the system to switch to a configuration with mostly <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> ’s, and thus the chain takes exponentially long to mix. Here, people are interested in understanding the <em>autocorrelation time</em>, because the goal is to run the chain for some time, get one sample, run the chain for some more time, get another sample, etc.</p>



<h2 id="glauber-dynamics">Glauber dynamics</h2>



<p>This next method (<strong>Glauber dynamics</strong>) is essentially the same as Metropolis-Hastings, but this is not immediately obvious. We are at a state <img src="https://s0.wp.com/latex.php?latex=x+%3D+%28x_1%2C%5Cdotsc%2Cx_n%29+%5Cin+%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x = (x_1,\dotsc,x_n) \in \Sigma^n" class="latex" title="x = (x_1,\dotsc,x_n) \in \Sigma^n" /> . (For the Metropolis-Hastings algorithm, we could be walking on a state space without a product structure. However, Glauber dynamics requires a product structure.) Then, we update <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> to <img src="https://s0.wp.com/latex.php?latex=%28x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_i%27%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" class="latex" title="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" /> with chance <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%5Cmid+-i%7D%28x_i%27+%5Cmid+x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" class="latex" title="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" /> . In other words, we hold all other bits fixed, and conditioned on those other bits, we resample the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> th bit. Like Metropolis-Hastings, <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> is stationary for this chain.</p>



<p>It is not obvious that these conditional distributions can be computed efficiently, but it is possible since normalizing the conditional distribution only requires summing over the possible configurations for a single random variable. On a Markov network, the conditional probability is <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi+%5Cmid+N%28i%29%7D%28x_i%27+%5Cmid+x_%7BN%28i%29%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" class="latex" title="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" /> , where <img src="https://s0.wp.com/latex.php?latex=N%28i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N(i)" class="latex" title="N(i)" /> denotes the set of neighbors of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> . This makes the computation a constant-sized calculation (i.e., does not depend on the size of the system).</p>



<p>For example, in the Ising model, suppose we are at state <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in {\{\pm 1\}}^n" class="latex" title="x \in {\{\pm 1\}}^n" /> . In Glauber dynamics, we pick a vertex <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> u.a.r. and update it to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> with probability <img src="https://s0.wp.com/latex.php?latex=p_%7Bi+%5Cmid+N%28i%29%7D%28%2B+%5Cmid+x_%7BN%28i%29%7D%29+%3D+%5Cfrac%7B%5Cexp%28T%5E%7B-1%7D%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D%7B%5Cexp%28-T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29+%2B+%5Cexp%28T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." class="latex" title="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." /></p>



<h1 id="scn:mixing_in_time">Mixing in time</h1>



<p>Mixing in time means that the dynamics will equilibrate rapidly. It turns out that this is equivalent to mixing in space, which means that <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> itself has decaying correlations. For example, the Ising model at low temperature has a lot of long-range correlations, but at high temperature it does not. For the high temperature regime, we can prove that mixing in time occurs. We will prove this for the ferromagnetic Ising model. The result is known more generally, but the proofs are much easier for the Ising model.</p>



<p>People have known about the Metropolis-Hastings algorithm since the 1950s, but only recently have researchers been able to prove convergence guarantees for the 2D Ising model. There is a large gap between theory and practice, but in some situations we can prove that the algorithm works.</p>



<p>Sampling from the distribution is roughly equivalent to estimating the partition function (sampling-counting equivalence). There have been many papers addressing tasks such as estimating the non-negative permanent, the number of colorings of a graph, etc.<sup><a href="https://windowsontheory.org/feed/#fn_2">2</a></sup> A dominant way of accomplishing these tasks is proving that the Metropolis-Hastings algorithm converges for these problems. It is easy to find algorithms for these problems that converge to Gibbs distributions, but the convergence may take exponential time.</p>



<p>We will look at the situation when the energy function looks like the Ising model, in the sense that the interactions are local and reflect the structure of some underlying space. Also, assume that the interactions are of size <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> and that the scaling comes from the size of the system. When can we expect that our algorithms work? There are two main cases when we can argue that there should be rapid mixing.</p>



<ul><li>High temperature regime: The system is very disordered, and in the limit as the temperature approaches infinity, we get the uniform distribution.</li><li>One-dimension: In 1D, we can exactly compute the partition function using dynamic programming. Before, we mentioned that if there are a sea of <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> s and an island of <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> s, then it is energetically favorable for the island to shrink; note that this is no longer true in 1D. In a way, 1D systems are more “boring” because they cannot exhibit arbitrarily long-range correlations.</li></ul>



<p>In this part of the blog post, we will try to be more proof-oriented. We will start by explaining why it is plausible that high temperature means that the chain will mix rapidly in time.</p>



<h2 id="coupling-method">Coupling method</h2>



<p>One method of proving rates of convergence for Markov chains is by analzying the spectral gap. Another method is the <strong>coupling method</strong>.</p>



<p>The idea behind the coupling method is to start with two configurations <img src="https://s0.wp.com/latex.php?latex=X%280%29%2CY%280%29+%5Cin+%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0),Y(0) \in \Omega" class="latex" title="X(0),Y(0) \in \Omega" /> . We want each one to evolve under the Markov chain.</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2018/12/p4.png?w=600" alt="" class="wp-image-6787" /></figure>



<p>The key part is that there is still some freedom with respect to what the dynamics looks like. In particular, we are allowed to correlate the <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> processes. Thus, we are defining a joint transition probability <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%281%29%3Dx%281%29%2CY%281%29%3Dy%281%29+%5Cmid+X%280%29%2CY%280%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" class="latex" title="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" /> . We want to design the process such that <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> are closer together than <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> . Imagine that we have two particles bouncing around. Each particle follows the dynamics of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> , but they are correlated so that they drift together, and once they meet, they stick together. It turns out that the mixing time can be upper bounded by the time it takes for the particles to meet each other.</p>



<p>Assume we have some sort of distance function <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}" class="latex" title="\;\mathrm{dist}" /> on the underlying space and we can prove that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%28X%281%29%2CY%281%29%29+%5Cle+%5Cexp%28-%5Calpha%29+%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" class="latex" title="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" /> . Then, it turns out that the mixing time <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon)" class="latex" title="t_{\rm mix}(\epsilon)" /> , i.e. the time required to get within <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> of the stationary distribution, is upper bounded as</p>



<p> <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%5C%7B%28%5C%3B%5Cmathrm%7Bdiam%7D%5COmega%29%2F%5Cepsilon%5C%7D%7D%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" class="latex" title="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" /> </p>



<p>Initially, the two particles can be <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiam%7D%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{diam}\Omega" class="latex" title="\;\mathrm{diam}\Omega" /> apart, but the expected distance is exponentially shrinking as we run the coupling, so the mixing time is logarithmic in the diameter.</p>



<p>The distance between probability distributions is defined as follows. Let <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> be two probability distributions on <img src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega" class="latex" title="\Omega" /> . Then, the metric is:<sup><a href="https://windowsontheory.org/feed/#fn_3">3</a></sup></p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+%5C%7Cp-q%5C%7C_1+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bx+%5Cin+%5COmega%7D%7Cp%28x%29-q%28x%29%7C+%3D+%5Cmin_%7B%5Csubstack%7B%28X%2CY%29+%5Csim+r+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%5COmega+%5Ctimes+%5COmega%29+%5C%5C+r_1+%3D+p+%5C%5C+r_2+%3D+q%7D%7D+%7B%5Cmathbb+P%7D_r%5C%7BX+%5Cne+Y%5C%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." class="latex" title="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." /> </p>



<p>In this expression, <img src="https://s0.wp.com/latex.php?latex=r_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r_1" class="latex" title="r_1" /> and <img src="https://s0.wp.com/latex.php?latex=r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r_2" class="latex" title="r_2" /> denote the first and second marginals of <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> respectively. The minimum is taken over all <em>couplings</em> of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> . This is the correct way to measure the distance between distributions. To give some intuition for this quantity, the quantity on the right represents the best <em>test</em> to distinguish the two distributions. If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> are the same, we can take a coupling in which <img src="https://s0.wp.com/latex.php?latex=X+%5Csim+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X \sim p" class="latex" title="X \sim p" /> and <img src="https://s0.wp.com/latex.php?latex=Y+%5Csim+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y \sim q" class="latex" title="Y \sim q" /> are always identical. If <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> have disjoint supports, then no matter what coupling we use, <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> will never be equal.</p>



<p>It suffices to consider when <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> are neighbors, i.e. at distance <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> apart. This is because if we have <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> far apart, then we could look at the path between them and reduce to the case when they are neighbors. Formally, this is known as <em>path coupling</em>. The formal statement is in Theorem 12.3 of <a href="https://windowsontheory.org/feed/#nature">[4]</a>:</p>



<p><strong>Theorem 3</strong>: <em>Let <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> be a connected weighted graph on the state space, where no edge has weight less than <img src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmin%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{\min}" class="latex" title="d_{\min}" /> . Let <img src="https://s0.wp.com/latex.php?latex=d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d(C,C')" class="latex" title="d(C,C')" /> be the length of the shortest path from <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> to <img src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'" class="latex" title="C'" /> in <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> and let <img src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmax%7D+%3D+%5Cmax_%7BC%2CC%27+%5Cin+%5COmega%7D+d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" class="latex" title="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" /> be the diameter of <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> . Suppose there is a coupling such that for some <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta &gt; 0" class="latex" title="\delta &gt; 0" /> </em>,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5Cbigl%5Bd%5Cbigl%28X%281%29%2CY%281%29%5Cbigr%29+%5Cbigm%5Cvert+%5Cbigl%28X%280%29%2CY%280%29%5Cbigr%29+%3D+%28C%2CC%27%29%5Cbigr%5D+%5Cle+%281-%5Cdelta%29d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" class="latex" title="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" /> </p>



<p><em>for all neighboring pairs <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> , <img src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'" class="latex" title="C'" /> , i.e., those pairs connected by an edge in <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" /> . Then, the mixing time is bounded by </em></p>



<p> <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%28%5Cepsilon%5E%7B-1%7Dd_%7B%5Cmax%7D%2Fd_%7B%5Cmin%7D%29%7D%7B%5Cdelta%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." class="latex" title="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." /> </p>



<h2 id="glauber-dynamics-at-high-temperature">Glauber dynamics at high temperature</h2>



<p>Recall that in Glauber dynamics, we pick a site <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> randomly and then update the site conditioned on its neighbors. The first way we will couple together <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> is by picking the <em>same</em> site for both of them.</p>



<ol><li>Pick a random <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> .</li><li>If <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_%7BN%28i%29%7D+%3D+%7BY%280%29%7D_%7BN%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" class="latex" title="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" /> , then set <img src="https://s0.wp.com/latex.php?latex=%7BX%281%29%7D_i+%3D+%7BY%281%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(1)}_i = {Y(1)}_i" class="latex" title="{X(1)}_i = {Y(1)}_i" /> (if the neighborhoods of the two points agree, then update them the same way). Otherwise, update them using the best possible coupling, i.e., pick a coupling for <img src="https://s0.wp.com/latex.php?latex=%28%7BX%281%29%7D_i%2C+%7BY%281%29%7D_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="({X(1)}_i, {Y(1)}_i)" class="latex" title="({X(1)}_i, {Y(1)}_i)" /> which minimizes <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7B+%7BX%281%29%7D_i+%5Cne+%7BY%281%29%7D_i+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" class="latex" title="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" /> .</li></ol>



<p>So if <img src="https://s0.wp.com/latex.php?latex=X%280%29+%3D+Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0) = Y(0)" class="latex" title="X(0) = Y(0)" /> , then the points will never drift apart. The reason why analyzing this coupling is non-trivial is because there is a chance that the distance between the two points can <em>increase</em>.</p>



<p>Assume that the degree of the graph is <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> . Suppose that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}(X(0),Y(0)) = 1" class="latex" title="\;\mathrm{dist}(X(0),Y(0)) = 1" /> , that is, there is a single <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_a \ne {Y(0)}_a" class="latex" title="{X(0)}_a \ne {Y(0)}_a" /> . What will happen to <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> ? We start by picking a random <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in [n]" class="latex" title="i \in [n]" /> . There are three cases:</p>



<ol><li><img src="https://s0.wp.com/latex.php?latex=i+%5Cnotin+%28%5C%7Ba%5C%7D+%5Ccup+N%28a%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \notin (\{a\} \cup N(a))" class="latex" title="i \notin (\{a\} \cup N(a))" /> (with probability <img src="https://s0.wp.com/latex.php?latex=1+-+%28%5CDelta+%2B+1%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 - (\Delta + 1)/n" class="latex" title="1 - (\Delta + 1)/n" /> ): Nothing changes; <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> agree at <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> , and <img src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(1)" class="latex" title="X(1)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(1)" class="latex" title="Y(1)" /> will also agree at <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> . The distance remains at <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> .</li><li><img src="https://s0.wp.com/latex.php?latex=i+%3D+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i = a" class="latex" title="i = a" /> (with probability <img src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/n" class="latex" title="1/n" /> ): We picked the one spot in which the two configurations differ. The neighborhoods of <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> are the same for <img src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0)" class="latex" title="X(0)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y(0)" class="latex" title="Y(0)" /> , so we update in the same way for both processes, and the distance drops to <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> .</li><li><img src="https://s0.wp.com/latex.php?latex=i+%5Cin+N%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \in N(a)" class="latex" title="i \in N(a)" /> (with probability <img src="https://s0.wp.com/latex.php?latex=%5CDelta%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta/n" class="latex" title="\Delta/n" /> ): We could have different updates. Here, we have to use the high temperature assumption, which says that if we change one bit, the probability of a configuration cannot change too much.In the Ising model, <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" title="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" /> . Changing <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> can bias the energy by at most <img src="https://s0.wp.com/latex.php?latex=%5CDelta%5Cmax_i+J_%7Bi%2Ca%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta\max_i J_{i,a}" class="latex" title="\Delta\max_i J_{i,a}" /> , so the expected distance afterwards is <img src="https://s0.wp.com/latex.php?latex=1+%2B+O%28%5Cmax_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D%2FT%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 + O(\max_{i,j=1}^n J_{i,j}/T)" class="latex" title="1 + O(\max_{i,j=1}^n J_{i,j}/T)" /> .</li></ol>



<p>Adding these cases up to get the overall expected distance gives</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%5Cbigl%28X%281%29%2C+Y%281%29%5Cbigr%29+%3D+1-%5Cfrac%7B1%7D%7Bn%7D+%2B+%5Cunderbrace%7BO%5CBigl%28%5Cfrac%7B%5CDelta+J_%7B%5Cmax%7D%7D%7BT%7D%5CBigr%29%7D_%7B%5Cle+1%7D%5Cfrac%7B1%7D%7Bn%7D+%3D+1+-+%5Cfrac%7Bc%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" class="latex" title="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" /> </p>



<p>for <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> large enough, so the expected distance will shrink. This argument also tells us how large the temperature must be, which is important for applications. This gives us <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%3D+O%5CBigl%28n%5Clog%5Cfrac%7Bn%7D%7B%5Cepsilon%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." class="latex" title="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." /> Notice that this is the same dependence as the coupon collector problem. Therefore, in the high temperature regime, the system behaves qualitatively as if there are no correlations.</p>



<h2 id="temporal-and-spatial-mixing-equivalence">Temporal and spatial mixing equivalence</h2>



<p>The analysis of Glauber dynamics at high temperature is already a version of the equivalence between mixing in time and mixing in space. It says that if the correlations even with the immediate neighbors of a node are weak, then Glauber dynamics rapidly mixes.</p>



<p>Now, we want to consider the situation in which there can be strong correlations between immediate neighbors, but weak correlation with far away sites. We want to show that spatial mixing implies temporal mixing.</p>



<p>We will give a few definitions of correlation decay. (Note: The definitions of correlation decay below are not exactly the ones from Aram’s lecture. These definitions are from <a href="https://windowsontheory.org/feed/#martinelli1">[5]</a> and <a href="https://windowsontheory.org/feed/#martinelli2">[6]</a>.)</p>



<p>For non-empty <img src="https://s0.wp.com/latex.php?latex=W+%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W \subseteq V" class="latex" title="W \subseteq V" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau \in \Sigma^{V\setminus W}" class="latex" title="\tau \in \Sigma^{V\setminus W}" /> , let <img src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_W^\tau" class="latex" title="\mu_W^\tau" /> be the distribution of the spins in <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> conditional on the spins in <img src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V \setminus W" class="latex" title="V \setminus W" /> being fixed to <img src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau" class="latex" title="\tau" /> . For <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> , let <img src="https://s0.wp.com/latex.php?latex=%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_{W,\Delta}^\tau" class="latex" title="\mu_{W,\Delta}^\tau" /> be the marginal of <img src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu_W^\tau" class="latex" title="\mu_W^\tau" /> on the spins in <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> . We will assume that the interactions between the spins have finite range <img src="https://s0.wp.com/latex.php?latex=r+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r &gt; 0" class="latex" title="r &gt; 0" /> , and <img src="https://s0.wp.com/latex.php?latex=%5Cpartial_r+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial_r W" class="latex" title="\partial_r W" /> denotes the <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> -boundary of <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> , i.e., <img src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%5Cin+V+%5Csetminus+W+%3A+%5C%3B%5Cmathrm%7Bdist%7D%28v%2CW%29+%5Cle+r%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" class="latex" title="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" /> .</p>



<ul><li>(<strong>Weak decay of correlations</strong>) Weak spatial mixing holds for <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> if there exist constants <img src="https://s0.wp.com/latex.php?latex=C%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C, \xi &gt; 0" class="latex" title="C, \xi &gt; 0" /> such that for any subset <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Csum_%7Bx%5Cin%5CDelta%2C+%5C%3B+y+%5Cin+%5Cpartial_r+W%7D+%5Cexp%5CBigl%28-+%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28x%2Cy%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." class="latex" title="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." /></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing holds for <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> if there exist constants <img src="https://s0.wp.com/latex.php?latex=C%2C%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C,\xi &gt; 0" class="latex" title="C,\xi &gt; 0" /> such that for every <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta \subseteq W" class="latex" title="\Delta \subseteq W" /> and every <img src="https://s0.wp.com/latex.php?latex=%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tau,\tau' \in \Sigma^{V\setminus W}" class="latex" title="\tau,\tau' \in \Sigma^{V\setminus W}" /> differing only at site <img src="https://s0.wp.com/latex.php?latex=y+%5Cin+V%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y \in V\setminus W" class="latex" title="y \in V\setminus W" /> , <img src="https://s0.wp.com/latex.php?latex=%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Cexp%5CBigl%28-%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28y%2C%5CDelta%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." class="latex" title="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." /></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing in the <em>truncated</em> sense holds for <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> if there exist <img src="https://s0.wp.com/latex.php?latex=n%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n, \xi &gt; 0" class="latex" title="n, \xi &gt; 0" /> such that for all functions <img src="https://s0.wp.com/latex.php?latex=f%2C+g+%3A+%5COmega+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f, g : \Omega \to {\mathbb R}" class="latex" title="f, g : \Omega \to {\mathbb R}" /> which depend only on the sites at <img src="https://s0.wp.com/latex.php?latex=%5CLambda_f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Lambda_f" class="latex" title="\Lambda_f" /> and <img src="https://s0.wp.com/latex.php?latex=%5CLambda_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Lambda_g" class="latex" title="\Lambda_g" /> respectively and such that <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28%5CLambda_f%2C%5CLambda_g%29+%5Cge+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" class="latex" title="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" /> , <img src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D+%5C%3B%5Cmathrm%7Bcov%7D_%7B%5Cmu_W%5E%5Ctau%7D%28f%2C+g%29+%5Cle+%7C%5CLambda_f%7C%7C%5CLambda_g%7C%5C%7Cf%5C%7C_%5Cinfty+%5C%7Cg%5C%7C_%5Cinfty+%5Cexp%5CBigl%28-%5Cfrac%7Bd%28%5CLambda_f%2C%5CLambda_g%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." class="latex" title="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." /></li></ul>



<p>Here, <img src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\xi" class="latex" title="\xi" /> is the <strong>correlation length</strong> (in physics, it is the characteristic length scale of a system). In the disordered phase, the correlation length is a constant independent of system size. For our purposes, the main consequence of these definitions is that the effective interaction range of each spin is <img src="https://s0.wp.com/latex.php?latex=O%28%5Cxi%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\xi)" class="latex" title="O(\xi)" /> . For the Ising model, there is a key simplification due to <em>monotonicity</em>. Namely, the ferromagnetic Ising model has the nice property (which is not true for other models) that if we flip a sign from <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> to <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> , this only makes <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> more likely everywhere. This is because the spins want to agree. There are a lot of boundary conditions to consider, but here, due to monotonicity, we only need to consider two: all of the spins are <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> , and all of the spins are <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> . All <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spins will give the highest probability of a <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spin, and all <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> spin will give the lowest probability of a <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> spin. This monotonicity property is generally not required for time-space mixing equivalence to hold, but it greatly simplifies proofs.</p>



<p>It is a very non-obvious fact that all of these notions of spatial mixing are equivalent. We will sketch a proof that strong correlation decay implies that <img src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D+%3D+O%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t_{\rm mix} = O(n\log n)" class="latex" title="t_{\rm mix} = O(n\log n)" /> .</p>



<p>The idea is to use another coupling argument. Let <img src="https://s0.wp.com/latex.php?latex=X%280%29%2C+Y%280%29+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5EV&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X(0), Y(0) \in {\{\pm 1\}}^V" class="latex" title="X(0), Y(0) \in {\{\pm 1\}}^V" /> differ in one coordinate, i.e., <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_a \ne {Y(0)}_a" class="latex" title="{X(0)}_a \ne {Y(0)}_a" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_i+%3D+%7BY%280%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{X(0)}_i = {Y(0)}_i" class="latex" title="{X(0)}_i = {Y(0)}_i" /> for <img src="https://s0.wp.com/latex.php?latex=i+%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i \ne a" class="latex" title="i \ne a" /> . We want to argue that the expected distance between the processes will decrease. The proof uses a generalization of Glauber dynamics called <strong>block Glauber dynamics</strong>. In Glauber dynamics, we take a single spin and resample it conditioned on its neighbors. In block Glauber dynamics, we take an <img src="https://s0.wp.com/latex.php?latex=L%5Ctimes+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L\times L" class="latex" title="L\times L" /> box and resample it conditioned on its neighbors. There is an argument, called <em>canonical paths</em>, which can be used to show that if block Glauber dynamics mixes, then regular Glauber dynamics also mixes (slightly more slowly; we lose a <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bpoly%7D%28L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{poly}(L)" class="latex" title="\;\mathrm{poly}(L)" /> factor, but anyway <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> will be a large constant) so analyzing block Glauber dynamics is fine.</p>



<p>If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> lies in the box, then the expected change in distance is <img src="https://s0.wp.com/latex.php?latex=-L%5E2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-L^2/n" class="latex" title="-L^2/n" /> . If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> is far away from the box, then there is no change. If <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> is in the boundary of the box, then it is possible for the distance to increase. However, strong spatial mixing allows us to control the influence of a single site, so the expected change in distance is bounded by <img src="https://s0.wp.com/latex.php?latex=O%28L%5Cxi%5E2%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(L\xi^2/n)" class="latex" title="O(L\xi^2/n)" /> . Now, since <img src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\xi" class="latex" title="\xi" /> is a constant, if we choose <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> sufficiently large, then we will have the same situation as in the high temperature case: the expected distance will exponentially shrink over time.</p>



<h1 id="quantum-systems">Quantum systems</h1>



<p>The quantum version of Markov chains has many more difficulties. The first difficulty is that the Hammersley-Clifford theorem (which we have been relying on throughout this blog post) fails.</p>



<h2 id="notation">Notation</h2>



<p>To properly discuss what we mean, let’s set up some notation. Readers already familiar with density matrices, quantum entropy, and quantum mutual information may wish to skip to the next subsection. Most of the time we discuss quantum objects here, we’ll be using density matricies, often denoted <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> . A density matrix can be thought of as an extension to regular quantum states <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle " class="latex" title="|{\psi}\rangle " /> , where there is some classical source of uncertainty.</p>



<p>A density matrix is a positive semidefinite matrix with trace <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . This extends the notion of a classical probability distribution; in the quantum setting, a classical probability distribution <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> (thought of as a vector whose entries sum to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> ) is represented as the density matrix <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{diag}(p)" class="latex" title="\;\mathrm{diag}(p)" /> .</p>



<p>For example, we can consider a situation in which there is a <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> probability that we started with the quantum state <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle " class="latex" title="|{\psi}\rangle " /> and a <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> probability that we started with the quantum state <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cphi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\phi}\rangle " class="latex" title="|{\phi}\rangle " /> . This would be denoted as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5Clangle%7B%5Cpsi%7D%7C+%2B+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle+%5Clangle%7B%5Cphi%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " class="latex" title="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " /> </p>



<p>Density matricies are generally useful for a lot of tasks, but for our purposes a density matrix will be used to discuss both the classical and quantum “uncertainty” we have about what state we have.</p>



<p>Now let’s also talk about a second important piece of notation: the tensor product. Often when discussing quantum states, it is important to discuss multiple quantum states simultaneously. For example, Alice has one system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and Bob has another system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . However, these systems might be entangled, meaning that the results of the two systems are correlated.</p>



<p>For instance, let us consider the following state:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+_A+%7C%7B%2B%7D%5Crangle+_B+%2B+%7C%7B-%7D%5Crangle+_A+%7C%7B-%7D%5Crangle+_B+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" class="latex" title="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" /> </p>



<p>This particular state has the property that Alice and Bob will always both measure <img src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="+" class="latex" title="+" /> or they will both measure <img src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-" class="latex" title="-" /> . The notation for tensors is often ambiguous in the literature as there are many ways of specifying tensors. For instance, above we used subscripts to explicitly denote which particle was in system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and which was in system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . One may also choose to simply use the index of the system as below. The symbol <img src="https://s0.wp.com/latex.php?latex=%5Cotimes&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\otimes" class="latex" title="\otimes" /> is used to denote a tensor between states (where it is assumed that the first state is system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and the second, system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> ). Gradually folks may shorten the notation as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+%7C%7B%2B%7D%5Crangle+%2B+%7C%7B-%7D%5Crangle+%7C%7B-%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bpmatrix%7D+1%5C%5C0+%5Cend%7Bpmatrix%7D+%5Cotimes+%5Cbegin%7Bpmatrix%7D+0%5C%5C1+%5Cend%7Bpmatrix%7D+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " class="latex" title="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " /> </p>



<p>These are all notations for the same state. Let’s now talk about this state in the context of a density matrix. The density matrix of this state is as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29+%5Cleft%28+%5Clangle%7B%2B%2B%7D%7C+%2B+%5Clangle%7B--%7D%7C+%5Cright%29%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1%260%260%261%5C%5C0%260%260%260%5C%5C0%260%260%260%5C%5C1%260%260%261+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " class="latex" title="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " /> </p>



<p>Writing the density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> as <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B}" class="latex" title="\rho_{A,B}" /> makes explicit that this is the density matrix over systems <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> .</p>



<p>A crucial operation that one will often perform using density matricies is the partial trace. The partial trace is a way of allowing us to consider only a smaller part of the larger part of the system, while taking into account the influence of the larger system around it.</p>



<p>Here’s an example: Suppose Bob wants to know what his state is. However, Bob really doesn’t care about Alice’s system and just wants to know what the density matrix for his system is. Bob’s density matrix is simply the following density matrix (a 50% chance of being in <img src="https://s0.wp.com/latex.php?latex=%7C%7B%2B%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{+}\rangle " class="latex" title="|{+}\rangle " /> and a 50% chance of being in <img src="https://s0.wp.com/latex.php?latex=%7C%7B-%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{-}\rangle " class="latex" title="|{-}\rangle " /> ).</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+%5Clangle%7B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+%5Clangle%7B-%7D%7C+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " class="latex" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " /> </p>



<p>More explicitly, we could write the following:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " class="latex" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " /> </p>



<p>The partial trace is an operation that will let us take our original density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B}" class="latex" title="\rho_{A,B}" /> and generates a new density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_B" class="latex" title="\rho_B" /> that ignores system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> . This is specifically called the partial trace over <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , or <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}_A" class="latex" title="\;\mathrm{tr}_A" /> .</p>



<p>So how do we do this? We simply sum over the state <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> (effectively taking a trace, but only along one axis):</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Csum_i+%5Clangle%7Bi%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7Bi%7D%5Crangle+_A%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " class="latex" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " /> </p>



<p>This is easier to evaluate using certain choices of notation:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Clangle%7B%2B%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%5C%5C%26%5Cqquad+%7B%7D%2B+%5Clangle%7B-%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%5Cright%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Crho_B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " class="latex" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " /> </p>



<p>This gives us the answer that we had expected.</p>



<p>We now have all of the tools we need to talk about quantum entropy. Intuitively, entropy can be thought of as the amount of uncertainty we have for our system, or equivalently the amount of information it takes to define our system. The entropy for a quantum system <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is defined as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H%28%5Crho%29+%26%3D+-%5C%3B%5Cmathrm%7Btr%7D%28%5Crho+%5Clog_2+%5Crho%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " class="latex" title="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " /> </p>



<p>Note that here we use the shorthand <img src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_B" class="latex" title="\rho_B" /> to denote <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}_A \rho_{A,B}" class="latex" title="\;\mathrm{tr}_A \rho_{A,B}" /> . Here, writing <img src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\;\mathrm{tr}" class="latex" title="\;\mathrm{tr}" /> without the subscript indicates that this is the full or normal trace that one might expect (or equivalently performing the partial trace over all systems). We can now define the conditional entropy of a system as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BH%28A+%5Cmid+B%29%7D_%5Crho+%26%3D+H%28%5Crho_%7BA%2CB%7D%29+-+H%28%5Crho_B%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " class="latex" title="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " /> </p>



<p>This definition intuitively makes sense since we can think of conditional entropy as the amount of information it takes to describe our joint system <img src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A,B)" class="latex" title="(A,B)" /> , given that we already know what <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> is.</p>



<p>We can now discuss quantum mutual information, the amount of information that measuring system <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> will provide you about system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . Like the classical case, this is defined as follows:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB%29%7D_%5Crho+%26%3D+%7BH%28A%2CB%29%7D_%5Crho+-+%7BH%28A%5Cmid+B%29%7D_%5Crho+-+%7BH%28B%5Cmid+A%29%7D_%5Crho%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " class="latex" title="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " /> </p>



<p>We can now finally discuss <strong>quantum mutual information (QCMI)</strong>, defined as follows: <img src="https://s0.wp.com/latex.php?latex=%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%3D+%7BI%28A%3BB%2CC%29%7D_%5Crho+-+%7BI%28A%3BC%29%7D_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" class="latex" title="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" /> . With some algebraic simplifications, one can arrive at the expression:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%26%3D+%7BH%28A%2CC%29%7D_%5Crho+%2B+%7BH%28B%2CC%29%7D_%5Crho+-+%7BH%28A%2CB%2CC%29%7D_%5Crho+-+%7BH%28C%29%7D_%5Crho.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " class="latex" title="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " /> </p>



<p>The QCMI equals <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is a <strong>quantum Markov state</strong>. Classically, the entropic characterization of conditional independence corresponds to an algebraic characterization.</p>



<h2 id="recovery-maps">Recovery Maps</h2>



<p>Here, the algebraic characterization is more grueling. We have</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Cexp%28%5Clog+%5Crho_%7BAB%7D+%2B+%5Clog+%5Crho_%7BBC%7D+-+%5Clog+%5Crho_B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" class="latex" title="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" /> </p>



<p>Equivalently,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BBC%7D%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%3D+R_%7BB%5Cto+AB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" class="latex" title="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" /> </p>



<p>Here, <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+AB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to AB}" class="latex" title="R_{B\to AB}" /> is called the <strong>Petz recovery map</strong>,<sup><a href="https://windowsontheory.org/feed/#fn_4">4</a></sup> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BB%5Cto+AB%7D%28X%29+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+X%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" class="latex" title="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" /> . One can think of a recovery may as a way that we can reconstruct the entire system <img src="https://s0.wp.com/latex.php?latex=A%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A, B" class="latex" title="A, B" /> using just system <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . It is not obvious that this is a quantum channel, but it is.</p>



<p>Suppose <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is a probability distribution, so <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho =\;\mathrm{diag}(p)" class="latex" title="\rho =\;\mathrm{diag}(p)" /> for some vector <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> . Then, all of the density matrices are diagonal and commuting. Then, the recovery map means that we divide by <img src="https://s0.wp.com/latex.php?latex=p_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_B" class="latex" title="p_B" /> and multiply by <img src="https://s0.wp.com/latex.php?latex=p_%7BAB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{AB}" class="latex" title="p_{AB}" /> , i.e., multiply by <img src="https://s0.wp.com/latex.php?latex=p_%7BA+%5Cmid+B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_{A \mid B}" class="latex" title="p_{A \mid B}" /> . This is the natural thing to do if we lost our information about <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and were trying to figure out what <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> was based on our knowledge of <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> . This is why <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to A,B}" class="latex" title="R_{B\to A,B}" /> is known as a <em>recovery</em> map, and it is used to discuss conditional distributions in the quantum setting. In the classical case, if we start with <img src="https://s0.wp.com/latex.php?latex=B%2C+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B, C" class="latex" title="B, C" /> , look only at <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , and use this to reconstruct <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , then we would have the whole state in a Markov chain. That is why this is a plausible quantum version of being a Markov chain.</p>



<p>However, quantum Gibbs states are not, in general, quantum Markov chains. The failure of this statement to hold is related to <em>topological order</em>, which is similar to the degrees of freedom that show up in error correcting codes.</p>



<h2 id="quantum-markov-networks">Quantum Markov Networks</h2>



<p>Here, we will formally define a quantum Markov network. The reference for this is <a href="https://windowsontheory.org/feed/#leifer">[7]</a>.</p>



<p>Let <img src="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G = (V, E)" class="latex" title="G = (V, E)" /> be a finite graph. We associate with each vertex <img src="https://s0.wp.com/latex.php?latex=v+%5Cin+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v \in V" class="latex" title="v \in V" /> a Hilbert space <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\mathcal{H}}_v" class="latex" title="{\mathcal{H}}_v" /> and we consider a density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> acting on <img src="https://s0.wp.com/latex.php?latex=%5Cbigotimes_%7Bv%5Cin+V%7D+%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bigotimes_{v\in V} {\mathcal{H}}_v" class="latex" title="\bigotimes_{v\in V} {\mathcal{H}}_v" /> . Then, <img src="https://s0.wp.com/latex.php?latex=%28G%2C+%5Crho_V%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(G, \rho_V)" class="latex" title="(G, \rho_V)" /> is a <strong>quantum Markov network</strong> if for all <img src="https://s0.wp.com/latex.php?latex=U%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\subseteq V" class="latex" title="U\subseteq V" /> , <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> is conditionally independent of <img src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V \setminus (U \cup \partial U)" class="latex" title="V \setminus (U \cup \partial U)" /> given <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\partial U" class="latex" title="\partial U" /> , where the conditional independence statement is w.r.t. <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> and means that the corresponding QCMI satisfies <img src="https://s0.wp.com/latex.php?latex=%7BI%28U%3B+V%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29+%5Cmid+%5Cpartial+U%29%7D_%7B%5Crho_V%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" class="latex" title="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" /> .</p>



<p>A quantum Markov network is called <strong>positive</strong> if <img src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_V" class="latex" title="\rho_V" /> has full rank. (Recall that in the statement of the Hammersley-Clifford Theorem, , it is assumed that the distribution is strictly positive.)</p>



<p>Now, consider the following example. First, we introduce the Pauli matrices</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csigma%5Ex+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ez+%3A%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+-1+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ey+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+-i+%5C%5C+i+%26+0+%5Cend%7Bbmatrix%7D.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " class="latex" title="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " /> </p>



<p>We define a Hamiltonian on three qubits <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> , <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> , <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> by</p>



<p> <img src="https://s0.wp.com/latex.php?latex=H+%3A%3D+%28%5Csigma_A%5Ex+%5Csigma_B%5Ex+%2B+%5Csigma_A%5Ey+%5Csigma_B%5Ey+%2B+%5Csigma_A%5Ez+%5Csigma_B%5Ez%29+I_C+%2B+I_A+%28%5Csigma_B%5Ex+%5Csigma_C%5Ex+%2B+%5Csigma_B%5Ey+%5Csigma_C%5Ey+%2B+%5Csigma_B%5Ez+%5Csigma_C%5Ez%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" class="latex" title="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" /> </p>



<p>(Juxtaposition in the above expression signifies the tensor product as discussed before.) Finally, for <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta &gt; 0" class="latex" title="\beta &gt; 0" /> , we define the Gibbs state</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D%28%5Cbeta%29+%3A%3D+%5Cfrac%7B1%7D%7BZ%28%5Cbeta%29%7D+%5Cexp%28-%5Cbeta+H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" class="latex" title="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" /> </p>



<p>The Hamiltonian here has local terms which correspond to interactions <img src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A,B)" class="latex" title="(A,B)" /> , <img src="https://s0.wp.com/latex.php?latex=%28B%2C+C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(B, C)" class="latex" title="(B, C)" /> . However, it can be shown that the QCMI between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> conditioned on <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> w.r.t. <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{A,B,C}" class="latex" title="\rho_{A,B,C}" /> is non-zero, which means that this is not a quantum Markov network w.r.t. the line graph <img src="https://s0.wp.com/latex.php?latex=A+%5Cleftrightarrow+B+%5Cleftrightarrow+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A \leftrightarrow B \leftrightarrow C" class="latex" title="A \leftrightarrow B \leftrightarrow C" /> . This demonstrates the failure of the Hammersley-Clifford Theorem in the quantum setting.</p>



<h2 id="important-results">Important Results</h2>



<p>We will briefly discuss the results of two papers.</p>



<ol><li><a href="https://windowsontheory.org/feed/#brandao1">[8]</a> This paper shows that mixing in space implies mixing in time in the quantum case. However, the result of the paper only applies to commuting Hamiltonians. For commuting Hamiltonians, it turns out that quantum Gibbs states are quantum Markov networks. They use a version of Glauber dynamics, which can be simulated on a quantum computer but are also plausible dynamics for a physical system in nature. This is a difficult paper to read, but it is worth digesting if you want to work in the field.</li><li><a href="https://windowsontheory.org/feed/#brandao2">[9]</a> This second paper is much easier and more general, covering non-commuting Hamiltonians, but it requires more conditions. They give a method of preparing the Gibbs state which can run on a quantum computer, but the dynamics are not plausible as a physical system because they are too complicated. The more complicated dynamics allows them to make the proof work. The paper also uses QCMI.They have two assumptions. The first assumption looks like mixing in space (weak correlation decay). The second assumption is that the state looks approximately like a quantum Markov network (this is definitely not met in general). A very important paper in this space is a recent breakthrough (<a href="https://windowsontheory.org/feed/#fawzi">[10]</a>) which characterizes quantum Markov chains. They show that if the QCMI is bounded by <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> , then the recovery map <img src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R_{B\to A,B}(\rho_{BC})" class="latex" title="R_{B\to A,B}(\rho_{BC})" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon'" class="latex" title="\epsilon'" /> -close to <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{ABC}" class="latex" title="\rho_{ABC}" /> , i.e., low QCMI implies that the recovery map works well. This is trivial to prove classically, but very difficult in the quantum world.The algorithm in <a href="https://windowsontheory.org/feed/#brandao2">[9]</a> is very elegant. Essentially, we take the entire system and punch out constant-sized boxes. If we can reconstruct the region outside of the boxes, then we can use the recovery maps to reconstruct the regions inside of the boxes, and the boxes are far apart enough so they are almost independent. For this argument, we must assume that the QCMI decays exponentially. Whenever we have exponential decay, we get a correlation decay that sets the size of the boxes. It is very difficult to condition on quantum states, but recovery maps provide a sense in which it is meaningful to do so. The paper gives an efficient method of preparing Gibbs states and simulating quantum systems on quantum computers.</li></ol>



<h1 id="additional-reading">Additional reading</h1>



<p>The standard treatment of information theory is <a href="https://windowsontheory.org/feed/#info">[11]</a>. This book contains definitions and properties of entropy, conditional entropy, mutual information, and conditional mutual information.</p>



<p>To see a treatment of the subject of Markov chains from the perspective of probability theory, see <a href="https://windowsontheory.org/feed/#durrett1">[12]</a> or the mathematically more sophisticated counterpart <a href="https://windowsontheory.org/feed/#durrett2">[13]</a>. An introduction to coupling can be found in <a href="https://windowsontheory.org/feed/#mitzenmacher">[14]</a>, as well as <a href="https://windowsontheory.org/feed/#nature">[4]</a> (the latter also contains an exposition to spatial mixing). The connection between Markov chain mixing and the so-called <em>logarithmic Sobolev inequality</em> is described in <a href="https://windowsontheory.org/feed/#cesi">[15]</a>.</p>



<h1 id="scn:appendix">Appendix: Intuition for Markov chains</h1>



<h2 id="random-walk-on-the-cycle">Random walk on the cycle</h2>



<p>We have <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> points on the cycle, <img src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0,1,\dotsc,n-1" class="latex" title="0,1,\dotsc,n-1" /> . At each step, we move left or right with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" /> . We can write the transition matrix as</p>



<p> <img src="https://s0.wp.com/latex.php?latex=T+%3D+%5Cfrac%7BS+%2B+S%5E%7B-1%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T = \frac{S + S^{-1}}{2}" class="latex" title="T = \frac{S + S^{-1}}{2}" /> </p>



<p>where <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> is the shift operator <img src="https://s0.wp.com/latex.php?latex=S+%7C%7Bx%7D%5Crangle+%3D+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S |{x}\rangle = |{x+1 \bmod n}\rangle " class="latex" title="S |{x}\rangle = |{x+1 \bmod n}\rangle " /> . The matrix <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> is diagonalized by the Fourier transform. Define, for <img src="https://s0.wp.com/latex.php?latex=k%3D0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=0,1,\dotsc,n-1" class="latex" title="k=0,1,\dotsc,n-1" /> ,</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Ctilde+k%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " class="latex" title="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " /> </p>



<p>We have the same amount of amplitude at every point, but there is a varying phase which depends on <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> . If <img src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 0" class="latex" title="k = 0" /> , we get the all-ones vector. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is small, then the phase is slowly varying. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is large, then the phase is rapidly varying. Look at what happens after we apply the shift operator:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+S+%7C%7B%5Ctilde+k%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D1%7D%5En+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+%28x-1%29%7D%7Bn%7D+%5CBigr%29+%7C%7Bx+%5Cbmod+n%7D%5Crangle+%3D+%5Cexp%5CBigl%28-+%5Cfrac%7B2%5Cpi+i+k%7D%7Bn%7D+%5CBigr%29+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " class="latex" title="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " /> </p>



<p>After the shift, we pick up an additional phase based on how rapidly the phase is varying. From this, we get:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%26%3D+%5Cfrac%7B%5Cexp%282%5Cpi+i+k+%2F+n%29+%2B+%5Cexp%28-2%5Cpi+i+k+%2F+n%29%7D%7B2%7D+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Ccos%5CBigl%28%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%5CBigr%29+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " class="latex" title="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " /> </p>



<p>The eigenvalues are</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%3D+%5Ccos+%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%2C+%5Cqquad+k%3D0%2C1%2C%5Cdotsc%2Cn-1.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." class="latex" title="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." /> </p>



<p>Only <img src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k = 0" class="latex" title="k = 0" /> will give me an eigenvalue of <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> .</p>



<p>How do we analyze <img src="https://s0.wp.com/latex.php?latex=T%5Et+%7C%7Bp%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t |{p}\rangle " class="latex" title="T^t |{p}\rangle " /> ? We should Fourier transform the distribution.</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T%5Et+%7C%7Bp%7D%5Crangle+%3D+T%5Et+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%5Clambda_k%5Et+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" class="latex" title="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" /> </p>



<p>If <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is odd, then as <img src="https://s0.wp.com/latex.php?latex=t%5Crightarrow%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\rightarrow\infty" class="latex" title="t\rightarrow\infty" /> , <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k%5Et+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_k^t \to 0" class="latex" title="\lambda_k^t \to 0" /> for all <img src="https://s0.wp.com/latex.php?latex=k%3D1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=1,\dotsc,n-1" class="latex" title="k=1,\dotsc,n-1" /> , so <img src="https://s0.wp.com/latex.php?latex=T%5Et+%5Cto+%7C%7B%5Cpi%7D%5Crangle+%5Clangle%7B1_n%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T^t \to |{\pi}\rangle \langle{1_n}| " class="latex" title="T^t \to |{\pi}\rangle \langle{1_n}| " /> . Whatever you put into this operator, you get <img src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pi" class="latex" title="\pi" /> out.</p>



<h2 id="spectral-gap">Spectral gap</h2>



<p>The example of the random walk on the cycle shows that there is generally a unique stationary distribution and suggests that the speed of convergence is determined by how close the other eigenvalues are to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> . Specifically, suppose for simplicity that the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> are <img src="https://s0.wp.com/latex.php?latex=1+%3D+%5Clambda_0+%5Cge+%5Clambda_1%5Cge%5Ccdots+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" class="latex" title="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" /> (real and positive). Then, the convergence time is on the order of <img src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sim 1/(1-\lambda_1)" class="latex" title="\sim 1/(1-\lambda_1)" /> .</p>



<p>Typically, the distance of the eigenvalues from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> reflects the size of the physical system. Even from the simple example, we can get some physical intuition from this. If <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is small, then the spectral gap is <img src="https://s0.wp.com/latex.php?latex=%5Ccos%282%5Cpi+k%2Fn%29+%3D+1-O%28k%5E2%2Fn%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cos(2\pi k/n) = 1-O(k^2/n^2)" class="latex" title="\cos(2\pi k/n) = 1-O(k^2/n^2)" /> . Thus, the convergence time is <img src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29+%5Csim+n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sim 1/(1-\lambda_1) \sim n^2" class="latex" title="\sim 1/(1-\lambda_1) \sim n^2" /> , which is indeed the convergence time for a random walk on a cycle.</p>



<h2 id="references">References</h2>



<hr class="wp-block-separator" />



<ol><li>S. Gharibian, Y. Huang, Z. Landau, and S. W. Shin, “Quantum Hamiltonian complexity,” <em>Found. Trends Theor. Comput. Sci.</em>, vol. 10, no. 3, pp. front matter, 159–282, 2014. </li><li>R. W. Keener, <em>Theoretical statistics</em>. Springer, New York, 2010, p. xviii+538. </li><li>E. Crosson, D. Bacon, and K. R. Brown, “Making Classical Ground State Spin Computing Fault-Tolerant,” <em>Physical Review E</em>, vol. 82, no. 3, Sep. 2010. </li><li>C. Moore and S. Mertens, <em>The nature of computation</em>. Oxford University Press, Oxford, 2011, p. xviii+985. </li><li>F. Martinelli, “Lectures on Glauber dynamics for discrete spin models,” in <em>Lectures on probability theory and statistics (Saint-Flour, 1997)</em>, vol. 1717, Springer, Berlin, 1999, pp. 93–191. </li><li>F. Martinelli and E. Olivieri, “Finite volume mixing conditions for lattice spin systems and exponential approach to equilibrium of Glauber dynamics,” in <em>Cellular automata and cooperative systems (Les Houches, 1992)</em>, vol. 396, Kluwer Acad. Publ., Dordrecht, 1993, pp. 473–490. </li><li>M. S. Leifer and D. Poulin, “Quantum graphical models and belief propagation,” <em>Ann. Physics</em>, vol. 323, no. 8, pp. 1899–1946, 2008. </li><li>M. J. Kastoryano and F. G. S. L. Brandão, “Quantum Gibbs samplers: the commuting case,” <em>Comm. Math. Phys.</em>, vol. 344, no. 3, pp. 915–957, 2016. </li><li>F. G. S. L. Brandão and M. J. Kastoryano, “Finite correlation length implies efficient preparation of quantum thermal states,” <em>ArXiv e-prints</em>, Sep. 2016. </li><li>O. Fawzi and R. Renner, “Quantum conditional mutual information and approximate Markov chains,” <em>Comm. Math. Phys.</em>, vol. 340, no. 2, pp. 575–611, 2015. </li><li>T. M. Cover and J. A. Thomas, <em>Elements of information theory</em>, Second. Wiley-Interscience [John Wiley &amp; Sons], Hoboken, NJ, 2006, p. xxiv+748. </li><li>R. Durrett, <em>Essentials of stochastic processes</em>. Springer, Cham, 2016, p. ix+275. </li><li>R. Durrett, <em>Probability: theory and examples</em>, Fourth., vol. 31. Cambridge University Press, Cambridge, 2010, p. x+428. </li><li>M. Mitzenmacher and E. Upfal, <em>Probability and computing</em>, Second. Cambridge University Press, Cambridge, 2017, p. xx+467. </li><li>F. Cesi, “Quasi-factorization of the entropy and logarithmic Sobolev inequalities for Gibbs random fields,” <em>Probab. Theory Related Fields</em>, vol. 120, no. 4, pp. 569–584, 2001. </li></ol>



<hr class="wp-block-separator" />



<ol><li>This is the opposite of the probabilists’ convention, i.e., the transition probability matrix that we define here is the <em>transpose</em> of the one usually found in most probability theory textbooks. <a href="https://windowsontheory.org/feed/#fnref_1"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>As a side note, it may be a good research question to investigate to what extent quantum algorithms can be used to compute summations whose terms are possibly negative. In quantum Monte Carlo, the quantum Hamiltonian is converted to a classical energy function; this conversion always works, but sometimes you end up with complex energies, which is terrible for estimating the partition function because terms can cancel each other out. <a href="https://windowsontheory.org/feed/#fnref_2"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>You may recognize this as the total variation norm. <a href="https://windowsontheory.org/feed/#fnref_3"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li><li>Petz wrote about quantum relative entropy in 1991, way before it was cool. <a href="https://windowsontheory.org/feed/#fnref_4"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li></ol></div>







<p class="date">
by wsmoses <a href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/"><span class="datestr">at December 20, 2018 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/">Theory Blog Aggregator Up!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The <strong>Theory of Computing Blog Aggregator</strong> is now back online at a new website: <a href="http://cstheory-feed.org/" rel="nofollow">http://cstheory-feed.org/</a> . There is also a twitter feed at <a href="https://twitter.com/cstheory" rel="nofollow">https://twitter.com/cstheory</a> .</p>
<p>See <a href="http://blog.geomblog.org/2018/12/the-theorycs-blog-aggregator-reborn.html">this blog post</a> by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to thank Arvind Narayanan who created the software to run it and maintained it all these years.</p>
<p>If you don’t want to rely on the aggregator to follow windows on theory, you can use the <strong>“Follow Blog by email”</strong> button on our side bar, and join the 590 other happy customers who don’t need to wait to the feed to get the <a href="https://windowsontheory.org/category/physics/">latest lecture notes</a> from our physics and computation seminar.</p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/"><span class="datestr">at December 20, 2018 09:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6358">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">What is Quantum Hamiltonian Complexity?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>by Ben Edelman</strong></p>
<p><em>This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. The second installment is <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">here</a>, and the third installment is <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">here</a>.</em></p>
<p>Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both physics and computation. Our hope is that these three posts will provide an accessible (and incomplete) preview of the subject for readers who know the basics of theoretical computer science and quantum information. Much of the material is adapted from an <a href="https://arxiv.org/abs/1401.3916">excellent survey by Gharibian et al.</a>.</p>
<p>In a nutshell, quantum Hamiltonian complexity is the study of the <em>local Hamiltonian problem</em>. Why is this problem important enough to justify the existence of an entire subfield? To illustrate why, here are two informal characterizations of it:</p>
<ol>
<li>To a <strong>physicist</strong>, the local Hamiltonian problem is a formalization of the difficulty of simulating and understanding many-particle quantum systems. There are deep connections between the complexity of this problem and the amount of quantum entanglement in a system. In practical terms, physicists would love to be able to solve this problem on a regular basis, and they’ve developed a rich theory of heuristics to that end.</li>
<li>To a <strong>computer scientist</strong>, local Hamiltonian problem is the quantum version of constraint satisfaction problems. Any CSP can be written as a local Hamiltonian problem; and just as constraint satisfaction is the prototypical NP-complete problem by the Cook-Levin theorem, the local Hamiltonian problem plays the equivalent role for QMA (a quantum analogue of NP) by the “quantum Cook-Levin theorem.” The connections to classical complexity go on… there is even a <a href="https://arxiv.org/pdf/1309.7495.pdf">quantum PCP conjecture</a>!</li>
</ol>
<p>But let’s take a step back and start at the beginning. To make sure we understand what a quantum Hamiltonian is and why it is important, it will be instructive to briefly rehash some of the <a href="https://windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">fundamentals of classical statistical mechanics</a>.</p>
<h2>Classical energy and ground states</h2>
<p>In the classical world, a physical system can be in any one of various states <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in \mathcal{X}" class="latex" title="x \in \mathcal{X}" />, each of which is a vector, with different coordinates representing different particles. Every state of the system has an <em>energy</em>, given by an energy function <img src="https://s0.wp.com/latex.php?latex=E%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E: \mathcal{X} \to \mathbb{R}" class="latex" title="E: \mathcal{X} \to \mathbb{R}" />. For example, in the classic Ising model of ferromagnetism, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D+%3D+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{X} = \{\pm 1\}^n" class="latex" title="\mathcal{X} = \{\pm 1\}^n" />. Each coordinate <img src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_i" class="latex" title="x_i" /> represents the spin of atom <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />, and atoms <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> and <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> interact with each other whenever <img src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(i,j)" class="latex" title="(i,j)" /> is an edge in a graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, which is usually a low-dimensional lattice. Energy for this system is defined as <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7B%28i%2Cj%29+%5Cin+G%7D-x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(x) = \sum_{(i,j) \in G}-x_i x_j" class="latex" title="E(x) = \sum_{(i,j) \in G}-x_i x_j" />.</p>
<p>Suppose we ignore our system for a long time, letting it interact with its external environment until, in the limit, it reaches thermal equilibrium at temperature <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" />. Then the probability the system is in state <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> is given by Boltzmann’s distribution: <img src="https://s0.wp.com/latex.php?latex=%5CPr%5Bx%5D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+E%28x%29%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" class="latex" title="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cpropto+1%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta \propto 1/T" class="latex" title="\beta \propto 1/T" /> and <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> is the partition function required to normalize the probabilities. As the temperature tends to infinity, this distribution will approach the uniform distribution over <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{X}" class="latex" title="\mathcal{X}" />, and as the temperature tends to absolute zero, the distribution will approach the uniform distribution over the states with minimum energy. We call these minimum energy states <em>ground states</em>, and we call their energy the <em>ground state energy</em>. If we want to calculate something about a system, then it is often crucial to know the ground states and ground state energy of the system. Going back to our example, the Ising model has two ground states whenever <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is connected. These are the states <img src="https://s0.wp.com/latex.php?latex=%28%2B1%2C%2B1%2C%5Cldots%2C%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(+1,+1,\ldots,+1)" class="latex" title="(+1,+1,\ldots,+1)" /> and <img src="https://s0.wp.com/latex.php?latex=%28-1%2C-1%2C%5Cldots%2C-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(-1,-1,\ldots,-1)" class="latex" title="(-1,-1,\ldots,-1)" /> in which all atoms have the same spin. The ground state energy is <img src="https://s0.wp.com/latex.php?latex=-%7C%5C%7Bi%2Cj%3A%28i%2Cj%29+%5Cin+G%5C%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-|\{i,j:(i,j) \in G\}|" class="latex" title="-|\{i,j:(i,j) \in G\}|" />.</p>
<h2>Quantum Hamiltonians</h2>
<p>A quantum Hamiltonian is essentially the quantum analogue of the classical energy function. Unlike with classical systems, when a quantum system is in a given <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit state <img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%5Cright%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left|\psi\right\rangle" class="latex" title="\left|\psi\right\rangle" />, it doesn’t have a determinate energy. Instead, when we measure the energy, the value we obtain may be probabilistic and will correspond to one of the eigenvalues of the observable matrix for energy. This Hermitian matrix, denoted <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" />, is the quantum Hamiltonian, and just as the energy function characterizes a classical system, the Hamiltonian characterizes a quantum system. For a given eigenvector <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_i\rangle" class="latex" title="|\lambda_i\rangle" /> of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> with eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" />, when we measure the energy of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> we obtain the result <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\psi|\lambda_i\rangle" class="latex" title="\langle\psi|\lambda_i\rangle" />, and the system collapses to the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_i\rangle" class="latex" title="|\lambda_i\rangle" /> (assuming the eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_i" class="latex" title="\lambda_i" /> has multiplicity 1). Thus, the ground state and ground state energy of a quantum system with eigenvalue <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> are the minimum eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0" class="latex" title="\lambda_0" /> of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> and the corresponding eigenvector <img src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\lambda_0\rangle" class="latex" title="|\lambda_0\rangle" />.</p>
<p>The Boltzmann distribution also has a quantum analogue. A quantum system at thermal equilibrium will be in the following mixed state: <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+H%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" class="latex" title="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" />. As the temperature approaches absolute zero, <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{\text{eq}}" class="latex" title="\rho_{\text{eq}}" /> will approach a superposition over the ground states.</p>
<p>Not only does the Hamiltonian tell us the energy of a system, it also describes the time evolution of the system (as long as it is closed). Schrödinger’s equation states that <img src="https://s0.wp.com/latex.php?latex=-i+%5Chbar+%5Cfrac%7Bd%7C%5Cpsi%5Crangle%7D%7Bdt%7D+%3D+H%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" class="latex" title="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" />, where <img src="https://s0.wp.com/latex.php?latex=%5Chbar&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\hbar" class="latex" title="\hbar" /> is Planck’s constant and <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> is time. Thus, if a closed system is in the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_0" class="latex" title="|\psi\rangle_0" /> at time 0, its state at time <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> will be <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_t+%3D+e%5E%7B-itH%2F%5Chbar%7D%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" class="latex" title="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" />. Since <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is Hermitian, <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-itH%2F%5Chbar%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e^{-itH/\hbar}" class="latex" title="e^{-itH/\hbar}" /> is unitary, which is another way of saying that quantum mechanical states are subject to unitary evolution.</p>
<h1>The Local Hamiltonian problem</h1>
<p>As we have seen, understanding the Hamiltonian of a quantum system is crucial for understanding both the system’s equilibrium behavior and its time evolution. There are a huge variety of questions physicists are interested in asking about systems, all of which boil down to questions about equilibrium behavior, time evolution, or both. There is a single problem that captures the complexity of many of these questions, in the sense that most of the questions can’t be answered without solving it. This is the problem of estimating the ground state energy of the Hamiltonian. Especially in condensed matter physics, this problem is ubiquitous.</p>
<p>Formally, we will study the following promise problem: (note: this will not be our final formulation)</p>
<hr />
<p><strong>The “Hamiltonian Problem”</strong></p>
<p>Given a Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" /> and non-negative reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> with <img src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b \geq a+1" class="latex" title="b \geq a+1" />,</p>
<ul>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \leq a" class="latex" title="\lambda_0(H) \leq a" />, output YES<p></p>
</li>
<li>
<p>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \geq b" class="latex" title="\lambda_0(H) \geq b" />, output NO</p>
</li>
</ul>
<hr />
<p>One issue with this definition is that the input includes an enormous <img src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n \times 2^n" class="latex" title="2^n \times 2^n" /> matrix. For a reasonable-sized system, there’d be no use in even trying to solve this problem through classical computation, and how to deal with it in the quantum computing setting is far from obvious. Luckily, physicists have found that in real-life systems, interactions tend to be <em>local</em>, and if we consider the special case of <em>local Hamiltonians</em>, the input for the problem is of reasonable size.</p>
<p></p><div style="width: 295px;" id="attachment_6361" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram0.png?w=285&amp;h=300" alt="circle_diagram0" height="300" class="aligncenter size-medium wp-image-6361" width="285" /><p class="wp-caption-text">Hamiltonians are too big to work with. What if we restrict our focus to local Hamiltonians?</p></div><p></p>
<p>A <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian is a Hamiltonian that is decomposed into a sum of terms, each of which represents a Hamiltonian acting on a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-unit subset of the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits in the system. In other words, <img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_i+%28H_i%29_%7BS_i%7D+%5Cotimes+I_%7B%5Bn%5D%5Cbackslash+S_i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" class="latex" title="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" />, where each <img src="https://s0.wp.com/latex.php?latex=S_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_i" class="latex" title="S_i" /> is a subset of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[n]" class="latex" title="[n]" /> of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. For brevity’s sake, we abuse notation and write <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> as <img src="https://s0.wp.com/latex.php?latex=%5Csum_i+H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_i H_i" class="latex" title="\sum_i H_i" />. We can think of the <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />’s as local constraints, and the ground state as the state that simultaneously satisfies the constraints to the maximal possible extent. Here, then, is the new-and-improved problem definition:</p>
<hr />
<p><strong><img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-Local Hamiltonian Problem</strong></p>
<p>Given a Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" /> specified as a collection of <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> local interactions <img src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H_i\}" class="latex" title="\{H_i\}" />, and non-negative reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> with <img src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b \geq a+1" class="latex" title="b \geq a+1" />,</p>
<ul>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \leq a" class="latex" title="\lambda_0(H) \leq a" />, output YES</li>
<li>If <img src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda_0(H) \geq b" class="latex" title="\lambda_0(H) \geq b" />, output NO</li>
</ul>
<hr />
<p>Presuming the matrices <img src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{H_i\}" class="latex" title="\{H_i\}" /> and the reals <img src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a, b" class="latex" title="a, b" /> are specified to polynomial precision, then the input size is polynomial in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, since <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is a constant and each of the matrices <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" /> has <img src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ccdot+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k \cdot 2^k" class="latex" title="2^k \cdot 2^k" /> entries. Thus, not only is our new problem physically realistic, it is also a problem we might hope to attack with classical computation. However, we will later see that in fact this problem is likely hard even for quantum computers. The remaining installments in this series of notes will deal with further restrictions of the class of Hamiltonians for which the local Hamiltonian problem may be tractable.</p>
<h2>Computer science motivation</h2>
<p>As we mentioned in the intro, the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian problem (henceforth denoted <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH) doesn’t just have myriad applications in physics—it is also important from a computer science perspective because it is a quantum generalization of constraint satisfiability (you may have noticed that quantum analogues of classical concepts are a running theme). Specifically, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP is a special case of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH.</p>
<p>Suppose we have a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP instance <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" />, and we want to turn it into a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH instance. A clause <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> with constituent variables <img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cldots%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \ldots, x_k" class="latex" title="x_1, \ldots, x_k" /> becomes a <img src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ctimes+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k \times 2^k" class="latex" title="2^k \times 2^k" /> diagonal <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\}" class="latex" title="\{0,1\}" /> matrix <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> acting on the qubits <img src="https://s0.wp.com/latex.php?latex=%7Cx_1%5Crangle%2C%5Cldots%2C%7Cx_k%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|x_1\rangle,\ldots,|x_k\rangle" class="latex" title="|x_1\rangle,\ldots,|x_k\rangle" />. Note that the rows and columns of this matrix are indexed by the assignment vectors <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B0%2C1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in \{0,1\}^k" class="latex" title="x \in \{0,1\}^k" />. Formally, <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> encodes the truth table of <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> in the following manner: <img src="https://s0.wp.com/latex.php?latex=%28H_C%29_%7Bx%2Cx%7D+%3D+1+-+C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(H_C)_{x,x} = 1 - C(x)" class="latex" title="(H_C)_{x,x} = 1 - C(x)" />. Another way of stating this is <img src="https://s0.wp.com/latex.php?latex=H_C+%3D+%5Csum_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5Ek%5Ctext%7B+s.t.+%7DC%28x%29%3D0%7D%7Cx%5Crangle%5Clangle%7Bx%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" class="latex" title="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" />.</p>
<p>Informally, <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> takes the clauses of <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> and turns them into local quantum interactions. We’ve constructed <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> so that it has two eigenvalues: 0 and 1. The eigenspace corresponding to 0 is spanned by the set of computational basis vectors <img src="https://s0.wp.com/latex.php?latex=%7Cx%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|x\rangle" class="latex" title="|x\rangle" /> that satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />, and the eigenspace corresponding to 1 is spanned by the computational basis vectors that don’t satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. In effect, when we consider <img src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_C" class="latex" title="H_C" /> as a term of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />, we are giving an energy penalty to any variable assignment that doesn’t satisfy <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />. <img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_%7BC%7DH_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H = \sum_{C}H_C" class="latex" title="H = \sum_{C}H_C" /> will have the eigenvalue 0 (in other words, a ground state energy of 0) if and only if there is some assignment of the variables <img src="https://s0.wp.com/latex.php?latex=x_1%2C%5Cldots%2Cx_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1,\ldots,x_n" class="latex" title="x_1,\ldots,x_n" /> that satisfies all of the clauses (in other words, iff <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable). Otherwise, the ground state energy of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> will be at least 1, so determining whether <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable is equivalent to solving <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH with inputs <img src="https://s0.wp.com/latex.php?latex=a+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a = 0" class="latex" title="a = 0" />, and <img src="https://s0.wp.com/latex.php?latex=b+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b = 1" class="latex" title="b = 1" />. (In fact, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH generalizes MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP, since the ground state energy of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is exactly the number of clauses minus the maximum number of satisfiable clauses.)</p>
<p><span id="more-6358"></span></p>
<p></p>
<p></p>
<p>Let’s work through an example. Consider the following 2-SAT formula:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cvarphi%28x_1%2Cx_2%2Cx_3%29+%3D+%28x_1+%5Cvee+x_2%29+%5Cwedge+%28%5Coverline%7Bx_1%7D+%5Cvee+x_3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" class="latex" title="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" /></p>
<p>The truth table for the first clause <img src="https://s0.wp.com/latex.php?latex=C_1+%3D+%28x_1+%5Cvee+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1 = (x_1 \vee x_2)" class="latex" title="C_1 = (x_1 \vee x_2)" /> is:</p>
<table>
<tbody>
<tr>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /></th>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_2" class="latex" title="x_2" /></th>
<th style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=x_1+%5Cvee+x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1 \vee x_2" class="latex" title="x_1 \vee x_2" /></th>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>So <img src="https://s0.wp.com/latex.php?latex=H_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_1" class="latex" title="H_1" /> is the following matrix:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_1+%3D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" title="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" /></p>
<p>We also have</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_2+%3D+%5Cbegin%7Bpmatrix%7D+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" title="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" /></p>
<p>Then,<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%26%3D+%28H_1%29_%7B1%2C2%7D+%5Cotimes+I_%7B3%7D+%2B+%28H_2%29_%7B1%2C3%7D+%5Cotimes+I_%7B2%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%260%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%260%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%2B+%5Cbegin%7Bpmatrix%7D+0%26%26%26%26%26%26%26+%5C%5C+%260%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" class="latex" title="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> has diagonal entries that are zero, so it has 0 as an eigenvalue. We can therefore conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varphi" class="latex" title="\varphi" /> is satisfiable. (In this example it was easy to write out <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> and see that it has zeros on the diagonal, but when <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is large, <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> becomes exponentially big, so we can’t just compute it explicitly and look through its diagonal entries.)</p>
<h1>Quantum Cook-Levin Theorem</h1>
<p>We’ve seen that any <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP problem can be thought of as a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH problem (with a diagonal Hamiltonian matrix). And the analogy can be drawn even further. One reason <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-CSP is so useful is that it (and in particular 3-SAT) is NP-complete, according to the Cook-Levin Theorem. 3-SAT captures the difficulty of classical efficiently verifiable computation. It may not come as a surprise, then, that <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH captures the difficulty of <em>quantum</em> efficiently verifiable computation. This result is the “quantum Cook-Levin theorem”, but before we see it we need to define the complexity class QMA, the quantum analogue of NP.</p>
<p>Because quantum computation is probabilistic, QMA is more precisely the quantum analogue of MA (Merlin Arthur), which allows the verifier to have a chance of error:</p>
<hr />
<p><strong>MA</strong></p>
<p><img src="https://s0.wp.com/latex.php?latex=L+%5Cin+%5Ctext%7BMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L \in \text{MA}" class="latex" title="L \in \text{MA}" /> iff there exists a probabilistic poly-time verifier <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and a polynomial <img src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(n)" class="latex" title="p(n)" /> such that</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L%2C+%5Cexists+y+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" class="latex" title="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" /><p></p>
</li>
<li>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \notin L" class="latex" title="\forall x \notin L" />, <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" class="latex" title="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" /></p>
</li>
</ul>
<hr />
<p>For QMA, the verifier is a quantum computer and the witness is a quantum state. Moreover, we’re interested in the complexity of promise problems:</p>
<hr />
<p><strong>QMA</strong></p>
<p>A promise problem <img src="https://s0.wp.com/latex.php?latex=L+%3D+L_%7Byes%7D+%5Ccup+L_%7Bno%7D+%5Cin+%5Ctext%7BQMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L = L_{yes} \cup L_{no} \in \text{QMA}" class="latex" title="L = L_{yes} \cup L_{no} \in \text{QMA}" /> iff there exists a quantum poly-time verifier <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and a polynomial <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> such that</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L_%7Byes%7D%2C+%5Cexists+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" class="latex" title="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" /><p></p>
</li>
<li>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L_%7Bno%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall x \notin L_{no}" class="latex" title="\forall x \notin L_{no}" />, <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" class="latex" title="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" /></p>
</li>
</ul>
<hr />
<p>A problem is QMA-complete if it is in QMA and if any problem in QMA can be reduced to it in polynomial time. In 2002, Kitaev proved that <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH is QMA-complete for all <img src="https://s0.wp.com/latex.php?latex=k+%5Cgeq+5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k \geq 5" class="latex" title="k \geq 5" />. This was the first time a natural problem was shown to be QMA-complete. In 2003 Kempe and Regev proved that 3-LH is QMA-complete, and finally in 2006 Kempe, Kitaev and Regev proved that 2-LH is QMA complete, achieving the best possible result unless P = QMA. (3-SAT is NP-complete but 2-SAT is in P, so it may seem curious that 2-LH is QMA-complete. But in fact, this isn’t too surprising, because as we mentioned earlier, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-LH corresponds to MAX-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-SAT, and MAX-2-SAT is NP-complete.)</p>
<hr />
<p><strong>“Quantum Cook-Levin Theorem”</strong></p>
<p>The 2-local Hamiltonian problem is QMA-complete.</p>
<hr />
<p><em>A very sketchy proof sketch.    </em>This theorem is called the quantum Cook-Levin theorem not just because of the result, but also because the proof is along the same lines as the proof of the Cook-Levin theorem.</p>
<p>Recall that in the proof of the Cook-Levin theorem, we start with a verifier Turing machine that takes as input <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" /> and, in time <img src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p(n)" class="latex" title="p(n)" /> accepts iff <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> being in the language. We then devise (for each <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />) a 3-SAT formula such that any satisfying solution to the instance must be an encoding of a valid history of the Turing machine from start to finish on the input <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />. The constraints must guarantee that (a) the input indeed starts with <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, (b) at every time step <img src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B1%2Cp%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t \in [1,p(n)]" class="latex" title="t \in [1,p(n)]" /> the state of the machine correctly follows from its state at time <img src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t-1" class="latex" title="t-1" />, and that (c) the final state of the machine indicates acceptance. The constraints for (a) and (c) are trivial, and the reason we can do (b) is because Turing machines compute <em>locally</em>.</p>
<p>For our quantum Cook-Levin proof, we follow the same template. Given a quantum circuit, we construct a local Hamiltonian that has ground energy below some constant only if there is a quantum encoding of the circuit that includes the proper (a) initial state, (b) intermediate computation, and (c) final state. As before, (a) and (c) are easy, because the parts of the initial and final states we need to ‘inspect’ (with the local terms of the Hamiltonian) are essentially classical. But when we try to compute local constraints for (b), we run into a big problem: entanglement.</p>
<p>Consider some step of the computation. This will consist of applying a quantum gate <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> to a state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> to obtain <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" />. Even assuming we’ve already written down constraints to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> is correct, it is non-trivial to write down constraints to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" /> because <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> may differ from <img src="https://s0.wp.com/latex.php?latex=U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U|\psi\rangle" class="latex" title="U|\psi\rangle" /> in a highly <em>non-local</em> way if there is entanglement between far-flung qubits. For example, suppose for the sake of illustration that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> and <img src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = I" class="latex" title="U = I" />. And suppose we want to check that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> with 1-local constraints. Unfortunately, there is no way to distinguish <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" title="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+-+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" class="latex" title="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" /> by looking at one qubit at a time: the reduced density matrix of either state for either qubit is the same: <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" />/2. There are examples like this that apply for <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local constraints for any <img src="https://s0.wp.com/latex.php?latex=k+%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k &gt;1" class="latex" title="k &gt;1" />, so we can’t even verify the ‘trivial’ gate <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" />, let alone gates that actually change the state. It would seem that we are stuck.</p>
<p>Luckily, although quantum superposition makes this problem more difficult, we can actually use superposition in a clever manner in order to surmount the difficulty. Instead of encoding the states <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> separately, we can put them in superposition in a way that will allow us to verify that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = U|\psi\rangle" class="latex" title="|\psi'\rangle = U|\psi\rangle" />. Suppose again that <img src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U = I" class="latex" title="U = I" />, so we want to check that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle = |\psi\rangle" class="latex" title="|\psi'\rangle = |\psi\rangle" />. Let <img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C%5Cpsi%5Crangle%7C0%5Crangle+%2B+%7C%5Cpsi%27%5Crangle%7C1%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" class="latex" title="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" />. Then, just by looking at the last qubit of <img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle" class="latex" title="|\eta\rangle" />, we can tell how close <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" /> is to <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" />: the reduced density matrix of the last qubit contains information about the angle between <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi'\rangle" class="latex" title="|\psi'\rangle" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bpmatrix%7D+1+%26+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%5C%5C+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" class="latex" title="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" /></p>
<p>The challenge is to describe a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> that has a state with energy below some parameter <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> whenever <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, and otherwise has no state with energy below <img src="https://s0.wp.com/latex.php?latex=b%3Ea&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b&gt;a" class="latex" title="b&gt;a" />. We won’t cover the details here, but the crucial idea is that when <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> is a valid witness for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, the following ‘witness state’ (which is a superposition of the states of the quantum computer over all the time steps) will have low energy for a carefully-devised <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7Bp%28n%29%7D%5Csum_%7Bt%3D0%7D%5E%7Bp%28n%29%7D%28U_t%5Ccdots+U_1%7C%5Cpsi_0%5Crangle%29%5Cotimes%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" class="latex" title="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7Cx%5Crangle%7Cy%5Crangle%7C0%5Crangle%5E%7B%5Cotimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" class="latex" title="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" /> is the initial state of the computation, and <img src="https://s0.wp.com/latex.php?latex=%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|t\rangle" class="latex" title="|t\rangle" /> is called the “clock register”. Note that because the size of the clock register is logarithmic in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, we actually need to use <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />-local constraints. For 5-local constraints to suffice, the witness state will need to be a little more complicated (the proof for 2-local constraints is even more difficult). Even for the case of <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />-LH, the complete proof must demonstrate that no state besides the witness state has low energy.</p>
<p style="text-align: right;">□</p>
<h1>Roadmap</h1>
<p>The upshot is that 2-LH is the canonical QMA-complete problem. This is a beautiful result from a quantum complexity theory perspective, but from a physics perspective it is very bad news. The QMA-completeness of the local Hamiltonian problem means that (presuming BQP <img src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\neq" class="latex" title="\neq" /> QMA) we can’t solve 2-LH, and we couldn’t even solve it with a quantum computer. Because of the central importance of finding the ground energy, this in turn means that <em>almost anything a physicist would like to compute about a system is intractable</em>.</p>
<p>So is all hope lost? No! Just as we started out wanting to understand Hamiltonians in general and restricted our focus to <em>local</em> Hamiltonians, the approach the physics community has taken is to focus on even more restricted classes of Hamiltonians that still capture interesting physical systems. One route is to restrict the topology of the system encoded by the Hamiltonian: for example, in many physics models, the particles form a low-dimensional lattice and the only interactions between them are 2-local interactions along edges. Even this isn’t enough, though: the problem remains QMA-hard on many simple topologies like lattices (for example, 2-LH on the 2-D lattice is QMA-complete, and 2-LH on even the 1-D lattice is QMA-complete when instead of qubits we are dealing with 8-dimensional qudits). So we add a further restriction, which is to focus on <em>gapped</em> Hamiltonians: these are Hamiltonians for which there is a constant gap between the ground energy and the second-lowest energy.</p>
<p></p><div style="width: 392px;" id="attachment_6405" class="wp-caption aligncenter"><img src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram1.png?w=382&amp;h=336" alt="circle_diagram1.png" height="336" class="  wp-image-6405 aligncenter" width="382" /><p class="wp-caption-text">Even local Hamiltonians are intractable in general. Gapped Hamiltonians on low-dimensional lattices, though, may be tractable.</p></div><p></p>
<p>Thus, in the notes to follow, we will focus our energies on trying to solve the gapped local Hamiltonian problem for 1-D and 2-D lattices. The reason there is hope in these settings is that entanglement is (or is conjectured to be) limited by ‘area laws’. In the next post, Fred Zhang will describe a diagrammatic language (‘tensor networks’) for thinking about low-entanglement quantum states, and he’ll show how physicists solve the local Hamiltonian problem for gapped 1-D systems.</p></div>







<p class="date">
by benedelman <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/"><span class="datestr">at December 20, 2018 09:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5365">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2018/12/20/incidences-in-a-recent-work-of-walsh/">Incidences in a Recent Work of Walsh</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Recently, Miguel Walsh posted a very interesting paper on arXiv. The main purpose of the paper is to study various properties of polynomials and varieties. These properties are related to incidence problems – some originally arose from studying incidences. Walsh also presents new incidence bounds as applications of his results. In this post I’ll briefly […]<p></p></div></div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2018/12/20/incidences-in-a-recent-work-of-walsh/"><span class="datestr">at December 20, 2018 05:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=614">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2018/12/20/50m-to-northeastern-computer-science/">$50M to Northeastern Computer Science</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: justify;"><a href="https://www.bostonglobe.com/business/2018/12/17/northeastern-receives-million-gift-further-studies/ygZaKf1F56SzNSCB818zJO/story.html">Northeastern Computer Science is receiving a $50M gift</a>.  If you are looking for a faculty position, check out our many openings, including the <a href="https://cstheory-jobs.org/2018/10/21/faculty-at-northeastern-university-apply-by-december-22-2018/">joint math-cs position</a>. Also if you are applying for a PhD take a look at our college.  In particular as I mentioned already <a href="https://emanueleviola.wordpress.com/2018/12/03/i-am-looking-for-students/">I am looking for students</a>.</p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2018/12/20/50m-to-northeastern-computer-science/"><span class="datestr">at December 20, 2018 03:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
