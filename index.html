<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="https://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="no data">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://scottaaronson.blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 14, 2022 04:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/071">TR22-071 |  Robustly Separating the Arithmetic Monotone Hierarchy Via Graph Inner-Product | 

	Utsab Ghosal, 

	Arkadev Chattopadhyay, 

	Partha Mukhopadhyay</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We establish an $\epsilon$-sensitive hierarchy separation for monotone arithmetic computations. The notion of $\epsilon$-sensitive monotone lower bounds was recently introduced by Hrubes [Computational Complexity'20]. We show the following:
   
(1) There exists a monotone polynomial over $n$ variables in VNP that cannot be computed by $2^{o(n)}$ size monotone circuits in an $\epsilon$-sensitive way as long as $\epsilon \ge 2^{-\Omega(n)}$.

(2) There exists a polynomial over $n$ variables that can be computed by polynomial size monotone circuits but cannot be computed by any monotone arithmetic branching program (ABP) of $n^{o(\log n)}$ size, even in an $\epsilon$-sensitive fashion as long as $\epsilon \ge n^{-\Omega(\log n)}$.

(3) There exists a polynomial over $n$ variables that can be computed by polynomial size monotone ABP but cannot be computed in $n^{o(\log n)}$ size by monotone formulas even in an $\epsilon$-sensitive way, when $\epsilon \ge n^{-\Omega(\log n)}$.

(4) There exists a polynomial over $n$ variables that can be computed by width-$4$  polynomial size monotone arithmetic branching programs (ABPs) but cannot be computed in $2^{o(n^{1/d})}$ size by monotone, unbounded fan-in formulas of product depth $d$ even in an $\epsilon$-sensitive way, when $\epsilon \ge 2^{-\Omega(n^{1/d})}$. This yields an $\epsilon$-sensitive separation of constant-depth monotone formulas and constant-width monotone ABPs. It seems that even an ordinary separation of the two classes was not known.   

An interesting feature of our separations is that in each case the polynomial exhibited is obtained from a graph inner-product polynomial by choosing an appropriate graph topology. The closely related graph inner-product Boolean function for expander graphs was invented by Hayes [DM &amp; TCS'11], also independently by Pitassi [2009], in the context of best-partition multiparty communication complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/071"><span class="datestr">at May 13, 2022 03:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06249">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06249">Optimal-Degree Polynomial Approximations for Exponentials and Gaussian Kernel Density Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aggarwal:Amol.html">Amol Aggarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alman:Josh.html">Josh Alman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06249">PDF</a><br /><b>Abstract: </b>For any real numbers $B \ge 1$ and $\delta \in (0, 1)$ and function $f: [0,
B] \rightarrow \mathbb{R}$, let $d_{B; \delta} (f) \in \mathbb{Z}_{&gt; 0}$ denote
the minimum degree of a polynomial $p(x)$ satisfying $\sup_{x \in [0, B]} \big|
p(x) - f(x) \big| &lt; \delta$. In this paper, we provide precise asymptotics for
$d_{B; \delta} (e^{-x})$ and $d_{B; \delta} (e^{x})$ in terms of both $B$ and
$\delta$, improving both the previously known upper bounds and lower bounds. In
particular, we show $$d_{B; \delta} (e^{-x}) = \Theta\left( \max \left\{
\sqrt{B \log(\delta^{-1})}, \frac{\log(\delta^{-1}) }{ \log(B^{-1}
\log(\delta^{-1}))} \right\}\right), \text{ and}$$ $$d_{B; \delta} (e^{x}) =
\Theta\left( \max \left\{ B, \frac{\log(\delta^{-1}) }{ \log(B^{-1}
\log(\delta^{-1}))} \right\}\right).$$
</p>
<p>Polynomial approximations for $e^{-x}$ and $e^x$ have applications to the
design of algorithms for many problems, and our degree bounds show both the
power and limitations of these algorithms.
</p>
<p>We focus in particular on the Batch Gaussian Kernel Density Estimation
problem for $n$ sample points in $\Theta(\log n)$ dimensions with error $\delta
= n^{-\Theta(1)}$. We show that the running time one can achieve depends on the
square of the diameter of the point set, $B$, with a transition at $B =
\Theta(\log n)$ mirroring the corresponding transition in $d_{B; \delta}
(e^{-x})$:
</p>
<p>- When $B=o(\log n)$, we give the first algorithm running in time $n^{1 +
o(1)}$.
</p>
<p>- When $B = \kappa \log n$ for a small constant $\kappa&gt;0$, we give an
algorithm running in time $n^{1 + O(\log \log \kappa^{-1} /\log \kappa^{-1})}$.
The $\log \log \kappa^{-1} /\log \kappa^{-1}$ term in the exponent comes from
analyzing the behavior of the leading constant in our computation of $d_{B;
\delta} (e^{-x})$.
</p>
<p>- When $B = \omega(\log n)$, we show that time $n^{2 - o(1)}$ is necessary
assuming SETH.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06249"><span class="datestr">at May 13, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06167">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06167">Line Search-Free Methods for Higher-Order Smooth Monotone Variational Inequalities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Adil:Deeksha.html">Deeksha Adil</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bullins:Brian.html">Brian Bullins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jambulapati:Arun.html">Arun Jambulapati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sachdeva:Sushant.html">Sushant Sachdeva</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06167">PDF</a><br /><b>Abstract: </b>Recent work by Jiang and Mokhtari [2022] has presented $p^{th}$-order methods
for solving higher-order smooth monotone variational inequalities which
establish a rate of $O(\epsilon^{-2/(p+1)})$. A drawback to their approach,
however, is the reliance on a line search scheme when solving a particular set
of subproblems. In this note, we provide a simple $p^{th}$-order method that
achieves the same $O(\epsilon^{-2/(p+1)})$ rate without depending on any line
search routine.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06167"><span class="datestr">at May 13, 2022 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06128">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06128">Space-Efficient Graph Coarsening with Applications to Succinct Planar Encodings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kammer:Frank.html">Frank Kammer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meintrup:Johannes.html">Johannes Meintrup</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06128">PDF</a><br /><b>Abstract: </b>We present a novel space-efficient graph coarsening technique for n-vertex
separable graphs G, in particular for planar graphs, called cloud partition,
which partitions the vertices V(G) into disjoint sets C of size O(log n) such
that each C induces a connected subgraph of G. Using this partition P we
construct a so-called structure-maintaining minor F of G via specific
contractions within the disjoint sets such that F has O(n/log n) vertices. The
combination of (F, P) is referred to as a cloud decomposition. We call a graph
G=(V, E) separable if it admits to an O(n^c)-separator theorem for some
constant c &lt; 1 meaning there exists a separator S subset V that partitions V
into {A, S, B} such that no vertices of A and B are adjacent in G and neither A
nor B contain more than c'n vertices for a fixed constant c' &lt; 1. Due to the
last property such separators are called balanced. This famously includes
planar graphs, which admit an O(sqrt(n) n)-separator theorem. For planar graphs
we show that a cloud decomposition can be constructed in O(n) time and using
O(n) bits. Given a cloud decomposition (F, P) constructed for a planar graph G
we are able to find a balanced separator of G in O(n/log n) time. Contrary to
related publications, we do not make use of an embedding of the input graph.
This allows us to construct the succinct encoding scheme for planar graphs due
to Blelloch and Farzan (CPM 2010) in O(n) time and O(n) bits improving both
runtime and space by a factor of Theta(log n). As an additional application of
our cloud decomposition we show that a tree decomposition for planar graphs of
width O(n^(1/2 + epsilon)) for any epsilon &gt; 0 can be constructed in O(n) bits
and a time linear in the size of the tree decomposition. Finally, we generalize
our cloud decomposition from planar graphs to arbitrary separable graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06128"><span class="datestr">at May 13, 2022 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06099">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06099">Faster quantum mixing of Markov chains in non-regular graph with fewer qubits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Xinyin Li, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shang:Yun.html">Yun Shang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06099">PDF</a><br /><b>Abstract: </b>Sampling from the stationary distribution is one of the fundamental tasks of
Markov chain-based algorithms and has important applications in machine
learning, combinatorial optimization and network science. For the quantum case,
qsampling from Markov chains can be constructed as preparing quantum states
with amplitudes arbitrarily close to the square root of a stationary
distribution instead of classical sampling from a stationary distribution. In
this paper, a new qsampling algorithm for all reversible Markov chains is
constructed by discrete-time quantum walks and works without any limit compared
with existing results. In detail, we build a qsampling algorithm that not only
accelerates non-regular graphs but also keeps the speed-up of existing quantum
algorithms for regular graphs. In non-regular graphs, the invocation of the
quantum fast-forward algorithm accelerates existing state-of-the-art qsampling
algorithms for both discrete-time and continuous-time cases, especially on
sparse graphs. Compared to existing algorithms we reduce log n, where n is the
number of graph vertices. In regular graphs, our result matches other quantum
algorithms, and our reliance on the gap of Markov chains achieves quadratic
speedup compared with classical cases. For both cases, we reduce the number of
ancilla qubits required compared to the existing results. In some widely used
graphs and a series of sparse graphs where stationary distributions are
difficult to reach quickly, our algorithm is the first algorithm to achieve
complete quadratic acceleration (without log factor) over the classical case
without any limit. To enlarge success probability amplitude amplification is
introduced. We construct a new reflection on stationary state with fewer
ancilla qubits and think it may have independent application.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06099"><span class="datestr">at May 13, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06097">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06097">Viable Algorithmic Options for Creating and Adapting Emergent Software Systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wareham:Todd.html">Todd Wareham</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haan:Ronald_de.html">Ronald de Haan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06097">PDF</a><br /><b>Abstract: </b>Given the complexity of modern software systems, it is of great importance
that such systems be able to autonomously modify themselves, i.e., self-adapt,
with minimal human supervision. It is critical that this adaptation both
results in reliable systems and scales reasonably in required memory and
runtime to non-trivial systems. In this paper, we apply computational
complexity analysis to evaluate algorithmic options for the reliable creation
and adaptation of emergent software systems relative to several popular types
of exact and approximate efficient solvability. We show that neither problem is
solvable for all inputs when no restrictions are placed on software system
structure. This intractability continues to hold relative to all examined types
of efficient exact and approximate solvability when software systems are
restricted to run (and hence can be verified against system requirements) in
polynomial time. Moreover, both of our problems when so restricted remain
intractable under a variety of additional restrictions on software system
structure, both individually and in many combinations. That being said, we also
give sets of additional restrictions that do yield tractability for both
problems, as well as circumstantial evidence that emergent software system
adaptation is computationally easier than emergent software system creation.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06097"><span class="datestr">at May 13, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06069">Sequential algorithms for testing identity and closeness of distributions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fawzi:Omar.html">Omar Fawzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Flammarion:Nicolas.html">Nicolas Flammarion</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garivier:Aur=eacute=lien.html">Aurélien Garivier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oufkir:Aadil.html">Aadil Oufkir</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06069">PDF</a><br /><b>Abstract: </b>What advantage do \emph{sequential} procedures provide over batch algorithms
for testing properties of unknown distributions? Focusing on the problem of
testing whether two distributions $\mathcal{D}_1$ and $\mathcal{D}_2$ on
$\{1,\dots, n\}$ are equal or $\epsilon$-far, we give several answers to this
question. We show that for a small alphabet size $n$, there is a sequential
algorithm that outperforms any batch algorithm by a factor of at least $4$ in
terms sample complexity. For a general alphabet size $n$, we give a sequential
algorithm that uses no more samples than its batch counterpart, and possibly
fewer if the actual distance $TV(\mathcal{D}_1, \mathcal{D}_2)$ between
$\mathcal{D}_1$ and $\mathcal{D}_2$ is larger than $\epsilon$. As a corollary,
letting $\epsilon$ go to $0$, we obtain a sequential algorithm for testing
closeness when no a priori bound on $TV(\mathcal{D}_1, \mathcal{D}_2)$ is given
that has a sample complexity
$\tilde{\mathcal{O}}(\frac{n^{2/3}}{TV(\mathcal{D}_1, \mathcal{D}_2)^{4/3}})$:
this improves over the $\tilde{\mathcal{O}}(\frac{n/\log n}{TV(\mathcal{D}_1,
\mathcal{D}_2)^{2} })$ tester of \cite{daskalakis2017optimal} and is optimal up
to multiplicative constants. We also establish limitations of sequential
algorithms for the problem of testing identity and closeness: they can improve
the worst case number of samples by at most a constant factor.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06069"><span class="datestr">at May 13, 2022 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.06042">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.06042">An improved KTNS algorithm for the job sequencing and tool switching problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Mikhail Cherniavskii, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldengorin:Boris.html">Boris Goldengorin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.06042">PDF</a><br /><b>Abstract: </b>We outline a new Max Pipe Construction Algorithm (MPCA) with the purpose to
reduce the CPU time for the classic Keep Tool Needed Soonest (KTNS) algorithm.
The KTNS algorithm is applied to compute the objective function value for the
given sequence of jobs in all exact and approximating algorithms for solving
the Job Sequencing and Tool Switching Problem (SSP). Our MPCA outperforms the
KTNS algorithm by at least an order of magnitude in terms of CPU times. Since
all exact and heuristic algorithms for solving the SSP spend most of their CPU
time on applying the KTNS algorithm we show that our MPCA solves the entire SSP
on average 59 times faster for benchmark instances of D compared to current
state of the art heuristics.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.06042"><span class="datestr">at May 13, 2022 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.05887">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.05887">Bottleneck Matching in the Plane</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katz:Matthew_J=.html">Matthew J. Katz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharir:Micha.html">Micha Sharir</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.05887">PDF</a><br /><b>Abstract: </b>We present an algorithm for computing a bottleneck matching in a set of
$n=2\ell$ points in the plane, which runs in $O(n^{\omega/2}\log n)$
deterministic time, where $\omega\approx 2.37$ is the exponent of matrix
multiplication.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.05887"><span class="datestr">at May 13, 2022 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.05795">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.05795">Algebraic Machine Learning with an Application to Chemistry</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sai:Ezzeddine_El.html">Ezzeddine El Sai</a>, Parker Gara, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pflaum:Markus_J=.html">Markus J. Pflaum</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.05795">PDF</a><br /><b>Abstract: </b>As data used in scientific application become more complex, studying their
geometry and topology has become an increasingly prevalent part of the data
analysis process. This can be seen for example with the growing interest in
topological tools such as persistent homology. However, on the one hand,
topological tools are inherently limited to providing only coarse information
about the underlying space of the data. On the other hand, more geometric
approaches rely predominately on the manifold hypothesis, which asserts that
the underlying space is a smooth manifold. This assumption fails for many
physical models where the underlying space contains singularities.
</p>
<p>In this paper we develop a machine learning pipeline that captures fine-grain
geometric information without having to rely on any smoothness assumptions. Our
approach involves working within the scope of algebraic geometry and algebraic
varieties instead of differential geometry and smooth manifolds. In the setting
of the variety hypothesis, the learning problem becomes to find the underlying
variety using sample data. We cast this learning problem into a Maximum A
Posteriori optimization problem which we solve in terms of an eigenvalue
computation. Having found the underlying variety, we explore the use of
Gr\"obner bases and numerical methods to reveal information about its geometry.
In particular, we propose a heuristic for numerically detecting points lying
near the singular locus of the underlying variety.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.05795"><span class="datestr">at May 13, 2022 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.05782">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.05782">On the Complexity of Determining Whether there is a Unique Hamiltonian Cycle or Path</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hudry:Olivier.html">Olivier Hudry</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lobstein:Antoine.html">Antoine Lobstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.05782">PDF</a><br /><b>Abstract: </b>The decision problems of the existence of a Hamiltonian cycle or of a
Hamiltonian path in a given graph, and of the existence of a truth assignment
satisfying a given Boolean formula $C$, are well-known {\it NP}-complete
problems. Here we study the problems of the {\it uniqueness} of a Hamiltonian
cycle or path in an undirected, directed or oriented graph, and show that they
have the same complexity, up to polynomials, as the problem U-SAT of the
uniqueness of an assignment satisfying $C$. As a consequence, these Hamiltonian
problems are {\it NP}-hard and belong to the class~{\it DP}, like U-SAT.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.05782"><span class="datestr">at May 13, 2022 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.05760">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.05760">Co-generation of Collision-Free Shapes for Arbitrary One-Parametric Motion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Clinton B. Morris, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behandish:Morad.html">Morad Behandish</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.05760">PDF</a><br /><b>Abstract: </b>Mechanical assemblies can exhibit complex relative motions, during which
collisions between moving parts and their surroundings must be avoided. To
define feasible design spaces for each part's shape, "maximal" collision-free
pointsets can be computed using configuration space modeling techniques such as
Minkowski operations and sweep/unsweep. For example, for a pair of parts
undergoing a given relative motion, to make the problem well-posed, the
geometry of one part (chosen arbitrarily) must be fixed to compute the maximal
shape of the other part by an unsweep operation. Making such arbitrary choices
in a multi-component assembly can place unnecessary restrictions on the design
space. A broader family of collision-free pairs of parts can be explored, if
fixing the geometry of a component is not required. In this paper, we formalize
this family of collision-free shapes and introduce a generic method for
generating a broad subset of them. Our procedure, which is an extension of the
unsweep, allows for co-generation of a pair of geometries which are modified
incrementally and simultaneously to avoid collision. We demonstrate the
effectiveness and scalability of our procedure in both 2D and 3D by generating
a variety of collision-free shapes. Notably, we show that our approach can
automatically generate freeform cam and follower profiles, gear teeth, and
screw threads, starting from colliding blocks of materials, solely from a
specification of relative motion and without the use of any feature-informed
heuristics. Moreover, our approach provides continuous measures of collision
that can be incorporated into standard gradient-descent design optimization,
allowing for simultaneous collision-free and physics-informed co-design of
mechanical parts for assembly.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.05760"><span class="datestr">at May 13, 2022 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2205.05713">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2205.05713">Concise tensors of minimal border rank</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jelisiejew:Joachim.html">Joachim Jelisiejew</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Landsberg:J=_M=.html">J. M. Landsberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Arpan.html">Arpan Pal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2205.05713">PDF</a><br /><b>Abstract: </b>We determine defining equations for the set of concise tensors of minimal
border rank in $C^m\otimes C^m\otimes C^m$ when $m=5$ and the set of concise
minimal border rank $1_*$-generic tensors when $m=5,6$. We solve this classical
problem in algebraic complexity theory with the aid of two recent developments:
the 111-equations defined by Buczy\'{n}ska-Buczy\'{n}ski and results of
Jelisiejew-\v{S}ivic on the variety of commuting matrices. We introduce a new
algebraic invariant of a concise tensor, its 111-algebra, and exploit it to
give a strengthening of Friedland's normal form for $1$-degenerate tensors
satisfying Strassen's equations. We use the 111-algebra to characterize wild
minimal border rank tensors and classify them in $C^5\otimes C^5\otimes C^5$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2205.05713"><span class="datestr">at May 13, 2022 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8329">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2022/05/12/workshop-on-local-algorithm-22-guest-post-by-clement-canonne/">Workshop on Local Algorithm 22: Guest post by Clément Canonne</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>After two years online, the <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f50e.png" style="height: 1em;" class="wp-smiley" alt="🔎" /> <strong>Workshop on Local Algorithms (WOLA)</strong> is back in person, and will be held in Warsaw from June 25th to June 27th. Come and discuss local algorithms of all kinds — sublinear-time, distributed, streaming, (massively) parallel, as well as graphical models and much more; and exchange ideas, techniques, and insights with others from various research communities.</p>



<p>The workshop will feature talks from a range of exciting speakers, social events, poster sessions, and local (!) outings: to stay up to date on the schedule, and register, please head to <a href="https://ideas-ncbr.pl/en/wola/" target="_blank" rel="noreferrer noopener">https://ideas-ncbr.pl/en/wola/</a></p>



<p>Looking forward to seeing you at WOLA!</p>



<p>PS: online attendance is also possible, for those who cannot attend in person. Streaming, after all, is on-topic <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2022/05/12/workshop-on-local-algorithm-22-guest-post-by-clement-canonne/"><span class="datestr">at May 12, 2022 02:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=622">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2022/05/12/tcs-talk-wednesday-may-18-thatchaphol-saranurak-university-of-michigan/">TCS+ talk: Wednesday, May 18 — Thatchaphol Saranurak, University of Michigan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, May 18th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://sites.google.com/site/thsaranurak/"><strong>Thatchaphol Saranurak</strong></a> from University of Michigan will speak about “<em>All-pairs minimum cuts in nearly quadratic time: a tutorial </em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We recently showed an algorithm for computing all-pairs minimum cuts (or, more precisely, the Gomory-Hu tree) in ~O(n^2) time in weighted graphs and even almost-linear time in unweighted graphs. For weighted graphs, this is the first improvement over the 60-year-old algorithm by Gomory and Hu. Thus, surprisingly, computing all-pairs minimum cuts seems to be strictly easier than computing all-pairs shortest paths, which is conjectured to require n^{3-o(1)} time.</p>
<p>I will give a tutorial on the techniques behind our new result, one of which is called “isolating cuts”. Then, I will survey recent progress in fast minimum cut algorithms and discuss open problems.</p>
<p>Joint work with Amir Abboud, Robert Krauthgamer, Jason Li, Debmalya Panigrahi, and Ohad Trabelsi.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2022/05/12/tcs-talk-wednesday-may-18-thatchaphol-saranurak-university-of-michigan/"><span class="datestr">at May 12, 2022 07:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=20001">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/">Differential Privacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<i>I’m low-key. I like my privacy—Kemba Walker.</i></p>
<p>
Avrim Blum, Irit Dinur, Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith, received the ACM 2021 Paris Kanellakis Theory and Practice <a href="https://awards.acm.org/kanellakis">Award</a>. They worked on and studied the notion of <a href="https://privacytools.seas.harvard.edu/differential-privacy">differential privacy</a>.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/all-12/" rel="attachment wp-att-20004"><img width="600" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/all.png?resize=600%2C338&amp;ssl=1" class="aligncenter size-full wp-image-20004" height="338" /></a></p>
<p><b> Privacy </b></p>
<p></p><p>
One of the key advances of modern cryptography is its ability to define new types of security. One can be pretty naive in defining simple notions of security. For example, it is not too hard to get correct the notion: Given the encrypted message <img src="https://s0.wp.com/latex.php?latex=%7BE_K%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{E_K(M)}" class="latex" /> one cannot easily determine <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{M}" class="latex" /> without knowing the key <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K}" class="latex" />. However, things are much more complex when we wish to define more complex notions. </p>
<p>
This happens with notions of privacy. Differential privacy is a framework for reasoning about statistical databases. Imagine you have two otherwise identical databases, one with your personal information in it, and one without it. Differential Privacy ensures that the probability that a statistical query will produce a given result is (nearly) the same whether it’s conducted on the first or second database. </p>
<p>
Perhaps a concrete question will help: <i>How can we use data to learn about a population, without learning about specific individuals within the population?</i> Consider these two questions: </p>
<ol>
<li> “How many people live in Vermont?”
</li><li> “How many people named Joe Smith live in Vermont?”
</li></ol>
<p>
The first reveals a property of the whole population, while the second reveals information about one person. We need to be able to learn about trends in the population while preventing the ability to learn anything new about a particular individual. This is the goal of many statistical analyses of data, such as the statistics published by the U.S. Census Bureau. This is what differential privacy is all about. </p>
<p>
</p><p><b> The Award </b></p>
<p></p><p>
From the award citation:</p>
<p>
<em><br />
Differential privacy is a definition and framework for reasoning about privacy in statistical databases. While the privacy of individuals contributing to a dataset has been a long-standing concern, prior to the Kanellakis recipients’ work, computer scientists only knew how to mitigate several specific privacy attacks via a disparate set of techniques. The foundation for differential privacy emerged in the early 2000’s from several key papers. At the ACM Symposium on the Principles of Database Systems (PODS 2003) Dinur and Nissim presented a paper which showed that any technique that allows reasonably accurate answers to a large number of queries is inherently non-private.</em></p><em>
</em><p><em>
Later, a sequence of papers by Dwork and Nissim at the International Conference on Cryptology (Crypto 2004); as well as Blum, Dwork, McSherry, and Nissim at the ACM Symposium on the Principles of Database Systems (PODS 2005); and Dwork, McSherry, Nissim, and Smith at the Theory of Cryptology Conference (TCC 2006) further defined and studied the notion of differential privacy.</em> </p>
<p>
Look at <a href="https://towardsdatascience.com/understanding-differential-privacy-85ce191e198a">the article</a> for more discussion of what it is all about. </p>
<p>
</p><p><b> Open Problems </b></p>
<p></p><p>
We wish Avrim, Irit, Cynthia, Frank, Kobbi, and Adam congrats on their well deserved award. </p>
<p></p></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/"><span class="datestr">at May 11, 2022 08:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5898963605660384340">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html">Queen Elizabeth is the 3rd longest reigning monarch; The problem with definitions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> A few days ago Queen Elizabeth passed Johann II of Liechtenstein to be the third longest reigning monarch (see <a href="https://en.wikipedia.org/wiki/List_of_longest-reigning_monarchs">here</a>). </p><p>A summary of the top 4:</p><p><br /></p><p>4) Johann II, Liechtenstein ruled from Nov 12 1858 until his death on Feb 11, 1929. When he became King he was 18. He was king for 70 years, 91 days. </p><p>3) Queen Elizabeth II (thats a two, not an eleven) ruled from Feb 2, 1952 until now. When she became Queen she was  25. I am writing this on May 10 at which time she ruled 70 years, 94 days. </p><p>2) Bhumibol Adulyadej (Thailand) ruled from June 9, 1946 until Oct 13, 2016. When he became King he was 19. He was king for 70 years, 126 days. </p><p>1) Louis XIV ruled from May 14, 1643 until Sept 1, 1715. When he became King he was 4 years and 8 months. He was king for 72 years, 110 days. </p><p><br /></p><p>Johann, Elizabeth, and Bhumibol started their reigns a bit young (they would have to to have ruled so long) but their first day of their reign they knew what the job was, what they are supposed to do etc. </p><p>Here is my complaint: Louis XIV being king at the age of 4 years 8 months should not count (someone who proofread this post wondered if 4 years 9 months would count. No.) Shouldn't we define the reign of a king as the point at which he can make real decisions as king? Or something like that. </p><p>For the record of the longest marriage there is a similar problem. The three longest marriages are legit in that the people got married at a reasonable age (I think all were married after they were 17). The fourth longest marriage of all time involved two people that were married when they were 5. That should not count (see <a href="https://en.wikipedia.org/wiki/List_of_long_marriages">here</a>).</p><p>Is there a way to define monarch's reigns and also marriage length so that it corresponds to our intuitions? </p><p>In Math we can use rigorous definitions but in English its harder. </p><p><br /></p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html"><span class="datestr">at May 11, 2022 03:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://gradientscience.org/datamodels-2/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/madry.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://gradientscience.org/datamodels-2/">Uncovering Brittleness with Datamodels</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a style="float: left; width: 45%;" href="https://arxiv.org/abs/2202.00622" class="bbutton">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a style="float: left; width: 45%;" href="https://github.com/MadryLab/datamodels-data" class="bbutton">
<i class="fab fa-github"></i>
   Data
</a>
<br /></p>

<p>In this blog post we use datamodels to identify and study a new form of model <em>brittleness.</em></p>

<h2 id="recap-datamodels">Recap: Datamodels</h2>

<p>In our <a href="https://gradientscience.org/datamodels-1/">last post</a>, we introduced datamodels: a framework for studying how models use training data to make predictions. While we summarize datamodels in short below, if you haven’t yet read about datamodels we recommend reading our <a href="https://gradientscience.org/datamodels-1/">last post</a> for the full picture.</p>

<p>Consider a training set $S$ (e.g., a set of images and labels from a computer vision dataset), a learning algorithm $\mathcal{A}$ (e.g., training a deep neural network from scratch with SGD), and a target example $x$ (e.g., a test image and label from the same dataset). A <em>datamodel</em> for the target example $x$ is a parameterized function that takes as input a subset $S’$ of the original training set $S$, and predicts the outcome of training a model on $S’$ (using $\mathcal{A}$) and evaluating on $x$. In other words, a datamodel predicts how the choice of a specific training subset changes the final model prediction.</p>

<p><img src="https://gradientscience.org/images/datamodels/datamodel_blogpost_figures.001.png" alt="A graphic showing a test image and a training set. Some of the training images are greyed out to indicate a subset S-prime of the training set. There is an arrow from the training set to a question asking, &quot;if i train a model on examples # 1, 3, 5, etc., how will the model behave on the given target example?&quot; This question is fed to the datamodel, which returns an estimate of what the output (e.g. loss) of a model trained on S-prime and evaluated on x would be." /></p>

<p>Our <a href="https://gradientscience.org/datamodels-1/">last post</a> focused on constructing <em>linear</em> datamodels (one for each CIFAR-10 test image) that accurately predict the outcome of training a deep neural network from scratch on subsets of the CIFAR-10 training set.</p>

<p>Today, we’ll use datamodels to investigate deep neural networks’ predictions. Specifically, we’ll introduce and measure <em>data-level brittleness</em>: how sensitive are model predictions to removing a small number of training set points?</p>

<h2 id="data-level-brittleness-a-motivating-example">Data-level brittleness: a motivating example</h2>

<p>Consider this image of a boat from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>

<p><img width="120px" alt="An image of a boat from the CIFAR-10 test set" src="https://gradientscience.org/images/datamodels/Untitled.png" /></p>

<p>A deep neural network (ResNet-9) trained on CIFAR-10 correctly classifies this example as a boat with <strong>71%</strong> (softmax) confidence. The classification is also “robust” in the sense that over different training runs (each with a different random initialization of the network, batch ordering, data augmentation, etc.), the trained model classifies this example correctly <strong>84%</strong> of the time.</p>

<p>It turns out, however, that if we remove just the following nine images from the CIFAR-10 training set…</p>

<p><img src="https://gradientscience.org/images/datamodels/datamodel_blogpost_figures.001%201.png" alt="Nine images from the CIFAR-10 training set that, when removed, induce misclassification of the boat example above." /></p>

<p>…models trained with the exact same training procedure (applied to the remaining 49,991 images in the training set) correctly classify the boat only <strong>35%</strong> of the time! Furthermore, when we remove only 11 additional training images, the probability of correct classification decreases to merely <strong>10%</strong> (the accuracy of a <em>random</em> classifier!).</p>

<p>Model behavior on this boat image exemplifies <em>data-level brittleness.</em> Models confidently and consistently output correct predictions, but these predictions hinge on a very small set of training examples. (One might hypothesize that in this case, brittleness stems from the fact that there are very few training examples of boats on land or grass.)</p>

<h2 id="quantifying-brittleness-with-datamodels">Quantifying brittleness with datamodels</h2>

<p>How do we actually measure data-level brittleness? In the example above, models misclassified the boat after we removed nine images. These were nine <em>specifically chosen</em> images, however: removing nine <em>randomly chosen</em> training images of boats does not at all degrade models’ probability of correctly classifying the boat image. Even removing the nine most <em>similar</em> training examples to the boat image (e.g., in terms of representation space distance) degrades this probability by only 4%.</p>

<p>So, how do we find the “right” images to remove? Specifically, what we’re looking for is the smallest subset of the training set whose removal induces misclassification on average, i.e.,</p>

<p>\begin{align}
\tag{1}
\label{eq:origobj}
\min_{R \subset S} |R’|, \text{ such that }\mathbb{E}[\text{margin of a model
trained on } S \setminus R \text{ on } x] \leq 0.
\end{align}</p>

<p>Unfortunately, problems like this (optimizing a black-box function over the space of all possible subsets of a large set) are computationally challenging to solve. In the worst case, to find the smallest set satisfying the above condition we would have to train several models for each possible training subset.</p>

<p>This is where datamodels come in. Recall that for a target example $x$ (e.g., our  boat example from before), we can construct (read our <a href="https://gradientscience.org/datamodels-1/">previous post</a> to see how) a <em>datamodel</em> $g$ that, for any subset of the training set $S’$, returns an estimate:</p>

<p>\begin{align}
g(S’) \approx \mathbb{E}[\text{margin of a classifier trained on $S’$ when
evaluated on $x$}].
\end{align}</p>

<p>(Here, the expectation is taken over training non-determinism.) Datamodel estimates can be highly accurate. For example, see the following graph of predicted average margin $g(S’)$ against true average margin (the RHS above) from our last post:</p>

<p><img src="https://gradientscience.org/images/datamodels/Untitled%201.png" alt="A graph comparing true and datamodel-predicted outcomes of model training." /></p>

<p>Datamodel predictiveness means we can (approximately) solve our earlier optimization problem (\eqref{eq:origobj}) by optimizing instead the <em>surrogate objective</em>:</p>

<p>\begin{align}
\tag{2}
\label{eq:surrogate1}
\min_{R \subset S} \vert R \vert \text{ such that } g(S \backslash R) \leq 0
\end{align}</p>

<p>Since $g(\cdot)$ is a simple (linear) function (see the drop-down below for more details), this new optimization problem is computationally easy to solve (and doesn’t involve training additional models).</p>

<section class="container">
<div>
<div class="checkboxdiv">
<input type="checkbox" id="ac-1" name="accordion-1" />
<label for="ac-1"><span class="fas fa-chevron-right" id="titlespan"></span><strong> Why is it easy to solve?</strong> (Click to expand)</label>
<article class="small">
In our last post, we showed that for deep neural networks, datamodels that are linear with respect to the <em>presence</em> of each training image can suffice to accurately predict model behavior. In the linear datamodel regime, we parameterize our datamodel $g(\cdot)$ for a target example $x$ with a weight vector $w \in \mathbb{R}^{50,000}$ (where $50,000$ is the size of the training set), and the datamodel prediction $g(S’)$ is precisely:
    
\begin{align}
    g(S’) = \mathbf{1}_{S’}^\top w,
\end{align}

where $\mathbf{1}_{S'}$ is a 50,000-dimensional indicator vector of $S'$ (i.e., taking on a value of one at index $i$ if the $i$-th training image is in $S'$, and zero otherwise).

Here, solving the optimization problem \(\eqref{eq:surrogate1}\) corresponds to choosing $R$ as the training images that correspond to the largest indices of $w_i$.
</article>
</div>
</div>
</section>
<p><br /></p>

<p>After finding a subset $R$ that minimizes the surrogate objective above, we can verify that $R$ is an upper bound on the objective above by training a collection of models on the remaining training images $S \setminus R$, and checking to see that the target example is misclassified on average. We can <em>ensure</em> we actually get an upper bound on the size of the minimum $R$ by solving</p>

<p>\begin{align}
\min_{R \subset S} \vert R \vert \text{ such that } g(S \setminus R) \leq C,
\end{align}</p>

<p>where $C&lt;0$ is a threshold that we (very coarsely) search for using the verification procedure—if the image isn’t misclassified on average, we can decrease $C$.</p>

<h2 id="looking-at-brittleness-in-aggregate">Looking at brittleness in aggregate</h2>

<p>So far in this post, we’ve seen an example of data-level brittleness, and provided a datamodel-based method for estimating the brittleness of any given prediction. How brittle are model predictions as a whole?</p>

<p>We use our datamodel-based approach to estimate the data-level brittleness of each image in (a random sample of) the CIFAR-10 test set. Specifically, for each test image, we estimate (and bound) the number of training images one would need to remove in order to flip models’ predictions on the test image. We plot the <em>cumulative distribution</em> of these estimates below: a point $(x, y)$ on the blue line below indicates that a $y$ fraction of test set predictions are brittle to the removal of at most $x$ training images.</p>

<p><img src="https://gradientscience.org/images/datamodels/cifar_brittleness_combined_withflips_False.svg" alt="CDF of data-level brittleness" /></p>

<p>It turns out that our motivating boat example is not so unusual. In fact, for around 20% of the CIFAR-10 test images it suffices to remove fewer than 60 training images to induce misclassification! Also, for around half of the test examples, it suffices to remove fewer than 250 training images (still only 0.5% of the training set).</p>

<p>The other lines in the graph above illustrate just how hard it is to identify prediction brittleness via other means. Each one represents a different heuristic: a point $(x, y)$ on the line indicates that for a $y$-fraction of the test set, removing the $x$ most similar images to the target example (according to the corresponding heuristic) is necessary to flip models’ predictions. (See Appendix F.2 in our <a href="https://arxiv.org/abs/2202.00622">paper</a> for more details on these baselines!)</p>

<h2 id="bonus-label-flipping-attacks">Bonus: Label-flipping attacks</h2>

<p>One immediate consequence of the techniques we discovered in this blog post is the existence of strong <em>label-flipping</em> attacks. So far, we’ve looked exclusively at the result of removing training images—if we use the exact same technique but instead just flip the labels of the images we would have removed, we find more severe brittleness:</p>

<p><img src="https://gradientscience.org/images/datamodels/cifar_brittleness_combined_withflips_True_True.svg" alt="flipping.png" /></p>

<p>The dashed line above is the same as the blue line from earlier—the new solid blue line shows that for over half of the CIFAR-10 test images, we are able to induce misclassification by relabeling just 35 (target-specific) images!</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we introduced a new notion of model brittleness, examined how to quantify it with datamodels, and demonstrated that a large fraction of predictions on the CIFAR-10 test set are quite brittle.</p>

<p>Our results demonstrate one of many ways in which datamodels can be a useful proxy for end-to-end training. More broadly (and as we’ll see in our upcoming posts!), datamodels open the door to many other fine-grained analyses of model predictions.</p></div>







<p class="date">
<a href="https://gradientscience.org/datamodels-2/"><span class="datestr">at May 11, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/05/10/postdoc-in-tcs-and-or-combinatorial-optimization-at-university-of-copenhagen-apply-by-june-29-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/05/10/postdoc-in-tcs-and-or-combinatorial-optimization-at-university-of-copenhagen-apply-by-june-29-2022/">Postdoc in TCS and/or combinatorial optimization at University of Copenhagen (apply by June 29, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS and/or combinatorial optimization. The application deadline is June 29. See <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-220629.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-220629.html</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=156468">https://employment.ku.dk/faculty/?show=156468</a><br />
Email: jn@di.ku.dk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/05/10/postdoc-in-tcs-and-or-combinatorial-optimization-at-university-of-copenhagen-apply-by-june-29-2022/"><span class="datestr">at May 10, 2022 10:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/">IDEAL Workshop on Algorithms for Massive Data Sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
May 13, 2022 Northwestern University and Zoom https://www.ideal.northwestern.edu/events/massive-data-sets/ We are inviting you to attend the IDEAL Workshop on Algorithms for Massive Data Sets. The workshop will take place at Northwestern University on Friday, May 13. It will be in a hybrid format. If you are interested in participating in the workshop (in-person or remotely), please … <a href="https://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/" class="more-link">Continue reading <span class="screen-reader-text">IDEAL Workshop on Algorithms for Massive Data Sets</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/"><span class="datestr">at May 10, 2022 04:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19987">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/05/10/peters-face/">Peter’s Face</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<i>Mathematics is not about numbers, equations, computations, or algorithms: it is about understanding—Bill Thurston.</i></p>
<p>
Peter Weinberger is a computer scientist who is famous for many things—including his <a href="http://spinroot.com/pico/pjw.html">face</a>. His name “Peter” alone stands for “rock or stone”. He did great work at Bell Labs, where he was part of the team that created the <a href="https://en.wikipedia.org/wiki/AWK">AWK</a> Programming Language: the others were Alfred Aho and Brian Kernighan. </p>
<p>
I just saw him, after a few years, at Bob <a href="https://wordpress.com/read/feeds/115529253/posts/3992043808">Sedgewick’s</a> retirement event in Princeton. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/05/10/peters-face/pw/" rel="attachment wp-att-19990"><img width="252" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/pw.jpg?resize=252%2C300&amp;ssl=1" class="aligncenter size-medium wp-image-19990" height="300" /></a></p>
<p>
</p><p><b> His Face </b></p>
<p></p><p>
Peter’s face comes up in Bell Lab’s lure:  For some reason, the <a href="http://spinroot.com/pico/pjw.html">portrait</a> of Peter Weinberger has always been our most popular target for picture editing experiments. It started a few years ago when Peter was raised to the rank of department head and was careless enough to leave a portrait of himself floating around. On a goofy Saturday evening at the lab, Rob Pike and I started making photocopies and, to emphasize Peter’s rise in the managerial hierarchy, prepared a chart of the Bell Labs Cabinet with his picture stuck in every available slot. Peter must have realized that the best he could do was not to react at all, if at least he wanted to avoid seeing his face 10 feet high on a watertower. Nevertheless, Peter’s picture appeared and reappeared in the most unlikely places in the lab. </p>
<p>
</p><p><b> Experiments </b></p>
<p></p><p>
Peter’s research over the years has been, I believe, an interesting mixture of theory and practice. Early on he did experimental work in deep number theory. For example his paper with Daniel Shanks <a href="http://matwbn.icm.edu.pl/ksiazki/aa/aa21/aa21139.pdf">refuted</a> an open conjecture. This work is an interesting blend of computations and theory. One of the surprises of deep number theory is that shocks abound in the fine structure of number fields. This structure is not always straightforward and often depends on examples and counterexamples. </p>
<p>
</p><p><b> Crypto </b></p>
<p></p><p>
Peter also worked with the US government in classified ways. He is part of <a href="https://en.wikipedia.org/wiki/JASON_(advisory_group)">Jason’s</a> group. For example you can see some of his work on the evaluation of research directions: </p>
<ol>
<li> <a href="https://irp.fas.org/agency/dod/jason/dna.pdf">DNA</a>: one of my favorite.
</li><li> <a href="https://irp.fas.org/agency/dod/jason/qc.pdf">Quantum</a>.
</li><li> <a href="https://irp.fas.org/agency/dod/jason/medimag.pdf">Medical Imaging</a>.
</li></ol>
<p>
Other parts of it are classified and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\dots}" class="latex" /></p>
<p>
</p><p><b> Renaissance and Google </b></p>
<p></p><p>
Renaissance Technologies is an American hedge fund based on Long Island. The firm is regarded as the most successful hedge fund in the world. Weinberger was the chief technology officer at Renaissance until he left for Google in 2003. This exit made sense since Peter seems to love problems in infrastructure and security. Working to solve infrastructure problems at the global scale at Google was clearly a compelling opportunity for him. </p>
<p>
Below is an excerpt from a <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1514393">talk</a> with Peter and Laurianne Mclaughlin:</p>
<div style="width: 250px;" class="wp-caption aligncenter" id="attachment_19992"><a href="https://rjlipton.wpcomstaging.com/2022/05/10/peters-face/peter-weinberger/" rel="attachment wp-att-19992"><img width="240" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/pw2.jpg?resize=240%2C300&amp;ssl=1" class="size-medium wp-image-19992" height="300" /></a><p class="wp-caption-text" id="caption-attachment-19992">Peter Weinberger, New York City, 2015</p></div>
<p>
<b>Weinberger</b>: I’m a software engineer. I write programs, infrastructure stuff mostly. I’m working on tools for processing various kinds of logs created by internal software. I’m not working on security directly, but a lot of what we do is affected by security and privacy concerns. As a result of the Sarbanes-Oxley Act, most companies now create a lot of logs to verify what code they’re running, and [show] how people work with internal data.</p>
<p>
Also, I spend a lot of time reading code. At Google, you can’t check in code without it being reviewed and approved by a peer, so if you work with productive people, there’s a lot of code to review.</p>
<p>
<b>LM</b>: What are the biggest technology challenges for Google today?</p>
<p>
<b>Weinberger</b>: Scale is the problem. Our business grows rapidly. That means every year, a lot of the technology decisions made a year ago don’t look so good any more. Exponential growth is a very pleasant problem but requires a lot of work.</p>
<p>
<b>LM</b>: What are your technology pet peeves?</p>
<p>
<b>Weinberger</b>: I’m sure I’ve got dozens. Password management. Sometimes people, like auditors, think users should regularly change passwords. I think this just encourages people to use crummy passwords—because either they have to write the passwords down, or they need a sequence of passwords that are very similar.</p>
<p>
One of my other pet peeves here is curious error messages. A lot of them are still awful. They start with the word “abort” but the program continues. We have a lot of legacy software, and you end up with these situations where an error message pops up, but the computer keeps on going. Deep in the software something went wrong, and reports it, but you’re seven levels of abstraction away, and it’s just useless noise.</p>
<p>
</p><p><b> Open Problems </b></p>
<p></p><p>
Peter is still working on his problems. We wish him well on solving them and on all he is doing.</p></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2022/05/10/peters-face/"><span class="datestr">at May 10, 2022 01:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4626">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2022/05/10/stoc-2022-and-other-theory-events/">STOC 2022, and other theory events</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Below is the call for participation to STOC 2022, which will take place in Rome in the third week of June. </p>



<p>If you would like to come to Italy a few days in advance, Alon Rosen and I are organizing two co-locating workshops on graph algorithms and on cryptography in Milan on June 15-18 (details forthcoming). If you want to stay longer, I am organizing a <a href="https://lucatrevisan.github.io/fai.html">mini-workshop on fairness in AI </a>in Milan on June 27 (more details about it in a few days). Registration will be free for both events. There are several high-speed trains every day between Rome and Milan, taking about 3 hours.</p>



<hr class="wp-block-separator has-alpha-channel-opacity" />



<p><strong>Call for Participation </strong></p>



<p><a href="https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Facm-stoc.org%2Fstoc2022%2F&amp;data=05%7C01%7Cl.trevisan%40unibocconi.it%7C1414e8ebe6c84cb1feab08da26d30a66%7C6bf3b57a9fb447c29ada51156518f52f%7C1%7C0%7C637864985669532280%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=IvAE0knKAOaU1M8xFhHlk%2B2JkbKCmitWJ7L0DdL7lq0%3D&amp;reserved=0" target="_blank" rel="noreferrer noopener"><strong>54th ACM Symposium on Theory of Computing (STOC 2022) – Theory Fest </strong></a></p>



<p><strong>June 20-24, 2022 </strong></p>



<p><strong>Rome, Italy </strong></p>



<p>The 54th ACM Symposium on Theory of Computing (STOC 2022) is sponsored by the ACM Special Interest Group on Algorithms and Computation Theory and will be held in Rome, Italy, Monday June 20 – Friday, June 24, 2022.</p>



<p>STOC 2022 – Theory Fest will feature technical talk sessions, <a href="https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Facm-stoc.org%2Fstoc2022%2Fworkshops.html&amp;data=05%7C01%7Cl.trevisan%40unibocconi.it%7C1414e8ebe6c84cb1feab08da26d30a66%7C6bf3b57a9fb447c29ada51156518f52f%7C1%7C0%7C637864985669532280%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=0IwoFBH2nZ9G4OVQYIeErR0tFrjqnJ1FSUXO1DAMflI%3D&amp;reserved=0" target="_blank" rel="noreferrer noopener">6 workshops</a> with introductory tutorials, poster sessions, social events, and a special joint session with “<a href="https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.lincei.it%2Fen&amp;data=05%7C01%7Cl.trevisan%40unibocconi.it%7C1414e8ebe6c84cb1feab08da26d30a66%7C6bf3b57a9fb447c29ada51156518f52f%7C1%7C0%7C637864985669532280%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=VdbRq7JdfE3gww0LXDyBGsFUmSFyhJzzTB6nT4JAqSc%3D&amp;reserved=0" target="_blank" rel="noreferrer noopener">Accademia Nazionale dei Lincei</a>”, the oldest and most prestigious Italian academic institution, followed by a reception and a concert at the <a href="https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.lincei.it%2Fen%2Fcorsini-palace&amp;data=05%7C01%7Cl.trevisan%40unibocconi.it%7C1414e8ebe6c84cb1feab08da26d30a66%7C6bf3b57a9fb447c29ada51156518f52f%7C1%7C0%7C637864985669688516%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=Qg8fp6EggGzAqdlfCV54DG%2FxEIWk2ZrOUbpy2NMhOy0%3D&amp;reserved=0" target="_blank" rel="noreferrer noopener">Academy historic site</a>. </p>



<p><strong>Registration</strong></p>



<p>STOC 2022 registration is available <a href="https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Facm-stoc.org%2Fstoc2022%2Fregistration.html&amp;data=05%7C01%7Cl.trevisan%40unibocconi.it%7C1414e8ebe6c84cb1feab08da26d30a66%7C6bf3b57a9fb447c29ada51156518f52f%7C1%7C0%7C637864985669688516%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=0p5rN4YqvT7g3qlE9x7X5A%2FiSCLAZ6slKQIVrm94iQw%3D&amp;reserved=0" target="_blank" rel="noreferrer noopener">here</a>.</p>



<p><strong>Early registration deadline: April 30th. </strong></p>



<p>STOC 2022 is sponsored by Algorand, Amazon, Apple, Google, IOHK, Microsoft, Sapienza University of Rome. </p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2022/05/10/stoc-2022-and-other-theory-events/"><span class="datestr">at May 10, 2022 12:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1667">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/2022/05/2022-voila-wola/">2022: Voilà, WOLA!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Good news, everyone! WOLA, the Workshop on Local Algorithms, is coming back this year, with <a href="https://ideas-ncbr.pl/en/wola/">WOLA 2022</a> taking place <strong>in person</strong>* in Warsaw on June 25–27. Exciting speakers, events and outings are being planned!</p>



<figure class="wp-block-image size-full"><a href="https://ptreview.sublinear.info/wp-content/uploads/2022/05/6fgrkl.jpg"><img width="620" alt="" src="https://ptreview.sublinear.info/wp-content/uploads/2022/05/6fgrkl.jpg" class="wp-image-1668" height="469" /></a></figure>



<p>Keep track of updates by visiting <a href="https://ideas-ncbr.pl/en/wola/">the website</a>, and <strong>register</strong> at <a href="https://ideas-ncbr.pl/en/wola/registration/">https://ideas-ncbr.pl/en/wola/registration/</a>  (even if you intend to attend remotely).</p>



<p>* Virtual participation is also possible.</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/2022/05/2022-voila-wola/"><span class="datestr">at May 09, 2022 01:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=22634">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2022/05/09/past-and-future-events/">Past and Future Events</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h3>Quick announcements of past (recorded) and future events</h3>
<p>1) Shachar Lovett was the <a href="https://mathematics.huji.ac.il/node/3086257">Erdos Speaker for 2022</a> and his great talks are recorded. (<a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=77834b4f-4050-495b-afd1-ae610069bb22">Lecture 1</a>, <strong>Tensor ranks and their applications</strong> <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e511cae0-b0ed-4024-8b56-ae670062fb01&amp;instance=HUJI21">lecture 2</a>, <strong>The monomial structure of Boolean functions</strong>, <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=424913ee-0af1-4496-b66d-ae67005ed4c5">lecture 3</a>, <strong>Point location: an interface between geometry, machine learning and complexity.</strong>)</p>
<p>2) Two weeks ago there was a wonderful <a href="https://math.nyu.edu/faculty/pollack/seminar/spring22/DCGDay22.html">workshop in memory of Eli Goodman and Ricky Pollack</a> The speakers were Andreas Holmsen, Micha Sharir (Tel Aviv University), Esther Ezra, Xavier Goaoc, Andrew Suk, and Sylvain Cappell. The lectures are recorded, <a href="https://youtube.com/playlist?list=PLl18CMjwy1yZmhwbMW6THPbu8vluKDrEz">here is the playlist</a> on the computational geometry <a href="https://www.youtube.com/channel/UC8bRNi3tJX-tfR_RMtyWR7w/videos">you tube channel</a>.</p>
<p>3) This week I give the <a href="https://secfac.wisc.edu/awards-lectures/hilldale-lecture-series/current-lectures/#physical-sciences">Hilldale <span class="d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d3f4x2em iv3no6db jq4qci2q a3bd9o3v b1v8xokw oo9gr5id hzawbc8m" dir="auto">Distinguished Lectures in Physical Sciences at the University of Wisconsin-Madison</span></a>. (The link contains the zoom address.) The topic is quantum computing. Lecture I (Tuesday, May 10, 12:00 CST) is on <strong>The Argument Against Quantum Computers</strong> and lecture II (Thursday, May 12, 12:00 CST) is on <strong>Quantum Computers, Predictability and Free Will. </strong></p>
<p><strong><a href="https://gilkalai.files.wordpress.com/2022/05/fwhilldale-blog.docx" title="FWHilldale-blog">Text for lecture 2</a></strong></p>
<p>4) This year I also give the Turàn memorial lectures in Budapest. The first talk <strong>Discrete Geometry – When Combinatorics Meets Convexity</strong> was given by zoom and <a href="https://video.renyi.hu/video/recent-progress-in-combinatorial-questions-in-convexity-408">here is a link to the recording.</a>  The two remaining talks, one devoted to probabilistic combinatorics and one devoted to extremal combinatorics will take place live (but in a hybrid setting) on June in Budapest.</p>
<p>5) The Simons Center at Berkeley celebrates on May 25-27 its <a href="https://simons.berkeley.edu/workshops/simons-institute-10th-anniversary-symposium" target="_blank" rel="noopener">10th Anniversary Symposium</a> (I plan to devote to it a special post).</p>
<p>6) <a href="https://vinberg.combgeo.org/igor-pak/">Igor Pak gave the Vinberg lecture</a> <strong>Combinatorial inequalities</strong> on Wednesday May 4. (<a href="https://www.youtube.com/playlist?list=PLU5TmElGttj2Edo_4KGOBaLXge3ZVRePU">This You Tube channel</a> is devoted to Vinberg’s talks and I will add a link to Igor’s talk here when it will be available.)</p>
<p>7) Remote lectures open up new opportunities. This summer I was invited to give a lecture in Indonesia and last fall I gave a lecture at Lahore, Pakistan.</p>
<p><a href="https://gilkalai.files.wordpress.com/2022/05/hilldale.png"><img width="332" alt="Hilldale" src="https://gilkalai.files.wordpress.com/2022/05/hilldale.png?w=332&amp;h=426" class="alignnone  wp-image-22647" height="426" /></a></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2022/05/09/past-and-future-events/"><span class="datestr">at May 09, 2022 06:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/070">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/070">TR22-070 |  On Solving Sparse Polynomial Factorization Related Problems | 

	Ilya Volkovich, 

	Pranav Bisht</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a recent result of Bhargava, Saraf and Volkovich [FOCS’18; JACM’20], the first sparsity bound for constant individual degree polynomials was shown. In particular, it was shown that any factor of a polynomial with at most $s$ terms and individual degree bounded by $d$ can itself have at most $s^{O(d^2\log n)}$ terms. It is conjectured, though, that the "true" sparsity bound should be polynomial (i.e. $s^{poly(d)}$). In this paper we provide supporting evidence for this conjecture by presenting polynomial-time algorithms for several problems that would be implied by a polynomial-size sparsity bound. In particular, we give an efficient (deterministic) identity testing algorithms for $\Sigma^{[2]}\Pi\Sigma\Pi^{[\deg_{x_i} \leq d]}$ circuits and testing if a sparse polynomial is an exact power. Hence, our algorithms rely on different techniques.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/070"><span class="datestr">at May 09, 2022 04:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1651">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/2022/05/news-for-april-2022/">News for April 2022</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We have…I don’t know, I’ve lost count of the number of papers this month. It’s a big bonanza. Sublinear algorithms for edit distance, planar graphs, distributions, bipartite graphs, groups, error correcting codes, Bayesian nets, polynomials…</p>



<p>Let’s proceed with the spread.</p>



<p><strong>Improved Sublinear-Time Edit Distance for Preprocessed Strings</strong> by Karl Bringmann, Alejandro Cassis, Nick Fischer, and Vasileios Nakos (<a href="https://arxiv.org/abs/2204.14137">arXiv</a>). The edit distance between strings is a classic and important problem in algorithms. You might recall that classic \(O(n^2)\) algorithm to compute the edit distance between strings of length \(n\). It has been show that getting a \(O(n^{2-\delta})\) time algorithm is SETH-hard. But what can be done in sublinear time? This paper considers the preprocessed version: suppose we can perform near-linear preprocessing on the strings. We now want to distinguish between edit distance between \(\leq k\) and \(\geq k\cdot n^{o(1)}\). This paper shows that with near-linear preprocessing on strings, one can solve this problem in \(k \cdot n^{o(1)}\) time. </p>



<p><strong>Optimal Closeness Testing of Discrete Distributions Made <s>Complex</s> Simple</strong> by (our own) Clément L. Canonne and Yucheng Sun (<a href="https://arxiv.org/abs/2204.12640">arXiv</a>). Given two distributions \(p, q\) over support \([k]\), the aim is to distinguish between (i) the distributions being equal, and (ii) the total variation distance between \(p, q\) being at least \(\epsilon\). The tester should has a failure probability of at most \(\delta\). A recent work nails down the sample complexity with respect to all parameters. This paper gives a simpler proof of the main result. Earlier proofs used Poissonization tricks and fairly clever arguments about Poisson random variables. This proof is much more transparent, and uses an identity that relates the expectation of a random variable to its characteristic function. A nice feature of this proof is that it works directly with the multinomial distribution, which means a fixed number of samples (rather than choosing the number of samples from a distribution).</p>



<p><strong>Tolerant Bipartiteness Testing in Dense Graphs</strong> by Arijit Ghosh, Gopinath Mishra, Rahul Raychaudhury, and Sayantan Sen (<a href="https://arxiv.org/abs/2204.12397">arXiv</a>). Testing bipartiteness of dense graphs is about as a classic as it gets. We wish to distinguish a bipartite graph from one that requires \(\varepsilon n^2\) edge removals to make it bipartite. Readers of this blog should know that there is a \(\widetilde{O}(\varepsilon^{-2})\)-query property tester for this problem. (Ok, so now you know.) This paper studies the tolerant version of bipartiteness testing. Note that this is equivalent to approximating the maxcut, up to additive error \(\varepsilon n^2\). Classic approximation algorithms show that the latter can be done in \(\widetilde{O}(\varepsilon^{-6})\) queries and \(\exp(\widetilde{O}(\varepsilon^{-2}))\) time. This paper considers the easier problem of distinguishing whether the distance to bipartiteness is at most \(\varepsilon\) or at least \(2 \varepsilon\). This problem is solved in \(\widetilde{O}(\varepsilon^{-3})\) queries and \(\exp(\widetilde{O}(\varepsilon^{-1}))\). </p>



<p><strong>Properly learning monotone functions via local reconstruction</strong> by Jane Lange, Ronitt Rubinfeld, Arsen Vasilyan (<a href="https://arxiv.org/abs/2204.11894">arXiv</a>). Ah yes, monotone functions. An ongoing love (obsession? interest?) for property testing people. This paper studies the problem of proper learning of Boolean valued monotone functions over the Boolean hypercube. Given access to uniform random evaluations of a monotone function \(f:\{0,1\}^n \to \{0,1\}\), we wish to compute a monotone function \(g\) that approximates the original function. Classic results from Fourier analysis show that an approximation  can be learned using \(\exp(\sqrt{n}/\varepsilon)\) queries. But this approximation function might not be monotone, and only yields improper learning. This paper gives a proper learner that outputs a monotone approximation, in roughly the same query complexity. This result directly gives a constant tolerance monotonicity tester for Boolean functions. The paper uses recent results from distributed algorithms and local computation. It also leads to tolerant testers for monotonicity over posets with small diameter.</p>



<p><strong>Massively Parallel Computation and Sublinear-Time Algorithms for Embedded Planar Graphs</strong> by Jacob Holm and Jakub Tětek (<a href="https://arxiv.org/abs/2204.09035">arXiv</a>). Sublinear algorithms for planar graphs is another ongoing love (at least for me). This paper considers a new take of this problem: suppose we have access to a geometric embedding of a planar graph \(G\). Can we get sublinear algorithms for a variety of problems? This paper first shows how to construct a convenient decomposition, called an \(r\)-division, in sublinear time. This division can be used to approximate Lipschitz graph parameters, such as maximum matching sizes, maximum independent set, etc. The paper also shows how to compute an \(r\)-division in the MPC model, which solves many classic graph  problems (connected components, matchings, etc.) in \(O(1)\) rounds. There is a (conditional) lower bound showing that, without an embedding, it is not possible to solve such problems in \(O(1)\) rounds (and sublinear space per processor).</p>



<p><strong>Independence Testing for Bounded Degree Bayesian Network</strong> by Arnab Bhattacharyya, Clément L. Canonne (again, our own), and Joy Qiping Yang (<a href="https://arxiv.org/abs/2204.08690">arXiv</a>). Given a distribution \(\mathcal{P}\) on the Boolean hypercube \(\{0,1\}^n\), the problem is to determine whether \(\mathcal{P}\) is a product distribution. In general, this problem requires \(\Omega(2^n)\) samples. Suppose \(\mathcal{P}\) has a sparse, “efficient” description. Can we do better? This paper shows that when \(\mathcal{P}\) is generated by a Bayesian network (with bounded indegree), then the independence testing problem can be solved with a \(\widetilde{O}(n/\varepsilon^2)\) samples. Think of a Bayesian network as a DAG, where each vertex generates a Bernoulli random variable. The variable at a vertex depends only the outcomes at its neighborhood.</p>



<p><strong>Low Degree Testing over the Reals </strong>by Vipul Arora, Arnab Bhattacharyya, Noah Fleming, Esty Kelman, and Yuichi Yoshida (<a href="https://arxiv.org/abs/2204.08404">arXiv</a>, <a href="https://eccc.weizmann.ac.il/report/2022/051/">ECCC</a>). The problem testing low degree polynomials goes back to the birth of property testing. This paper studies real valued polynomials, in the distribution free setting. Formally, we have query access to a function \(f: \mathbb{R}^d \to \mathbb{R}\). The distance is measured with respect to an unknown distribution \(\mathcal{D}\) over the domain. This paper shows that the real low degree testing problem can be solved in \(poly(d\varepsilon^{-1})\) queries (under some reasonableness conditions on the distribution). The approach is go to via the “self-correct and test” approach: try to compute a low degree polynomial that fits some sampled data, and then check how far the self-corrected version is from another sample.</p>



<p><strong>Testing distributional assumptions of learning algorithms</strong> by Ronitt Rubinfeld and Arsen Vasilyan (<a href="https://arxiv.org/pdf/2204.07196.pdf">arXiv</a>). Consider the problem of learning a halfspace over \(\mathbb{R}^n\). If the underlying distribution is Gaussian, then this class can be learned in \(n^{poly(\varepsilon^{-1})}\) samples. If the distribution is arbitrary, no \(2^{o(n)}\) algorithm is known despite much research. This paper introduces the notion of having a <em>tester-learner</em> pair. The tester first checks if the input distribution is “well-behaved” (Gaussian-like). If the tester passes, then we run the learner. Indeed, this perspective goes back to some of the original motivations for property testing (when is testing faster than learning). The intriguing aspect of this problem is that we do not have efficient testers for determining if an input distribution is Gaussian. This paper circumvents that problem by estimating certain moments of the distribution. If these moments agree with the moments of a Gaussian, then the learner is guaranteed to succeed. We get the best of both worlds: if the input distribution is Gaussian, the learning is done correctly. If the learner succeeds, then then output (hypothesis) is guaranteed to be correct, regardless of the input distribution.</p>



<p><strong>Testability in group theory</strong> by Oren Becker, Alexander Lubotzky, and Jonathan Mosheiff (<a href="https://arxiv.org/abs/2204.04539">arXiv</a>). This paper is the journal version of a result of the authors, and it gives a group theoretic presentation of a property testing result. Consider the following problem. The input is a pair permutations \((\sigma_1, \sigma_2)\) over \([n]\). The aim is to test whether they commute: \(\sigma_1 \sigma_2 = \sigma_2 \sigma_1\). Another result of the authors gives a tester that makes \(O(\varepsilon^{-1})\) queries. They refer to this problem as “testing the relation” \(XY = YX\). This paper gives a grand generalization of that result, best explained by another example. Consider another relation/property denoted \(\{XZ = ZX, YZ = ZY\}\). This property consists of all triples of permutations \((\sigma_1, \sigma_2, \sigma_3)\), where \(\sigma_3\) commutes with the other two. A consequence of the main theorem is that this property is not testable with query complexity independent of \(n\). The main result of this paper is a characterization of testable relations, which goes via studying the expansion of an infinite graph associated with the relation.</p>



<p><strong>Testing Positive Semidefiniteness Using Linear Measurements</strong> by Deanna Needell, William Swartworth, and David P. Woodruff (<a href="https://arxiv.org/abs/2204.03782">arXiv</a>). The input is a \(d \times d\) real, symmetric matrix \(M\) and we wish to determine if it is positive semidefinite (all eigenvalues are positive). For the testing problem, we reject when the minimum eigenvalue is at most \(-\varepsilon \|M\|_2\). (The paper also considers general Schatten \(p\)-norms.) This paper gives a list of results for non-adaptive vs adaptive, and one-sided vs two-sided testers. There are two access models considered: a single query consists of either a (i) matrix-vector product \(Mx\) or (ii) vector-matrix-vector product \(y^TMx\). Typical models that query entries of the matrix require strong bounds on the entries, which is less reasonable in practical situations. An interesting discovery is that the non-adaptive, one-sided complexity is \(\Theta(\sqrt{d}\varepsilon^{-1})\) while the two-sided bound is independent of \(d\).</p>



<p><strong>Relaxed Locally Decodable and Correctable Codes: Beyond Tensoring</strong> by Gil Cohen and Tal Yankovitz (<a href="https://eccc.weizmann.ac.il/report/2022/045/">ECCC</a>). Locally decodable and correctable codes are a fundamental object of study in property testing (and TCS in general). Consider a locally correctable code (LCC). Given a string \(x\), the decoder/corrector makes \(q\) queries to \(x\), and outputs a symbol. We can think of the output collectively as a string \(y\). If \(x\) is a codeword, then \(y = x\). Otherwise, \(dist(y,z) \leq \varepsilon\), where \(z\) is some codeword close to \(x\). In the relaxed version, the corrector is allowed to output \(\bot\), denoting that it has discovered corruption. The distance is only measured in the coordinates where the corrector does not output \(\bot\). Thus, the corrector gets a “free pass” if it outputs \(\bot\). But note that when \(x\) is a codeword, the output must be exactly \(x\). This paper gives a Relaxed LCC with query complexity \((\log n)^{O(\log\log\log n)}\), a significant improvement over the previous best \((\log n)^{O(\log\log n)}\). It is know from previous work that the query complexity must be \(\Omega(\sqrt{\log n})\).</p>



<p><strong>Verifying The Unseen: Interactive Proofs for Label-Invariant Distribution Properties</strong> by Tal Herman and Guy Rothblum (<a href="https://eccc.weizmann.ac.il/report/2022/052/">arXiv</a>). This paper considers the distribution testing problem in the context of interactive proofs. The verifier, who wishes to test a property of a distribution \(\mathcal{P}\), interacts with a prover who knows the distribution. The guarantee required is the standard one for interactive proof systems: in the YES case, an honest prover should be able to convince the verifier. In the NO case, no prover can convince the verifier with high probability. There are two important parameters of interest: the sample complexity of the verifier, and the communication complexity of the messages. It is useful to consider the two extremes. In one extreme, the verifier can simply solve the problem herself, ignoring the prover. This could require \(\Theta(n/\log n)\) queries (for the hardest properties like entropy and support size). Another extreme is for the honest prover to simply send an approximate description of the distribution, which takes \(O(n)\) bits. The prover can just test equality to the prover message, which only takes \(\Theta(\sqrt{n})\) queries. This paper shows a 2-round protocol for any (label-invariant) property where both the communication and the sample complexity can be made \(\Theta(\sqrt{n})\). This result shows the power of interaction for distribution testing problems.</p></div>







<p class="date">
by Seshadhri <a href="https://ptreview.sublinear.info/2022/05/news-for-april-2022/"><span class="datestr">at May 06, 2022 09:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-1290268660743913623">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2022/05/halg-2022-call-for-participation.html">HALG 2022: Call for participation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I am posting this call for participation on behalf of<strong> </strong>Keren Censor-Hillel, PC chair for HALG 2022. I expect that many colleagues from the Track A community will attend that event<span style="color: #0000ee;"><u> </u>and enjoy its mouth-watering scientific programme.<u> </u></span><strong></strong><div style="text-align: left;"><p><strong> </strong></p><p style="text-align: center;"><strong>7th Highlights of Algorithms conference (HALG 2022)<br /></strong>The London School of Economics and Political Science, June 1-3, 2022<br /><a href="https://www.lse.ac.uk/HALG-2022" target="_blank" rel="noreferrer noopener">https://www.lse.ac.uk/HALG-2022</a></p>   <p><br />The Highlights of Algorithms conference is a forum for presenting  the highlights of recent developments in algorithms and for discussing  potential further advances in this area. The conference will provide a  broad picture of the latest research in algorithms through a series of  invited talks, as well as the possibility for all researchers and  students to present their recent results through a series of short talks  and poster presentations. Attending the Highlights of Algorithms  conference will also be an opportunity for networking and meeting  leading researchers in algorithms.</p>   <p>For local information, visa information, or information about registration, please contact Tugkan Batu <a href="mailto:t.batu@lse.ac.uk" target="_blank" rel="noreferrer noopener">t.batu@lse.ac.uk</a>.—<br /> </p><p><b>PROGRAM </b></p>   <p>A detailed schedule and a list of all accepted short contributions is available at <a href="https://www.lse.ac.uk/HALG-2022/programme/Programme" target="_blank" rel="noreferrer noopener">https://www.lse.ac.uk/HALG-2022/programme/Programme</a><br /><br /><strong>REGISTRATION</strong></p>   <p><a href="https://www.lse.ac.uk/HALG-2022/registration/Registration" rel="nofollow">https://www.lse.ac.uk/HALG-2022/registration/Registration</a></p>   <p><strong></strong></p>   <p style="margin-left: 40px; text-align: left;"><strong>Early registration (by 20th May 2022)</strong></p><div style="margin-left: 40px; text-align: left;">   </div><p style="margin-left: 40px; text-align: left;">Students: £100<br class="" />Non-students: £150</p><div style="margin-left: 40px; text-align: left;">   </div><p style="margin-left: 40px; text-align: left;"><strong>Late registration (from 21st May 2022)</strong><br class="" />Students: £175<br class="" />Non-students: £225</p>   <p>Registration includes the lunches provided, coffee breaks, and the conference reception.</p>   <p>There are some funds from conference sponsors to subsidise student  registration fees. Students can apply for a fee waiver by sending an  email to Enfale Farooq (<a href="mailto:e.farooq@lse.ac.uk" target="_blank" rel="noreferrer noopener">e.farooq@lse.ac.uk</a>) by <strong>15th May 2022</strong>.  Those students presenting a contributed talk will be given priority in  allocation of these funds. The applicants will be notified of the  outcome by 17th May 2022.<br /></p>   <p><strong>INVITED SPEAKERS</strong></p>   <p style="margin-left: 40px; text-align: left;">Survey speakers:</p><div style="margin-left: 40px; text-align: left;">   </div><p style="margin-left: 40px; text-align: left;">Amir Abboud (Weizmann Institute of Science) <br />Julia Chuzhoy (Toyota Technological Institute at Chicago)<br />Martin Grohe (RWTH Aachen University)<br />Anna Karlin (University of Washington)<br />Richard Peng (Georgia Institute of Technology)<br />Thatchaphol Saranurak (University of Michigan)</p><div style="margin-left: 40px; text-align: left;">   </div><p style="margin-left: 40px; text-align: left;">Invited talks:<br class="" /><strong><br class="" /></strong>Peyman Afshani (Aarhus University)  <br class="" />Soheil Behnezhad (Stanford University)  <br class="" />Sayan Bhattacharya (University of Warwick)<br class="" />Guy Blelloch (Carnegie Mellon University)<br class="" />Greg Bodwin (University of Michigan)<br class="" />Mahsa Eftekhari (University of California, Davis)<br class="" />John Kallaugher (Sandia National Laboratories)<br class="" />William Kuszmaul (Massachusetts Institute of Technology)<br class="" />Jason Li (Carnegie Mellon University)<br class="" />Joseph Mitchell (SUNY, Stony Brook)<br class="" />Shay Moran (Technion)<br class="" />Merav Parter (Weizmann Institute of Science)<br class="" />Aviad Rubinstein (Stanford University)<br class="" />Rahul Savani (University of Liverpool)<br class="" />Mehtaab Sawhney (Massachusetts Institute of Technology)<br class="" />Jakub Tetek (University of Copenhagen)<br class="" />Vera Traub (ETH Zurich)<br class="" />Jan Vondrak (Stanford University)<br class="" />Yelena Yuditsky (Université Libre de Bruxelles) </p></div><p></p><p></p><p></p><p></p><p></p><p></p><p></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2022/05/halg-2022-call-for-participation.html"><span class="datestr">at May 06, 2022 03:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8325">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2022/05/06/halg-22-call-for-participation-guest-post-by-keren-censor-hillel/">HALG ’22 Call for Participation (Guest post by Keren Censor-Hillel)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>7th Highlights of Algorithms conference (HALG 2022)<br /></strong>The London School of Economics and Political Science, June 1-3, 2022<br /><a href="https://www.lse.ac.uk/HALG-2022" target="_blank" rel="noreferrer noopener">https://www.lse.ac.uk/HALG-2022</a></p>



<p><br />The Highlights of Algorithms conference is a forum for presenting the highlights of recent developments in algorithms and for discussing potential further advances in this area. The conference will provide a broad picture of the latest research in algorithms through a series of invited talks, as well as the possibility for all researchers and students to present their recent results through a series of short talks and poster presentations. Attending the Highlights of Algorithms conference will also be an opportunity for networking and meeting leading researchers in algorithms.</p>



<p>For local information, visa information, or information about registration, please contact Tugkan Batu <a href="mailto:t.batu@lse.ac.uk" target="_blank" rel="noreferrer noopener">t.batu@lse.ac.uk</a>.—<br />PROGRAM: </p>



<p>A detailed schedule and a list of all accepted short contributions is available at:<a href="https://www.lse.ac.uk/HALG-2022/programme/Programme" target="_blank" rel="noreferrer noopener">https://www.lse.ac.uk/HALG-2022/programme/Programme</a><br />—<br /><strong>REGISTRATION</strong></p>



<p><a href="https://www.lse.ac.uk/HALG-2022/registration/Registration" rel="nofollow">https://www.lse.ac.uk/HALG-2022/registration/Registration</a></p>



<p><strong></strong></p>



<p><strong>Early registration (by 20th May 2022)</strong></p>



<p>Students: £100<br class="" />Non-students: £150</p>



<p><strong>Late registration (from 21st May 2022)</strong><br class="" />Students: £175<br class="" />Non-students: £225</p>



<p>Registration includes the lunches provided, coffee breaks, and the conference reception.</p>



<p>There are some funds from conference sponsors to subsidise student registration fees. Students can apply for a fee waiver by sending an email to Enfale Farooq (<a href="mailto:e.farooq@lse.ac.uk" target="_blank" rel="noreferrer noopener">e.farooq@lse.ac.uk</a>) by <strong>15th May 2022</strong>. Those students presenting a contributed talk will be given priority in allocation of these funds. The applicants will be notified of the outcome by 17th May 2022.—<br /></p>



<p><strong>INVITED SPEAKERS</strong></p>



<p>Survey speakers:</p>



<p>Amir Abboud (Weizmann Institute of Science) <br />Julia Chuzhoy (Toyota Technological Institute at Chicago)<br />Martin Grohe (RWTH Aachen University)<br />Anna Karlin (University of Washington)<br />Richard Peng (Georgia Institute of Technology)<br />Thatchaphol Saranurak (University of Michigan)</p>



<p>Invited talks:<br class="" /><strong><br class="" /></strong>Peyman Afshani (Aarhus University)  <br class="" />Soheil Behnezhad (Stanford University)  <br class="" />Sayan Bhattacharya (University of Warwick)<br class="" />Guy Blelloch (Carnegie Mellon University)<br class="" />Greg Bodwin (University of Michigan)<br class="" />Mahsa Eftekhari (University of California, Davis)<br class="" />John Kallaugher (Sandia National Laboratories)<br class="" />William Kuszmaul (Massachusetts Institute of Technology)<br class="" />Jason Li (Carnegie Mellon University)<br class="" />Joseph Mitchell (SUNY, Stony Brook)<br class="" />Shay Moran (Technion)<br class="" />Merav Parter (Weizmann Institute of Science)<br class="" />Aviad Rubinstein (Stanford University)<br class="" />Rahul Savani (University of Liverpool)<br class="" />Mehtaab Sawhney (Massachusetts Institute of Technology)<br class="" />Jakub Tetek (University of Copenhagen)<br class="" />Vera Traub (ETH Zurich)<br class="" />Jan Vondrak (Stanford University)<br class="" />Yelena Yuditsky (Université libre de Bruxelles) </p>



<p></p>



<p>Best regards,</p>



<p>Keren Censor-Hillel</p>



<p>PC chair for HALG 2022</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2022/05/06/halg-22-call-for-participation-guest-post-by-keren-censor-hillel/"><span class="datestr">at May 06, 2022 02:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=131">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2022/05/06/wednesday-may-11th-2022-sebastien-bubeck-from-microsoft-research/">Wednesday May 11th 2022 — Sébastien Bubeck from Microsoft Research</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next <a href="https://sites.google.com/view/dstheory/home" target="_blank" rel="noreferrer noopener">Foundations of Data Science</a> virtual talk of this year will take place on <strong>Wednesday, March 11th</strong> at <strong>1:00 PM Pacific Time</strong> (16:00 Eastern Time, 22:00 Central European Time, 20:00 UTC). <a href="http://sbubeck.com/">Sébastien Bubeck</a> from<strong> Microsoft Research</strong> will speak about “Set Chasing, with an application to online shortest path.<em>”</em></p>



<p><a href="https://sites.google.com/view/dstheory" target="_blank" rel="noreferrer noopener">Please register here to join the virtual talk.</a></p>



<p><strong>Abstract</strong>:  Since the late 19th century, mathematicians have realized the importance and generality of selection problems: given a collection of sets, select an element in each set, possibly in a “nice” way. Of particular importance in computer science is the scenario where the ground set is a metric space, in which case it is natural to ask for <strong>Lipschitz</strong> selection. In this talk I will describe a far-reaching extension of this classical Lipschitz selection problem to an *online* setting, where sets are streaming to the selector. I will show how Riemannian gradient descent (aka mirror descent) can be used to approach this type of problems. I will illustrate the power of the framework by solving a long-standing problem in online shortest path known as layered graph traversal (introduced by Papadimitriou and Yannakakis in 1989).</p>



<p> The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2022/05/06/wednesday-may-11th-2022-sebastien-bubeck-from-microsoft-research/"><span class="datestr">at May 06, 2022 02:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/069">TR22-069 |  List-Decoding Random Walk XOR Codes Near the Johnson Bound | 

	Silas Richelson, 

	Sourya Roy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a breakthrough result, Ta-Shma described an explicit construction of an almost optimal binary code (STOC 2017).  Ta-Shma's code has distance $\frac{1-\varepsilon}{2}$ and rate $\Omega\bigl(\varepsilon^{2+o(1)}\bigr)$ and thus it almost achieves the Gilbert-Varshamov bound, except for the $o(1)$ term in the exponent.  The prior best list-decoding algorithm for (a variant of) Ta-Shma's code achieves is due to Alev et al (STOC 2021).  This algorithm makes use of SDP hierarchies, and is able to recover from a $\frac{1-\rho}{2}-$fraction of errors as long as $\rho\geq2^{\log(1/\varepsilon)^{1/6}}$.  In this work we give an improved analysis of a similar list-decoding algorithm.  Our algorithm works for Ta-Shma's original code, and it is able to list-decode almost all the way to the Johnson bound: it can recover from a $\frac{1-\rho}{2}-$fraction of errors as long as $\rho\geq2\sqrt{\varepsilon}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/069"><span class="datestr">at May 05, 2022 01:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/068">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/068">TR22-068 |  Sketching Approximability of (Weak) Monarchy Predicates | 

	Santhoshini Velusamy, 

	Chi-Ning  Chou, 

	Madhu Sudan, 

	Alexander Golovnev, 

	Amirbehshad Shahrasbi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We analyze the sketching approximability of constraint satisfaction problems on Boolean domains, where the constraints are balanced linear threshold functions applied to literals. In particular, we explore the approximability of monarchy-like functions where the value of the function is determined by a weighted combination of the vote of the first variable (the president) and the sum of the votes of all remaining variables. The pure version of this function is when the president can only be overruled by when all remaining variables agree. For every $k \geq 5$, we show that CSPs where the underlying predicate is a pure monarchy function on $k$ variables have no non-trivial sketching approximation algorithm in $o(\sqrt{n})$ space. We also show infinitely many weaker monarchy functions for which CSPs using such constraints are non-trivially approximable by $O(\log(n))$ space sketching algorithms. Moreover, we give the first example of sketching approximable asymmetric Boolean CSPs. Our results work within the framework of Chou, Golovnev, Sudan, and Velusamy (FOCS 2021) that characterizes the sketching approximability of all CSPs. Their framework can be applied naturally to get a computer-aided analysis of the approximability of any specific constraint satisfaction problem. The novelty of our work is in using their work to get an analysis that applies to infinitely many problems simultaneously.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/068"><span class="datestr">at May 05, 2022 01:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/067">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/067">TR22-067 |  Black-box Identity Testing of Noncommutative Rational Formulas of Inversion Height Two in Deterministic Quasipolynomial-time | 

	Vikraman Arvind, 

	Abhranil Chatterjee, 

	Partha Mukhopadhyay</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Hrube\v{s} and Wigderson (2015) initiated the complexity-theoretic study of noncommutative formulas with inverse gates. They introduced the Rational Identity Testing (RIT) problem which is to decide whether a noncommutative rational formula computes zero in the free skew field. In the white-box setting, deterministic polynomial-time algorithms are known for this problem following the works of Garg, Gurvits, Oliveira, and Wigderson (2016) and Ivanyos, Qiao, and Subrahmanyam (2018).

A central open problem in this area is to design an efficient deterministic black-box identity testing algorithm for rational formulas. In this paper, we solve this problem for the first nested inverse case. More precisely, we obtain a deterministic quasipolynomial-time black-box RIT algorithm for noncommutative rational formulas of inversion height two via a hitting set construction. Several new technical ideas are involved in the hitting set construction, including key concepts from matrix coefficient realization theory (Vol?i?, 2018) and properties of cyclic division algebra (Lam, 2001). En route to the proof, an important step is to embed the hitting set of Forbes and Shpilka for noncommutative formulas (2013) inside a cyclic division algebra of small index.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/067"><span class="datestr">at May 05, 2022 10:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/066">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/066">TR22-066 |  On sketching approximations for symmetric Boolean CSPs | 

	Joanna Boyland, 

	Michael Hwang, 

	Tarun Prasad, 

	Noah Singer, 

	Santhoshini Velusamy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A Boolean maximum constraint satisfaction problem, Max-CSP\((f)\), is specified by a predicate \(f:\{-1,1\}^k\to\{0,1\}\). An \(n\)-variable instance of Max-CSP\((f)\) consists of a list of constraints, each of which applies \(f\) to \(k\) distinct literals drawn from the \(n\) variables. For \(k=2\), Chou, Golovnev, and Velusamy [CGV20, FOCS 2020] obtained explicit ratios characterizing the \(\sqrt n\)-space streaming approximability of every predicate. For \(k \geq 3\), Chou, Golovnev, Sudan, and Velusamy [CGSV21, arXiv:2102.12351] proved a general dichotomy theorem for \(\sqrt n\)-space sketching algorithms: For every \(f\), there exists \(\alpha(f)\in (0,1]\) such that for every \(\epsilon&gt;0\), Max-CSP\((f)\) is \((\alpha(f)-\epsilon)\)-approximable by an \(O(\log n)\)-space linear sketching algorithm, but \((\alpha(f)+\epsilon)\)-approximation sketching algorithms require \(\Omega(\sqrt{n})\) space.
     
In this work, we give closed-form expressions for the sketching approximation ratios of multiple families of symmetric Boolean functions. Letting \(\alpha'_k = 2^{-(k-1)} (1-k^{-2})^{(k-1)/2}\), we show that for odd \(k \geq 3\), \(\alpha(k\)AND\()\, = \alpha'_k\), and for even \(k \geq 2\), \(\alpha(k\)AND\()\, = 2\alpha'_{k+1}\). Thus, for every \(k\), \(k\)AND can be \((2-o(1))2^{-k}\)-approximated by \(O(\log n)\)-space sketching algorithms; we contrast this with a lower bound of Chou, Golovnev, Sudan, Velingker, and Velusamy [STOC 2022] implying that streaming \((2+\epsilon)\cdot2^{-k}\)-approximations require \(\Omega(n)\) space! We also resolve the ratio for the "at-least-\((k-1)\)-\(1\)'s" function for all even \(k\); the "exactly-\(\frac{k+1}2\)-\(1\)'s" function for odd \(k \in \{3,\ldots,51\}\); and fifteen other functions. We stress here that for general \(f\), the dichotomy theorem in [CGSV21] only implies that \(\alpha(f)\) can be computed to arbitrary precision in \(\textbf{PSPACE}\), and thus closed-form expressions need not have existed a priori. Our analyses involve identifying and exploiting structural "saddle-point" properties of this dichotomy.
    
Separately, for all threshold functions, we give optimal "bias-based" approximation algorithms generalizing [CGV20] while simplifying [CGSV21]. Finally, we investigate the \(\sqrt n\)-space streaming lower bounds in [CGSV21], and show that they are incomplete for \(3\)AND, i.e., they fail to rule out \((\alpha(3\)AND\()-\epsilon)\)-approximations in \(o(\sqrt n)\) space.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/066"><span class="datestr">at May 04, 2022 09:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1003512012676442457">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2022/05/the-revolution-of-steve-jobs.html">The (R)evolution of Steve Jobs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://cdn2.atlantamagazine.com/wp-content/uploads/sites/4/2022/04/stevejobsopera04_courtesy.jpg"><img width="400" src="https://cdn2.atlantamagazine.com/wp-content/uploads/sites/4/2022/04/stevejobsopera04_courtesy.jpg" border="0" height="240" /></a></div><br /><div>I don't mention it that often in this blog, but I fell in love with opera in the 90's and watch as much as I can, often fitting opera into my travels or vice-versa. Rarely do the tech world and operas collide but they did so this weekend in visit to Atlanta, I saw the <a href="https://www.atlantaopera.org/performance/the-revolution-of-steve-jobs/">(R)evolution of Steve Jobs</a>, yes an opera about the iconic Apple founder that was first performed in Santa Fe five years ago. This production played in Austin and Kansas City earlier this year.</div><div><br /></div><div>The story focused on relationships, Steve Wozniak, his wife Laurene, his guru Kōbun Chino Otogawa and Chrisann Brennan, the mother of Job's daughter Lisa, and on Steve Jobs focus on perfection and his company, as he often shunned others and even his own health. The <a href="https://open.spotify.com/album/3tIWs92ipMRVl7M6PTziO0">music</a> worked and the singers were generally strong. There were about 20 large monitors on the set which were used to enhance the story in pretty clever ways. The opera bounced around in time from when Steve Jobs father bought him a worktable to his memorial service. </div><div><br /></div><div>100 minutes is short for an opera, especially one on a person as complicated as Jobs, and some of the story lines and characters could have benefited by a longer exposition, or perhaps a more focused story could have had a larger emotional punch.</div><div><br /></div><div>Laurene had a message at the memorial service but really meant for the audience in the opera.</div><div><blockquote><div><div>And after this is over,</div><div>The very second this is over,</div><div>For better or worse,</div><div>Everyone will</div><div>Reach in their pockets,</div><div>Or purses,</div><div>And — guess what? —</div><div>Look at their phones,</div><div>Their “one device.”</div><div>I’m not sure Version 2.0 of Steve</div><div>Would want that.</div><div>Version 2.0 might say:</div><div>“Look up, look out, look around.</div><div>Look at the stars,</div><div>Look at the sky,</div><div>Take in the light,</div><div>Take another sip,</div><div>Take another bite,</div><div>Steal another kiss,</div><div>Dance another dance,</div><div>Glance at the smile</div><div>Of the person right there next to you.”</div></div><div></div></blockquote><div>The (R)evolution of Steve Jobs has a couple of more performances in Atlanta this weekend, including a <a href="https://stream.atlantaopera.org/products/the-r-evolution-of-steve-jobs">livestream</a>, and <a href="https://calgaryopera.com/22-23/revolution">heads to Calgary</a> and other venues in the future.</div><div><br /></div><div>Next year, <a href="https://chicagooperatheater.org/22-23-season/turing">The Life and Death(s) of Alan Turing</a> at Chicago Opera Theater. </div></div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2022/05/the-revolution-of-steve-jobs.html"><span class="datestr">at May 04, 2022 02:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19968">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/05/04/sedgewick-to-emeritus-status/">Sedgewick to Emeritus Status</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<i>Retire from your job, but never retire your mind.</i></p>
<p>
Bob Sedgewick is becoming an <a href="https://dof.princeton.edu/book/export/html/5486">emeritus</a> professor: </p>
<p>
When Faculty transfer to emeritus status and retain a professional connection with Princeton, they are expected to conduct their future research and University-related activities with the same ethical standards currently expected from all Princeton Faculty. </p>
<p>
Emeritus faculty members may receive such University publications as the Princeton University Bulletin and the Princeton Alumni Weekly, as well as agendas and minutes of University Faculty Meetings. They may attend meetings of the University and departmental faculty upon invitation, but do not have votes at these meetings. Emeritus faculty members continue to receive University identification cards and to have use of the library, the athletic facilities and dining facilities on the same basis as active faculty members. </p>
<p>
A not so recent picture: <a href="https://rjlipton.wpcomstaging.com/rs/"><img width="218" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/rs.jpg?resize=218%2C300&amp;ssl=1" class="aligncenter size-medium wp-image-19971" height="300" /></a></p>
<p>
</p><p><b> Some History </b></p>
<p></p><p>
Sedgewick got his PhD at Stanford and returned to Brown to start his academic career as an assistant professor in 1975. He was promoted to associate professor in 1980 and full professor in 1983. At Brown, he <a href="http://cs.brown.edu/events/25th-anniversary/hist_text.html">participated</a> in the <a href="https://news.brown.edu/articles/2014/05/cs35#:~:text=This year marks the 35th,Digital VAX-11/80.">founding</a> of the computer science department, in 1979. </p>
<p>
Later in 1985 he joined the faculty at Princeton as <a href="https://www.princeton.edu/news/2019/05/03/sedgewick-recognized-contribution-computer-science-education">founding</a> chair of the Department of Computer Science. Two founding positions—pretty neat. His first-year courses in computer science are among the most popular ever offered at Princeton. He also pioneered the practice of replacing large live lectures with on-demand online videos—pretty clever. </p>
<p>
Bob has worked at research institutions outside of Princeton during summers and leaves. Three come to mind: </p>
<ul>
<li> <a href="https://idaccr.org/about-us">IDA</a>, the Institute for Defense Analyses, gave him an opportunity to work with the CRAY-1 <a href="https://en.wikipedia.org/wiki/Cray-1">supercomputer</a>.
</li><li> <a href="https://www.parc.com">PARC</a>, Xerox Palo Alto Research Center, gave him an opportunity to see the personal computer come into existence.
</li><li> <a href="https://en.wikipedia.org/wiki/French_Institute_for_Research_in_Computer_Science_and_Automation">INRIA</a>, The Institut National de Recherche en Informatique et en Automatique, gave him a chance to work closely with Philippe Flajolet
</li></ul>
<p>
I joined him at IDA a few years later. I had to get a security clearance which is another whole story—see this <a href="https://rjlipton.wpcomstaging.com/2015/09/03/open-problems-that-might-be-easy/">post</a> for some fun thoughts.</p>
<p>
</p><p><b> Some More History </b></p>
<p></p><p>
Bob and I wrote some papers together: Two were on <a href="https://en.wikipedia.org/wiki/Very_Large_Scale_Integration">VLSI</a>. The first on <a href="https://sedgewick.io/wp-content/themes/sedgewick/papers/1981Lower.pdf">lower</a> bounds on the size of chips that computed something and the second on a language <a href="https://sedgewick.io/wp-content/themes/sedgewick/papers/1982ALI.pdf">ALI</a> for designing VLSI circuits. </p>
<p>
Another paper was included also Jin-yi Cai and Andy Yao on <a href="https://ieeexplore.ieee.org/document/336546">Towards Uncheatable benchmarks</a>. Or see a follow-on <a href="https://link.springer.com/content/pdf/10.1007/978-0-387-35568-9_18.pdf">paper</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/bs/"><img width="225" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/bs.png?resize=225%2C300&amp;ssl=1" class="aligncenter size-medium wp-image-19972" height="300" /></a></p>
<p>
</p><p><b> Open Problems </b></p>
<p></p><p>
It was wonderful working <i>for</i> Bob when he was the chair of Computer Science and wonderful working <i>with</i> him on the above papers and more. </p>
<p>
Bob, have a wonderful time being retired. And happy emeritus status.</p>
<p></p></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2022/05/04/sedgewick-to-emeritus-status/"><span class="datestr">at May 04, 2022 10:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://scottaaronson.blog/?p=6411">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://scottaaronson.blog/?p=6411">Donate to protect women’s rights: a call to my fellow creepy, gross, misogynist nerdbros</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>So, I’d been planning a fun post for today about the <a href="https://en.wikipedia.org/wiki/DALL-E">DALL-E</a> image-generating AI model, and in particular, a brief new <a href="https://arxiv.org/abs/2204.13807">preprint</a> about DALL-E’s capabilities by <a href="https://cs.nyu.edu/~davise/">Ernest Davis</a>, <a href="https://en.wikipedia.org/wiki/Gary_Marcus">Gary Marcus</a>, and myself.  We wrote this preprint as a sort of “adversarial collaboration”: Ernie and Gary started out deeply skeptical of DALL-E, while I was impressed bordering on awestruck.  I was pleasantly surprised that we nevertheless managed to produce a text that we all agreed on.</p>



<p>Not for the first time, though, world events have derailed my plans.  The most important part of today’s post is this:</p>



<p><strong>For the next week, I, Scott Aaronson, will personally match all reader donations to <a href="https://fundtexaschoice.org/">Fund Texas Choice</a>—a group that helps women in Texas travel to out-of-state health clinics, for reasons that are neither your business nor mine—up to a total of $5,000.</strong></p>



<p>To show my seriousness, I’ve already donated $1,000.  Just let me know how much you’ve donated in the comments section!</p>



<p>The first reason for this donation drive is that, perhaps like many of you, I stayed up hours last night reading Alito’s <a href="https://www.documentcloud.org/documents/21835435-scotus-initial-draft">leaked decision</a> in a state of abject terror.  I saw how the logic of the decision, consistent and impeccable on its own terms, is one by which the Supreme Court’s five theocrats could now proceed to unravel the whole of modernity.  I saw how this court, unchecked by our broken democratic system, can now permanently enshrine the will of a radical minority, perhaps unless and until the United States is plunged into a second Civil War.</p>



<p>Anyway, that’s the first reason for the donation drive.  The second reason is to thank <em>Shtetl-Optimized</em>‘s commenters for their … err, consistently generous and thought-provoking contributions.  Let’s take, for example, <a href="https://scottaaronson.blog/?p=6405#comment-1938839">this</a> comment on last week’s admittedly <a href="https://scottaaronson.blog/?p=6405">rather silly post</a>, from an anonymous individual who calls herself “Feminist Bitch,” and who was enraged that it took me <em>a</em> <em>full day</em> to process one of the great political cataclysms of our lifetimes and publicly react to it:</p>



<blockquote class="wp-block-quote"><p>OF COURSE. Not a word about Roe v. Wade being overturned, but we get a pseudo-intellectual rationalist-tier rant about whatever’s bumping around Scott’s mind right now. Women’s most basic reproductive rights are being curtailed AS WE SPEAK and not a peep from Scott, eh? Even though in our state (Texas) there are already laws ON THE BOOKS that will criminalize abortion as soon as the alt-right fascists in our Supreme Court give the go-ahead. If you cared one lick about your female students and colleagues, Scott, you’d be posting about the Supreme Court and helping feminist causes, not posting your “memes.” But we all know Scott doesn’t give a shit about women. He’d rather stand up for creepy nerdbros and their right to harass women than women’s right to control their own fucking bodies. Typical Scott.</p></blockquote>



<p>If you want, you can <a href="https://scottaaronson.blog/?p=6405#comment-1938839">read</a> all of Feminist Bitch’s further thoughts about my failings, with my every attempt to explain and justify myself met with further contempt.  No doubt my well-meaning friends of both sexes would counsel me to ignore her.  Alas, from my <a href="https://www.theatlantic.com/politics/archive/2015/01/the-blog-comment-that-achieved-an-internet-miracle/384539/">infamous ordeal</a> of late 2014, I know that with her every word, Feminist Bitch speaks for thousands, and the knowledge eats at me day and night.</p>



<p>It’s often said that “the right looks for converts, while the left looks only for heretics.”  Has Feminist Bitch ever stopped to think about <em>how</em> our civilization reached its current terrifying predicament—how Trump won in 2016, how the Supreme Court got packed with extremists who represent a mere 25% of the country, how Putin and Erdogan and Orban and Bolsonaro and all the rest consolidated their power?  Does she think it happened because wokeists like herself reached out too much, made too many inroads among fellow citizens who share <em>some</em> but not <em>all</em> of their values?  Would Feminist Bitch say that, if the Democrats want to capitalize on the coming tsunami of outrage about the death of <em>Roe</em> and the shameless lies that enabled it, if they want to sweep to victory in the midterms and enshrine abortion rights into federal law … then their best strategy would be to double down on their condemnations of gross, creepy, smelly, white male nerdbros who all the girls, like, <em>totally hate</em>?</p>



<p>(until, thank God, some of them don’t)</p>



<p>I continue to think that the majority of my readers, of all races and sexes and backgrounds, are reasonable and sane.  I continue to think the majority of you recoil against hatred and dehumanization of <em>anyone</em>—whether that means women seeking abortions, gays, trans folks, or (gasp!) even white male techbros.  In this sad twilight for the United States and for liberal democracy around the world, we the reasonable and sane, we the fans of the Enlightenment, we the <a href="https://scottaaronson.blog/?p=3922">Party of Psychological Complexity</a>, have decades of work cut out for us.  For now I’ll simply say: I don’t hear from you nearly enough in the comments.</p></div>







<p class="date">
by Scott <a href="https://scottaaronson.blog/?p=6411"><span class="datestr">at May 04, 2022 05:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/065">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/065">TR22-065 |  Streaming and Sketching Complexity of CSPs: A survey | 

	Madhu Sudan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this survey we describe progress over the last decade or so in understanding the complexity of solving constraint satisfaction problems (CSPs) approximately in the streaming and sketching models of computation. After surveying some of the results we give some sketches of the proofs and in particular try to explain why there is a tight dichotomy result for sketching algorithms working in subpolynomial space regime.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/065"><span class="datestr">at May 03, 2022 07:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/064">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/064">TR22-064 |  Improved Low-Depth Set-Multilinear Circuit Lower Bounds | 

	Deepanshu Kush, 

	Shubhangi Saraf</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper, we prove strengthened lower bounds for constant-depth set-multilinear formulas. More precisely, we show that over any field, there is an explicit polynomial $f$ in VNP defined over $n^2$ variables, and of degree $n$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at least $n^{\Omega \left( n^{1/\Delta}/\Delta\right)}$. The hard polynomial $f$ comes from the class of Nisan-Wigderson (NW) design-based polynomials. 

Our lower bounds improve upon the recent work of Limaye, Srinivasan and Tavenas (STOC 2022), where a lower bound of the form $(\log n)^{\Omega (\Delta n^{1/\Delta})}$ was shown for the size of product-depth $\Delta$ set-multilinear formulas computing the iterated matrix multiplication (IMM) polynomial of the same degree and over the same number of variables as $f$. Moreover, our lower bounds are novel for any $\Delta\geq 2$.

The precise quantitative expression in our lower bound is interesting also because the lower bounds we obtain are "sharp" in the sense that any asymptotic improvement would imply general set-multilinear circuit lower bounds via depth reduction results. 

In the setting of general set-multilinear formulas, a lower bound of the form $n^{\Omega(\log n)}$ was already obtained by Raz (J. ACM 2009) for the more general model of multilinear formulas. The techniques of LST (which extend the techniques of the same authors in (FOCS 2021)) give a different route to set-multilinear formula lower bounds, and allow them to obtain a lower bound of the form $(\log n)^{\Omega(\log n)}$ for the size of general set-multilinear formulas computing the IMM polynomial. Our proof techniques are another variation on those of LST, and enable us to show an improved lower bound (matching that of Raz) of the form $n^{\Omega(\log n)}$, albeit for the same polynomial $f$ in VNP (the NW polynomial). As observed by LST, if the same $n^{\Omega(\log n)}$ size lower bounds for unbounded-depth set-multilinear formulas could be obtained for the IMM polynomial, then using the self-reducibility of IMM and using hardness escalation results, this would imply super-polynomial lower bounds for general algebraic formulas.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/064"><span class="datestr">at May 03, 2022 07:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/063">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/063">TR22-063 |  Fast Multivariate Multipoint Evaluation Over All Finite Fields | 

	Mrinal Kumar, 

	Sumanta Ghosh, 

	Zeyu Guo, 

	Chris Umans, 

	Vishwas Bhargava</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Multivariate multipoint evaluation is the problem of evaluating a multivariate polynomial, given as a coefficient vector, simultaneously at multiple evaluation points. In this work, we show that there exists a deterministic algorithm for multivariate multipoint evaluation over any finite field $\mathbb{F}$ that outputs the evaluations of an $m$-variate polynomial of degree less than $d$ in each variable at $N$ points in time 
\[
(d^m+N)^{1+o(1)}\cdot poly(m,d,\log|\F|)
\]
for all $m\in\mathbb{N}$ and all sufficiently large $d\in \mathbb{N}$.

A previous work of Kedlaya and Umans (FOCS 2008, SICOMP 2011) achieved the same time complexity when the number of variables $m$ is at most $d^{o(1)}$ and had left the problem of removing this condition as an open problem. A recent work of Bhargava, Ghosh, Kumar and Mohapatra (STOC 2022) answered this question when the underlying field is not too large  and has characteristic less than $d^{o(1)}$. In this work, we remove this constraint on the number of variables over all finite fields, thereby answering the question of Kedlaya and Umans over all finite fields. 

Our algorithm relies on a non-trivial combination of ideas from three seemingly different previously known algorithms for multivariate multipoint evaluation, namely the algorithms of Kedlaya and Umans, that of  Bj\"orklund, Kaski and Williams (IPEC 2017, Algorithmica 2019), and that of Bhargava, Ghosh, Kumar and Mohapatra, together with a result of Bombieri and Vinogradov from analytic number theory about the distribution of primes in an arithmetic progression. 

We also present a second algorithm for multivariate multipoint evaluation that is completely elementary and in particular, avoids the use of the Bombieri--Vinogradov Theorem. However, it requires a mild assumption that the field size is bounded by an exponential-tower in $d$ of bounded height. More specifically, our second algorithm solves the multivariate multipoint evaluation problem over a finite field $\mathbb{F}$ in time 
\[
(d^m+N)^{1+o(1)}\cdot poly(m,d,\log |\mathbb{F}|)\]
for all $m\in \mathbb{N}$ and all sufficiently large $d\in \mathbb{N}$, provided that the size of the finite field $\mathbb{F}$ is at most $(\exp(\exp(\exp(\cdots (\exp(d)))))$, where the height of this tower of exponentials is fixed.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/063"><span class="datestr">at May 03, 2022 07:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8321">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/">Philosophy of science and the blockchain: A book review</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This blog post is a book review of sorts for the following two books:</p>



<p><a href="https://www.amazon.com/Explain-World-Discovery-Modern-Science/dp/0062346660">To Explain the World: The Discovery of Modern Science</a> by Steven Weinberg (2016)</p>



<p><a href="https://www.amazon.com/Knowledge-Machine-Irrationality-Created-Science/dp/1631491377/">The Knowledge Machine: How Irrationality Created Modern Science</a> by Michael Strevens (2020).</p>



<p>Both books cover (in different proportions) the history and philosophy of science. By the end of this post, I will also discuss my thoughts. <em>Trigger warning:</em> I will end up comparing science to the blockchain and finding positive aspects of the dreaded “reviewer 2”.</p>



<p>Both books attempt to answer the question of <strong>“why and how did the scientific revolution happen?”</strong>. Strevens describes this conundrum as follows:</p>



<p><em>“[If you were a citizen of ancient Greece], you could enjoy just about every cultural invention that makes life worth living today. You could delight in the poetry of Homer and Sappho, visit the theater to relish Oedipus Rex and other masterpieces of ancient drama… You could live in cities regulated by law and a system of courts shaped by the architects and sculptors who built some of the seven wonders of the world and governed in accordance with political models that have lasted to this day: monarchy, oligarchy, sweet democracy.”</em></p>



<p>The point Strevens makes is that while obviously, a lot has changed in culture and society since 300 BC, the change has not been so drastic as to make life unrecognizably different. In contrast, science and technology have undergone drastic changes in the same period, with most changes occurring in the last few centuries. Weinberg quotes the historian Herbert Butterfield, who claimed that the scientific revolution <em>“outshines everything since the rise of Christianity and reduces the Renaissance and Reformation to the rank of mere episodes.”</em></p>



<p>If you are the type of person who prefers data to quotes from historians, there is no shortage of graphs demonstrating this point, including the following:</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/DMx0_KjPGixzzYdBleMYRX2Xx_sf0ubgbU04kyluA_vMugVbJhnRnI_I8lY7u8h2qYfHVxjnKltPKG8V94LrNYMGAeUPvV8I-h8JPFL00rC8FCReH0E-aavJsV7gnxpwXSRv43RH0tRF_ES8uA" alt="" /></figure>



<p>(The right graph is adapted from Terry Tao’s excellent <a href="https://terrytao.wordpress.com/2010/10/10/the-cosmic-distance-ladder-ver-4-1/">cosmic distance ladder</a> presentation; I was happy to hear Tao is planning to turn it into a <a href="https://terrytao.wordpress.com/2020/10/10/climbing-the-cosmic-distance-ladder-book-announcement/">popular science book</a>.)</p>



<p>One distinguishing property of science (compared to activities such as religion, philosophy, art, political thought, sports etc.) is that it simultaneously satisfies the following three properties:</p>



<ul><li><strong>Consensus:</strong> While scientists don’t agree about everything, they generally agree on much, and the scientific literature does seem to converge toward consensus in the long run. Perhaps most importantly, even when scientists disagree on interpreting facts, they agree on what these facts are and agree on the forum where these should be discussed. In contrast, there is much less consensus in other spheres of human activities. Often, there isn’t even a consensus on what forum to hold the debate or even if to hold it at all. As far as I know, there isn’t a <em>Science</em> or <em>Nature</em> journal of theology where clergypersons of all faiths debate with one another. Indeed, with the polarized media these days, there are fewer and fewer forums where Democrats and Republicans debate with one another.<br /></li><li><strong>Change:</strong> The consensus is not just frozen in time but instead evolves. Scientists today generally agree with one another, but their views have radically changed over time. While, as Strevens notes, in art and religion, millennia-old texts are still very much relevant, in Machine Learning, when I recommend my students “read the classics,” I mean papers written before 2018 <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /><br /></li><li><strong>Correlation with reality:</strong> Science does not merely change but also <em>progresses</em>, in the sense that with time we gain a better understanding of nature. While some radical subjectivists might dispute that external reality exists or that science gets to know more of it, most people who have ever flown in a plane, were administered a vaccine, or read a blog post over the Internet, will agree that science did advance. Science’s path may be a random walk, but that walk is biased towards progress.</li></ul>



<p>Science did not always possess the above properties, and the distinction between science and philosophy was much murkier in the past. Both Strevens and Weinberg trace the birth of modern science to the Scientific Revolution of the 16th and 17th centuries. Both books describe the history of science and attempt to answer what changed since ancient times and why.</p>



<p><strong>Strevens: Modern Science as a result of Newton and the “Iron Rule”:</strong></p>



<p>Strevens begins by explaining the philosophies of Karl Popper and Thomas Kuhn. I found this part very informative since I have never read a proper philosophy of science book.  (He also describes their fascinating personal histories.)</p>



<p>For Popper, progress in science happens via <em>refutations</em>. At a given point in time, there is a collection of hypotheses H₁,…,Hₖ that are currently consistent with known experiments. Then an experiment happens which refutes some of these, narrowing down the set of potentially feasible theories.</p>



<p>According to Strevens, Popper is an absolutist. Once a theory has been falsified, it’s dead, and all theories that have not been yet falsified will <em>“forever remain … conjectures”</em>. That is, Popper was not a Bayesian and did not assign any likelihood to theories based on how many true predictions they made. The only question was whether they still survive or have been refuted.</p>



<p>Popper is said to have been inspired by Einstein, who was willing to put his theory to the test and said, <em>“if the redshift of spectral lines due to the gravitational potential should not exist, then [my] general theory of relativity will be untenable.” </em> Indeed, a classical story of testing a theory via refutation is <a href="https://en.wikipedia.org/wiki/Eddington_experiment">Eddington’s expedition</a> to check Einstein’s predictions during the 1919 total solar eclipse. Specifically, due to the curvature of space, the effect of the sun’s gravity on the light shining from stars would be double the effect predicted by Newton’s theory. </p>



<p>A priori, the Eddington expedition seems like a textbook Popperian refutation: an experiment is set out to test conflicting predictions of two theories, after which only one of them will survive. However, as Strevens points out, the truth is murkier. The expedition took three measurements: one on the island of Principe, off the coast of West Africa, and two in Brazil. The weather in Principe was cloudy, and the resulting photos were blurry. In Brazil weather was good, but the measurements were taken using two different telescopes that gave conflicting results. Concretely, one of the Brazil telescopes’ measurements conformed with Einstein’s predictions, while the other conformed with the Newtonian theory. Eddington argued that the second Brazil telescope had a systematic error, and hence Einstein’s theory was confirmed. This was accepted by the Royal Society and made big headlines at the time. While Eddington probably <a href="https://www.nature.com/articles/d41586-019-01172-z">made the best conclusion given the data</a>, Strevens claims that he also had extra-scientific motivations to endorse Einstein’s theory: a desire to unite British and German science after WW-I. Einstein’s response to the experiment was also famously non-Popperian: When asked what he would have done if the investigation had the opposing results, he said, <em>“Then I would feel sorry for the dear Lord. The theory is correct anyway.”</em></p>



<p>Thomas Kuhn famously saw scientific progress as not so much a process of incremental refutation as periodic revolutions and paradigm shifts. A paradigm consists not just of mere factual predictions but also ways of thinking and determining truth. As such, paradigms are internally self-consistent, and one cannot “refute” them as much as step away from them, when they outlive their usefulness and cannot handle “anomalies”. Geo-centrism is a good example. While Strevens doesn’t say this, it is impossible to refute a geocentric point of the world (we can always say that the sun rotates around the earth but just does it in a very complex path). And of course, as Earth-based scientists, making it the center of the universe is a very natural prior assumption. Therefore, Helio-centrism did not arise from refuting geo-centrism but through switching to a different paradigm. </p>



<p>For Popper, scientific theories die in a duel with one another. For Kuhn, they die of old age. As scientists struggle ever more to get useful results out of their current paradigm (maybe fine-tuning it more and more to fit the data), they get the sinking feeling that it’s a dead end, and are ready to accept a new paradigm.  While some of Kuhn’s radical followers believed there is no such thing as scientific progress and all paradigms are equally valid, Strevens says that (at least later in life)  Kuhn did not agree with this view. Thus, for Kuhn, while switching paradigms is not as much a rational deliberation as a “leap of faith,” it typically results in improved understanding and predictive power. </p>



<p>If the Popperian scientist is a refutation machine, according to Kuhn, the vast majority of scientists are confirmation machines. They cannot see beyond the current paradigm, but rather because of their belief in it, they continue to push it forward, accumulating more and more data until its natural demise. Popper thought of scientists as always keeping an open mind and never believing in anything not proven. Kuhn thought that blind faith (and the pleasure of “puzzle-solving”) keeps scientists going in what 99% of the time is a slog to do more experiments and produce more data.</p>



<p>Strevens has his own view on the philosophy of science. In particular, he pinpoints the beginning of the Scientific Revolution to a single person – Isaac Newton. To Strevens, Newton’s theory was so different from what came before because it gives precise predictions without claiming to explain the deeper reasons. Newton gave the equation for gravity without explaining why objects can act on each other at a distance. In his postscript to the Principia, Newton said,</p>



<p> <em>“I have not as yet been able to deduce from phenomena the reasons for these properties of gravity, and I do not feign hypotheses. For whatever is not deduced from the phenomena … [has] no place in experimental philosophy. … It is enough that gravity really exists and acts according to the laws that we have set forth and is sufficient to explain all the motions of the heavenly bodies and of our sea.” </em></p>



<p>In other words, Strevens sees Newton as saying, “shut up and calculate,” and indeed believes that Newton would have had no trouble with quantum mechanics’ famous “measurement problem.”  </p>



<p>Strevens sees this as key to modern science: giving up on deeper explanation and focusing only on empirical predictions. He admits scientists take other considerations, including the beauty of theories, into account in their motivations. But he claims that the “rules of engagement” are that all scientific disputes should be settled based on empirical evidence alone and within the domain of the formal scientific literature. He calls this the “Iron Rule of Explanations.” Strevens also sees Newton as science personified, in the sense in which Newton was an archetype of the modern scientific professionalism, formalism, and compartmentalization of thought. While Newton was very interested in both alchemy and biblical studies, unlike prior philosophers, he completely separated those interests from his work on physics. In that, Strevens says, Newton anticipated the modern universities, with its focus on specialization. </p>



<p>“Breaking down silos” is a common slogan these days, but Strevens argues that specialization and compartmentalization were crucial to science’s success. He says that  <em>“whatever is lost through detachment and disregard for the grand view of life is more than recompensed by the narrow, tightly focused beam that searches out the diminutive but telling fact.”</em></p>



<p><strong>Weinberg: Science history through modern eyes</strong></p>



<p>Weinberg’s is a gem of a book. Weinberg does not merely describe the works of ancient scientists, but he redoes their calculations, explaining what they got right, what they got wrong, and whether or not they could have done better with the data available. The book contains 35 technical notes, including everything from reworking Aristarchus’ derivations of the sizes and distances of the sun and the moon, through Descartes’ derivation of the law of refraction, to Newton’s calculations showing that the moon’s motion can be explained by the same gravitational force we see here on earth.</p>



<p>Weinberg places the beginning of the scientific revolution with Copernicus. While the choice of starting point might seem immaterial, this betrays a nearly opposite philosophical stance to Strevens’. While Strevens sees the reduction of science’s goal to empirical predictions as key, Copernicus’ heliocentric theory was actually a <em>step back</em> in terms of predictive power. The theory fitted the data worse than the prior geocentric theory of Ptolemy. Ptolemy introduced <em>epicycles</em> to adjust Aristotle’s clean but wrong geocentric theory to fit the data better. Today we know that epicycles correspond to the Fourier decomposition, and hence with enough of them, one can fit any periodic function. So, Ptolemy’s theory was the quintessential “shut up and calculate” theory: a good fit with observed data, but ugly and with several “fine-tuned” aspects that didn’t have any explanations. This has troubled astronomers for ages. The following words of the 12th-century Muslim scholar Ibn Rushd about Ptolemy’s theory could have been written about quantum mechanics today: <em>“The astronomical science of our days surely offers nothing from which one can derive an existing reality. The model that has been developed in the time in which we live accords with the computations, not with existence.” </em>[A side note is that quantum mechanics is very different from Ptolemy’s theory in the sense that while it does not offer a satisfactory story about reality, it is not “fine-tuned” and has its own sense of beauty, even if seeing this beauty is an “acquired taste”.]</p>



<p>Thus Copernicus’ contribution was not to find a more predictive theory, but rather a more beautiful one. As Weinberg says, this theory <em>“provides a classic example of how a theory can be selected on aesthetic criteria, with no experimental evidence that factors it over other theories… [this is] a recurrent theme in the history of physical science: a simple and beautiful theory that agrees pretty well with observation is often closer to the truth than a complicated ugly theory that agrees better with observation.”</em> [This might be a point to make a side note: while Popper, Kuhn, and (to some extent) Strevens often consider experiments as having discrete or logical outcomes – either true or false – for Weinberg quantities are always continuous or approximate, and every experiment always has a measure of uncertainty.]</p>



<p>Not surprisingly, while Strevens calls Francis Bacon’s extreme-empiricist book “one of the most significant books ever written on scientific inquiry”, Weinberg says that Bacon is one of the individuals “whose importance in the scientific revolution is most overrated” and that “it is not clear to me that anyone’s scientific work was actually changed for the better by Bacon’s writing.”</p>



<p>That is, as far as Weinberg is concerned, the novel parts of Bacon’s writing– the extreme empiricism– are false, and the true parts— plain-old experimentalism— are not novel and were known to scientists before Bacon’s time.</p>



<p>However, both Strevens and Weinberg agree on the significance of Newton. Newton’s innovation was not showing that gravity induces a uniform acceleration on objects. As Weinberg describes, already in 1603 Galileo did experiments showing that an object in free fall undergoes uniform acceleration, and showed that the distance it undergoes under gravity is proportional to the square of the time. Newton’s crucial insight was that the same relation is enough to explain the motion of the moon around the earth. He then saw that the ratio between the gravitational acceleration on earth and the one applied on the moon corresponds to the square of the distance between the two objects, and so (through Kepler’s law and his own invention of calculus) used this relation to explain the motion of all planets around the sun. </p>



<p>This was an astounding achievement. Not because Newton dared use a calculation without understanding the underlying mechanism: that was already done thousands of years before by Ptolemy and many others. Rather the impressive feat was that Newton formulated a simple law that works equally well on falling apples here on earth as well as moving stars in space. By doing this, Newton gave us the reason to hope that there are simple mathematical laws that govern all objects in the universe, and truly initiated modern science.</p>



<p><strong>Concluding thoughts</strong></p>



<p>I enjoyed reading both books and highly recommend them.  Personally, I am more inclined toward Weinberg’s view than Strevens’. I think the history of science is fascinating and can teach us a lot about science even today. The philosophy of science, whether Bacon’s, Popper’s, Kuhn’s, or Strevens’, is nice to know but is of second-order importance. That said, I think Strevens does make an essential point that the scientific “rules of engagement” may well have been key to maintaining the balance between progress and consensus that made science so successful. In particular, he believes that much of science’s success can be explained by its emphasis on formal publications, with their insistence on a “sterile language” and spelling out all details of experiments or calculations, maintained through the peer review process and generations of “reviewers 2”. This might be something to keep in mind in our era, where social media, including blogs, Twitter, and company websites, sometimes replace formal venues as the main medium for conveying scientific results. </p>



<p>My own view is that truth in science is not settled as much by debates as by momentum.  Whether the scientific consensus is X is not determined by some committee of experts, but rather by scientists, and especially students, “voting with their feet”. It is not so much a result of a debate between two distinguished scientists, but a result of a new generation of students abandoning what they think of as dead ends. (This is also known as <a href="https://en.wikipedia.org/wiki/Planck%27s_principle">Planck’s Principle</a>, sometimes grimly expressed as “science progresses one funeral at a time”.) For example,  in Computer Science, scores of papers and Ph.D. dissertations would be rendered meaningless if P=NP. This is stronger proof that the consensus is P≠NP than any poll of Turing laureates. </p>



<p>In that sense, science reminds me of the <em>blockchain</em> of bitcoin and other cryptocurrencies. The blockchain is a history of transactions of the form “User A paid X amount to user B”. User B will only be able to use this amount if there is <em>consensus</em> on this history. The blockchain is decentralized, and so several “forks” of it can exist simultaneously, but if users work on a “dead-end fork” that will not end up as part of the consensus history then their work will be for nothing. This motivates users to ensure that they are on the “right side of history” and only work on extensions of the chains that they believe will be part of the future consensus. This also means that we have more assurance of the veracity of an entry in the blockchain the further back it is, since there has been more work done that is built on this entry.</p>



<p>Similarly, scientists can be said to mine natural and artificial reality for scientific credit (not credit in the crass CV-padding or citation-counting way, but in terms of impact on the long-term direction of the field). But they will not get any such credit if their assumptions are eventually invalidated. Hence scientists are incentivized to ensure that they are always on the “right side of history”. They don’t want to work on a “dead-end fork” that will never get “merged” into the future main scientific discourse. <strong>A corollary is that if the truth of a particular proposition P is irrelevant to the way people do science then science will never need to form a consensus on whether P  is true or false. </strong>For example, as long as the choice of interpretation of quantum mechanics remains irrelevant to actual papers, debates between the Many-Worlds, Bohm and other interpretations will continue to take place in “cheap talk” outside the formal literature (whether over beer, in blog comments, or the popular press) and science will not need to form a consensus on which interpretation is correct. In particular, I don’t think science will ever need to form a consensus on whether any view of the philosophy of science, including my own, is the true one.</p>



<p><strong>Acknowledgments:</strong> Thanks to Scott Aaronson for recommending Weinberg’s book to me and Ludwig Schmidt for recommending Strevens’ book. Thanks also to Scott, Ludwig, and Preetum Nakkiran for useful comments on an earlier draft of this post.</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/"><span class="datestr">at May 03, 2022 01:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
