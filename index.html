<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at December 10, 2020 07:38 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17849">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/12/10/the-future-of-mathematics/">The Future of Mathematics?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Proving proofs are proven</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/10/the-future-of-mathematics/k1/" rel="attachment wp-att-17853"><img width="150" alt="" class="alignright  wp-image-17853" src="https://rjlipton.files.wordpress.com/2020/12/k1.jpg?w=150" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Kevin Buzzard is Professor of Pure Mathematics at Imperial College London. Wikipedia says that he <a href="https://en.wikipedia.org/wiki/Kevin_Buzzard">specialises</a> in algebraic number theory, rather than “specializes.” Is this because he was born in Britain, works in Britain, both, or could it be neither?</p>
<p>
This month, he has an <a href="https://www.ams.org/journals/notices/202011/rnoti-p1791.pdf">article</a> in the <em>AMS Notices</em> that highlights the system <a href="https://leanprover.github.io/about/"><img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /></a>. We thought we’d discuss <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> and its potential to change math—or <a href="https://www.youtube.com/watch?v=SbZCECvoaTA">maths</a>—as we know it.</p>
<p>
For starters we should say that <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> is: </p>
<blockquote><p><b> </b> <em> Lean is an open source theorem prover and programming language being developed at Microsoft Research. Lean aims to bridge the gap between interactive and automated theorem proving, by situating automated tools and methods in a framework that supports user interaction and the construction of fully specified axiomatic proofs. </em>
</p></blockquote>
<p></p><p>
This wording should perk up the ear of us complexity theorists. We know that polynomial-size interactive proofs have the power of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPSPACE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{PSPACE}}" class="latex" title="{\mathsf{PSPACE}}" /> for one prover, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NEXP}}" class="latex" title="{\mathsf{NEXP}}" /> for two, and the Halting Problem for two quantum provers, all of which are believed bigger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> as for non-interactive proofs. We believe that our concrete capabilities are shaped by this abstract lay-of-the-land, though this is a meta-scientific assertion that we could never try to prove. What Buzzard’s article and <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> are on about is the scientific state of what we do try to prove, or think we have proved.</p>
<p>
</p><p></p><h2> Aftermath as We Know It </h2><p></p>
<p></p><p>
Buzzard spoke early this year at the second annual “Lean Together” segment of the Formal Methods in Mathematics <a href="http://www.andrew.cmu.edu/user/avigad/meetings/fomm2020/index.html">conference</a> at CMU. </p>
<p>His <a href="https://www.andrew.cmu.edu/user/avigad/meetings/fomm2020/slides/fomm_buzzard.pdf">talk</a> was not so much about details of  <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> but about the fact of errors and specter of gaps in published mathematics. While a student of Richard Taylor, he had a front-row seat to a major instance. As he relates on a slide marked <b>Gaps</b> in big letters: </p>
<blockquote><p><b> </b> <em> </em></p><em>
<ul>
<li>
In 1993, Andrew Wiles announced a proof of Fermat’s Last Theorem. There was a gap in the proof. <p></p>
</li><li>
In 1994, Wiles and Taylor fixed the gap, the papers were published, and our community accepted the proof. <p></p>
</li><li>
In 1995, I pointed out to Taylor that the proof used work of Gross which was known to be incomplete.<br />
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\dots}" class="latex" title="{\dots}" /><br />
Taylor told me it was OK, because he knew another argument which avoided Gross’s work completely.
</li></ul>
</em><p><em></em>
</p></blockquote>
<p></p><p>
He also highlights the current unfinished state of the <a href="https://en.wikipedia.org/wiki/Classification_of_finite_simple_groups">classification</a> theorem. The process of writing its proof may outlive all of the first generation of provers. We at GLL have accepted it almost all of our working lives. The “after math” can be harder than the initial publication even in the traditional process, let alone the totally free dissemination we have today.</p>
<p>
Buzzard points out that some long proofs have now been written in <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> or related systems. These include the famous Feit-Thompson odd order theorem in <a href="https://coq.inria.fr">Coq</a>, and the 2017 Ellenberg-Gijswijt proof of the cap set conjecture. This shows that complex arguments can be written in systems like <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> and others. He maintains his own <a href="https://xenaproject.wordpress.com/what-is-the-xena-project/">blog</a>, “The Xena Project,” on practical and educational uses of <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> and similar software.</p>
<p>
</p><p></p><h2> Really Proved? </h2><p></p>
<p></p><p>
But there is a problem with <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> and all the other similar systems. </p>
<blockquote><p><b> </b> <em> Their correct proofs may be incorrect. </em>
</p></blockquote>
<p><img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> is a large software system and may have bugs. This is of course a major concern, but perhaps one that can be handled. Perhaps not.</p>
<p>
I thought about this issue years ago when people argued for verification of operating systems to prove that they had no errors. They wanted to argue that software systems could be error-free only by making a formal proof that they were correct. Over forty years ago, Rich DeMillo and Alan Perlis and I wrote a <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a> on this issue. Our paper starts with </p>
<blockquote><p><b> </b> <em> Many people have argued that computer programming should strive to become more like mathematics. Maybe so, but not in the way they seem to think. </em>
</p></blockquote>
<p>We go on to argue against formal verification as the answer to correctness. It is interesting to see that now the argument is flipped: Should mathematics become more like programming?</p>
<p>
Ken opines out that a bug in <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> would probably be more catchable because it would likely replicate. Mistakes in proofs ought by nature to be more recognizable than telling whether a <a href="https://leanprover.github.io/lean4/doc/tactics.html">tactic</a> to try to build a proof is likely to succeed.</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/10/the-future-of-mathematics/group_photo_leaning/" rel="attachment wp-att-17869"><img width="550" alt="" src="https://rjlipton.files.wordpress.com/2020/12/group_photo_leaning.jpeg?w=550&amp;h=150" class="wp-image-17869" height="150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Leaning Together at CMU <a href="http://www.andrew.cmu.edu/user/avigad/meetings/fomm2020/participants.html">src</a><br />
</font>
</td>
</tr>
</tbody></table>
<p></p><h2> Leaning Into <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> </h2><p></p>
<p></p><p>
The fundamental idea of <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> is to create a language that does make proofs more like programming. The key is that a proof written in <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> can be checked automatically. This is like saying that a program in Python can be executed. </p>
<p>
The project that Buzzard and others are interested in is several-fold. One is that <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> can be a teaching tool. Another is it can help us ensure that the proofs we write down are correct. </p>
<p>
The use of <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> is akin to LaTeX. Most of us now write our proofs in LaTeX or some similar typesetting language. We love and hate the issues involved in getting the LaTeX to compile and to look good. Buzzard argues that adding the new ability to be sure that one’s proof is solid is a great leap. LaTeX lets us be sure the proof looks good, while <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> allows us to be sure it is correct. </p>
<p>We have generally taken a reserved attitude toward formal methods on this blog—or maybe <a href="https://rjlipton.wordpress.com/2013/07/14/surely-you-are-joking/">not</a> so reserved. We keep our reservations expressed above. But what may help <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> overcome them is its emphasis on interaction—on being an assistant. Maybe writing a proof in <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> won’t be like taking castor oil proverbially used to be—it might be more like <a href="https://en.wikipedia.org/wiki/Marmite">Marmite</a>.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Two final thoughts. For the main one: Proofs are not as important as discoveries. Can we use <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> to suggest ideas, open problems, approaches, and more? The gene folding program we discussed recently does not claim to prove its fold is correct. But it seems useful. If <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> could help make guesses or provided intuition that would be valuable. Perhaps more valuable than assuring that a long proof is correct. </p>
<p>
Another possible idea: How about we insist that claimed proofs of P<img src="https://s0.wp.com/latex.php?latex=%7B%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{=}" class="latex" title="{=}" />NP or other famous conjectures must be presented using <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" />. The “claimed” proofs are all relatively short, so it would not be too hard for the authors of these results to write them out in the <img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> system. They already LaTeX them, so why not? This would have a double benefit: The false claims that are made about famous problems might decrease; and the chance that a correct proof would not be overlooked might increase. The cost would be the time to write up the<img src="https://s0.wp.com/latex.php?latex=L%5Cexists+%5Cforall+N&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L\exists \forall N" class="latex" title="L\exists \forall N" /> proof.</p>
<p>
Buzzard is a colorful (or colourful?) character, and may also be gaining a reputation for being well ahead of the times. In 2017 he gave a <a href="https://www.youtube.com/watch?v=jQPb7DRMoZY&amp;list=LLuXRsVD2rJdPs_rstTQZeow&amp;index=9">talk</a> on P<img src="https://s0.wp.com/latex.php?latex=%7B%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{=}" class="latex" title="{=}" />NP for the Royal Institution, but what we note in the cideo is how he was presciently dressed for Zoom.</p>
<p></p><p><br />
[some format fixes]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/12/10/the-future-of-mathematics/"><span class="datestr">at December 10, 2020 03:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20503">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/12/10/open-problem-session-of-huji-combsem-problem-2-chaya-keller-the-krasnoselskii-number/">Open problem session of HUJI-COMBSEM: Problem #2 Chaya Keller: The Krasnoselskii number</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div style="width: 650px;" class="wp-caption alignnone" id="attachment_20545"><a href="https://gilkalai.files.wordpress.com/2020/11/chaya-keller.jpg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/11/chaya-keller.jpg?w=640&amp;h=479" class="size-full wp-image-20545" height="479" /></a><p class="wp-caption-text" id="caption-attachment-20545"><span style="color: #ff0000;">Chaya Keller</span></p></div>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/11/mbreen.jpg"><img src="https://gilkalai.files.wordpress.com/2020/11/mbreen.jpg?w=640" alt="" class="alignnone size-full wp-image-20544" /></a></p>
<p><span style="color: #ff0000;">Marilyn Breen</span></p>
<p>This is our second post on the open problem session of the HUJI combinatorics seminar. <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=1ac330a2-d6b7-4b86-9bac-ac7500d14205">The video of the session is here</a>.</p>
<h2>The Krasnoselskii number</h2>
<p>One of the best-known applications of Helly’s theorem (that is, actually, equivalent to Helly’s theorem, see [Bo]) is the following theorem, due to Krasnoselskii~\cite{Krasnoselskii}:</p>
<p><strong>Theorem 1 (Krasnoselskii):</strong> Let <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> be an infinite compact set in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5Ed%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbb{R}^d}" class="latex" title="{\mathbb{R}^d}" />. If every <img src="https://s0.wp.com/latex.php?latex=%7Bd%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d+1}" class="latex" title="{d+1}" /> points of <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> are visible from a common point, then <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> is starshaped, that is there exists some <img src="https://s0.wp.com/latex.php?latex=%7Bx_0+%5Cin+S%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x_0 \in S}" class="latex" title="{x_0 \in S}" /> that sees all points in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" />.</p>
<p>Krasnoselskii’s theorem does not hold for non-compact sets. However, all known counter-examples satisfy the weaker requirement of being finitely starlike, namely that any finite subset of <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> is visible from a common point. This led Peterson [P] to ask the following:</p>
<p>Does there exist a Krasnoselskii number <img src="https://s0.wp.com/latex.php?latex=%7BK%28d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K(d)}" class="latex" title="{K(d)}" /> such that for any infinite set <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+%5Cmathbb%7BR%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S \subset \mathbb{R}^d}" class="latex" title="{S \subset \mathbb{R}^d}" />, if every <img src="https://s0.wp.com/latex.php?latex=%7BK%28d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K(d)}" class="latex" title="{K(d)}" /> points of <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> are visible from a single point, then <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> is finitely starlike?</p>
<p>Marilyn Breen obtained positive results for special cases of sets that satisfy additional topological conditions [Br1,Br2,Br3], e.g., Krasnoselskii number 3 for closed sets in the plane. On the other hand, she proved that if <img src="https://s0.wp.com/latex.php?latex=%7BK%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K(2)}" class="latex" title="{K(2)}" /> exists, then it must be larger than <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{8}" class="latex" title="{8}" />. Recently, Micha Perles and me proved that under no restriction on the set, the Krasnoselskii number does not exist. More precisely, we proved that for any <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k \geq 2}" class="latex" title="{k \geq 2}" />, there exists a set <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S \subset \mathbb{R}^2}" class="latex" title="{S \subset \mathbb{R}^2}" /> such that any <img src="https://s0.wp.com/latex.php?latex=%7B2k%2B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2k+3}" class="latex" title="{2k+3}" /> points in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> are visible from a common point, but there exist <img src="https://s0.wp.com/latex.php?latex=%7B2k%2B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2k+4}" class="latex" title="{2k+4}" /> points in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> that are not visible from a common point. But this counter example is absolutely not constructive (since it is based on a transfinite induction), and the resulting set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" title="{S}" /> admits no resonable topological structure.</p>
<p>This leads to the following two problems:</p>
<h3><span style="color: #0000ff;">Problem 1: Can you show constructively that the Krasnoselskii number does not exist?</span></h3>
<h3><span style="color: #0000ff;">Problem 2: Can you find more natural topological conditions under which the Krasnoselskii number exists?</span></h3>
<h3><span style="color: #ff0000;">References</span></h3>
<p>[Bo] Borwein, J., A proof of the equivalence of Helly’s and Krasnosselsky’s theorems,Canad. Math. Bull., 20 (1977), 35-37.</p>
<p>[Br1] M. Breen, Clear visibility, starshaped sets, and finitely starlike sets, J. of Geometry, 19 (1982), 183-196.</p>
<p>[Br2] M. Breen, Some Krasnoseleskii numbers for finitely starlike sets in the plane, J. of Geometry, 32 (1988), 1-12.</p>
<p>[Br3] M. Breen, Finitely starlike sets whose F-stars have positive measure, J. of Geometry, 35 (1989), pp.~19–25.</p>
<p>[K] M. A. Krasnoselskii, Sur un Critére pour Qu’un Domain Soit Étoilé, Math. Sb., 19 (1946), pp.309-310.</p>
<p>[P] B. Peterson, Is there a Krasnonselskii theorem for finitely starlike sets?, Convexity and Related Combinatorial Geometry, Marcel Dekker, New York, 1982, pp.81-84.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/12/10/open-problem-session-of-huji-combsem-problem-2-chaya-keller-the-krasnoselskii-number/"><span class="datestr">at December 10, 2020 11:17 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4139075556580650905">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/12/shuffling-around.html">Shuffling Around</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the fall of 1983 as a junior at Cornell I took CS 481, Introduction to the Theory of Computing, from Juris Hartmanis. Needless to say this was the course that changed my life and led me down a path that would have me teach a variation of this course myself more than twenty times.</p><p>For some reason one of the final exam questions is still stuck in my head.</p><blockquote style="border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;"><p>Let the permutation of a language L be the set of strings x such that there is a string y in L which is a permutation of the letters in x. For example perm({01},{001})={01,10,001,010,100}. </p><p>Are regular languages closed under permutations?</p></blockquote><p>There's a short and easy answer that's not so easy to find. Just in that P v NP spirit a Hartmanis test question should have. Give it a try before you read more.</p><p>If you <a href="https://www.chegg.com/homework-help/questions-and-answers/ll-shuffle-language-l-let-shuffle-l-following-language-w-x-elementof-l-w-x-w-permutation-l-q23260847">ask Chegg</a> you end up with </p><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://d2vlcm61l7u1fs.cloudfront.net/media%2F357%2F35711f1a-f8bc-490e-893d-cb13349ebfa3%2FphpMmxXRb.png"><img src="https://d2vlcm61l7u1fs.cloudfront.net/media%2F357%2F35711f1a-f8bc-490e-893d-cb13349ebfa3%2FphpMmxXRb.png" border="0" width="400" height="70" /></a></div><p>And for $15 you can get the answer. Back in 1983 we called that cheating.</p><p>The hint only works if there are regular languages whose permutations are not context free. Which is true in general but oddly enough the <a href="https://cs.stackexchange.com/questions/55507/proving-that-the-scramble-of-a-regular-language-is-context-free">permutation of every context-free language over a two-letter alphabet is context free</a>. The proof uses <a href="https://en.wikipedia.org/wiki/Parikh%27s_theorem">Parikh's theorem</a> which implies that the permutation of any context-free language is the permutation of a regular language (over any alphabet size).</p><p>Some other fun permutation questions:</p><p></p><ul style="text-align: left;"><li>Show that NP is closed under permutations.</li><li>Show that P is closed under permutations if and only if E = NE.</li><li>What about NL and L?</li></ul><div>Go ahead and chegg on those. </div><p></p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/12/shuffling-around.html"><span class="datestr">at December 09, 2020 05:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04517">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04517">A Geometric Framework for Pitch Estimation on Acoustic Musical Signals</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodman:Tom.html">Tom Goodman</a>, Karoline van Gemst, Peter Tino <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04517">PDF</a><br /><b>Abstract: </b>This paper presents a geometric approach to pitch estimation (PE)-an
important problem in Music Information Retrieval (MIR), and a precursor to a
variety of other problems in the field. Though there exist a number of
highly-accurate methods, both mono-pitch estimation and multi-pitch estimation
(particularly with unspecified polyphonic timbre) prove computationally and
conceptually challenging. A number of current techniques, whilst incredibly
effective, are not targeted towards eliciting the underlying mathematical
structures that underpin the complex musical patterns exhibited by acoustic
musical signals. Tackling the approach from both a theoretical and experimental
perspective, we present a novel framework, a basis for further work in the
area, and results that (whilst not state of the art) demonstrate relative
efficacy. The framework presented in this paper opens up a completely new way
to tackle PE problems, and may have uses both in traditional analytical
approaches, as well as in the emerging machine learning (ML) methods that
currently dominate the literature.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04517"><span class="datestr">at December 09, 2020 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04488">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04488">A Concentration Inequality for the Facility Location Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silwal:Sandeep.html">Sandeep Silwal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04488">PDF</a><br /><b>Abstract: </b>We give a concentration inequality for a stochastic version of the facility
location problem on the plane. We show the objective \[ C_n(X) = \min_{F
\subseteq [0,1]^2} \, |F| + \sum_{x\in X} \min_{f \in F} \| x-f\| \] is
concentrated in an interval of length $O(n^{1/6})$ and $\mathbb{E}[C_n] =
\Theta(n^{2/3})$ if the input $X$ consists of $n$ i.i.d. uniform points in the
unit square. Our main tool is to use a suitable geometric quantity, previously
used in the design of approximation algorithms for the facility location
problem, to analyze a martingale process.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04488"><span class="datestr">at December 09, 2020 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04437">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04437">On proof theory in computer science</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>L. Gordeev, E. H. Haeusler <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04437">PDF</a><br /><b>Abstract: </b>The subject logic in computer science should entail proof theoretic
applications. So the question arises whether open problems in computational
complexity can be solved by advanced proof theoretic techniques. In particular,
consider the complexity classes NP, coNP and PSPACE. It is well-known that NP
and coNP are contained in PSPACE, but till recently precise characterization of
these relationships remained open. Now [2], [3] (see also [4]) presented proofs
of corresponding equalities NP = coNP = PSPACE. These results were obtained by
appropriate proof theoretic tree-to-dag compressing techniques to be briefy
explained below.
</p>
<p>[2] L. Gordeev, E. H. Haeusler, Proof Compression and NP Versus PSPACE,
Studia Logica (107) (1): 55{83 (2019)
</p>
<p>[3] L. Gordeev, E. H. Haeusler, Proof Compression and NP Versus PSPACE II,
Bulletin of the Section of Logic (49) (3): 213{230 (2020)
<a href="http://dx.doi.org/10.18788/0138-0680.2020.16">this http URL</a>
</p>
<p>[4] L. Gordeev, E. H. Haeusler, Proof Compression and NP Versus PSPACE II:
Addendum, <a href="http://export.arxiv.org/abs/2011.09262">arXiv:2011.09262</a> (2020)
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04437"><span class="datestr">at December 09, 2020 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04420">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04420">Maximum Coverage with Cluster Constraints: An LP-Based Approximation Technique</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sch=auml=fer:Guido.html">Guido Schäfer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zweers:Bernard_G=.html">Bernard G. Zweers</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04420">PDF</a><br /><b>Abstract: </b>Packing problems constitute an important class of optimization problems, both
because of their high practical relevance and theoretical appeal. However,
despite the large number of variants that have been studied in the literature,
most packing problems encompass a single tier of capacity restrictions only.
For example, in the Multiple Knapsack Problem, we assign items to multiple
knapsacks such that their capacities are not exceeded. But what if these
knapsacks are partitioned into clusters, each imposing an additional capacity
restriction on the knapsacks contained in that cluster? In this paper, we study
the Maximum Coverage Problem with Cluster Constraints (MCPC), which generalizes
the Maximum Coverage Problem with Knapsack Constraints (MCPK) by incorporating
cluster constraints. Our main contribution is a general LP-based technique to
derive approximation algorithms for cluster capacitated problems. Our technique
allows us to reduce the cluster capacitated problem to the respective original
packing problem. By using an LP-based approximation algorithm for the original
problem, we can then obtain an effective rounding scheme for the problem, which
only loses a small fraction in the approximation guarantee. We apply our
technique to derive approximation algorithms for MCPC. To this aim, we develop
an LP-based $\frac12(1-\frac1e)$-approximation algorithm for MCPK by adapting
the pipage rounding technique. Combined with our reduction technique, we obtain
a $\frac13(1-\frac1e)$-approximation algorithm for MCPC. We also derive
improved results for a special case of MCPC, the Multiple Knapsack Problem with
Cluster Constraints (MKPC). Based on a simple greedy algorithm, our approach
yields a $\frac13$-approximation algorithm. By combining our technique with a
more sophisticated iterative rounding approach, we obtain a
$\frac12$-approximation algorithm for certain special cases of MKPC.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04420"><span class="datestr">at December 09, 2020 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04403">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04403">Computing the Exact Packedness of a Curve</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aghamolaei:Sepideh.html">Sepideh Aghamolaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keikha:Vahideh.html">Vahideh Keikha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghodsi:Mohammad.html">Mohammad Ghodsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohades:Ali.html">Ali Mohades</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04403">PDF</a><br /><b>Abstract: </b>A curve $P$ with $n$ vertices is said to be $c$-packed if the length of the
curve within any disk of radius $r$ is at most $cr$, for any $r&gt;0$. If the
ratio $\frac L \delta$ is fixed, where $L$ is the total length of $P$ and
$\delta$ is the minimum distance between any two points on $P$, other than the
intersection points, a $2(1+\epsilon)$-approximation algorithm exists for
disks, and a $(1+\epsilon)$-approximation algorithm exists for convex polygons,
with time complexities $O(\frac{\log (L/\delta)}{\epsilon}n^3)$ and
$O(\frac{\log (L/\delta)}{\epsilon}n^3\log n)$, respectively. Recently, two
other algorithms were claimed to be constant-factor approximations for the
$c$-packedness using axis-aligned cubes instead of disks, which only consider
the vertices of the curve when determining the $c$-packedness and therefore
contradict the original definition of the $c$-packedness that has no
assumptions on the placement of the disks. Call this measure the relative
$c$-packedness. Using an example, we show that $c$-packedness and relative
$c$-packedness are not within a constant factor of each other. We design the
first exact algorithm for computing the minimum $c$ for which a given curve $P$
is $c$-packed. Our algorithm runs in $O(n^5)$ time. Also, we show that there
are no constant-factor approximation algorithms that solve the problem in
sub-quadratic time in the worst-case and only uses intersection information to
solve the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04403"><span class="datestr">at December 09, 2020 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04400">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04400">An Answer to the Bose-Nelson Sorting Problem for 11 and 12 Channels</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jannis Harder <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04400">PDF</a><br /><b>Abstract: </b>We show that 11-channel sorting networks have at least 35 comparators and
that 12-channel sorting networks have at least 39 comparators. This positively
settles the optimality of the corresponding sorting networks given in The Art
of Computer Programming vol. 3 and closes the two smallest open instances of
the Bose-Nelson sorting problem. We obtain these bounds by generalizing a
result of Van Voorhis from sorting networks to a more general class of
comparator networks. From this we derive a dynamic programming algorithm that
computes the optimal size for a sorting network with a given number of
channels. From an execution of this algorithm we construct a certificate
containing a derivation of the corresponding lower size bound, which we check
using a program formally verified using the Isabelle/HOL proof assistant.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04400"><span class="datestr">at December 09, 2020 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04388">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04388">Algorithms for finding $k$ in $k$-means</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharyya:Chiranjib.html">Chiranjib Bhattacharyya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kannan:Ravindran.html">Ravindran Kannan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04388">PDF</a><br /><b>Abstract: </b>$k-$means Clustering requires as input the exact value of $k$, the number of
clusters. Two challenges are open: (i) Is there a data-determined definition of
$k$ which is provably correct and (ii) Is there a polynomial time algorithm to
find $k$ from data ? This paper provides the first affirmative answers to both
these questions. As common in the literature, we assume that the data admits an
unknown Ground Truth (GT) clustering with cluster centers separated. This
assumption alone is not sufficient to answer Yes to (i). We assume a novel, but
natural second constraint called no tight sub-cluster (NTSC) which stipulates
that no substantially large subset of a GT cluster can be "tighter" (in a sense
we define) than the cluster. Our yes answer to (i) and (ii) are under these two
deterministic assumptions. We also give polynomial time algorithm to identify
$k$. Our algorithm relies on NTSC to peel off one cluster at a time by
identifying points which are tightly packed. We are also able to show that our
algorithm(s) apply to data generated by mixtures of Gaussians and more
generally to mixtures of sub-Gaussian pdf's and hence are able to find the
number of components of the mixture from data. To our knowledge, previous
results for these specialized settings as well, assume generally that $k$ is
given besides the data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04388"><span class="datestr">at December 09, 2020 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04343">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04343">Reading Articles Online</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karrenbauer:Andreas.html">Andreas Karrenbauer</a>, Elizaveta Kovalevskaya <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04343">PDF</a><br /><b>Abstract: </b>We study the online problem of reading articles that are listed in an
aggregated form in a dynamic stream, e.g., in news feeds, as abbreviated social
media posts, or in the daily update of new articles on arXiv. In such a
context, the brief information on an article in the listing only hints at its
content. We consider readers who want to maximize their information gain within
a limited time budget, hence either discarding an article right away based on
the hint or accessing it for reading. The reader can decide at any point
whether to continue with the current article or skip the remaining part
irrevocably. In this regard, Reading Articles Online, RAO, does differ
substantially from the Online Knapsack Problem, but also has its similarities.
Under mild assumptions, we show that any $\alpha$-competitive algorithm for the
Online Knapsack Problem in the random order model can be used as a black box to
obtain an $(\mathrm{e} + \alpha)C$-competitive algorithm for RAO, where $C$
measures the accuracy of the hints with respect to the information profiles of
the articles. Specifically, with the current best algorithm for Online
Knapsack, which is $6.65&lt;2.45\mathrm{e}$-competitive, we obtain an upper bound
of $3.45\mathrm{e} C$ on the competitive ratio of RAO. Furthermore, we study a
natural algorithm that decides whether or not to read an article based on a
single threshold value, which can serve as a model of human readers. We show
that this algorithmic technique is $O(C)$-competitive. Hence, our algorithms
are constant-competitive whenever the accuracy $C$ is a constant.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04343"><span class="datestr">at December 09, 2020 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04327">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04327">Settling the complexity of Nash equilibrium in congestion games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Babichenko:Yakov.html">Yakov Babichenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinstein:Aviad.html">Aviad Rubinstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04327">PDF</a><br /><b>Abstract: </b>We consider (i) the problem of finding a (possibly mixed) Nash equilibrium in
congestion game, and (ii) the problem of finding an (exponential precision)
fixed point of the gradient descent dynamics of a smooth function $f:[0,1]^n
\rightarrow \mathbb{R}$. We prove that these problems are equivalent. Our
result holds for various explicit descriptions of $f$, ranging from (almost
general) arithmetic circuits, to degree-$5$ polynomials. By a very recent
result of [Fearnley, Goldberg, Hollender, Savani 2020], this implies that these
problems are PPAD$\cap$PLS-complete. As a corollary, we also obtain the
following equivalence of complexity classes: CCLS = PPAD$\cap$PLS.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04327"><span class="datestr">at December 09, 2020 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04211">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04211">Quantum Fully Homomorphic Encryption without Preprocessing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Ma:Guangsheng.html">Guangsheng Ma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Hongbo.html">Hongbo Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04211">PDF</a><br /><b>Abstract: </b>We present a novel quantum fully homomorphic encryption (QFHE) scheme. In our
scheme, any quantum circuit can be directly evaluated with no need to be
decomposed into Clifford/non-Clifford gates, or be transformed into the
real-representation frist. This advantage makes our QFHE more convenient to
evaluate the general quantum algorithms than the previous QFHE schemes.
</p>
<p>Theoretically, our main technique allows one to perform the conditional
rotation with the control bit in encrypted form. This technique builds upon a
specific kind of so-called quantum capable FHE schemes. The security of our
scheme relies on the hardness of the underlying quantum capable FHE scheme,
which bases its security on the learning with errors problem and the circular
security assumption.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04211"><span class="datestr">at December 09, 2020 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04204">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04204">On rich lenses in planar arrangements of circles and related problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ezra:Esther.html">Esther Ezra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Orit_E=.html">Orit E. Raz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharir:Micha.html">Micha Sharir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zahl:Joshua.html">Joshua Zahl</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04204">PDF</a><br /><b>Abstract: </b>We show that the maximum number of pairwise non-overlapping $k$-rich lenses
(lenses formed by at least $k$ circles) in an arrangement of $n$ circles in the
plane is $O\left(\frac{n^{3/2}\log{(n/k^3)}}{k^{5/2}} + \frac{n}{k} \right)$,
and the sum of the degrees of the lenses of such a family (where the degree of
a lens is the number of circles that form it) is
$O\left(\frac{n^{3/2}\log{(n/k^3)}}{k^{3/2}} + n\right)$. Two independent
proofs of these bounds are given, each interesting in its own right (so we
believe). We then show that these bounds lead to the known bound of Agarwal et
al. (JACM 2004) and Marcus and Tardos (JCTA 2006) on the number of point-circle
incidences in the plane. Extensions to families of more general algebraic
curves and some other related problems are also considered.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04204"><span class="datestr">at December 09, 2020 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.04090">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.04090">Almost Optimal Bounds for Sublinear-Time Sampling of $k$-Cliques: Sampling Cliques is Harder Than Counting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Talya.html">Talya Eden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ron:Dana.html">Dana Ron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosenbaum:Will.html">Will Rosenbaum</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.04090">PDF</a><br /><b>Abstract: </b>In this work, we consider the problem of sampling a $k$-clique in a graph
from an almost uniform distribution in sublinear time in the general graph
query model. Specifically the algorithm should output each $k$-clique with
probability $(1\pm \epsilon)/n_k$, where $n_k$ denotes the number of
$k$-cliques in the graph and $\epsilon$ is a given approximation parameter.
</p>
<p>We prove that the query complexity of this problem is \[
\Theta^*\left(\max\left\{ \left(\frac{(n\alpha)^{k/2}}{
n_k}\right)^{\frac{1}{k-1}} ,\; \min\left\{n\alpha,\frac{n\alpha^{k-1}}{n_k}
\right\}\right\}\right). \] where $n$ is the number of vertices in the graph,
$\alpha$ is its arboricity, and $\Theta^*$ suppresses the dependence on $(\log
n/\epsilon)^{O(k)}$. Interestingly, this establishes a separation between
approximate counting and approximate uniform sampling in the sublinear regime.
For example, if $k=3$, $\alpha = O(1)$, and $n_3$ (the number of triangles) is
$\Theta(n)$, then we get a lower bound of $\Omega(n^{1/4})$ (for constant
$\epsilon$), while under these conditions, a $(1\pm \epsilon)$-approximation of
$n_3$ can be obtained by performing $\textrm{poly}(\log(n/\epsilon))$ queries
(Eden, Ron and Seshadhri, SODA20).
</p>
<p>Our lower bound follows from a construction of a family of graphs with
arboricity $\alpha$ such that in each graph there are $n_k$ cliques (of size
$k$), where one of these cliques is "hidden" and hence hard to sample. Our
upper bound is based on defining a special auxiliary graph $H_k$, such that
sampling edges almost uniformly in $H_k$ translates to sampling $k$-cliques
almost uniformly in the original graph $G$. We then build on a known
edge-sampling algorithm (Eden, Ron and Rosenbaum, ICALP19) to sample edges in
$H_k$, where the challenge is simulate queries to $H_k$ while being given
access only to $G$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.04090"><span class="datestr">at December 09, 2020 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.03996">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.03996">Galloping in natural merge sorts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jug=eacute=:Vincent.html">Vincent Jugé</a>, Ghazal Khalighinejad <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.03996">PDF</a><br /><b>Abstract: </b>We study the algorithm TimSort and the sub-routine it uses to merge monotonic
(non-decreasing) sub-arrays, hereafter called runs. More precisely, we look at
the impact on the number of element comparisons performed of using this
sub-routine instead of a naive routine.
</p>
<p>In this article, we introduce a new object for measuring the complexity of
arrays. This notion dual to the notion of runs on which TimSort built its
success so far, hence we call it dual runs. It induces complexity measures that
are dual to those induced by runs. We prove, for this new complexity measure,
results that are similar to those already known when considering standard
run-induced measures. Although our new results do not lead to any improvement
on the number of element moves performed, they may lead to dramatic
improvements on the number of element comparisons performed by the algorithm.
</p>
<p>In order to do so, we introduce new notions of fast- and middle-growth for
natural merge sorts, which allow deriving the same upper bounds. After using
these notions successfully on TimSort, we prove that they can be applied to a
wealth of variants of TimSort and other natural merge sorts.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.03996"><span class="datestr">at December 09, 2020 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.03938">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.03938">The Local Structure of Bounded Degree Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Yossi Rozantsev <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.03938">PDF</a><br /><b>Abstract: </b>Let $G=(V,E)$ be a simple graph with maximum degree $d$. For an integer
$k\in\mathbb{N}$, the $k$-disc of a vertex $v\in V$ is defined as the rooted
subgraph of $G$ that is induced by all vertices whose distance to $v$ is at
most $k$. The $k$-disc frequency distribution vector of $G$, denoted by
$\text{freq}_{k}(G)$, is a vector indexed by all isomorphism types of rooted
$k$-discs. For each such isomorphism type $\Gamma$, the corresponding entry in
$\text{freq}_{k}(G)$ counts the fraction of vertices in $V$ that have a
$k$-disc isomorphic to $\Gamma$. In a sense, $\text{freq}_{k}(G)$ is one way to
represent the "local structure" of $G$. The graph $G$ can be arbitrarily large,
and so a natural question is whether given $\text{freq}_{k}(G)$ it is possible
to construct a small graph $H$, whose size is independent of $|V|$, such that
$H$ has a similar local structure. N. Alon proved that for any $\epsilon&gt;0$
there always exists a graph $H$ whose size is independent of $|V|$ and whose
frequency vector satisfies
$||\text{freq}_{k}(G)-\text{freq}_{k}(H)||_{1}\le\epsilon$. However, his proof
is only existential and does not imply that there is a deterministic algorithm
to construct such a graph $H$. He gave the open problem of finding an explicit
deterministic algorithm that finds $H$, or proving that no such algorithm
exists. Our main result is that Alon's problem is undecidable if and only if a
much more general problem (involving directed edges and edge colors) is
undecidable. We also prove that both problems are decidable for the special
case when $G$ is a path. We show that the local structure of any directed
edge-colored path $G$ can be approximated by a suitable fixed-size directed
edge-colored path $H$ and we give explicit bound on the size of $H$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.03938"><span class="datestr">at December 09, 2020 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-12-08-a-simple-and-succinct-zero-knowledge-proof/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-12-08-a-simple-and-succinct-zero-knowledge-proof/">A Simple and Succinct Zero Knowledge Proof</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Many people have popularized the idea that succinct proofs and zero-knowledge proofs are a type of moon math. In this post, our goal is to present a simple proof system that can provide an introduction and intuition to this space. Perhaps surprisingly, the only tool we will use is the...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-12-08-a-simple-and-succinct-zero-knowledge-proof/"><span class="datestr">at December 08, 2020 06:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/07/ram-and-vijay-shriram-data-science-fellows-at-stanford-apply-by-december-14-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/07/ram-and-vijay-shriram-data-science-fellows-at-stanford-apply-by-december-14-2020/">Ram and Vijay Shriram Data Science Fellows at Stanford (apply by December 14, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Stanford Data Science offers postdoctoral fellow positions in interdisciplinary research with expertise in both Data Science AND its application in a domain of scholarship. Application requires research plan and identifying potential faculty collaborators.</p>
<p>Hard application deadline.</p>
<p>Website: <a href="https://datascience.stanford.edu/data-science-postdocs">https://datascience.stanford.edu/data-science-postdocs</a><br />
Email: datascience@stanford .edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/07/ram-and-vijay-shriram-data-science-fellows-at-stanford-apply-by-december-14-2020/"><span class="datestr">at December 07, 2020 05:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/07/tt-faculty-junior-and-senior-at-boston-university-apply-by-december-1-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/07/tt-faculty-junior-and-senior-at-boston-university-apply-by-december-1-2020/">TT Faculty (junior and senior) at Boston University (apply by December 1, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Three searches in the new Faculty of Computational and Data Sciences (colocated with CS and Math/Stats), each with strong TCS components. Senior position in data science’s relations to societal goals, policy, ethics (in particular, accountability, fairness, trust, privacy). Junior positions related to algorithms, learning, AGT and economics, large-scale computing, human-centric computing, AI.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17169">https://academicjobsonline.org/ajo/jobs/17169</a><br />
Email: ads22@bu.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/07/tt-faculty-junior-and-senior-at-boston-university-apply-by-december-1-2020/"><span class="datestr">at December 07, 2020 04:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1444">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1444">News for November 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Highlights in property testing this month, include developments across the board. We have a nice potpourri of results which will catch your fancy. From a result which shows the tightness of quadratic gap between query complexities of adaptive vs non-adaptive testers for dense graph properties, to isoperimetric Talagrand-like inequalities for real valued functions over the hypercube, to results which consider face off between quantum computing and distribution testing and more. Looks like the festive season came early for the PTReview readers.</p>



<p></p>



<p><strong>Non-adaptive vs Adaptive Queries in the Dense Graph Testing Model</strong> (by Oded Goldreich and Avi Wigderson) (<a href="https://eccc.weizmann.ac.il/report/2020/160/">ECCC</a>) It has been long established in the dense graph property testing literature that the query complexity of adaptive testers and non-adaptive testers are only a quadratic factor apart. This work asks: is this gap necessarily tight and answers in the affirmative. The main conceptual tool used in the paper is the notion of <em>robustly self-ordered graphs</em> and <em>local self-ordering procedures</em> for these graphs (which was developed by the same authors and was covered in our <a href="https://ptreview.sublinear.info/?p=1420">September Post</a>). These results use these tools to port lower bounds on property testing problems for bit strings to graph properties.</p>



<p></p>



<p><strong>Direct Sum and Partitionability Testing over General Groups </strong>(by Andrej Bogdanov and Gautam Prakriya) (<a href="https://eccc.weizmann.ac.il/report/2020/164/">ECCC</a>)  In their celebrated work, Blum, Luby and Rubinfeld gave a four query test to determine whether a function \(f \colon \mathbb{F}_2^n \to \mathbb{F}_2\) is affine. This paper considers a generalization of the notion of affinity to functions \(f \colon \{0,1\}^n \to G\) where \(G\) is an Abelian group. The generalization sough asks: does \(f\) have the form \(f = \sum x_ig_i + g_0\) for group elements \(g_0, g_1, \cdots, g_n \in G\). In this setting, the BLR analysis does not apply as the domain and range are note equipped with the same group structure. This work presents a four query test for the above problem. In fact, the test is more general and can be used to decide whether a function \(f \colon D_1 \times D_2 \ldots \times D_n \to G\) from a product domain \(D_1 \times D_2 \ldots \times D_n\) to an Abelian group $G$ is a direct sum if it has the form \(f(x_1, x_2, \cdots, x_n) = \sum f_i(x_i)\) which resolves a conjecture of Dinur and Golubev. The work also presents results for testing whether a function \(f\) defined from a product domain to an Abelian group \(G\) is a direct product.</p>



<p></p>



<p><strong>Isoperimetric Inequalities for Real-Valued Functions with Applications to Monotonicity Testing</strong> (by Hadley Black, Iden Kalemaj and Sofya Raskhodnikova) (<a href="https://arxiv.org/pdf/2011.09441.pdf">ArXiv</a>) This paper generalizes the celebrated isoperimetric inequalities of boolean functions over the hypercube to the setting of real valued functions. This generalized isoperimetry is then put to work to obtain a monotonicity tester for \(f \colon \{0,1\}^n \to \mathbb{R}\). The tester makes \(\min(\tilde{O}(r \sqrt n), O(n))\) non-adaptive queries (where \(r\) is the size of image of \(f\)) and has one-sided error. The authors generalize the KMS inequality by a Boolean decomposition theorem which allows them to represent any real valued function over the cube as a collection of Boolean functions over the cube which capture \(f\)’s distance to montonicity as well the structure of violations to monotonicity in \(f\). </p>



<p></p>



<p><strong>Erasure-Resilient Sublinear-Time Graph Algorithms</strong> (by Amit Levi, Ramesh Krishnan S. Pallavoor, Sofya Raskhodnikova and Nithin Varma) (<a href="https://arxiv.org/pdf/2011.14291.pdf">ArXiv</a>) In a previous work, a subset of the authors explored how to equip property testers with the erasure-resilience for function properties. With graph properties, a different picture emerges. In the dense graph model, where you have query access to the adjacency matrix, the situation is <em>still</em> fine: adjacency matrices are functional representations of graphs: therefore, if you have a <em>black belt</em> in making property testers erasure resilient for function properties, you would be able to test properties of dense graphs too. However, if I give you query access to the graph through an adjacency list, the picture changes. These are non-functional representations of graphs and therefore need new conceptual tools. This paper begins the study of erasure resilience in the adjacency list model. It focuses on two computational tasks: testing connectivity and estimating average degree.  Let me showcase the results in the paper on testing connectivity. It is shown that you encounter a threshold phenomena in testing connectivity. As long as the fraction of erasures is small, you get testers which run in time independent of the size of the graph. But when the fraction of erasures exceeds a certain cutoff, it is shown that the tester needs a number of queries linear in the size of the adjacency list. </p>



<p><strong>Expander Random Walks: A Fourier Analytic Approach</strong> (by Gil Cohen, Noam Peri and Amnon Ta-Shma) (<a href="https://eccc.weizmann.ac.il/report/2020/163/">ECCC</a>) While this is a not exactly a property testing paper, how can you not report a paper which proves a significant strengthening of the classic CLT for Markov Chains (alright, for random walks on expanders) with respect to the TV distance? Let us now unpack the above a little. So, consider the following setup: Suppose you have a \(d\)-regular expander \(G\). Now, imagine running the following process \(\textsf{(P)}\):</p>



<p>1) Label half the vertices in \(G\) as \(+1\) and the other half as \(-1\) arbitrarily.<br />2) Take a \(t-1\) step random walk which involves \(t\) vertices: say \(v_1, v_2, \ldots v_t\).<br />3) Finally, return the boolean label of all of the visited vertices. This gives a bit-vector \(x \in {-1,1}^t\).</p>



<p>Now, let us ask: Which class of functions get fooled by this process?</p>



<p>The main result of the paper shows that this process fools</p>



<p>1) Symmetric functions<br />2) The class \(AC^0\)<br />3) Functions \(f\) which are computable by low width read once branching programs.</p>



<p>In more detail, let \(f\) be a symmetric function and let \(G\) be a \(\lambda\)-spectral expander. For the process \(\textsf{(P)}\) defined above, it follows by the spectral expansion of \(G\), that \(discrepancy(f) = |E_{x \sim \textsf{(P)}} [f(x)] – E_{x \sim U_t} [f(x)]|\) is small.</p>



<p>Now note that the total variation distance is precisely equal to the maximum discrepancy you get over all symmetric functions \(f\). This leads to the connection that allows the authors to upgrade CLT for expander random walks as they are able to show a CLT for Markov Chains with respect to the TV distance (as opposed to the CLT with respect to the Kolmogorov Distance which is what was known from the work of Kipnis and Vadhan since 1986).</p>



<p></p>



<p><strong>New Sublinear Algorithms and Lower Bounds for LIS Estimation</strong> (by Ilan Newman and Nithin Varma) (<a href="https://arxiv.org/pdf/2010.05805.pdf">ArXiv</a>) As the title suggests, this paper considers the task of estimating the length of the longest increasing sequence in an array. In particular, it gives a non-adaptive algorithm which estimates the LIS length within an additive error of \(\pm \varepsilon n\) in \(\tilde{O}\left(\frac{r}{\varepsilon^3}\right)\) queries (where \(r\) is the number of distinct elements in \(A\)). On the lower bound side, the paper presents a lower bound of $(\log n)^{\Omega(1/\varepsilon)}$ non-adaptive queries. The lower bound construction uses ideas from lower bound of Ben-Eliezer, Canonne, Letzter and Waingarten on testing monotone pattern freeness.</p>



<p></p>



<p><strong>Stability and testability: equations in permutations</strong> (by Oren Becker, Alexander Lubotzky, AND Jonathan Mosheiff) (<a href="https://arxiv.org/pdf/2011.05234.pdf">ArXiv</a>) Consider the following question: Suppose I ask if two permuations \(A,B \in Sym(n)\). Suppose I want to decide whether these permutations commute or whether they are far from permutations which commute. Can this question be answered in time independent of \(n\)? The authors answer this question in the affirmative. They show a simple <em>Sample and Substitute</em> procedure which essentially does the following: take samples \(x_1, x_2, cdots x_k \sim [n]\). And accept <em>iff</em> \(ABx_i = BAx_i\) for each \(i\). The authors call this particular set of equations/constraints (checking whether \(AB = BA\)) stable: as it admits a Sample and Substitute style tester with query complexity independent of \([n]\).  This allows the authors to consider the group theoretic notion of stability as a property testing concept and allows them to examine the notion of stability from a computational standpoint.   </p>



<p></p>



<p><strong>StoqMA meets distribution testing</strong> (by Yupan Liu) (<a href="https://arxiv.org/pdf/2011.05733.pdf">ArXiv</a>) This paper shows a containment result. A certain complexity class \(\textsf{eStoqMA}\) is shown to be a subset of \(\textsf{StoqMA}\). Let us informally define what these classes are. A language \(L \in \textsf{StoqMA}\) if there exists a verifier (which is a reversible quantum circuit) such that on input a string \(x\) such that for every \(x \in L\) there exists a witness quantum state which makes the verifier accept with probability at least \(2/3\). And in case \(x \not\in L\), for every quantum state the verifier rejects \(x\) with probability at least \(2/3\). The paper characterizes this class from a distribution testing point of view. And this connection allows the author to conclude that \(\textsf{eStoqMA} = \textsf{MA}\). Here, \(\textsf{eStoqMA}\) is a sub-class of \(\textsf{StoqMA}\) where all YES instances have an easy <em>witness</em>.</p>



<p></p>



<p><strong>(Edit: <em>Added later</em>)</strong> We missed the following two papers. Thanks to our readers for pointing it out.</p>



<p></p>



<p><strong>Near-Optimal Learning of Tree-Structured Distributions by Chow-Liu</strong> (by Arnab Bhattacharya, Sutanu Gayen, Eric Price and N.V. Vinodchandran) (<a href="https://arxiv.org/pdf/2011.04144.pdf">ArXiv</a>) Graphical models are a convenient way to describe high dimensional data in terms of its dependence structure. An important question in this area concerns learning/inferring the underlying graphical model from <em>iid</em> samples. This paper considers the problem when the underlying graph is in fact a tree. Thus, the challenge is to learn a tree structured distribution. The main result is that given sample access to a tree structured distribution, you can recover an \(\varepsilon\) <em>approximate</em> tree with good probability in \(O(n/\varepsilon)\).</p>



<p></p>



<p><strong>Relaxed Locally Correctable Codes with Improved Parameters</strong> (by Vahid R. Asadi and Igor Shinkar) (<a href="https://eccc.weizmann.ac.il/report/2020/142/">ECCC</a>) In their work on Robust PCPs of Proximity, Ben-Sasson et al. asked whether it is possible to obtain a \(q\)-query <em>(Relaxed)</em> Locally Decodable Code whose block length is strictly smaller than the best known bounds on block lengths for Locally Decodable Codes. Recall with relaxed LDCs you are allowed to abort outputting the \(i^{th}\) bit of the message should you detect that the received word is not a valid codeword. This paper makes progress on this problem and shows that you can actually construct an \(O(q)\)-query relaxed LDCs which encode a message of length \(k\) using \(O(k^{1 + 1/q})\) queries. This matches some of the known lower bounds for constant query LDCs which thus makes progress towards understanding the gap between LDCs and relaxed LDCs in the regime \(q = O(1)\).</p></div>







<p class="date">
by Akash <a href="https://ptreview.sublinear.info/?p=1444"><span class="datestr">at December 07, 2020 04:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5151">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5151">Shor’s algorithm in higher dimensions: Guest post by Greg Kuperberg</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Upbeat advertisement:</strong> If research in QC theory or CS theory otherwise is your thing, then wouldn’t you like to live in peaceful, quiet, <a href="https://vimeo.com/75059452" target="_blank" rel="noreferrer noopener">bicycle-based</a><a href="https://en.wikipedia.org/wiki/Davis,_California" target="_blank" rel="noreferrer noopener"> Davis, California</a>, and be a faculty member at the large, prestigious, friendly university known as <a href="https://www.ucdavis.edu/" target="_blank" rel="noreferrer noopener">UC Davis</a>? In the QCQI sphere, you’d have <a href="https://sites.google.com/site/marinaradulaski/" target="_blank" rel="noreferrer noopener">Marina Radulaski</a>, <a href="https://www.math.ucdavis.edu/~bxn/" target="_blank" rel="noreferrer noopener">Bruno Nachtergaele</a>, <a href="https://www.math.ucdavis.edu/~fraas/" target="_blank" rel="noreferrer noopener">Martin Fraas</a>, <a href="https://mukund.physics.ucdavis.edu/" target="_blank" rel="noreferrer noopener">Mukund Rangamani</a>, <a href="https://hubeny.physics.ucdavis.edu/" target="_blank" rel="noreferrer noopener">Veronika Hubeny</a>, and <a href="https://curro.ucdavis.edu/">Nick Curro</a> as faculty colleagues, among others; and <a href="https://www.math.ucdavis.edu/~greg/" target="_blank" rel="noreferrer noopener">yours truly</a>, and hopefully more people in the future. This year the UC Davis <a href="https://cs.ucdavis.edu/" target="_blank" rel="noreferrer noopener">CS department</a> has a <a href="https://recruit.ucdavis.edu/JPF03853" target="_blank" rel="noreferrer noopener">faculty opening in quantum computing</a>, and another <a href="https://recruit.ucdavis.edu/JPF03838" target="_blank" rel="noreferrer noopener">faculty opening in CS theory</a> including quantum computing. If you are interested, then time is of the essence, since the full-consideration deadline is December 15.</p>



<hr class="wp-block-separator" />



<p>In this guest post, I will toot my own horn about a paper in progress (hopefully nearly finished) that goes back to the revolutionary early days of quantum computing, namely Shor’s algorithm. <strong>The takeway: I think that the strongest multidimensional generalization of Shor’s algorithm has been missed for decades. It appears to be a new algorithm that does more than the standard generalization described by Kitaev.</strong> (Scott wanted me to channel Captain Kirk and boldly go with a takeaway, so I did.)</p>



<p>Unlike Shor’s algorithm proper, I don’t know of any dramatic applications of this new algorithm. However, more than one quantum algorithm was discovered just because it looked interesting, and then found applications later. The input to Shor’s algorithm is a function \(f:\mathbb{Z} \to S\), in other words a symbol-valued function \(f\) on the integers, which is periodic with an unknown period \(p\) and otherwise injective. In equations, \(f(x) = f(y)\) if only if \(p\) divides \(x-y\). In saying that the input is a function \(f\), I mean that Shor’s algorithm is provided with an algorithm to compute \(f\) efficiently. Shor’s algorithm itself can then find the period \(p\) in (quantum) polynomial time in the number of digits of \(p\). (Not polynomial time in \(p\), polynomial time in its logarithm.) If you’ve heard that Shor’s algorithm can factor integers, that is just one special case where \(f(x) = a^x\) mod \(N\), the integer to factor. In its generalized form, Shor’s algorithm is miraculous. In particular, if \(f\) is a black-box function, then it is routine to prove that any classical algorithm to do the same thing needs exponentially many values of \(f\), or values \(f(x)\) where \(x\) has exponentially many digits.</p>



<p>Shor’s algorithm begat the Shor-Kitaev algorithm, which does the same thing for a higher dimensional periodic function \(f:\mathbb{Z}^d \to S\), where \(f\) is now periodic with respect to a lattice \(L\). The Shor-Kitaev algorithm in turn begat the hidden subgroup problem (called HSP among friends), where \(\mathbb{Z}\) or \(\mathbb{Z}^d\) is replaced by a group \(G\), and now \(f\) is \(L\)-periodic for some subgroup \(L\). HSP varies substantially in both its computationally difficulty and its complexity status, depending on the structure of \(G\) as well as optional restrictions on \(L\).</p>



<p>A funny thing happened <s>on the way to the forum</s> in later work on HSP. Most of the later work has been in the special case that the ambient group \(G\) is finite, even though \(G\) is infinite in the famous case of Shor’s algorithm. My paper-to-be explores the hidden subgroup problem in various cases when \(G\) is infinite. In particular, I noticed that even the case \(G = \mathbb{Z}^d\) isn’t fully solved, because the Shor-Kitaev algorithm makes the extra assumption that \(L\) is a maximum-rank lattice, or equivalently that \(L\) a finite-index subgroup of \(\mathbb{Z}^d\). As far as I know, the more general case where \(L\) might have lower rank wasn’t treated previously. I found an extension of Shor-Kitaev to handle this case, which is I will sketch after discussing some points about HSP in general.</p>



<h2>Quantum algorithms for HSP</h2>



<p>Every known quantum algorithm for HSP has the same two opening steps. First prepare an equal superposition \(|\psi_G\rangle\) of “all” elements of the ambient group \(G\), then apply a unitary form of the hiding function \(f\) to get the following: \[ U_f|\psi_G\rangle \propto \sum_{x \in G} |x,f(x)\rangle. \] Actually, you can only do exactly this when \(G\) is a finite group. You cannot make an equal quantum superposition on an infinite set, for the same reason that you cannot choose an integer uniformly at random from among all of the integers: It would defy the laws of probability. Since computers are finite, a realistic quantum algorithm cannot make an unequal quantum superposition on an infinite set either. However, if \(G\) is a well-behaved infinite group, then you can approximate the same idea by making an equal superposition on a large but finite box \(B \subseteq G\) instead: \[ U_f|\psi_G\rangle \propto \sum_{x \in B \subseteq G} |x,f(x)\rangle. \] Quantum algorithms for HSP now follow a third counterintuitive “step”, namely, that you should discard the output qubits that contain the value \(f(x)\). You should take the values of \(f\) to be incomprehensible data, encrypted for all you know. A good quantum algorithm evaluates \(f\) too few times to interpret its output, so you might as well let it go. (By contrast, a classical algorithm is forced to dig for the only meaningful information that the output of \(f\) to have. Namely, it has to keep searching until it finds equal values.) What remains, want what turns out to be highly valuable, is the input state in a partially measured form. I remember joking with <a href="http://tuvalu.santafe.edu/~moore/" target="_blank" rel="noreferrer noopener">Cris Moore</a> about the different ways of looking at this step:</p>



<ol><li>You can measure the output qubits.</li><li>The janitor can fish the output qubits out of the trash and measure them for you.</li><li>You can secretly not measure the output qubits and say you did.</li><li>You can keep the output qubits and say you threw them away.</li></ol>



<p>Measuring the output qubits wins you the purely mathematical convenience that the posterior state on the input qubits is pure (a vector state) rather than mixed (a density matrix). However, since no use is made of the measured value, it truly makes no difference for the algorithm.</p>



<p>The final universal step for all HSP quantum algorithms is to apply a quantum Fourier transform (or QFT) to the input register and measure the resulting Fourier mode. This might seem like a creative step that may or may not be a good idea. However, if you have an efficient algorithm for the QFT for your particular group \(G\), then you might as well do this, because (taking the interpretation that you threw away the output register) the environment already knows the Fourier mode. You can assume that this Fourier mode has been published in the New York Times, and you won’t lose anything by reading the papers.</p>



<h2>Fourier modes and Fourier stripes</h2>



<p>I’ll now let \(G = \mathbb{Z}^d\) and make things more explicit, for starters by putting arrows on elements \(\vec{x} \in \mathbb{Z}^d\) to indicate that they are lattice vectors. The standard begining produces a superposition \(|\psi_{L+\vec{v}}\rangle\) on a translate \(L+\vec{v}\) of the hidden lattice \(L\). (Again, \(L\) is the periodicity of \(f\).) If this state could be an equal superposition on the infinite set \(L+\vec{v}\), and if you could do a perfect QFT on the infinite group \(\mathbb{Z}^d\), then the resulting Fourier mode would be a randomly chosen element of a certain dual group \(L^\# \subseteq (\mathbb{R}/\mathbb{Z})^d\) inside the torus of Fourier modes of \(\mathbb{Z}^d\). Namely, \(L^\#\) consists of those vectors \(\vec{y} \in (\mathbb{R}/\mathbb{Z})^d\) whose such that the dot product \(\vec{x} \cdot \vec{y}\) is an integer for every \(\vec{x} \in L\). (If you expected the Fourier dual of the integers \(\mathbb{Z}\) to be a circle \(\mathbb{R}/2\pi\mathbb{Z}\) of length \(2\pi\), I found it convenient here to rescale it to a circle \(\mathbb{R}/\mathbb{Z}\) of length 1. This is often considered gauche these days, like using \(h\) instead of \(\hbar\) in quantum mechanics, but in context it’s okay.) In principle, you can learn \(L^\#\) from sampling it, and then learn \(L\) from \(L^\#\). Happily, the unknown and irrelevant translation vector \(\vec{v}\) is erased in this method.</p>



<p>In practice, it’s not so simple. As before, you cannot actually make an equal superposition on all of \(L+\vec{v}\), but only trimmed to a box \(B \subseteq \mathbb{Z}^d\). If you have \(q\) qubits available for each coordinate of \(\mathbb{Z}^d\), then \(B\) might be a \(d\)-dimensional cube with \(Q = 2^q\) lattice points in each direction. Following Peter Shor’s famous paper, the standard thing to do here is to identify \(B\) with the finite group \((\mathbb{Z}/Q)^d\) and do the QFT there instead. This is gauche as pure mathematics, but it’s reasonable as computer science. In any case, it works, but it comes at a price. You should rescale the resulting Fourier mode \(\vec{y} \in (\mathbb{Z}/Q)^d\) as \(\vec{y}_1 = \vec{y}/Q\) to match it to the torus \((\mathbb{R}/\mathbb{Z})^d\). Even if you do that, \(\vec{y}_1\) is not actually a uniformly random element of \(L^\#\), but rather a noisy, discretized approximation of one.</p>



<p>In Shor’s algorithm, the remaining work is often interpreted as the post-climax. In this case \(L = p\mathbb{Z}\), where \(p\) is the hidden period of \(f\), and \(L^\#\) consists of the multiples of \(1/p\) in \(\mathbb{R}/\mathbb{Z}\). The Fourier mode \(y_1\) (skipping the arrow since we are in one dimension) is an approximation to some fraction \(r/p\) with roughly \(q\) binary digits of precision. (\(y_1\) is often but not always the very best binary approximation to \(r/p\) with the available precision.) If you have enough precision, you can learn a fraction from its digits, either in base 2 or in any base. For instance, if I’m thinking of a fraction that is approximately 0.2857, then 2/7 is much closer than any other fraction with a one-digit denominator. As many people know, and as Shor explained in his paper, continued fractions are an efficient and optimal algorithm for this in larger cases.</p>



<p>The Shor-Kitaev algorithm works the same way. You can denoise each coordinate of each Fourier example \(\vec{y}_1\) with the continued fraction algorithm to obtain an exact element \(\vec{y}_0 \in L^\#\). You can learn \(L^\#\) with a polynomial number of samples, and then learn \(L\) from that with integer linear algebra. However, this approach can only work if \(L^\#\) is a finite group, or equivalently when \(L\) has maximum rank \(d\). This condition is explicitly stated in Kitaev’s paper, and in most but not all of the papers and books that cite this algorithm. if \(L\) has maximum rank, then the picture in Fourier space looks like this: </p>



<figure class="wp-block-image"><a href="https://www.scottaaronson.com/f1-torus.png"><img src="https://www.scottaaronson.com/f1-torus.png" alt="" /></a></figure>



<p>However, if \(L\) has rank \(\ell &lt; d\), then \(L^\#\) is a pattern of \((k-\ell)\)-dimensional stripes, like this instead: </p>



<figure class="wp-block-image"><a href="https://www.scottaaronson.com/f2-torus.png"><img src="https://www.scottaaronson.com/f2-torus.png" alt="" /></a></figure>



<p>In this case, as the picture indicates, each coordinate of \(\vec{y}_1\) is flat random and individually irreparable. If you knew the direction of the stripes, then you use could define a slanted coordinate system where some of the coordinates of \(\vec{y}_1\) could be repaired. But the tangent directions of \(L^\#\) essentially beg the question. They are the orthogonal space of \(L_\mathbb{R}\), the vector space subtended by the hidden subgroup \(L\). If you know \(L_\mathbb{R}\), then you can find \(L\) by running Shor-Kitaev in the lattice \(L_\mathbb{R} \cap \mathbb{Z}^d\).</p>



<p>My solution to this conundrum is to observe that the multiples of a randomly chosen point \(\vec{y}_0\) in \(L^\#\) have a good chance of filling out \(L^\#\) adequately well, in particular to land near \(\vec{0}\) often enough to reveal the tangent directions of \(L^\#\). You have to make do with a noisy sample \(\vec{y}_1\) instead, but by making the QFT radix \(Q\) large enough, you can reduce the noise well enough for this to work. Still, even if you know that these small, high-quality multiples of \(\vec{y}_1\) exist, they are needles in an exponential haystack of bad multiples, so how do you find them? It turns out that the versatile LLL algorithm, which finds a basis of short vectors in a lattice, can be used here. The multiples of \(\vec{y}_0\) (say, for simplicity) aren’t a lattice, they are a dense orbit in \(L^\#\) or part of it. However, they are a shadow of a lattice one dimension higher, that you can supply to the LLL algorithm. This step produces lets you compute the linear span \(L_\mathbb{R}\) of \(L\) from its perpendicular space, and then as mentioned you can use Shor-Kitaev to learn the exact geometry of \(L\).</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5151"><span class="datestr">at December 07, 2020 06:14 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3063488709598214165">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/12/in-1974-planarity-was-ov-time-and-could.html">In 1974 Planarity was O(V) time and could do 900 node graphs in 12 seconds! Fast then...</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In 1974  Hopcroft and Tarjan showed that Planarity is in polynomial time. That is an understatement- they actually have an O(V) algorithm which one can actually code up. See their paper <a href="https://dl.acm.org/doi/pdf/10.1145/321850.321852">here</a>.</p><p>It has the curious line:</p><p><br /></p><p><i>An Algol implementation of the algorithm successfully tested graphs with as many as 900 vertices in less than 12 seconds.</i></p><p>900 nodes in 12 second was fast then but it slow now. </p><p>1) How would their algorithm do on todays machines? How does that compare to what Moore's law (for time) would have predicted? Can this help us determine an x such that Moore's law stopped working at year x. I've  heard various candidates for x including the notion that the death of Moore's law has been greatly exaggerated. Moore himself is still alive, at the age of 91. </p><p>2) Are there better algorithms now? Nothing can beat O(V); however, is there an algorithm  with a better constant? </p><p>3) Is there a modern implementation of it (or perhaps even an old implementation run on a modern machine)? If so, how fast does it run on 900 nodes? 9000 nodes? 90,000 nodes? 900,000 nodes? Not sure where to stop.</p><p>4) The people in the real world who really need to solve this problem fast: (a) do they exist, and (b) if they do exist then what do they use? </p><p><br /></p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/12/in-1974-planarity-was-ov-time-and-could.html"><span class="datestr">at December 07, 2020 02:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/12/06/long-countours-chessboard">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/12/06/long-countours-chessboard.html">Long contours and chessboard coloring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The image below is a topographic map of some parkland a couple miles from my house, clipped from <a href="https://opentopomap.org/#map=15/33.61985/-117.77702">opentopomap.org</a>.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/BommerCanyon.jpg" alt="Topographic map of Bommer Canyon, Irvine, from opentopomap.org" /></p>

<p>Here’s another picture of the same place that I took <a href="http://www.ics.uci.edu/~eppstein/pix/vvbc/">a few years ago</a>.</p>

<p style="text-align: center;"><img src="https://www.ics.uci.edu/~eppstein/pix/vvbc/MustardMeadow-m.jpg" alt="Bommer Canyon, Irvine" /></p>

<p>It’s pretty hilly there, as you can tell from the brown <a href="https://11011110.github.io/blog/2020/12/06/Contour line">contour lines</a> on the map, sets of points that are all at the same height as each other. Some contours are short closed curves. Typically these surround hilltops, although they could also mark basins in the landscape; it’s dry enough here that a basin wouldn’t necessarily stay filled with rainwater. Others wiggle around for quite a long distance before escaping the map and connecting to its surrounding regions. Some of them (including the darker brown curve surrounding a pair of hilltops in the upper left of the map) look like they cross or touch themselves at a saddle point of the landscape. This kind of point, where four or more branches of a contour meet, can indeed happen for a contour at the exact height of a saddle point, but a closeup inspection of the upper left one reveals that it has slightly lower height and is actually a single simple closed curve around both hills. It is also possible for contours to reach a dead end (for instance when they follow the top of a level ridgeline) or for an odd number of branches to meet at a junction.</p>

<p>It turns out that every possible landscape has a contour that stretches from one edge of the map to the opposite edge. To state this more precisely and avoid fractal difficulties, let’s model the landscape as a <a href="https://en.wikipedia.org/wiki/Polyhedral_terrain">polyhedral terrain</a> or <a href="https://en.wikipedia.org/wiki/Triangulated_irregular_network">triangulated irregular network</a>, the graph of a piecewise-linear continuous function from a planar polygon \(p\) to the height at each point. Its <a href="https://en.wikipedia.org/wiki/Level_set">level sets</a> are inverse images of heights, and its contours are connected components of level sets. They might not actually be curves or lines; for instance a level plain in the landscape would belong to a single contour. Every contour touches the boundary of \(P\) in a (possibly empty) set of points, dividing the boundary into arcs. Then the existence of a long contour can be stated more explicitly: there is a contour such that all of these arcs have length at most half the perimeter of \(P\). If \(P\) is a rectangle or square, this long contour touches two opposite sides, possibly at their endpoints, because avoiding both a horizontal side and a vertical side would cause the arc containing those sides to be too long.</p>

<p>The proof sketch is not particularly difficult but I’ve indented it below so you can skip over it anyway:</p>

<p style="padding-left: 40px;">Start with the contour containing an arbitrary boundary point, and suppose that it doesn’t immediately solve the problem. This means that there is an arc (and there can be only one) between two of its boundary points (say clockwise from \(x\) to \(y\)) that covers more than half of the perimeter of \(P\). Now consider what happens if you move clockwise continuously from \(x\) to some point \(x'\), and then walk along a contour from \(x'\) (staying to the left whenever you have a choice) to reach another boundary point \(y'\). Then \(y'\), wherever it is, must be within the arc from \(x\) to \(y\), because the two contours cannot cross, so the arc from \(x'\) to \(y'\) is shorter than the arc from \(x\) to \(y\). As we move \(x'\) continuously away from \(x\), the position of \(y'\) moves continuously in the other direction away from \(y\), except at points when the contour passes through a vertex of the landscape; at those points the contour can change its shape discontinuously and \(y'\) can jump discontinuously. But regardless of whether \(y'\) changes continuously or jumps, the length of the arc from \(x'\) to \(y'\) decreases as \(x'\) and \(y'\) move towards each other until eventually they cross.</p>

<p style="padding-left: 40px;">At some point before they do cross, one of two other things must happen. Either the length of arc \(x'y'\) decreases continuously through half the perimeter, or it jumps from being larger than half the perimeter to being smaller than half the perimeter. If it decreases continuously through half the perimeter, the contour containing the points \(x'\) and \(y'\) at the time that it reaches exactly half the perimeter has the desired property. If it jumps, consider the contour \(C\) exactly at the point when it jumps. If \(C\) has the desired property, we are done. Alternatively, there might still be a long boundary arc \(uv\) for \(C\), nested within the pre-jump arc \(x'y'\), and we can continue the same process from there until eventually terminating in one of the other cases.</p>

<p style="padding-left: 40px;">(Exercise: Use this method to find a long contour in the topographic map.)</p>

<p>That was all very continuous and topological but I actually came to this problem from something much more discrete: If you color the squares of a chessboard with three colors, must there be some two of the three colors whose squares stretch all the way across the board, touching edge to edge? In contrast, with four colors you can make colorings where all two-color regions are small:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/plaid.svg" alt="4-coloring of grid squares so that 2-colored regions are all small" /></p>

<p>The four-coloring above is <em>proper</em> (no two adjacent squares have the same color) and I can use contours prove that every proper three-coloring has a two-colored region that stretches across the board.</p>

<p>The idea is, first, to turn any three-coloring of the chessboard squares into a discrete height function, one that takes integer values on each square and where these values differ by \(\pm 1\) on adjacent squares, so that the coloring can be recovered by taking the heights modulo three. I discussed this briefly in an <a href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html">earlier post about reconfiguring Miura-folded origami</a>, with the following example:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/heightfn.svg" alt="Height function of a proper 3-coloring of a square grid" /></p>

<p>It doesn’t look very continuous, but we can make it continuous by using these height values only for the middle points of the squares. At each corner point where two or four squares come together, set the height value to be the average of the heights of the squares that meet there. Divide each square into four isosceles right triangles, meeting at the center of the square, and interpolate these height values linearly within each triangle. Then, find a long contour for the resulting polyhedral terrain. If the long contour is at an integer height, it can be turned into an edge-to-edge sequence of squares using that height and either one of the two neighboring integer heights. If the long contour is at a non-integer height, it can be turned into an edge-to-edge sequence of squares using the integer heights closest to it above and below that height. The image below shows the integer and half-integer contours of the same grid 3-coloring, with the long contour through the large red-yellow region shown in bold. The crosshatched regions are level shelves in the surface, and the black dots are peaks and basins.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/checkerboard-topo.svg" alt="Topographic map of height function derived from proper 3-coloring of a square grid" /></p>

<p>Sadly, the same argument doesn’t work for improper three-colorings, because they don’t usually have height functions. More strongly, the property that we want to prove, the existence of large two-colored regions, is just not true of improper colorings. The improper coloring below can be extended to arbitrarily large chessboards, with all two-colored regions having at most 13 squares:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/plaid2.svg" alt="Improper 3-coloring of grid squares so that 2-colored regions are all small" /></p>

<p>(<a href="https://mathstodon.xyz/@11011110/105335210914176059">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/12/06/long-countours-chessboard.html"><span class="datestr">at December 06, 2020 12:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/183">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/183">TR20-183 |  Constant Depth Formula and Partial Function Versions of MCSP are Hard | 

	Rahul Ilango</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Attempts to prove the intractability of the Minimum Circuit Size Problem (MCSP) date as far back as the 1950s and are well-motivated by connections to cryptography, learning theory, and average-case complexity. In this work, we make progress, on two fronts, towards showing MCSP is intractable under worst-case assumptions. 


While Masek showed in the late 1970s that the version of MCSP for DNF formulas is NP-hard, extending this result to the case of depth-$3$ AND/OR formulas was open.  We show that determining the minimum size of a depth-$d$ formula computing a given Boolean function is NP-hard under quasipolynomial-time randomized reductions for all constant $d \geq 2$. Our approach is based on a method to "lift" depth-$d$ formula lower bounds to depth-$(d+1)$. This method also implies the existence of a function with a $2^{\Omega_d(n)}$ additive gap between its depth-$d$ and depth-$(d+1)$ formula complexity.


We also make progress in the case of general, unrestricted circuits. We show that the version of MCSP where the input is a partial function (represented by a string in $\{0,1,\star\}^*$) is not in P under the Exponential Time Hypothesis (ETH).


Intriguingly, we formulate a notion of lower bound statements being $(P/poly)$-recognizable that is closely related to Razborov and Rudich's definition of being $(P/poly)$-constructive. We show that unless there are subexponential-sized circuits computing SAT, the collection of lower bound statements used to prove the correctness of our reductions cannot be $(P/poly)$-recognizable.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/183"><span class="datestr">at December 06, 2020 02:49 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20557">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/">Photonic Huge Quantum Advantage ???</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This is a quick and preliminary post about a very recent announcement in a Science Magazine paper: <a href="https://science.sciencemag.org/content/early/2020/12/02/science.abe8770">Quantum computational advantage using photons</a> by a group of researchers leaded by <a href="https://en.wikipedia.org/wiki/Pan_Jianwei">Jianwei Pan</a> and <a href="https://twitter.com/chaoyanglu?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Chao-Yang Lu.</a> (Most of the researchers are from USTC in Hefei, China.)</p>
<p>The paper announces achieving  quantum advantage (aka “quantum supremacy”) using photonic implementation of BosonSampling.  (I heard about it from a <a href="https://www.scottaaronson.com/blog/?p=5122">SO post</a> that contains further links.) The claimed advantage is huge and clearly I will have to look carefully at the results, the data, and the interpretation. The idea that this could be done was raised ten years ago by Aaronson and Arkhipov and we discussed it in <a href="https://gilkalai.wordpress.com/2010/11/17/aaronson-and-arkhipovs-result-on-hierarchy-collapse/">here</a> and in several other posts along with the idea that it<em> cannot</em> be done.</p>
<p>Boson Sampling was studied in a 2014 paper by Guy Kindler and me <a href="https://arxiv.org/abs/1409.3093" rel="nofollow ugc">Gaussian Noise Sensitivity and BosonSampling</a>. Our paper and the connection with noise sensitivity and the Fourier description is the basis for <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwii7ure67ftAhVDhqQKHRMsCyoQFjACegQIAhAC&amp;url=https%3A%2F%2Fwww.ams.org%2Fnotices%2F201605%2Frnoti-p508.pdf&amp;usg=AOvVaw3S3tSldRaLR6RwskAYwLUo">my argument</a> against quantum computers.  Of course, a demonstration of a huge quantum advantage, as claimed in the new paper, if valid, would refute my theory.</p>
<p>The crux of the matter is if the statistical performance of the photonic samples produced in the experiment could be achieved by classical sampling. (This is referred to as “spoofing.”) My paper with Guy proposes a very simple way to try to do it based  on the low degree Hermite-Fourier truncation of the Boson Sampling distribution.</p>
<p>The easiest way to implement it is as follows: Given an n by m matrix you draw (with the appropriate weights based on repeated columns) at random n by n minor M (with repeated columns), then compute the degree k approximation X to the |permanent(M)|^2, (based on formula (8) from our paper) and then take the sample with probability according to the value of X and toss it away otherwise. This may work even for degree-2 truncation. (Rather than the straight truncation we can also try the “Beckner-noise” version but I don’t think this will make much difference.)</p>
<p>Since my paper with Guy Kindler offers “off the shelf” classic algorithm that may “spoof” the claims I propose to test it. (And I am a little surprised that this was not tried already.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/12/bosonsampling.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/12/bosonsampling.png?w=640&amp;h=384" class="alignnone size-full wp-image-20563" height="384" /></a></p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/12/06/photonic-huge-quantum-advantage/"><span class="datestr">at December 05, 2020 10:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/182">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/182">TR20-182 |  An Improved Derandomization of the Switching Lemma | 

	Zander Kelley</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove a new derandomization of Håstad's switching lemma, showing how to efficiently generate restrictions satisfying the switching lemma for DNF or CNF formulas of size $m$ using only $\widetilde{O}(\log m)$ random bits. Derandomizations of the switching lemma have been useful in many works as a key building-block for constructing objects which are in some way provably-pseudorandom with respect to AC$^0$-circuits.

Here, we use our new derandomization to give an improved analysis of the pseudorandom generator of Trevisan and Xue for AC$^0$-circuits (CCC'13): we show that  the generator $\varepsilon$-fools size-$m$, depth-$D$ circuits with $n$-bit inputs using only $\widetilde{O}(\log(m/\varepsilon)^{D} \cdot \log n)$ random bits. In particular, we obtain (modulo the $\log \log$-factors hidden in the $\widetilde{O}$-notation) a dependence on $m/\varepsilon$ which is best-possible with respect to currently-known AC$^0$-circuit lower bounds.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/182"><span class="datestr">at December 04, 2020 08:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/181">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/181">TR20-181 |  Monotone Circuit Lower Bounds from Robust Sunflowers | 

	Bruno Pasqualotto Cavalar, 

	Mrinal Kumar, 

	Benjamin Rossman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Robust sunflowers are a generalization of combinatorial sunflowers that have applications in monotone circuit complexity, DNF sparsification, randomness extractors, and recent advances on the Erd\H{o}s-Rado sunflower conjecture.  The recent breakthrough of Alweiss, Lovett, Wu and Zhang gives an improved bound on the maximum size of a $w$-set system that excludes a robust sunflower.  In this paper, we use this result to obtain an $\exp(n^{1/2-o(1)})$ lower bound on the monotone circuit size of an explicit $n$-variate monotone function, improving the previous best known $\exp(n^{1/3-o(1)})$ due to Andreev and Harnik and Raz. We also show an $\exp(\Omega(n))$ lower bound on the monotone arithmetic circuit size of a related polynomial.  Finally, we introduce a notion of robust clique-sunflowers and use this to prove an $n^{\Omega(k)}$ lower bound on the monotone circuit size of the CLIQUE function for all $k \le n^{1/3-o(1)}$, strengthening the bound of Alon and Boppana.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/181"><span class="datestr">at December 04, 2020 07:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/04/harvard-quantum-initiative-postdocoral-fellowship-at-harvard-apply-by-december-4-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/04/harvard-quantum-initiative-postdocoral-fellowship-at-harvard-apply-by-december-4-2020/">Harvard Quantum Initiative postdocoral fellowship at Harvard (apply by December 4, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>(Soft deadline but please apply as soon as you can)</p>
<p>2 year fellowship with possiblity of 3rd year extention.</p>
<p>Applications focused on collaborative and cross-disciplinary research are especially encouraged.</p>
<p>Competitive annual salary, discretionary funds to support their research, and access to opportunities such as lunches with visiting speakers and access to research seed funding.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/fellowship/17462">https://academicjobsonline.org/ajo/fellowship/17462</a><br />
Email: ann_quaicoe@fas.harvard.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/04/harvard-quantum-initiative-postdocoral-fellowship-at-harvard-apply-by-december-4-2020/"><span class="datestr">at December 04, 2020 07:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4430">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/">Keith Ball on Bourgain’s Legacy in Geometric Functional Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Bulletin of the AMS has just posted an <a href="https://www.ams.org/journals/bull/0000-000-00/S0273-0979-2020-01719-2/S0273-0979-2020-01719-2.pdf">article by Keith Ball</a> on the legacy of Bourgain’s work on geometric functional analysis. </p>

<p></p>

<p>
This beautifully written article talks about results and conjectures that are probably familiar to readers of <i>in theory</i>, but from the perspective of their mathematical motivations and of the bigger picture in which they fit.</p>



<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/"><span class="datestr">at December 04, 2020 01:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/">PhD positions  at International Max Planck Research School on Trustworthy Computing (apply by December 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de/">https://www.imprs-trust.mpg.de/</a><br />
Email: imprs@mpi-klsb.mpg.de</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/"><span class="datestr">at December 04, 2020 12:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7948">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/">Obfuscation: The season 4 Finale</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p></p>



<p>For many of the famous open problems of theoretical computer science, most researchers agree on what the answer is, but the challenge is to <em>prove </em>it. Most complexity theorists (with few notable exceptions) believe that P≠NP, but we don’t know how to prove it. Similarly, most people working on matrix multiplication believe that there is an Õ(n²) algorithm for this problem, but we’re still stuck at <a href="https://arxiv.org/abs/2010.05846">2.3728596</a>.   We believed that primality checking has a deterministic polynomial-time algorithm long before it was <a href="https://en.wikipedia.org/wiki/AKS_primality_test">proven </a>and we still believe the same holds for polynomial identity testing.</p>



<p>The story of <em>cryptographic obfuscation</em> is different. This story deserves a full length blog post (though see my now outdated <a href="https://cacm.acm.org/magazines/2016/3/198855-hopes-fears-and-software-obfuscation/fulltext">survey</a>), but the short version is as follows. In 2001 we (in a <a href="http://www.wisdom.weizmann.ac.il/~oded/p_obfuscate.html">paper </a>with Goldreich, Impagliazzo, Rudich, Sahai, Vadhan, and Yang) showed that what is arguably the most natural definition of obfuscation is impossible to achieve. That paper explored a number of obfuscation-related questions, and in particular left as an open question the existence of so-called <em>indistinguishable obfuscators</em> or <em>IO</em>. Since then there were arguably more negative than positive results in obfuscation research until in 2012, extending some of the ideas behind fully-homomorphic encryption, <a href="https://eprint.iacr.org/2012/610">Garg Gentry and Halevi</a> gave a heuristic construction of multilinear map, which one can think of as “Diffie Hellman on steroids” (or maybe LSD..). Then in 2013 <a href="https://eprint.iacr.org/2013/451">Garg, Gentry, Halevi., Raykova, Sahai and Waters (GGHRSW)</a> built on top of these maps to give a heuristic construction of IO. </p>



<p>The GGHRSW paper opened the floodgates to many papers using IO to achieve many longstanding cryptographic goals as well as show that IO provides a unified approach to solve many classic cryptographic problems. The fact that so many goals were achieved through heuristic constructions was not very comforting to cryptographers. Even less comforting was the fact that several cryptographic attacks were discovered on these heuristic constructions. The years that followed saw a sequence of constructions and breaks,  giving cryptographers an “emotional whiplash”.  Everyone agreed that IO would be amazing if it exists, but whether or not it actually exists depended on who you asked, and what paper in the eprint archive they read that morning…</p>



<p>The “holy grail” in this line of work is to base obfuscation on a standard assumption, and ideally Regev’s <a href="https://en.wikipedia.org/wiki/Learning_with_errors">Learning With Errors (LWE)</a> assumption. Of course, we don’t know that LWE is true (in particular LWE implies P≠NP) but if it’s false it would bring down so much of the field that cryptographers might as well pack their bags and do machine learning (or try to sabotage progress in quantum computing, since the only other standard <a href="https://eprint.iacr.org/2017/365">assumptions for public-key crypto</a> are broken by fully scalable quantum computing).</p>



<p>We have not yet achieved this holy grail (this is only the 4th season) but as described in <a href="https://www.quantamagazine.org/computer-scientists-achieve-crown-jewel-of-cryptography-20201110/">this quanta article</a>, there has been a remarkable progress in the last few months. In particular, <a href="https://eprint.iacr.org/2020/1003">Jain, Lin and Sahai (JLS)</a>  (building on a long sequence of works by  many people including Ananth, Matt, Tessaro and Vaikuntanathan) obtained IO based on LWE and several standard assumptions in cryptography. This is arguably the first “heuristic free” construction, and is a fantastic breakthrough. However, there is still work to do – the JLS construction uses not just LWE but also a variant of it that is not as well studied. It is also based on pairing-based cryptography. This is an area that has thousands of papers, but for which known instantiations can be broken by quantum computers.  However, there is yet more hope – in another  sequence of works by <a href="https://eprint.iacr.org/2018/633">Agrawal</a>, <a href="https://eprint.iacr.org/2020/1024">Brakerski, Döttling, Garg, and Malavolta</a>, <a href="https://eprint.iacr.org/2020/1042">Wee and Wichs</a>, <a href="https://eprint.iacr.org/2020/1010">Gay and Pass</a> a construction of IO was achieved that is “almost” heuristic free. It still uses one heuristic assumption (circular security) but has the advantage that apart from this assumption it only relies on LWE. </p>



<p>One can hope that in the next season, these two lines of work will converge to give a construction of IO based on LWE, achieving a “meta theorem” deriving from LWE a huge array of cryptographic primitives.</p>



<p>Want to learn more about these amazing advances? Want to know what’s next in store for IO? <br /><br />Fortunately there is a virtual <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">Simons symposium on indistinguishability obfuscation</a> <strong>coming to your computer screen on December 10-11</strong>. Authors of all the papers mentioned will join together in coordinated presentations to give a unified view of the field and the challenges ahead. We will also have a historical opening talk by Yael Kalai, as well as a talk by Benny Applebaum on the computational assumptions used, followed by a panel discussion with Yael, Benny and Chris Peikert. Finally, like every proper crypto event, there will be a rump session, though you will have to supply your own beer.</p>



<p>See the <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">schedule of the workshop</a> and you can register on <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">this page</a>.</p>



<p>Hope you to see you there! Bring your favorite programs to obfuscate with you*<br /><br />*<sub>Disclaimer/fine print: Due to large constants and exponents, we do not recommend the compiler be used on programs that are more than one nanobit long.</sub></p>



<p>Image credit: <a href="https://news.mit.edu/2015/secure-foundation-any-cryptographic-system-1028">MIT</a></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/"><span class="datestr">at December 04, 2020 12:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5122">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5122">Quantum supremacy, now with BosonSampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong><span class="has-inline-color has-vivid-red-color">Update (12/5):</span></strong> The Google team, along with Gil Kalai, have raised questions about whether the results of the new BosonSampling experiment might be easier to spoof classically than the USTC team thought they were, because of a crucial difference between BosonSampling and qubit-based random circuit sampling.  Namely, with random circuit sampling, the marginal distribution over any k output qubits (for small k) is exponentially close to the uniform distribution.  With BosonSampling, by contrast, the marginal distribution over k output modes is <em>distinguishable</em> from uniform, as Arkhipov and I noted in a <a href="https://arxiv.org/abs/1309.7460">2013 followup paper</a>.  On the one hand, these easily-detected nonuniformities provide a quick, useful sanity check for whether BosonSampling is being done correctly.  On the other hand, they <em>might</em> also give classical spoofing algorithms more of a toehold.  The question is whether, by spoofing the k-mode marginals, a classical algorithm could also achieve scores on the relevant “HOG” (Heavy Output Generation) benchmark that are comparable to what the USTC team reported.</p>



<p>One way or the other, this question should be resolvable by looking at the data that’s already been collected, and we’re trying now to get to the bottom of it.  And having failed to flag this potential issue when I reviewed the paper, I felt a moral obligation at least to let my readers know about it as soon as I did.  If nothing else, this is an answer to those who claim this stuff is all obvious.  Please pardon the science underway!</p>



<p></p><hr /><p></p>



<p>A group led by <a href="https://en.wikipedia.org/wiki/Pan_Jianwei">Jianwei Pan</a> and <a href="https://twitter.com/chaoyanglu?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Chao-Yang Lu</a>, based mainly at USTC in Hefei, China, announced today that it <a href="https://science.sciencemag.org/lookup/doi/10.1126/science.abe8770">achieved BosonSampling with 40-70 detected photons</a>—up to and beyond the limit where a classical supercomputer could feasibly verify the results.  (Technically, they achieved a variant called <a href="https://arxiv.org/abs/1612.01199">Gaussian BosonSampling</a>: a generalization of what I called <a href="https://www.scottaaronson.com/blog/?p=1579">Scattershot BosonSampling</a> in a 2013 post on this blog.)</p>



<p>For more, see also <a href="https://www.sciencenews.org/article/new-light-based-quantum-computer-jiuzhang-supremacy">Emily Conover’s piece in <em>Science News</em></a>, or <a href="https://www.scientificamerican.com/article/light-based-quantum-computer-exceeds-fastest-classical-supercomputers/">Daniel Garisto’s in <em>Scientific American</em></a>, both of which I consulted on.  (Full disclosure: I was one of the reviewers for the Pan group’s <em>Science</em> paper, and will be writing the Perspective article to accompany it.)</p>



<p>The new result follows the <a href="https://arxiv.org/abs/1910.09930">announcement</a> of 14-photon BosonSampling by the same group a year ago.  It represents the second time quantum supremacy has been reported, following Google’s celebrated <a href="https://www.scottaaronson.com/blog/?p=4317">announcement</a> from last year, and the first time it’s been done using photonics rather than superconducting qubits.</p>



<p>As the co-inventor of <a href="https://www.scottaaronson.com/papers/optics.pdf">BosonSampling</a> (with Alex Arkhipov), obviously I’m gratified about this.</p>



<p>For anyone who regards it as boring or obvious, <a href="https://www.scottaaronson.com/blog/?p=2435#comment-798278">here</a> and <a href="https://www.scottaaronson.com/blog/?p=1579#comment-92034">here</a> is Gil Kalai<a href="http://gilkalai.wordpress.com/">,</a> on this blog, telling me why BosonSampling would never scale beyond 8-10 photons.  (He wrote that, if aliens forced us to try, then much like with the <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Ramsey number</a> R(6,6), our only hope would be to attack the aliens.)  <a href="https://www.youtube.com/watch?v=oR-ufBz13Eg">Here’s </a>Kalai making a similar prediction, on the impossibility of quantum supremacy by BosonSampling or any other means, in his plenary address to the International Congress of Mathematicians two years ago.</p>



<p>Even if we set aside the quantum computing skeptics, many colleagues told me they thought experimental BosonSampling was a dead end, because of photon losses and the staggering difficulty of synchronizing 50-100 single-photon sources.  They said that a convincing demonstration of quantum supremacy would have to await the arrival of <a href="https://en.wikipedia.org/wiki/Quantum_threshold_theorem">quantum fault-tolerance</a>—or at any rate, some hardware platform more robust than photonics.  I always agreed that they might be right.  Furthermore, even if 50-photon BosonSampling <em>was</em> possible, after Google reached the supremacy milestone first with superconducting qubits, it wasn’t clear if anyone would still bother.  Even when I learned a year ago about the USTC group’s intention to go for it, I was skeptical, figuring I’d believe it when I saw it.</p>



<p>Obviously the new result isn’t dispositive.  Nevertheless, as someone whose intellectual origins are close to pure math, it’s strange and exciting to find myself in a field where, once in a while, the world itself gets to weigh in on a theoretical disagreement.</p>



<p>Since excitement is best when paired with accurate understanding, please help yourself to the following FAQ, which I might add more to over the next couple days.</p>



<p><strong>What is BosonSampling?</strong>  You must be new here!  Briefly, it’s a proposal for achieving quantum supremacy by simply passing identical, non-interacting photons through an array of beamsplitters, and then measuring where they end up.  For more: in increasing order of difficulty, <a href="https://news.mit.edu/2011/quantum-experiment-0302">here’s</a> an <em>MIT News</em> article from back in 2011, <a href="https://en.wikipedia.org/wiki/Boson_sampling">here’s</a> the Wikipedia page, <a href="http://www.scottaaronson.com/talks/bbn.ppt">here</a> are my PowerPoint slides, <a href="https://www.scottaaronson.com/blog/?p=1631">here</a> are my lecture notes from Rio de Janeiro, and <a href="https://www.scottaaronson.com/papers/optics.pdf">here’s</a> my original paper with Arkhipov.</p>



<p><strong>What is quantum supremacy?</strong>  Roughly, the use of a programmable or configurable quantum computer to solve <em>some</em> well-defined computational problem much faster than we know how to solve it with any existing classical computer.  “Quantum supremacy,” a term <a href="https://arxiv.org/abs/1203.5813">coined</a> by John Preskill in 2012, does <em>not</em> mean useful QC, or scalable QC, or fault-tolerant QC, all of which remain outstanding challenges.  For more, see my <a href="https://www.scottaaronson.com/blog/?p=4317">Supreme Quantum Supremacy FAQ</a>, or (e.g.) my recent <a href="https://www.youtube.com/watch?v=ZLhyTFk-WGs">Lytle Lecture</a> for the University of Washington.</p>



<p><strong>If Google already announced quantum supremacy a year ago, what’s the point of this new experiment?</strong>  To me, at least, quantum supremacy seems important enough to do at least twice!  Also, as I said, this represents the first demonstration that quantum supremacy is possible <em>via photonics</em>.  Finally, as the authors point out, the new experiment has one big technical advantage compared to Google’s: namely, many more possible output states (~10<sup>30</sup> of them, rather than a mere ~9 quadrillion).  This makes it infeasible to calculate the whole probability distribution over outputs and store it on a gigantic hard disk (after which one could easily generate as many samples as one wanted), which is what IBM proposed doing in its <a href="https://arxiv.org/abs/1910.09534">response</a> to Google’s announcement.</p>



<p><strong>Is BosonSampling a form of universal quantum computing?</strong>  No, we don’t even think it can simulate universal <em>classical</em> computing!  It’s designed for exactly one task: namely, demonstrating quantum supremacy and refuting Gil Kalai.  It <em>might</em> have some other applications besides that, but if so, they’ll be icing on the cake.  This is in contrast to Google’s Sycamore processor, which in principle <em>is</em> a universal quantum computer, just with a severe limit on the number of qubits (53) and how many layers of gates one can apply to them (about 20).</p>



<p><strong>Is BosonSampling at least a <em>step</em> toward universal quantum computing?</strong>  I think so!  In 2000, Knill, Laflamme, and Milburn (KLM) <a href="https://en.wikipedia.org/wiki/KLM_protocol">famously showed</a> that pure, non-interacting photons, passing through a network of beamsplitters, are capable of universal QC, provided we assume one extra thing: namely, the ability to measure the photons at intermediate times, and change which beamsplitters to apply to the remaining photons depending on the outcome.  In other words, “BosonSampling plus adaptive measurements equals universality.”  Basically, KLM is the holy grail that experimental optics groups around the world have been working toward for 20 years, with BosonSampling just a more achievable pit stop along the way.</p>



<p><strong>Are there any applications of BosonSampling?</strong>  We don’t know yet.  There are proposals in the literature to apply BosonSampling to vibronic spectra in quantum chemistry, finding dense subgraphs, and other problems, but I’m not yet sure whether these proposals will yield real speedups over the best we can do with classical computers, for a task of practical interest that involves estimating specific numbers (as opposed to sampling tasks, where BosonSampling almost certainly <em>does</em> yield exponential speedups, but which are rarely the thing practitioners directly care about).  [See <a href="https://www.scottaaronson.com/blog/?p=5122#comment-1867226">this comment</a> for further discussion of the issues regarding dense subgraphs.]  In a completely different direction, one could try to use BosonSampling to generate cryptographically certified random bits, along the lines of my proposal from 2018, much like one could with qubit-based quantum circuits.</p>



<p><strong>How hard is it to simulate BosonSampling on a classical computer?</strong>  As far as we know today, the difficulty of simulating a “generic” BosonSampling experiment increases roughly like 2<sup>n</sup>, where n is the number of detected photons.  It <em>might</em> be easier than that, particularly when noise and imperfections are taken into account; and at any rate it might be easier to spoof the statistical tests that one applies to verify the outputs.  I and others managed to give some theoretical evidence against those possibilities, but just like with Google’s experiment, it’s conceivable that some future breakthrough will change the outlook and remove the case for quantum supremacy.</p>



<p><strong>Do you have any amusing stories?</strong>  When I refereed the <em>Science</em> paper, I asked why the authors directly verified the results of their experiment only for up to 26-30 photons, relying on plausible extrapolations beyond that.  While directly verifying the results of n-photon BosonSampling takes ~2<sup>n</sup> time for any known classical algorithm, I said, surely it should be possible with existing computers to go up to n=40 or n=50?  A couple weeks later, the authors responded, saying that they’d now verified their results up to n=40, but it burned $400,000 worth of supercomputer time so they decided to stop there.  This was by far the most expensive referee report I ever wrote!</p>



<p>Also: when Covid first started, and facemasks were plentiful in China but almost impossible to get in the US, Chao-Yang Lu, one of the leaders of the new work and my sometime correspondent on the theory of BosonSampling, decided to mail me a box of 200 masks (I didn’t ask for it).  I don’t think that influenced my later review, but it was appreciated nonetheless.</p>



<p>Huge congratulations to the whole team for their accomplishment!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5122"><span class="datestr">at December 03, 2020 10:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/">Postdoc at Tel Aviv University at Tel Aviv University (apply by December 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I (Gil Cohen) invite applications for a postdoctoral position to start in September 2021 (the exact start date will be flexible). The position will have an initial appointment of one year, but will be extendible to two years. My main research interests right now include randomness extractors, derandomization of space bounded computation, tree codes, coding theory, and spectral graph theory.</p>
<p>Website: <a href="https://www.gilcohen.org/postdoc2021">https://www.gilcohen.org/postdoc2021</a><br />
Email: gil@tauex.tau.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/"><span class="datestr">at December 03, 2020 06:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/">Postdoctoral Associate at DIMACS at Rutgers University (apply by January 15, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, invites applications for postdoctoral associate positions for 2021-2023. Applicants should be recent PhDs with interest in DIMACS areas, including theoretical computer science, discrete mathematics, statistics, operations research, data science, AI, machine learning, and their applications.</p>
<p>Website: <a href="https://jobs.rutgers.edu/postings/122935">https://jobs.rutgers.edu/postings/122935</a><br />
Email: postdoc@dimacs.rutgers.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/"><span class="datestr">at December 03, 2020 06:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3699673705974309715">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html">Chess is Back</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Back in 2005, I wrote a post titled <a href="https://blog.computationalcomplexity.org/2005/11/chess-and-poker.html">Chess and Poker</a>. Not really comparing the two but noting that Chess had lost its mojo while poker had high-stakes prime time tournaments. The inspiration was an <a href="https://www.nytimes.com/2005/11/27/opinion/all-the-right-moves.html">NYT Op-Ed</a> that started "CHESS in America is having a crisis". I suggested that computers getting better than humans may have reduced interest in the game. </p><p>Now chess is <a href="https://www.nytimes.com/2020/11/23/arts/television/chess-set-board-sales.html">booming again</a>, due to all of us being stuck at home and the Netflix limited series <a href="https://www.imdb.com/title/tt10048342/">The Queen's Gambit</a> (highly recommended). </p><p>The fictional show takes place in the 1960's when interest in chess in the US started to pick up due to <a href="https://blog.computationalcomplexity.org/2008/01/bobby-fischer-guest-post-by-ken-regan.html">Bobby Fischer's exploits</a> and well before computers played a decent game. Fischer isn't mentioned in the Netflix series, the main character Beth Harmon sort of plays his role. The games themselves, created by Gary Kasparov and others, are even a joy to watch. Check out <a href="https://www.youtube.com/watch?v=oIMaTKOZG-8">this analysis</a> of the final game (spoiler warning). </p><p>The New York Times <a href="https://www.nytimes.com/2012/04/22/crosswords/chess/chess-50-years-of-new-york-times-columns.html">started a chess column</a> in 1962 and ran its <a href="https://www.nytimes.com/2014/10/12/crosswords/chess/after-rocky-start-grand-prix-finds-a-favorite-in-the-lead.html">last column</a> in 2014, though that might be saying more about the state of newspapers than the state of chess.</p><p>What about the computers? They have just gotten so good and with <a href="https://blog.computationalcomplexity.org/2017/12/our-ai-future-good-and-ugly.html">AlphaZero</a> mastering the game with just machine learning on top of the rules of chess, it's not even fun to watch computer versus computer anymore. Now we're back to watching humans and getting back into the games ourselves.</p><p>Computers have opened the door to cheating. Complexity theorist Ken Regan has a <a href="http://www.buffalo.edu/news/experts/ken-regan-faculty-expert-chess.html">side gig</a> reviewing games to determine if a player punching above their weight secretly used a computer algorithm. </p><p>Microsoft just <a href="https://www.microsoft.com/en-us/research/blog/the-human-side-of-ai-for-chess/">announced</a> chess programs that play as a human at various levels of strength. I suppose someone could use a program like this to cheat in a way that even Ken couldn't detect. But mostly it would be like Googling in pub trivia--just takes the fun out of the game.</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html"><span class="datestr">at December 03, 2020 02:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/180">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/180">TR20-180 |  Shrinkage under Random Projections, and Cubic Formula Lower Bounds for $\mathbf{AC}^0$ | 

	Yuval Filmus, 

	Or Meir, 

	Avishay Tal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Håstad showed that any De Morgan formula (composed of AND, OR and NOT gates) shrinks by a factor of $O(p^{2})$ under a random restriction that leaves each variable alive independently with probability $p$ [SICOMP, 1998]. Using this result, he gave an $\widetilde{\Omega}(n^{3})$ formula size lower bound for the Andreev function, which, up to lower order improvements, remains the state-of-the-art lower bound for any explicit function.

  In this work, we extend the shrinkage result of Håstad to hold under a far wider family of random restrictions and their generalization — random projections. Based on our shrinkage results, we obtain an $\widetilde{\Omega}(n^{3})$ formula size lower bound for an explicit function computed in $\mathbf{AC}^0$. This improves upon the best known formula size lower bounds for $\mathbf{AC}^0$, that were only quadratic prior to our work. In addition, we prove that the KRW conjecture [Karchmer et al., Computational Complexity 5(3/4), 1995] holds for inner functions for which the unweighted quantum adversary bound is tight. In particular, this holds for inner functions with a tight Khrapchenko bound.

  Our random projections are tailor-made to the function's structure so that the function maintains structure even under projection --- using such projections is necessary, as standard random restrictions simplify $\mathbf{AC}^0$ circuits. In contrast, we show that any De Morgan formula shrinks by a quadratic factor under our random projections, allowing us to prove the cubic lower bound.

  Our proof techniques build on the proof of Håstad for the simpler case of balanced formulas. This allows for a significantly simpler proof at the cost of slightly worse parameters. As such, when specialized to the case of $p$-random restrictions, our proof can be used as an exposition of Håstad's result.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/180"><span class="datestr">at December 03, 2020 02:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17821">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/">Too Long, Didn’t Read</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>How to summarize papers</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/all-8/" rel="attachment wp-att-17825"><img width="200" alt="" src="https://rjlipton.files.wordpress.com/2020/12/all.png?w=200&amp;h=134" class="alignright wp-image-17825" height="134" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Top row: Cohan, Weld. Bottom: Cachola, Lo.</font></td>
</tr>
</tbody>
</table>
<p>
Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent <a href="https://arxiv.org/abs/2004.15011">paper</a> on summarizing papers. They are all connected in various way to the <a href="https://allenai.org/papers">Allen Institute</a> for Artificial Intelligence. </p>
<p>
Today we take a moment to try out the <a href="https://scitldr.apps.allenai.org/">webtool</a> that comes with their paper.  It is noted also in a <a href="https://www.nature.com/articles/d41586-020-03277-2">news item</a> last week in <i>Nature</i>.</p>
<p>
They have created a program that reads a science article and outputs a single sentence that summarizes its content. Their goal is to help researchers search through the huge number of published papers faster than looking at abstracts. The software utilizes neural networks trained on many examples. </p>
<p>
For example: Their own <a href="https://arxiv.org/abs/2004.15011">paper</a> has for its abstract:</p>
<blockquote><p><b> </b> <em> We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. </em>
</p></blockquote>
<p></p><p>
And this becomes:</p>
<blockquote><p><b> </b> <em> “We introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers.” </em>
</p></blockquote>
<p></p><p>
Not so impressive, but more on their program shortly.</p>
<p>
</p><p></p><h2> Another Tryout </h2><p></p>
<p></p><p>
Perhaps the big news this week is an advance on protein folding by Google DeepMind, the same team whose work on <a href="https://rjlipton.wordpress.com/2016/03/11/stonefight-at-the-goke-corral/">AlphaGo</a> and <a href="https://rjlipton.wordpress.com/2017/12/17/truth-from-zero/">AlphaZero</a> we have covered. Sure enough, their new system is called <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a>—actually, AlphaFold2. See <a href="https://en.wikipedia.org/wiki/Protein_folding">here</a> for basic information: </p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/fold-2/" rel="attachment wp-att-17826"><img width="500" alt="" src="https://rjlipton.files.wordpress.com/2020/12/fold.png?w=500&amp;h=222" class="aligncenter wp-image-17826" height="222" /></a></p>
<p></p><p><br />
The detailed <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">announcement</a> on the DeepMind <a href="https://deepmind.com/blog">blog</a> says:</p>
<blockquote><p><b> </b> <em> Until we’ve published a paper on this work, please cite: “High Accuracy Protein Structure Prediction Using Deep Learning,” John Jumper [et al.]. In Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book), 30 November – 4 December 2020. Retrieved from <a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a></em>.
</p></blockquote>
<p>The link under “<a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a>” goes to a long book of abstracts. Among them, there is a <a href="https://www.nature.com/articles/s41586-019-1923-7">paper</a> last January in <em>Nature</em> with many of the same authors, though Jumper not as first author. Using its abstract, we got:</p>
<blockquote><p><b> </b> <em> “We train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions.” </em>
</p></blockquote>
<p></p><p>
The abstracts book has the abstract for the current paper:</p>
<blockquote><p><b> </b> <em> In the CASP14 experiment, we deployed AlphaFold 2. This new system uses a different deep learning method than CASP13 AlphaFold, and it produces much more accurate protein structures and estimates of model accuracy. The training data for the system is publicly available and similar to that used for CASP13 AlphaFold. </em>
</p></blockquote>
<p></p><p>
This is already short, but with SCITLDR it becomes:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a new deep learning system that produces much more accurate protein structures and” </em>
</p></blockquote>
<p></p><p>
The dangling “and” is a little mystifying. SCITLDR has optional fields for <i>Introduction</i> and <i>Conclusions</i>. The entry in the abstracts book has a body titled “Methods,” whose last subsection “T1064” reads like a conclusion, so we added them as such. We cleaned up the paste from PDF to have normal line breaks. After a few seconds, we obtained:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a novel attention-based deep learning architecture that produces accurate protein structures” </em>
</p></blockquote>
<p></p><p>
The DeepMind announcement poses a further challenge: how to glean an important paper that for now exists only as a blog post. The first paragraph of their <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">post</a> is boldfaced and reads like an abstract:</p>
<blockquote><p><b> </b> <em> Proteins are essential to life, supporting practically all its functions. They are large complex molecules, made up of chains of amino acids, and what a protein does largely depends on its unique 3D structure. Figuring out what shapes proteins fold into is known as the “protein folding problem,” and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP). This breakthrough demonstrates the impact AI can have on scientific discovery and its potential to dramatically accelerate progress in some of the most fundamental fields that explain and shape our world. </em>
</p></blockquote>
<p></p><p>
It becomes: </p>
<blockquote><p><b> </b> <em> “AlphaFold has been recognized as a solution to this grand challenge by the organizers of the Critical Assessment of protein Structure Prediction (CASP)” </em>
</p></blockquote>
<p></p><p>
Pretty good—do you agree?</p>
<p>
</p><p></p><h2> Even Faster </h2><p></p>
<p></p><p>
Both Ken and I are fans of the <a href="https://en.wikipedia.org/wiki/The_Mathematical_Experience">book</a> <em>The Mathematical Experience</em> by Philip Davis and Reuben Hersch. The following passage, from the chapter “The Ideal Mathematician,” describes how one writes a paper, but Ken has always taken it to describe the swiftness needed to read a paper:</p>
<blockquote><p><b> </b> <em> The intended readers (all twelve of them) can decode the formal presentation, detect the new idea hidden in lemma 4, ignore the routine and uninteresting calculations of lemmas 1, 2, 3, 5, 6, 7, and see what the author is doing and why he does it. </em>
</p></blockquote>
<p></p><p>
Nowadays we pore through papers as they appear on arXiv. For most, we just scan the titles. For others, we go to the main page with the abstract. For some, we click on the PDF to read the paper. This may be the greatest exercise in freedom of intellect we have our professional lives, but it is also an exercise in speed. We who do research in time complexity need to minimize our own time. </p>
<p>
</p><p></p><h2> Some CS Examples </h2><p></p>
<p></p><p>
Another way to say this: we all need to read through the literature faster and more precisely. Here are a few examples of their one sentence abstracts for theory papers from the SCITLDR program. Rate them by seeing if you can match the summarizes with the papers.</p>
<p></p><p><br />
Here are the one sentence summaries: </p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <p></p>
</li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <p></p>
</li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <p></p>
</li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <p></p>
</li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <p></p>
</li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <p></p>
</li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .”
</li></ol>
<p></p><p><br />
Match them to the paper titles: </p>
<ol>
<li>
The complexity of theorem-proving procedures <p></p>
</li><li>
Some connections between nonuniform and uniform complexity classes <p></p>
</li><li>
Finite Automata and Their Decision Problem <p></p>
</li><li>
A Machine-Independent theory of the Complexity of Recursive Functions <p></p>
</li><li>
Some connections between nonuniform and uniform complexity classes <p></p>
</li><li>
The Knowledge Complexity Of Interactive Proof Systems <p></p>
</li><li>
The primes contain arbitrarily long arithmetic progressions
</li></ol>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p>The papers:</p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <a href="http://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf">1</a><p></p>
<p></p></li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <a href="http://port70.net/~nsz/articles/classic/blum_complexity_1976.pdf">2</a><p></p>
<p></p></li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <a href="https://dl.acm.org/doi/10.1145/146585.146609">3</a><p></p>
<p></p></li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <a href="http://crypto.cs.mcgill.ca/~crepeau/COMP647/2007/TOPIC02/GMR89.pdf">4</a><p></p>
<p></p></li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <a href="https://dl.acm.org/doi/10.1145/800157.805047">5</a><p></p>
<p></p></li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <a href="https://arxiv.org/abs/math/0404188">6</a><p></p>
<p></p></li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .” <a href="https://dl.acm.org/doi/10.1145/800141.804678">7</a>
</li></ol>
<p>
The answers in brief: <b>a-5, b-7,c-1,d-2,e-3,f-4,g-6</b>.</p>
<p></p><p><br />
[fixed blog formatting issues, fixed paper ascription in the intro]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/"><span class="datestr">at December 02, 2020 10:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/179">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/179">TR20-179 |  Decoding Multivariate Multiplicity Codes on Product Sets | 

	Mrinal Kumar, 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Madhu Sudan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The multiplicity Schwartz-Zippel lemma bounds the total multiplicity of zeroes of a multivariate polynomial on a product set. This lemma motivates the multiplicity codes of Kopparty, Saraf and Yekhanin [J. ACM, 2014], who showed how to use this lemma to construct high-rate locally-decodable codes. However, the algorithmic results about these codes crucially rely on the fact that the polynomials are evaluated on a vector space and not an arbitrary product set. 

In this work, we show how to decode multivariate multiplicity codes of large multiplicities in polynomial time over finite product sets (over fields of large characteristic and zero characteristic).  Previously such decoding algorithms were not known even for a positive fraction of errors. In contrast, our work goes all the way to the distance of the code and in particular exceeds both the unique decoding bound and the Johnson bound. For errors exceeding the Johnson bound, even combinatorial list-decodablity of these codes was not known.

Our algorithm is an application of the classical polynomial method directly to the multivariate setting. In particular, we do not rely on a reduction from the multivariate to the univariate case as is typical of many of the existing results on decoding codes based on multivariate polynomials.  However, a vanilla application of the polynomial method in the multivariate setting does not yield a polynomial upper bound on the list size. We obtain a polynomial bound on the list size by taking an alternative view of multivariate multiplicity codes. In this view,  we glue all the partial derivatives of the same order  together  using a fresh set $\mathbf{z}$ of variables.  We then apply the polynomial method by viewing this as a problem over the field $\mathbb{F}(\mathbf{z})$ of rational functions in $\mathbf{z}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/179"><span class="datestr">at December 02, 2020 03:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/">Tenure-track assistant professors at Rochester Institute of Technology (apply by January 2, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department.</p>
<p>Website: <a href="https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291">https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291</a><br />
Email: csfacsearch@cs.rit.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/"><span class="datestr">at December 02, 2020 01:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
