[{"content": "<![CDATA[<p>Thanks everyone for the suggestions! I did indeed mean both computability theory as well as complexity theory, so many relevant suggestions.</p>\n<p>Actually, that brings to mind a follow-up question &#8211; how much computability should I learn before starting with complexity theory? Or an even more pointed question &#8211; I am under the impression that computability theory basically hasn&#8217;t advanced much in the last while, and most people are working more on results in complexity, which is the &#8220;natural progression&#8221; after computability. Is this impression right? Or are there still fundamental *computability* results that are being worked on?</p>\n]]>", "author": "Edan Maor", "published": "2018-06-14 13:08:27+00:00", "title": "By: Edan Maor"}, {"content": "<![CDATA[<p>Edan #16: I think it&#8217;s a fair statement that most of the remaining open problems in computability theory, the ones worked on today, are rather abstruse and hard for outsiders to appreciate.  Certainly they have nothing analogous to P vs. NP.  Furthermore, modern work in computability theory is mostly done in math departments; within CS departments, almost all work in theoretical computer science since the 1970s has involved considerations of complexity and efficiency.</p>\n<p>Having said that, there <i>is</i> great work being done today at the intersection of computability theory with probability theory, measure theory, and (so I&#8217;m told&#8230;) programming language semantics.  And many of the classic results of computability theory (not just Church and Turing, but the later work on recursively enumerable sets, Busy Beaver, Kolmogorov complexity, Chaitin&#8217;s &Omega;&#8230;) were triumphs of human reason.  So it all depends on what you&#8217;re interested in and where you want to go.</p>\n<p>Yes, you could study computability first, but you could also jump straight to complexity after only the tiniest smattering of computability.  There are certain topics in complexity, like the polynomial hierarchy and relativization and intermediate degrees, that will make more sense if you&#8217;ve first seen the analogous topics in computability, but even there you could, anachronistically, learn the complexity versions first and <i>then</i> the computability versions (as Lance Fortnow once put it, &#8220;the Friedberg-Muchnik Theorem is just Ladner&#8217;s Theorem for computability!&#8221;).</p>\n]]>", "author": "Scott", "published": "2018-06-14 14:19:55+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>James B: I believe that Stefan O&#8217;Rear, building off my and Adam Yedidia&#8217;s paper, eventually managed to get things down to a 748-state Turing machine that halts iff ZFC is inconsistent (improving over my and Adam&#8217;s bound by an order of magnitude), and that that still stands as the world record.  For more, see <a href=\"https://github.com/sorear/metamath-turing-machines\" rel=\"nofollow\">Stefan&#8217;s Github page</a> (he never wrote up a research paper, but you can find all his code and documentation there).</p>\n]]>", "author": "Scott", "published": "2018-06-14 14:26:03+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #7,<br />\nThanks for sharing your interesting experience with Bitcoin \ud83d\ude42<br />\nComing from a Physics/Maths background I can\u2019t help but notice that there might be something we are be able to learned from the blockchain. Firstly, solving double-spending is mainly about coming to agreement on the order of transactions, for all the nodes in a distributed system. This sounds quite analogous to how clock is synchronized in Relativity, since there is no such thing as absolute time (no trusted third party in blockchain to determine the universal time order).<br />\nSecondly, the older transactions are more certain than later ones, as they are hashed many more times than the later ones. (A good analogy is the amber.) So, the entropy is the lowest for earliest  transactions, and gradually increases with time. This sounds like an arrow of time, arising naturally from some kind of repeated operations.<br />\nThirdly, it has been shown recently that chaotic stirring of viscous fluid satisfies properties of a hash function.<br />\nThen, of course, it is the problem of double-spending without a trusted third party, which was first solved by bitcoin in the classical domain. Then people recognised that quantum domain naturally allows a solution to the problem due to no-cloning theorem, which leads to quantum money, a topic you have worked on. But the significant difference between bitcoin and quantum money is that in the former there are only operations on ledgers, without any coin literally moving around. The ledgers themselves are the coins. In quantum money we need quantum channels, and perhaps things are happening through these channels.<br />\nYeah, in short, I think Phsics could be inspired by some of the cool ideas in blockchain.</p>\n]]>", "author": "Daniel", "published": "2018-06-14 16:55:58+00:00", "title": "By: Daniel"}, {"content": "<![CDATA[<p>Close analogies between computational logic, probability theory and complexity theory become apparent when you perform a splitting into 3 levels of abstractions!  Look:</p>\n<p>Computational logic_______Probability&Stats_________Complexity&Computation:</p>\n<p>Functional Programming____Statistics_______________Information Theory/Crypto<br />\nMany-valued logic_________Probability______________Complexity<br />\nGrammar frameworks______Stats Models____________Computability/Automata</p>\n<p>See the 3 levels?  First line is practical (procedural knowledge).  Second line is low-level theoretical.  Third line is high-level theoretical.</p>\n<p>Conjecture:  Equivalence between grammar frameworks, stats models (graphical, Markov) and abstract machines (cellular automata)?</p>\n<p>More interesting still, the third line domains seem to blur into artificial intelligence/cog-sci fields, thusly;</p>\n<p>Inference_____________AI</p>\n<p>Grammar frameworks___Reflection/Conceptual Trees<br />\nStats models__________Prediction/Neural Networks<br />\nAutomata_____________Optimization/Fitness Landscapes</p>\n]]>", "author": "mjgeddes", "published": "2018-06-14 18:41:17+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>Rather impressed that one of our legislators has the foresight to encourage investment in a program that will pay dividends over the long term, whose tangible benefits are still hypothetical at this point.  It&#8217;s not the the typical pork appropriation you usually see.</p>\n]]>", "author": "Roy Abrams", "published": "2018-06-15 13:06:37+00:00", "title": "By: Roy Abrams"}, {"content": "<![CDATA[<p>When I took my first advanced computability theory course (based on Scott&#8217;s topical characterization), we used a manuscript that Richard Shore had put together. We used it more as a reference than as a textbook, but the parts of it I read were helpful and enlightening. I looked around Prof. Shore&#8217;s website and there&#8217;s no mention of the manuscript and he hasn&#8217;t released a book recently, so I don&#8217;t want to provide the document. This course was in early 2016, so hopefully it&#8217;ll be published soon and y&#8217;all&#8217;ll be able to access it. Prof. Shore had provided it to my professor to beta test on the course.</p>\n<p>The table of contents is:<br />\n0 Introduction<br />\n1 An Overview<br />\n2 The Basics<br />\n3 The Turing Degrees<br />\n4 R.E. Sets and the Turing Jump<br />\n5 Embeddings into Turing Degree<br />\n6 Forcing in Arithmetic and Recursion Theory<br />\n7 Theories of D and D(\\leq 0&#8242;)<br />\n8 Domain Properties<br />\n9 Minimal Degrees and Their Jumps<br />\n10 Latice Initial Segments of D<br />\n11 Pi_0^1 Classes<br />\n12 Pseudo-Jump Operators: Defining A<br />\n13 Global Results<br />\n14 Defining the Turing Jump</p>\n<p>Hopefully this gives insight into the contents of the book. If anyone is/knows Prof Shore and has insight into where the book is and if it would be okay for me to share in this venue, I would appreciate that knowledge.</p>\n<p>Scott said &#8220;Furthermore, modern work in computability theory is mostly done in math departments; within CS departments, almost all work in theoretical computer science since the 1970s has involved considerations of complexity and efficiency.&#8221;</p>\n<p>This has been precisely my experience as a theoretical computer scientist. I would go a bit further and say that logic as a whole seems to be increasingly the domain of mathematicians rather than computer scientists. Bias disclaimer: I have a degree in each of math and cs but consider myself a mathematician.</p>\n<p>I studied complexity before computability (in fact, my first computer science course ever was on complexity and algorithms), and made exactly the same remark that Lance Fortnow apparently did, about the Friedberg-Muchnik Theorem and Ladner\u2019s Theorem. I think that a lot of people see complexity theory as more accessible than computability theory, in part because complexity theory research tends to be easier to understand than computability theory research. Most undergraduates are not learning measure theory or category theory in their first few years, which makes talking to professors whose work revolves around those tools much harder. On the other hand, even advanced problems in combinatorics and complexity theory are methodologically accessible to undergraduates because Fourier analysis and group theory are things that they tend to be more familiar with. Yes, some of complexity theory does lean heavily on category theory, but I see that as more the exception than the rule. I also think that it&#8217;s a lot easier to communicate the underlying ideas and motivations of those problems without using category theory.</p>\n]]>", "author": "Stella", "published": "2018-06-16 20:34:21+00:00", "title": "By: Stella"}, {"content": "<![CDATA[<p>Wow, welcome back to Berkeley! \ud83d\ude42 Hopefully you have good memories of this place. I&#8217;m amazed that you&#8217;re open to meeting with blog readers (not to mention debating the random [insert political group that&#8217;s far away from your politics] reader that comes to this blog). Too bad I missed this meet-up but I had a full day so would have been hard for me to come.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seita:Daniel.html\">Daniel Seita</a>", "published": "2018-06-17 02:20:52+00:00", "title": "By: Daniel Seita"}, {"content": "<![CDATA[<p>I hope your visit includes time spent with some of the fine folk in Berkeley like rival Caliphs Scott Alexander and Eliezer Yudkowsky!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crowley:Paul.html\">Paul Crowley</a>", "published": "2018-06-17 14:56:56+00:00", "title": "By: Paul Crowley"}, {"content": "<![CDATA[<p>Paul #24: I saw or am seeing many friends from the rationalist world, like Julia Galef, Sarah Constantin, Paul Christiano, Stuart Armstrong, and others.  I would&#8217;ve loved to see the other Scott but (as he said on his blog) he&#8217;s away on vacation.  I&#8217;d also gladly see Eliezer again but he hasn&#8217;t answered my email&#8212;probably too busy trying to save the universe or something.</p>\n]]>", "author": "Scott", "published": "2018-06-17 17:56:18+00:00", "title": "By: Scott"}]