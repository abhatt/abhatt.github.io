[{"content": "<![CDATA[<p>Comment #13:<br />\nExactly, they both involve math and biology.  Haha. \ud83d\ude42</p>\n<p>Thanks for the detailed description of Chaitin&#8217;s work.  I read Meta Math and Goedel&#8217;s Way, but not his biology-themed book.</p>\n<p>I have seen panel talks with Chaitin and physicists duking it out on stage. From an audience perspective, I love it!  We need people in there mixing it up, causing trouble, and challenging conventional wisdom. \ud83d\ude42  I think you are good at asking difficult questions too, but usually from the more orthodox perspective, keeping speculative theories in check.  I think both sides are needed for progress.  Open-mindedness(even when conflicting with prior beliefs) and skepticism can both serve a scientist well.</p>\n<p>I do think looking at biology in a computational and informational way is a pretty big idea, although nobody has any robust biological models yet.  I avoided biology classes as well growing up, but after seeing how mRNA and ribosomes work like a tape and tape head, I got more interested in the mechanics of biology.  I think CRISPR experiments and machine learning should help with analyzing the complexity and building better models over time.  If statistical models on drug efficacy, disease predisposition, etc. become more statistically acurate in the future, they start look more like a deterministic computer program model than a statistical model that would need random seeds in order to be simulated.  So in that sense, drawing an anology between biology and computer programs might be useful.</p>\n]]>", "author": "Jon K.", "published": "2016-07-23 16:34:45+00:00", "title": "By: Jon K."}, {"content": "<![CDATA[<p>Scott @ 13:  So I think what you&#8217;re saying is that there is an algorithm which, given n and BB(n), computes a set of n integers one of which must equal BB(n+1)?</p>\n<p>Except that this can&#8217;t be right, since if I iterate the algorithm then I can get a computable upper bound for BB(n) for any n.</p>\n<p>So what am I missing?  I guess maybe the algorithm could be invoking the oracle for HALT, but then I don&#8217;t see the point, since if I have the oracle I can just compute BB(n+1) anyway.</p>\n<p>(Also, re: the original post &#8212; very nice paper!)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miller:Alison.html\">Alison Miller</a>", "published": "2016-07-23 20:13:11+00:00", "title": "By: Alison Miller"}, {"content": "<![CDATA[<p>(correction: the set should have size polynomial in n, not necessarily equal to n.  but the argument stands).</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miller:Alison.html\">Alison Miller</a>", "published": "2016-07-23 21:58:53+00:00", "title": "By: Alison Miller"}, {"content": "<![CDATA[<p>Hi Alison, good to have you back!  You&#8217;re exactly right&#8212;the algorithm is invoking the HALT oracle; otherwise this would be trivial.  What makes it somewhat nontrivial, even with the HALT oracle, is that you&#8217;re trying to learn (say) n+1 bits&#8212;namely, the (n+1)-bit program that runs for the longest finite time&#8212;but you only get O(log n) bits depending on the HALT oracle, plus n bits that you might have thought were totally irrelevant to your problem, namely the n-bit program that runs the longest.  Nevertheless this suffices, again as long as your programs are written in a prefix-free language (one where one valid program is never a proper prefix of another valid program).</p>\n]]>", "author": "Scott", "published": "2016-07-24 04:04:43+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>OK, I think I get it now.  Thanks &#8212; that&#8217;s pretty interesting.</p>\n<p>So an example of how this could be the case would be e.g. if one knew that the longest-running terminating program of length (n+1) belonged to a specific subset of size O(log(n))?  Then you could query your oracle O(log(n+1)) times to determine which programs halted, and then run only those to find BB(n+1).</p>\n<p>The issue I was being confused about before was: why can&#8217;t I do the following? I make myself O(poly(n)) &#8220;fake oracles&#8221;, each of which gives a different set of answers to my queries, such that at least one of them is correct.  Then I run the algorithm once using each fake oracle, and I get a set of possible values for BB(n+1), at least one of which is correct.  However, this is impossible as explained in my previous post</p>\n<p>But now that I have the example above, I see what the issue is:  if I invoke my algorithm with the wrong fake oracle, it won&#8217;t halt &#8212; and I have no way of knowing for which fake oracles this will be the case without having a legit oracle for HALT.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miller:Alison.html\">Alison Miller</a>", "published": "2016-07-24 07:45:19+00:00", "title": "By: Alison Miller"}, {"content": "<![CDATA[<p>Hi Scott,</p>\n<p>I want to thank you for maintaining this blog and making your research accessible to the general public. Hearing about the interdisciplinary and collaborative approach the team took is awesome, and I wouldn&#8217;t have independently read the paper without seeing this post. I&#8217;m an undergraduate in EECS with a latent interest in synthetic biology&#8212;this has motivated me to take a closer look and check out Professor Weiss&#8217;s class (6.580) in the fall. Thank you!</p>\n]]>", "author": "Julia Belk", "published": "2016-07-24 22:32:32+00:00", "title": "By: Julia Belk"}, {"content": "<![CDATA[<p>Scott #19: Oh, hm &#8212; I was hoping to find the other lower bounds in the paper, but I finally got around to looking through it and it looks like they aren&#8217;t.  So, uh, what are they?  How <i>does</i> one fill in the intermediate values of k?</p>\n]]>", "author": "Sniffnoy", "published": "2016-07-25 04:23:37+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>Sniffnoy #27: A fair question!  Since I&#8217;m about to board a plane and don&#8217;t have time to write a new essay for you, I&#8217;m simply going to cut and paste from the emails that Nate Roquet and I exchanged about this, with some light editing.  Let me know if you have any questions.</p>\n<p>For k=2, the key point is just that there&#8217;s a way to use 2 pairs of recognition sites to get 5 distinct DNA strings (rather than the 4 that would be the maximum possible in the k=1 case).  So then, if we have n recombinases available (let n be even), we just break them up into n/2 pairs, and repeat the construction over and over along the string to get 5<sup>n/2</sup><sup> output strings.</p>\n<p>Here&#8217;s the way to get 5, which Nate and Tim discovered:</p>\n<p>(&#8216; S1 ( S2 [ S3 ) S4 [ S5 )&#8217; </p>\n<p>Here, the primed () brackets are &#8220;orthogonal&#8221; to the unprimed () brackets but belong to the same flavor. </p>\n<p>if we treat with the ()-recombinase we get:<br />\nS5* S4* S2 S3 S1*</p>\n<p>if we treat with the []-recombinase we get:<br />\nS1 S2 S5</p>\n<p>if we treat with the ()-recombinase followed by the []-recombinase we get:<br />\nS5* S2* S4 S3 S1*</p>\n<p>if we treat with the []-recombinse followed by the ()-recombinase we get:<br />\nS5* S2* S1*</p>\n<p>OK, now let&#8217;s generalize and improve the bound!</p>\n<p>CLAIM: Suppose we have n flavors of recombinase, and k subflavors per flavor (where k< =3n/2).  Then we can generate a number of distinct strings that grows asymptotically at least like (2k/3e)^n.\n\nPROOF: The string\n(' A ( B [ C ) D [ E )'\nrecords not only whether the (-recombinase was applied and whether the [-recombinase was applied, but also the order in which they were applied (assuming they both were).  Thus, given h recombinase flavors, suppose we create a substring like the above for every choose(h,2) pairs of flavors, using different subflavors for each substring.  For example, with the h=3 flavors (, [, {, we would have\n(' A ( B [ C ) D [ E )'     ['' F [' G { H ]' I { J ]''     {'' F {' G ('' H }' I ('' J }''\nIn general, doing this will require about k=3h/2 subflavors per flavor (since each flavor, say (, is paired with h-1 other flavors, and for half of them we need two subflavors of (, while for the other half we only need one).  And this construction lets us generate about e*(h!) distinct strings -- one for every ordered list of the h recombinases in which each one appears at most once.\nSo, if we divide the n flavors into n/h blocks of h flavors each, and do the above construction for each flavor, then the total number of strings we can generate is about\n(e*(h!))^(n/h) ~ (h/e)^n ~ (2k/3e)^n.  QED\n\nThe above bound isn't tight for small k, and working things out carefully in the special case k=6, we find that we can get at least 326^floor(n/5) ~ 3.18^n distinct strings.\n\nSome further clarifications here:\n\nTo get from (e*(h!))^(n/h) to (h/e)^n, I simply used Stirling's formula: h! is about (h/e)^h.\n\nThe 326^floor(n/5) ~ 3.18^n does not come from the formula (2k/3e)^n, but from the construction that yielded the formula.  When k=6, you can check that it's possible to implement the sorting construction with n=5 flavors.  (In fact, k=6 subflavors is just *barely* enough for this -- nothing is left over!!)  Furthermore, the n=5 sorting construction lets you differentiate among\n\n5! * (1 + 1 + 1/2! + 1/3! + 1/4! + 1/5!) = 326\n\npossibilities.  So then, if we have n>>5 flavors, we just group them into n/5 blocks of 5 flavors each, and apply the construction to each block.</p>\n<p>So, for the problem of how many distinct strings can be generated, using n flavors and k subflavors per flavor, I now have an upper bound of 2^{kn} and a lower bound of k^{cn} (for some constant c).  Between these two, I conjecture that the lower bound is closer to the truth &#8212; i.e., that the k should be in the base rather than in the exponent.  Certainly we know that the lower bound becomes tight (and the upper bound non-tight) when k~n, since no matter how large k is, we always have the obvious upper bound e*(n!) on the number of possible recombinase sequences.</p>\n<p>Here are a few other thoughts.</p>\n<p>In my proof of the 2^n upper bound, for the special case k=1 (i.e., one pair of parentheses of each flavor), you might wonder where I used the assumption that k=1.  (Clearly I used it *somewhere*, since if k>1 then the bound is false!)  In fact, there&#8217;s only one place in the entire proof where I used that k=1.  That&#8217;s in the statement that, if a recombinase sequence S of length n is irreducible, then when we apply S, no parenthesis (say, ( ) can ever get deleted as a byproduct of applying some *other* flavor of recombinase (say, the [ flavor).  This is false for k>1 because applying the [-recombinase might delete the (-subflavor of ( but not the (&#8216;-subflavor &#8212; so that there would still be a reason to apply the (-recombinase later.  Indeed, that&#8217;s exactly what happens in the first construction: when we apply the [-recombinase to</p>\n<p>(&#8216; A ( B [ C ) D [ E )&#8217;</p>\n<p>we get</p>\n<p>(&#8216; A B E )&#8217;</p>\n<p>which has deleted the ( subflavor, but left the (&#8216; subflavor, so that applying the (-recombinase still does something to the string, changing it to</p>\n<p>E* B* A*.</p>\n<p>And because &#8220;no parentheses deleted as byproducts&#8221; fails, it&#8217;s no longer true that every symbol in the string has unique left and right &#8220;soulmates&#8221;: which symbol it ends up next to could depend on whether certain parentheses got &#8220;accidentally deleted along the way,&#8221; which in turn could depend on the order in which the recombinases were applied.  So, in the above example, if the ( and ) get &#8220;accidentally deleted&#8221; as a byproduct of first applying the [-recombinase, then B* ends up next to A*, since there&#8217;s no longer anything to pry them apart.  But if we apply the (-recombinase first and the [-recombinase second, then A and C* get to &#8220;consummate their soulmate relationship&#8221; :-), and we end up with</p>\n<p>E* B* D C A*.</p>\n<p>How much do we care about more precise bounds on the number of possible output strings?  For example, when k=2, what I know right now is that the number is at least sqrt(5)^n (via the sorting construction) and at most 4^n (via my 2^{kn} bound).  Should we try to determine the exact base between sqrt(5) and 4?</p>\n<p>To answer the above question, it would help to know something about the following closely-related question: let&#8217;s go back to the case k=1.  And suppose I have n recombinases, and suppose I have to use ALL of them &#8212; but in any order I want.  (Call a sequence that uses all n of the recombinases a &#8220;complete&#8221; sequence.)  Then how many distinct DNA strings can I generate?</p>\n<p>Via sorting constructions, I can show that the answer is at least 2^{n/2}, and in fact at least 3^{n/3} (which is slightly larger).  But the only upper bound I know is 2^n, from my general 2^n bound.</p>\n<p>Trying out examples, I can&#8217;t get anywhere close to 2^n: the best I can find so far is 2 different outcomes from complete sequences when n=2, or 3 different outcomes from complete sequences when n=3.  So I suspect that the 2^n upper bound can be improved.  However, *if* it were possible to get ~2^n different outcomes from complete sequences, then I can show that would have an implication for the other problem: it would mean that, when k=2, there would be a way to generate at least 3^n distinct DNA strings.</sup></p>\n]]>", "author": "Scott", "published": "2016-07-25 12:36:03+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Any thoughts on &#8220;Why genetic information processing could have a quantum basis&#8221;.</p>\n<p><a href=\"https://arxiv.org/pdf/quant-ph/0105001v2.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/quant-ph/0105001v2.pdf</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2016-07-25 13:05:01+00:00", "title": "By: James Cross"}, {"content": "<![CDATA[<p>Hi all. I worked with Scott on this paper. Sorry I\u2019m a little late to the party, but I can help with responding to comments that are more on the biological side. I&#8217;ll start now with comment #5 and I hope to answer more later in the day.</p>\n<p>Re comment #5 (Eniteris): There are many ways to implement logic in biological systems. They each have advantages and disadvantages depending on context and application. Recombinases are good for applications that require state-dependent logic because the recombinases encode states (memories) in DNA, which makes the states very stable. The state is easily inherited between generations of cells (as Eniteris mentions), and it is maintained with little energetic cost to the cell (in fact, the DNA state is maintained even when its surrounding cell chassis dies). </p>\n<p>In our research paper, we used a subfamily of recombinases called large serine recombinases (LSRs), which perform irreversible operations on DNA (inversion or excision as Scott discusses in his post). The irreversible nature of these recombinases gives us the added benefit of enhanced programmability. That is, when a LSR is expressed in response to an input, it will drive all DNA to the downstream state. Imagine instead if we had used recombinases that perform reversible operations (in an unbiased fashion- not favoring one state over another). Then equilibrium tells us that no more than ~50% of the DNA will end up in the downstream state. So the use of LSRs was crucial for the proper function of our state machines, albeit limiting in the sense that they constrained our state machines to directed acyclic graphs. </p>\n<p>That being said, bioengineers are exploring strategies for programmable, recombinase-based circuits that can reverse state. Two examples that come to mind are from the Endy Lab at Stanford (Bonnet et al. 2012: <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384180/\" rel=\"nofollow\">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384180/</a>) and the Voigt Lab at MIT (Fernandez-Rodriguez et al. 2015: <a href=\"http://pubs.acs.org/doi/10.1021/acssynbio.5b00170\" rel=\"nofollow\">http://pubs.acs.org/doi/10.1021/acssynbio.5b00170</a>). In the former example, researchers build a DNA inversion switch using a LSR to drive the switch to one state and then the same LSR together with a recombination directionality factor (RDF) to drive the switch back to its original state. In the latter example, researchers use antagonistic recombinases (FimE and HbiF) to drive a DNA inversion switch between its two states.</p>\n]]>", "author": "Nathaniel", "published": "2016-07-25 20:42:11+00:00", "title": "By: Nathaniel"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>Not always would a layperson get an opportunity to ask a mathematician who has a new proof about the thought process behind the discovery &#8211; if it is not too much trouble and if you don&#8217;t mind, could you please share how you came up with the proof? (Especially since this math is &#8216;easily accessible&#8217;.)</p>\n]]>", "author": "Ashley Lopez", "published": "2016-07-26 05:45:58+00:00", "title": "By: Ashley Lopez"}, {"content": "<![CDATA[<p>Ashley #31: Interesting request!</p>\n<p>Fortunately for me, this was a pretty easy problem, one that required just a day or so of trial-and-error (less, I&#8217;m sure, had they asked someone in the theory group other than me \ud83d\ude42 ).</p>\n<p>As far as I remember, what I did was basically just, first, to fill sheet after sheet of paper applying the rules by hand to a bunch of examples (with 2-4 pairs of recognition sites each), with every possible order on every possible subset, to see what happened.</p>\n<p>This convinced me that the &#8220;2<sup>n</sup> conjecture&#8221; was almost certainly true, but left me confused about why.  At some point, though, I must&#8217;ve noticed that certain pairs of letter-chunks had a propensity to stick together in the final output, which would&#8217;ve led me to the concept of &#8220;soulmates,&#8221; which <i>must</i> be brought together under certain conditions no matter how far apart they are on the string, e.g. because they both border a [ recognition site, and the recognition sites will just travel along with them when recombinases other than [ are applied.  But under what conditions will these letter-chunks be brought together?  Does it suffice for the [ recombinase to be applied?  No, clearly not, since maybe it won&#8217;t even find the [ recognition sites to act on.  This, in turn, would&#8217;ve led me to the concept of an irreducible sequence, and thence to the theorem.</p>\n]]>", "author": "Scott", "published": "2016-07-26 16:30:06+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Thanks Scott!</p>\n<p>When I read the proof &#8211; I was trying to retrace your possible steps &#8211; I stupidly assumed that you must have imagined up the concept of an irreducible sequence and the main lemma (only because they were presented first in the text!) BEFORE you noticed the &#8216;soulmates&#8217; thing (in an attempt to prove the lemma AFTERWARDS). But I could not visualize how one could imagine those up at the beginning of the proof attempt, subject to P != NP \ud83d\ude42 . Now it makes sense.</p>\n]]>", "author": "Ashley Lopez", "published": "2016-07-26 17:06:21+00:00", "title": "By: Ashley Lopez"}, {"content": "<![CDATA[<p>Re comment #31 (Scott): I&#8217;ve wondered this myself. The way you describe it sounds like you took a very bottom-up approach: first looking for any interesting properties of the system and then looking at those interesting properties and how they could come together to prove the theorem at hand.<br />\n.<br />\nThe key lemma states that applying all irreducible sequences of the same subset of recombinases will lead to the same DNA string. Did you know at the outset of your work that the proof of the 2^N upper bound conjecture would likely involve a lemma of this nature (some sort of statement about the equivalence of recombinase sequences made from the same subset of recombinases)? I don&#8217;t see why the proof would have necessarily involved something like this, but it seems like it would have been a good hunch.</p>\n]]>", "author": "Nathaniel", "published": "2016-07-26 17:13:45+00:00", "title": "By: Nathaniel"}, {"content": "<![CDATA[<p>Re comment #7 (Lewikee): We introduce the initial DNA string into the system (so we know the starting configuration of letter-chunks). Later on, when we read the DNA (with DNA sequencing), if we notice that a letter chunk is missing, then we know that a deletion operation must have occurred. If we are clever about the way we design the starting DNA string then we will know exactly which deletion operation occurred and when it occurred relative to the operations of other recombinases. One of the main aims of our paper was to find starting DNA strings that would record this sort of information, which we theoretically did for up to 7 recombinases (experimentally validating for up to 3). This required designing DNA strings with multiple pairs of recognition sites per recombinase \u2013 otherwise, as Scott explains in his post, this feat would be impossible.<br />\n.<br />\nIn my comment #30, I explain that strategies have been (and continue to be) developed to reverse the activity of directional recombinases. To explain why reversal is possible, I need to delve into some biological detail. When two recognition sites are acted on by a recombinase, they recombine. The recombination \u201cpastes\u201d the back end of one recognition site in a pair with the front end of the other, and vice-versa. See Figure S2 in the supplement of our paper for a diagram of how recombination occurs in our system. Depending on the type of recombinase, recombination can sometimes lead to recombined sites that no longer look like the original recognition sites, as is the case with the large serine recombinases (LSRs) used in our research. When this happens, the original recombinase can no longer (without extra co-factors) operate on the recombined sites because they no longer look like the original recognition sites, however the recombined sites can still act as recognition sites for a separate factor (LSR+RDF complex, or perhaps a separate recombinase entirely) that can operate on them in the same way (pasting the back end of one site to the front end of the other), and therefore reverse the operation of the original recombinase. Let us refer to recognition sites in their starting state as BP sites, and let us refer to their recombined configurations (made up of conjoined halves of each BP site) as LR sites. An inversion operation will take two anti-aligned BP sites on a DNA string and turn them into two anti-aligned LR sites on a DNA string. Reversing this reaction is then simply (in theory, at least) a matter of applying a recombination factor that acts on the LR sites. However, reversing a deletion operation on BP sites is a separate beast. Deletion leaves one LR site on the original DNA string and the other LR site on the deleted fragment. Biologically, unless the deleted DNA fragment has components (e.g. an origin of replication) that allow it to be maintained and replicated by the cell, then it will not be inherited when cells divide and it will essentially become lost after several generations. Therefore, even with a recombination factor that can act on LR sites, reversing deletion operations would still be challenging (and likely time-sensitive) due to a loss of LR substrate.</p>\n]]>", "author": "Nathaniel", "published": "2016-07-26 17:18:21+00:00", "title": "By: Nathaniel"}, {"content": "<![CDATA[<p>Nathaniel #34:</p>\n<ul>Did you know at the outset of your work that the proof of the 2^N upper bound conjecture would likely involve a lemma of this nature (some sort of statement about the equivalence of recombinase sequences made from the same subset of recombinases)?</ul>\n<p>No, I didn&#8217;t know anything of the kind.  At first, I was just on an open-ended hunt for any mathematical structure I could find, any clue for why you couldn&#8217;t get more than 2<sup>N</sup> sequences.  For a problem of this kind, I can&#8217;t overstate the importance of simply trying a huge number of examples, not just one or two of them.  (Well, maybe other people can proceed more abstractly, but <i>I</i> can&#8217;t!)  Nor would it have helped much, in this case, to write a program to work out the examples for me, since the whole point was to think carefully through each one and try to deduce what would happen more generally.</p>\n]]>", "author": "Scott", "published": "2016-07-26 17:36:13+00:00", "title": "By: Scott"}]