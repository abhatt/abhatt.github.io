[{"content": "<![CDATA[<blockquote><p><b>Scott</b> wonders (<a href=\"#comment-1740105\" rel=\"nofollow\">#137</a>) &#8220;If I measure a non-equilibrium state, does the interaction with a macroscopic measuring device (assuming the latter is in equilibrium) essentially always force it back to equilibrium anyway?&#8221;</p></blockquote>\n<p>This question can be mathematically sharpened to:</p>\n<blockquote><p>Can any superoperator that is associated to weak-limit dynamical coupling to a thermal reservoir&nbsp;&mdash; including but not limited to weak radiative coupling to a finite-temperature electrodynamic vacuum&nbsp;&mdash; be presented as a Lindblad operation that explicitly corresponds to a (weak) measurement process driving a feedback controller?</p></blockquote>\n<p>The short answer is &#8220;yes&#8221;.  </p>\n<p>Physically, this principle identifies the thermodynamic notion of a zero-temperature reservoir with the informatic notion of an optimal feedback controller.  Conversely, non-optimal feedback controllers are identified with finite temperature thermodynamic reservoirs.  </p>\n<p>So in a nutshell, temperature is a control parameter, and an empty vacuum is an optimal controller that drives systems to zero temperature.</p>\n<p>Mathematically, this principle can be applied to prove concrete algebraic integral identities that link Q-representations of quantum thermal states to positive P-representations of those states.</p>\n<p>Computationally, this principle helps us to appreciate why coherent states are generically effectient in computationally unravelling the nonequilibrium dynamics of finite-temperature systems.</p>\n]]>", "author": "John Sidles", "published": "2017-07-24 20:44:54+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>John Sidles #139: No, my question was specifically about Bohmian mechanics.</p>\n]]>", "author": "Scott", "published": "2017-07-24 21:09:17+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p><a href=\"#comment-1740008\" rel=\"nofollow\">Scott #93</a>, #1, reversibility, is an input from fundamental physics, with real consequences, although thermodynamics can draw conclusions without it. The others are just details determining how we go about measuring information.</p>\n]]>", "author": "Douglas Knight", "published": "2017-07-24 21:21:48+00:00", "title": "By: Douglas Knight"}, {"content": "<![CDATA[<p>Thank you for the Bohm-context clarification, Scott.   </p>\n<p>Now I am interested in precisely how, in Bohmian mechanics, the identification of thermodynamic temperature with control optimality&nbsp;&mdash; an identification that is natural, useful, and illuminating in the Church of the Larger Hilbert Space&nbsp;&mdash; can be concretely demonstrated.</p>\n<p>To paraphrase von Neumann&#8217;s letter to Marston (of <a href=\"#comment-1740096\" rel=\"nofollow\">#90</a>)</p>\n<blockquote><p>In Bohmian quantum mechanics, either thermodynamic theory can be naturally identified with control theory, or else something is totally wrong with the way that the development of Bohmian quantum mechanics is now proceeding. Either alternative would be interesting and significant.</p></blockquote>\n<p>Considerably to my amazement, an arxiv full-text search finds dozens of preprints that concern themselves with &#8220;<a href=\"http://search.arxiv.org:8081/?query=Bohmian+entropy+thermodynamic*+control&byDate=1\" rel=\"nofollow\">Bohmian+entropy+thermodynamic*+control</a>&#8220;.  </p>\n<p>Out of this large set, perhaps some Bohmian quantum mechanics expert can recommend specific references?  This filtering would be very welcome.</p>\n]]>", "author": "John Sidles", "published": "2017-07-24 21:36:31+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>A quick note about Bohmian mechanics. Even without any special access, one can both see the interference and know in retrospect which slit the particle went through. Since trajectories cannot cross, particles that went through the upper slit end up on the upper part of the screen and those that went through the lower slit end on the lower part.</p>\n]]>", "author": "Tim", "published": "2017-07-24 21:47:54+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Waterbergs #138: Thanks!  I decided to investigate whether you were right.  But the <a href=\"https://en.m.wikipedia.org/wiki/Event_horizon\" rel=\"nofollow\">Wikipedia article on event horizons</a> seems to back me up here.  It defines cosmological event horizons, which sound like exactly the relevant concept, and then says:</p>\n<ul>Examples of cosmological models without an event horizon are universes dominated by matter or by radiation. An example of a cosmological model with an event horizon is a universe dominated by the cosmological constant (a de Sitter universe).</ul>\n<p>A universe without a cosmological constant would still have particle horizons, but those don&#8217;t represent an ultimate limit on where you can get signals from.</p>\n<p>Of course, anyone who understands these matters is extremely welcome to set us straight.</p>\n]]>", "author": "Scott", "published": "2017-07-24 22:40:27+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #137: If you are talking about a system about which you know the position &#8212; from the divine slip of paper &#8212; the answer is simply no. The evolution is deterministic, there is no way randomness will be introduced by evolving the system in time. If instead what you have is a probability distribution over the positions, then yes, the Bohmians always claim that generically probability distributions will relax to |\\psi|^2 under unitary evolution, no appeal to measurement apparatuses needed.</p>\n<p>But I think I understood what the confusion is about: in your first comment you were thinking about a situation where in every round of the experiment the gods will give you the \\emph{same} piece of paper. Then the photon would always go through the same slit, which would be a gigantic contradiction with quantum mechanics, and only be acceptable in non-equilibrium Bohmian mechanics. </p>\n<p>However, I think the best way to model this situation is simply to have a position x_i in each round i, in such a way that in every given round you do find the particle going through the slits that the gods promised that it would go, but if you take the ensemble average over x_i you find that they are distributed according to |\\psi|^2, and therefore the probabilities you find are distributed according to quantum mechanics.</p>\n<p>In this way we can do everything with plain vanilla Bohmian mechanics, no mention to non-equilibrium needed.</p>\n]]>", "author": "Mateus Arajo", "published": "2017-07-24 23:00:46+00:00", "title": "By: Mateus Ara\u00fajo"}, {"content": "<![CDATA[<p>Impatient reader here :0)</p>\n<p>Any resolution on the Tim v. Daniel front? Are we seeing an unravelling of the argument, loss of interest in defending / attacking the argument, or a successful defense of the proof?</p>\n<p>Thanks!</p>\n]]>", "author": "Ian", "published": "2017-07-24 23:52:41+00:00", "title": "By: Ian"}, {"content": "<![CDATA[<p>Mateus #142: No, I was thinking about a situation where you have a divine slip of paper for the positions of the particles you&#8217;re measuring, but <i>not</i> for the positions of the particles in your measuring apparatus, which are distributed in the usual |&psi;|<sup>2</sup> way.  In such a case, it seemed completely plausible to me that an Avogadro&#8217;s number of &#8220;random&#8221; particles would overwhelm a tiny number of &#8220;non-random&#8221; ones.</p>\n]]>", "author": "Scott", "published": "2017-07-25 00:13:03+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ian #143: Here&#8217;s my current thinking about it:</p>\n<p>1. The <i>conclusion</i> of the argument&#8212;that (with a suitable light-sheet definition) number of qubits scales at most with surface area in Planck units&#8212;is a cornerstone of modern physics.  It beggars belief to me that this conclusion would be wrong because of some simple error that was overlooked by everyone for 20+ years until the comments section of this blog post.</p>\n<p>2. Having said that, the usual <i>arguments</i> for the conclusion are much more technical than my attempt at a conceptual verbal summary in the post.  If they&#8217;re more technical, it&#8217;s probably for a good reason.  It&#8217;s possible, even likely, that my verbal summary misses some important aspects of what&#8217;s going on&#8212;even if the things it misses were not egregious enough for (say) John Preskill or Sean Carroll to have flagged them.</p>\n<p>3. The steps in the argument that have attracted the most criticism&#8212;namely, 4 and 7&#8212;are precisely the steps that I myself was most stuck on and needed Daniel Harlow to explain to me.  I&#8217;m still in the mode of asking questions of both sides in an attempt to get to the bottom of it.</p>\n<p>4. As I explained in comment #130, even supposing we dropped steps 4 and 7, we&#8217;d still be left with a powerful statement about &#8220;the physicality of information&#8221;: in this case, an upper bound on the <i>number of computational steps</i> that could take place within a given time interval without creating a black hole.  It just wouldn&#8217;t be quite the same statement that I&#8217;d claimed.</p>\n]]>", "author": "Scott", "published": "2017-07-25 00:46:16+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #147: That seems plausible to me, but I don&#8217;t see what this has to do with the subject at hand. We&#8217;re not talking about the evolution of the system after the measurement, but just about how the result of the measurement depends on the particle&#8217;s position. </p>\n<p>And every single Bohmian paper I have ever seen just assigns a position to the particle, ignoring the hidden variables of the measurement apparatus, and from the quantum potential derives a deterministic trajectory that connects this initial position to the measurement result. Are you trying to argue that this somehow does not work? That the initial position does not in fact determines the measurement result? I&#8217;m very confused about what your point is.</p>\n]]>", "author": "Mateus Arajo", "published": "2017-07-25 06:49:04+00:00", "title": "By: Mateus Ara\u00fajo"}, {"content": "<![CDATA[<p>Scott #144</p>\n<p>Hi Scott, thanks for your prompt and as always courteous reply to a pipsqueak raising an issue. But (you knew there was going to be but!) I do think that you are wrong on this one. There are two horizons in question here as I understand, an event horizon and a particle horizon. The later is the furthest point from which light emitted in the past can have come and reached us, and is, I think about 46 billion light years away from us. This seems to be the horizon you are refering to in comment #85.</p>\n<p>The exsitence of such an horizon doesn&#8217;t depend on the cosmological constant &#8211; which has only really kicked in at about 9 billion years into the expansion of the universe, as it grows in influence as the amount of spacetime grows. It has just speeded up the expansion a bit. I think in most expanding universes (even with no cosmological constant) such an horizon will exist. If one thinks of the 2D analogy of the surface of an expanding balloon, every point sees every other point receeding with an apparent velocity proportional to the amount of spacetime between the two points. So to get an arbitrary large apparent recession velocity (such as one greater than the speed of light) one just needs to go far enough away. I think the same applies in our universe with 3 spatial dimensions. </p>\n<p>As you say, maybe we need a cosmology expert to kick in here and clarify for us.</p>\n]]>", "author": "Waterbergs", "published": "2017-07-25 07:19:25+00:00", "title": "By: Waterbergs"}, {"content": "<![CDATA[<p>Tim #116: I think the issue is that if you have a particle with zero (or very low) momentum, its wave function is spread out, so its probability of being in a particular region of space is zero (or almost zero), and so the information contained in that region of space coming from that particle is very small.</p>\n]]>", "author": "Will", "published": "2017-07-25 07:48:30+00:00", "title": "By: Will"}, {"content": "<![CDATA[<p>Ian #143</p>\n<p>I haven&#8217;t found Daniel&#8217;s later post responsive. So that&#8217;s where I stand.</p>\n<p>In response to Scott: as you know, I currently have a paper arguing that the whole &#8220;black hole information loss paradox&#8221; is due to a pretty simple error that occurred more than 40 years ago. So my belief is not easily beggared in this context. (Just today I think I have sewed up the last loose ends of that paper.)</p>\n<p>Regarding your point 4, I can&#8217;t see where even the conceptual apparatus comes from. If you insist on analogizing the physical time development of the universe to a computation, it is an analog computation (so long as we are using differential equations) not a digital or Turing machine one. I have no idea how to count &#8220;computational steps&#8221; in such a setting.</p>\n]]>", "author": "Tim", "published": "2017-07-25 03:11:37+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>One of the greatest blog posts in the history of physics.</p>\n]]>", "author": "Nate Gentile", "published": "2017-07-25 03:11:50+00:00", "title": "By: Nate Gentile"}, {"content": "<![CDATA[<p>Ian #146, the short answer is that I have better things to do than debate with would-be-skeptics who can&#8217;t be bothered to understand free field theory.  The argument Scott describes in points 4-7 is one intuitive way to think about a precise theorem in quantum field theory, which you can read about in  <a href=\"https://arxiv.org/abs/0804.2182\" rel=\"nofollow\">https://arxiv.org/abs/0804.2182</a>.  It definitely isn&#8217;t wrong.  My previous two comments give a bit more quantitative intuition, which may help some people.</p>\n<p>Also to whomever asked about horizons in expanding universes above, Scott is right.  In an expanding universe dominated by matter or radiation, if you wait long enough you can eventually see anything.</p>\n]]>", "author": "Daniel", "published": "2017-07-25 05:05:17+00:00", "title": "By: Daniel"}, {"content": "<![CDATA[<p>Mateus #152: I&#8217;m no longer trying to win an argument; I concede that the situation with the slips of paper can be understood in terms of non-equilibrium Bohmian mechanics.  My curiosity was pulled in a different direction: even if (say) Valentini was right, and non-equilibrium Bohmian states abounded in our universe, would exploiting those states for superluminal communication and so forth still be a practical near-impossibility, because the interaction with the equilibrium states of the macroscopic measuring devices would pull the particle positions back to equilibrium anyway?  This seems completely plausible to me, but it&#8217;s fine if you&#8217;re not interested to go there.</p>\n]]>", "author": "Scott", "published": "2017-07-25 15:22:11+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Waterbergs #153: Rereading comment #85, the resolution is simply that I was sloppy there, and didn&#8217;t properly distinguish between particle horizon and cosmological event horizon.  But when applying the holographic entropy bound, it&#8217;s clearly the latter that&#8217;s relevant: we care about the maximum number of bits that can ever be stored, and the maximum size of a computation that can ever be done.  And we agree, I think, that the event horizon is finite in a de Sitter universe, but infinite in a universe with no cosmological constant.</p>\n]]>", "author": "Scott", "published": "2017-07-25 15:28:43+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Will #154<br />\nMy point was just that the spatial variation in one frame at a moment plus the Lorentz transformation does not yield the temporal variation in any frame. The example is just the easiest to see, but the point is universal.</p>\n]]>", "author": "Tim", "published": "2017-07-25 15:10:23+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Scott #155: I still don&#8217;t see how the macroscopic measurement device pushing the state back to equilibrium would affect the capability of predicting the measurement result. For me it is clear that this would make the post-measurement state unpredictable, but we&#8217;re not talking about the post-measurement state, are we?</p>\n<p>What I understand by having a non-equilibrium state is having a capability to prepare an ensemble of quantum states with enough control over the positions so that their ensemble average is not distributed as |\\psi|^2, but something much sharper. Since a deviation from this distribution must cause a deviation from the Born rule probabilities, and a deviation from Born rule probabilities imply superluminal signalling and assorted fireworks, it seems to me that having non-equilibrium states mean having the ability \\emph{in practice} to do this stuff.</p>\n]]>", "author": "Mateus Arajo", "published": "2017-07-25 15:50:56+00:00", "title": "By: Mateus Ara\u00fajo"}, {"content": "<![CDATA[<p>Is there any Bohmian hanging around that knows the answer to this?</p>\n]]>", "author": "Mateus Arajo", "published": "2017-07-25 15:52:03+00:00", "title": "By: Mateus Ara\u00fajo"}, {"content": "<![CDATA[<p>Scott #148</p>\n<p>&#8221; in this case, an upper bound on the number of computational steps that could take place within a given time interval without creating a black hole.&#8221;</p>\n<p>I guess that analysis also takes care of the cases where one tries to use special relativity to take advantage of time dilation? (i.e. the energy necessary to accelerate close enough to the speed of light makes it too expensive).</p>\n]]>", "author": "fred", "published": "2017-07-25 16:14:56+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Douglas #141: Every physical theory has a conceptual core, surrounded by an accretion disk of auxiliary facts that are crucial to applying the theory in practice.</p>\n<p>Now, I&#8217;m on record as saying that I <i>always</i> prefer to learn about physics by starting at the core of a theory, even if that&#8217;s completely ahistorical&#8212;even if it took decades of clearing away crud in the accretion disk before the core even came into view.  E.g. first learn that states are complex unit vectors and evolution is unitary, and only later learn about bosons and fermions, e=hv, and the uncertainty principle.</p>\n<p>Thermodynamics, it seems to me, follows exactly this same pattern&#8212;except with the interesting twist that almost <i>all</i> the actual physics input belongs to the accretion disk, the core being almost entirely pure math (again, except for evolution being reversible).  So, yes, start by teaching the information-theoretic core!  But then if you want to say something about heat and temperature&#8212;which is the part of the story that always confused me, precisely because it&#8217;s <i>not</i> completely information-theoretic&#8212;you need to move out to the accretion disk.</p>\n]]>", "author": "Scott", "published": "2017-07-25 17:30:53+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #160: Yes, that&#8217;s right.</p>\n]]>", "author": "Scott", "published": "2017-07-25 17:32:33+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Mateus #158: No, I wasn&#8217;t talking about the post-measurement state, but about the classical measurement outcome.  My point was that, as far as I can see, there&#8217;s no principle telling us that even the measurement outcome won&#8217;t get pushed back to &#8220;equilibrium&#8221; (i.e., to the Born probabilities) during the process by which whatever observable we&#8217;re measuring gets recorded macroscopically.  I&#8217;m sure there are papers by Bohmians analyzing this issue; I just don&#8217;t know where they are or what conclusions they reach.</p>\n]]>", "author": "Scott", "published": "2017-07-25 17:38:09+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott and Fred #160 & 162 &#8220;i.e. the energy necessary to accelerate close enough to the speed of light makes it too expensive&#8221;</p>\n<p>This is a very good clue why the cosmological constant is tiny today, but still consistent with the 10^124 number at the time of the big bang. Even today relativistic physics implications are hard to wrap your head around so that ALL its implications are understood.</p>\n]]>", "author": "Eric Habegger", "published": "2017-07-25 18:22:11+00:00", "title": "By: Eric Habegger"}, {"content": "<![CDATA[<p>@Tim #155 Sorry, I misunderstood. We have to distinguish two claims</p>\n<p>1) The spatial variation of a field in some Lorentz frame determines the energy in that (or some other) Lorentz frame.</p>\n<p>2) The spatial variation of a field in some Lorentz frame lower-bounds the energy in that Lorentz frame.</p>\n<p>The first claim is false. You correctly debunked it earlier with the example of a zero-momentum particle.</p>\n<p>However, Scott didn&#8217;t make that claim &#8211; or at least not intentionally. Instead he made the second claim:</p>\n<p>> If we know how quickly a field varies across space, then we can lower-bound how much energy it has to contain.</p>\n<p>Do you disagree with this?</p>\n<p>In the case of the wave function of a spin-free particle, we can see for instance in the equation Daniel gave.  For a classical relativistic particle or substance, I guess this comes from the fact that the stress-energy tensor is nonnegative when summed against the metric tensor, so large momentum implies large energy. </p>\n<p>There is an additional issue which is how Scott&#8217;s argument to verify this with a Lorentz transformation is supposed to work.   As far as I can see, the right way to verify this with Lorentz conditions is to assume that the energy is nonnegative (or has some finite lower bound) in each reference frame. In this case, if the momentum is large but the energy is small, we can take a Lorentz transformation to a frame where the energy is arbitrarily negative.</p>\n<p>So I think Scott&#8217;s claim is true, and his argument with a Lorentz transformation does at least point towards the actual argument.</p>\n]]>", "author": "Will", "published": "2017-07-25 18:28:46+00:00", "title": "By: Will"}, {"content": "<![CDATA[<p>Scott and Mateus: The exact initial position of the incoming particle would determine where it lands on the screen in a 2-slit experiment, and the exact initial positions of the pair of particles in a Bell experiment determine the exact pair of outcomes (together with a macroscopic description of the apparatus). The detailed apparatus positions are not necessary to determine the outcome. They could not be, or else the Bell correlations would fail. So Mateus is right on this point. </p>\n<p>Will:I do disagree, and the same counterexample proves that not even a lower bound can be derived. Daniel pulled out the Klein-Gordon equation, and if you look you will notice that the equation contains an &#8220;m&#8221;. That is the rest mass of the particle. And that, of course, lower bounds the energy of the state by E = mC^2. But that lower bound has nothing at all to do with spatial variation taken by itself. From the spatial variation at a time you have no clue about what the relevant rest mass is.</p>\n<p>Daniel has retired from comment. But I will note one more thing. The paper he posted as somehow rigorously establishing the conclusion is all about the *von Neumann* entropy of states. The von Neumann entropy has exactly nothing to do with the thermodynamic entropy, with temperature, or with energy. Mixing up von Neumann entropy with Shannon entropy with thermodynamic entropy with statistical-mechanical entropy (either Gibbs or Boltzmann) is more or less a hallmark of this literature starting with Beckenstein. A proper analysis has to begin by carefully separating these distinct notions of &#8220;entropy&#8221; and arguing what connection\u2014if any\u2014there is between them. That will not get settled here, but if you want some advice before reading a paper, be sure to see how clear it is made which entropy is at issue and why it is a notion of entropy relevant to the question at hand.</p>\n]]>", "author": "Tim", "published": "2017-07-25 19:31:26+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Tim #166: You might be completely right that the detailed apparatus positions don&#8217;t matter.  Not knowing enough about Bohmian mechanics, I just raised it as a question; I didn&#8217;t claim an answer.</p>\n<p>But I don&#8217;t understand the following argument at all:</p>\n<ul>They could not be, or else the Bell correlations would fail</ul>\n<p>If the probabilities of measurement outcomes were determined entirely by the quantum state, the Bohmian positions never even entering into it&#8212;for example, because the interaction with the measuring apparatus had &#8220;re-equilibrated&#8221; the positions&#8212;then clearly you <i>would</i> see Bell correlations, because standard QM predicts them.</p>\n]]>", "author": "Scott", "published": "2017-07-25 20:05:35+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott # 167</p>\n<p>The issue to think about is not whether the measurement *probabilities* are determined by the quantum state, with the positions not coming in, but what determines the particular *outcomes*, which are the things that display the empirical statistics. What I was thinking of was just the simple EPR perfect correlations. The particular results of such an experiment\u2014whether it is Up-Down or Down-Up\u2014depends on the particular initial location of the particles. Through the entanglement in the wave function, as soon as one of the particles interacts with a measurement device the conditional wave-function collapses to one state or the other, depending on the position of the particle interacted with. My thought was that if the particle positions in the apparatus, in addition to the position of the measured particle, also determined the outcome then there would be no guarantee that the conditional wave function would have the right form to enforce the perfect correlation on the other side. Now that I have written it down, though, I can see ways around it. </p>\n<p>In the usual analysis, the measurement device is just represented by a potential term in the Hamiltonian, which obviously is independent of the detailed particle positions in the apparatus, and in that analysis everything comes out fine. I have to think a little more about whether one could easily compensate for having the particle positions in the apparatus play a critical role in determining the outcome. I guess I can say for sure that in the usual analysis they certainly don&#8217;t.</p>\n]]>", "author": "Tim", "published": "2017-07-25 21:21:30+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Regarding the double slit experiment &#8211; interference + detection of which path was taken:<br />\n<a href=\"https://en.wikipedia.org/wiki/Afshar_experiment\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Afshar_experiment</a></p>\n<p>Seems consistent with<br />\n<a href=\"https://en.wikipedia.org/wiki/Transactional_interpretation\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Transactional_interpretation</a></p>\n<p>hmm&#8230;</p>\n]]>", "author": "fred", "published": "2017-07-25 21:27:02+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Thanks for this post. Just a simple remark: a constant field can affect the information content of the universe is a much less trivial way than suggested in this post. If that field has a non-zero potential energy, it will contribute to the energy content as dark energy, which in turn affects the size of the cosmological horizon, in turn affecting the total amount of information visible to any particular observer (even an immortal one).</p>\n]]>", "author": "Dan Carney", "published": "2017-07-25 22:12:10+00:00", "title": "By: Dan Carney"}, {"content": "<![CDATA[<p>fred #37 and so on:<br />\nInformation as a concept *is* divorced from consciousness. The typical example is DNA which encodes the information necessary to produce an organism.  No consciousness required.</p>\n]]>", "author": "RKM", "published": "2017-07-26 04:55:03+00:00", "title": "By: RKM"}, {"content": "<![CDATA[<p>First of all, great post! I am not very knowledegeable about these things, but I have one query:</p>\n<p>> Why is this assumption justified?  \u201cBecause experiment bears it out,\u201d the physics teacher explains\u2014but we can do better.  The assumption is justified because, as long as the degrees of freedom that we\u2019re talking about all interact with each other, they\u2019ve already had plenty of time to equilibrate.</p>\n<p>Why do you assume that all degrees of freedom in this universe will interact with each other? What if, for example, by accident someone comes up with an instrument which detects a new type of behaviour, and its degree of freedom is totally independent of the ones we know today?</p>\n]]>", "author": "Nikhil", "published": "2017-07-26 08:14:16+00:00", "title": "By: Nikhil"}, {"content": "<![CDATA[<p>#71 RKM<br />\nThat&#8217;s a good point.<br />\nDNA, memory, a thermostats, neurons, are all micro systems having a state that&#8217;s dependent on (hyper sensitive to) some global properties of outside macro systems.<br />\nE.g. a thermostat is dependent on the room temperature it&#8217;s in.<br />\nE.g. the state of a handful of neurons in the brain of a cosmologist is highly dependent on the shape of very distant clumps of matter (galaxies).</p>\n<p>One could find what those dependencies are through careful experiments &#8211; e.g. finding that something shaped like a cat, a chair, or a cloud, or a certain sound is a sort of invariant in the studied system&#8217;s state changes. Then possibly build a growing list of such concepts/symbols, and then infer a dictionary representing the &#8220;world vision&#8221; of the studied system.<br />\nThat said, to make sense of it, we would have to be able to interpret it in terms of the structures in our own brain.<br />\nIn that sense the interpretation of information is always subjective &#8211; because it&#8217;s always done by some other sentient system (one mystery is how life kickstarted this, or the question of when a baby/fetus becomes conscious).</p>\n<p>E.g. if I handed you an embedded microchip system, you would have a tough time deciding whether it&#8217;s been programmed in a brand new high level programming language or programmed by hand in low level assembly, or just mass produced as is. There&#8217;s no denying that there&#8217;s &#8220;information&#8221; in there, but how to interpret it, at what level of abstraction is subjective on the observer (a computer works by just &#8220;running&#8221; the laws of physics on its atoms, there&#8217;s no such thing as software &#8220;running&#8221; the hardware).</p>\n<p>E.g. the understanding of mathematics of Ramanujan may not be entirely transferable to another average human brain (is all mathematical knowledge always expressible as symbols on a 2D sheet of paper, which is the standard way for humans to encode math information?).</p>\n<p>E.g. Go strategies used by Alpha Go may not be apparent/make sense to human players.<br />\nThat&#8217;s a real issue going forward with AIs because we would like to understand (at least qualitatively) what motivates the conclusions/decisions of an AI, even if it always appears to be right. If we ever give up on this, and accept those AIs as impenetrable black box oracles (gods?), humanity would lose a lot and starts to stagnate. There is already research done on adding extra AIs on top of such AIs just to interpret its decisions in ways that are more intelligible to us (adding recursive introspection akin to consciousness?).</p>\n]]>", "author": "fred", "published": "2017-07-26 13:01:13+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Nikhil #172: Please read further&#8212;that question is answered in the post!</p>\n<p>(Basically, a totally decoupled degree of freedom doesn&#8217;t matter for thermodynamics.  And if we&#8217;re doing equilibrium thermodynamics, then an interacting degree of freedom is assumed to have already equilibrated.)</p>\n]]>", "author": "Scott", "published": "2017-07-26 14:18:16+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Just saw an ad for a book likely to be of interest to those in this discussion:  </p>\n<p>Picturing Quantum Processes<br />\nA First Course in Quantum Theory and Diagrammatic Reasoning</p>\n]]>", "author": "Raoul Ohio", "published": "2017-07-26 15:15:27+00:00", "title": "By: Raoul Ohio"}, {"content": "<![CDATA[<p>Maybe another comment about Bohemian mechanics will help. It makes no sense to say of an individual particle, or the particles in an individual measuring device, that it is (or they are) &#8220;in equilibrium&#8221; in the relevant sense. What can have an equilibrium distribution (or not) is a large *ensemble* of systems which all have the same conditional wave function. It is contentful to ask of such a large ensemble whether the particle positions are (approximately) psi-squared distributed (relative to the conditional wave function). It is this condition that assures that the empirical statistics in a Bohmian universe will match quantum-mechanical predictions. Asking whether the state of a *single* system is or is not in quantum equilibrium is a category mistake. You can only ask of large ensembles. Asking about a single system is the analog in stat. mech. of asking whether an individual atom in a gas is &#8220;in equilibrium&#8221;. The gas can (or cannot) be: for the atom it makes no sense.</p>\n]]>", "author": "Tim", "published": "2017-07-26 15:24:41+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Scott:</p>\n<p>I was waiting for someone else to notice this thing, but apparently none has, not at least very directly or saliently. Guess there still is time to point it out. So, OK, here we go.</p>\n<p>Scott says in the main post:</p>\n<p>>> &#8220;And suppose She then created a bunch of new fundamental fields, which didn\u2019t interact with gravity, electromagnetism, or any of the other fields that we know from observation&#8221;</p>\n<p>A strawman, that one is. </p>\n<p>The real issue is not whether God or Mother Nature could or could not create (or (choose to) reveal) a field that <i>does not</i> interact with any of the forces/fields already known to us.</p>\n<p>The real issue is this: </p>\n<p>What if there is a new form of force (in whatever form: as a field of force, or as a &#8220;particle&#8221; of force, or in whatever other form) which <i>does</i> (and has been) in reality interacting with the known forms of forces, but only in such regimes of parameters that our observations (including the technological limitations of our instruments) thus far have not been able to detect either the phenomena involving it or its interactions?</p>\n<p>Thermodynamics is both a scheme (or to use that much abused word: &#8220;framework&#8221;) and a body of content (a set of facts, and valid inferences therefrom). </p>\n<p>Qua a scheme, thermodynamics would be quick to absorb the new force within itself&#8212;for instance, it could simply add a new form of energy in the law of conservation of energy.</p>\n<p>By the same token, qua a body of content, the list of forms of force/energy it <i>presently</i> acknowledges is <i>not</i> closed. We can&#8217;t ever bring a &#8220;closure&#8221; like that to <i>any</i> branch of physics. Our list is &#8220;complete&#8221;&#8212;but only within the scope of our present state of <i>inductively</i> derived knowledge. </p>\n<p>In short, we <i>can</i> confidently speak from our knowledge&#8212;about the aspects of reality we have already seen. But we <i>cannot</i> therefore assert that we have seen all there <i>is</i>, in reality. There is no principle which allows us to do that.</p>\n<p>Any argument (e.g. one involving &#8220;degrees of freedom&#8221; or &#8220;dynamics&#8221; or &#8220;equilibrium&#8221; or &#8220;interactions&#8221;) must be consistent with these, more fundamental, facts. And the way to do that is simple: drop the strawman, and add the preface (even if only implicitly): &#8220;within the scope (&#8220;ambit&#8221; etc.) of our current state of knowledge&#8230;&#8221;. The main hypothesis would be quite fine then.</p>\n<p>Sorry, too long a comment, but didn&#8217;t know how to compress it&#8212;all its (what I think are) <i>pertinent</i> aspects!</p>\n<p>Best,</p>\n<p>&#8211;Ajit</p>\n]]>", "author": "Ajit R. Jadhav", "published": "2017-07-26 15:25:28+00:00", "title": "By: Ajit R. Jadhav"}, {"content": "<![CDATA[<p>And I even corrected &#8220;Bohemian&#8221; to &#8220;Bohmian&#8221;!</p>\n]]>", "author": "Tim", "published": "2017-07-26 15:25:57+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Ajit #177: The surprising part is that, whatever new forces or particles might exist in our universe, one can upper-bound (for example) how much energy they could possibly contain, because all energy interacts with gravity.</p>\n<p>To me, this is what&#8217;s actually much more surprising than the existence of dark matter: namely, that even with our present ignorance, we can upper-bound the <i>amount</i> of dark matter, as &#8220;merely&#8221; a factor of 3 or so larger than the types of matter we&#8217;ve accounted for!</p>\n<p>In a similar spirit, sometimes people worry about a &#8220;turtles all the way down&#8221; scenario, where there would be no fundamental theory of physics or fundamental constituents of matter, just nuclei made of protons and neutrons made of quarks made of &#8230; and so on ad infinitum.  But this is already ruled out!  The existence of the Planck scale, and the associated Bekenstein-type bounds, put a clear cap on how far down things can go.</p>\n]]>", "author": "Scott", "published": "2017-07-26 15:44:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #179:</p>\n<p>1. I respectfully disagree. </p>\n<p>2. All energy does interact with gravity (and with any other form of known forces). A co-existence without any form of interaction is nothing but a &#8220;gap&#8221; in the knowledge. </p>\n<p>But the mere fact of existence of interactions does not mean that all forms of energy interact with each other to the same degrees in every possible regime of physical parameters (and therefore can get detected in the regime currently accessible to experimental observations). </p>\n<p>We cannot rule out the idea that in the regime of experimental parameters currently available to us, the degree of the interaction of the new XYZ form of force is too small to be detected.</p>\n<p>3. I gather (but don&#8217;t really know) that the Planck scale is the lower-most bound for the scales on which known force-phenomena can be studied. </p>\n<p>OK, I can accept that on &#8220;faith&#8221;. But only with an emphasis on the word <i>&#8220;known&#8221;</i>.</p>\n<p>4. The argument for the infinite regress of phenomena at ever finer (or larger) scales also is easy to counter. </p>\n<p>There is no positive (actually, inductive) evidence in favor of such an assertion. Indeed, inasmuch as it is an <i>infinite</i> regress, it can only be a mathematical statement, not of physical facts (or of completed cognitive processes). On that one count alone, it can be rejected from physics.</p>\n<p>At the same time, a closure for the known forms of physical forces also has not been inductively established. </p>\n<p>The latter (absence of the closure) does not mean the former (infinite regress).</p>\n<p>5. In one respect, mine is the same position as you yourself have argued so well in favor of, in the following passage: </p>\n<p>>> &#8220;&#8230;If the cosmologists revise their models next week,&#8230;&#8221;</p>\n<p>The outer extent of the known universe cannot be taken as an actually existing boundary of the physical universe. Similarly, for the forms of forces there can be. An unknown form of a force was a possibility in ancient times when the weak interaction had not yet been discovered. It remains so, even today.</p>\n<p>Best,</p>\n<p>&#8211;Ajit</p>\n]]>", "author": "Ajit R. Jadhav", "published": "2017-07-26 16:37:36+00:00", "title": "By: Ajit R. Jadhav"}, {"content": "<![CDATA[<p>Ajit #180: OK, but I never said that there were no new fundamental particles or forces to be discovered.  It would surprise me if there weren&#8217;t!  I only said that there&#8217;s a known bound on the total energy content of any new particles and forces, and also on the energy scales at which they can appear.  The two statements are 100% compatible.</p>\n]]>", "author": "Scott", "published": "2017-07-26 16:55:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<blockquote><p>Tim asserts in <a href=\"#comment-1740185\" rel=\"nofollow\">#166</a>: &#8220;The von Neumann entropy has exactly nothing to do with the thermodynamic entropy, with temperature, or with energy. Mixing up von Neumann entropy with Shannon entropy with thermodynamic entropy with statistical-mechanical entropy (either Gibbs or Boltzmann) is more or less a hallmark of this [quantum gravity] literature starting with Beckenstein.&#8221;</p></blockquote>\n<p>This view is contrary to the literature, both historically and logically.  Historically, von Neumann derived his celebrated entropy-expression as a logical consequence of a <i>Gendankenexperiment</i> crucially involving the classical thermodynamic entropy of an ideal gas.  </p>\n<p>The student-friendly literature that is cited in comment <a href=\"#comment-1740022\" rel=\"nofollow\">#97</a> works through the details of von Neumann&#8217;s derivation.</p>\n<p>The short summary is von Neumann&#8217;s logical reasoning about \u201c\u03c9-gases\u201d established, way back in 1935, that the entropy of irreversible mixing&nbsp;&mdash; as presented equivalently by the random classical mixing of molecules (e.g. benzene and toluene), and by the random quantum mixing of states (e.g. radiative decoherence), and by the random combinatoric mixing of symbols (e.g. Shannon noise)&nbsp;&mdash; is a universal phenomenon that is compatibly grounded in classical, quantum, and combinatoric dynamics. </p>\n<p>It is natural to wonder whether 21st century researchers will discover further expressions for entropy&nbsp;&mdash; expressions that are novel and yet compatible with classical, quantum, and combinatoric entropy-expressions of the 20st century.  </p>\n<p>For&nbsp;sure, present-day quantum gravity researchers and varietal dynamics researchers (aka &#8220;quantum quasi-skeptics&#8221;) have concrete ambitions in this regard!&nbsp;\ud83d\ude42</p>\n]]>", "author": "John Sidles", "published": "2017-07-26 17:05:07+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>John Sidles # 182:  My remark had to do with the conflation of these various notions of &#8220;entropy&#8221; in the literature since Beckenstein. Perhaps &#8220;nothing to do with&#8221; is too strong, but the von Neumann entropy is not the thermodynamic entropy. This is obvious in that the von Neumann entropy of a system is not even extensive: the parts can have much, much higher entropy than the whole. Entropy of mixing can be given a clear sense in statistical mechanics, but the  thermodynamic implications of it per se are problematic (hence Gibbs&#8217; paradox, which is a special case of the &#8220;mixing paradox&#8221;). Likening issues of entropy to issues of Shannon noise is again a strange comparison. The Shannon entropy is definable even if there is a noiseless channel, so it is not as if the Shannon entropy somehow quantifies noise. In any case, mixing is hardly a central notion in thermodynamics, so trying to find connections here through it is already somewhat implausible. What I warned against was mixing up these entropies, and I think the warning stands. The story about how Shannon&#8217;s got its name does not need repeating here, but ought to be appreciated.</p>\n]]>", "author": "Tim", "published": "2017-07-26 19:56:22+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>This argument for information &#8211;> energy begins by assuming that information is variation across space, and that &#8220;increasing information&#8221; is &#8220;packing the variations in tighter&#8221;.<br />\nBut how can this include information such as an electron charge? The information of the electron charge comes out in that, when we place the electron in such and such field, it moves in such and such way. The information of charge seems to be &#8220;stored&#8221; in counterfactual worlds &#8212; if we did this, we&#8217;d have that &#8212; rather than &#8220;stored&#8221; in variations across space.</p>\n]]>", "author": "QuanThomas", "published": "2017-07-26 21:14:53+00:00", "title": "By: QuanThomas"}, {"content": "<![CDATA[<p>Tim (<a href=\"#comment-1740229\" rel=\"nofollow\">#183</a>), your observations at least suggest that it would be an instructive exercise to (attempt to) demonstrate, in von Neumann&#8217;s &omega;-gas framework, that the following three entropy functions:</p>\n<p>&nbsp;&nbsp;(1)&nbsp;classical entropy of an ideal gas, </p>\n<p>&nbsp;&nbsp;(2)&nbsp;von Neumann quantum entropy, and </p>\n<p>&nbsp;&nbsp;(3)&nbsp;Shannon&#8217;s entropy function,</p>\n<p>in aggregate constitute (what is called) &#8220;a&nbsp;K&auml;hlerian triple&#8221;, which is to say, a set of three structures of which any two structures compatibly specify the third.</p>\n<p>Also commended to younger <i>Shtetl Optimized</i> readers the (true? or at the very least, much-celebrated!) physics story about &#8220;<a href=\"https://en.wikipedia.org/wiki/History_of_entropy#Information_theory\" rel=\"nofollow\">What von Neumann Said to Shannon</a>&#8220;</p>\n<blockquote><p>&#8220;My [Claude Shannon&#8217;s] greatest concern was what to call it. I thought of calling it &#8216;information&#8217;, but the word was overly used, so I decided to call it &#8216;uncertainty&#8217;. </p>\n<p>When I discussed it with John von Neumann, he had a better idea. Von Neumann told me:</p>\n<blockquote><p>You should call it entropy, for two reasons: In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. </p>\n<p>In the second place, and more important, nobody knows what entropy really is, so in a debate you will always have the advantage.</p></blockquote>\n</blockquote>\n<p>Needless to say, history has proven von Neumann right!&nbsp;\ud83d\ude42</p>\n<p>Also commended is the recent Simons Institute/<i>Quanta Magazine</i> article in which &#8220;K&auml;hler structures&#8221; appear, namely Kevin Hartnett&#8217;s profile of the algebraic geometer June Huh, title &#8220;<a href=\"https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/\" rel=\"nofollow\">A Path Less Taken to the Peak of the Math World</a>&#8220;:</p>\n<blockquote><p>In 2015 he [Karim Adiprasito] traveled to IAS and visited [June] Huh. Adiprasito realized that while the Hodge index theorem alone would explain log concavity, the way to prove the Hodge index theorem for matroids was to try and prove a larger set of ideas from Hodge theory that includes the Hodge index theorem&nbsp;&mdash; what the three collaborators refer to as &#8216;the K&auml;hler package.&#8217;</p></blockquote>\n<p>Without any pretense that I myself grasp the specific (Hodge-theoretic)  K&auml;hler package that Huh and Adiprasito are exploring, it&#8217;s nice to appreciate that quantum mechanics is blessed with a particularly wide-ranging K&auml;hler package, namely the compatible triple of symplectic, metric, and complex structures on its state-space.  </p>\n<p>In essence, whenever we contemplate the fundamental K&auml;hlerian quantum triple of quantum dynamics, quantum measurement, and quantum operator algebra&nbsp;&mdash; or any of the many compatible triples that derive from this fundamental triple (including entropy-function triples)&nbsp;&mdash; our mathematical appreciation of any two of these attributes naturally extends our appreciation of the third attributes&nbsp;&mdash; sometimes in surprising ways.</p>\n<p>This K&auml;hlerian quantum package is manifest both in the Hilbert space that quantum supremacists cherish, and in the varietal state-spaces that quantum quasi-skeptics cherish.  For&nbsp;me at least, the existence of this shared K&auml;hlerian package provides a concrete reason why there need be no fundamental mathematical incompatibility between (triple-respecting) quantum supremacists and (triple-respecting) quantum quasi-skeptics.  </p>\n<p>To borrow a phrase from Melville &#8220;<a href=\"http://www.bartleby.com/91/18.html\" rel=\"nofollow\">In this we can all splice hands&nbsp;&hellip; mathematically</a>!&#8221;&nbsp;\ud83d\ude42</p>\n]]>", "author": "John Sidles", "published": "2017-07-26 21:37:47+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>QuanThomas #184: It&#8217;s a good question, though it seems effectively the same as the question I answered for wolfgang (see #56 and #63).  As I was trying to say there&#8212;I probably didn&#8217;t do a good job&#8212;what&#8217;s bounded by Bekenstein-type bounds is effectively the number of bits that you can set arbitrarily and then store in a hard drive with given dimensions, in such a way that they can be reliably retrieved later.  It&#8217;s not the number of bits needed to describe the laws of physics themselves with all their parameters.  The latter we think of as simply being O(1)&#8212;or <i>maybe</i> there&#8217;s an infinitely long message from God encoded into the electron/proton mass ratio, or something like that.  But even if so, it would take exp(n) time to decide the first n bits of the message, so it&#8217;s not as if it&#8217;s very easily accessible.  Nor would we, as beings within the universe, be able to modify the message at will (something that <i>would</i> violate the Bekenstein bound).</p>\n]]>", "author": "Scott", "published": "2017-07-26 22:53:54+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>John (# 185) The idea that these different notions of entropy form a K\u00e4hlerian triple is, how shall I say it, a bold conjecture. I would be more than astonished if it were true. To paraphrase Bell, if someone offers a proof I will listen, but I would not attempt such a proof myself.</p>\n]]>", "author": "Tim", "published": "2017-07-26 23:31:40+00:00", "title": "By: Tim"}]