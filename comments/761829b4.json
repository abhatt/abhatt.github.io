[{"content": "<![CDATA[<p>I&#8217;m confused, because I still don&#8217;t understand how that prevents Alice from opening her envelope at 12:00 AM and finding &#8220;heads&#8221; and Bob opening his at 12:05 AM (6 hours before the wave front from Earth hits him) and finding &#8220;tails&#8221;.</p>\n]]>", "author": "C Murdock", "published": "2017-01-04 18:45:29+00:00", "title": "By: C Murdock"}, {"content": "<![CDATA[<p>C Murdock #85: I&#8217;m confused about what <i>you&#8217;re</i> confused about, so maybe someone else should take a crack at explaining it?</p>\n]]>", "author": "Scott", "published": "2017-01-04 20:07:12+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>From Carroll on Bayes&#8217; theorem:</p>\n<blockquote><p>If you say, \u201cI have no idea whether that\u2019s true or not,\u201d you\u2019re really just saying, \u201cMy prior is 50%.\u201d</p></blockquote>\n<p>This view seems widespread, but I don&#8217;t know that it makes much sense, even if taken normatively.</p>\n<p>E.g. I don&#8217;t think it&#8217;s irrational to simultaneously have &#8220;no idea&#8221; whether 1. A is true or not, 2. B is true or not, and 3. (A & B) is true or not.</p>\n]]>", "author": "Leon", "published": "2017-01-05 04:12:16+00:00", "title": "By: Leon"}, {"content": "<![CDATA[<p>From <a href=\"https://www.edge.org/response-detail/27098\" rel=\"nofollow\">Carroll on Bayes&#8217; theorem</a>:</p>\n<blockquote><p>Whether you admit it or not, no matter what data you have, you implicitly have a prior probability for just about every proposition you can think of. If you say, \u201cI have no idea whether that\u2019s true or not,\u201d you\u2019re really just saying, \u201cMy prior is 50%.\u201d</p></blockquote>\n<p>I don&#8217;t think this is true, even if taken normatively.</p>\n<p>Counterexample: &#8220;I have no idea about A&#8221; and &#8220;I have no idea about B&#8221; are compatible with &#8220;I have no idea about (A and B)&#8221; without A and B being equivalent.</p>\n]]>", "author": "Leon", "published": "2017-01-05 05:11:06+00:00", "title": "By: Leon"}, {"content": "<![CDATA[<p>Leon #88,</p>\n<p>It seems Caroll doesn&#8217;t care to discuss it, but yes that&#8217;s a well known loophole.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Ellsberg_paradox\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Ellsberg_paradox</a></p>\n]]>", "author": "Jay", "published": "2017-01-05 18:00:03+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>Leon #87: As a believer in the concept of Knightian uncertainty, I also disagree with that particular statement.</p>\n]]>", "author": "Scott", "published": "2017-01-05 19:26:42+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>>> universality and superintelligence</p>\n<p>I am quite proud to be a human being, after all we have figured out how most of the universe actually works &#8211; from the standard model to the big bang.<br />\nSure there are some open problems and perhaps some aliens have an easier time with superstrings or the measurement problem than we do. But we have decades of research ahead of us (if we are lucky).</p>\n<p>In my opinion there are actually two independent miracles here:<br />\ni) It is quite amazing that a bunch of apes, after a few million years of brain evolution on a tiny planet, was able to figure out math and physics.<br />\nii) It is perhaps even more amazing that the world is such that it can be figured out. This is mostly due to the fact that the basic laws of nature are simple and elegant in a certain way (this includes the 2nd law btw) and a priori it could be quite different imho.</p>\n<p>If one wants to look for meaning in this world, this is where one could start.</p>\n]]>", "author": "wolfgang", "published": "2017-01-05 21:53:27+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Leon and Scott,</p>\n<p>Yes I too have become a believer in &#8216;Knightian uncertainty&#8217;.  That means Carroll is simply wrong here.</p>\n<p>Bayesian inference is not the foundation of rationality, because even *before* any probability assignments can be made, you need to have an underlying model or vocabulary for talking about a particular domain , and there will always be some irreducible fuzziness or imprecision in the model itself.  So you need an extra measure (not itself a probability) to handle this meta-uncertainty in the model itself.</p>\n<p>The measure you need is &#8216;conceptual coherence&#8217;, the degree to which the concepts or vocabulary you&#8217;re using *coherence* into a integrated explanatory whole.</p>\n<p>The correct foundation of rationality is categorization (or reflection), not Bayesian inference.</p>\n<p>This can be clearly be seen in my top-level &#8216;domain model of reality&#8217; at link here:<br />\n<a href=\"http://www.zarzuelazen.com/CoreKnowledgeDomains2.html\" rel=\"nofollow\">http://www.zarzuelazen.com/CoreKnowledgeDomains2.html</a></p>\n<p>Here I treat reality as a &#8216;language&#8217;, and you can clearly see a grand pattern whereby knowledge domains arrange themseleves hierarchically into a fractal structure, with a &#8216;3-level recursion&#8217; &#8211; any language of unbounded complexity always needs 3-levels of recursion (object, meta and meta-meta).   </p>\n<p>At link above, go to left-hand column, look to middle grouping of 3 domains , and there&#8217;s the 3-level recursion for rationality :<br />\nCategorization (Reflection), Probability Theory and Logic</p>\n<p>It&#8217;s clear that categorization is the root and probability theory is on the 2nd level.</p>\n]]>", "author": "mjgeddes", "published": "2017-01-05 22:39:19+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>#64 Daniel</p>\n<p>The mitochondria are inherited only from <i>the mother</i>, not &#8220;one parent&#8221; as you said &#8211; I guess you know what you meant but your sentence is perhaps  a little sloppy just like Helena Cronin&#8217;s in her courageous contribution (Which seems mostly sensible to me)</p>\n<p>Get well soon Scott. As for solipsism, can we not just ask someone something which we couldn&#8217;t possibly know (eg translate this sentence into Japanese), or something simple like &#8220;what&#8217;s around the corner?&#8221; before you get there. Other minds have to exist or else we are omniscient &#8211; not a proof, I don&#8217;t think there can be absolute proof against idealism, but convincing enough for little me.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gallagher:James.html\">James Gallagher</a>", "published": "2017-01-07 21:39:18+00:00", "title": "By: James Gallagher"}, {"content": "<![CDATA[<p>James #93: Fortunately, my ankle is mostly healed&#8212;I can walk and only feel it occasionally!  Thanks for asking.</p>\n<p>Yes, you&#8217;re pointing to special cases of the autonomous, non-dreamlike nature of the external world, which is the general fact that I think makes solipsism such a terrible theory.  Even if you&#8217;re arrogant enough to think that everyone besides you is a mindless automaton or philosophical zombie&#8212;even so, <i>they&#8217;re not zombies that you just imagined,</i> for example because they too often know things that you don&#8217;t know but can verify later.</p>\n]]>", "author": "Scott", "published": "2017-01-07 23:04:35+00:00", "title": "By: Scott"}]