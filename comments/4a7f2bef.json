[{"content": "These sorts of reviews also have a very detrimental effect on the field, in that they discourage researchers from finding the simplest way to present their results.(Even if the researchers themselves are not deliberately trying to dress up their results as more complicated than they really are, the complicated ones are the ones that make it through the review filter.)<br /><br />That is one of the reasons I like the Canadian Conference on Computational Geometry as a model: it&#39;s not a high-prestige conference, because they take almost all the submissions that are on topic, novel, and not obviously wrong. But they&#39;re not afraid to take the small &quot;easy&quot; results that help build the literature but do not look deep enough to go to more prestigious conferences, and I think it&#39;s important to have a place for these results.", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:D=.html\">D. Eppstein</a>", "published": "2013-11-18 14:24:30.523000-05:00", "title": ""}, {"content": "Thankfully in CS systems research, the opposite is true. Papers are rejected because the solution presented is too complex. Simple and somewhat correct wins over complex and correct.<br /><br />The underlying system tends to be quite complex (take a look at any recent SOSP/OSDI paper), but the underlying central idea tends to be really simple, and explainable in 2-3 sentences/bullet points.", "author": "PS", "published": "2013-11-18 15:04:32.130000-05:00", "title": ""}, {"content": "I&#39;ve started sometimes stating explicitly and prominently in the intro of papers something like:<br />&quot;an important advantage of this result is that it&#39;s analysis and algorithm are very simple,&quot; when relevant.  <br /><br />The sample size is still too small to know if it has helped, but it has prevented reviews that directly complain it is not complicated enough.  ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/P:Jeff.html\">Jeff P</a>", "published": "2013-11-18 15:17:14.823000-05:00", "title": ""}, {"content": "To echo what MM says: if the question is deemed of interest, simplicity in the solution should be considered an asset not a drawback. <br /><br />Sadly this is not the case in TCS today. The more selective the conference, the more enamored with proof difficulty they seem to be.", "author": "Anonymous", "published": "2013-11-18 16:14:05.836000-05:00", "title": ""}, {"content": "Hi Michael,<br /><br />  I sympathize with the issue you raised. My  &quot;partial solution&quot;  that I employed over the last  few years will not come as a novelty or surprise to you, but it seems to be reasonably effective. Specifically: if something is simple and looks like it could actually work, I try to code it up (well, get my students to do it) and get at least some empirical results. They could end up in the paper itself, or in the pre/post-cursor. Many (although perhaps not all) good theory venues will find an empirical validation to be a valuable addition to the paper.  As an added bonus, the paper can attract a much wider audience, and ultimately have more impact. <br /><br />Piotr", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html\">Piotr Indyk</a>", "published": "2013-11-18 17:52:15.617000-05:00", "title": ""}, {"content": "JeffP  :  I think it&#39;s very useful to do what you say (and I do it myself);  I&#39;m unconvinced that it&#39;s effective.  One paper I submitted had &quot;Simple&quot; in the title, but the reviewers still thought it was too simple.  :)<br /><br />Piotr:  Similarly, I completely agree with you that I think experiments are good to add to (algorithmic) theory papers.  However, I don&#39;t think this is really a positive or negative in terms of getting papers accepted (to theory conferences).  In fact, I&#39;ve had reviews where people have told me to remove simulations (that I felt were important) from theoretical venues, so at least some people view them as a negative.  (Why do you need simulations?  You have a proof.)<br /><br />", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2013-11-18 19:43:09.951000-05:00", "title": ""}, {"content": "It&#39;s even worse when one reviewer thinks the paper is uninteresting for being &quot;too simple&quot; and another reviewer considers the same submission &quot;too complicated&quot;.<br /><br />Usually &quot;simple&quot; also means smaller constants, which is a definite plus.", "author": "Mahdi", "published": "2013-11-18 19:59:51.747000-05:00", "title": ""}, {"content": "We&#39;ve tried JeffP suggestion on our own, first with a small sentence, then with an entire paragraph. In both cases the paper got rejected with &quot;too simple&quot; as sole reason, in spite of resolving several well studied open questions. We then submitted it to a journal and rejected again for the same reason. <br /><br />This time we challenged the decision through the editor (first time we ever done this) and requested that the referee explain why simplicity was a drawback of our paper. Only then the referee stopped long enough to ponder about this, and to his/her credit replied saying &quot;indeed simplicity in this case is a plus&quot;. <br /><br />Total time elapsed from submission to first conference to accept decision from journal? over four years.", "author": "Anonymous", "published": "2013-11-18 21:35:24.621000-05:00", "title": ""}, {"content": "In defence of referees, it is sometime very hard to tell the difference between simple and trivial. That is why, when refereeing, I usually try to figure out the main result of a paper on my own before I read the technical part. <br /><br />And indeed, sometime, a thing looks easy, but it takes months to come up with it. Sometime all you need is one simple definition.<br /><br />However, it is not true that simple things get rejected automatically. You just need to add additional results to the paper to convince the referees that the mass is there.<br /><br />But yes, I also got bitten by the &quot;its too easy bug&quot;. I take it as the price of doing business...<br /><br />--Sariel", "author": "sariel", "published": "2013-11-18 22:36:06.363000-05:00", "title": ""}, {"content": "The reason why papers with simple proofs are considered &quot;uninteresting&quot; boils down to the fact that it is very hard to estimate significance of the problem itself. The reason for this is that most research in TCS has little relevance to practical problems and algorithms. What&#39;s important and interesting is guided primarily by mathematical tastes and CV building efforts of the community members. This is not unique to TCS: theoretical research in economics, physics and several other areas have similar problems. In such a world the problems themselves become secondary to many other interests (both mathematical and personal). <br /><br />So if you write a paper on a problem that has not been explored  (much) before and has a simple solution then a natural reaction is to classify it as a shallow question which is not worth much attention.<br />", "author": "Anonymous", "published": "2013-11-18 23:21:20.797000-05:00", "title": ""}, {"content": "Anon 11:41pm gives a good explanation of how the preference for technical results came to be. The problem is when referees solely prefer complexity even when there is evidence that the problem is interesting and/or well explored as was the case for both Michael (&quot;solved an at least seemingly interesting and/or useful problem&quot;) and Anon 9:35pm (&quot;resolving several well studied open questions&quot;).<br />", "author": "Anonymous", "published": "2013-11-18 23:54:40.852000-05:00", "title": ""}, {"content": "@David Eppstein :<br /><br />My version of your CCCG is the Allerton Conference.  I don&#39;t think it&#39;s viewed as high-prestige, but I&#39;ve more than once used it as an outlet for results that didn&#39;t seem to have another natural conference home.  And it turns out it&#39;s a very good conference, in that there&#39;s a lot of networking/EE theory people there or paying attention to it, and they seem to have less of an aversion to &quot;simple&quot;.  ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2013-11-19 00:07:39.048000-05:00", "title": ""}, {"content": "I agree with Piotr, but from a slightly different angle. In my experience, a typical dilemma with such papers is whether to submit them to a 2-tier theory conference or to a 1-tier applied conference. Some of the advantages of the latter choice are 1) wider dissemination 2) opportunity to express simple ideas simply rather than complying to established theory writing standards, which can obfuscate basic ideas quite a lot (e.g. by throwing in unnecessary levels of generality, formalism, etc.). ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaroslavtsev:Grigory.html\">Grigory Yaroslavtsev</a>", "published": "2013-11-19 00:28:29.945000-05:00", "title": ""}, {"content": "My experience with experimental sections for papers has been similarly negative. In one recent case, we had a worst case analysis that at first looked fairly pessimistic and unlikely to occur, thus leaving open the question of whether to use the algorithm in practice or not. We then ran experiments showing that &quot;typical&quot; inputs (as opposed to worst case) were as bad as the worst case theorem had predicted only for the referee to complain: &quot;experiments are not needed, theorem is already there&quot;.<br /><br />In this specific case the paper had other flaws so this wasn&#39;t a deciding factor in the rejection, but it does back up the point that not all referees see experimental sections favorably. ", "author": "Anonymous", "published": "2013-11-19 01:16:51.237000-05:00", "title": ""}, {"content": "Is this a more recent phenomenon, or has there always been a bias against simpler/less surprising papers?", "author": "GZ", "published": "2013-11-19 11:54:45.491000-05:00", "title": ""}, {"content": "@Anon 1:16 AM, @ Michael Mitzenmacher (regarding negative feedback on experiments described or referred to in submissions to theory conferences): <br /><br />I guess all of us deal with limited sample sizes, which makes it hard to infer general trends. Still, in my experience, the feedback ranged from neutral (as in, the value was lost on the reviewers) to positive (the reviewers though that experiments add value to the paper). I don&#39;t remember ever getting a negative feedback, although I am sure there is a first time for everything. <br /><br />This isn&#39;t all roses, of course: I did have a paper rejected as &quot;impractical&quot;, despite a clear reference to a followup publication at an applied conference using the algorithm.  Of course, it is often hard to tell what were the main reasons for the decision.", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html\">Piotr Indyk</a>", "published": "2013-11-19 14:12:35.486000-05:00", "title": ""}, {"content": "<i> I did have a paper rejected as &quot;impractical&quot;, despite a clear reference to a followup publication at an applied conference using the algorithm. </i><br /><br />He, he. I have the distinction of having three papers studying algorithms from actual commercial production systems be rejected because said algorithms were, according to the referee, impractical. What makes it funnier, is that the reviewer was likely in academia with little or no insight into what is or isn&#39;t used in the real world.<br /><br />One of the problems is that because of NDAs we cannot write: &quot;this family of algorithms is in use in Cisco Catalysts&quot;. All we can say is &quot;this is the family of algorithms running in various modern network switches&quot;.", "author": "Anonymous", "published": "2013-11-19 15:17:14.296000-05:00", "title": ""}, {"content": "I&#39;ve always wondered who these bad referees are that so unjustly victimize our whole community. Their code of silence seems much stronger than the mafia&#39;s.  The bad referees seem to be legion, but I&#39;m not aware than anyone has ever admitted to being one.  ", "author": "Anonymous", "published": "2013-11-19 21:17:35.680000-05:00", "title": ""}]