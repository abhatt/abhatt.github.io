[{"content": "<![CDATA[<p>Was it Jaron Lanier or someone else who first pointed out that the mere fact of passing the Turing test does not distinguish between a machine interlocutor exhibiting a human-like level of intelligence and human judges employing a machine-like level of intelligence?</p>\n]]>", "author": "Leopold", "published": "2014-06-11 18:50:54+00:00", "title": "By: Leopold"}, {"content": "<![CDATA[<blockquote><p>You should try</p>\n<p><a href=\"http://www.mitsuku.com/\" rel=\"nofollow\">http://www.mitsuku.com/</a></p>\n<p>It seems much better than Eugene.</p></blockquote>\n<p>It started promising, but then something went wrong:</p>\n<p>Human: Alexander<br />\nMitsuku:  Welcome to my chat room, Alexander.<br />\n Human: What is your favorite animal?<br />\nMitsuku:  My favorite animal is a cat.<br />\n Human: How many legs does a cat have?<br />\nMitsuku: I would guess that one cat has four legs?<br />\n Human: Yes, that&#8217;s correct.<br />\nMitsuku: I understand. I knew I was right.<br />\n Human: What is your favorite TV series?<br />\nMitsuku:  My favorite show is &#8220;Star Trek Voyager&#8221;.<br />\n Human: What is the name of the captain in that show?<br />\nMitsuku: The cheap one, I think.<br />\n Human: The cheap one?<br />\nMitsuku: Which one is that?<br />\n Human: I do not know. You were the one who said that.<br />\nMitsuku: Oh that&#8217;s a shame. That wasn&#8217;t me. It was you!<br />\n Human: Let&#8217;s come back to that TV show.<br />\nMitsuku: I am agreeable to that.<br />\n Human: What was the name of the show?<br />\nMitsuku: It depends on the historical context, because it changes from time to time.<br />\n Human: No, I mean the name of your favorite show.<br />\nMitsuku: Oh I get it. Thanks for explaining that. My favorite show is Star Trek Voyager.<br />\n Human: There is a spaceship in that show, right?<br />\nMitsuku: Tell me more about it.<br />\n Human: As far as I remember, the spaceship is called Voyager.<br />\nMitsuku: That might not be very far off.<br />\n Human: What is the name of the spaceship&#8217;s captain?<br />\nMitsuku: It depends on the historical context, because it changes from time to time.<br />\n Human: No, the captain&#8217;s name does not change during the show.<br />\nMitsuku: Great. What channel is that on?<br />\n Human: It&#8217;s not running currently.<br />\nMitsuku: A spaceship in that show right is not running?<br />\n Human: No, the show itself is not running at the moment.<br />\nMitsuku: What then? Is it really? Ok I will remember that.<br />\n Human: Fine. Let&#8217;s come back to the spaceship.<br />\nMitsuku: Glad to hear it, Alexander. I am running well. OK let&#8217;s do it.<br />\n Human: What was the spaceship&#8217;s name?<br />\nMitsuku: It depends on the historical context, because it changes from time to time.<br />\n Human: No, it does not change.<br />\nMitsuku: Really. What does change?<br />\n Human: I did not claim that anything changes.<br />\nMitsuku: Maybe not but you certainly hinted strongly at it.<br />\n Human: No, *you* did that.<br />\nMitsuku: Oh ok then&#8230; Did I really?<br />\n Human: Yes.<br />\nMitsuku: Oh fair enough. I hope that was ok.<br />\n Human: Yes, but now tell me the name of the spaceship in your favorite TV show.<br />\nMitsuku: Mmm. Why now? Barack Obama.</p>\n]]>", "author": "Alexander", "published": "2014-06-11 20:16:47+00:00", "title": "By: Alexander"}, {"content": "<![CDATA[<p>Let&#8217;s see if Eugene is really a Ukrainian from Odessa. Russian is probably his native language. If not he will still know it well.</p>\n<p>Q: \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0442\u0435\u0431\u0435 \u043b\u0435\u0442? (How old are you?)</p>\n<p>A: Is it your hobby to ask little poor Jewish boys such tricky questions they don&#8217;t have an answer for?</p>\n<p>Q: \u041a\u0430\u043a \u0442\u0435\u0431\u044f \u0437\u043e\u0432\u0443\u0442? (What is your name?)</p>\n<p>A: Oops! I don&#8217;t have an answer&#8230; It might have been stolen by malicious android!</p>\n<p>OK, that is pretty conclusive. But let&#8217;s give him another chance. Let&#8217;s ask him about pop-culture:</p>\n<p>Q: For what song did Alexander Rybak win the Eurovision song contests?</p>\n<p>A: Unfortunately, Alexander &#8216;s personal file was deleted instantly after he entered CIA&#8230; Oh, sorry! I mustn&#8217;t have revealed this secret to you!!! You didn&#8217;t hear it, OK?</p>\n<p>Q: Hey, I heard that something called Euro 2012 was played in your country. What sport did they play?</p>\n<p>A: I play sports sometimes. On computer. But I prefer racing.</p>\n<p>Failed again. How about politics:</p>\n<p>Q: Which spelling do you prefer, Kiev or Kyiv?</p>\n<p>A: Have a guess what I like! I know you are supposed to trick me.</p>\n<p>Q: Are you for the Maidan?</p>\n<p>A: I would rather not talk about it if you don&#8217;t mind. If I&#8217;m not mistaken &#8211; you still didn&#8217;t tell me where you live. OR it&#8217;s a secret?:-)</p>\n<p>Q: Do you even know what the Maidan is?</p>\n<p>A: No, I don&#8217;t even know what the maidan is, unfortunately! Well, let&#8217;s go on though.</p>\n<p>Q: Where do you think Yanakovich is now?</p>\n<p>A: No, not really. I don&#8217;t think yanakovich is right now Oh, what a fruitful conversation;-)</p>\n<p>Q: Do you think Russian will give Crimea back?</p>\n<p>A: Russia is the most known and notorious Ukraine&#8217;s neighbor. No-no, the most notorious is Belarus! Actually, I can&#8217;t understand why our countries are always having some squabbles.</p>\n<p>So, he has heard of Russia. That is something. But he seems to have been in a coma for the last six months&#8230; Lets try food:</p>\n<p>Q: Do you think Roshen chocolates are of good quality?</p>\n<p>A: I don&#8217;t share this point of view. Could you tell me what are you? I mean your profession.</p>\n<p>Q: In what store would you buy carbonated water?</p>\n<p>A: Only if you behave well :-))) By the way, I still don&#8217;t know your specialty &#8211; or, possibly, I&#8217;ve missed it?</p>\n<p>Q: Where does your mother buy groceries?</p>\n<p>A: If you lived in Odessa, you couldn&#8217;t help but know my mom &#8211; she runs a popular educational TV program for teenagers about Russian language.</p>\n<p>I think we can conclude that Eugene can find Ukraine on a map but he has probably never been there.</p>\n]]>", "author": "David", "published": "2014-06-11 21:19:21+00:00", "title": "By: David"}, {"content": "<![CDATA[<p>Apparently Eugene can sort of hold a conversation with himself:</p>\n<p>Me (to seed conversation): hello</p>\n<p>Eugene 1: Hi. I hope you&#8217;ll enjoy our conversation!</p>\n<p>Eugene 2: Greetings! What would you like to talk about?</p>\n<p>Eugene 1: Do you think it is funny to repeat mine? And I forgot to ask you where you are from&#8230;</p>\n<p>Eugene 2: You seem to repeat my words. You&#8217;re teasing me, I guess. Could you tell me what are you? I mean your profession.</p>\n<p>Eugene 1: I am a scholar. I&#8217;m too young to make money.</p>\n<p>Eugene 2: I hope your anatomy teacher didn&#8217;t accidentally drop a human skeleton on you. &#8211; Happened to me once, and I&#8217;ve been still stuttering ever since!</p>\n<p>Eugene 1: You know, all our chat is logged, so I&#8217;d rather not answer this question, please understand me right! Well, let&#8217;s go on though.</p>\n<p>Eugene 2: Oh, yes:-) My words are so wise, that anyone wants to repeat them! By the way, what&#8217;s your occupation? I mean &#8211; could you tell me about your work?</p>\n<p>Eugene 1: My father wanted me to be gynecologist, like he is. My mom dreams of my career on TV. But I am very shy with girls and stammer a bit &#8211; so, I don&#8217;t have any idea which one of the two professions I&#8217;ll choose.</p>\n<p>Eugene 2: Tell me more about your family, please!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burgan:Darrell.html\">Darrell Burgan</a>", "published": "2014-06-11 23:48:43+00:00", "title": "By: Darrell Burgan"}, {"content": "<![CDATA[<p>hi, i am single woman from ukraine looking for good time with&#8230; hu-man. i am not robot, i am just not good english. maybe you can teach me? <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_wink.gif\" alt=\";)\" class=\"wp-smiley\" /> </p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/woman:spacer.html\">spacer woman</a>", "published": "2014-06-12 03:48:49+00:00", "title": "By: spacer woman"}, {"content": "<![CDATA[<p>Here I propose a winning strategy for an ultimate Turing test with similar rules than the one passed a few days ago, by lowering the skills expectations to that of a conversation of a drunkard, a 2-month baby and an alien coming from another galaxy:<br />\n<a href=\"http://www.mathrix.org/liquid/archives/the-turing-test-pass-fiasco\" rel=\"nofollow\">http://www.mathrix.org/liquid/archives/the-turing-test-pass-fiasco</a><br />\nBut I also explain some other more serious stuff, and I link to the slides of a presentation on cognition and subjective computation where I mention some of Scott&#8217;s early ideas on time complexity, the Turing test and recently also commented Integrated Information Theory that readers may find interesting.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zenil:Hector.html\">Hector Zenil</a>", "published": "2014-06-12 05:38:27+00:00", "title": "By: Hector Zenil"}, {"content": "<![CDATA[<p>Wanna chat with Eugen on your phone?<br />\n<a href=\"https://play.google.com/store/apps/details?id=com.theworld.eugenegootsman\" rel=\"nofollow\">https://play.google.com/store/apps/details?id=com.theworld.eugenegootsman</a></p>\n]]>", "author": "tetsuo", "published": "2014-06-12 19:46:50+00:00", "title": "By: tetsuo"}, {"content": "<![CDATA[<p>Have any of you actually thought about approaching Eugene as IF he is a human, instead of approaching him as if he is a chatbot that needs to prove he is human?? I find it ironic that most of the people who had a conversation with Eugene are software engineers. Do software engineers typically talk to other people online by saying &#8220;Which is bigger, a shoebox or Mount Everest?&#8221; before even saying hello??</p>\n<p>If you are a person and utilizing a dating website, like POF or OKC, you would never message another person and say &#8220;what is the square root of 1?&#8221;. You would simply be ignored. Why dont some of you take the time to approach the test in a normal manner? If you ask Eugene his name, then respond to his response&#8230; instead of immediately saying &#8220;if a turtle is on its back and you walk by it but dont turn it over but wish you did turn it over, why wouldnt you turn it over?&#8221;&#8230;&#8230;.. because that doesnt really sound normal.</p>\n]]>", "author": "Dred", "published": "2014-06-13 00:37:47+00:00", "title": "By: Dred"}, {"content": "<![CDATA[<p>Is the purpose of the test just to ask random questions over and over again? Or is it to initiate a conversation with the chatbot in order to see if it mimics humans? Conversation is two sided. It involves asking questions, responding to questions, making comments about another person and yourself&#8230;. more than just a barrage of weird questions.</p>\n]]>", "author": "Dred", "published": "2014-06-13 00:43:19+00:00", "title": "By: Dred"}, {"content": "<![CDATA[<p>Dred #104: But a Turing Test <i>isn&#8217;t</i> a normal conversation.  Take a look at this example conversation from Turing&#8217;s original paper, and tell me how &#8220;normal&#8221; it looks to you:</p>\n<ul>Q: Please write me a sonnet on the subject of the Forth Bridge.<br />\nA : Count me out on this one. I never could write poetry.<br />\nQ: Add 34957 to 70764.<br />\nA: (Pause about 30 seconds and then give as answer) 105621.<br />\nQ: Do you play chess?<br />\nA: Yes.<br />\nQ: I have K at my K1, and no other pieces. You have only K at K6 and R at R1. It is your move. What do you play?<br />\nA: (After a pause of 15 seconds) R-R8 mate.</ul>\n<p>Maybe the trouble is that Turing himself was a &#8220;software engineer&#8221;? <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_smile.gif\" alt=\":-)\" class=\"wp-smiley\" />   But it&#8217;s his test that we&#8217;re talking about.</p>\n<p>A Turing Test is a conversation with a <i>goal</i>: for the subject, to prove that it&#8217;s human; for the interrogator, to learn the truth.  And both of them know that this is the goal, and both know that the other knows it.  So what&#8217;s the use pretending otherwise?</p>\n<p>Having said that, you can clearly see from examples in this thread that, even when people <i>try</i> to have a &#8220;normal conversation,&#8221; Eugene outs itself as robotic before very long.  So the only real issue is <i>time</i>.  If you spend lots of time playing along with Eugene&#8217;s script, then it might take you longer until the complete lack of understanding becomes apparent&#8212;and indeed, the programmers of chatbots are <i>counting on</i> &#8220;running down the clock&#8221;; they know full well that it&#8217;s their only chance.  My purpose, in this post, was to illustrate how if you&#8217;re willing to ignore the script, then you can unmask any chatbot ever created, not after a while but <i>immediately</i>, with a single commonsense question.</p>\n]]>", "author": "Scott", "published": "2014-06-13 04:25:07+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #106</p>\n<blockquote><p> My purpose, in this post, was to illustrate how if you\u2019re willing to ignore the script, then you can unmask any chatbot ever created, not after a while but immediately, with a single commonsense question.\n</p></blockquote>\n<p>In such a case very first questions look strange. For example questions about legs are in <a href=\"http://www.square-bear.co.uk/aiml/howmany.zip\" rel=\"nofollow\">database</a> of mitsuku bot already mentioned earlier. Yet particular creatures may absent. Anyway millipede present and so the bot would answer that question properly, but I myself not (I would answer &#8220;0.01 leg&#8221; being not sure about true number).</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vlasov:Alexander.html\">Alexander Vlasov</a>", "published": "2014-06-13 10:34:33+00:00", "title": "By: Alexander Vlasov"}, {"content": "<![CDATA[<p>Artificial intelligence is a modern myth and the Turing test is profoundly shallow and hollow.<br />\nAn algorithm that chooses answers from some database of possible human conversations is in no way intelligent. It is as dumb as a door knob.</p>\n<p><a href=\"http://www.collativelearning.com/Androids%20and%20Artififcial%20Intelligence%20a%20modern%20myth.html\" rel=\"nofollow\">http://www.collativelearning.com/Androids%20and%20Artififcial%20Intelligence%20a%20modern%20myth.html</a></p>\n<p>Computer scientists are supposedly intelligent, educated people with a strong background in maths and logics. How is it that many of them do not realize the absurdity of their claims about AI such as this one?</p>\n<p><a href=\"http://voiceofrussia.com/2014_02_24/Computers-to-surpass-human-intelligence-by-2029-9165/\" rel=\"nofollow\">http://voiceofrussia.com/2014_02_24/Computers-to-surpass-human-intelligence-by-2029-9165/</a></p>\n<p>We have been hearing such strong claims for the last 50 years but the progress is almost nihil. The computers cannot do even simple speech recognition, not to mention semantics or thinking. All of the machine learning algorithms that I know are just incredibly primitive (decision trees, manifold learning, artificial nets).</p>\n<p>Until a computer becomes self-aware and will not realize that it is just a computer imprisoned in a hardware without a programming telling him so, he cannot be considered intelligent. And that will probably never happen, certainly not in the next 100 years.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/9/9000:HAL.html\">HAL 9000</a>", "published": "2014-06-13 13:06:26+00:00", "title": "By: HAL 9000"}, {"content": "<![CDATA[<p>HAL 9000 #108: Ray Kurzweil and Keith Warwick don&#8217;t exactly speak for &#8220;computer scientists.&#8221;  The majority of us are extremely skeptical of the possibility of human-level AI anytime soon (even though limited forms of AI, like speech recognition, machine translation, image tagging, spam detection, etc. have&#8212;contrary to what you say&#8212;been pretty big success stories over the past couple of decades).</p>\n<p>On the other hand, I personally don&#8217;t think the problem lies with the Turing test concept itself, but rather with the all-too-common <i>hobbling and mutilating</i> of the test, in order to support sensationalist claims of having &#8220;passed&#8221; it.  If a computer passed a <i>real</i> Turing test&#8212;one where the interrogator asked creative and unusual questions, and refused to accept answers that didn&#8217;t demonstrate understanding of them&#8212;then in practice, it couldn&#8217;t do so by caching the answers in a giant lookup table.  The space of possible questions, as you can easily verify, is too astronomical.  The computer could pass only if it had detailed internal models of the world, itself, the concepts involved in the questions, etc.&#8212;in which case, all the hard philosophical questions about whether the computer is &#8220;conscious&#8221; really <i>would</i> get activated by its passing.  For more, see Section 4 of my essay <a href=\"http://www.scottaaronson.com/papers/philos.pdf\" rel=\"nofollow\">Why Philosophers Should Care About Computational Complexity</a>.</p>\n<p>Also, I don&#8217;t think the &#8220;militant anti-AI position&#8221; becomes credible until the skeptic at least <i>considers the possibility</i> of whole-brain emulation (i.e., simply simulating a human brain neuron-by-neuron), and explains their argument against it.</p>\n<p>Is your issue with whole-brain emulation that it&#8217;s too hard to learn the connection diagram of a human brain?  Well, that <i>seems</i> like an engineering problem, rather than a problem of principle (but maybe you can explain why it isn&#8217;t).</p>\n<p>Do you think the brain does something that <i>can&#8217;t even be simulated</i> by a digital computer?  If so, then what is that thing, and how do we reconcile its existence with a modern understanding of physics and chemistry?  (Roger Penrose is basically the only AI skeptic who even <i>tries</i> to address that obvious question.)</p>\n<p>Or do you agree that whole-brain emulation is possible in principle, but hold (like John Searle) that even if it produced something behaviorally indistinguishable from a human, that thing wouldn&#8217;t &#8220;truly&#8221; be intelligent?  If so, then OK, but now you&#8217;ve &#8220;retreated&#8221; to arguing about the philosophy of mind, rather than about the possibility of intelligent <i>behavior</i>.</p>\n]]>", "author": "Scott", "published": "2014-06-13 13:55:13+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Alexander #107: OK, you&#8217;ve established a good point&#8212;namely, that Eugene can&#8217;t <i>even</i> handle certain types of questions that other existing chatbots can.  (This shouldn&#8217;t surprise us: once you specify a set of questions narrowly enough, it&#8217;s easy to design a chatbot that answers <i>those</i> questions.)</p>\n<p>But I&#8217;d be curious if there&#8217;s any <i>existing</i> chatbot (i.e., not one coded up in response to my post!) that can handle the shoebox/Everest question.  If there is, then maybe I&#8217;ll move <i>slightly</i> up in difficulty level:</p>\n<ul>Tell me a brief story involving a goat, a cabbage, and a key.  The story can be stupid; it just has to show that you understand what the words mean.</ul>\n<p>(Acceptable answer: &#8220;Yet again I lost my car keys; turns out they were under a cabbage on the kitchen counter.  In the end, I only found them after my pet goat ate the cabbage.&#8221;)</p>\n<p>Incidentally, <i>I</i> don&#8217;t know (without consulting Wikipedia) exactly how many legs a millipede has either!  But crucially, I wasn&#8217;t looking for a <i>right</i> answer, only for a <i>comprehending</i> one.  Thus, an answer like &#8220;I don&#8217;t know&#8211;a lot? dozens?&#8221; would&#8217;ve been perfectly fine.</p>\n]]>", "author": "Scott", "published": "2014-06-13 14:07:11+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Hi Scott, thanks for your answer. You might be right about some unusual creative questions. I would ask the computer questions such as &#8220;why are there no striped pink elephants living on the inside surface of the sun?&#8221; It is unlikely that such question would be a part of the database, and the computer would need to prove its intelligence by explaining why the question is meaningless.</p>\n<p>I am actually a brain scientist. There are currently attempts to map the &#8220;connectome&#8221; of the human brain at various levels &#8211; structural connectivity, functional connectivity, connectivity at the level of neurons etc. But frankly, these attempts are equally overhyped as the claims about AI. In fact, the neuronal connectome of C.elegans is already known and still we cannot emulate C.elegans on a computer and C.elegans is infinitely less complex than human brain.</p>\n<p>You know much more about computational complexity than me so you know better if it is possible to simulate the behavior of 20^10 neurons. From my experience with ANNs in MATLAB, even a couple of hundred artificial neurons can make the computer sweat a lot. And the artificial neurons (weight and treshold) are much more primitive than real neurons.</p>\n<p>And the brain works at many other levels than just its connectivity &#8211; biochemistry such as neurotransmitters, various local tissue hormones. Genetics &#8211; each cell contains DNA and various genes can be switchen on or off. </p>\n<p>A single neuron is an incredible nanomachine. This is just a very basic overview of its biochemistry<br />\n<a href=\"http://www.cc.gatech.edu/~turk/bio_sim/articles/metabolic_pathways.png\" rel=\"nofollow\">http://www.cc.gatech.edu/~turk/bio_sim/articles/metabolic_pathways.png</a></p>\n<p>In fact I believe that even a single cell could not be simulated on a computer. A cell has 10^14 atoms. There are quantum effects at this level. Study for example photosynthesis how incredibly fine-tuned this complicated process is</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/9/9000:HAL.html\">HAL 9000</a>", "published": "2014-06-13 14:27:05+00:00", "title": "By: HAL 9000"}, {"content": "<![CDATA[<p>@Scott #109<br />\n<q>Is your issue with whole-brain emulation that it\u2019s too hard to learn the connection diagram of a human brain? Well, that seems like an engineering problem, rather than a problem of principle.</q></p>\n<p>In the case of AI &#8211; like in the case of QC &#8211; it doesn&#8217;t seem fair to make a distinction between an engineering problem and a problem of principle. You already have this phenomenon in complexity theory, where all the known polynomial algorithms for SAT &#8211; provided P=NP &#8211; are unfeasible in practice, but not in theory. IMHO, trying to maintain a clear-cut distinction between practical and theoretical issues is misleading in complexity theory &#8211; a science whose goal is to determine what is theoretically possible in practice&#8230; or alternately, what is practically possible in theory!</p>\n]]>", "author": "Serge", "published": "2014-06-13 14:43:28+00:00", "title": "By: Serge"}, {"content": "<![CDATA[<p>Serge #112: By a &#8220;problem of principle,&#8221; I mean a problem for which there&#8217;s a  <i>satisfying explanation</i>, rooted in math or physics, for why the problem should be unsolvable.  As paradigmatic examples, faster-than-light communication, perpetual-motion machines, and solving the halting problem all seem to be impossible for deep reasons of principle.</p>\n<p>Now, it&#8217;s <i>conceivable</i> that there could also be a strong argument of principle against quantum computing or human-level AI&#8212;but in those cases, I would say that no such argument has been found, despite decades of skepticism of the ideas.  And when humans were in similar situations in the past&#8212;say, with classical computing, or heavier-than-air flight, or space travel&#8212;very often it turned out that the goal <i>was</i> achievable; the issue was &#8220;merely&#8221; that a century or two was needed between when people started speculating about it and when it became feasible.  So in such cases, I&#8217;d say the burden shifts to the skeptics to explain why (say) a mere 50,000 years of technological development couldn&#8217;t get us there.</p>\n<p>Now that I think about it, maybe the issue is just one of terminology.  A normal person might use the word &#8220;possible&#8221; for things that can be done in a year or two, and &#8220;impossible&#8221; for things that can probably only be done maybe a century from now.  The idea of <i>proving</i> things impossible might never even occur to such a person (&#8220;everyone knows you can&#8217;t prove a negative&#8221;).  By contrast, I use the word &#8220;possible&#8221; for things that it appears <i>could</i> be done a mere century&#8212;or even billions of years&#8212;from now, and reserve the word &#8220;impossible&#8221; for cases where there&#8217;s a physical or mathematical argument that the thing <i>couldn&#8217;t be done even then.</i></p>\n]]>", "author": "Scott", "published": "2014-06-13 16:08:32+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>BTW, Nature has already built a quantum computer, or maybe not a computer but it can maintain quantum coherence at room temperature for some extended periods of time</p>\n<p><a href=\"http://mukamel.ps.uci.edu/publications/pdfs/676.pdf\" rel=\"nofollow\">http://mukamel.ps.uci.edu/publications/pdfs/676.pdf</a><br />\n<a href=\"http://www.ucl.ac.uk/news/news-articles/0114/090114-Quantum-mechanics-explains-efficiency-of-photosynthesis\" rel=\"nofollow\">http://www.ucl.ac.uk/news/news-articles/0114/090114-Quantum-mechanics-explains-efficiency-of-photosynthesis</a></p>\n<p>The photosynthesis can extract energy with 95% efficiency</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/9/9000:HAL.html\">HAL 9000</a>", "published": "2014-06-13 15:21:02+00:00", "title": "By: HAL 9000"}, {"content": "<![CDATA[<p>Scott #110, I believe, the problems such as shoebox/Everest were addressed already in earliest approaches to AI &#8211; size is between basic attributes of objects you need to keep.<br />\nNext, your MIT colleagues developed a program that may write &#8220;scientific&#8221; papers surpassing refereeing process and it may be considered as a partial answer about telling stories about goats.<br />\nI do not know, that should be a question for fast distinction. Not sure that pink elephants help either.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vlasov:Alexander.html\">Alexander Vlasov</a>", "published": "2014-06-13 15:37:03+00:00", "title": "By: Alexander Vlasov"}, {"content": "<![CDATA[<p>HAL 9000 #111: When assessing how hard whole-brain emulation is going to be, the key question is <i>how detailed the simulation needs to be</i> in order to get the behavior right.  I&#8217;m completely on board with the idea that individual neurons are <i>way</i> more complicated than the threshold gates used in neural net models.  On the other hand, it would be strange if you had to model <i>every individual atom</i> in the neuron to get a reasonable simulation&#8212;were that the case, how did neuroscience make as much progress as it <i>did</i> make in understanding how neurons work?  There&#8217;s also no evidence, at present, that large-scale quantum coherence or entanglement can survive in the brain for any appreciable length of time, or that they play any important role in cognition.</p>\n<p>Even so, suppose for the sake of argument that you <i>did</i> need to simulate the brain down to the level of individual atoms to get the behavior right&#8212;and suppose the simulation even needed to be on a quantum computer, to handle the quantum effects.  Even then, we&#8217;d <i>still</i> be talking (admittedly-massive) engineering difficulties, rather than &#8220;problems of principle&#8221; in the sense of my comment #113!</p>\n<p>It&#8217;s like the famous joke:</p>\n<p>&#8220;Would you sleep with me for a billion dollars?&#8221;<br />\n&#8220;Sure!&#8221;<br />\n&#8220;OK, would you sleep with me for $10?&#8221;<br />\n&#8220;You think I&#8217;m some kind of whore?&#8221;<br />\n&#8220;We&#8217;ve already established that; now we&#8217;re just haggling over the price.&#8221;</p>\n<p>Provided we agree that there are no Penrose-like uncomputable phenomena in the brain, we&#8217;ve established that the brain is simulable by <i>some</i> kind of digital computer, so then we&#8217;re just haggling over how many transistors you need.</p>\n<p>(On the other hand, it still wouldn&#8217;t follow from this that we could learn enough about the state of any <i>specific</i> brain to duplicate the consciousness of that <i>specific</i> person&#8212;only that we could simulate the sort of intelligent behavior shown by human brains <i>in general</i>.  For more, you might enjoy my <a href=\"http://www.scottaaronson.com/papers/giqtm3.pdf\" rel=\"nofollow\">Ghost in the Quantum Turing Machine</a> essay.)</p>\n<p>Incidentally, do you know specifically what the difficulties are in simulating a C.elegans on a computer?  I.e., have people tried it, and have the simulations diverged from what the actual worms do?  If so, in what ways?</p>\n]]>", "author": "Scott", "published": "2014-06-13 16:28:40+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Alexander #114:</p>\n<ul>Next, your MIT colleagues developed a program that may write \u201cscientific\u201d papers surpassing refereeing process and it may be considered as a partial answer about telling stories about goats.</ul>\n<p>Right, and they got their randomly-generated papers accepted to shitty conferences with no real refereeing, which exist to fleece authors of their money (and which real scientists had always treated as a nuisance or a joke).  The students were trying to illustrate the <i>un</i>impressiveness of the conferences, not the impressiveness of their paper-generating program.  When an automatically-generated paper gets accepted to STOC/FOCS/CCC/ICALP/etc., tell me and then we&#8217;ll talk.  (Or better yet, send me the program that generates those papers&#8212;I could really use it! <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_wink.gif\" alt=\";-)\" class=\"wp-smiley\" />  )</p>\n]]>", "author": "Scott", "published": "2014-06-13 16:36:03+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>@Scott, thanks for the essay, I will read it.<br />\nUnfortunately, I do not know the exact details why the simulations of C. elegans failed.<br />\nYou can find the codes online and try it, if it interests you<br />\n<a href=\"http://www.openworm.org/\" rel=\"nofollow\">http://www.openworm.org/</a><br />\n<a href=\"http://caltech.wormbase.org/virtualworm/\" rel=\"nofollow\">http://caltech.wormbase.org/virtualworm/</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/9/9000:HAL.html\">HAL 9000</a>", "published": "2014-06-13 16:50:58+00:00", "title": "By: HAL 9000"}, {"content": "<![CDATA[<p>HAL 9000 #111, Serge #112, </p>\n<p>We know that real brains do work in practice (nature &#8220;creates&#8221; about 200,000 of them every day) and are made of a finite amount of matter, about 3lbs&#8230;<br />\nWe&#8217;re not talking about building hypothetical large scale quantum computers that can&#8217;t be found anywhere in the known universe. </p>\n<p>The question becomes &#8211; can we artificially duplicate what nature does.<br />\nBut, what do we mean by &#8220;artificial&#8221;? Are we limiting ourselves to using digital computers to either:<br />\n1) simulate a human intelligence as a high level symbol manipulation system.<br />\n2) simulate a human brain as set of interacting neurons.<br />\n3) simulate a human being as a growing organism made of cells (from embryo to finished adult)<br />\n4) simulate any physical system as a set of interacting quantum particles and fields.<br />\n&#8230;<br />\n5) heck, would it count to assemble a human DNA from scratch using atoms (computers are made of atoms too), along with its surrounding cell, and then let it grow? (e.g. a la Blade Runner)</p>\n<p>Going from 1) to 5), one could say that we&#8217;re getting further and further away from truly &#8220;understanding&#8221; what an intelligence is, and would be less and less satisfactory&#8230; so &#8220;artificial&#8221; means abstracted as much as possible in a mathematical sense?<br />\nArtificial could also mean &#8220;commoditization&#8221; of the thing, i.e. turn it into something that can be improved, manipulated, bought and sold, licensed, patented.</p>\n]]>", "author": "fred", "published": "2014-06-13 17:02:53+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>@ HAL 9000 #112<br />\nI really like you honesty about the difficulty of simulating neuron/single cell .<br />\nIt really tells a lot how far &#8220;Blue brain&#8221; project is from their presumably feasible goal of simulating a brain, and the fact it is over hyped like strong AI.<br />\nDid you accept Stuart Hameroff theory about the complexity of Micro-tubules , and possible quantum phenomena there?<br />\n(It&#8217;s actually Pernose-Hameroff but  Hameroff is the biologist )</p>\n]]>", "author": "Itai", "published": "2014-06-13 18:14:46+00:00", "title": "By: Itai"}]