[{"content": "<![CDATA[<p>Sniffnoy #8: Excellent question!  Again: future research. \ud83d\ude42</p>\n<p>There are actually natural arithmetical statements known to be independent of PA, like Goodstein&#8217;s Theorem and the non-losability of the hydra game.  But all the ones I know are &Pi;<sub>2</sub>-sentences rather than &Pi;<sub>1</sub>-sentences.</p>\n]]>", "author": "Scott", "published": "2016-05-03 23:36:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Fantastic. Seems like a good candidate for a good Polymath project (similar to the prime gaps project) to lower this number as much as possible? It would need to draw on a bigger CS crowd than previous projects though, so I&#8217;m not sure where it should be hosted.</p>\n]]>", "author": "Qiaochu Yuan", "published": "2016-05-03 23:36:22+00:00", "title": "By: Qiaochu Yuan"}, {"content": "<![CDATA[<p>Could this sort of Turing machine efficient compiler tactics have any chance of being used to improve on the sort of results about how fast Busy Beaver grows at nearby values like the sort that we&#8217;ve discussed earlier.</p>\n]]>", "author": "Joshua Zelinsky", "published": "2016-05-04 00:50:53+00:00", "title": "By: Joshua Zelinsky"}, {"content": "<![CDATA[<p>&#8220;Turing machine that halts iff there\u2019s a counterexample to Goldbach\u2019s Conjecture&#8230;  this is the first time we\u2019ve had an explicit upper bound on how many states you need in a Turing machine before you can see the behavior in question&#8221; &#8211; one writes a Java program that halts iff there is a counterexample to Goldbach conjecture. One diligently translates this program into a Turing machine. One gets thus an upper bound on the minimal number of states of such a Turing Machine. What am I missing here?</p>\n]]>", "author": "anonymous", "published": "2016-05-04 00:50:59+00:00", "title": "By: anonymous"}, {"content": "<![CDATA[<p>anonymous #13: Well sure, doing that would give you <i>some</i> crappy upper bound, probably on the order of 100,000 states (or much more if you were actually compiling from Java).  I don&#8217;t know that anyone bothered, but I agree that it would be routine.</p>\n<p>Now, if you want a more respectable upper bound like 5,000 states, that takes more work, along with the on-tape processing and introspective encoding tricks.</p>\n<p>The question of whether you could construct (say) a 50-state Turing machine that encodes Goldbach remains open, and I confess interesting to me.</p>\n<p>Of course, if anyone actually <i>proves</i> Goldbach, we&#8217;ll then have a 1-state Turing machine that&#8217;s equivalent to it, namely one that just loops forever unconditionally! \ud83d\ude42  But no similar observation applies to the ZFC machine&#8212;there, the smallest n such that BB(n) is independent of ZFC really is a knowledge-independent constant that one could consider the &#8220;intrinsic complexity of ZFC.&#8221;  So, our main goal was to get the first nontrivial upper bound on that constant.  The Goldbach and Riemann machines were mostly just &#8220;comparison/control cases.&#8221;</p>\n]]>", "author": "Scott", "published": "2016-05-04 01:09:30+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Joshua #12: Yes!  In particular, the &#8220;introspective encoding&#8221; tactic of Ben-Amram and Petersen is directly relevant to that.  I actually first learned about introspective encoding when Luke Schaeffer and I were thinking about your &#8220;Ask Me Anything&#8221; challenge, and Luke realized that introspective techniques would let you show the existence of a constant C such that, for every computable function f and every n,</p>\n<p>BB(n + C*n/log(n) + O<sub>f</sub>(1)) > f(BB(n)).</p>\n<p>Luke even worked out an explicit value for C (I don&#8217;t remember what it was).  But then we found out that Ben-Amram and Petersen had done it earlier.</p>\n<p>Later, when Adam was building the small ZFC-independent machine with on-tape processing, Luke realized that introspective encoding would be relevant there as well.</p>\n]]>", "author": "Scott", "published": "2016-05-04 01:33:37+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Is it possible to convert your TM into the explicit 3&#215;3 matrices such that RH is true iff the &#8220;mortal matrix problem&#8221; isn&#8217;t solvable for these matrices? For all we know the determinants are all nonzero, which would immediately imply RH.</p>\n<p>Also, can you find the explicit 3SAT formula such that RH has a proof length at most n in ZFC iff the formula is satisfiable? It would be fun trying to guess satisfying assignments!</p>\n]]>", "author": "D", "published": "2016-05-04 01:51:40+00:00", "title": "By: D"}, {"content": "<![CDATA[<blockquote><p>Namely: do the axioms of set theory suffice to analyze the behavior of every computer program that\u2019s at most, let\u2019s say, 50 machine instructions long?  Or are there super-short programs that already exhibit \u201cG\u00f6delian behavior\u201d?</p></blockquote>\n<p>Excluding programs with access to a random number generator, right?</p>\n<p>Otherwise you can still shoehorn complexity by randomly assembling a TM and interpreting it.</p>\n]]>", "author": "Job", "published": "2016-05-04 01:57:16+00:00", "title": "By: Job"}, {"content": "<![CDATA[<p>D #16: Sure, you could run the reduction from our RH TM to the 3&#215;3 matrix mortality problem, although there&#8217;s probably a more direct way to do it (yielding fewer matrices with smaller entries), which would go through the Post Correspondence Problem or something close to it rather than through Turing machines.</p>\n<p>If you do this, I&#8217;ll bet my life savings that at least one of the matrices has zero determinant (and more generally, that this doesn&#8217;t yield a proof of RH), since no actual knowledge of number theory has been used in getting to this point&#8212;you&#8217;re just starting from Lagarias&#8217;s statement, then pouring the same mathematical content from one computational vessel into another one.</p>\n<p>I completely agree, constructing explicit 3SAT instances whose solutions encode proofs of RH would be another fun challenge for another motivated student! \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-04 02:14:46+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Job #17: Yes, of course, we&#8217;re talking about deterministic programs here.</p>\n]]>", "author": "Scott", "published": "2016-05-04 02:16:47+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>The ZFC program is a neat accomplishment, but a Goldbach machine ought to be doable with a few hundred states.</p>\n]]>", "author": "code golf addict", "published": "2016-05-04 03:55:04+00:00", "title": "By: code golf addict"}, {"content": "<![CDATA[<p>I agree with:<br />\n&#8220;If ZFC can prove that the Turing machine Z halts, then ZFC can prove that ZFC is inconsistent.&#8221;</p>\n<p>But I don&#8217;t see how you&#8217;re getting:<br />\n&#8220;If ZFC can prove that the Turing machine Z halts, then ZFC is *actually* inconsistent.&#8221;</p>\n<p>I would agree with the second one if you changed &#8220;inconsistent&#8221; to &#8220;not $\\Sigma_1$-sound&#8221;[1].  Am I missing something?</p>\n<p>[1] <a href=\"https://en.wikipedia.org/w/index.php?title=%CE%A9-consistent_theory&#038;oldid=685818686\" rel=\"nofollow\">https://en.wikipedia.org/w/index.php?title=%CE%A9-consistent_theory&#038;oldid=685818686</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zinberg:Ben.html\">Ben Zinberg</a>", "published": "2016-05-04 04:18:56+00:00", "title": "By: Ben Zinberg"}, {"content": "<![CDATA[<p>Since you&#8217;re actually running TMs and finding it slow: have you considered using something like hashlife to speed it up? In more detail: I assume your simulator does one TM step at a time, but that your TM steps are very repetitive. The idea of hashlife is to cache bigger-sized chunks of the time-space diagram and, when they match, to fill them in from the cached copy rather than just going through all those steps again. It was designed for cellular automata (and works amazingly well for certain Game of Life patterns, allowing simulation to numbers of steps far beyond what could be done step-by-step) but Turing Machines are similar enough that I wonder whether it might work for them as well.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html\">David Eppstein</a>", "published": "2016-05-04 04:34:43+00:00", "title": "By: David Eppstein"}, {"content": "<![CDATA[<p>This is so cool =)</p>\n]]>", "author": "John Hawksley", "published": "2016-05-04 04:46:40+00:00", "title": "By: John Hawksley"}, {"content": "<![CDATA[<p>Fascinating!  Two questions. 1) How much memory (i.e. squares of the tape) was used in disproving the conjecture that all squares are less than 5?  2) Somewhat along the lines of anonymous13: Suppose instead of the Turing machine, you use the hypercompact language that Chaitin presents in &#8220;Algorithmic Information Theory&#8221; (IIRC). Do you have any sense how many bits these various programs would require?</p>\n]]>", "author": "Ernie Davis", "published": "2016-05-04 04:53:39+00:00", "title": "By: Ernie Davis"}, {"content": "<![CDATA[<p>Even though it may be impossible to show in ZF that a particular Turing machine A will halt, does that rule out being able to show with ZF that Turing machine A halts if and only if Turing machine B does not halt?</p>\n<p>If it is possible to pair Turing machines (or otherwise count related Turing machines), then it might be possible with ZF to prove an infinite set of busy beaver numbers without being able to prove the haltingness of particular Turing machines.</p>\n]]>", "author": "Joe Random", "published": "2016-05-04 05:43:19+00:00", "title": "By: Joe Random"}, {"content": "<![CDATA[<p>Dear Scott,</p>\n<p>What is the smallest n for which you can prove that BB(n) is *HUGE* by constructing an n-state Turing Machine that halts only after a very very long time?</p>\n<p>Here&#8217;s an idea based on the &#8220;TREE sequence&#8221;: Fix a value of k (say k=3, or k=1000), and construct a Turing Machine that tries to build an infinite sequence T_1, T_2, &#8230; of k-labeled tress such that each T_i has at most i vertices and no T_i is homeomrophically embeddable into any later T_j. The machine would traverse all the search space of this problem, and then halt. We know it will halt by Kruskal&#8217;s tree theorem.</p>\n<p>You probably already know about this idea since it is based on Harvey Friedman&#8217;s work&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nivasch:Gabriel.html\">Gabriel Nivasch</a>", "published": "2016-05-04 06:08:56+00:00", "title": "By: Gabriel Nivasch"}, {"content": "<![CDATA[<p>Scott #14: Regarding the Goldbach result becoming meaningless if Goldbach is proven. Well, you can still have results of the form &#8220;sentence A is provable in strong axiom system T2 and unprovable in weak axiom system T1, and there is a Turing machine M with only N states s.t. T1 can prove that M halts iff A.&#8221;</p>\n]]>", "author": "Vadim Kosoy", "published": "2016-05-04 07:53:58+00:00", "title": "By: Vadim Kosoy"}, {"content": "<![CDATA[<p>Very neat.  Regarding &#8220;Such a program might be thousands of lines long if written in a standard programming language like C&#8221;, I think this is an overestimate; link goes to a stripped-down Metamath kernel in Laconic (very untested).  I&#8217;d be curious to know how many states it generates, but the current Laconic compiler doesn&#8217;t appear to support nullary functions.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-04 08:37:12+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>What about  problems that were proven to be ZFC-independent, like the continuum hypothesis? Can those be done?</p>\n]]>", "author": "Artem", "published": "2016-05-04 08:39:39+00:00", "title": "By: Artem"}, {"content": "<![CDATA[<p>Sincere congratulations are extended to Adam Yedidia (and to Scott) for this fine and thought-provoking work.  </p>\n<p>Many a thesis and many a scientific article are graced by literary quotations; the following poem can be read as a meditation upon works like Adam&#8217;s. The poem is from poet/computer scientist Vincenzo Della Mea&#8217;s essay &#8220;G\u00f6del\u2019s childhood and other algorithms,&#8221; as collected in <i>Imagine Math 2: Between Culture and Mathematics</i> (2013, Michael Emmer, editor).  </p>\n<p>Della Mea&#8217;s poem is a meditation upon Turing programs that do not stop:<br />\n<blockquote><b>Oracolo</b><br />\nLa macchina universale di Turing<br />\nse opportunamente caricata<br />\ncon una descrizione minuziosa<br />\ndella mia vita, per definizione<br />\npotrebbe raccontarmi in anticipo<br />\ncosa far\u00f2 da grande, se far\u00f2<br />\nqualcosa; per\u00f2 se inerte raggiungo<br />\nil limite del nastro illimitato,<br />\nallora la macchina altro non pu\u00f2<br />\nche osservarmi con le sue transizioni,<br />\nlentamente, di stato in stato,<br />\nmentre anch\u2019io l\u2019osservo. Facendo niente.\n</p></blockquote>\n<p>Della Mea translates his own &#8220;unstoppable&#8221; poem as follows<br />\n<blockquote><b>Oracle</b><br />\nThe Universal Turing Machine,<br />\nif opportunely loaded<br />\nwith a meticolous description<br />\nof my life, by definition<br />\ncould tell me in advance<br />\nwhat I will do when grown up,<br />\nif I will do anything; but if I idle reach<br />\nthe limit of the limitless tape,<br />\nthen the machine only will be able<br />\nto observe me with its transitions,<br />\nslowly, from state to state,<br />\nwhile I too observe it. Doing nothing.</p></blockquote>\n<p><b>Note</b>&nbsp; The essay&#8217;s in Emmer&#8217;s collection vary greatly in their math-to-poetry ratio; in particular Marco Abate&#8217;s &#8220;Exotic spheres and John Milnor&#8221; is among the most lucid (and poetry-free) discussions of &#8220;homeomorphic but not diffeomorphic&#8221; (that are known to me). </p>\n<p><b>Conclusion</b>&nbsp; It nearly certain that any given reader will be greatly pleased by at least one of the essays in <i>Imagine Math 2</i>, and nearly certain too that any given reader will be repelled by at least one of them. In either event, <i>Shtetl Optimized</i> readers who are writing theses and/or articles will find abundant raw material for reflection and quotation.  \ud83d\ude42</p>\n]]>", "author": "John Sidles", "published": "2016-05-04 11:26:58+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Hello,</p>\n<p>> programming language like C or Python &#8230; we needed a language that could address an unlimited amount of memory. </p>\n<p>In Python, integers (actually long ints, which were unified with ints)  have infinite precision i.e. can be arbitrarily big until your machine runs out of memory. So I don&#8217;t follow this argument. Can you expand? Maybe I&#8217;ve missed the point.</p>\n]]>", "author": "andrew", "published": "2016-05-04 11:31:24+00:00", "title": "By: andrew"}, {"content": "<![CDATA[<p>Isn&#8217;t there something a bit bizarre about fighting for constants in the size of the TM description due to physical analogies, while the busy beaver of even one-hundredth of that constant is so enormously big that there is literally nothing physical about it?</p>\n]]>", "author": "casey", "published": "2016-05-04 11:39:21+00:00", "title": "By: casey"}, {"content": "<![CDATA[<p>code golf addict #20:</p>\n<ul>The ZFC program is a neat accomplishment, but a Goldbach machine ought to be doable with a few hundred states.</ul>\n<p>I challenge you or any other readers of this blog to demonstrate that&#8212;I don&#8217;t really think it&#8217;s wrong, but I&#8217;d be extremely interested in how to do it!  I can tell you that Adam tried several different approaches for the Goldbach machine (with and without on-tape processing, introspective encoding, etc.), but they all produced machines with ~5,000 states or more.</p>\n]]>", "author": "Scott", "published": "2016-05-04 12:01:39+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ben Zinberg #21:</p>\n<ul>I don\u2019t see how you\u2019re getting:<br />\n\u201cIf ZFC can prove that the Turing machine Z halts, then ZFC is *actually* inconsistent.\u201d</ul>\n<p>Ah, but I never said that; just reread the post to make sure!  I said: assuming a reasonable consistency statement, Z runs forever, and ZFC can&#8217;t prove that Z runs forever.</p>\n<p>If Z halted, what that would mean is that ZFC (and forget about ZFC, even your favorite weak fragment of arithmetic) could prove that SRP was inconsistent, and also that SRP would <i>actually</i> be inconsistent.</p>\n<p>If ZFC were consistent but not arithmetically sound, then yes, it&#8217;s possible in principle that ZFC could prove that Z halts even though Z doesn&#8217;t actually halt.  To fix that issue, I suppose you&#8217;d want an equivalent of the Rosser sentence (rather than the G&ouml;del sentence)&#8212;another project for the next motivated student!</p>\n]]>", "author": "Scott", "published": "2016-05-04 12:18:12+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Gabriel Nivasch #26: You may be interested in my answer to the following MSE question:</p>\n<p><a href=\"http://math.stackexchange.com/questions/723286/milton-greens-lower-bounds-of-the-busy-beaver-function\" rel=\"nofollow\">http://math.stackexchange.com/questions/723286/milton-greens-lower-bounds-of-the-busy-beaver-function</a></p>\n<p>which gives various enormous lower bounds to the Busy Beaver function, starting at BB(23) > Graham&#8217;s Number (that has since been improved to BB(22) > Graham&#8217;s Number).  The TREE(n) function lies between the Kirby-Paris Hydra function and the Buchholz Hydra function mentioned in the link.  The reason TREE(n) specifically was not implemented is that it appears to be more difficult to implement than the hydras, which are deterministic sequences, whereas for the TREE function you have to search through all possible sequences to find the longest sequence.</p>\n]]>", "author": "Royce Peng", "published": "2016-05-04 13:00:52+00:00", "title": "By: Royce Peng"}, {"content": "<![CDATA[<p>The Laconic language has many similarities to the &#8216;assembler&#8217; language I designed in 2002 to describe programs for a Minsky Register Machine. An example of a program is at the supplied link. I used it to build the first finite universal computer in the game of life.</p>\n<p>The main difference is that I used macros where you use functions. But we both went for a finite number of nonnegative integer registers to represent the state of the computation.</p>\n<p>As you can imagine, then, this kind of thing is right up my alley. \ud83d\ude42</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chapman:Paul.html\">Paul Chapman</a>", "published": "2016-05-04 14:12:11+00:00", "title": "By: Paul Chapman"}, {"content": "<![CDATA[<p>David Eppstein #22: Using hashlife to speed things up is an interesting idea!  But the real answer to your question is that if you cared about speed, you&#8217;d make completely different design choices from the very beginning.  E.g., rather than compiling TMD to Turing machine, you&#8217;d just run the TMD directly.  Better yet, rather than compiling Laconic to TMD, you&#8217;d run the Laconic directly.  Better yet, rather than writing the program in Laconic, you&#8217;d write it in C&#8212;and you&#8217;d use more lines of code and make it faster. \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-04 14:44:42+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ernie Davis #24: I forwarded your questions to Adam&#8212;he can surely answer 1) and <i>might</i> try to field 2) (though 2) is really a subject for future research).</p>\n]]>", "author": "Scott", "published": "2016-05-04 14:48:02+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Joe Random #25:</p>\n<ul>Even though it may be impossible to show in ZF that a particular Turing machine A will halt, does that rule out being able to show with ZF that Turing machine A halts if and only if Turing machine B does not halt?</ul>\n<p>First of all, if a TM halts, then ZF can <i>always</i> prove that it halts, by just simulating it until halting.  A difficulty can only arise if the TM <i>doesn&#8217;t</i> halt.  But let me assume you meant, &#8220;Even though it may be impossible to show in ZF that a particular Turing machine A runs forever&#8230;&#8221;</p>\n<p>In that case, the answer is yes, the sort of conditional result that you ask for <i>is</i> ruled out, assuming that ZF is arithmetically sound (i.e., that the statements it proves about Turing machines are actually true).  For if you could prove that exactly one of A and B halts, then you could simply simulate A and B until one of them had halted, and then you&#8217;d have proven the &#8220;haltingnesses&#8221; of both.  And ZF can formalize that.</p>\n]]>", "author": "Scott", "published": "2016-05-04 14:52:16+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>There&#8217;s a minor error on Page 2 of the linked paper -> &#8220;7-tuple M = (Q, \u0393, b, \u03a3, \u03b4, q0, F)&#8221; must be &#8220;7-tuple M = (Q, \u0393, a, \u03a3, \u03b4, q0, F)&#8221; according to the symbol explanations given.</p>\n]]>", "author": "Raunak", "published": "2016-05-04 14:59:33+00:00", "title": "By: Raunak"}, {"content": "<![CDATA[<p>Try your hand at Quantum Computing! IBM online QC:</p>\n<p><a href=\"http://www.research.ibm.com/quantum/\" rel=\"nofollow\">http://www.research.ibm.com/quantum/</a></p>\n<p>For those of you on a budget, this is about $10M less than D-Wave.</p>\n]]>", "author": "Raoul Ohio", "published": "2016-05-04 15:02:36+00:00", "title": "By: Raoul Ohio"}, {"content": "<![CDATA[<p>Wired report on IBM&#8217;s online QC:</p>\n<p><a href=\"http://www.wired.com/2016/05/ibm-letting-anyone-play-quantum-computer/\" rel=\"nofollow\">http://www.wired.com/2016/05/ibm-letting-anyone-play-quantum-computer/</a></p>\n]]>", "author": "Raoul Ohio", "published": "2016-05-04 15:08:46+00:00", "title": "By: Raoul Ohio"}, {"content": "<![CDATA[<p>This is really cool.</p>\n<p>Also, if you want some expertise in Turing machine programming, there&#8217;s a chance it could be fruitful to contact LittlePeng9 from the Googology wiki. It seems he&#8217;s implemented a lot of TMs for all sorts of things &#8211; it could be possible that with collaboration, the number of states in the interpreter could be reduced.</p>\n<p><a href=\"http://googology.wikia.com/wiki/User_blog:LittlePeng9/Random_Turing_machines\" rel=\"nofollow\">http://googology.wikia.com/wiki/User_blog:LittlePeng9/Random_Turing_machines</a></p>\n<p>Here&#8217;s another user from the Googology page who has used LittlePeng9 and many other users&#8217; work to determine bounds on the busy beaver function. Some of the strongest bounds listed there take advantage of LittlePeng9&#8217;s implementation of a machine that expands the Kirby-Paris hydra and/or the Buchholz hydra.</p>\n<p>See:<br />\n<a href=\"http://googology.wikia.com/wiki/User:Wythagoras/Rado%27s_sigma_function\" rel=\"nofollow\">http://googology.wikia.com/wiki/User:Wythagoras/Rado%27s_sigma_function</a><br />\n(Most of the interesting bounds with links to the machines are visible if you click to expand the first header under &#8220;All Known Bounds&#8221;, &#8220;One dimension, one head, absolute movement, Sigma&#8221;)</p>\n<p>The approach there seems to be to implement these hydras using TMs with more than 2 colors, then apply to apply a reduction to 2 colors. Unlike the introspective encoding approach, this gives a multiplicative blowup rather than an additive blowup, but it might be worth the additional ease of programming enabled by more colors, I don&#8217;t know.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:David.html\">David Wu</a>", "published": "2016-05-04 15:10:10+00:00", "title": "By: David Wu"}, {"content": "<![CDATA[<p>Thanks for sharing the code!</p>\n<p>There is an easy way to speed up the simulation by a factor of ~7: just use the PyPy interpreter (<a href=\"http://pypy.org\" rel=\"nofollow\">http://pypy.org</a>) instead of CPython. I timed a full run of squaresaresmall (2862347231 steps) at 13 minutes.</p>\n<p>And there&#8217;s probably another order of magnitude to be gained by optimising the code a bit.</p>\n]]>", "author": "Ronan Lamy", "published": "2016-05-04 15:20:08+00:00", "title": "By: Ronan Lamy"}, {"content": "<![CDATA[<p>Vadim #27:</p>\n<ul>Regarding the Goldbach result becoming meaningless if Goldbach is proven. Well, you can still have results of the form \u201csentence A is provable in strong axiom system T2 and unprovable in weak axiom system T1, and there is a Turing machine M with only N states s.t. T1 can prove that M halts iff A.\u201d</ul>\n<p>Yes, that&#8217;s a good point!  But still, if a statement S is provable in such a weak axiom system that we need those same axioms anyway just to engage in &#8220;everyday reasoning about arithmetic and Turing machines&#8221;&#8212;the sort of reasoning needed to prove, e.g., that some Turing machine does or doesn&#8217;t encode S&#8212;then it might make sense to stop worrying about the strength of axiomatic theories, and just say the damn statement is <b>true</b>! \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:25:20+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Stefan O&#8217;Rear #28: Wow, thanks so much for writing a metamath kernel in Laconic!  I&#8217;m amazed that you were able to do that less than 12 hours after the existence of the Laconic programming language was publicly announced. \ud83d\ude42</p>\n<p>I can ask Adam to add support for nullary functions to the Laconic compiler.  In the meantime, though, on your side: how much more work would it take to get from the kernel you wrote, to a program that actually enumerates all the theorems of ZF and searches for a proof of a contradiction?</p>\n<p>If it turns out to be possible to get a Turing machine with 8000-10000 states (or maybe even fewer?) without using Friedman&#8217;s statements at all, just using direct enumeration of the theorems of ZF (plus tricks like on-tape processing and introspective encoding), that will be an extremely interesting result that will force us to revise our views.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:32:47+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Artem #29:</p>\n<ul>What about problems that were proven to be ZFC-independent, like the continuum hypothesis? Can those be done?</ul>\n<p>Errr, how do you write a program that loops over the transfinite cardinalities, searching for one that&#8217;s intermediate between $$\\aleph_0$$ and $$2^{\\aleph_0}$$? \ud83d\ude42  More seriously, the problem is that CH is not an arithmetical statement.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:35:20+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>andrew #31:</p>\n<ul>In Python, integers (actually long ints, which were unified with ints) have infinite precision i.e. can be arbitrarily big until your machine runs out of memory.</ul>\n<p>Cool!  So then Python (and Lisp, I suppose) don&#8217;t have the technical problem about addressable memory, and there&#8217;s only the other worry, that the Python or Lisp interpreter is doing too much of the work for you.  The memory issue would only arise for languages like C.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:39:59+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>casey #32:</p>\n<ul>Isn\u2019t there something a bit bizarre about fighting for constants in the size of the TM description due to physical analogies, while the busy beaver of even one-hundredth of that constant is so enormously big that there is literally nothing physical about it?</ul>\n<p>Yes, I&#8217;ll agree, there&#8217;s something bizarre about it. \ud83d\ude09</p>\n<p>If you like, what&#8217;s &#8220;physical&#8221; about our machine Z is not that its halting or (more likely) non-halting would occur within the lifetime of our universe&#8212;but rather, that there&#8217;s a short <i>proof</i> that Z&#8217;s eventual behavior encodes a question about the consistency of a transfinite set theory.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:43:46+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Exciting!</p>\n<p>Maybe you&#8217;ll indulge a question I always wonder about these kinds of things:</p>\n<p>Why are answers about what&#8217;s &#8220;provable within ZFC&#8221; telling us about the &#8220;boundary between the knowable and the unknowable&#8221;? I mean, we &#8220;know&#8221; this thing doesn&#8217;t halt, right? Even though that&#8217;s not provable in ZFC.</p>\n]]>", "author": "DavidC", "published": "2016-05-04 15:44:23+00:00", "title": "By: DavidC"}, {"content": "<![CDATA[<p>Raunak #40: Thanks for bringing that to our attention!  We have a few other minor revisions to make to the paper, and hope to post an updated version within a day or two.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:45:20+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>[&#8230;] you haven&#8217;t seen it: this blog post by Scott Aronson (on a new paper has co-authored with\u00a0Adam Yedidia), written with his usual clarity and zest, is [&#8230;]</p>\n]]>", "author": "The 8000th Busy Beaver number eludes ZF set theory | Logic Matters", "published": "2016-05-04 15:52:59+00:00", "title": "By: \u201cThe 8000th Busy Beaver number eludes ZF set theory\u201d | Logic Matters"}, {"content": "<![CDATA[<p>DavidC #50: Yes, fine, you&#8217;re right, there&#8217;s not a single &#8220;boundary between the knowable and the knowable.&#8221;  What there is, is more like a concentric <i>series</i> of boundaries, with signs warning you that as you proceed outward you need to take on bolder and bolder axioms (which might be large-cardinal axioms and might be something else).  What&#8217;s significant about going beyond ZFC is just that, by that point, you&#8217;ve clearly passed the <i>first</i> of those boundaries.</p>\n]]>", "author": "Scott", "published": "2016-05-04 15:56:29+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Great post! One of my favorites ever on this blog, in fact. Definitely worth the wait after the recent post drought.</p>\n<p>I have two (sets of) questions:</p>\n<p>1) The technical topic at hand is provability in ZFC, but several times you use the vaguer and more philosophical-sounding word &#8220;knowable&#8221;. To what extent do you identify knowability with formal provability? Does it make a difference if we&#8217;re talking about knowability wrt humans or knowability wrt gods? What about provability wrt to ZFC vs some weaker or stronger system? Do you construe this result as a result about the general knowability of some Busy Beaver numbers? (Obviously you&#8217;ve spent a lot of time talking about this kind of thing over the years, but I&#8217;m interested to hear your thoughts about it as it concerns this specific example.)</p>\n<p>2) Imagine that tomorrow you wake up and discover that the Z machine has halted. After you change your pants, what&#8217;s the next thing you do? What happens long-term?</p>\n]]>", "author": "Nick", "published": "2016-05-04 15:56:33+00:00", "title": "By: Nick"}, {"content": "<![CDATA[<p>Scott #52:</p>\n<p>&#8220;Yes, fine, you\u2019re right &#8230;&#8221;</p>\n<p>Sorry, I really wasn&#8217;t trying to nitpick! Your answer helps me understand what&#8217;s going on. Thanks.</p>\n]]>", "author": "DavidC", "published": "2016-05-04 15:58:31+00:00", "title": "By: DavidC"}, {"content": "<![CDATA[<p>Nick #54:</p>\n<p>1) For ZFC versus other axiom systems, see my comment #53, which I just posted.</p>\n<p>For provability versus knowability: as a practical matter, we might never be able to know even BB(7), even assuming (as seems plausible) that its value is provable in ZFC.  On the other hand, if you want to <i>know</i> that there&#8217;s a sense it&#8217;s unknowable whether some specific mathematical statement is true or false, then the only clear way we know how to do that is to prove the statement independent of a strong axiom system.  That at least tells you that you can &#8220;know&#8221; the statement, only at the price of assuming axioms well beyond the ones used in almost all of modern mathematics.</p>\n<p>2) If Z halted, then the most probable explanation by far would be that our Turing machine had a bug. \ud83d\ude09</p>\n<p>The second most probable explanation would be that Friedman&#8217;s order-theoretic statement had a bug.</p>\n<p>And the third most probable explanation would be that the large-cardinal theory SRP was inconsistent, even though ZFC was consistent.  That would be a big deal to set theorists, but less of a big deal to other mathematicians.</p>\n<p>A good goal for future research would be to design a Turing machine such that, not only is its halting provably <i>equivalent</i> to Con(ZFC), but a formal proof of the equivalence can be fully written out and machine-verified.  That would address all three issues above.</p>\n]]>", "author": "Scott", "published": "2016-05-04 16:08:26+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #46: the code I posted does search for a contradiction, or rather a proof of &#8220;all sets are unequal to themselves&#8221; .  I&#8217;ve found two bugs so far: the proof checker recurses infinitely on zero (should be invalid), and I left out the three &#8220;propositional logic&#8221; axioms (ax-1, ax-2, and ax-3).</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-04 16:39:54+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>To make your interpreter as simple as possible you should consider using unlambda or brainfuck.</p>\n<p>This result is a weird yin-yang of high school student understandability. All the constructions are straightforwardly HSSU. The work of Friedman which it depends on, not so much.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Bram.html\">Bram Cohen</a>", "published": "2016-05-04 16:52:02+00:00", "title": "By: Bram Cohen"}, {"content": "<![CDATA[<p>Stefan O&#8217;Rear #57: Wow, OK, awesome!  Then my remaining question is: what&#8217;s the axiomatic strength of the theory in which you&#8217;re searching for a contradiction?  Is it really full ZF?</p>\n<p>And also: would it be easy to change your code to get rid of the nullary functions and make it compile?  (Regardless, I&#8217;ve already asked Adam to add nullary support to the Laconic compiler.)</p>\n]]>", "author": "Scott", "published": "2016-05-04 17:00:04+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Bram #58: Yes, other people also suggested unlambda and brainfuck to us&#8212;footnote 6 in our paper talks about them.  Writing a Turing machine interpreter for those languages, and seeing how the state count (i.e., the count for the interpreter <i>plus</i> the count for an interesting program to be interpreted) compares to what we got, would be an excellent project for the <i>next</i> motivated student or hobbyist!</p>\n<p>And yes, it was fun for me to work on something so high-school-student-understandable, given how much of what I do isn&#8217;t.</p>\n]]>", "author": "Scott", "published": "2016-05-04 17:06:52+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #59: It&#8217;s ZF without Regularity (but for bugs), so yes.  I can try to deal with the nullary functions later; the hope was that a function call without arguments would generate very few bits in the intermediate description, which is useful since we&#8217;re encoding the axiom schemes as sequences of function calls.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-04 17:16:06+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>The fact the Riemann Hypothesis is equivalent to a Pi_1 sentence is really cool. It makes me wonder whether it&#8217;s possible to find a Pi_1 formulation of P=/=NP. On the face of it, P=/=NP is a Pi_2 sentence: for all K there is N and a satisfiable instance of SAT of size N s.t. it takes Levin&#8217;s universal search more than N^K + K steps to find the answer.</p>\n<p>It might also be interesting to explore the formulation of higher-order sentences as oracle machines. For example Pi_2 sentences correspond to halting of machines with a halting oracle. Of course this requires fixing the encoding of Turing machines that the oracle accepts.</p>\n]]>", "author": "Vadim Kosoy", "published": "2016-05-04 18:25:58+00:00", "title": "By: Vadim Kosoy"}, {"content": "<![CDATA[<blockquote><p><b>Andrew</b> asserts (#31) &#8220;In Python, integers (actually long ints, which were unified with ints) have infinite precision i.e. can be arbitrarily big until your machine runs out of memory.&#8221;</p></blockquote>\n<p>This statement is true for machines with 2^63 bytes of memory, which includes all of the physical machines that presently exist.  However all of the languages (known to me) that support what are called &#8220;bignum&#8221; calculations fail for a <i>different</i> reason when integer lengths exceed 2^63 bytes, namely, they fail by pointer overflow.</p>\n<p>For details, see for example Pat Shaughnessey&#8217;s essay &#8220;<a href=\"http://patshaughnessy.net/2014/1/9/how-big-is-a-bignum\" rel=\"nofollow\">How big is a bignum?</a>&#8220;.</p>\n<p>In comparison, it has been estimated that a pointer-length of 63 bits would suffice to address <a href=\"https://en.wikipedia.org/wiki/Exabyte#All_words_ever_spoken\" rel=\"nofollow\">all the words ever spoken</a>, and so is plausible that no real-world &#8220;bignum&#8221; computer code has yet encountered this limit.</p>\n<p>Overcoming pointer-length restrictions is entirely practical from an engineering point-of-view, and need not incur any substantial computational overhead: consider for example a compile-target consisting of an unbounded chain of laptop computers, each linked by a USB cable to a left-neighbor and a right-neighbor, with an execution token passing from computer-to-computer along the chain as required, and with new computers (in unbounded number) added to the chain upon request of the executing computer.  </p>\n<p><b>Conclusion</b>&nbsp; In rigorously implementing unbounded-runtime&nbsp;/ unbounded-memory calculations, pending a scrupulous review of the compiler used with due consideration of pointer-length bounds, it&#8217;s good practice to code with languages that compile to explicit Turing Machines, in the style of Yedidia and Aaronson.</p>\n<p>Needless to say, folks who compute Gr\u00f6bner bases commonly encounter these big-memory problems in real life.  Just because a state-space is <i>formally</i> a variety doesn&#8217;t mean it&#8217;s feasible to work with an explicit representation of it; explicit Gr\u00f6bner representations are commonly far too big for that.</p>\n]]>", "author": "John Sidles", "published": "2016-05-04 18:34:03+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Royce Peng #35 and David Wu #43: Enormous thanks for the links!  I&#8217;m astounded that I&#8217;d never discovered the &#8220;Googology Wiki&#8221; until today&#8212;it contains so much information of so much interest to me.  I updated my post to include the astounding lower bounds on BB(7) and BB(23) that were recently found by Googology users.  The obvious question now is whether these constructions give us any handle on how to construct tiny TMs (with 30 states or whatever) whose behavior is unprovable in strong axiomatic theories.  Maybe one could at least get such a machine whose behavior was independent of PA, using some variant of the hydra game?</p>\n]]>", "author": "Scott", "published": "2016-05-04 19:30:07+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Stefan #61: Awesome!</p>\n<p>In that case, let&#8217;s just wait for Adam to add support for nullary functions to his compiler.  I met with him this afternoon, and he said it would be simple to do.  But he also quickly noticed various bugs in your program (e.g., functions missing return statements).  He might get in touch with you directly to talk about this.</p>\n<p>If this indeed works, then Adam predicts that it will indeed lead to a TM with fewer states than what you get from Friedman&#8217;s statement &#8212; he says your program is about as complicated as his program for the Riemann hypothesis, which suggests that we might get under 6000 states.</p>\n<p>Meanwhile, regarding &#8220;minimalist&#8221; languages like Unlambda and Brainfuck&#8212;Adam&#8217;s view is that Laconic is almost as minimalist as he knew how to make it, <i>if</i> you need a function stack (which Unlambda and Brainfuck apparently lack).  So, if we wanted further huge reductions in the state count (e.g., below 4000 states), we might need to give up on a function stack in the high-level language.</p>\n]]>", "author": "Scott", "published": "2016-05-04 19:43:22+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Vadim #62: I can tell you that a &Pi;<sub>1</sub> equivalent for P&ne;NP would be a breakthrough in the field.  In particular, it would mean that we could do a straightforward computer search for polynomial-time SAT algorithms (or at least, certificates that such algorithms exist), in the same way one does computer searches for counterexamples to Goldbach or Riemann!</p>\n]]>", "author": "Scott", "published": "2016-05-04 19:46:48+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Thanks, everybody, for all the extremely kind comments! I am surprised and flattered that my project generated so much interest.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 19:54:47+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Sniffnoy #8: As Scott said, that is a very interesting question! If you can find a nice simple Pi-1 sentence that is independent of PA, you could go and code it up in Laconic, and see what you get! Unfortunately, with my current design, you won&#8217;t be able to get below 4,000 states (so a factor of 2 from ZFC) because that is the fixed cost of the &#8220;interpreter&#8221; part of the Turing Machine. But if your program is simple enough, you might be able to do better than that by redesigning the interpreter to be smaller and correspondingly weaker. That could be an interesting direction for future research!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 19:58:07+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Anonymous #13, Scott #14: Yes, that is the gist of my project! To Scott&#8217;s response, I&#8217;d just add that general conversion of Java to Turing Machine is quite a large undertaking just from an engineering perspective! Indeed, one thing that is too bad is that I had to make my own, reduced-instruction language (Laconic) which would compile to Turing Machine, instead of compiling from a well-known language like Java. The problem is that Java is huge in scope, even if you only allow a fraction of the commands it supports (and if you make that fraction small enough, well, Laconic is approximately what you get!)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:02:46+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>code golf addict #20: It&#8217;s quite possible you&#8217;re correct, but a few hundred states is quite an ambitious goal! With my current design, you won&#8217;t be able to get that low, but you might be able to get there with an overhaul of the &#8220;interpreter&#8221; part of the Turing Machine. The &#8220;interpreter&#8221; as currently designed has support for some things, in particular the low-level function stack, which aren&#8217;t necessary for the Goldbach program. </p>\n<p>This relates to what I was saying to Sniffnoy #8, so let me elaborate a little bit. There is a trade-off to be had here, where a larger interpreter involves a larger fixed cost but allows you to represent more complex programs more cheaply. In the limit as your programs get more and more complex, it is always worth it to have a beefier interpreter! </p>\n<p>I optimized my interpreter size, roughly speaking, for the central result of the paper: the result about the Busy Beaver function. For much simpler statements, like Goldbach&#8217;s conjecture or (potentially) something independent of Peano Arithmetic, this interpreter size is probably too big. Ideally, I would have some kind of &#8220;sliding scale&#8221; of progressively more powerful interpreters, which could be chosen according to the complexity of the program I was trying to represent! Maybe one day \ud83d\ude42</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:11:19+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>David Epstein #22: I don&#8217;t usually find that simulation speed is that important&#8211;for example, my independent-of-ZFC TM almost immediately begins execution by writing (8!)! 1&#8217;s onto the tape. An order-of-magnitude simulation speedup is unlikely to help too much in seeing what&#8217;s going on! \ud83d\ude42 </p>\n<p>Of course, for TMs like the squaresaresmall TM, or more seriously the Goldbach or Riemann TM&#8217;s, it would be nice if simulation was quicker, just to give viewers a better sense for what they&#8217;re doing in a shorter time. It sounds at glance like the caching methods you&#8217;re describing here could indeed be applied to make them faster, since the execution histories of the TMs are indeed extremely repetitious!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:21:47+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>John Sidles #30: Your comments always bring a smile to my face, John Sidles. \ud83d\ude42</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:28:16+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Ronan Lamy #44: Wow, that is very good to know! I didn&#8217;t know about that. Thanks for sharing!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:33:28+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Stephen O&#8217;Rear #28, #57, #61: Wow, I am extremely impressed that you did all this just in the last half-day! I am very curious about how your program works. There are a few kinks to be worked out, of course, and on my end I can easily modify Laconic to support nullary functions if you give me a day or two. But I would be very interested in speaking with you about your program! Email me at adamy at mit dot edu and we can schedule a Skype meeting from there.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:41:51+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Scott #48</p>\n<p>An abstract C program does have an infinite memory because it has an infinite stack.  It isn&#8217;t obvious to me how to use that to simulate a Turing machine&#8217;s infinite tape. But proving it can&#8217;t be done would require a more subtle argument than just the finiteness of the memory.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwarz:Jerry.html\">Jerry Schwarz</a>", "published": "2016-05-04 20:43:56+00:00", "title": "By: Jerry Schwarz"}, {"content": "<![CDATA[<p>Jerry #75: Ah, thanks for that observation!  But keep in mind that, if your <i>only</i> infinite resource is a stack, then what you&#8217;ve got is a <a href=\"https://en.wikipedia.org/wiki/Pushdown_automaton\" rel=\"nofollow\">pushdown automaton</a>, which is certainly not as powerful as a Turing machine.  An infinite <i>queue</i>, on the other hand, or <i>two</i> infinite stacks, do let you simulate a TM.  (I actually give that as a homework problem in my undergrad class.)</p>\n]]>", "author": "Scott", "published": "2016-05-04 20:48:55+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Bram Cohen #58, Scott #65: Indeed, I have little doubt that a Brainfuck interpreter would be smaller than the interpreter I currently have! It&#8217;s very similar to TMD, but with less flexibility in what is representable on each tape, and with no function stack, both of which are going to make the interpreter smaller! But that means that for programs like the independent-of-ZFC program, you will need to make your own function stack, which will make your program correspondingly bigger, potentially by a lot. This relates to the tradeoff I was talking about with Sniffnoy #8 and code golf addict #20. I think you&#8217;re right that for programs like the Goldbach program, you&#8217;d be better off with a smaller interpreter, like a Brainfuck interpreter.</p>\n<p>As for tiny lambda-calculus-based languages like Unlambda, and its cousins Iota and Jot&#8211;well, you might indeed be right that the interpreter would be much smaller than the TMD interpreter, although that is less obvious to me (and, of course, you&#8217;d still want a higher-level language that compiles to Unlambda/Iota/Jot). But yes, I agree that this is a promising direction if you are looking for interpreters that &#8220;dominate&#8221; the current one I&#8217;m using (that is, that are both smaller and read programs that are more concise than this one). David Madore warns on his page about Unlambda that Unlambda is very difficult to write interpreters for&#8211;but that maybe just means it will be a fun challenge! \ud83d\ude42 In any case, I would encourage you to give this a shot if you are interested&#8211;you are likely to be able to reuse my code and documentation that works at the TM level.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 20:59:51+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Possibly stupid (or more likely irrelevant) question: do you suppose this has any application for understanding the minimum complexity required for consciousness (a la Hofstadter)?</p>\n]]>", "author": "Amanda", "published": "2016-05-04 21:05:53+00:00", "title": "By: Amanda"}, {"content": "<![CDATA[<p>*Stefan* O&#8217;Rear: Sorry for misspelling your name earlier!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 21:10:30+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Adam #77,</p>\n<p>I have a new Iota/Jot/Zot interpreter written in C++ as well as a simple language based on the SKI calculus that transcompilers to/from lambda calculus and has some efficient speed ups here and here:</p>\n<p><a href=\"https://github.com/manyoso/zot\" rel=\"nofollow\">https://github.com/manyoso/zot</a><br />\n<a href=\"https://github.com/manyoso/hof\" rel=\"nofollow\">https://github.com/manyoso/hof</a></p>\n<p>So in theory you could write an interpreter in &#8220;high level&#8221; lambda calculus for the SKI calculus-like Hof language and compile that to Hof and have a self-hosting interpreter.</p>\n]]>", "author": "AdamT", "published": "2016-05-04 21:30:52+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>I&#8217;d advise staying away from Unlambda, personally; Brainfuck is sensibly minimalist, but unlambda is a strange mix of sensible minimalism and deliberate perversion.  Iota and Jot are better suggestions (or any other universal combinator &#8212; <a href=\"http://math.stackexchange.com/questions/153163/what-is-the-shortest-function-of-lambda-calculus-that-generates-all-functions-of\" rel=\"nofollow\">relevant math.stackexchange question</a>).  Or just the plain old SKI- or SK-calculus; any of these possibilities can then be written with an unlambda-like syntax.  And if you use two bits to encode each of the three possibilities of &#8220;apply&#8221;, &#8220;S&#8221;, and &#8220;K&#8221;; well, now you&#8217;ve reinvented <a href=\"https://en.wikipedia.org/wiki/Binary_combinatory_logic\" rel=\"nofollow\">binary combinatory logic</a>.  If you use the universal combinator idea, like Iota or Jot, then you only have two possibilities and get get away with only one bit.</p>\n<p>Other interesting possibilities: <a href=\"https://en.wikipedia.org/wiki/Binary_lambda_calculus#Lambda_encoding\" rel=\"nofollow\">Binary lambda calculus</a>; any of various <a href=\"https://en.wikipedia.org/wiki/One_instruction_set_computer\" rel=\"nofollow\">OISCs</a>.</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-04 21:31:02+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>Amanda #78: I suppose that if you agreed with Penrose&#8217;s ideas about consciousness, the minimum complexity of a Turing machine needed to elude ZF set theory <i>might</i> be related in some way to the minimum complexity needed for consciousness.  But</p>\n<p>(1) Z is still a Turing machine!  So presumably Penrose wouldn&#8217;t find it an acceptable model for consciousness.  Maybe he&#8217;d instead consider it our current candidate for the smallest artifact that human consciousness can understand but computers can&#8217;t??</p>\n<p>(2) In any case, this whole discussion is academic, because I <i>don&#8217;t</i> agree with Penrose&#8217;s ideas about G&ouml;del and consciousness, for reasons I&#8217;ve spelled out in detail elsewhere.</p>\n<p>So to summarize: probably no relevance. \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-04 21:51:22+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ernie Davis #24:</p>\n<p>To your first question: 24,652 squares of tape memory were used in the execution of the squaresaresmall TM. </p>\n<p>To your second question: I&#8217;m unfamiliar with Chaitin&#8217;s hypercompact language. But I assume what this is essentially asking is: if we compressed all of the redundancy out of the TMD binaries, then what would be the size of the independent-of-ZFC program? That&#8217;s an extremely interesting question! I don&#8217;t know the answer, but you could get a rough upper bound on it by taking some TMD binaries outputted by the example programs in the tmd_dirs directory, building some kind of compression scheme (maybe Lempel-Ziv? I&#8217;m not sure) to compress them as much as you possibly can, and then applying that compression scheme to the independent-of-ZFC program&#8217;s TMD binary. I&#8217;d be very curious to see what this kind of thing might yield!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 21:47:40+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Withouth having read about SRP: Isn&#8217;t it kind of cheating that you need the consistency of what I assume is more than ZFC to prove the non-termination of your TM?</p>\n]]>", "author": "javra", "published": "2016-05-04 21:49:54+00:00", "title": "By: javra"}, {"content": "<![CDATA[<p>The call stack in a C program is actually quite limited, either by the compiler, like in a Windows environment, or by an OS environment variable, like in Linux, which is why iteration is so strongly preferred over recursion in C. But one can allocate memory from the heap, which is &#8220;unlimited&#8221; subject to physical memory constraints (which would include disk space if virtual memory is enabled). One can make use of that heap space as part of any data structure. For a Turing machine, a doubly linked list seems perfect.</p>\n]]>", "author": "Vadim P.", "published": "2016-05-04 21:53:20+00:00", "title": "By: Vadim P."}, {"content": "<![CDATA[<p>AdamT #80: That&#8217;s really neat! So Hof is your language, and is like the other minimalist lambda-calculus-based languages but supports random behavior?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-04 21:58:56+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>javra #83: It&#8217;s not cheating, it&#8217;s just an opportunity for further research!  (The scientific version of &#8220;it&#8217;s not a bug, it&#8217;s a feature!&#8221;) \ud83d\ude42</p>\n<p>More seriously: if Stefan O&#8217;Rear&#8217;s Laconic program from earlier in this thread ends up working, then not only will it decrease the number of states from 8000 to possibly around 6000, it will also immediately fix the issue with ZFC vs SRP.</p>\n]]>", "author": "Scott", "published": "2016-05-04 22:19:39+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Adam #86,</p>\n<p>Yes, it is just the SKI calculus + transcompiler to/from lambda calculus + a couple of extra combinators for introducing randomness and output.  Planned usage is for a Quine in Hof that will self-mutate via the random combinator.  Anyway, the transcompiler would give you ability to write in &#8220;high-level&#8221; lambda calculus but run in nothing more than SKI calculus which other than the universal combinators and possibly binary lambda calculus&#8230; You can&#8217;t get much simpler for a Turing complete language.</p>\n]]>", "author": "AdamT", "published": "2016-05-04 22:29:29+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>Hi Scott!</p>\n<p>We should have been discussing this at our recent dinner:-)</p>\n<p>To demonstrate the compactness of Binary Lambda Calculus, I constructed a 267 bit binary lambda term</p>\n<p>at <a href=\"https://github.com/tromp/AIT/blob/master/goldbach.lam\" rel=\"nofollow\">https://github.com/tromp/AIT/blob/master/goldbach.lam</a></p>\n<p>and pictured in <a href=\"https://github.com/tromp/AIT/blob/master/goldbach.gif\" rel=\"nofollow\">https://github.com/tromp/AIT/blob/master/goldbach.gif</a></p>\n<p>that normalizes iff there\u2019s a counterexample to Goldbach\u2019s Conjecture</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-04 22:32:37+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Just for clarification, when you say &#8220;the 8000th Busy Beaver number eludes ZF set theory&#8221;, is that equivalent to saying that there is no number n such that ZF proves n = BB(8000)? If not, can you spell it out a little more concretely?</p>\n]]>", "author": "Nick", "published": "2016-05-04 22:39:00+00:00", "title": "By: Nick"}, {"content": "<![CDATA[<p>Nick #90: Yes, although actually something than that is true: there&#8217;s no integer n such that ZFC proves n>=BB(8000).</p>\n]]>", "author": "Scott", "published": "2016-05-04 22:51:16+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott? This seems like one of the biggest discoveries in the history of computer science. Please tell me you are taking Adam with you to Texas and that you will continue working on these results!</p>\n]]>", "author": "Cat Freak", "published": "2016-05-04 23:15:28+00:00", "title": "By: Cat Freak"}, {"content": "<![CDATA[<p>Great work!  Congrats, Adam and Scott!  I&#8217;d not seen any previous discussion of TMs whose halting behavior was provably independent of ZF.  This answers a question I&#8217;d been wondering about for some time: are there programs that halt whose computational complexity depends on which axiom system you assume?</p>\n<p>I&#8217;d like to ask a slightly different question: I don&#8217;t know anyone who thinks ZF+\u00acCon(ZF) is a reasonable system to work in, however consistent it might be.  Are there any axioms A such that both ZF+A and ZF+\u00acA are considered &#8220;reasonable&#8221;, such that you can made a TM behave differently at infinity depending on which is &#8220;true&#8221;?  Or can the behavior of TMs at infinity only be determined by axioms about countable infinities, and all such axioms have a somehow &#8220;natural&#8221; truth value?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gross:Jason.html\">Jason Gross</a>", "published": "2016-05-04 23:43:36+00:00", "title": "By: Jason Gross"}, {"content": "<![CDATA[<p>Cat Freak #92: I&#8217;m delighted that you like it, but no, it&#8217;s not &#8220;one of the biggest discoveries in the history of CS.&#8221; \ud83d\ude42</p>\n<p>I said this in the post, but maybe it bears repeating: <i>the fact that there&#8217;s a program whose behavior is independent of ZF is not the slightest bit new.</i>  That&#8217;s just G&oul;del&#8217;s Theorem.  The only new part is that this time we also fought to minimize the <i>size</i> of the program.</p>\n<p>And Adam is currently a PhD student of Martin Rinard, doing programming languages.  This project involved an amazing synergy between my interests and his, but sadly for me, he&#8217;s already more-or-less moved on. \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-05 00:41:26+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Jason Gross #93:</p>\n<ul>This answers a question I\u2019d been wondering about for some time: are there programs that halt whose computational complexity depends on which axiom system you assume?</ul>\n<p>Sorry, I don&#8217;t understand that question, let alone how our work answers it!  Different axiom systems can differ in how much they can <i>prove</i> about the running time of a program&#8212;but the running time itself is just an intrinsic property of the program.</p>\n<ul>Are there any axioms A such that both ZF+A and ZF+\u00acA are considered \u201creasonable\u201d, such that you can made a TM behave differently at infinity depending on which is \u201ctrue\u201d? Or can the behavior of TMs at infinity only be determined by axioms about countable infinities, and all such axioms have a somehow \u201cnatural\u201d truth value?</ul>\n<p>Again, to be clear: whether a TM halts or doesn&#8217;t halt has no dependence on which axioms you use to reason about the TM, any more than whether a bird flies or not depends on which words you use to discuss the bird.</p>\n<p>If ZF+A and ZF+\u00acA disagree about whether a TM halts, then the only possible conclusion is that either A or \u00acA has a consequence that&#8217;s arithmetically false.  So then, the one that I&#8217;d consider &#8220;natural,&#8221; is simply whichever one I believe <i>doesn&#8217;t</i> have arithmetically false consequences!</p>\n<p>So for example, ZF+Con(ZF) seems more natural ZF+\u00acCon(ZF) to me, that&#8217;s because I believe that Con(ZF) is a true statement of arithmetic.</p>\n<p>This is completely different from (say) CH versus \u00acCH or AC versus \u00acAC, where it&#8217;s possible to argue that you really <i>do</i> get to pick which one you like better as a matter of taste.  This is the difference between statements about transfinite sets (which, in cases like CH and AC, can be shown to have no arithmetical consequences) and arithmetical statements.</p>\n]]>", "author": "Scott", "published": "2016-05-05 00:58:21+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #0: In \u00a78.3.2 you state that a Turing machine with \\(n\\) states can store \\( 2(\\log_2(n)+1) \\) bits of information.  I think this is not quite accurate because the space of possible Turing machines is greatly reduced by isomorphism; I think the factor of \\(2\\) approximately disappears due to the \\(n!\\) legal state relabelings, but I haven&#8217;t worked out all the details. </p>\n<p>Artem #29: To elaborate on Scott&#8217;s answer, CH is not only not an arithmetical statement, it provably has no arithmetical consequences; both G&ouml;del&#8217;s model of CH and Cohen&#8217;s model of &not;CH have the same natural numbers as the models they are built in.</p>\n<p>Vadim Kosoy #62: The question of \\(\\Pi_1\\)-sentences which approximate \\(P \\neq NP\\) is touched on in \u00a75 of <a href=\"http://www.scottaaronson.com/papers/pnp.pdf\" rel=\"nofollow\">http://www.scottaaronson.com/papers/pnp.pdf</a>.</p>\n<p>Adam Yedidia #74: Sent you an email.  Also willing to answer any questions about it here.</p>\n<p>Adam Yedidia #77: I&#8217;m not very optimistic that Unlambda will help you; the process of compiling down to combinators blows up the state count quite a bit.  The pure untyped lambda calculus would be a better idea; I&#8217;m also partial to Forth-style stack machines, as you may have noticed.  BTW, David Madore seems to have stopped updating the page; I emailed him an Unlambda-to-OCaml compiler several years ago and the page still lists it as an open problem.</p>\n<p>Scott #87: I do think there&#8217;s still a lot of interesting space to explore with these arithmetical statements, even if the current statement is in a tight race with direct FOL implementations for the Con(ZFC) question, better statements could be discovered and you can also move the goalposts (make the problem &#8220;consistency of SRP&#8221; \ud83d\ude42). </p>\n<p>Meta: Hi everyone!  Been reading this blog for a few years, first comment.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-05 01:50:58+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>Since the &#8220;Name the bigger number&#8221; game is your idea you obviously get to make and interpret the rules, but when I looked at your essay my reaction was that using the busy beaver function should get you disqualified precisely because it&#8217;s not computable. The most straightforward interpretation of your instructions to the contestants (&#8220;Be precise enough for any reasonable modern mathematician to determine exactly what number you\u2019ve named, by consulting only your card and, if necessary, the published literature&#8221;) is that the modern mathematician should be able to compute the number, meaning write a computer program that with unlimited running time would print the digits and then halt. If you write BusyBeaverFunction(Graham&#8217;s Number) then there is some ambiguity in the instructions about whether the modern mathematician can &#8220;determine exactly what number you&#8217;ve named.&#8221;</p>\n]]>", "author": "Ward Cleaver", "published": "2016-05-05 01:58:08+00:00", "title": "By: Ward Cleaver"}, {"content": "<![CDATA[<p>What&#8217;s up with the Theory of Computing journal? It&#8217;s almost Mother&#8217;s Day and there are zero articles for 2016. Even if Babai uses this journal for his graph isomorphism paper it&#8217;ll be a slow year for open access theoretical CS.</p>\n]]>", "author": "Ward Cleaver", "published": "2016-05-05 02:05:47+00:00", "title": "By: Ward Cleaver"}, {"content": "<![CDATA[<p>Sorry if this is a dumb question, but I recall that Conway was able to exhibit an explicit FRACTRAN program consisting of very small set of fractions (fewer than 30?) capable of universal (and therefore undecidable) calculation. Is there any relation between Conway&#8217;s result and this one?</p>\n]]>", "author": "Linda Janourova", "published": "2016-05-05 02:30:17+00:00", "title": "By: Linda Janourova"}, {"content": "<![CDATA[<p>Scott Aaronson. Have you looked at (or has Harvey Friedman pointed you towards) Laver tables to provide the desired Turing machines with few states where the question of whether such a Turing machine halts is possibly independent of ZFC (but settled under strong large cardinal hypotheses)? Let me now present two programs that illustrate how easy it is to produce computer programs using Laver tables where whether the program halts may be independent of ZFC.</p>\n<p><b>Program A</b><br />\n<code><br />\ntable:=function(n,x,y)<br />\nif x=2^n then return y;<br />\nelif y=1 then return RemInt(x,2^n)+1;<br />\nelse return table(n,table(n,x,y-1),x+1);fi;end;<br />\nn:=5; while table(n,1,32)=2^n do n:=n+1; od;<br />\n</code></p>\n<p>Program A is a program (written in a meager 5 lines) that halts when it finds some 2^n by 2^n classical Laver table such that in this algebra 1*32 is less than 2^n. Program A is not known to halt in ZFC, but under the very strong large cardinal hypothesis, for all n there is an n-huge cardinal, program A halts. However, Dougherty has shown that program A lasts for at least Ack(9,Ack(8,Ack(8,254))) steps.</p>\n<p><b>Program B</b></p>\n<p><code><br />\ntable:=function(n,x,y)<br />\nif x=2^n then return y;<br />\nelif y=1 then return RemInt(x,2^n)+1;<br />\nelse return table(n,table(n,x,y-1),x+1);fi;end;<br />\ntest:=true; n:=0;<br />\nwhile test=true do<br />\nfor m in [0..n] do if table(n,2,2^m)=2^n and not table(n,2,2^m)=2^n then test:=false; fi; od; od;</code></p>\n<p>If for all n there exists an n-huge cardinal, then program B does not halt. However, it is not known whether ZFC implies that program B does not halt. Furthermore, it is not known whether ZFC along with the hypothesis &#8220;program A does not halt when 32 is replaced by any other power of 2&#8221; implies that program B does not halt. As with program A, it is known that program B runs at least Ack(9,Ack(8,Ack(8,254))) steps without halting.</p>\n<p><b>Turing machines for these programs</b></p>\n<p>It seems like program A and program B are not only easy to write in GAP or any other popular programming language, but that one should be able to construct Turing machines with few states that simulate program A and program B. </p>\n<p>In particular, I believe that the Turing machines that one can construct to compute program A or program B would use closer to 10 states than 8000 states. It looks like one could build Turing machines with few states that compute program A or program B directly without needing the 4000 state interpreter (it should not be too hard to make a Turing machine that calculates table(n,x,y) simply by simulating a program running on a stack of numbers but I have not gone through the details).</p>\n]]>", "author": "Joseph Van Name", "published": "2016-05-05 02:58:50+00:00", "title": "By: Joseph Van Name"}, {"content": "<![CDATA[<p>Ward Cleaver: Sorry, I confess that I don&#8217;t know what&#8217;s up with ToC.   Maybe Laci has been too busy traveling the world giving lectures about GI!</p>\n<p>Eliezer Yudkowsky also suggested to me that the biggest number contest should have the rule that, to &#8220;name&#8221; a number, you must have in mind a computer program that halts and outputs that number.  To me, though, that&#8217;s just an interestingly different rule, which would need to be spelled out explicitly in the instructions.</p>\n<p>The first point I can make is that your and Eliezer&#8217;s rule has an ambiguity of its own.  Namely, how do you convince the judges that your program really <i>does</i> halt and output an integer?  Presumably you need to give them a proof?  OK then, what axioms are you allowed to assume in that proof?</p>\n<p>This is far from an academic worry, because it turns out that, the wilder the large-cardinal axioms you&#8217;re willing to assume, the longer-running the computer programs for which you can give proofs that they halt!  (Basically because stronger and stronger large-cardinal axioms let you prove the well-definedness of wilder and wilder ordinal notations, which you can then use to define more and more rapidly-growing functions.)</p>\n<p>For this reason, even your and Eliezer&#8217;s contest, with two skilled participants, will probably devolve into an argument about transfinite set theory.</p>\n<p>But the second point I can make is that, from my standpoint, there&#8217;s a clear difference between a number&#8217;s being &#8220;determined&#8221; and its being &#8220;computable.&#8221;  For me, &#8220;determined&#8221; means <i>definable arithmetically</i> (or at least, using ordinal notations that I agree are well-founded).</p>\n<p>More concretely: sure, we&#8217;ll never &#8220;know&#8221; BB(1000) by a list of its digits, but by that criterion we&#8217;ll never &#8220;know&#8221; Graham&#8217;s number either.  But regardless of whether we have the digits, can anyone doubt that, just as there&#8217;s exactly one positive integer that answers to &#8220;Graham&#8217;s number,&#8221; so there&#8217;s exactly one that answers &#8220;BB(1000)&#8221;?  There&#8217;s a finite list of 1000-state Turing machines, and each one either halts or doesn&#8217;t halt, and there&#8217;s <i>some</i> maximum number of steps that any of the halting ones run for.  And we can prove lower bounds; we know, for example, that BB(1000) dominates Graham&#8217;s number.</p>\n<p>Up in computational heaven, where every angel gets issued an oracle for the halting problem, they find BB(1000) as straightforward to compute as we find 9<sup>9</sup>.  To them, free from the epistemic limitations imposed by our laws of physics, BB(1000) is just another positive integer.  And yet even in computational heaven, the angels still argue about whether the Continuum Hypothesis is true or false&#8212;and for example, they regard</p>\n<p>&#8220;min{100, the number of intermediate cardinalities}&#8221;</p>\n<p>as an ill-defined positive integer&#8212;because not even a HALT oracle can help them with <i>those</i> sorts of perplexities. \ud83d\ude09</p>\n]]>", "author": "Scott", "published": "2016-05-05 03:16:24+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Linda #99: Conway&#8217;s construction gives a small <i>universal machine</i> in Fractran.  I explained in the post why I regard that as a fundamentally different sort of quest from finding a small machine such that set theory can&#8217;t prove what it does on a blank input.</p>\n<p>To say it another way: if M is universal, you&#8217;re right that there&#8217;s some <i>input</i> x such that ZF can&#8217;t prove whether M(x) halts, assuming ZF is consistent.  But in that case, the complexity that I care about is going to be the complexity of M <i>plus</i> the complexity of x, not one or the other in isolation!  Alas, in practice, all the constructions of &#8220;small universal TMs&#8221; that I&#8217;ve seen minimize the complexity of M only by shoehorning a huge amount of complexity into x, which they then don&#8217;t count towards the total.</p>\n<p>If we want to close that loophole, and get rid of the &#8220;offshore complexity havens in Panama,&#8221; one good way is to consider TMs that already need to do something interesting even when they&#8217;re run on a blank tape.</p>\n]]>", "author": "Scott", "published": "2016-05-05 03:32:25+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Joseph van Name #100: Thanks so much for the reference to <a href=\"https://en.wikipedia.org/wiki/Laver_table\" rel=\"nofollow\">Laver tables</a>!  I confess I&#8217;d never heard of them before your comment.</p>\n<p>Your program B does indeed look like an outstanding candidate for converting into a small Turing machine!  But:</p>\n<p>(a) There&#8217;s the obvious difficulty that no one knows, at present, whether this program&#8217;s running forever is provable in ZFC&#8212;are there any related programs for which that&#8217;s known <i>not</i> to be provable?</p>\n<p>(b) I&#8217;ve learned, from experience, to withhold judgment whenever anyone confidently guesstimates how few Turing machine states will be needed to accomplish something (e.g., &#8220;probably only ten or twenty!&#8221;).  I used to do that myself: you can see an example in my &#8220;Who Can Name the Bigger Number?&#8221; essay, where I guesstimated that there should be a simple 100-state machine for Goldbach&#8217;s Conjecture.  But &#8230; how to say this?  The rubber meets the road where the head meets the tape. \ud83d\ude42</p>\n<p>Of course, even if Laver tables &#8220;merely&#8221; led to (say) an 800-state machine that eluded ZFC, that would still be fantastic.</p>\n<p>Incidentally, in your code, what does the RemInt function do?</p>\n]]>", "author": "Scott", "published": "2016-05-05 03:45:23+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #95:  I think what you do here is equivalent to making a Turing Machine that enumerates all ZF proofs and halts iff it finds a proof of 1=0.  This Turing Machine halts iff ZF is inconsistent, i.e., if Con(ZF) is false.  You can turn this into a TM that is in P if Con(ZF) is true but in EXPTIME if Con(ZF) is false by using a trick similar to the one that lets you write a concrete SAT solver that runs in polynomial time iff P=NP.</p>\n<p>My follow-up question is if you can do this with other axons, e.g., Choice or CH.  I think the answer is no, though, because of the difference you mention about transfinite axioms.</p>\n<p>(If I believe in Tegmark IV (or level V, maybe?), then there should be a universe modeling ZF+\u00acCon(ZF), and it&#8217;s not clear to me how to distinguish this universe from the one we live in.  The confusing phrasing of my question probably comes from this philosophical background, and what I meant by &#8220;what axioms you assume&#8221; was roughly &#8220;which axioms are true&#8221; or &#8220;which axiom system does our universe model&#8221;?)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gross:Jason.html\">Jason Gross</a>", "published": "2016-05-05 05:51:20+00:00", "title": "By: Jason Gross"}, {"content": "<![CDATA[<p>Re #34:</p>\n<p>Makes sense.  I.m.o., your comment #34 merits mention in the paper, both for interest and for technical correctness (if I&#8217;m reading it right, we don&#8217;t yet know whether BB(7918) is independent of ZFC, if we only assume ZFC is consistent).</p>\n<p>I&#8217;d be really interested to see if we could craft an encoding such that the corresponding Rosser sentence is equivalent to a natural-sounding math problem.  It seems really far off, but maybe that&#8217;s mostly a reflection of how little tooling we have.</p>\n<p>Viewed from that perspective, Parsimony/Laconic could be the first step in a project to establish practical heuristics for how hard it is to prove a given statement (such as the size of a partially optimized Turing machine to search for a proof).  I&#8217;d guess that for purposes of estimating how hard things would be for a real-world mathematician, practical heuristics could be better than ideal quantities like Kolmogorov complexity.  Better yet, unlike the latter, we can compute the former without knowing the answer to the search problem.  I wonder if Coq or other proof assistant researchers are working on this?</p>\n<p>Very cool stuff, congratulations to Adam and you.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zinberg:Ben.html\">Ben Zinberg</a>", "published": "2016-05-05 06:02:37+00:00", "title": "By: Ben Zinberg"}, {"content": "<![CDATA[<p>Congrats, guys. It&#8217;s satisfying to see concrete bounds in the face of uncomputable functions.</p>\n<p>I firmly believe (and some of the other commenters seem to agree) that the next step is an interpreter for either the lambda calculus, or SKI combinatory logic. In either case the program is essentially a tree, and as unpleasant as it will be to write trees as strings and manipulate them with a Turing machine, I can&#8217;t imagine the interpreter being more than a few hundred states. I&#8217;d guess combinatory logic is the easier of the two (you can judge the difficulty for yourself by reading the rules <a href=\"https://cemc.math.uwaterloo.ca/contests/computing/2004/stage2/sk/sk.pdf\" rel=\"nofollow\">here</a>, for example), but it tends to have larger programs (see below) for the kinds of tasks you&#8217;re interested in.</p>\n<p>As John Tromp (#89) points out above, he already has a short program for the Goldbach conjecture. It ends up compiling down to </p>\n<p>(\\1 ((\\1 1) (\\\\\\(\\\\6 2 (1 (5 5 2))) (\\1 1 2 (\\1 4) 1)) (\\\\\\\\1))) ((\\1 1) (\\\\\\1 (\\\\1) ((\\4 4 1 ((\\1 1) (\\2 (1 1)))) (\\(\\1 (1 (4 2))) (\\\\\\\\1 3 (2 4))))) (\\\\\\\\1 (\\\\2) (2 4)))</p>\n<p>as a lambda term (in de Bruijn notation), a tree of 247 S and K combinators, a 267 bit binary lambda calculus representation, or a 740 bit (!!) binary combinatory logic representation. If I&#8217;m doing the math right, that would mean either 45 + 77 = 122 or 106 + 87 = 232 states for the blob + extractor, so I&#8217;d say 500 states for Goldbach is a realistic goal. </p>\n<p>I assume you&#8217;d be able to compress Friedman&#8217;s statement by a similar factor. But even if it doesn&#8217;t compress (or you just can&#8217;t stomach rewriting it in the lambda calculus), an interpreter for the lambda calculus would connect a lot of existing research in algorithmic information theory (like Tromp&#8217;s) to Turing machines in a concrete way.</p>\n]]>", "author": "Luke", "published": "2016-05-05 06:04:09+00:00", "title": "By: Luke"}, {"content": "<![CDATA[<p>Scott Aaronson #103.</p>\n<p><b>Response to (a)</b> So far program A and program B are the only computer programs about the classical Laver tables where the halting problem is solved with large cardinals but where the solution to this instance of the halting problem has not been obtained in ZFC. In fact, these two results are the only published results about Laver tables which have been established under large cardinal hypotheses but which not have been established in ZFC.</p>\n<p>For program B, there are no known independence results and I would be very surprised if someone were to actually show that the halting problem for program B is independent of ZFC. The only independence result about the classical Laver tables is the result by Randall Dougherty which states that the statement &#8220;program A halts even when 32 is replaced by some other power of 2&#8221; is independent of PRA (Primitive Recursive Arithmetic) which is much weaker than even Peano arithmetic. This independence result follows from the fact that the halting time for program A (again when 32 is replaced by some other power of 2) is not a primitive recursive function. Randall Dougherty in [1] has given a lower bound for the halting time for algorithm A which grows slightly faster than the Ackermann function. These lower bounds obtained by Dougherty have not been improved upon so it is still unknown whether the halting problem for problem A is undecidable in Peano Arithmetic or in any other system stronger than PRA.</p>\n<p>In [2], Randall Dougherty has done work to attempt to show that algorithm A always terminates and the time it takes for algorithm A to terminate is a function that grows slightly faster than the Ackermann function. However, this attempt by Dougherty was abandoned as the Laver table calculations became too complicated.</p>\n<p>I would not be too surprised if someone proves these results in ZFC or Peano Arithmetic since people have often proven results using large cardinal hypotheses where the large cardinal hypotheses were later removed from the results. For example, Richard Laver showed that the word problem for the free left-distributive algebra on one generator was decidable using rank-into-rank cardinals (Laver&#8217;s results on the free left-distributive algebras is very closely related to his results on the Laver tables). However, later Patrick Dehornoy (I think) has proven in ZFC that the word problem for the free left-distributive algebra on one generator is decidable.</p>\n<p><b>Response to (b)</b> One reason why I am still hopeful for a simple Turing machine for calculating Laver tables is the similarities between what I think a good Laver table computing Turing machine would look like and the Turing machines computing the Ackermann like functions. I guess I will only find out how easy it is to construct the Laver table computing Turing machine once the Turing machine is built.</p>\n<p>The <a href=\"http://www.gap-system.org/Manuals/doc/ref/chap14.html\" rel=\"nofollow\">RemInt(x,y)</a> function in the language GAP simply takes x mod y.</p>\n<p>[1]. <a href=\"http://arxiv.org/abs/math/9205202\" rel=\"nofollow\">Critical points in an algebra of elementary embeddings I</a></p>\n<p>[2] <a href=\"http://arxiv.org/abs/math/9503204\" rel=\"nofollow\">Critical points in an algebra of elementary embeddings II</a></p>\n<p>[3] <a href=\"http://www.math.unicaen.fr/~dehornoy/Surveys/Dgs.pdf\" rel=\"nofollow\">Handbook of Set Theory 2010. Chapter 11. Elementary embeddings and algebra</a></p>\n<p>[4] Braids and self-distributivity. 2000. Patrick Dehornoy. (the primary reference for the classical Laver tables.)</p>\n]]>", "author": "Joseph Van Name", "published": "2016-05-05 06:59:45+00:00", "title": "By: Joseph Van Name"}, {"content": "<![CDATA[<p>Scott #33: I have a 73-state, two-symbol, one-tape TM that halts iff Goldbach&#8217;s conjecture is false, and which checks N<=1000 in about 10 seconds and N<=2000 in about 2 minutes on a desktop computer.  You want me to e-mail you?</p>\n<p>Hash of proof of concept:<br />\n8c91299b6ea6371ef60329e210ed50165c9c8942623a1fc9e0c08ab00595009d</p>\n]]>", "author": "Jared S", "published": "2016-05-05 09:47:23+00:00", "title": "By: Jared S"}, {"content": "<![CDATA[<p>Jason #104: Yes, you&#8217;re correct, there&#8217;s no way to do anything analogous with AC or CH, because there&#8217;s no way to make a finitary computer program do one thing versus another depending on whether AC or CH are true or false.</p>\n<p>(At most, you could make a computer program do something if it found, say, a <i>proof</i> or <i>disproof</i> of AC or CH in ZF&#8212;but we already know from G&ouml;del and Cohen that it&#8217;s not going to find them!)</p>\n<p>Related to that, it&#8217;s hard to imagine how anything measurable in the physical world could depend on whether AC or CH were true or false.  (Indeed, it almost sounds like a joke&#8230;)</p>\n<p>FWIW, I don&#8217;t think even Tegmark would assign a Platonic reality to the truth or falsehood of AC and CH&#8212;in his book, he&#8217;s very explicit that only &#8220;computable&#8221; mathematical structures are Platonically real (<i>and therefore physically real!</i>), in his conception.</p>\n]]>", "author": "Scott", "published": "2016-05-05 10:54:51+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>John Tromp #89 and Luke #106: Thanks so much for the thoughts!</p>\n<p>Yes, I completely agree that using one of these lambda calculus or combinatory logic thingies would be the natural next step.  Having just warned against shoot-from-the-hip estimates of Turing machine size in comment #103, I&#8217;m now going to disregard that, and say that I think 500 states for Goldbach, 750 for Riemann, and 1000 for Con(ZFC) are all reasonable goals for an enterprising individual to aim for.</p>\n]]>", "author": "Scott", "published": "2016-05-05 10:59:54+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Jared #108: Yes, of course!!  (And is my last comment already laughably obsolete? \ud83d\ude42 )  Either email me or post a comment here, or write a short article about it&#8212;I&#8217;d love to know the details!  Make sure to explain the ideas behind how you got down to 73 states, in addition to listing the machine.</p>\n]]>", "author": "Scott", "published": "2016-05-05 11:04:24+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>In the paper you give a short argument that BB grows faster than any computable function. Actually your argument only proves that, if f is computable, then you cannot have f(n)>=BB(n) for *all* large enough n. </p>\n<p>If I recall correctly, Tibor Rad\u00f3 in his original 1962 paper on the busy beaver function gives a somewhat more involved argument that you must actually have f(n)<BB(n) for all large enough n. (Correct me if I&#039;m wrong.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nivasch:Gabriel.html\">Gabriel Nivasch</a>", "published": "2016-05-05 11:26:13+00:00", "title": "By: Gabriel Nivasch"}, {"content": "<![CDATA[<p>Gabriel #112: Yes, you&#8217;re right, it takes another argument to show that for all computable functions f, we have f(n)<BB(n) for all large enough n.  But I can give you that argument right now.</p>\n<p>Here it is: let M be a k-state Turing machine that computes f(n).  Then we can clearly design another machine, M<sub>n</sub>, that first prints n on its tape, then computes f(n), then runs for f(n)+1 steps.  This M<sub>n</sub> will have k+O(log(n)) states.  Therefore</p>\n<p>BB(k+O(log(n))) > f(n).</p>\n<p>Therefore BB(n) > f(n) for all sufficiently large n.</p>\n]]>", "author": "Scott", "published": "2016-05-05 11:32:23+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #76: As well as the functions stack, Laconic has another infinite (unbounded) resource: the size of integer variables. Godel encoding can therefore be used to simulate any other unbounded computational resource, including any number of stacks or queues, or even a heap.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chapman:Paul.html\">Paul Chapman</a>", "published": "2016-05-05 11:56:14+00:00", "title": "By: Paul Chapman"}, {"content": "<![CDATA[<p>What about a Turing machine that scans all variable values of an explicit Matiyasevich type polynomial that has no root (while this fact cannot be proved in ZFC), and halts on zero? Would this do the trick? How many states would it have?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schreiber:Ehud.html\">Ehud Schreiber</a>", "published": "2016-05-05 12:12:36+00:00", "title": "By: Ehud Schreiber"}, {"content": "<![CDATA[<p>Paul Chapman #114: Right!  There&#8217;s no issue with unbounded memory in Laconic, because it was explicitly designed not to have that issue.  We were talking about C.</p>\n]]>", "author": "Scott", "published": "2016-05-05 12:39:41+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ehud #115: Once again, the issue is that <i>the description length of the polynomial itself</i> would also need to be counted toward the state complexity, because given a blank input, the machine would need to print the polynomial before searching for its zeroes.  And even if the zero-testing machine was small, the polynomial that encoded ZFC might be quite enormous.</p>\n]]>", "author": "Scott", "published": "2016-05-05 12:42:23+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #113: Your argument does not even use the undecidability of the halting problem! Am I missing something?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nivasch:Gabriel.html\">Gabriel Nivasch</a>", "published": "2016-05-05 13:12:59+00:00", "title": "By: Gabriel Nivasch"}, {"content": "<![CDATA[<p>Note that a 500 state TM for Goldbach still takes 11000 bits to represent its transition function. Compared to a 267 bit lambda calculus term, you&#8217;d be spending 99.976 of your description on cramming a tiny program into the straightjacket of the Turing Machine model.</p>\n<p>Perhaps we should admit that Turing Machines are not the most suitable for these types of investigations?</p>\n<p>With the lambda caluclus there is also no suspicion whatsoever that its choice as programming language is artificially helping to make the pgrogram small.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-05 13:15:00+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Gabriel #118: No, you&#8217;re not missing anything!  There&#8217;s a sort of diagonalization built into the argument, but it never needs to invoke the undecidability of HALT.</p>\n]]>", "author": "Scott", "published": "2016-05-05 15:12:18+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Adam and Scott, congratulations on a fine achievement! I hope that your work will help people understand the importance of Friedman&#8217;s achievements, which IMO have been seriously undervalued by the mathematical/scientific public.</p>\n<p>In terms of reducing the bound further, my gut instinct is that currently, a &#8220;direct&#8221; encoding of ZFC could be competitive with an encoding using Friedman-type statements, but only because there&#8217;s probably still an order of magnitude to be gained by &#8220;engineering&#8221; improvements. After engineering improvements &#8220;max out&#8221;, further improvements will require significant new mathematical insights, and the power of Friedman&#8217;s methods will become even more apparent.</p>\n<p>Regarding Vadim #62 on P \u2260 NP, Friedman has emphasized that mathematics is very much a \u03a0_1 enterprise. If someone were to prove that P \u2260 NP then one of the first reactions would be to attempt to strengthen the result as much as possible. So for example, the following &#8220;slight&#8221; strengthening of P \u2260 NP is \u03a0_1: &#8220;For every n > 100, the smallest AND/OR/NOT circuit that solves all SAT instances of size at most n has more than n^(log n) gates.&#8221; So if you don&#8217;t mind overshooting a bit, you can play the same game.</p>\n<p>By the way, I wonder if you are aware of Jones&#8217;s work on undecidable Diophantine equations. <a href=\"https://projecteuclid.org/euclid.bams/1183547548\" rel=\"nofollow\">https://projecteuclid.org/euclid.bams/1183547548</a>  It has the same flavor as your work and I think it would be similarly interesting to see &#8220;how low you can go&#8221; with a Diophantine equation whose lack of solutions is unprovable in ZFC.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chow:Timothy.html\">Timothy Chow</a>", "published": "2016-05-05 15:48:03+00:00", "title": "By: Timothy Chow"}, {"content": "<![CDATA[<p>Scott #111: Unfortunately, my dramatic reduction is specific to Goldbach, so only one part of your comment #110 is obsolete.</p>\n<p>I&#8217;m going to be a bit vague for a couple of days, purely for TM code golf reasons: in case other commenters (&#8220;code golf addict&#8221;?) want to try, I think Goldbach is amenable to TM code golf.  This weekend I&#8217;ll post my TM, possibly slightly improved, and an explanation.  But I&#8217;ll be nice and e-mail you today.</p>\n<p>Here&#8217;s my vague commentary.  The reason that Goldbach can be reduced so much is that the desired computation is something that I can fully model in my head, consider totally different approaches, and then understand in my head how the approach would play to a TM&#8217;s strengths and weaknesses.  My TM was written directly as a state machine with no abstraction.</p>\n<p>I expect that for more complex problems, possibly including both of yours, an interpreter-type approach like yours will dominate.</p>\n]]>", "author": "Jared S", "published": "2016-05-05 15:57:32+00:00", "title": "By: Jared S"}, {"content": "<![CDATA[<p>John Tromp #119 (and others): I have to confess that I&#8217;ve never really understood lambda calculus (or indeed, any functional programming language), and that&#8217;s a major hole in my understanding of CS.  Like, I can read an exposition of &lambda;-calculus and say OK, I guess I more-or-less understand these rules for manipulating &lambda;-expressions.  But what a roundabout way of trying to get a Turing machine! \ud83d\ude42  </p>\n<p>Given how many people rave about &lambda;-calculus and functional programming, there&#8217;s <i>obviously</i> something I&#8217;m missing.</p>\n<p>But it now occurs to me: if &lambda;-calculus turned out to be the best way to build a tiny Turing machine whose behavior was independent of ZF, that&#8217;s a development that would <i>force</i> me to finally learn what other people keep raving about!</p>\n<p>Of course, you might complain that I&#8217;m still using the number of Turing machine states as my &#8220;gold standard&#8221;&#8212;saying that &lambda;-calculus needs to win in a metric like that one (rather than the number of bits in a functional program) before I recognize its superiority.  But that&#8217;s because I instinctively think about computation in terms of <i>why you could actually implement these operations using a machine compatible with the laws of physics</i>&#8212;something that Turing machines seem to make much more explicit than &lambda;-calculus.  And when I look at the fairly complicated <a href=\"https://en.wikipedia.org/wiki/Lambda_calculus#Reduction\" rel=\"nofollow\">manipulation rules</a> for &#038;lambda-expressions, I immediately ask myself how much Turing-machine complexity is getting swept under the hood.</p>\n<p>I.e., if the Turing machine model is a straitjacket, then maybe I&#8217;m only comfortable in a straitjacket? \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-05 16:06:52+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #84: &#8220;In any case, this whole discussion is academic.&#8221; </p>\n<p>lol.</p>\n]]>", "author": "Dave", "published": "2016-05-05 18:05:20+00:00", "title": "By: Dave"}, {"content": "<![CDATA[<p>Dave #124: Maybe I should have a new phrase, &#8220;This whole discussion is academic<sup>2</sup>&#8220;&#8212;i.e., academic even by the standards generally operative here.</p>\n]]>", "author": "Scott", "published": "2016-05-05 18:18:28+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>This is blowing my mind, and I also love your blog. To nitpick a little, there&#8217;s a missing word in the first sentence of Section 1.1. The word &#8216;century&#8217; is missing, between &#8216;twentieth&#8217; and &#8216;which&#8217;.</p>\n]]>", "author": "Brian Muhia", "published": "2016-05-05 18:51:30+00:00", "title": "By: Brian Muhia"}, {"content": "<![CDATA[<p>Scott #123</p>\n<p>For those wanting to learn the magic of Functional Programming, I recommend reading <a href=\"http://web.mit.edu/alexmv/6.037/sicp.pdf\" rel=\"nofollow\">http://web.mit.edu/alexmv/6.037/sicp.pdf</a> and do its programming exercises on an iPad using something like Lisping<br />\n<a href=\"https://itunes.apple.com/us/app/lisping/id512138518?mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/lisping/id512138518?mt=8</a><br />\n(a lisp interpreter with a nice editor).</p>\n<p>Very pleasant/relaxing/fun!</p>\n]]>", "author": "fred", "published": "2016-05-05 18:56:55+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>OK, I&#8217;ll bite: What&#8217;s so complicated about the rules for manipulation of lambda-expressions?</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-05 19:06:50+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>Scott #124</p>\n<p>&#8220;It\u2019s hopeless to design a Turing machine by hand for all but the simplest tasks, so as a first step, Adam created a new programming language, called Laconic,&#8221;</p>\n<p>Are these the words of someone comfortable in their straitjacket, or eager to escape it:-?</p>\n<p>I am comfortable enough with lambda calculus to design the goldbach conjecture by hand.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-05 19:34:28+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Sniffnoy #128: Well, look at the Wikipedia page!  There&#8217;s &alpha;-conversion, &eta;-conversion, and &beta;-reduction, each one of which has rules about how to handle bound and unbound variables, renaming, etc.  Maybe it would help to see how a &lambda;-expression evaluator gets implemented with a small amount of machine code.</p>\n]]>", "author": "Scott", "published": "2016-05-05 19:37:23+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>If you look for a small TM where &#8220;does it halt on blank tape&#8221; is notoriously unsolved then one way you might do much better than Goldbach&#8217;s conjecture is asking whether a small instance of a 3x+1-type problem ever reaches 1. By Conway&#8217;s results, this eventually escapes the logical power of any axiomatic system. The original 3x+1 problem isn&#8217;t well suited to this because it conjecturally always reaches 1, but a TM executing the &#8220;halt on 1, cut evens in half, take odds >=3 to 3x+1&#8221; loop is a great candidate for &#8220;smallest TM where it&#8217;s notoriously hard to say if it computes a total function&#8221;.</p>\n]]>", "author": "Joe Shipman", "published": "2016-05-05 19:39:36+00:00", "title": "By: Joe Shipman"}, {"content": "<![CDATA[<p>John #129: It now seems clear that Laconic was overkill for Goldbach!  See comment #108 above: Jared S appears to have built a Goldbach Turing machine completely by hand with only 73 states (pending verification).  Even in terms of bit-length, this is within a factor of 3 of your 267-bit binary &lambda; term for Goldbach.  We should&#8217;ve tried it ourselves.</p>\n<p>But, OK, what about Riemann and Con(ZFC)?  Are <i>you</i> comfortable writing programs for those directly in &lambda;-calculus?  If not, then it seems like Turing machines and &lambda;-calculus are <i>both</i> currently 1 for 3 on our example problems&#8230; \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-05 19:45:44+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Joe Shipman #131: Yeah, we actually thought about the 3x+1 problem.  The drawback, from our standpoint, is just that it&#8217;s not a &Pi;<sub>1</sub>-sentence&#8212;i.e., we don&#8217;t know how to phrase it in terms of whether a TM halts on a blank input.</p>\n]]>", "author": "Scott", "published": "2016-05-05 19:53:01+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Nice to see Harvey Friedman&#8217;s work crossing over in this way.</p>\n]]>", "author": "Mitchell Porter", "published": "2016-05-05 20:02:11+00:00", "title": "By: Mitchell Porter"}, {"content": "<![CDATA[<p>Here is a dot file with the 7918-state machine:<br />\n<a href=\"https://www.dropbox.com/s/38rkzj7vvogfeop/Yedidia-Aaronson-TM.dot?dl=0\" rel=\"nofollow\">https://www.dropbox.com/s/38rkzj7vvogfeop/Yedidia-Aaronson-TM.dot?dl=0</a><br />\nHowever, Graphviz crashes when I try to render it on my machine&#8230; Not sure what to make of that!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html\">Rasmus Pagh</a>", "published": "2016-05-05 20:07:05+00:00", "title": "By: Rasmus Pagh"}, {"content": "<![CDATA[<p>Luke #106: It isn&#8217;t totally obvious to me why lambda calculus should yield an interpreter that is much smaller than the TMD interpreter that I am currently using. But I am happy to be proven wrong! If someone is interested in trying to build an interpreter of this kind, the software and documentation in the parsimony/src/tm/ directory will probably prove quite helpful.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yedidia:Adam.html\">Adam Yedidia</a>", "published": "2016-05-05 20:13:18+00:00", "title": "By: Adam Yedidia"}, {"content": "<![CDATA[<p>Scott #133: Something very close to the 3x+1 problem that is equivalent to a TM halting on blank input is, &#8220;There is a cycle that does not contain 1.&#8221; The only mildly tricky point is that you need to multitask over all starting numbers at once; i.e., if C(i,j) denotes the result of iterating the Collatz map j times starting with i, then you need to traverse all pairs in such a way that any fixed (i,j) is reached after a finite number of steps.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chow:Timothy.html\">Timothy Chow</a>", "published": "2016-05-05 20:20:10+00:00", "title": "By: Timothy Chow"}, {"content": "<![CDATA[<p>Scott #133 A 73 state TM takes 73*2*(ceil(log(73))+1+1) = 1606 bits, 6 times more than goldbach.blc, but indeed quite impressive for a TM!<br />\nI&#8217;d be comfortable writing Riemann and Con(ZFC) in a lambda calculus with some syntactic sugar on top, which is basically what Haskell is.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-05 20:50:39+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Scott #130: Aside from some slight naming and bound/free weirdnesses that I don&#8217;t think are that practically relevant &#8212; and that are unlikely to trip you up if you keep in mind what the rules actually mean &#8212; I don&#8217;t think any of that is really complicated.  Or if you do consider it consider it complicated, it&#8217;s certainly <i>less</i> complicated than formal logic, which has pretty much exactly the same rules for dealing with renaming and bound/free variables, but whose rules for dealing with &forall; and &exist; are, at least in every formulation I&#8217;ve seen, more complicated than the three (two once you drop renaming) rules of the lambda calculus.</p>\n<p>You might say, well, that&#8217;s not a problem with first order logic, because we know what &forall; and &exist; mean, and don&#8217;t need so much to rely on the formal rules; but we know what &lambda; means too, so, like, I don&#8217;t think that&#8217;s a real difference.</p>\n<p>And I mean, the three rules are just:<br />\n&alpha;-renaming: What variables are called does not matter.  I.e., you can rename them.<br />\n&beta;-reduction: Functions do what they say they do.<br />\n&eta;-conversion: &#8220;The function that takes x and returns f(x)&#8221; is just the same thing as f.</p>\n<p>The one really weird thing I think, is the possibility of doubly-binding a variable &#8212; you need some convention to define what the hell is meant by &lambda;x.&lambda;x.x; there&#8217;s nothing intuitive about that.  As it is, it&#8217;s defined that inner bindings override outer ones, so the above is equivalent to &lambda;x.&lambda;y.y.  But once again, formal logic has the same problem; you need to define what&#8217;s meant by &forall;x&exist;x P(x), and the convention is the same, that it means &forall;x&exist;y P(y).  (Kind of a dumb statement since it has no real dependence on x, but&#8230;)  And of course you might object that nobody would ever write a statement like that, but the same applies to the lambda-calculus &#8212; why would anyone ever write a function like &lambda;x.&lambda;x.x?  Just write &lambda;x.&lambda;y.y so people can tell what you mean.</p>\n<p>Note by the way that &beta;-reduction doesn&#8217;t care about whether variables are bound or free; and while &alpha; does, well, &alpha; is just a rule saying you can rename variables, so how that interacts with boundness should already be intuitive even if writing it out formally is annoying &#8212; as I said, it&#8217;s no different than how you can rename variables in formal logic, or, well, anywhere in math.  The only nontrivial rule where it&#8217;s an issue is &eta;.  But again, keep in mind what it means and it&#8217;s simple; &eta; is supposed to mean &#8220;The function that takes x and returns f(x)&#8221; is just the same thing as f&#8221;, not &#8220;The function that takes x and returns f_x(x) is just the same thing as f&#8221;, because the latter statement is obviously false.</p>\n<p>And if you really want to avoid renaming and bound/free issues, you can always use De Bruijn index notation&#8230; though personally I find that to be just about unreadable, and it makes the two remaining rules (&alpha; is unnecessary when variables don&#8217;t have names!) considerably less clear.</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-05 20:51:37+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>John Tromp #138: Sorry, I was counting the number of bits needed to describe an n-state TM as growing like n(log<sub>2</sub>n + O(1)) rather than 2n(log<sub>2</sub>n + O(1)), because of the need to mod out by permutation symmetry (as Stefan O&#8217;Rear #96 pointed out).</p>\n<p>But John Tromp and Haskell: OK, it sounds like I should just set aside a week sometime to learn how to code in Lisp or Haskell!</p>\n]]>", "author": "Scott", "published": "2016-05-05 21:43:27+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #131: A simple machine implementation of lambda calculus is shown in Figure 1 of <a href=\"http://pop-art.inrialpes.fr/~fradet/PDFs/HOSC07.pdf\" rel=\"nofollow\">http://pop-art.inrialpes.fr/~fradet/PDFs/HOSC07.pdf</a><br />\nAn obfuscated C implementation of the Krivine machine is shown at the top of my homepage.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-05 21:48:20+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Haskell is really nice, it&#8217;s a lot like just writing math!</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-05 22:52:42+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>Scott wrote: &#8221; if \u03bb-calculus turned out to be the best way to build a tiny Turing machine whose behavior was independent of ZF, that\u2019s a development that would force me to finally learn what other people keep raving about!&#8221;</p>\n<p>The pattern of this remark is familiar to category theorists: &#8220;if you can promise that the mathematics you love turns out be the key to solving whatever highly specialized, technical problem I&#8217;m interested in at the moment, then I&#8217;ll learn it&#8221;.  And there&#8217;s an unspoken addendum: &#8220;But otherwise, forget it.&#8221;  \ud83d\ude42</p>\n<p>Turing machines are idealized, ultra-simple hardware; the \u03bb-calculus is an idealized, ultra-simple programming language.  So, their charms are complementary.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baez:John.html\">John Baez</a>", "published": "2016-05-05 23:44:34+00:00", "title": "By: John Baez"}, {"content": "<![CDATA[<p>&#8216;&#8230; if you\u2019re in a biggest-number-naming contest, and you write \u201cBB(10000),\u201d you\u2019ll destroy any opponent &#8230;&#8217;</p>\n<p>That was wonderful essay indeed. IIRC one of the requirement for the game in that essay was that one should name a number that would be unambiguous for a reasonable mathematician&#8230; Wait, didn&#8217;t Yedida and you just disqualified the entry of &#8220;BB(10000)&#8221; in that game by proving that it&#8217;s not computable? \ud83d\ude42</p>\n]]>", "author": "Michael P", "published": "2016-05-06 00:14:55+00:00", "title": "By: Michael P"}, {"content": "<![CDATA[<p>John Baez #143: Yes, I&#8217;ve noticed a strong analogy between &lambda;-calculus and category theory&#8212;both in terms of how their proponents talk about them and in terms of how I respond!</p>\n<p>But come on: it&#8217;s not like I said, &#8220;unless the mathematics you love helps me with my problem, I&#8217;m going to condemn it and ban you from studying it.&#8221;  I just said I probably won&#8217;t get around to studying it <i>myself</i>!</p>\n<p>But in any case, this time it looks highly plausible that &lambda;-calculus <i>will</i> help us&#8212;in which case, I will indeed have no choice but to learn it!</p>\n]]>", "author": "Scott", "published": "2016-05-06 00:42:33+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Michael P. #144:</p>\n<ul>Wait, didn\u2019t Yedida and you just disqualified the entry of \u201cBB(10000)\u201d in that game by proving that it\u2019s not computable?</ul>\n<p>Please see my comment #101 to Ward Cleaver, which answers exactly that.</p>\n]]>", "author": "Scott", "published": "2016-05-06 00:47:17+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Paul Chapman #114: You may have noticed that my ZF/FOL program does, in fact, use unbounded integers to simulate a stack \ud83d\ude42</p>\n<p>John Tromp #119: while I think that, with the benefit of hindsight, you may be right that Turing machines are not the best choice for algorithmic information theory, they are the rules Rad\u00f3 gave us to work with.</p>\n<p>Timothy Chow #121: I think you are absolutely right, the future belongs to Friedman-type statements.  Many people overestimate the complexity of FOL, but there&#8217;s still a limit to how far it can go.</p>\n<p>Jared S #123: I&#8217;ll be interested to see what you&#8217;ve done, and I&#8217;m also kind of interested in what a skilled TM-golfer can do with a minimal FOL enumerator like mine.</p>\n<p>Sniffnoy #139: it looks like Tromp et al are already using de Bruijn numbers.  IIRC, it&#8217;s not that bad if you stick to normal order reduction, as you won&#8217;t have to adjust any numbers that way.</p>\n<p>NOT A REPLY: There was a brief thread on the FOL program <a href=\"https://groups.google.com/forum/#!topic/metamath/OumBq83Ksqs\" rel=\"nofollow\">on the Metamath list</a>.  Norman Megill, creator of the axioms I&#8217;m using, pointed out that I can&#8217;t just drop Regularity because it&#8217;s required in order to recover standard Infinity from his axinfnd; I&#8217;ve revised the gist to include a version of Regularity.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-06 02:53:59+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>Timothy #137: No big deal. Do as follows: For i = 1, 2, 3, &#8230; test whether, starting from any j<=i, you fall into a loop in at most i steps. You just start from scratch each time!</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nivasch:Gabriel.html\">Gabriel Nivasch</a>", "published": "2016-05-06 03:14:42+00:00", "title": "By: Gabriel Nivasch"}, {"content": "<![CDATA[<p>Scott #145 &#8211; I hope you learn the \u03bb-calculus, just to see if you too start trying to convert others to that religion.  \ud83d\ude42</p>\n<p>You may be amused to know that when Jim Lambek supposedly proved that the \u03bb-calculus was just a formalism for working with cartesian closed categories, a number of category theorists said &#8220;whew, so now I don&#8217;t need to learn the \u03bb-calculus!&#8221;</p>\n<p>I don&#8217;t know if any experts on the \u03bb-calculus said &#8220;whew, so now I don&#8217;t need to learn cartesian closed categories!&#8221;</p>\n<p>(When I first tried to learn the \u03bb-calculus, I thought it might be <i>true</i> that it was just a formalism for working with cartesian closed categories &#8211; but I discovered it was not.  There&#8217;s more to it, even from a purely category-theoretic view.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baez:John.html\">John Baez</a>", "published": "2016-05-06 03:29:09+00:00", "title": "By: John Baez"}, {"content": "<![CDATA[<p>Gabriel Nivasch #148: You don&#8217;t even need a cycle finder, since a Collatz cycle which does not contain 1 is the same as a Collatz cycle which starts at >4.  (That reminds me, I found a way to derandomize your logspace cycle finder a few months ago using a variant of the Cole-Vishkin graph coloring.  I&#8217;ll write up something if you haven&#8217;t already heard it.)</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-06 04:24:22+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>I&#8217;ve got 31 states for Goldbach. Props to Jared S for being the first to put up a number! My solution&#8217;s SHA-256 is e24e155537f3dc3537265ec29d3118c4b00cfa1542a20ae61af0266da5400066.<br />\nHmm, when should we code golfers reveal our solutions?</p>\n]]>", "author": "code golf addict", "published": "2016-05-06 11:45:08+00:00", "title": "By: code golf addict"}, {"content": "<![CDATA[<p>code golf addict #151: Wow!!!  That&#8217;s incredible.  Could you email me your solution, along with an explanation of it&#8212;the more details the better?  Then I&#8217;ll be happy to call it out in the post, whenever you&#8217;re ready for that.</p>\n<p>This whole &#8220;posting the SHA-256 of your solution&#8221; is awesome, but not normally how we&#8217;ve rolled in academia since the 1600s or so (when Galileo did something similar, not with SHA-256 of course but with a cryptogram of his own design)&#8230; . \ud83d\ude09</p>\n]]>", "author": "Scott", "published": "2016-05-06 13:00:38+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>The basic question this research is trying to answer is<br />\n&#8220;What is the complexity of undecidability?&#8221;</p>\n<p>And we&#8217;re talking about descsriptional complexity, the size<br />\nof a description of some machine or program whose behaviour is undecidable.</p>\n<p>An important concept in Algorithmic Information Theory is universality. A description method is universal if it gives sizes<br />\nat most a constant larger than with any other (computable) method. This requires comparable size measures, so we normally measure sizes in bits.</p>\n<p>For Turing Machines to be universal in this sense of additive overhead, they must allow for binary input, and have their size measured as the combined length of an encoding of its transition rules and the input consumed (we also need to be able to tell these apart, but let&#8217;s ignore that for now).<br />\nWe can then in fact consider a fixed Universal Turing Machine that parses a description of another TM from its input and simulates that on the remainder of input.<br />\nIn this view TMs are just another programming language.</p>\n<p>This would get around the need for &#8220;introspective encoding&#8221;.</p>\n<p>I think the TMs will be more efficient if they can read input<br />\nfrom a separate input tape. But we don&#8217;t want to complicate the transition function too much. Perhaps, in addition to the special HALT state, there can be a special INPUT state. If you transition from state i to INPUT then<br />\nyou actually end up in state i+1 with the next bit of input written or xor-ed into the current celll. Has anything similar to that been proposed before?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-06 17:08:24+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>I got so interested in Laver tables that I wrote a semi-pop article about them <a href=\"https://johncarlosbaez.wordpress.com/2016/05/06/shelves-and-the-infinite/\" rel=\"nofollow\">here</a>.  It&#8217;s truly jaw-dropping math.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baez:John.html\">John Baez</a>", "published": "2016-05-06 17:08:28+00:00", "title": "By: John Baez"}, {"content": "<![CDATA[<p>@John Baez #143</p>\n<p>>> the \u03bb-calculus is an idealized, ultra-simple programming language</p>\n<p>It seems that to every programming language there is a book &#8220;how to learn &#8230; in 24 hours &#8211; for dummies and complete idiots.&#8221; </p>\n<p>Is there a similar thing for the \u03bb-calculus, if possible freely available? \ud83d\ude0e</p>\n]]>", "author": "wolfgang", "published": "2016-05-06 18:41:24+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>John Baez #154</p>\n<p>Suppose we design a Turing Machine that iterates over the P(n) and halts when it finds 42. This machine do have a well defined behavior: either it stops, or it doesn&#8217;t. </p>\n<p>But if it stops, then we don&#8217;t need I3 to prove it: just construct the TM and wait (a physically impossibly looong time) until it stops. So it must run forever.<br />\nBut if it runs forever, then the negation of I3 must be inconsistent within ZF (or within any system of axioms powerfull enough to construct the above TM), even if this particular proof is physically impossible to reach. So I3 must be true.<br />\nBut no one seems to say that I3 was proven, so what do I miss? </p>\n<p>PS: thanks all for the WOW post and amazingly interesting comments! \ud83d\ude42</p>\n]]>", "author": "Jay", "published": "2016-05-06 18:44:38+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>Scott,<br />\nin your 1998 essay &#8220;Who can name the bigger number&#8221;, you wrote</p>\n<p>&#8220;And in Go, which has a 19-by-19 board and over 10^150 possible positions, even an amateur human can still rout the world\u2019s top-ranked computer programs.&#8221;</p>\n<p>At the time, would you have been very surprised if someone had told you that this would no longer be true 18 years later?</p>\n]]>", "author": "fred", "published": "2016-05-06 19:14:42+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Jay #156: From reading John&#8217;s post, I believe the situation is the following.  If P(n) reaches a finite maximum, then the I3 axiom is inconsistent with ZFC.  (We might also say, &#8220;I3 is false&#8221;&#8212;but when possible, I prefer to talk about the <i>arithmetical consequences</i> of large-cardinal axioms, rather than the axioms themselves.)  If, on the other hand, P(n) grows without bound, then I3 <i>might or might not</i> be consistent with ZFC.  Meanwhile, ZFC might or might not prove all by itself that P(n) grows without bound; that&#8217;s an open problem.</p>\n<p>But notice that neither eventuality&#8212;P(n) growing without bound or it reaching a finite maximum&#8212;can be certified by a Turing machine&#8217;s halting!  A Turing machine can only halt and tell you that P(n) has reached some <i>specific</i> bound, like 32.</p>\n<p>In any case, though, I personally have no strong intuition as to whether I3 should be consistent with ZFC or not.</p>\n<p>I completely agree that Laver tables are amazing, and am glad to have learned about them!</p>\n]]>", "author": "Scott", "published": "2016-05-06 19:18:04+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #157: Hard to say &#8230; I think I would&#8217;ve been interested and impressed but not shocked.</p>\n]]>", "author": "Scott", "published": "2016-05-06 19:39:51+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Your big-numbers article is strangely topical, particularly the part that goes </p>\n<p>> And in Go, which has a 19-by-19 board and over 10150 possible positions, even an amateur human can still rout the world\u2019s top-ranked computer programs.</p>\n]]>", "author": "Emilio Pisanty", "published": "2016-05-06 20:46:43+00:00", "title": "By: Emilio Pisanty"}, {"content": "<![CDATA[<p>Forgive me if I&#8217;m missing something (or you&#8217;ve answered this already), but when you say:</p>\n<p>&#8220;To see why, consider again a Turing machine M that halts if and only if there\u2019s a contradiction in ZF set theory.  Clearly such a machine could be built, with some finite number of states k. &#8221;</p>\n<p>Is the implication that the minimum k such that you could construct such a Turing machine is the first k for which you cannot prove it will run forever in ZFC, or is it possible that even this bound is not tight &#8211; i.e. there may be even a smaller k?</p>\n]]>", "author": "Dave", "published": "2016-05-06 22:02:40+00:00", "title": "By: Dave"}, {"content": "<![CDATA[<p>This is a really neat project!  I wonder:  How hard would it be to code a universal Turing machine in Laconic?  (Has anyone already done this yet?)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/White:Philip.html\">Philip White</a>", "published": "2016-05-06 22:43:12+00:00", "title": "By: Philip White"}, {"content": "<![CDATA[<p>Dave #161: Great question!  Yes, it&#8217;s conceivable that there exists a k for which there&#8217;s not yet a k-state Turing machine whose running forever we can prove implies Con(ZFC)&#8212;and yet nevertheless, there&#8217;s a k-state machine that <i>does</i> run forever, and which ZFC can&#8217;t prove runs forever for some other reason.</p>\n<p>On the other hand, in practice, I believe that essentially the <i>only</i> way we know how to show that the fact a Turing machine&#8217;s running forever is unprovable in ZFC, is to show that it implies Con(ZFC).  (Any experts can correct me if I&#8217;m wrong.)</p>\n]]>", "author": "Scott", "published": "2016-05-06 23:22:05+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Philip #162: I don&#8217;t think it would be hard at all to code up a universal Turing machine in Laconic (at least, were Laconic appropriately extended to deal with Turing machines that take input).  But since we already know tiny universal Turing machines, what would be the point?</p>\n]]>", "author": "Scott", "published": "2016-05-06 23:23:51+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Jay #156: The gap in your argument comes when you say, &#8220;So it must run forever.&#8221; You are correct that if the TM stops then this fact can be proven without I3. In this sense I3 is not &#8220;needed.&#8221; But when people say that I3 is &#8220;needed&#8221; to prove that P(n) eventually hits 32, they mean only that nobody <i>knows</i> a proof of this fact that doesn&#8217;t invoke I3 (or something similar), not that there couldn&#8217;t be one.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chow:Timothy.html\">Timothy Chow</a>", "published": "2016-05-07 00:07:22+00:00", "title": "By: Timothy Chow"}, {"content": "<![CDATA[<p>Scott #164:  I hadn&#8217;t initially realized that Laconic isn&#8217;t designed to construct Turing machines that take input.  But if Laconic programs can be compiled to Turing machines, and since every variable when declared is initialized to 0, shouldn&#8217;t the inner workings of the Turing machine that gets compiled allow the TM to still work on other inputs&#8230;even if the Laconic interpreter itself can&#8217;t simulate the TM on other values?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/White:Philip.html\">Philip White</a>", "published": "2016-05-07 00:50:07+00:00", "title": "By: Philip White"}, {"content": "<![CDATA[<p>Scott #163: One approach that comes to mind is to have a machine that searches for ZFC-proofs of <i>its own</i> non-termination, a la the <i>first</i> incompleteness theorem.  I think this would not give you Con(ZFC), but an expert would have to weigh in.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-07 02:41:32+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>Stefan #163: The Goedel sentence G of the first incompleteness theorem (that states &#8220;G is not provable in T&#8221;) is equivalent to Con(T). To see this, note first that if we assume G, i.e., if we assume that G is not provable in T, then in particular T is consistent, since inconsistent systems prove everything. Conversely, if we assume that T is consistent, then by the first incompleteness theorem, we can conclude that G is not provable in T; i.e., we can conclude G.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chow:Timothy.html\">Timothy Chow</a>", "published": "2016-05-07 04:27:41+00:00", "title": "By: Timothy Chow"}, {"content": "<![CDATA[<p>Wolfgang #155 wrote:</p>\n<p>&#8220;Is there a similar thing for the \u03bb-calculus, if possible freely available? \ud83d\ude0e&#8221;</p>\n<p>My own route to the \u03bb-calculus went through category theory, so I&#8217;m not the best guy to ask.   There&#8217;s this:</p>\n<p>&bull; Palmstr\u00f6m, <a href=\"http://palmstroem.blogspot.com/2012/05/lambda-calculus-for-absolute-dummies.html\" rel=\"nofollow\">The Lambda Calculus for Absolute Dummies (like myself) </a>.</p>\n<p>but personally I find this clearer:</p>\n<p>&bull; Wikipedia, <a href=\"https://en.wikipedia.org/wiki/Lambda_calculus\" rel=\"nofollow\">Lambda calculus</a>.</p>\n<p>together with this stripped-down, formal treatment:</p>\n<p>&bull; Wikipedia, <a href=\"https://en.wikipedia.org/wiki/Lambda_calculus_definition\" rel=\"nofollow\">Lambda calculus definition</a>.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baez:John.html\">John Baez</a>", "published": "2016-05-07 05:12:54+00:00", "title": "By: John Baez"}, {"content": "<![CDATA[<p>Scott #158 wrote:</p>\n<p>&#8220;In any case, though, I personally have no strong intuition as to whether I3 should be consistent with ZFC or not.&#8221;</p>\n<p>Indeed, I3 was intended to come almost as close as possible to being inconsistent without actually being inconsistent.   So this is risky territory!</p>\n<p>There&#8217;s a beautiful kind of large cardinal called a <a href=\"https://en.wikipedia.org/wiki/Reinhardt_cardinal\" rel=\"nofollow\">Reinhardt cardinal</a>.  Unfortunately, it was proved to be inconsistent with ZFC in 1971.  So, set theorists backed down a bit and formulated axioms <a href=\"https://en.wikipedia.org/wiki/Rank-into-rank\" rel=\"nofollow\">I0, I1, I2, and I3</a>, which state the existence of somewhat smaller large cardinals (with I0 being the biggest).  </p>\n<p>Nobody has been able to prove these are inconsistent with ZFC.  But they&#8217;re trying to get as close to the fire as they can without getting burned!  It&#8217;s a high-powered version of &#8220;trying to name the biggest number&#8221;.  </p>\n<p>Indeed, Eliezer Yudkowsky used an I0 rank-into-rank cardinal to <a href=\"http://echochamber.me/viewtopic.php?p=3254229#p3254229\" rel=\"nofollow\">win a contest for naming the largest computable natural number</a>.  But if this existence of this cardinal turns out to be inconsistent with ZFC, his number will turn out to have been a mirage.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baez:John.html\">John Baez</a>", "published": "2016-05-07 05:29:40+00:00", "title": "By: John Baez"}, {"content": "<![CDATA[<p>Scott #110: I&#8217;ve got some work in progress that looks like it&#8217;ll hit all three of your benchmarks, although it&#8217;s far too general to compete with code golf addict #151 \u2026</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-07 11:21:39+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>Stefan #167, Timothy #168: While, indeed, Stefan&#8217;s idea doesn&#8217;t quite work (because the G&ouml;del sentence G(ZFC) is equivalent to Con(ZFC)), I thought of something else that in principle <i>would</i> work: the Rosser sentence, R(ZFC).  That is, we could build a Turing machine M that halts iff it finds a ZFC proof that <i>there&#8217;s a proof that M runs forever and no shorter proof that M halts.</i></p>\n<p>We then have:<br />\n(1) Con(ZFC) implies that M runs forever.<br />\n(2) ZFC can&#8217;t <i>prove</i> that M runs forever, without being inconsistent.<br />\n(3) There&#8217;s at least no obvious proof that M running forever implies Con(ZFC).  (For even if M runs forever, ZFC could still have an inconsistency, as long as the proof that M halts is shorter than the proof that it runs forever.)</p>\n<p>In practice, though, it&#8217;s hard to imagine how a machine whose running forever was equivalent to the Rosser sentence, would be smaller than a machine whose running forever was equivalent to the G&ouml;del sentence and to Con(ZFC).</p>\n]]>", "author": "Scott", "published": "2016-05-07 12:47:48+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>You mention how the Collatz conjecture and many other conjectures are not a \u03a0\u2080 problems, so we can&#8217;t disprove it with a Turing machine.  Could you tell me good examples of famous conjectures or open problems that are thought to be very difficult to resolve, but not generally conjectured to be independent of ZFC, and that are \u03a0\u2080 statements?  The best I can come up with are the value of the sixth Ramsey number (this is actually \u0394\u2080, we can compute it with a program with a known time bound), or the Hadwiger conjecture about graph coloring.</p>\n]]>", "author": "jonas", "published": "2016-05-07 13:06:41+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<p>jonas #173: I think you mean &Pi;<sub>1</sub> statements.  This post already mentioned two famous examples: Goldbach&#8217;s Conjecture and the Riemann Hypothesis!  But there are many, many others:</p>\n<p>&#8211; Any conjecture about a Diophantine equation not being solvable, or only having a fixed list of solutions (e.g., your favorite generalization of Fermat&#8217;s Last Theorem)</p>\n<p>&#8211; Strengthenings of P&ne;NP, such as 3SAT having no circuits of size n<sup>log(n)</sup> (more generally, &Pi;<sub>1</sub> strengthenings of almost any asymptotic conjecture in combinatorics or theoretical computer science)</p>\n<p>&#8211; The conjecture that the frequencies of the digits of &Pi; never deviate from their means by more than a prescribed value; other such conjectures in probability theory</p>\n<p>For the &#8220;other&#8221; Clay problems&#8212;Navier-Stokes existence and smoothness, the Yang-Mills mass gap, the Birch and Swinnerton-Dyer conjecture, etc.&#8212;their logical complexity is an interesting question to which I don&#8217;t know the answer.  I don&#8217;t know that anyone has even bothered to check!  But if nothing else, I&#8217;m pretty sure all these statements have plausible &Pi;<sub>1</sub> variants &#8220;in their neighborhood&#8221; (e.g., that imply them or are implied by them).</p>\n]]>", "author": "Scott", "published": "2016-05-07 13:52:24+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>I read this post with interest, and I have a layman&#8217;s question: why focus on ZFC, and not on Peano or Robinson arithmetic ? Since G\u00f6del&#8217;s incompleteness theorems apply to formal systems containing Robinson arithmetic, I thought the latter appears as a &#8220;distinguished&#8221; system, more than ZFC (please correct me if I&#8217;m wrong). Besides, it might be easier to handle since it is finitely axiomatized, with no axiom scheme.<br />\nMaybe the difficulty is to prove that consistency of Robinson arithmetic implies that the constructed TM runs forever?</p>\n]]>", "author": "Benoit", "published": "2016-05-07 14:24:06+00:00", "title": "By: Benoit"}, {"content": "<![CDATA[<p>I too basically learned the basics of &lambda;-calculus from Wikipedia.  Basically the one big thing about it I remember learning elsewhere was that it&#8217;s confluent, which wasn&#8217;t mentioned on Wikipedia at the time, but now it is, so!  (I&#8217;m not sure Wikipedia&#8217;s presentation is really the greatest at the moment, but, it&#8217;s probably good enough?)</p>\n<p>Here&#8217;s a neat little &lambda;-calculus challenge I like to give people: Write a function that takes (in the usual curried way) first a whole number n, folllowed by n arguments, and returns them in a list.  (By a list I mean a linked list.  You can represent all this however you like; basically I&#8217;m assuming that you&#8217;ve already built up sensible &#8220;primitives&#8221; for working with numbers, with ordered pairs, and with &#8220;nil&#8221;.)</p>\n<p>Note that this isn&#8217;t possible, in say, Haskell; there&#8217;s no possible type for such a function!  It&#8217;s only possible in the untyped &lambda;-calculus.  But it&#8217;s a little tricky.</p>\n<p>BTW, this has been linked here before, but <a href=\"http://mathoverflow.net/questions/108433/for-which-millennium-problems-does-undecidable-true\" rel=\"nofollow\">here&#8217;s</a> a MathOverflow question where people try to place the various Millennium Prize problems on the arithmetic hierarchy.  For the most part, they don&#8217;t come to any conclusions beyond what&#8217;s already been said, but apparently Navier-Stokes is &Pi;_2.</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-07 15:04:24+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>Regarding this sentence in the paper:</p>\n<p>&#8220;It is therefore impossible  to  prove  the  value  of BB(4,888)  without  simultaneously  proving  or  disproving  Goldbach\u2019s conjecture.&#8221;</p>\n<p>This says that any proof of BB(4888) would prove whether G halts or not. Is that actually true?</p>\n<p>A proof of BB(4888)=x implies that G either doesn&#8217;t halt or halts in a number of steps <= x (which still leaves Goldbach&#039;s conjecture undecided). Why does it need to imply anything more than that?</p>\n]]>", "author": "Ricardo Barreira", "published": "2016-05-07 15:27:31+00:00", "title": "By: Ricardo Barreira"}, {"content": "<![CDATA[<p>Benoit #175: We chose ZFC because it&#8217;s around the &#8220;maximum&#8221; of what working mathematicians would normally assume (whereas PA is clearly less, since it doesn&#8217;t even allow ordinal induction); because Harvey Friedman had ZFC-independent statements that were suitable for our purpose; and because the most famous PA-independent statements, like Goodstein&#8217;s Theorem and the non-losability of the hydra game, are not &Pi;<sub>1</sub>.  But as Adam and I said before, the smallest TM whose halting is independent of PA is one of the most interesting directions for future research!  And conceivably a PA-independent TM could be found that was vastly smaller than the smallest known ZFC-independent TM.</p>\n<p>I don&#8217;t understand the power of Robinson arithmetic well enough to be able to comment much, but can&#8217;t Robinson arithmetic not even prove that addition is commutative?</p>\n]]>", "author": "Scott", "published": "2016-05-07 17:43:36+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Ricardo #177: A more careful statement would be that, if you knew BB(4888)&#8212;or scratch that, BB(31)&#8212;then the problem of proving or disproving Goldbach&#8217;s Conjecture would be reduced to a &#8220;mere finite calculation.&#8221;  You&#8217;d simply need to run your Goldbach TM for BB(31) steps, and see if it had halted by then!  If not, then it can never halt.</p>\n]]>", "author": "Scott", "published": "2016-05-07 17:57:59+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Yeah, despite being enough for G\u00f6del, Robinson arithmetic is really weak.  On that note, here&#8217;s an interesting <a href=\"http://arxiv.org/abs/1604.07309\" rel=\"nofollow\">paper</a> (stemming from this <a href=\"http://mathoverflow.net/a/194502/5583\" rel=\"nofollow\">MathOverflow answer</a>, also worth looking at) I encountered recently.  It considers the problem &#8212; given a Diophantine equation, is it <i>consistent</i> with Robinson arithmetic?  Like, is there at least <i>some</i> model of Robinson arithmetic where it has a solution?  For stronger theories like PA this is undecidable, of course, but for Robinson arithmetic instead it is NP-complete!  The models constructed for the proof are pretty far from resembling the actual natural numbers, unsurprisingly, and I think do a good job demonstrating the weakness of Robinson arithmetic.</p>\n<p>If you really want to go weaker than PA, maybe <a href=\"https://en.wikipedia.org/wiki/Elementary_function_arithmetic\" rel=\"nofollow\">elementary function arithmetic</a> might be an appropriate challenge, in light of &#8220;Friedman&#8217;s grand conjecture&#8221;?  I don&#8217;t know, this is really not my area either!</p>\n]]>", "author": "Sniffnoy", "published": "2016-05-07 18:21:20+00:00", "title": "By: Sniffnoy"}, {"content": "<![CDATA[<p>@ #179 Thanks Scott, that&#8217;s what I suspected.</p>\n]]>", "author": "Ricardo Barreira", "published": "2016-05-07 20:03:30+00:00", "title": "By: Ricardo Barreira"}, {"content": "<![CDATA[<p>I don&#8217;t understand this thread well enough to properly ask my question.  I also don&#8217;t understand Hamkins-Miasnikov arXiv  math/0504351(H-M) well enough, either. Nevertheless I want to ask if it would be possible to use techniques similar to those in Yedidia-Aaronson (Y-A) to tighten up H-M so that it says linear or quadratic or whatever in place of polynomial, and also so that a specific TM representation, or a specific UTM is specified?  If it is not obvious, the point is to make H-M into a real working tool.</p>\n]]>", "author": "James Graber", "published": "2016-05-07 23:07:36+00:00", "title": "By: James Graber"}, {"content": "<![CDATA[<p>Off Topic :<br />\nScott, </p>\n<p>Do you have any thoughts on Donald Hoffman&#8217;s interface theory of consciousness and his idea to start with mathematically describing consciousness and then deriving down to physical reality rather than the standard approach of going the other way ? </p>\n<p><a href=\"https://www.youtube.com/watch?v=oYp5XuGYqqY\" rel=\"nofollow\">https://www.youtube.com/watch?v=oYp5XuGYqqY</a></p>\n]]>", "author": "Sam Howley", "published": "2016-05-08 03:06:43+00:00", "title": "By: Sam Howley"}, {"content": "<![CDATA[<p>In regard to Sniffnoy&#8217;s mention (in #180) of <a href=\"https://en.wikipedia.org/wiki/Elementary_function_arithmetic#Friedman.27s_grand_conjecture\" rel=\"nofollow\">Elementary Function Arithmetic (EFA) and Friedman&#8217;s Grand Conjecture</a>, Freedman&#8217;s original discussion (1999) particularly focused upon Hilbert&#8217;s elegantly short, but transfinite and hence nonconstructive proof of what is todays called Hilbert&#8217;s Basis Theorem, as contrasted (by Friedman) with modern-day proofs that are longer and stodgier, but on the other hand are EFA-compatible and explicitly constructive. </p>\n<p>As Friedman observes<br />\n<blockquote>&#8220;These are seriously different proofs!!!&#8221;</p></blockquote>\n<p>(punctuation by Friedman).</p>\n<p>For practical calculations the more-modern less-elegant (?) EFA-compatible constructive methods have substantial advantages.  Two well-regarded texts that teach these methods are by David Cox, John Little, and Donal O&#8217;Shea&#8217;s <i>Using Algebraic Geometry</i> (2nd edition, 2005) and <i>Ideals, Varieties, and Algorithms</i> (3rd edition, 2007), by the same authors.</p>\n<p>Here&#8217;s a Ken Wilson quote that illuminates the above considerations (and also my earlier comment #63 on Gr\u00f6bner bases):<br />\n<blockquote>I particularly got interested in the question if I had a computer big enough, how would I do this computation [in quantum statistical mechanics]?  That became sort of a guiding point to drive me to how to think about the [quantum simulation] problem. </p>\n<p>How can I convert this from a problem of infinite number of degrees of freedom, which you can&#8217;t deal with anyhow, to a problem which is finite even if it was so large that you would have to have an astronomical size computer? </p>\n<p>I just wanted to convert it from an infinite number of degrees of freedom to a finite number.</p></blockquote>\n<p>From &#8220;Interview with Kenneth G. Wilson&#8221; (2002, Google finds it).</p>\n<p><b>Conclusion</b>&nbsp; Plenty of enduringly successful projects in mathematics and physics have begun with insights gleaned from explicitly constructive, explicitly finitistic computations, similar to Adam Yedidia&#8217;s project. </p>\n<p>As the poet Pope might have put it:<br />\n<blockquote>Reduce the space,<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if possible, with grace.<br />\nIf not, by any means<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reduce the space.</p></blockquote>\n<p>Congratulations to Adam Yedidia and his colleagues for a fascinating research program that is well-begun.</p>\n]]>", "author": "John Sidles", "published": "2016-05-08 03:12:00+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Sam #183: No, sorry, I don&#8217;t know anything about that.</p>\n]]>", "author": "Scott", "published": "2016-05-08 03:23:39+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>We can attempt to classify instances of the halting problem into a few different types:</p>\n<p>1. We know the answer to this question.<br />\n2. We can prove that this question is equivalent to some open mathematical problem.<br />\n3. We can prove this question is equivalent to the consistency of some theory, or is  otherwise undecidable in some standard theory.<br />\n4. We have no idea how to turn this question into a human-comprehensible mathematical problem &#8211; the program looks totally random but it inexplicably continues to run for a very long time. As far as we know, we could run it for a few more steps and it would halt, or we could the next day find a proof that it runs forever.<br />\n5. We are quite confident that we will never figure out how to turn this question into a human-comprehensible one and would be shocked if it was proved unsolvable.</p>\n<p>Of course these boundaries are somewhat subjective and problems can move between the different categories. Still I think they are a pretty good classification.</p>\n<p>What I want to know is &#8211; in some model of computation, is the first hard instance of type 2,3,4, or 5?</p>\n<p>The pessimistic answer is of course 4, that we reach the limits of our understanding before we reach the precious jewels of interesting mathematics. For n-state 2-symbol Turing machines, I think the answer is pretty likely 4. In particular note that the shortest Turing machine currently of type 2 has 31 states, and that it is only known to be of type 2 to one person (code golf addict #151), and that any other mathematician looking at the Turing machine might very well fail to detect the pattern. Given the Busy Beaver number data, it seems likely that there are very many Turing machines of at most 30 states that do not halt in the time we can run them on our computers.</p>\n<p>This question gets more interesting if we use more human-comprehensible languages, and in particular human-comprehensible languages that are useful for representing mathematical concepts. The extreme end here might be Peano Arithmetic, which I guess does not always produce an instance of the Halting problem. Is it true that every statement in Peano arithmetic using at most 33 symbols is one of the first two types? </p>\n<p>One could also ask this about standard programming languages. Do we reach total combinatorial chaos before we hit the ordinary mathematical kind of difficulty?</p>\n<p>Surely for really weird Turing complete languages like Wang tiling we reach 4 long before we reach 2 and 3.</p>\n]]>", "author": "Will", "published": "2016-05-08 05:33:40+00:00", "title": "By: Will"}, {"content": "<![CDATA[<p>Regarding TM&#8217;s that look for a counterexample to Goldbach&#8217;s conjecture: Here is how I would build one.</p>\n<p>Let us first allow more than two tape symbols. There is one basic nonblank symbol &#8220;b&#8221;, plus other symbols, which we can think of as post-it labels of different colors that the machine uses to mark different places.</p>\n<p>Say the machine wants to check whether the even number n is the sum of two primes. It has n written out in unary in the tape as bbb&#8230;b.</p>\n<p>To represent the splitting of n into two numbers x+y, it sticks a &#8220;blue&#8221; label on the x-th &#8220;b&#8221;.</p>\n<p>To check whether x (or y) is prime, the machine tries, for each i = 2,3,&#8230;x-1 the following: Hop i steps at a time along the representation of x, and see whether in the last hop you fall exactly at the end of x. (Then x is not prime.)</p>\n<p>To do the hopping, you have to have the number i written in unary somehere else on the tape, and you have to go back and forth between the representation of x and the representation of i, using and moving around labels of a few other colors.</p>\n<p>The details are left as an exercise to the reader&#8230; \ud83d\ude42</p>\n<p>How do we convert this into a two-symbol machine? Well, if the number of distinct label colors is k, then we leave k spaces between each pair of adjacent &#8220;b&#8221;s, and we use these spaces to put &#8220;flags&#8221; that mark the presence of labels of different colors.</p>\n<p>I did not work out the details, but I cannot imagine that the number of states would reach into the thousands&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nivasch:Gabriel.html\">Gabriel Nivasch</a>", "published": "2016-05-08 05:35:47+00:00", "title": "By: Gabriel Nivasch"}, {"content": "<![CDATA[<p>And in some sense Busy Beaver is just an explanation device for the real answer: Arithmetic Beaver.</p>\n<p>Even Yudkowsky&#8217;s definition already depends on the chosen natural number model: \u00abthe length of the shortest contradiction in ZFC+CH\u00bb can be ill-defined or well-defined depending on the chosen model of PA (or ZFC, or ZFC+CH)</p>\n<p>And if we allow such dependence, we should use it to the max. </p>\n<p>So my answer to BB(1000000) is \u00abthe largest number that can be described as the minimal number (finite ordinal) satisfying some formula in ZFC language (including the functional symbols for standard operations and constant \u00f8) with no more than 1000000 predicate symbols, functional symbols and constant symbols combined\u00bb</p>\n]]>", "author": "Michael", "published": "2016-05-08 12:20:07+00:00", "title": "By: Michael"}, {"content": "<![CDATA[<p>Scott #174: You use &#8220;etc.&#8221; to stand for just the Hodge conjecture, as it&#8217;s the only unsolved Millennium Prize Problem that you don&#8217;t mention. While the other MPPs are indeed quite likely to be Pi_1, I&#8217;m not so sure that HC is. Of course that could just be because I don&#8217;t really understand anything about HC, but if there is a proof that it&#8217;s Pi_1, I&#8217;d like to know.</p>\n]]>", "author": "Aula", "published": "2016-05-08 12:37:06+00:00", "title": "By: Aula"}, {"content": "<![CDATA[<p>[&#8230;] al Busy Beaver, mi perdonerai se questa volta non mi documento affatto e mi limito a segnalarti questo interessante articolo (del solito Scott Aaronson) che divulga\u00a0 un nuovo risultato sulla simpatica bestiola. Se sei [&#8230;]</p>\n]]>", "author": "Beaver sempre pi Busy | Massimo Morelli's blog", "published": "2016-05-08 13:48:53+00:00", "title": "By: Beaver sempre pi\u00f9 Busy | Massimo Morelli's blog"}, {"content": "<![CDATA[<p>Scott re #174: yes, I mean \u03a0\u2081 instead of \u03a0\u2080, and even with that change the question I asked wasn&#8217;t very good.  </p>\n<p>I&#8217;m not sure about the status of Goldbach conjecture itself.  Do the number theorists who actually understand that topic still consider it such a hard conjecture that they don&#8217;t expect it to be cracked in a few decades?  There&#8217;s been a lot of advances on it.</p>\n<p>The Fermat generalizations and statements about the digits of \u03c0 are a good suggestion, there are probably some that people consider very difficult.  Although now you mention it, are there also \u03a0\u2081 versions of Schanuel&#8217;s conjecture?  Something like that might be even more convincing.  </p>\n<p>About \u201c3SAT having no circuits of size n**log(n)\u201d, that&#8217;s a nice idea, if you put some realistic lower bound on n (like n is greater than 2**64 or something) then indeed you&#8217;d get a \u03a0\u2081 statement that sounds like a good strengthening of P!=NP.  I didn&#8217;t think there were \u03a0\u2081 versions like this, it&#8217;s obvious only in retrospect, so thank you for mentioning that.</p>\n]]>", "author": "jonas", "published": "2016-05-08 15:30:19+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<p>Michael #188: Aha, but if <i>I&#8217;m</i> setting the rules of the biggest number contest, then I reject any number whose identity depends on an &#8220;intended model of set theory.&#8221;  As it happens, I just had an email exchange about this with Agustin Rayo&#8212;he&#8217;s my colleague at MIT who invented <a href=\"https://en.wikipedia.org/wiki/Rayo%27s_number\" rel=\"nofollow\">Rayo&#8217;s number</a>&#8212;and Agustin was clear and explicit that, if you reject the idea of an &#8220;intended model of ZFC&#8221; (something that would even decide, e.g., the Axiom of Choice and Continuum Hypothesis), then you should also reject the well-definedness of his number.  I believe similar comments apply to Eliezer&#8217;s number.</p>\n<p><i>My</i> rule is that the number you name need not come with an algorithm to compute it, but it does need to have a definition that &#8220;bottoms out in arithmetic and computation,&#8221; as BB(1000) clearly does and as Rayo&#8217;s number clearly doesn&#8217;t.  Now, I freely admit that my rule is still somewhat ambiguous: in particular, once you generalize the Busy Beaver function to the ordinal levels of the arithmetic hierarchy, the whole big-number contest degenerates into a debate about <i>which notations for computable ordinals we can &#8220;know&#8221; to be well-founded</i>&#8212;which will in turn likely boil down to which large-cardinal axioms we can &#8220;know&#8221; to be consistent with ZFC.</p>\n<p>OK, but it&#8217;s crucial to understand that the point at which my contest dissolves into arguments about the consistency of this or that large-cardinal axiom, is <i>still</i> vastly before the point at which we&#8217;re talking about &#8220;intended models&#8221; for all of ZFC! \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-05-08 15:37:12+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>jonas #191: FWIW, Terry Tao has expressed optimism about Goldbach, which seems reasonable to me, since there are so many <a href=\"https://en.wikipedia.org/wiki/Goldbach%27s_conjecture#Rigorous_results\" rel=\"nofollow\">related statements</a> (Vinogradov&#8217;s Theorem) that have been proven.  My opinion certainly doesn&#8217;t count for much, but I&#8217;d bet plenty of money against Goldbach being independent of ZFC.</p>\n<p>(All the more so because, as unlikely as it seems to me that Goldbach is independent of ZFC, it seems even more unlikely that we&#8217;d <i>prove it if so</i>, and therefore that my counterparty could collect! \ud83d\ude42 )</p>\n]]>", "author": "Scott", "published": "2016-05-08 15:42:14+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>There seems to be a general pattern here of cases where diagonalization is &#8220;the only easy way out&#8221;.</p>\n<p>All natural arithmetical statements known to be independent of ZFC imply Con(ZFC).</p>\n<p>All natural computable predicates known to be outside P are DTIME(superpoly)-hard.  (hey, if someone can prove NP=EXP  via succinct certificates for generalized chess it would neatly solve both P=NP and ETH!)</p>\n<p>All natural functions known to be non-computable are hard for the halting problem (i.e. they lie at or above 0&#8242;, as opposed to intermediate Turing degrees).</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-08 17:00:51+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>I&#8217;ve got Goldbach down to 27 now. At the link you can see code for the 27- and 31-state versions, as well as pseudocode explaining the 31-state version.</p>\n]]>", "author": "code golf addict", "published": "2016-05-08 17:46:48+00:00", "title": "By: code golf addict"}, {"content": "<![CDATA[<p>Has Terry Tao expressed optimism about binary (strong) Goldbach? I&#8217;m not an expert on this, but as far as I know, there&#8217;s an obstacle (known as &#8220;the parity problem&#8221;) which seems to make methods such as used for the weak Goldbach unusable for the strong case. I believe that experts think that something completely new is needed.</p>\n]]>", "author": "anon", "published": "2016-05-08 18:03:59+00:00", "title": "By: anon"}, {"content": "<![CDATA[<p>Scott #193: Where has Terry Tao expressed optimism about Goldbach? Last time I checked, there was no plausible way around the notorious &#8220;parity problem&#8221; that makes Goldbach much more challenging than the odd Goldbach conjecture or Chen&#8217;s theorem.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chow:Timothy.html\">Timothy Chow</a>", "published": "2016-05-08 18:32:00+00:00", "title": "By: Timothy Chow"}, {"content": "<![CDATA[<p>Scott re #192, by \u201cbottoms out in arithmetic and computation\u201d, do you mean to say that you want a definition somewhere within the arithmetical hierarchy?  You probably don&#8217;t mean that exactly, because then you&#8217;d just name a number much higher than BB(1000000).</p>\n]]>", "author": "jonas", "published": "2016-05-08 18:37:37+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<p>anon and Timothy: Sorry, it was wrong of me to put words in his mouth.  I remember he made a list of current open problems about structure and pseudorandomness among primes, talking very pragmatically about what techniques might or might not work for each, in which Goldbach appeared as &#8220;just another entry.&#8221;  (In any case, I can&#8217;t find that list now&#8212;can anyone else?)  But the fact that he included Goldbach on what read like a to-do list doesn&#8217;t imply any particular &#8220;optimism&#8221; on his part&#8212;maybe he just put it there for completeness!</p>\n]]>", "author": "Scott", "published": "2016-05-08 18:54:19+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>TM golfer #195: gratz on reaching 3^3 states / 378 bits.</p>\n<p>Is there a straightforward way to encode the transition table to avoid the n log n redundancy in state ordering?</p>\n<p>When listing a transition, one could use only enough bits<br />\nto encode the number of already listed states, plus one to<br />\nallow introducing a new state. But that would onlly appear to save a linear number of bits&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-08 19:09:54+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>A search for laver tables with periodicity > 16 takes at most 212 bits in binary lambda calculus, so somewhat simpler than goldbach. See</p>\n<p><a href=\"https://github.com/tromp/AIT/blob/master/laver.lam\" rel=\"nofollow\">https://github.com/tromp/AIT/blob/master/laver.lam</a></p>\n<p>courtesey of <a href=\"https://github.com/int-e\" rel=\"nofollow\">https://github.com/int-e</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-08 19:14:40+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>[&#8230;] 0.4 stochastic hours reading The 8000th Busy Beaver number eludes ZF set theory [&#8230;]</p>\n]]>", "author": "Weekly reading post #1 | David R. MacIver", "published": "2016-05-08 21:37:56+00:00", "title": "By: Weekly reading post #1 | David R. MacIver"}, {"content": "<![CDATA[<p>@Stefan #194</p>\n<p>>All natural functions known to be non-computable are hard for the halting problem (i.e. they lie at or above 0\u2032, as opposed to intermediate Turing degrees).</p>\n<p>I don&#8217;t know very much about this, but what degree is the following function:</p>\n<p>Take Chaitin&#8217;s constant, and rearrange its binary digits as follows: for each of the sets {1st digit} {2-3rd digits} {4-7th digits} {2^n-(2^n+1)-1}, order the digits within in ascending order, i.e. zeros then ones. I can&#8217;t think of a good argument that this can be computed, and yet and oracle for it doesn&#8217;t seem to yield a halting oracle as well, because you don&#8217;t know the order of the digits. So even if you simulate enough programs to get something with the same number of 0s and 1s as my constant, maybe running more will turn a 0 to a 1 and a 1 to a 0.</p>\n<p>Is this trivially wrong somehow? Does this count as a &#8220;natural function&#8221;?</p>\n]]>", "author": "Avi", "published": "2016-05-08 21:46:38+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<blockquote><p><b>Scott</b> wonders (#199) &#8220;I can\u2019t find that list [Terry Tao&#8217;s pragmatic discussion of structure and pseudorandomness among primes] now&nbsp;\u2014 can anyone else?</p></blockquote>\n<p>Terry Tao&#8217;s three-part <a href=\"https://terrytao.wordpress.com/tag/marker-lecture/\" rel=\"nofollow\">Marker Lecture post</a> (from November of 2008) may be the &#8220;pragmatic discussion&#8221; that you recall.  The&nbsp;three posts, which span four Marker Lectures, are titled \u201clinear equations in primes,\u201d \u201csmall gaps between primes,\u201d and \u201csieving for almost primes and expanders.&#8221;   </p>\n<p>In any event, this material is well worth reading.</p>\n]]>", "author": "John Sidles", "published": "2016-05-08 22:43:01+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>This is really cool.</p>\n<p>Sorry if the following is too trivial.<br />\nI read your writing on big numbers and also found it entertaining. I saw the comments in the Berry paradox and they seem similar to what happens in Tarski undefinability of truth. So maybe one could circumvent that by saying something like &#8220;let D(N) be the smallest number not definable by formulas of quantifier complexity less than 100 (say), with less than N symbols&#8221; Definable meaning for example in ZFC, this would be a formula of quantifier complexity 101 (metamathematical) in the variable N (mathematical) and captures the spirit of that idea. This looks pretty weird though, I don&#8217;t even know if this depends on the model of ZFC. I would guess that roughly quantifier complexity 1 is something like busy beaver and higher would be something like the generalizations of busy beaver?</p>\n]]>", "author": "Juan", "published": "2016-05-08 22:43:24+00:00", "title": "By: Juan"}, {"content": "<![CDATA[<p>Avi #203: I think that counts as a natural function.  But we know that Chaitin&#8217;s constant is non-computable <b>because</b> it can be used to solve the halting problem.  I suspect one of the following holds for your function:</p>\n<p> You can&#8217;t prove that your function is actually non-computable.<br />\nYou can, and I can extract a halting oracle from your proof.</p>\n]]>", "author": "Stefan O'Rear", "published": "2016-05-09 00:41:21+00:00", "title": "By: Stefan O'Rear"}, {"content": "<![CDATA[<p>John Tromp #201. Very nice. On Code Golf Stackexchange, I just <a href=\"http://codegolf.stackexchange.com/questions/79620/laver-table-computations-and-an-algorithm-that-is-not-known-to-terminate-in-zfc\" rel=\"nofollow\">asked</a> for the shortest program that searches for the least n where <code>2^n>1*32</code> in the n-th classical Laver table. I also plan on asking another question there for the shortest code that halts if and only if it finds a counterexample to the statement <q><code>2*2^m=2^n</code> then <code>1*2^m=2^n</code> in the n-th classical Laver table.</q> Feel free to post your solution there.</p>\n]]>", "author": "Joseph Van Name", "published": "2016-05-09 00:52:44+00:00", "title": "By: Joseph Van Name"}, {"content": "<![CDATA[<p>Sam #183</p>\n<p>I checked out the Hoffman TED talk.  In so far as he&#8217;s saying anything true, it&#8217;s nothing new.  Basically he&#8217;s just making the point that our perceptions are not reality , but rather &#8216;virtual reality&#8217; models or icons created by our brains.  All OK so far.   </p>\n<p>But it appears he a fan of Chopra&#8217;s mystical nonsense (he works with the Chopra foundation) , and he&#8217;s basically just trying to promote the old discredited idea of idealism, that consciousness is the base-level of reality.  It&#8217;s been refuted ever since the beginning of last century, but the new age movement still rakes in a lot of money telling people what they want to hear (basically there&#8217;s still lots of dollars to be made pandering to wishful thinking).</p>\n<p>It&#8217;s pretty clear that Hoffman and co. are dead wrong and Tegmark is basically correct:  it&#8217;s math that&#8217;s actually the base-level of reality.  Physical properties are emergent higher-level properties of mathematics , and mental properties such as consciousness are even higher-level properties generated by physical processes.  So the mystics have everything arse-backwards.</p>\n]]>", "author": "mjgeddes", "published": "2016-05-09 03:19:13+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>Stefan #206: Avi&#8217;s function is non-computable, because it has unbounded information about omega.</p>\n<p>We know that K(Omega_n) >= n + O(1), but knowing how many 0s and 1s are in the second half of n/2 bits would allow you to save about (log n)/2 bits. This gives a contradiction for large enough n of the form n=2^i&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-09 03:36:05+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<p>Scott: Out of curiosity&#8230; \ud83d\ude42</p>\n<p>Let n be the first natural number such that ZFC does not prove an explicit upper bound for BB(n). Conditional on ZFC being consistent, for what value of k would you currently put even odds on n >= k vs n < k?</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:David.html\">David Wu</a>", "published": "2016-05-09 04:27:08+00:00", "title": "By: David Wu"}, {"content": "<![CDATA[<p>To understand what you&#8217;ve accomplished, what was the situation before this result? It was known that there exists an n such that BB(n) is independent of ZFC set theory, but was it known that it would be &#8220;straightforward&#8221; (time-consuming but doable without requiring creative insight) to also determine an explicit value of n for which BB(n) is independent of ZFC? Without using clever constructions, would people&#8217;s hunch be that this n would be much larger than 7,918 but not crazy large?&#8211;say, n would be less than a billion, as opposed to a googolplex.</p>\n]]>", "author": "Richard", "published": "2016-05-09 14:08:16+00:00", "title": "By: Richard"}, {"content": "<![CDATA[<p>Tromp #209: </p>\n<p>Does that allow you to turn an oracle for my function into a halting oracle? Intuitively it seems not because it&#8217;s not giving *enough* information quickly enough.</p>\n]]>", "author": "Avi", "published": "2016-05-09 14:15:43+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Juan #205: Yes, that&#8217;s apparently what Agustin Rayo and Eliezer Yudkowsky did&#8212;namely, attempt to define &#8220;the largest number definable in ZFC with 1,000,000 symbols or fewer&#8221; (which isn&#8217;t itself definable in ZFC, so there&#8217;s no Berry paradox).  The problem is that, unless I&#8217;m seriously misunderstanding something, this could still depend on your intended model of ZFC, and therefore wouldn&#8217;t be allowed by <i>my</i> contest rules.</p>\n]]>", "author": "Scott", "published": "2016-05-09 15:33:53+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>David Wu #210: I dunno, maybe k=15?</p>\n]]>", "author": "Scott", "published": "2016-05-09 15:35:43+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Richard #211:</p>\n<ul>was it known that it would be \u201cstraightforward\u201d (time-consuming but doable without requiring creative insight) to also determine an explicit value of n for which BB(n) is independent of ZFC? Without using clever constructions, would people\u2019s hunch be that this n would be much larger than 7,918 but not crazy large?\u2013say, n would be less than a billion, as opposed to a googolplex.</ul>\n<p>I can actually address this question empirically!  As a first step, we <i>did</i> encode Friedman&#8217;s statement in a straightforward way, without using any ideas to reduce the state count, and we got about 1,000,000 states.  My initial expectation would&#8217;ve been that encoding ZFC directly in the same way would lead to even more states (though not more than 10,000,000), but Stefan O&#8217;Rear has now changed my view on that; I now think that too would lead to about 1,000,000 states.  I don&#8217;t know whether people would&#8217;ve predicted higher or lower before we tried it, but certainly no one would&#8217;ve predicted a googolplex.</p>\n]]>", "author": "Scott", "published": "2016-05-09 15:39:43+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>@code gold addict, #195: I tried to understand your 27-state machine, and made a couple of guesses about your notation convention, which must be wrong, because my hand simulations went off the rails quickly. Contact me at <a href=\"mailto:acwacw@gmail.com\">acwacw@gmail.com</a>, please?</p>\n]]>", "author": "Allan C. Wechsler", "published": "2016-05-09 16:06:44+00:00", "title": "By: Allan C. Wechsler"}, {"content": "<![CDATA[<p>Avi #213: I&#8217;m not sure, but I suspect you might.<br />\nTo recover the first n bits of Omega, you could request the reordered first 2^2^n bits of your oracle, and then approximate Omega from below until the segment frequencies match. At that point one would expect the first n bits to be correct.<br />\nThis is just intuition, and one needs to find a way to formalize it into a real proof&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tromp:John.html\">John Tromp</a>", "published": "2016-05-09 17:31:35+00:00", "title": "By: John Tromp"}, {"content": "<![CDATA[<blockquote><p><b>mjgeddes</b> criticizes (#183) &#8220;the old discredited idea of idealism, that consciousness is the base-level of reality.&#8221;</p></blockquote>\n<p>It is plausible that two  essays that have been mentioned recently in <i>Shtetl Optimized</i> may help to rehabilitate and reinvigorate these idealistic notions; these two essays are Frank Wilczek&#8217;s <i>Quanta Essay</i> &#8220;Entanglement Made Simple&#8221; (of&nbsp;April 2016) and Robert Langland&#8217;s &#8220;Is there beauty in mathematical theories? (2013, search engines find both on-line).</p>\n<p>Wilczek&#8217;s (shorter) essay boils quantum entanglement down to two key principles, which Wilczek states explicitly as:<br />\n<blockquote>(1) &#8220;A property that is not measured need not exist&#8221;, and (2)&nbsp;&#8220;measurement is an active process that alters the system being measured.&#8221;</p></blockquote>\n<p>Langland&#8217;s (longer) essay authorizes and encourages us to apply Wilczek&#8217;s reasoning along the following lines:<br />\n<blockquote>(A.1) Measurements are dynamical processes that reduce the entropy of the system being measured; (A.2)&nbsp;shared entropy-reducing processes produce flows of information that compose our shared objective reality.</p>\n<p>(B.1) Algorithms are dynamical processes that transform informatic flows; (B.2)&nbsp;shared informatic flows compose networks that distill and distribute our shared informatic reality.</p>\n<p>(C.1) Theorem-proving is a dynamical process that conditions our choice of algorithmic postulates; (C.2)&nbsp;shared algorithmic postulates compose inferential frameworks that diversely comprise our shared mathematical realities.</p></blockquote>\n<p>Here (A.1-2) are simply a restatement of Wilczek&#8217;s entanglement principles, in a form that permits  statements (B.1-2) and (C.1-2) to summarize Langland&#8217;s worldview as manifestly parallel to Wilczek&#8217;s.  </p>\n<p>For details of this parallelism, see Langland&#8217;s discussion quantum dynamical processes, in light of which (for example) Langland&#8217;s Diagram A presents an evolutionary tree of quantum mathematical theories and concepts, while Diagram B surveys some of the mathematical names that are associated these theories and concepts.</p>\n<p>Langland&#8217;s perspective on mathematics in general, and quantum dynamics in particular, is algebra-centric (unsurprisingly, given Langland&#8217;s research interests).  This perspective turns out to be advantageous, in that Wilczek&#8217;s perspective on quantum entanglement lends itself very naturally to algebraic elaboration along Langland&#8217;s lines.  </p>\n<p>Note too that Adam Yedidia&#8217;s two-symbol Turing machines too can be naturally described in algebraic terms, as dynamical processes that operate upon Boolean state-spaces.   Turing processes being universal, it is plausible (to me) that our deepest and most fundamental appreciation of Wilczek/Langland worldview will emerge from Yedidia-style investigations.   Certainly Adam has made an outstanding start.</p>\n<p>Perhaps it&#8217;s legitimate to wonder whether there are <i>any</i> STEM disciplines that modern-day algebraists do <i>not</i> aspire to colonize and transform?  Not everyone welcomes this increasing algebraic dominance, needless to say. \ud83d\ude42</p>\n<p><b>Conclusion</b>&nbsp; Wilczek&#8217;s and Langland&#8217;s essays, considered jointly and algebraically, rehabilitate and reinvigorate (what #183 calls) &#8220;that old discredited idea of idealism, that consciousness is the base-level of reality&#8221;.  The  expanded notion is that &#8220;algebraic processes compose a natural base-level of reality&#8221;; a&nbsp;base-level that can be concomitantly realized physically (via&nbsp;A.1-2), informatically (via&nbsp;B.1-2), and cognitively (via&nbsp;C.1-2). </p>\n<p>What&#8217;s invigorating (for me) about the illumination that the Wilczek/Langland worldview casts upon <i>Shtetl Optimized</i> concerns, is that the implications of the Wilczek/Langland worldview are concrete and practical, and its implementations are (at present) largely unexplored.  </p>\n<p>Is this broadening and deepening good news, for young researchers especially?  Surely it&#8217;s reasonable to hope so.</p>\n]]>", "author": "John Sidles", "published": "2016-05-09 17:44:52+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Tromp #217:</p>\n<p>Each piece of information we get is independent from the others. So if we want Omega&#8217;s first n digits, the only useful info is the frequencies of the n/2 &#8211; n bits. Frequencies above that don&#8217;t help at all. But that can never be known, unless the ones all come first. Because if the actual sequence is xxxx0xxxx1xxxx, then once we get there we can&#8217;t know that the real sequence isn&#8217;t maybe xxxx1xxxx0xxxx, and some other programs will halt to make it so. This isn&#8217;t a proof, because it might be useful some other way, but we can&#8217;t do it directly like you&#8217;d think.</p>\n]]>", "author": "Avi", "published": "2016-05-09 17:56:48+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Someone on <a href=\"http://mathoverflow.net/a/238400/44423\" rel=\"nofollow\">http://mathoverflow.net/a/238400/44423</a> thinks it&#8217;s below 0&#8242;. So if that&#8217;s right and your proof above is right, then this is a &#8220;natural&#8221; example.</p>\n]]>", "author": "Avi", "published": "2016-05-09 17:59:15+00:00", "title": "By: Avi"}]