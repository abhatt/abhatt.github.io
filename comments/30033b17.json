[{"content": "<![CDATA[<p>Scott #158: No, I don&#8217;t claim intuition about those functions being differentiable or not. Only intuition about the continuity of f(x) = x sin(1/x). That f(x) gets &#8220;closer and closer&#8221; to 0, as x approaches 0.</p>\n<p>Alexander #170: I was following the usual convention, at least for this particular function, that  f(0) = 0.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cleve:Richard.html\">Richard Cleve</a>", "published": "2014-06-08 13:57:07+00:00", "title": "By: Richard Cleve"}, {"content": "<![CDATA[<p>@Alexander #169</p>\n<p>>> we can simulate much simpler brains</p>\n<p>I think it is *possible* that consciousness is a side effect with little evolutionary advantage. </p>\n<p>As far as I know, the (classical) neural network of e.g. snails is sufficient to explain all the behavior of those animals.<br />\nThis could still be true for larger brains, however, consciousness *could* be an inevitable quantum side effect of wet computers.</p>\n<p>It could very well be that the (classical) neural network of human brains would explain (almost) all of our behavior; indeed most of our brain activity is most likely unconscious.</p>\n<p>But it is possible that the simulation of a *conscious* brain would require a quantum computer and it is *possible* that quantum computers cannot exist due to some unknown reason.</p>\n<p>Otherwise, we have to accept one of the other conclusions, which seem equally strange.</p>\n]]>", "author": "wolfgang", "published": "2014-06-08 14:09:57+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Alexander #170: If a function has a limiting value at 0 (like the entropy function p log(1/p)), I thought the usual convention was just to set it equal to that limiting value.</p>\n<p>Richard #171: OK then, you should substitute differentiability of x^k sin(1/x) for continuity of x sin(1/x), and the rest of my analogy should go through as before. <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_smile.gif\" alt=\":-)\" class=\"wp-smiley\" /> </p>\n]]>", "author": "Scott", "published": "2014-06-08 17:57:45+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott (#46): &#8220;So for example, if you burn a book, it must be possible in principle to recover the book from the smoke and ash and emitted photons; if you scramble an egg, it must be possible in principle to unscramble it, etc. These things are \u201ceffectively\u201d impossible, but only for the same statistical reason that you never see the gas particles in a box all collect themselves in a single corner. </p>\n<p>If you want to reject the above, then you need to rewrite not only QM, but essentially all of physics going back to Galileo and Newton!</p>\n<p>&#8230;\u00a0One caveat: above, I was talking only about the evolution of isolated physical systems,..&#8221;</p>\n<p>It is always nice to return to these examples, and while I don&#8217;t fully understand what Scott means by &#8220;possible in principle&#8221; and yet &#8220;effectively impossible,&#8221; let me give my (tentative) take on it:</p>\n<p>It is impossible to recover the book from the smoke and ash and emitted photons; The reason (or principle) behind it is that the amount of information on the ambient quantum system required for such a &#8220;recovery&#8221; exceeds by much the amount of information required to create the book from scratch.</p>\n<p>One aspect of this explanation is that it is information-theoretic and not computational-complexity theoretic so the principle for why the recovery is not possible extends also if we assume unlimited computational resources for the &#8220;recoveror&#8221;.</p>\n<p>(Again, I don&#8217;t know how my explanation is related to Scott&#8217;s.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2014-06-08 18:09:25+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Scott, Richard, it is not only my idea about necessity to be accurate with x=0 for the function.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vlasov:Alexander.html\">Alexander Vlasov</a>", "published": "2014-06-08 18:24:34+00:00", "title": "By: Alexander Vlasov"}, {"content": "<![CDATA[<p>PS. It is interesting an appearance word &#8220;convention&#8221; in such circumstances, cf. the debates about consciousness</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vlasov:Alexander.html\">Alexander Vlasov</a>", "published": "2014-06-08 19:08:43+00:00", "title": "By: Alexander Vlasov"}, {"content": "<![CDATA[<p>Gil #174: No, the issue isn&#8217;t merely the amount of information.  The issue is that the <i>same</i> information is literally there in the smoke and ash.  I.e., if you took the quantum state of the smoke and ash, and ran the evolution equations of physics backwards, you would recover the book.</p>\n]]>", "author": "Scott", "published": "2014-06-08 19:48:24+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #178: so I guess we are in small disagreement. The way I see it, running the equations of physics backwards to retrieve, with good approximation, the  book, requires an amount of information about the &#8220;isolated physical system&#8221; which exceeds by far the amount of information needed to create the book from scratch. (Of course, if you have full information about the &#8220;isolated physical system&#8221; then the question about retrieving the book loses its content.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2014-06-08 21:30:52+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>wolfgang #172:</p>\n<blockquote><p>I think it is *possible* that consciousness is a side effect with little evolutionary advantage.</p></blockquote>\n<p>Yes, that&#8217;s certainly possible. How likely it seems depends on what you mean by consciousness. On the one extreme, there is this meaning of consciousness as in the zombie thought experiments, but then, there is also this meaning as in &#8220;losing consciousness&#8221;.</p>\n<blockquote><p>This could still be true for larger brains, however, consciousness *could* be an inevitable quantum side effect of wet computers.</p></blockquote>\n<p>Yes, that&#8217;s the Penrose/Hameroff hypothesis. Of course, we cannot refute it. But I never really understood why consciousness resulting from quantum effects should be more plausible than consciousness resulting just from the interaction of 10^11 neurons and 10^15 synapses.</p>\n]]>", "author": "Alexander", "published": "2014-06-08 22:41:14+00:00", "title": "By: Alexander"}, {"content": "<![CDATA[<p>wolfgang #172</p>\n<p>wolfgang = snail++;</p>\n<p> <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_smile.gif\" alt=\":)\" class=\"wp-smiley\" /> </p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2014-06-08 23:34:32+00:00", "title": "By: James Cross"}]