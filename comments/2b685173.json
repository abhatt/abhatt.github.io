[{"content": "<![CDATA[<p>Thank you for these fascinating considerations!<br />\nSomething I really enjoy about your decoherence-cosmological theory is that it feels somewhat related to Polanyi&#8217;s idea for how you can have higher levels of description that are not entirely reducible to their components.<br />\nMy understanding/interpretation of his point: our theories perfectly account for the microscopic laws happening &#8220;in the bulk&#8221;, but those bulk laws only serve to process boundary conditions into other boundary conditions. The information stored in the boundaries may very well have its own rules, structures and modes of organization, that are certainly constrained by how they are transmitted by the bulk, but not determined by it.<br />\nIn other words, the medium is not quite the message. And this feels like a decent viewpoint on the problem of consciousness: it is not something that is stored in an object, but in a timeline of interactions (just like meaning does not reside in the book, but in its reading). Maybe interacting sufficiently closely with an agent already involved in a consciousness-web is sufficient to entangle you into that web. How exactly to measure it, and whether it can be copied and transmitted, though, I have no idea.</p>\n]]>", "author": "mrcbar", "published": "2016-06-02 16:58:39+00:00", "title": "By: mrcbar"}, {"content": "<![CDATA[<p>>To see why, I\u2019d like to point to one empirical thing about the brain that currently separates it from any existing computer program. Namely, we know how to copy a computer program. We know how to rerun it with different initial conditions but everything else the same. We know how to transfer it from one substrate to another. With the brain, we don\u2019t know how to do any of those things.</p>\n<p>What about DRM? We can copy programs because we make them or we know specifications of the original computer it was meant to be run on or we can guess (because there aren&#8217;t that many architectures, etc.)</p>\n<p>What if a DRM scheme didn&#8217;t need to run on modern architectures, was written in new programming languages from machine language and up, on entirely new paradigms? Do you think it would be easy to copy? What if it was unethical and illegal to do anything that could stop the program, or break the hardware? Would it even be surprising that we couldn&#8217;t emulate it?</p>\n<p>Even today&#8217;s DRM schemes have not all been broken, and not all programs can be run on other substrates. The ones that have been reverse engineered is because they&#8217;re written for architectures that are already known, and there&#8217;s just specifics that need to be figured out. (Or so is the impression I get from reverse engineering discussions).</p>\n]]>", "author": "Avi", "published": "2016-06-02 17:07:03+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>&#8220;Rather, it was about the human capacity to pass from a formal system S to a stronger system S\u2019 that one already implicitly accepted if one was using S at all\u2014and that indeed, that Turing himself had clearly understood this as the central message of G\u00f6del, that our ability to pass to stronger and stronger formal systems was necessarily non-algorithmic.&#8221;</p>\n<p>You replied that it was odd to appeal to Turing, because he&#8217;d thought about and rejected the Godelian skeptical case against strong AI, but this isn&#8217;t very satisfying to my ears.  What about Penrose&#8217;s contention on its face?</p>\n<p>Also, you state in this piece that you agree that these hard questions that the problem of consciousness implies are worthy of being thought about and worried over.  What do you think about the &#8220;problem of reality&#8221; that I presented in the last post?  Given the initial conditions of the universe and the accurate laws that govern it&#8230; does the universe have to be embodied, i.e., does it have to &#8220;run&#8221; for the consciousness&#8217; within to be considered &#8220;real?&#8221;  I think all the problems you&#8217;ve posed above can be subsumed by this question perhaps minus the question of the seeming non-copyability of consciousness.</p>\n<p>In many ways, these problems of consciousness are rather just a backhanded way at trying to come to grips with the problem of what it means to be &#8220;real.&#8221;  In this age of scientific reductionism, &#8220;reality&#8221; is assumed, but not really defined and I would say this lies at the heart of all these problems of consciousness.</p>\n]]>", "author": "AdamT", "published": "2016-06-02 17:25:46+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>Avi #2,</p>\n<p>I think the point of the non-copyablity of consciousness is that there might very well be something about consciousness which *fundamentally* makes it non-copyiable by the very laws that govern this universe.  With DRM, there is no no-go theorem that disallows copying even in principle like there is with the possibly non-copyable problem of consciousness.  Thus, I don&#8217;t think DRM is particularly helpful analogy here.</p>\n]]>", "author": "AdamT", "published": "2016-06-02 17:29:28+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>Even if our behavior can&#8217;t be predicted due to quantum uncertainty, if that quantum information is truly random, it still wouldn&#8217;t mean &#8220;we&#8221; are choosing our behavior, any more than we could choose any quantum observed property.</p>\n<p>There&#8217;s a bit of leeway on the &#8220;truly random&#8221; part, though. Algorithmic randomness is not enough, because you can easily have algorithmically random numbers that are fully specified (e.g. Chaitin&#8217;s constant). Even if we measured quantum data, we might not be able to prove even in principle if it conformed to some ordering like that while still being algorithmically random.</p>\n<p>So maybe there&#8217;s some room to say that quantum uncertainties affecting decisions do have something to do with free will, without conjecturing any new physical law that has observable properties. We&#8217;d have no way to tell if quantum mechanics isn&#8217;t actually random, as long as it was random in the complexity sense.</p>\n]]>", "author": "Avi", "published": "2016-06-02 17:35:45+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Adamt #4</p>\n<p>I get that. I&#8217;m saying that the fact that we can&#8217;t copy minds (yet) isn&#8217;t as strong evidence for them being uncopyable as it may appear, because copying generic computer programs isn&#8217;t as easy as claimed.</p>\n<p>That is, there&#8217;s a decent &#8220;explanation&#8221; of why it would be hard even without &#8220;fundamental&#8221; difficulties, which lowers the probability that such difficulties are real.</p>\n]]>", "author": "Avi", "published": "2016-06-02 17:38:14+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>AdamT #3: But I <i>did</i> reply to the contention on its face.  Once you realize that the human process of passing to stronger and stronger formal systems is error-prone (if nothing else, we might be wrong about which ordinal notations we use to organize the iterated consistency statements are actually well-founded), you then have to admit that an AI could be error-prone as well but still extremely smart, and the G&ouml;delian argument collapses.</p>\n<p>You raise interesting metaphysical questions.  At the end of the day, though, I&#8217;m more interested in answering a concrete question, one with obvious ethical implications: namely, <i>which physical entities should we judge to be conscious, and which should we judge not to be?</i>  As both neuroscience and AI advance, I&#8217;m optimistic that we might be able to gain more insight about this concrete question without needing to &#8220;solve the problem of reality,&#8221; even if worrying too much about consciousness really <i>can</i> send you off the metaphysical cliff.</p>\n]]>", "author": "Scott", "published": "2016-06-02 17:40:40+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #8,</p>\n<p>I see.  You believe an AI could also jump from formal system to higher formal systems in an error-prone way just like human mathematicians.  It was my assumption that Penrose&#8217; argument was that since an AI must be embodied in a regular old Turing machine equivalent &#8211; without weird gravitational quantum effects &#8211; that it must be running under a particular formal system and could not then conceive of a higher formal system.  I confess I don&#8217;t really understand what is going on when human mathemeticians &#8220;jump&#8221; from one formal system to another much less why Godelian arguments would preclude this.</p>\n<p>You are right that the question <i>which physical entities should we judge to be conscious, and which should we judge not to be</i> has obvious ethical implications and that the answer could be efficacious in the not too distant future.  I would say that the question, unfortunately, hinges upon what we consider &#8220;real&#8221; to be.</p>\n<p>&#8230;</p>\n<p>Or whether we consider &#8220;real&#8221; to be \ud83d\ude09</p>\n]]>", "author": "AdamT", "published": "2016-06-02 17:56:03+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>My answers are:</p>\n<p>* I don&#8217;t consider (intellectually) anything to be &#8220;real&#8221;<br />\n* Including myself<br />\n* This does not preclude suffering<br />\n* Including my own<br />\n* The suffering (of myself and others) occurs because we have not internalized this intellectual understanding (if we even have that)<br />\n* Rather some deep part of our consciousness rebels against this unreality and has done so since beginning less time<br />\n* Consciousness does not arise from matter, but it does obey a conservation law and the No Cloning theorem might indeed be pointing to this conservation of consciousness</p>\n]]>", "author": "AdamT", "published": "2016-06-02 18:04:36+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>Avi #5:</p>\n<ul>Even if our behavior can\u2019t be predicted due to quantum uncertainty, if that quantum information is truly random, it still wouldn\u2019t mean \u201cwe\u201d are choosing our behavior, any more than we could choose any quantum observed property.</ul>\n<p>I addressed this in detail in <a href=\"http://www.scottaaronson.com/papers/giqtm3.pdf\" rel=\"nofollow\">The Ghost in the Quantum Turing Machine</a>&#8212;please take a look (especially Section 3).</p>\n<p>Briefly, though, I think you&#8217;re completely right that the randomness of quantum measurement outcomes (i.e., that of the Born Rule) is a red herring, because ironclad probabilistic laws leave just as scope for libertarian free will as deterministic laws.  (Would we say that a radioactive atom &#8220;freely chooses&#8221; when to decay&#8212;but always, as it happens, by sampling from an exponential distribution?)  That&#8217;s why, in GIQTM, I ask instead about unclonable details of the initial quantum states that eventually get measured (or at least, correlated with their external environments), and not at all about the randomness introduced by the measurement process.  The former is of interest as a potential source of &#8220;Knightian uncertainty,&#8221; whereas quantum measurement gives you merely probabilistic uncertainty.</p>\n]]>", "author": "Scott", "published": "2016-06-02 18:41:25+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Your quantum theory of consciousness is fascinating even though I find it unlikely. A few questions.</p>\n<p>1. Why do you expect an elegant mathematical answer to the question &#8220;is it OK to murder X&#8221;, any more than an elegant mathematical answer to the question &#8220;what is the equation for the coastline of Africa&#8221;? After all, our preferences seem to be a complex jumble of evolutionary accidents and not-murdering is just one of our preferences.</p>\n<p>2. Suppose that human brains indeed contain unique quantum information. Clearly it is also possible to construct objects that contain unique quantum information which have few other brain-like properties. Do you truly grant consciousness to all such objects? If not, if you claim your criterion to be necessary but insufficient, what are the other conditions? If you cannot state them but assume the existence of some unknown non-trivial conditions, what makes you think these extra-conditions will not be sufficient for consciousness without invoking quantum non-cloning?</p>\n<p>3. You write that &#8220;this picture agrees with intuition that murder, for example, entails the destruction of something irreplaceable, unclonable, a unique locus of identity\u2014something that, once it\u2019s gone, can\u2019t be recovered even in principle&#8221; Do you see any strong causal relation between things like the quantum non-cloning theorem and the presence of this intuition in our brain? It seems easy to imagine a universe in which physics doesn&#8217;t allow &#8220;quantum consciousness&#8221; but intelligent entities evolve which have the same intuition for evolutionary reasons. If so, how can this intuition be evidence for the quantum consciousness hypothesis?</p>\n<p>4. What type of argument can plausibly convince you the quantum consciousness theory is wrong?</p>\n]]>", "author": "Vadim Kosoy", "published": "2016-06-02 18:51:16+00:00", "title": "By: Vadim Kosoy"}, {"content": "<![CDATA[<p>Regarding the dangers of AI, I recently read a blog post that did a good job underlying that a more practical and real issue will manifest itself way sooner than we think, regardless of the advances in AI.</p>\n<p><a href=\"http://spectrum.ieee.org/automaton/robotics/military-robots/why-should-we-ban-autonomous-weapons-to-survive\" rel=\"nofollow\">http://spectrum.ieee.org/automaton/robotics/military-robots/why-should-we-ban-autonomous-weapons-to-survive</a></p>\n]]>", "author": "fred", "published": "2016-06-02 18:55:28+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Wow! So much great stuff in a single post!</p>\n<p>My suggestions for the free-will oracle:</p>\n<p>a) Show the history of the computer&#8217;s guess&#8217;s against the user&#8217;s input.</p>\n<p>b) Even better, have it <a href=\"https://en.wikipedia.org/wiki/Commitment_scheme#Bit-commitment_in_the_random_oracle_model\" rel=\"nofollow\">cryptographically commit</a> to a guess, before you make it, so the user can verify.</p>\n]]>", "author": "Silas Barta", "published": "2016-06-02 19:02:50+00:00", "title": "By: Silas Barta"}, {"content": "<![CDATA[<p>Scott #10</p>\n<p>I don&#8217;t think you addressed the point that, even if quantum properties were not random (thus making QM wrong), they could be random enough to appear random, and could even be algorithmically random but not truly random and therefore their nonrandomness would not be detectable even in principle. This means that even if Penrose is proven wrong about his empirical predictions, we would still have an &#8220;out&#8221; consistent with all our observations.</p>\n<p>You can then get Knightian uncertainty over such QM randomness without going back to original states at all.</p>\n<p>Just because something can be predicted probabilistically doesn&#8217;t mean it&#8217;s &#8220;actually&#8221; probabilistic. Just like the mere knowledge that a coin can be modelled accurately with 50% heads/tails doesn&#8217;t imply that the coin is actually a series of independent flips: perhaps it&#8217;s just 101010&#8230; and we haven&#8217;t recognised the pattern yet; analogously, if we have an algorithmically random sequence that doesn&#8217;t imply that there&#8217;s no pattern or no &#8220;freeness&#8221;.</p>\n]]>", "author": "Avi", "published": "2016-06-02 19:07:55+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Hi Scott, I was pleasantly surprised by this; I would have pictured you on the hardline AI-is-merely-computation side for sure. During my undergrad and graduate work (physics) I kept a running list of things that seemed similar between consciousness and QM. Among them, (a) our &#8220;free will&#8221; is really a feeling that &#8220;I didn&#8217;t have to do X, I could have done Y,&#8221; and precisely this sort of nondeterminism is exhibited by measurements in QM; (b) all of this talk about &#8220;intentionality&#8221; is about a sort of spooky connection between two states where their states correlate, which becomes much more trivial if you can just say &#8220;your brain-thought is entangled with that cat-state outside of you&#8221;; (c) consciousness all comes to you in some sort of strange unified whole of &#8220;system-wide properties&#8221;; you see while you hear while you smell &#8212; and occasionally QM requires you to take different parts, say two electrons with opposite momentum, and treat them together (in this case as a Cooper pair) to understand the properties of a system as a whole.</p>\n<p>I wanted to mention one thing which might help you understand Searle&#8217;s Chinese Room argument, because there is a particular point of incredulity which you have to surpass in order to understand it. It&#8217;s that the Turing Test does not distinguish *embeddability* (within other consciousness) and the Chinese Room uses that as leverage to argue that computation is not the mojo by which consciousness works. </p>\n<p>In the Chinese Room, the dance your brain does naturally offers one conscious experience, but then you are also with that brain emulating a separate dance which is another consciousness which understands Chinese, even though you don&#8217;t. (Note that the room is not important and we can imagine that you memorize the symbol table and that the slips of paper in and out are instead presented to you with some pronunciation guide. The point remains even if the Chinese Room is in your head.) </p>\n<p>The Chinese Room argument is precisely that in doing this elaborate mental dance, which feels to you absolutely nothing like understanding what you are saying and therefore speaking Chinese, you are (by hypothesis) nevertheless able to cogently vocalize Chinese locutions. And therefore, the Turing Test wants to say that you understand Chinese, even though we know that it&#8217;s just the emulated-consciousness that understands, not you yourself. The problem boils down to, &#8220;well, you SAID we didn&#8217;t need to look at the plumbing, just at the effects, to figure out whether I understand Chinese. According to the computational theory there is no distinction between &#8216;I understand Chinese&#8217; and &#8216;I implement an algorithm that understands Chinese&#8217; &#8212; but we can see here that there is, we know that these two are very different. Some computer program living within my head understands Chinese but I don&#8217;t? That&#8217;s great &#8212; but you&#8217;ve now given up your hope that consciousness is purely computational with no reference to the causal processes of the brain!&#8221;</p>\n<p>nonetheless the Turing test wants to say &#8220;hey, you understand Chinese!&#8221; and we know that *you* don&#8217;t &#8212; all of these</p>\n]]>", "author": "Chris Drost", "published": "2016-06-02 19:09:25+00:00", "title": "By: Chris Drost"}, {"content": "<![CDATA[<p>A thought experiment\u2026</p>\n<p>Say we adopt scientific reductionism and assume that consciousness arises from particular configurations of matter.  Further, we agree that the problems of consciousness are worthy of investigation and that we *should* grapple with whether we\u2019d be ok with a teleportation device destroying our current physical self and copying it and recreating it on Mars.  Is this something we would be willing to sign up for.  Would we have the courage of our scientific reductionism convictions?</p>\n<p>Ok, so let\u2019s adopt Scott\u2019s No-Cloning escape hatch and say that because of this we wouldn\u2019t be ok with teleportation.  A thorny question comes up: precisely *when* did some particular configuration of matter arise and receive safe harbor from this No Cloning theorem?  When did we become \u201cspecial\u201d from the viewpoint of the No Cloning theorem?  Surely it was at some particular moment in time. Some particular time in the womb I would guess?</p>\n<p>There must have been a time before which we were just a lump of matter with no consciousness which could safely be put through the teleportation device with no material harm and another moment after that where we were endowed with consciousness and it could be said that if we went into the teleportation device whatever came out of the device on Mars would not be *us.*  What could possibly have changed in between those two *discreet* moments?  Let\u2019s go from moment A, specified in planck time, to moment B, one unit of planck time later.  </p>\n<p>If you believe consciousness arises solely from the physical I say it is incumbent upon you to describe the physical principle that provides the spark from moment A, to moment B.  How can moment A have no consciousness, but moment B has it and thereby comes under the safe harbor of the No Cloning theorem to make us \u201cus\u201d and not somebody else.</p>\n<p>Maybe you appeal to the continuum of consciousness and say that some things are completely without it, like a dumb rock, and some have it in spades like a Human.  You *still* have to give the physical principle which allows matter to go from completely devoid of consciousness to something *not* completely void of consciousness.</p>\n<p>I think some scientific reductionists would throw up there hands at this point and say, \u201cBah consciousness\u2026 we\u2019re all just delusional and consciousness is just a category error.  There is nothing *real* about consciousness.\u201d  At that point I would say to those scientific reductionists that if you now don\u2019t believe your own qualia is *real*, then why do you ascribe anything to be real?  Surely, if anything is real, it is our own qualia which is the only thing we have direct contact with.</p>\n]]>", "author": "AdamT", "published": "2016-06-02 19:18:13+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>Avi #14: While I didn&#8217;t completely understand your comment, I addressed some related issues in Sections 12 and 13 of GIQTM (the appendices about defining &#8220;freedom,&#8221; and about prediction and Kolmogorov complexity).</p>\n<p>I should mention that the idea of a &#8220;pseudorandom pattern&#8221; in quantum measurement outcomes is already ruled out by the (now loophole-free) Bell inequality violation experiments&#8212;unless you <i>also</i> want to posit a faster-than-light conspiracy to coordinate faraway pseudorandom outcomes with one another.</p>\n]]>", "author": "Scott", "published": "2016-06-02 19:18:28+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>This post seems like a good place to leave a comment on a seed of an idea that I am not well-trained enough to develop properly: &#8220;Could the mathematical structure of consciousness be a transfinite rather than finite structure?&#8221; When we seek for a mathematical object that resembles the structure of consciousness as embodied in the brain, we would like to capture our intuition that we can perceive the consistency of ZFC. That moves us up the consistency hierarchy of set theory, because a system like ZFC+&#8221;there exists a measurable cardinal&#8221; can prove the consistency of basic ZFC. The logical structure of large cardinal axioms is also suggestive: they possess a kind of self-referential quality which reminds me of Hofstadter&#8217;s belief that strange loops are central to consciousness. Perhaps we live in a mathematical multiverse, but not a finitistic computable one like Tegmark&#8217;s &#8211; maybe we live in the wilder full platonic realm of mathematical possibility, including the transfinite, and our conscious experience is the point of connection between a given computational subset known as physical reality, and the transfinite realm associated subjectively with the inifinite possibilities of pure thought and imagination.</p>\n]]>", "author": "Ben Kidwell", "published": "2016-06-02 19:31:23+00:00", "title": "By: Ben Kidwell"}, {"content": "<![CDATA[<p>> Do you agree, I asked, that the physical laws relevant to the brain are encompassed by the Standard Model of elementary particles, plus Newtonian gravity?</p>\n<p>Even if I agree, from this does not follow we can simulate brain. Take for example movement of bodies in our solar system. We cannot simulate solar system precisely enough with *any* computing power and any precision of data available available beyond few millions of years (see &#8220;Lyapunov time&#8221;). Trying to apply &#8220;people exchanging papers&#8221; computation on that problem is plainly wishful thinking. This considered, how comes anyone can seriously propose billions of neurons in constant interaction can be simulated?</p>\n]]>", "author": "JuroV", "published": "2016-06-02 19:33:12+00:00", "title": "By: JuroV"}, {"content": "<![CDATA[<p>JuroV #19: That&#8217;s precisely why I was careful to say, \u201cgive me a big enough computer <i>and the relevant initial conditions,</i> and I\u2019ll simulate the brain atom-by-atom.\u201d  The reason why the solar system is hard to predict beyond the Lyapunov time of a few million years is because we can&#8217;t measure its initial conditions to sufficient precision.  It&#8217;s not because the relevant dynamical laws contain the ability to solve the halting problem, or anything of that kind.</p>\n<p>Now, could our inability to know the initial conditions to sufficient precision have anything to do with free will or consciousness?  That&#8217;s exactly the question that I spent 85 pages wondering about in <a href=\"http://www.scottaaronson/papers/giqtm3.pdf\" rel=\"nofollow\">The Ghost in the Quantum Turing Machine</a>.  So you might say I&#8217;m open to the idea! \ud83d\ude09</p>\n<p>But I do think it&#8217;s important to clearly distinguish that idea from the very different idea of uncomputability in the dynamical laws.  In particular, we know from Bekenstein and Hawking that, in quantum gravity, you ought to be able to specify the quantum state of any bounded physical system using only a finite number of qubits.  And because unitary evolution preserves inner products, if you got the quantum state slightly wrong, your error would <i>not</i> chaotically blow up over time, but would remain exactly as small as it was.  Thus, if you knew the quantum state of the solar system, a brain, or whatever else, to within some small error &epsilon;, everything that&#8217;s currently known about the laws of physics suggests you could then simulate the system on a Turing machine arbitrarily far into the future.</p>\n<p>So, as I said in the OP, I think the relevant question is not whether, given the initial state, you could simulate the time evolution.  Rather it&#8217;s whether you <i>could</i> know the initial state to sufficient precision without violating the No-Cloning Theorem.</p>\n]]>", "author": "Scott", "published": "2016-06-02 19:50:19+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>There seems to be plenty of discussions relative to the no-cloning argument, and the relation of consciousness in the spatial dimensions.<br />\nBut I rarely see any point on what makes consciousness special in the temporal dimension.<br />\nIt involves the subjective feeling of the passage of time and memories (long term and short term).<br />\nThe sense of &#8220;now&#8221; also involves a finite time window &#8211; now is more than 0.1 sec, but clearly less than an hour. Why is it on that scale? (brain signal speed? chemistry of memory formation? scale of parallelism?)<br />\nWe tend to think that we only exist in the &#8220;now&#8221;, but, according to general relativity, isn&#8217;t space time a solid, eternal &#8220;block&#8221;, with all my temporal &#8220;clones&#8221; simultaneously thinking they&#8217;re the current one? Isn&#8217;t this concept at least as strange as the idea of a spatial cloning?</p>\n]]>", "author": "fred", "published": "2016-06-02 19:51:24+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Scott #17</p>\n<p>Appendix 13 partially addresses my concern, thanks.</p>\n<p>Re Bell, if you&#8217;re willing to allow new physical laws to allow consciousness (you aren&#8217;t, but Penrose is and I&#8217;m offering a simpler version of his claim), you should be willing to allow a new physical law that only applies to human minds, which can&#8217;t be measured in a way that would violate Bell. At the level where we&#8217;re proposing new physical laws, I don&#8217;t think Bell comes into play.</p>\n]]>", "author": "Avi", "published": "2016-06-02 20:03:11+00:00", "title": "By: Avi"}, {"content": "<![CDATA[<p>Chris Drost #15: Thank you!  I have to say, <i>your</i> version of the Chinese Room Argument is much more subtle and interesting than what I took either from Searle himself, or from any of his other expositors.</p>\n<p>In particular, I think your version correctly establishes the following conclusion:</p>\n<ul>Even if we wanted to be extreme computationalists, and say that consciousness must be present in any physical system that passes the Turing test, we could still face enormous difficulties in locating &#8220;where&#8221; within that system the consciousness resides.</ul>\n<p>Thus, in your example, if you&#8217;d memorized the Chinese rulebook, it would be silly to ascribe the understanding of Chinese to <i>you</i>, rather than to the other computational process that you&#8217;re implementing in your head.</p>\n<p>Now, when I try to simulate a strong-AI defender in <i>my</i> head, that person just shrugs and replies, &#8220;the error of ascribing the Chinese understanding to &#8216;you&#8217; is merely a slightly more subtle version of the error that a toddler makes when she sees an actor in a Mickey Mouse costume, and ascribes consciousness to the costume (or maybe to the &#8216;combined Mickey system&#8217;), rather than solely to the actor inside.  Or the error that the ancients made when they identified the mind with the heart rather than the brain.  One can be wildly wrong about <i>which part of a black box</i> contains the consciousness one is talking to, yet still be right that there <i>is</i> a consciousness one is talking to, and that it resides <i>somewhere</i> in the box.&#8221;</p>\n<p>I agree with Searle, or with your simulation of Searle, that the strong-AI position leaves unanswered how to wall off one part of the giant computation that is the universe, and declare, &#8220;<i>this</i> is the part that corresponds to the specific conscious entity Alice.&#8221;  On the other hand, if Searle&#8217;s answer is just to appeal to unspecified &#8220;causal powers&#8221; of certain biological organs&#8212;causal powers for which there&#8217;s no criterion to decide their presence or absence besides &#8220;I have them, my friends have them, and all other entities can go to hell&#8221;&#8212;then that strikes me as a hundred times worse!</p>\n<p>Focusing on in-principle unclonability, rather than just the passing of the Turing test, represents the best I&#8217;ve been able to do towards squaring this circle.  I admit it&#8217;s not very far.</p>\n]]>", "author": "Scott", "published": "2016-06-02 20:28:15+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>A little spoiler first: is Penrose serious when introducing humans as an example for surpassing G\u00f6del&#8217;s incompleteness theorem? That is, human thought as a prototype for correctness and completeness in a formal system?<br />\nSecond, I disagree strongly with every single argument in this discussion. If consciousness is about subjectively doing something (experiencing, deciding, having an opinion), then all you did it is explaining the algorithm that makes a robot say &#8220;but I really like waffles&#8221;. The important word in the last sentence however is &#8220;subject&#8221;.<br />\nI have not read any satisfying definition of consciousness so far, which I believe to be a much more fundamental concept than causing some effect under circumstances which coincidentally relate to the spectrum of morality, free will, computation and the like.<br />\nA thought experiment: Can you think of a measurable property that lets you decide irrefutably whether or not a fellow human of your choice is indeed equipped with conciousness?</p>\n]]>", "author": "tzm", "published": "2016-06-02 20:34:15+00:00", "title": "By: tzm"}, {"content": "<![CDATA[<p>This is a very nice and thought provoking post. I suppose that copying, predicting, or teleporting to Mars fairly small quantum systems: An interesting computation process running on the future IBM quantum computer with 10 qubits, or BosonSampling at an interesting state with 10 bosons (and 20 modes), will already require quantum fault tolerance. </p>\n<p>Thus perhaps we are in agreement that large scale quantum computers and quantum fault tolerance are prerequisites to the more fantastic possibilities mentioned in the post.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2016-06-02 21:08:03+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Interesting discussion.</p>\n<p>I tried the f-g predictor first by myself, then with a pocket coin and then with a random list of numbers (from random.org). It still gave around 95%, constantly going up. Is there something I am missing?</p>\n]]>", "author": "Nu\u00f1o", "published": "2016-06-02 21:20:14+00:00", "title": "By: Nu\u00f1o"}, {"content": "<![CDATA[<p>Nu\u00f1o #26: Nick informs me that a previous version of his app had that bug, and your browser probably cached it.  Try reloading a few times.</p>\n]]>", "author": "Scott", "published": "2016-06-02 22:01:01+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>I think I have your predictor beat. I used my free will to type the following sequence:</p>\n<p>d-f-dd-df-fd-ff-ddd-ddf-dfd-dff-fdd-fdf-ffd-fff&#8230;</p>\n<p>In other words, I entered all sequences of one letter, then all sequences of two letters, then all sequences of three letters, and so on.</p>\n<p>Once I got through the five-letter sequences (too lazy to go further), your predictor was at 45%. A win for free will? Or am I disqualified for cheating? \ud83d\ude00</p>\n]]>", "author": "Joseph", "published": "2016-06-02 22:10:58+00:00", "title": "By: Joseph"}, {"content": "<![CDATA[<p>> Now, I\u2019d argue that this copyability question bears not only on consciousness, but also on free will.  For the question is equivalent to asking: could an entity external to you perfectly predict what you\u2019re going to do, without killing you in the process?</p>\n<p>I hate when scientists talk about free will, because it&#8217;s inevitably conflated with the older concept of free will discussed in philosophy and law, but it&#8217;s not remotely the same thing. Experimenter free will is not (necessarily) the kind of free will most people are concerned with in daily life!</p>\n<p>> Like, imagine they knew the complete quantum state on some spacelike hypersurface where it intersects the interior of your past light-cone.  In that case, the person clearly could predict and clone you!</p>\n<p>Past-you, which is not present-you. And they would need to not only know your complete past quantum state, but every quantum state that influenced your evolution into present-you, which is clearly intractable even if it were possible in principle. I think that&#8217;s a meaningful distinction.</p>\n<p>I think the conundrums you present don&#8217;t have anything to do with consciousness per se, they result from the vaguely defined concept of identity. Certainly consciousness imbues you with subjective awareness such that you feel you have an identity in a colloquial sense, but do you really have identity in a formal sense? What is identity in a formal sense?</p>\n<p>The most well known conundrum of identity: how many car parts can you swap before it&#8217;s really a new car? Does this even have a sensible answer? We too are constantly changing, and parts of us are being replaced like the car. Am I the &#8220;same&#8221; self I was a year ago? 10 years ago? Not really, either subjectively or objectively. At best, it seems I share many commonalities with my past self.</p>\n<p>In computer science, identity is pretty straightforward: it&#8217;s a value equal only to itself. A programming language goes out of its way to ensure that values with identity always equal only themselves at any ONE point in time. Across time all bets are off, and you&#8217;ll get answers either way, but what SHOULD the answer be?</p>\n<p>Finally, it&#8217;s not clear that your notion of &#8220;unclonable, unpredictable, irreversible&#8221; is sufficient, even if it might be necessary. Unique things have *intrinsic value* solely because of their uniqueness, such that many would hesitate to destroy something unique, but that doesn&#8217;t naturally imbue them with any sort of consciousness. But I suppose you are merely saying that consciousness must have this property, not that anything with this property must be conscious.</p>\n<p>> I\u2019d expected to be roasted alive over my attempt to relate consciousness and free will to unpredictability, the No-Cloning Theorem, irreversible decoherence, microscopic fluctuations left over from the Big Bang, and the cosmology of de Sitter space.  Sure, my ideas might be orders of magnitude less crazy than anything Penrose proposes, but they\u2019re still pretty crazy!</p>\n<p>I think your idea is too cross-disciplinary for most people to engage. I&#8217;m interested in philosophical questions like this, but it&#8217;s been too long since my quantum mechanics classes to engage on the minutiae of decoherence, let alone the cosmological aspects that your grand picture paints.</p>\n]]>", "author": "Sandro", "published": "2016-06-02 22:37:20+00:00", "title": "By: Sandro"}, {"content": "<![CDATA[<p>Scott #23:<br />\n> Even if we wanted to be extreme computationalists, and say that consciousness must be present in any physical system that passes the Turing test, we could still face enormous difficulties in locating \u201cwhere\u201d within that system the consciousness resides.</p>\n<p>The Chinese Room is just a clash of intuition and over-reduction. It&#8217;s like being given a sorting algorithm and being told to point out exactly which step does the sorting. It&#8217;s a patently absurd question! Every step does the sorting, and removing even one part breaks it.</p>\n]]>", "author": "Sandro", "published": "2016-06-02 22:56:38+00:00", "title": "By: Sandro"}, {"content": "<![CDATA[<p>Nu\u00f1o #26: the keys are f-d not f-g like you wrote. I made the same mistake initially, so rest assured, you&#8217;re not so predictable!</p>\n]]>", "author": "Sandro", "published": "2016-06-02 23:00:00+00:00", "title": "By: Sandro"}, {"content": "<![CDATA[<p>From my perspective you prove too much; I don\u2019t see why something has to be either non-copyable or in-principle-unpredictable in order to be considered conscious. Since such copying and predicting are outside our experience, I say who knows how we would feel about the robots and robot-human systems with which we would have co-evolved in that far future when the copying/predicting are occurring?<br />\nIt isn\u2019t just that decisions about which beings are conscious have ethical implications\u2014in fact I think that this connection is upside-down: when we represent \u201cconsciousness\u201d as an objective state of an object we are PRIMARILY making an ethical judgment\u2014a judgment about how we will interact with that object\u2014 which we are clothing in metaphysics. To see this, consider the Cartesian position on dogs and cats, which is to regard them as mechanisms lacking souls. Cartesians are thus free to torture them. But from a more modern philosophical perspective, there is no \u201cmental substance\u201d inhering in the brains or pineal glands of either dogs are humans. [One of my phil. profs in Texas recounted the question of the racist janitor who asked the professor whether black people have souls, and was answered \u201cNo! And neither do you!\u201d] Your decision whether to respect and be kind to dogs comes long before any ascertainment of the metaphysical \u201cfact\u201d about something called \u201cconsciousness\u201d in the dog.<br />\nSo I say that the consciousness of robots depends on the future natural history of humans. Another way of saying this is to say that the word \u201cconsciousness\u201d is used in malleable and not-necessarily-consistent ways, and that centuries of living with smart robots will undoubtedly lead to new uses.</p>\n]]>", "author": "Gabe Eisenstein", "published": "2016-06-02 23:12:04+00:00", "title": "By: Gabe Eisenstein"}, {"content": "<![CDATA[<p>I love the &#8220;Aaronson Oracle&#8221;.  It would be a bit spookier if there was an option to show the prediction so that we know it isn&#8217;t cheating.</p>\n]]>", "author": "Jair", "published": "2016-06-02 23:21:47+00:00", "title": "By: Jair"}, {"content": "<![CDATA[<p><i>So it\u2019s tempting just to say at this point\u2014as Bousso and Susskind do, in their \u201ccosmological/multiverse interpretation\u201d of quantum mechanics\u2014\u201cthe measurement has happened\u201d!</i></p>\n<p>Dirac is the earliest person to say something like this I believe,  at the 1927 Solvay Conference <a href=\"https://books.google.co.uk/books?id=UWwgAwAAQBAJ&lpg=PA166&ots=PGvZeA3gyO&dq=dirac%201927%20solvay%20conference%20nature%20does%20all%20the%20collapse&pg=PA166#v=onepage&q&f=false\" rel=\"nofollow\">here</a></p>\n<p><i>This view of the nature of the results of experiments fits in very well with the new quantum mechanics. According to quantum mechanics the state of the world at any time is describable by a wave function \u03c8, which normally varies according to a causal law, so that its initial value determines its value at any later time. It may however happen that at a certain time t_1 , \u03c8 can be expanded in the form \u03c8 = (sum over n) c_n * \u03c8_n , where the \u03c8_n \u2019s are wave functions of such a nature that they cannot interfere with one another at any time subsequent to t_1 . If such is the case, then the world at times later than t_1 will be described not by \u03c8 but by one of the \u03c8_n \u2019s. The particular \u03c8_n that it shall be <b>must be regarded as chosen by nature.</b> One may say that nature chooses which \u03c8_n it is to be, as the only information given by the theory is that the probability of any \u03c8_n being chosen is |c_n|^2 . The value of the suffix n that labels the particular \u03c8_n chosen may be the result of an experiment, and the result of an experiment must always be such a number. <b>It is a number describing an irrevocable choice of nature, which must affect the whole of the future course of events. </b></i></p>\n<p>A draft copy of the whole book free <a href=\"http://arxiv.org/abs/quant-ph/0609184\" rel=\"nofollow\">here</a></p>\n]]>", "author": "James Gallgher", "published": "2016-06-02 23:24:10+00:00", "title": "By: James Gallgher"}, {"content": "<![CDATA[<p>One other point about the argument being too strong: the concept of consciousness doesn\u2019t depend on some unconditional principle of continuity. Whether I am the same person as my baby self or Alzheimer\u2019s self or robot-upload self is very much open to interpretation. There is not a core fact that answers the question objectively.</p>\n]]>", "author": "Gabe Eisenstein", "published": "2016-06-02 23:25:59+00:00", "title": "By: Gabe Eisenstein"}, {"content": "<![CDATA[<p>Sandro #29,</p>\n<p>&#8220;The most well known conundrum of identity: how many car parts can you swap before it\u2019s really a new car? Does this even have a sensible answer? We too are constantly changing, and parts of us are being replaced like the car. Am I the \u201csame\u201d self I was a year ago? 10 years ago? Not really, either subjectively or objectively. At best, it seems I share many commonalities with my past self.&#8221;</p>\n<p>This is exactly right, but I think since self-identity depends upon sentience/consciousness the latter is still suitable as a topic for the framing of this discussion.  Still, I think the No Cloning part of Scott&#8217;s framework is indeed tied up with identity and to the degree that there can be consciousness without self-identity this might not be applicable.</p>\n<p>This car parts conundrum was in ancient times presented as the question of a whether a chariot can be found in its parts or is somehow separate from its parts.  The answer to the conundrum is to regard the question as having a false assumption.  That there is any such thing as a chariot that is in any sense real.  Chariot is a mere label imputed by a consciousness apprehending a functioning thing and in no way whatsoever can be considered real.</p>\n]]>", "author": "AdamT", "published": "2016-06-02 23:39:23+00:00", "title": "By: AdamT"}, {"content": "<![CDATA[<p>I lost an &#8216;a&#8221; in my name tag posted above. Maybe a rare cosmic ray flipped a bit on my, quite old laptop, or a rare quantum tunneling event occurred to remove the  &#8216;a&#8217; or, I just accidentally deleted it after a few beers. You decide</p>\n]]>", "author": "James Galla gher", "published": "2016-06-03 00:01:56+00:00", "title": "By: James Galla gher"}, {"content": "<![CDATA[<p>> &#8220;If you really thought humans had an algorithm, a computational procedure, for spitting out true mathematical statements, such an algorithm could never have arisen by natural selection&#8221;</p>\n<p>What a confusion of ideas! Why should our understanding of mathematics, specifically, be hard-coded by evolution? Like everything else we do, we do by learning from others or finding patterns. </p>\n<p>It *absolutely* makes sense that the meta-task of pattern finding *would* be hard-coded and selected into an evolved beast; mathematics is only the result of applying the procedure of &#8220;find patterns&#8221; to the topic of numbers and procedures.</p>\n<p>I was somewhat disappointed that the author&#8217;s rebuttal missed this point.</p>\n<p>(It&#8217;s also worth nothing that humans make false mathematical statements on a regular basis, so even if there *were* such an algorithm, it wouldn&#8217;t be giving better than probablistic results!)</p>\n]]>", "author": "Tim", "published": "2016-06-03 01:11:20+00:00", "title": "By: Tim"}, {"content": "<![CDATA[<p>Vadim #11: Thanks for the challenging questions!</p>\n<ul>1. Why do you expect an elegant mathematical answer to the question \u201cis it OK to murder X\u201d, any more than an elegant mathematical answer to the question \u201cwhat is the equation for the coastline of Africa\u201d? After all, our preferences seem to be a complex jumble of evolutionary accidents and not-murdering is just one of our preferences.</ul>\n<p>I don&#8217;t think the truth is obvious here.  On the one hand, if you&#8217;re a Dennett-style eliminativist, then there <i>might or might not</i> be reasonably-clear criteria that would match our considered intuitions about which entities it is or isn&#8217;t OK to &#8220;murder.&#8221;  Sometimes you can&#8217;t do any better than a complex jumble of preferences, and other times you can.  Even in that case, I&#8217;d say it&#8217;s at least worth putting various proposals on the table and critiquing them to see where they fail.  For even if a complex jumble is the best we can do, we&#8217;ll have a <i>better</i> complex jumble if we understand why the simple proposals don&#8217;t work.</p>\n<p>If, on the other hand, you think it &#8220;actually means something&#8221; to ask whether an entity has experiences or not, over and above all the behavioral facts, then the reason to hope for a simple criterion is the same reason as with any &#8220;ordinary&#8221; scientific question.  Namely, because that&#8217;s how science has always succeeded, by assuming that the truth is simple and then often turning out to be right.</p>\n<p>In either case, I&#8217;d say there&#8217;s no guarantee that any simple criterion will exist, but also no reason not to look (if not for a <i>perfect</i> criterion, at least for a reasonably simple one that does reasonably well).</p>\n<ul>2. Suppose that human brains indeed contain unique quantum information. Clearly it is also possible to construct objects that contain unique quantum information which have few other brain-like properties. Do you truly grant consciousness to all such objects? If not, if you claim your criterion to be necessary but insufficient, what are the other conditions? If you cannot state them but assume the existence of some unknown non-trivial conditions, what makes you think these extra-conditions will not be sufficient for consciousness without invoking quantum non-cloning?</ul>\n<p>I should have said this explicitly, but when I worry about whether an entity is conscious, my <i>starting assumption</i> is almost always that the entity exhibits some sort of intelligent behavior&#8212;i.e., either it passes the Turing test, or at least it passes the dolphin Turing test, or it&#8217;s unlike any living thing but can discover a proof of the Riemann hypothesis, or <i>something</i>.</p>\n<p>Penrose said in his talk that he ascribes a sort of &#8220;proto-consciousness&#8221; to any entity that can induce objective wavefunction reduction (e.g., his QG-sensitive microtubules), even if they don&#8217;t do anything intelligent by themselves.  Many other writers about consciousness, like David Chalmers and Rebecca Goldstein, have likewise flirted with <a href=\"https://en.wikipedia.org/wiki/Panpsychism\" rel=\"nofollow\">panpsychist</a> ideas.  Personally, I don&#8217;t reject those ideas, so much as I simply don&#8217;t care whether they&#8217;re true, or rather, I don&#8217;t know what I&#8217;d do differently if they were true!  By contrast, if I knew that a software emulation of my brain would or wouldn&#8217;t be conscious, it&#8217;s pretty obvious what I might do differently with that knowledge (e.g., in the future Robin Hanson talks about), so that&#8217;s why I care about the latter question.</p>\n<ul>3. You write that \u201cthis picture agrees with intuition that murder, for example, entails the destruction of something irreplaceable, unclonable, a unique locus of identity\u2014something that, once it\u2019s gone, can\u2019t be recovered even in principle\u201d Do you see any strong causal relation between things like the quantum non-cloning theorem and the presence of this intuition in our brain? It seems easy to imagine a universe in which physics doesn\u2019t allow \u201cquantum consciousness\u201d but intelligent entities evolve which have the same intuition for evolutionary reasons. If so, how can this intuition be evidence for the quantum consciousness hypothesis?</ul>\n<p>This is a variant of the favorite argument of the Dennett-style eliminativist: &#8220;even if consciousness didn&#8217;t exist, it&#8217;s plausible that unconscious apes governed by the laws of physics would evolve to pontificate about their own consciousnesses exactly as they do now.  So, whatever grounds you can articulate for consciousness existing, how could they possibly be persuasive, since you&#8217;d be saying exactly the same things in zombie-world&#8212;and hence your stated reasons can&#8217;t have any logical connection to whatever is the <i>real</i> reason for consciousness to exist, supposing it does exist?&#8221;</p>\n<p>In some sense, this is an unfair argument.  E.g., a believer in consciousness could always turn the tables, and say to the eliminativist: &#8220;even if consciousness <i>were</i> a fundamental feature of the world, it&#8217;s still plausible that you&#8217;d be giving all the same arguments that it wasn&#8217;t, so how can your arguments possibly be persuasive?&#8221;</p>\n<p>Even so, I admit that this is one of the most perplexing aspects of the whole subject.  I.e., to whatever extent you can give an ordinary causal story for why someone expressed certain views about consciousness, to that extent, the <i>actual truth or falsehood</i> of their views would seem to have no ability to influence what they said!</p>\n<p>Still, one could look at it this way: all our views about personal identity, free will, consciousness, psychophysical parallelism, etc. seem to require that our minds can&#8217;t be freely copied, predicted, and rewound like computer code.  This presents a puzzle for ~250 years, since nothing in the laws of physics seems able to offer any such guarantee.  Then, in the 1920s, in the biggest revolution since Galileo and Newton, physics gets rewritten in a way that could very plausibly provide <i>exactly</i> such unclonability.  It &#8220;didn&#8217;t have to&#8221; turn out that way, but it did.</p>\n<p>To me, it would be absurd <i>not</i> to ask whether the things fit together, as has happened so often in the history of ideas.  E.g., maybe evolution can happen in all sorts of universes, with and without unclonability, but only in the unclonability ones is there &#8220;anyone there to notice&#8221;?  The truth is, we have no idea why we find ourselves in a world with one set of physical laws rather than another (besides some relatively-uninteresting anthropic constraints), and that strikes me as one the biggest questions there is.</p>\n<p>In summary, you&#8217;re right that &#8220;we seem to need X to reason sensibly about indexical questions&#8221; and &#8220;amazingly, improbably, our universe provides X&#8221; might be totally disconnected facts.  But until the matter gets resolved, whether they are or aren&#8217;t disconnected seems like it will remain an obvious question that people ask.</p>\n<ul>4. What type of argument can plausibly convince you the quantum consciousness theory is wrong?</ul>\n<p>Plenty of things.  If physicists find that the cosmological constant isn&#8217;t actually constant and will become negative, or for some other reason, there&#8217;s a fully unitary description of our causal patch (e.g., our deSitter horizon radiates back information just like black hole horizons are thought to do), then the picture I outlined is wrong.  If the brain has a &#8220;clean digital abstraction layer&#8221; that captures everything cognitively relevant, and that notices the lower-level stuff purely as thermal noise, then the picture is wrong.  If the sorts of experiments that (e.g.) Libet and Soon et al. do&#8212;the ones that use EEGs and fMRIs to try to predict human decisions&#8212;ever achieve truly <i>impressive</i> accuracy (like, better than the Aaronson Oracle!), then the picture is rendered increasingly irrelevant.  There are a few other things, e.g. involving &#8220;past macroscopic determinants&#8221; of the quantum states occurring in nature.  For more, see Section 9 of <a href=\"http://www.scottaaronson.com/papers/giqtm3.pdf\" rel=\"nofollow\">GIQTM</a> (&#8220;Is the Freebit Picture Falsifiable?&#8221;).</p>\n]]>", "author": "Scott", "published": "2016-06-03 01:30:45+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>A bit of a side point, but I feel like the kind of hand-waving, traditional-philosophical style Ethics is a bit pointless now that we have things like game theory to make social-signaling-and-bargaining-and-implicit-threatening (aka morality) much more precise. But even most intellectuals can&#8217;t pause their signalling long enough to realize this.</p>\n]]>", "author": "ShardPhoenix", "published": "2016-06-03 03:11:21+00:00", "title": "By: ShardPhoenix"}, {"content": "<![CDATA[<p>ShardPhoenix #40:</p>\n<ul>But even most intellectuals can\u2019t pause their signalling long enough to realize this.</ul>\n<p>That sentence was a fine way for you to signal how far you are above most intellectuals! \ud83d\ude09</p>\n]]>", "author": "Scott", "published": "2016-06-03 03:15:55+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>James #34: Thanks for the lovely Dirac passage!  For me, the contrast is striking: where Bohr and Heisenberg can come across as ponderous and dated, Dirac, in 1927 (with &#8220;the ink barely dry&#8221; on quantum mechanics itself), is already talking about it <i>exactly</i> the same way we&#8217;d talk about it today, just a little more eloquently.</p>\n]]>", "author": "Scott", "published": "2016-06-03 03:21:17+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Following up #40, the reason why this is so hard to get people to even talk about is probably because being clearly (first-order) irrationally committed to your moral principles (etc) can be a (higher order) successful strategy in the game of evolution. So we&#8217;ve pretty much evolved to not be unable (or at least unwilling) to understand what morality actually is from an objective perspective. I guess that makes me a mutant.</p>\n]]>", "author": "ShardPhoenix", "published": "2016-06-03 03:15:59+00:00", "title": "By: ShardPhoenix"}, {"content": "<![CDATA[<p>>That sentence was a fine way to signal how far you are above most intellectuals! \ud83d\ude09</p>\n<p>Yes, this is indeed a problem when trying to talk about signalling objectively &#8211; if you&#8217;re writing for other humans, you&#8217;re signalling on *some* level. Nonetheless I think signalling is real, important, and can cause problems when the &#8220;circle-jerk&#8221; (is there a concise polite term for this?) drifts too far from reality.</p>\n]]>", "author": "ShardPhoenix", "published": "2016-06-03 03:17:51+00:00", "title": "By: ShardPhoenix"}, {"content": "<![CDATA[<p>I always liked this thought experiment: &#8220;Could we teleport you to Mars by \u201cfaxing\u201d you: that is, by putting you into a scanner that converts your brain state into pure information, then having a machine on Mars reconstitute the information into a new physical body?&#8221;</p>\n<p>You can also consider doing different things to a sleeping person: move them to a different room, disassemble their body and recreate it in the different room with the same atoms, or build a new body in the room with different atoms. Since fundamental particles are indistinguishable, it shoudn&#8217;t make any difference.</p>\n<p>My expectation is that a teleported copy on Mars would indeed be conscious and would believe that it was a continuation of my previous Earth self, which of course would also remain conscious assuming a non-destructive copy. Consciousness is a mysterious thing, but it exists in a physical universe and is somehow a product of those physical processes taking place in the brain.</p>\n<p>I also believe that consciousness is somewhat ephemeral, being created and destroyed as a side-effect of underlying processes, e.g., destroyed when you sleep, but a new consciousness created when you wake up. It&#8217;s not a physical thing that has continuity over time.</p>\n]]>", "author": "incompatible", "published": "2016-06-03 03:33:27+00:00", "title": "By: incompatible"}, {"content": "<![CDATA[<p>ShardPhoenix #43: Whenever I read Robin Hanson&#8217;s <a href=\"http://www.overcomingbias.com/\" rel=\"nofollow\">Overcoming Bias</a> blog, I get depressed, because every day he&#8217;s analyzing how yet another facet of the human experience is really just a status-signalling game, and of course he&#8217;s almost always onto something.  But then isn&#8217;t his blog itself just more status-signalling?  If he&#8217;s right, then what&#8217;s the point of even discussing it?</p>\n<p>The only solution I&#8217;ve found is to spend time in fields&#8212;theoretical computer science being an example&#8212;where status-signalling is correlated with <i>actually doing good work.</i>  I.e., no matter where you go, or how ironic or self-conscious you are about it, you can never escape the reality that when people (especially intellectuals) say X, part of what they mean to convey is &#8220;look at how smart/original/in-the-know/etc. I am to say X.&#8221;  But what you <i>can</i> do, and what&#8217;s <i>worth</i> doing, is to join, build, and maintain epistemic communities where &#8220;look at how smart I am to say X&#8221; works the best when X is original and important and true.</p>\n]]>", "author": "Scott", "published": "2016-06-03 03:58:32+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>I continue to be puzzled that nobody seems to call Penrose on his use of the term &#8220;non-computational&#8221;.  Isn&#8217;t it generally accepted that computers run because of physical laws, and not vice versa.  The handful of transistors that implement a NAND gate are at some level not made of software, and even stronger the quantum devices that implement a CNOT cannot be properly emulated by a pure Turing Machine, one without at least a non-computational hardware random number generator.  Only if you believe that you&#8217;re a brain-in-a-box simulation and it&#8217;s &#8220;simulations all the way down&#8221; should &#8220;non-computational&#8221; mean anything astonishing.</p>\n<p>But it&#8217;s obvious that Penrose has a compelling mental that certain mathematical facts are clearly and incontrovertibly true, and are true just as certainly as most of us believe that 2+2=4, and as certainly as many of us believe that the Peano Axioms are self-consistent.  However, for Roger, those perceptions go beyond Godel-provable facts.  The real question is whether we can imagine what&#8217;s going on in Roger&#8217;s brain that leads him to these perceptions.</p>\n<p>One thing that I can imagine as a left-hander who&#8217;s studied the neurophysiology of handedness a bit, is that Roger&#8217;s brain has multiple cortical regions, say in its left and right hemispheres (it&#8217;s much more complicated than this) that are connected by what amounts to a hardware Fourier transform network or some other convolutional network.  It is very difficult for the mental processes in one hemisphere to compute in software what the other hemisphere computes in hardware, so that results from one hemisphere are easily viewed as a nondeterministic oracle by the other, with corresponding mysterious powers.  Mathematics in the frequency domain of mathematical structures can yield all kinds of remarkable results &#8212; a small example is the way that Fourier transform pops up in unexpected places of classic number theory.</p>\n<p>When Roger&#8217;s verbal, sequential, symbol processing &#8220;left hemisphere&#8221; receives thoughts from his parallel, subsymbolic, geometric &#8220;right hemisphere&#8221;, his LH mind is very likely to interpret them as oracular Platonic truths that must come from some supra-Turing capability.  Backing those oracular thoughts into a gravitized QM framework would be natural for someone working in his field of study.</p>\n<p>[Minds that arise from brain operations in convolutional networks, by the way, pose bad prospects for bottom-up brain simulation, because the neuropil of fibers connecting neurons can be seen as equivalent to the permutation matrices of cryptographic functions.  Is this convolution actually the case?  Studying the possibility is difficult and unpopular, and impossible to rule out via current diffusion-tensor MRI and serial electron microscopic techniques that are getting billions of dollars of funding.]</p>\n]]>", "author": "GMcK", "published": "2016-06-03 05:38:45+00:00", "title": "By: GMcK"}, {"content": "<![CDATA[<p>Scott #46: I agree with what you say here (though intentionally designing such systems is not easy), but I still find the concept of ethics/morality as typically understood to be too vague to be useful in a intellectual/academic context (as opposed to when you&#8217;re trying to stir people to immediate action). In a theoretical context I think it&#8217;s clearer to talk in terms of game-theoretical decisions by actors with various preferences, etc.</p>\n]]>", "author": "ShardPhoenix", "published": "2016-06-03 05:59:42+00:00", "title": "By: ShardPhoenix"}, {"content": "<![CDATA[<p>>&#8221;I should mention that the idea of a \u201cpseudorandom pattern\u201d in quantum measurement outcomes is already ruled out by the (now loophole-free) Bell inequality violation experiments\u2014unless you also want to posit a faster-than-light conspiracy to coordinate faraway pseudorandom outcomes with one another.&#8221;</p>\n<p>I would like to know where this idea of a conspiracy with faster than light signals comes from, and why in the quote regarding superdeterminism Bell gave didn&#8217;t mention it explicitly and clearly like so, he merely says we just have to suppose we lack free will, aka determinism applies to the experimenter, which is a reality and no faster than light signal is required.</p>\n<p>Superdeterminism is merely determinism without a magical experimenter imbued with a soul and possessing free will thus escaping from the determinism we would consider applies to the rest of the world if we invoked a deterministic worldview.   Thus superdeterminism is merely determinism in other words, as there is no reason to suppose the experimenter escapes determinism if determinism were taken to be true.</p>\n<p>>&#8221;There is a way to escape the inference of superluminal speeds and spooky action at a distance. But it involves absolute determinism in the universe, the complete absence of free will. Suppose the world is super-deterministic, with not just inanimate nature running on behind-the-scenes clockwork, but with our behavior, including our belief that we are free to choose to do one experiment rather than another, absolutely predetermined, including the &#8220;decision&#8221; by the experimenter to carry out one set of measurements rather than another, the difficulty disappears. There is no need for a faster than light signal to tell particle A what measurement has been carried out on particle B, because the universe, including particle A, already &#8220;knows&#8221; what that measurement, and its outcome, will be.&#8221;-Bell</p>\n]]>", "author": "Darien S", "published": "2016-06-03 06:30:30+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>One of the things I find strange about associating identity with as-of-yet-unmeasured quantum information is that the information by definition hasn&#8217;t affected your behavior throughout your entire life yet. There&#8217;s zero correlation between a sourced-from-the-initial-state qubit and everything I&#8217;ve ever thought or done. Which seems like not the correct amount of correlation if I&#8217;m going to call that qubit part of my identity.</p>\n<p>Secretly swap &#8220;my&#8221; sourced-from-the-initial-state qubits with &#8220;your&#8221; sourced-from-the-initial-state qubits, and no one&#8217;d ever be able to tell. So in what sense were they &#8220;me&#8221; and &#8220;you&#8221;, instead of just a source of entropy?</p>\n]]>", "author": "Craig Gidney", "published": "2016-06-03 07:13:06+00:00", "title": "By: Craig Gidney"}, {"content": "<![CDATA[<p>Scott, </p>\n<p>I like the connection you make between free will and the possibility of coying brains, but I didn&#8217;t get the connection with consciousness. Why has consciousness anything to do with the possibility or impossibility of brain cloning?<br />\nThanks for the very interesting post.</p>\n]]>", "author": "Pascal", "published": "2016-06-03 07:33:11+00:00", "title": "By: Pascal"}, {"content": "<![CDATA[<p>Scott #20: This is not only about &#8220;knowing initial condition perfectly&#8221;. Also infinite precision arithmetic and perfect measurement of any and all external influences.</p>\n]]>", "author": "JuroV", "published": "2016-06-03 09:44:34+00:00", "title": "By: JuroV"}, {"content": "<![CDATA[<p>I&#8217;ve thought of a good argument you could have used that might have actually convinced old Penrose, Scott.</p>\n<p>What I would have done is simply pointed out that in his (Penrose&#8217;s) own field of physics, no one seriously suggests that perfect certainty can be achieved.  What happens is a combination of theory and empirical data, from which inferences to the best explanation (abduction) and generalizations (induction) are made.  Simply ask Penrose: why should math should be any different to physics in this regard?   Why not just accept that math is combination of a priori AND empirical-type (numerical) investigation/guesswork &#8211;  once you can see that an uncertain (empirical) element gets slipped in, then the Godelian argument quickly collapses.</p>\n<p>As to your own ideas about consciousness, very interesting indeed, very clever!   I like the idea of trying to establish a connection to the wider environment (boundary condition), and you do sort of have the same idea I did of transmission of information between different levels of abstraction (link between micro- and macro- worlds)!  I&#8217;m not really buying the specifics of it though \ud83d\ude09</p>\n<p>As I said in the other thread, I think free will is preserved even with duplicate copies of you predicting what you&#8217;d do next IF AND ONLY IF the software doing the prediction is NECCESSERILY conscious.   That is to say, there must be no computational short-cut where someone can create an unconscious simulation of you.  In that case, I agree, free-will would be empirically falsified.    In the case of CONSCIOUS software that is predicting your actions, well, I don&#8217;t see that as falsifying free will, because there is still an actual instantiation of a person there (namely, you).</p>\n<p>The teleportation thing is definitely rather puzzling.  What we really need is a proper scientific theory of consciousness that is generally accepted as correct.  I think once we actually have that, these mysteries will be greatly clarified.  The problem is that philosophy by itself can&#8217;t really resolve anything, it can only chart the various possibilities and give an indication of what general direction to go in.  Clear specific answers really need science.<br />\nThe Hansonian/Yudkowskian answers to the teleportation/copying puzzles have a better than even chance of being correct.  (May be even in 70% + range of confidence).  But these are philosophical &#8216;plausibility&#8217; arguments, and that level of certainty is nowhere near high enough for me to be comfortable risking my life getting &#8216;uploaded&#8217; or stepping into one of those &#8216;teleporters&#8217; \ud83d\ude09</p>\n<p>Lets wait for a proper scientific theory of consciousness and see what it has to say.  I think that once we do have a proper scientific theory, these puzzles will be cleared up quite quickly.</p>\n]]>", "author": "mjgeddes", "published": "2016-06-03 09:57:24+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>It&#8217;s possible this is addressed above, I&#8217;ve only skimmed through the comments, but: Both here and in your quora answer you seem to suggest that anyone disagreeing with the computationalist framework that doesn&#8217;t present an alternative, at least to the level of a plausible scheme for deciding what is or is not conscious, isn&#8217;t doing their job (and that Penrose is remarkable here because he actually tries to answer that question). But even if you set aside the IMO reasonable objection that you don&#8217;t need to know a right answer in order to reject a wrong one, this privileges computationalism significantly, as in general computationalists can&#8217;t answer that question either! Unless they&#8217;re integrated information theorists, but them I&#8217;d point to this great blog post by Scott Aaronson a while back about their theory.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levy:Shea.html\">Shea Levy</a>", "published": "2016-06-03 10:09:10+00:00", "title": "By: Shea Levy"}, {"content": "<![CDATA[<p>There is a simple argument in favor of Penrose&#8217;s &#8220;gravitized quantum mechanics&#8221;: </p>\n<p>The wavelength of macroscopic objects is typically much smaller than the Planck length, so it is natural to switch from a quantum description to a classical description.<br />\nAnd if one thinks that the Copenhagen reduction of the wavefunction is associated with the switch from objective (wavefunction) to subjective (conscious observation) then it is natural to conclude that &#8220;gravitized quantum mechanics&#8221; has something to do with consciousness.</p>\n<p>This is Penrose&#8217;s argument in a nutshell as I understand it and it is hard to argue with as long as we do not have a full understanding of quantum gravity.</p>\n]]>", "author": "wolfgang", "published": "2016-06-03 11:09:23+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Hi Scott, </p>\n<p>Awesome blog and awesome article. I have put in a request to reincarnation central to come back as a small section of your frontal lobe, but I&#8217;m not holding out much hope. </p>\n<p>I loved all your arguments, and the engaging way you present them, but (you knew there was going to be a but) I would like to take issue with your comment that the burden to show what it is that might make the brain &#8220;relevantly different from a digital computer&#8221; is on the &#8220;brains are different&#8221; team.</p>\n<p>I dont see it this way. The issue is that no-one has come up with any explanation of what consciousness actually is, or how it could possibly emerge from the interaction of a set of Standard model particles. What actually is the &#8220;movie in my head&#8221;, or the &#8220;redness of red&#8221;, and how do I experience things such as love? It seems to me that if we dont even have a clue how to answer these questions about what human consciousness is then we would do well to be humble when proposing that &#8220;Of course, this property (we completely don&#8217;t understand) will be shared by a silicon-based model of our brains&#8221;. </p>\n<p>So, my contention would be that the onus is on the AI world to show that this thing we completely don&#8217;t understand will also be shared by a cool future AI-bot. If this can&#8217;t be shown then let us rather take a more humble approach, and admit that we are really in the dark as to what this whole consciousness thing is and so maybe we are in the dark about whether the ultimate AI will share it.</p>\n<p>Thoughts?</p>\n]]>", "author": "Philip Calcott", "published": "2016-06-03 11:26:54+00:00", "title": "By: Philip Calcott"}, {"content": "<![CDATA[<p>ShardPhoenix:<br />\n> <i> A bit of a side point, but I feel like the kind of hand-waving, traditional-philosophical style Ethics is a bit pointless now that we have things like game theory to make social-signaling-and-bargaining-and-implicit-threatening (aka morality) much more precise.</i></p>\n<p>Simply declaring that &#8220;morality&#8221; is a pretty big leap. At best, you can claim that it might explain ethics-seeking behaviour, but that&#8217;s not the same as it <i>being</i> ethics. Analogously, you might use some psychological theory to explain particle-seeking behaviour to explain physicists&#8217; obsessive desire to build particle accelerators, but it would be quite an astonishing leap to then claim that said theory therefore <i>is</i> particle physics.</p>\n<p>> <i>I agree with what you say here (though intentionally designing such systems is not easy), but I still find the concept of ethics/morality as typically understood to be too vague to be useful in a intellectual/academic context (as opposed to when you\u2019re trying to stir people to immediate action).</i></p>\n<p>Of course it&#8217;s vague, morality in philosophy is still literally undefined, with significant debate over what classify as moral questions, and whether moral questions even have truth value at all!</p>\n<p>This debate probably won&#8217;t generally interest science-minded people, because a moral fact, if it exists, probably wouldn&#8217;t explain natural facts any better than a natural fact would. But they&#8217;re not intended to! Natural facts explain other natural facts, and moral facts, if they exist, would explain other moral facts.</p>\n<p>And if natural facts don&#8217;t exist, then morality might simply be evolutionary game theory ethics. But <a href=\"https://www.reddit.com/r/philosophy/comments/3etl9b/a_proof_of_the_objectivity_of_morals_bambrough/\" rel=\"nofollow\">many have argued convincingly</a>, IMO, that moral facts exist.</p>\n]]>", "author": "Sandro", "published": "2016-06-03 12:18:11+00:00", "title": "By: Sandro"}, {"content": "<![CDATA[<p>Darien S #49: In my view, what&#8217;s whimsically called the &#8220;free will loophole&#8221; in the Bell experiment has essentially nothing to do with free will in the human sense.  It&#8217;s an unfortunate choice of term.  (And I&#8217;m not concerned here with how Bell put things in his original papers; that&#8217;s a history-of-science question, whereas I&#8217;m talking about what&#8217;s true.)</p>\n<p>I think the issue is the same if, instead of Alice and Bob using their free will (or &#8220;free will&#8221;) to choose the measurement settings, we used computers with access to random number sources, as actually happens in Bell experiments.  There, again, the trouble is that no matter how the random numbers were chosen, no matter how unrelated (and spatially distant) Alice&#8217;s and Bob&#8217;s randomness-generation procedures were from each other, no matter how unrelated they both were from the &#8220;entangled&#8221;-but-not-really-entangled particles, if you believe in superdeterminism then you believe the procedures always had to conspire across the universe to generate challenges that for some unexplained reason were easy enough for the particles to pass.</p>\n<p>So <b>let&#8217;s leave Alice and Bob out of this!</b>  For two separated mechanical random-number generators to conspire in such a way is a thousand times crazier and more nonlocal than anything in quantum mechanics, which is the theory that we were trying to &#8220;tame&#8221; in the first place.</p>\n<p>One can be more technical about it: with quantum mechanics, there&#8217;s a clear, precise explanation for why you can do <i>only this and no more</i>&#8212;for instance, why you can win the CHSH game with 85% probability, but you can&#8217;t send faster-than-light signals, or for that matter, even win the CHSH game with 86% probability.  With superdeterminism, by contrast, this is completely unexplained.  You posit correlations that <i>would</i> let superluminal signals appear to be sent, the CHSH game appear to be won with certainty, etc. etc., and then you just declare by fiat that they only let you win CHSH 85% of the time, because you cribbed that correct answer from quantum mechanics, the theory you were trying to replace.</p>\n<p>In summary, superdeterminism is a miserable failure as a scientific explanation, for reasons having nothing to do with free will.</p>\n]]>", "author": "Scott", "published": "2016-06-03 13:05:30+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>mjgeddes #53:</p>\n<ul>I\u2019ve thought of a good argument you could have used that might have actually convinced old Penrose, Scott.</p>\n<p>What I would have done is simply pointed out that in his (Penrose\u2019s) own field of physics, no one seriously suggests that perfect certainty can be achieved.</ul>\n<p>Return to Go, do not collect $200. \ud83d\ude42  Roger Penrose is a mathematician, one whose main interest is mathematical physics.  He&#8217;s the Emeritus Rouse Ball Professor of <i>Mathematics</i> at Oxford.  His degrees are also in math (or sorry, maths).  Penrose is also probably the best-known living exponent of mathematical Platonism.</p>\n]]>", "author": "Scott", "published": "2016-06-03 13:15:34+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>JuroV #52:</p>\n<ul>This is not only about \u201cknowing initial condition perfectly\u201d. Also infinite precision arithmetic and perfect measurement of any and all external influences.</ul>\n<p>OK, let&#8217;s subsume the initial conditions and any external influences into &#8220;knowing the boundary conditions perfectly,&#8221; which we both agree is a central issue.</p>\n<p>If we know the boundary conditions, then infinite-precision arithmetic is <i>not</i> additionally required, if we assume the physical Hilbert space is finite-dimensional, as Bekenstein tells us it has to be.  That was the main point of my comment.</p>\n]]>", "author": "Scott", "published": "2016-06-03 13:19:46+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Shea Levy #54 and Philip Calcott #56: You both take issue with my contention that the burden is on the anti-AI camp to articulate a criterion that separates the brain from a digital computer.  As Philip put it:</p>\n<ul>So, my contention would be that the onus is on the AI world to show that this thing we completely don\u2019t understand will also be shared by a cool future AI-bot. If this can\u2019t be shown then let us rather take a more humble approach&#8230;</ul>\n<p>Consider the following fictional scenario: European explorers encounter Native Americans for the first time.  The explorers say: wow, these people have language, agriculture, complex social structure, all the same sorts of things we have, modulo unimportant details.  They&#8217;re probably also <i>conscious</i> like we are!  But then the ship&#8217;s philosopher-in-residence responds:</p>\n<ul>No, you see, we don&#8217;t understand consciousness at all.  Therefore, if someone claims that native people are conscious as Europeans are, the onus is that person to <i>prove</i> their claim.  If this can\u2019t be shown then let us rather take a more humble approach&#8230;</ul>\n<p>In this case, I hope the problem is obvious: what masquerades as humility is actually extreme arrogance, because it imposes an <a href=\"http://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/\" rel=\"nofollow\">isolated demand for rigor</a>.  Why does consciousness need to be proven only in the case of the natives?  Why is its presence assumed without argument for the Europeans?</p>\n<p>The strong-AI position doesn&#8217;t face the same burden, because it&#8217;s maximally simple and also maximally generous: <i>anything</i> that exhibits intelligent behavior is assumed to be associated with consciousness.  No entity needs to prove its consciousness, beyond what we already do in everyday life that leads us to regard each other as conscious.  Or as Turing put it in &#8220;Computing Machinery and Intelligence&#8221;:</p>\n<ul>A is liable to believe &#8220;A thinks but B does not&#8221; whilst B believes &#8220;B thinks but A does not.&#8221;  Instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.</ul>\n]]>", "author": "Scott", "published": "2016-06-03 14:27:54+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Human PI: &#8220;Can you write a sonnet?&#8221;<br />\nRobot: &#8220;Can you?&#8221;</p>\n<p>I agree with a couple of commenters (such as what I take to be the gist of <b>tzm</b> and <b>Gabe Eisenstein</b>) that many of the philosophical arguments about consciousness &#8220;try too hard&#8221;.</p>\n<p>For the most part, we humans do not contemplate the consistency of formal systems (and when we do, we don&#8217;t necessarily find the same conclusions), do not exhibit creativity or intelligence in most of our daily doings, and are fairly predictable in our behavior.</p>\n<p>But despite all that, and despite whatever teenage edge-lords might claim, a standard of morality where it is ok to kill most people because they are &#8216;mindless sheep[le]&#8217; has not gained wide-spread open acceptance. (It may be okay to kill THEM sheep, but US sheep are sacrosanct.) </p>\n<p>If consciousness is to be interpreted as &#8216;whatever that X-factor is for which people need a word like \u201cconsciousness\u201d in moral deliberations&#8217;, the bar is much lower than many intellectually interesting properties.</p>\n<p>And to my intuition, &#8220;non-copyability&#8221; is trying too hard also.</p>\n<p>irt. <b>Scott</b>: &#8220;Still, one could look at it this way: all our views about personal identity, free will, consciousness, psychophysical parallelism, etc. seem to require that our minds can\u2019t be freely copied, predicted, and rewound like computer code.&#8221;</p>\n<p>Speak for yourself \ud83d\ude09</p>\n<p>The problem with appeals to intuition though is that they don&#8217;t necessarily cross-over. The things you see as strange if minds can be copied don&#8217;t seem strange to me. There&#8217;s not much difference between blackmailing an AI by threatening to torture 1000 exact copies of itself, or 1000 near-copies that would operate mostly the same for significant amounts of time (and why shouldn&#8217;t such near-perfect copies be possible for the human brain, QM be damned?), or 1000 other random people the torturer happened to round up. </p>\n<p>One reason is because I don&#8217;t buy the &#8220;you should consider it likely to be one of those 1000 copies&#8221;. I&#8217;d like some specifics on how the copies are made, because I suspect if the process is such that the original AI has any doubts about being in the torture group at the end, then the process presupposes a kidnapping before it starts. No cloning necessary, and just as applicable to non-copyable minds.</p>\n<p>To explain that a bit, see the &#8220;fax a copy of me to Mars&#8221; example. My brain is on Earth at the beginning of the process, stays on Earth throughout, and I have no reason to suspect my consciousness is suddenly going to jump or split. I&#8217;ll still feel as if I&#8217;m on Earth (regardless of whether a more or less similar individual now runs around on Mars). Conversely, if the me on Earth is destroyed in the copying, then I&#8217;m gone, however similar the Mars one is.</p>\n<p>In other words, same intuition as behind passing fire around. I can have a fire here, and build a microscopically accurate copy over there; or I can take a flaming torch and use it to ignite another. In both cases I find it easy to say the original fire is still around. Or I can have a burning glass of oil, pour it into a large puddle, from which I then collect 1000 glasses of burning oil; in this case, I find it intuitive to say the original flame is gone and replaced by its copies.</p>\n<p>Maybe this is the wrong intuition. But as long as we&#8217;re talking what&#8217;s intuitive/weird not what&#8217;s accurate in the universe &#8230; \ud83d\ude1b</p>\n<p>Cheers.</p>\n]]>", "author": "BLANDCorporatio", "published": "2016-06-03 15:32:21+00:00", "title": "By: BLANDCorporatio"}, {"content": "<![CDATA[<p>@BLANDCorporatio</p>\n<p>>> a standard of morality where it is ok to kill most people because they are \u2018mindless sheep&#8217; &#8230;</p>\n<p>I would use a very simple utility function and argue that anybody and anything smart enough or unique enough should not be killed or destroyed, whether there is consciousness or not involved, for purely selfish reasons.</p>\n<p>A robot smart enough to solve the riddles of quantum gravity should not be turned off whether she is conscious or not, for the simple reason that we want to know her answers.</p>\n<p>And an antique temple should not be destroyed because its unique history provides long term aesthetic pleasure to us, even if a hotel at the same place might generate more cash in the short term; but of course the temple is not conscious.</p>\n]]>", "author": "wolfgang", "published": "2016-06-03 16:10:53+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Following Elon Musk&#8217;s claim, and you being among the Singularity crowd, what do you think is the probability of us living in a simulation?<br />\nDo you think that living in a simulation would probably entail something along the lines of a Extended Church Thesis (<a href=\"http://cstheory.stackexchange.com/questions/7528/extended-church-turing-thesis/7553#7553\" rel=\"nofollow\">the original one is mostly bust</a>)?</p>\n]]>", "author": "Flavio Botelho", "published": "2016-06-03 16:15:38+00:00", "title": "By: Flavio Botelho"}, {"content": "<![CDATA[<p>Flavio #64: I think the probability that <i>we&#8217;ll get convincing empirical evidence</i> that we&#8217;re living in a computer simulation is close to zero (and I&#8217;d be willing to bet on that, if Dana still let me bet on such things).</p>\n<p>If, on the other hand, it&#8217;s the kind of simulation that&#8217;s so perfect that we can never get evidence that it <i>is</i> a simulation, even in principle, then I regard the question as too ill-defined even to assign a probability.  (We might as well debate &#8220;the probability that the Greek goddess Gaea created other universes besides this one.&#8221;)</p>\n<p>See also my <a href=\"http://blogs.scientificamerican.com/cross-check/scott-aaronson-answers-every-ridiculously-big-question-i-throw-at-him/\" rel=\"nofollow\">answer to John Horgan&#8217;s related question</a> (scroll down to question #9).</p>\n]]>", "author": "Scott", "published": "2016-06-03 16:30:13+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Hi! I believe de Sitter space is the one with the positive curvature, and is spatially finite and has a bounded maximum entropy; anti-de Sitter space is the hyperbolic one that is spatially infinite and has unbounded maximum entropy. (The AdS boundary is at infinity.)</p>\n<p>I&#8217;m not an expert by any means, but I&#8217;ve been checking some references and I&#8217;m pretty sure that is how it goes. For example, &#8220;Disturbing Implications of a Cosmological Constant,&#8221; 2002, Lisa Dyson, Matthew Kleban, and Leonard Susskind.</p>\n<p>So if we live in a positively curved de Sitter space, there is a bound on the maximal entropy and we are not conscious in this sense. But also, I thought the latest evidence was that we live in a flat universe within experimental error, with the absolute value of \u03a9_K being less than 0.005. (&#8220;Planck 2015 results. XIII. Cosmological parameters,&#8221; 2015, P. A. R. Ade, N. Aghanim, M. Arnaud, M. Ashdown, J. Aumont, C. Baccigalupi, A. J. Banday, R. B. Barreiro, J. G. Bartlett, N. Bartolo, E. Battaner, R. Battye, K. Benabed, A. Benoit, A. Benoit-Levy, J.-P. Bernard, M. Bersanelli, P. Bielewicz, A. Bonaldi, L. Bonavera, J. R. Bond, J. Borrill, F. R. Bouchet, F. Boulanger, M. Bucher, C. Burigana, R. C. Butler, E. Calabrese, J.-F. Cardoso, A. Catalano, A. Challinor, A. Chamballu, R.-R. Chary, H. C. Chiang, J. Chluba, P. R. Christensen, S. Church, D. L. Clements, S. Colombi, L. P. L. Colombo, C. Combet, A. Coulais, B. P. Crill, A. Curto, F. Cuttaia, L. Danese, R. D. Davies, R. J. Davis, P. de Bernardis, A. de Rosa, G. de Zotti, J. Delabrouille, F.-X. Desert, E. Di Valentino, C. Dickinson, J. M. Diego, K. Dolag, H. Dole, S. Donzelli, O. Dore, M. Douspis, A. Ducout, J. Dunkley, X. Dupac, G. Efstathiou, F. Elsner, T. A. Ensslin, H. K. Eriksen, M. Farhang, J. Fergusson, F. Finelli, O. Forni, M. Frailis, A. A. Fraisse, E. Franceschi, A. Frejsel, S. Galeotta, S. Galli, K. Ganga, C. Gauthier, M. Gerbino, T. Ghosh, M. Giard, Y. Giraud-Heraud, E. Giusarma, E. Gjerlow, J. Gonzalez-Nuevo, K. M. Gorski, S. Gratton, A. Gregorio, A. Gruppuso, J. E. Gudmundsson, J. Hamann, F. K. Hansen, D. Hanson, D. L. Harrison, G. Helou, S. Henrot-Versille, C. Hernandez-Monteagudo, D. Herranz, S. R. Hildebrandt, E. Hivon, M. Hobson, W. A. Holmes, A. Hornstrup, W. Hovest, Z. Huang, K. M. Huffenberger, G. Hurier, A. H. Jaffe, T. R. Jaffe, W. C. Jones, M. Juvela, E. Keihanen, R. Keskitalo, T. S. Kisner, R. Kneissl, J. Knoche, L. Knox, M. Kunz, H. Kurki-Suonio, G. Lagache, A. Lahteenmaki, J.-M. Lamarre, A. Lasenby, M. Lattanzi, C. R. Lawrence, J. P. Leahy, R. Leonardi, J. Lesgourgues, F. Levrier, A. Lewis, M. Liguori, P. B. Lilje, M. Linden-Vornle, M. Lopez-Caniego, P. M. Lubin, J. F. Macias-Perez, G. Maggio, D. Maino, N. Mandolesi, A. Mangilli, A. Marchini, P. G. Martin, M. Martinelli, E. Martinez-Gonzalez, S. Masi, S. Matarrese, P. Mazzotta, P. McGehee, P. R. Meinhold, A. Melchiorri, J.-B. Melin, L. Mendes, A. Mennella, M. Migliaccio, M. Millea, S. Mitra, M.-A. Miville-Deschenes, A. Moneti, L. Montier, G. Morgante, D. Mortlock, A. Moss, D. Munshi, J. A. Murphy, P. Naselsky, F. Nati, P. Natoli, C. B. Netterfield, H. U. Norgaard-Nielsen, F. Noviello, D. Novikov, I. Novikov, C. A. Oxborrow, F. Paci, L. Pagano, F. Pajot, R. Paladini, D. Paoletti, B. Partridge, F. Pasian, G. Patanchon, T. J. Pearson, O. Perdereau, L. Perotto, F. Perrotta, V. Pettorino, F. Piacentini, M. Piat, E. Pierpaoli, D. Pietrobon, S. Plaszczynski, E. Pointecouteau, G. Polenta, L. Popa, G. W. Pratt, G. Prezeau, S. Prunet, J.-L. Puget, J. P. Rachen, W. T. Reach, R. Rebolo, M. Reinecke, M. Remazeilles, C. Renault, A. Renzi, I. Ristorcelli, G. Rocha, C. Rosset, M. Rossetti, G. Roudier, B. Rouille d&#8217;Orfeuil, M. Rowan-Robinson, J. A. Rubino-Martin, B. Rusholme, N. Said, V. Salvatelli, L. Salvati, M. Sandri, D. Santos, M. Savelainen, G. Savini, D. Scott, M. D. Seiffert, P. Serra, E. P. S. Shellard, L. D. Spencer, M. Spinelli, V. Stolyarov, R. Stompor, R. Sudiwala, R. Sunyaev, D. Sutton, A.-S. Suur-Uski, J.-F. Sygnet, J. A. Tauber, L. Terenzi, L. Toffolatti, M. Tomasi, M. Tristram, T. Trombetti, M. Tucci, J. Tuovinen, M. Turler, G. Umana, L. Valenziano, J. Valiviita, B. Van Tent, P. Vielva, F. Villa, L. A. Wade, B. D. Wandelt, I. K. Wehus, M. White, S. D. M. White, A. Wilkinson, D. Yvon, A. Zacchei, A. Zonca)</p>\n]]>", "author": "Hannah", "published": "2016-06-03 16:30:58+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<p>Hannah #66: Thanks!  It was entirely plausible to me that I was using terminology incorrectly, but I just looked up the <a href=\"https://en.wikipedia.org/wiki/De_Sitter_universe\" rel=\"nofollow\">de Sitter universe</a>, and that was indeed what I meant.</p>\n<p>Exactly as you say, in a dS universe subject to the Bekenstein bound, the amount of entropy accessible to any one observer is finite, and is set by the dS radius.  (In our universe, assuming the dark energy is constant so that the future is really dS, the bound is about 10<sup>122</sup> qubits.)</p>\n<p>Crucially, however, the dynamics within this 10<sup>122</sup>-qubit causal patch is <b>non-unitary</b>!  I.e., our patch is an open quantum system, in which a light ray can escape to infinity, so that it&#8217;s no longer accessible to us even in principle.  So you can get irreversible decoherence, measurements that can never be undone.  And on the picture I suggested in the post, <i>that&#8217;s</i> what&#8217;s relevant, not whether the number of qubits accessible to a given observer is finite or infinite.</p>\n<p>Incidentally, while it&#8217;s true that AdS space is hyperbolic and infinite, my understanding is that a light ray can reach the AdS boundary and bounce off it in finite time (even though anything traveling more slowly than light would take infinitely long to reach the boundary).</p>\n<p>Obviously experts should correct whatever I got wrong.</p>\n]]>", "author": "Scott", "published": "2016-06-03 16:48:18+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>irt. <b>wolfgang</b>:</p>\n<p>I would agree with you. I think a lot of moral debates are informed more by practicality and usefulness than any lofty principles. But I would argue (or, well, tbh hope :P) that there&#8217;s more to morality than that.</p>\n<p>Cheers.</p>\n]]>", "author": "BLANDCorporatio", "published": "2016-06-03 17:07:51+00:00", "title": "By: BLANDCorporatio"}, {"content": "<![CDATA[<p>Whoa, really? Non-unitary? That&#8217;s neat! In a de Sitter space, you really have a non-unitary evolution operator? Does it work like an observation, where it&#8217;s random, or does it just deterministically zero out part of the state space?</p>\n<p>I was thinking that you meant that you wanted to be in a universe where entropy was constantly increasing at a high rate, so that the accessible macrostates would each have a fairly well-defined macro-history.</p>\n]]>", "author": "Hannah", "published": "2016-06-03 17:08:39+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<blockquote><p>The Church-Turing Thesis, I said, is so versatile that the only genuine escape from it is to propose entirely new laws of physics.</p></blockquote>\n<p>I don&#8217;t think I understand this properly. Do you mean something like: we can come up with postulates that treated axiomatically we can derive the Church-Turing Thesis as well model portions of the  physical world just as well as, say, Class Mech or QM? Wouldn&#8217;t this mean that the thesis becomes like Ptolemy&#8217;s epicycles in discussions about consciousness?</p>\n<blockquote><p>But until that happens, I\u2019m unwilling to go up against what seems like an overwhelming consensus, in an empirical field that I\u2019m not an expert in.</p></blockquote>\n<p>In my limited studying of neuroscience, it seems neuroscientists do not find the computational view useful. Gary Marcus wrote an op-ed in the NYT with the title: <a href=\"http://www.nytimes.com/2015/06/28/opinion/sunday/face-it-your-brain-is-a-computer.html\" rel=\"nofollow\">Face it, Your Brain is a Computer</a>, precisely decrying this situation. I quote:</p>\n<blockquote><p>Many neuroscientists today would add to this list of failed comparisons the idea that the brain is a computer \u2014 just another analogy without a lot of substance. Some of them actively deny that there is much useful in the idea; most simply ignore it.</p></blockquote>\n<p>As an example: in the neuroscience of learning and memory we currently simply have no clue about how to connect LTP &#8211; the most studied possibility &#8211; to learning in vertebrates. (I think this highlights the danger or pop-sciences which you are so well aware of).</p>\n<p>A final question:</p>\n<p>Suppose we simulate addition, say, in an FSM, can what it does be called &#8216;adding&#8217; when our species have disappeared? Could say certain stalactites dripping be a &#8216;qadding&#8217; for some long dead alien species?  </p>\n<p>Illocutionary disclaimer: re-read the post and I hope it doesn&#8217;t sound combative since I am a big fan.</p>\n]]>", "author": "unapologetically_procrastinating", "published": "2016-06-03 17:21:25+00:00", "title": "By: unapologetically_procrastinating"}, {"content": "<![CDATA[<p>Whether a &#8220;brain&#8221;/&#8221;mind&#8221; can be cloned sounds a bit like hair splitting to me since two separated systems could just happen to be &#8220;identical&#8221; by chance anyway, no? There&#8217;s nothing preventing this, even if very unlikely.</p>\n]]>", "author": "fred", "published": "2016-06-03 17:54:13+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Hannah #69:</p>\n<ul>Whoa, really? Non-unitary? That\u2019s neat! In a de Sitter space, you really have a non-unitary evolution operator? Does it work like an observation, where it\u2019s random, or does it just deterministically zero out part of the state space?</ul>\n<p>It&#8217;s probably less amazing than you think. \ud83d\ude42  All that happens is that a photon escapes past your dS boundary, so then if you want to write the density matrix for the universe <i>inside</i> your boundary, the standard rules of quantum mechanics say that you need to take a partial trace over all the possible states of the photon.  It&#8217;s exactly like if you&#8217;d lost track of the photon in a lab experiment, except that in this case, cosmology tells us that the photon can never again be recovered, even using arbitrarily-advanced technology of the remote future.</p>\n]]>", "author": "Scott", "published": "2016-06-03 18:05:54+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #71:</p>\n<ul>Whether a \u201cbrain\u201d/\u201dmind\u201d can be cloned sounds a bit like hair splitting to me since two separated systems could just happen to be \u201cidentical\u201d by chance anyway, no? There\u2019s nothing preventing this, even if very unlikely.</ul>\n<p>I&#8217;m imagining a new bumper-sticker slogan, to go along with &#8220;you can have my gun when you pry it from my cold, dead hands&#8221;: &#8220;you can have my identity when you <i>guess it by chance</i>&#8221; \ud83d\ude09</p>\n]]>", "author": "Scott", "published": "2016-06-03 18:08:42+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #65</p>\n<p>&#8220;I think the probability that we\u2019ll get convincing empirical evidence that we\u2019re living in a computer simulation is close to zero&#8221;</p>\n<p>If the simulation relies on limited resources and &#8220;multi-threading&#8221;, then it&#8217;s possible to imagine that one part of the simulation could affect other parts of the simulation in some observable way. </p>\n<p>E.g. we build a massive quantum computer, and when we turn it on we see that physics in other part of our observable universe suddenly runs in a dumbed-down mode.<br />\nIn current video games using adaptive physics engines and renderers, when the local computation requirements around the player increase, distant processes degrade (tick rate or level of detail) in order to keep the overall simulation cost constant.</p>\n]]>", "author": "fred", "published": "2016-06-03 18:15:22+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>fred #74: Yes, one can certainly imagine such experiments.  What I assign a probability close to 0 is that running them will give anything other than a null result. \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-06-03 18:23:20+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #73</p>\n<p>haha, well, I was thinking more along the lines of the &#8220;exclusion principle&#8221; &#8211; two electrons can&#8217;t occupy the same quantum state simultaneously. There&#8217;s nothing in QM preventing two identical brains to exist in the same universe.<br />\nBut with or without cloning, identical systems would diverge very quickly anyway since their surroundings are always different by definition.</p>\n]]>", "author": "fred", "published": "2016-06-03 18:23:54+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Apologies to previous commenters if my points have already been discussed, but after reading a long, complex (but fascinating) post I am not up for reading 67 doubtless even also complex and interesting comments, so here goes:</p>\n<p>Two minor thoughts:</p>\n<p>1)  A general rebuttal to the need for specific algorithms for an AI (or human brains) to follow is I think provided by the evolutionary algorithm (random ideas, selection criteria, memory&#8211;I have detailed these components numerous times so won&#8217;t repeat that here) (shorter form: trial and error). It is the naturally-occurring algorithm which produced our amazing nano-tech brains in the first place. And yes, the development of this algorithm in biological nervous systems was a survival trait.</p>\n<p>2) &#8220;For imagine someone had such fine control over the physical world that they could trace all the causal antecedents of some decision you\u2019re making.  Like, imagine they knew the complete quantum state on some spacelike hypersurface where it intersects the interior of your past light-cone.  In that case, the person clearly could predict and clone you!&#8221; is not clear to me. If quantum events are random, then knowing all the random events which happened in the past will not allow anyone to predict what will happen in the future.</p>\n<p>Example: suppose there were a (very) tiny piece of radio-active material somewhere in the brain, and a (very) tiny nano-tech geiger-counter monitoring it, and further suppose that your brain contains an algorithm such that whenever an immediate decision is needed among two or more alternative courses of action (from which there is no clear choice), it uses the number of geiger-counter clicks between heartbeats to chose the one to implement.</p>\n<p>(I actually think there could be a similar mechanism in our brains &#8211; unpredictability being a survival trait in some circumstances &#8211; but would guess it is actually based on the number of nerve cells being triggered by external input, such as the number of photons hitting retinas. Most game programs use some such code.)</p>\n]]>", "author": "JimV", "published": "2016-06-03 18:26:05+00:00", "title": "By: JimV"}, {"content": "<![CDATA[<p>Scott #75</p>\n<p>Ok, what about this &#8211; could it turn out that the big discrepancies we see in large scale physics/cosmology (dark energy/dark matter, etc), could be one day explained by the underlying simulation of our universe being &#8220;imperfect&#8221;?</p>\n]]>", "author": "fred", "published": "2016-06-03 18:33:42+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>unapologetically_procrastinating (great name BTW) #70:</p>\n<ul>I don\u2019t think I understand this properly. Do you mean something like: we can come up with postulates that treated axiomatically we can derive the Church-Turing Thesis as well model portions of the physical world just as well as, say, Class Mech or QM?</ul>\n<p>No, I just meant that all the fundamental theories of physics we&#8217;ve known&#8212;Newtonian mechanics, Maxwell&#8217;s electrodynamics, special and general relativity, quantum mechanics, quantum field theory&#8212;have had the property that they appear to be simulable on a computer (at least, a computer with a random number generator) to any desired precision.  And to whatever extent there have been caveats to that statement, they&#8217;ve been because of aspects of one theory that are then revealed to be idealized approximations by the next theory.  E.g., in Newtonian mechanics, it&#8217;s at least conceivable that you could build a hypercomputer that solved the halting problem in finite time by orbiting point masses around each other faster and faster, but then special relativity rules that possibility out.  Or, as the example par excellence, there are many proposals today for hypercomputers, but all of them involve unbounded amounts of energy or unbounded division of time and space, and for that reason, they&#8217;re all excluded by the tiny amount we know so far about quantum gravity (e.g., the work of Jacob Bekenstein in the 70s and 80s).</p>\n<p>A priori, it&#8217;s possible that there could&#8217;ve been an experimentally-confirmed physical theory that robustly predicted that we could violate the Church-Turing Thesis&#8212;much like quantum mechanics robustly predicts we can violate the <i>Polynomial-Time</i> Church-Turing Thesis.  But that hasn&#8217;t been our experience.</p>\n<ul>In my limited studying of neuroscience, it seems neuroscientists do not find the computational view useful.</ul>\n<p>It probably depends on <i>which</i> neuroscientists (there&#8217;s a whole subfield of computational neuroscience&#8230;).  But to whatever extent what you say is true, I&#8217;d explain it in terms of differing levels of description&#8212;just like I said in the post.  E.g., neuroscientists probably also don&#8217;t find it useful to view the brain as an assemblage of leptons and quarks&#8212;but that doesn&#8217;t change the fact that the brain <i>is</i> an assemblage of leptons and quarks!  In exactly the same way, even if neuroscientists don&#8217;t find it useful to think in terms of the Church-Turing Thesis, the burden is still on you to say something new about physics, if you think the Church-Turing Thesis doesn&#8217;t apply to the brain.</p>\n<ul>Suppose we simulate addition, say, in an FSM, can what it does be called \u2018adding\u2019 when our species have disappeared?</ul>\n<p>Sure, why not?</p>\n<ul>Could say certain stalactites dripping be a \u2018qadding\u2019 for some long dead alien species?</ul>\n<p>Aren&#8217;t stalactites usually a mere 50,000-100,000 years old or something?  They&#8217;re young enough that the aliens who needed the qaddition done could&#8217;ve interacted with early humans and shown up in cave paintings&#8230; \ud83d\ude09</p>\n]]>", "author": "Scott", "published": "2016-06-03 18:34:25+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #78:</p>\n<ul>could it turn out that the big discrepancies we see in large scale physics/cosmology (dark energy/dark matter, etc), could be one day explained by the underlying simulation of our universe being \u201cimperfect\u201d?</ul>\n<p>Peter Shor loves to joke that the solution to quantum gravity is that whoever coded up the universe simply never figured out how to make QM and GR mesh with each other, so if you did an experiment that depended on both theories, the universe would crash.</p>\n<p>Personally, though, when I&#8217;m given a choice between</p>\n<p>(a) God, or the godlike programmer-aliens who created our universe, were too dumb to figure out how to make something work,</p>\n<p>versus</p>\n<p>(b) <i>We&#8217;re</i> too dumb to figure out how it works,</p>\n<p>my probability for (b) is something like 1 &#8211; 1/BB(BB(10000)).</p>\n]]>", "author": "Scott", "published": "2016-06-03 18:51:17+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Hi Scott,</p>\n<p>I dont think your native american comparison is a very good one. We believe that all humans are conscience for the very simple reason that they all have brains built on the very same principles that ours are! It is no stretch at all to suggest that any human is conscious (unless you want to play solipsitic games). In this case the question of what consciousness is and how it arises is not relevant &#8211; you are a human with a brain like me, whatever makes me conscious almost certainly makes you conscious as well. The onus is clearly firmly with someone who wants to suggest another human is not conscious to prove it. </p>\n<p>However, it is a huge stretch to apply this to a totally different system (silicon) trying to emulate a process we have no understanding of (consciousness). This stretch relies on lots of assumptions about how information processing relates to consciousness &#8211; assumptions that seem fairly weakly anchored considering we dont know what the heck consciousness is and how it arises.</p>\n<p>BTW totally off topic, I played your &#8220;guess the f or d&#8221; game. You might think my approach was cheating &#8211; I rolled a die and submitted my input based on the result. After quite a few plays the prediction algorithm was sitting at a 37% prediction rate. Its obviously better at second guessing humans than dealing with real randomness \ud83d\ude42</p>\n]]>", "author": "Philip Calcott", "published": "2016-06-03 18:45:27+00:00", "title": "By: Philip Calcott"}, {"content": "<![CDATA[<p>Scott #39: Thanks for answering!</p>\n<p>2. If you assume a notion of proto-consciousness, why not prefer the simpler hypothesis that consciousness = proto-consciousness?</p>\n<p>3. &#8220;a believer in consciousness could always turn the tables, and say to the eliminativist: even if consciousness were a fundamental feature of the world, it\u2019s still plausible that you\u2019d be giving all the same arguments that it wasn\u2019t, so how can your arguments possibly be persuasive?\u201d</p>\n<p>This seems similar to the theist who says &#8220;maybe I haven&#8217;t proved god exists but none of your arguments prove god *doesn&#8217;t* exist.&#8221; If we can manage equally well with concept X and without it then Occam&#8217;s razor says we should do without.</p>\n<p>&#8220;all our views about personal identity, free will, consciousness, psychophysical parallelism, etc. seem to require that our minds can\u2019t be freely copied, predicted, and rewound like computer code&#8221;</p>\n<p>This is a strong statement. At the very least, *my* views on these subjects don&#8217;t require those assumptions \ud83d\ude42</p>\n<p>&#8220;To me, it would be absurd not to ask whether the things fit together&#8221;</p>\n<p>This is certainly a sentiment I empathize with.</p>\n<p>4. &#8220;If the brain has a &#8216;clean digital abstraction layer&#8217; that captures everything cognitively relevant, and that notices the lower-level stuff purely as thermal noise, then the picture is wrong.&#8221; </p>\n<p>To the best of my understanding, this is indeed the leading hypothesis in neurobiology which I therefore find most likely. It is commendable that you&#8217;re willing to put your neck on the line like this (unless you mean something more restrictive than what I think you mean?)</p>\n<p>Nevertheless, let&#8217;s assume for the sake of the argument that physics looks like you want it to look. In this world, would nothing convince you quantum consciousness is wrong? Imagine that the world would already be populated by some sort of artificial humans that violate your consciousness criteria but that are a part of society as ordinary as &#8220;wild type&#8221; humans. In such a world, would you still be tempted to articulate a theory of consciousness which rules that a large portion of the world&#8217;s population (consisting of normative, often likable and even admirable people) is unconscious?</p>\n]]>", "author": "Vadim Kosoy", "published": "2016-06-03 18:48:28+00:00", "title": "By: Vadim Kosoy"}, {"content": "<![CDATA[<p>Scott #82</p>\n<p>Isn&#8217;t it a bit strange to claim that computability is the most fundamental property of our universe and also think that it&#8217;s very unlikely that our universe could be a simulation?</p>\n<p>It doesn&#8217;t require the assumption of any god-like/perfect beings, just the observation that we, as flawed as we are, are routinely running Turing complete computations (often world simulations).</p>\n<p>It&#8217;s merely the observation that a Turing machine can emulate any other hardware, so there could be many layers of &#8220;reality&#8221;, existing at various levels of abstraction, and there&#8217;s no reason to think we&#8217;re &#8220;special&#8221; and are at the very bottom of this recursion.</p>\n]]>", "author": "fred", "published": "2016-06-03 19:53:00+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Scott #82</p>\n<p>Forgot to add:</p>\n<p>The evidence also seems to suggest that a universe that&#8217;s computable naturally assembles itself into more and more powerful Turing machines.</p>\n<p>E.g. the earth 6 billion years ago, as a molten blob of lava&#8230; fast forward &#8230; and it&#8217;s now covered with billions of computers.</p>\n]]>", "author": "fred", "published": "2016-06-03 20:02:23+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Scott #39</p>\n<p>>all our views (&#8230;) require that our minds can\u2019t be freely copied, predicted, and rewound like computer code. </p>\n<p>This seems the root idea and motive for &#8220;The ghost&#8221;, but it&#8217;s actually unclear to me (maybe because I don&#8217;t share this intuition) whether you think these *are* common views or whether you think these *should be* common views. Why do you think these are or should be common views?</p>\n]]>", "author": "Jay", "published": "2016-06-03 20:08:13+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>Here is my response to Searle&#8217;s argument: <a href=\"http://interdependentscience.blogspot.com/2009/07/machine-intelligence.html\" rel=\"nofollow\">http://interdependentscience.blogspot.com/2009/07/machine-intelligence.html</a></p>\n]]>", "author": "Jim Kukula", "published": "2016-06-03 20:17:23+00:00", "title": "By: Jim Kukula"}, {"content": "<![CDATA[<p>>&#8221;if you believe in superdeterminism then you believe the procedures always had to conspire across the universe to generate challenges that for some unexplained reason were easy enough for the particles to pass.&#8221;</p>\n<p>That&#8217;s the thing, the wording by Bell should&#8217;ve been not that everything being determined erases the issue, but that everything being determined and there being a spooky conspiracy erases the issue.   I guess he wasn&#8217;t quite clear in his wording, as it makes it seems that full determinism alone, without conspiracies, is superdeterminism and that it resolves the issue.</p>\n<p>>In summary, superdeterminism is a miserable failure as a scientific explanation, for reasons having nothing to do with free will.</p>\n<p>Bell described superdeterminism as simply determinism applying to everything.  The only escape from determinism is true randomness.   And true randomness simply seems nonsensical.</p>\n<p>So whether it explains the issue or not, it seems difficult to believe that reality doesn&#8217;t exhibit deterministic mechanisms at its root.  If we need to add nonlocality or something else to explain the experiment, then that may be the case.  But bringing true randomness into the mix just seems like an unacceptable addition.</p>\n<p>It&#8217;s not only adding true randomness, you need to add a fundamental difference between past present and future, and a mechanism that transitions between these, something that turns the uncertain future into the labile present and then into the nonchanging past.  You need absolute simultaneity, the existence of the present for this, something whose existence some consider relativity does not allow.</p>\n<p>If past, &#8216;present&#8217; and  future are similar in nature, then just as the past is nonchanging so to is the &#8216;present&#8217; and the future.</p>\n<p>>Flavio #64: I think the probability that we\u2019ll get convincing empirical evidence that we\u2019re living in a computer simulation (i.e., something some entity purposefully created) is close to zero\u2014</p>\n<p>Wolfram showed that extremely simple programs can produce extraordinary complexity.   There have been examples of naturally occurring unlikely things like nuclear reactors, it is not inconceivable that given that extraordinarily simple programs can produce extraordinary complexity, the possibility of a naturally occurring simulation occurred in some natural medium is not zero.</p>\n<p>If it was a naturally occurring simulation, depending on the details of implementation, it may be possible to modify the fundamental rules.   At least it would open the greatest potential for unbounded technological progress, if existence, if reality, itself becomes malleable.</p>\n<p>> It\u2019s exactly like if you\u2019d lost track of the photon in a lab experiment, except that in this case, cosmology tells us that the photon can never again be recovered, even using arbitrarily-advanced technology of the remote future.</p>\n<p>I&#8217;d say that depends on expansion of space continuing or accelerating.   If brains can pop out of the vacuum, then something that reflects the photon can also pop out of the vacuum.</p>\n]]>", "author": "Darien S", "published": "2016-06-03 20:34:43+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>If I deliberately overcorrect for &#8220;randomness doesn&#8217;t look random&#8221; biases I can keep the Oracle&#8217;s accuracy consistently below 50%. It&#8217;s an interesting challenge.</p>\n]]>", "author": "Adam", "published": "2016-06-03 21:08:22+00:00", "title": "By: Adam"}, {"content": "<![CDATA[<p>On a long walk after my previous comment, a couple more thoughts occurred to me (so naturally I can&#8217;t resist posting them, sorry).</p>\n<p>1) The &#8220;\u201cAaronson Oracle&#8221; is not in my opinion a good way to test for an intrinsic random function in human brains &#8211; because randomization is presented as a specific goal (be as random as possible in your choices) so the next choice will be a function of previous choices (e.g., four of my last five choices were &#8220;d&#8221; so next I must chose &#8220;f&#8221;). In a way, it&#8217;s like telling people not to think about hippopotamuses. You need to disguise the  purpose of the test (e.g., make it about speed of choosing rather than randomness) and present the choices in a way that is unbiased. I thought of a possible way to do this on my walk, but I&#8217;m sure everyone here can do so as well or better, so I won&#8217;t describe it.</p>\n<p>2) I&#8217;m probably missing something in Dr. Penrose&#8217;s argument, but if he is saying computers can&#8217;t be conscious because humans do it by using gravitized QM in microtubes, isn&#8217;t the answer to make computers with gravitized QM microtubes? If evolution could do it, why can&#8217;t we (in principle)? Or maybe he means we are going about it in the wrong way (by not using gravitized microtubes).</p>\n<p>As I&#8217;ve said many times before, I see consciousness as similar to Windows or other operating systems, which take external inputs, transfer them to internal routines without knowing what those internal routines are doing, and receiving outputs from those routines which it may then transmit externally. That is, much of the mystery shrouding consciousness is due to the fact that there are no nerves which monitor the brain internally and thus no way to know what it is going on in the background. As to how it feels, or how it would feel to a computer, who cares? (Not me.)</p>\n<p>Anyway, as I forgot to say last time, thanks for the interesting post. And please add a donations button so I can reciprocate.</p>\n]]>", "author": "JimV", "published": "2016-06-03 21:44:19+00:00", "title": "By: JimV"}, {"content": "<![CDATA[<p>Jay #85: If it&#8217;s <i>not</i> a common view, I think that&#8217;s because most people simply haven&#8217;t spent enough time thinking through the full strangeness of a world with copyable minds!  Making any plans or predictions for the future requires not only a model of the physical world and how it&#8217;s going to evolve, but also a model for how your &#8220;indexical pointer&#8221; (the invisible arrow pointing out which little part of physical world is &#8220;you&#8221;) is going to evolve.  In all the circumstances we&#8217;re used to, it&#8217;s so obvious how to handle the indexical pointer that we don&#8217;t even think about: it just continues pointing to <b>you</b>, silly!  Until you&#8217;re dead, or possibly comatose.</p>\n<p>Great, now try to think through how you&#8217;d make decisions, as a rational agent, if your indexical pointer could split in two or split into a million, and recombine, or point to two widely-separated physical objects that only <i>become</i> you when recombined, or point to an inert piece of software in transit from earth to Mars, or &#8230;</p>\n<p>And please come back to me when you have a coherent theory for all this! \ud83d\ude42</p>\n<p>For more, see Sec. 2.5 of GIQTM itself.</p>\n]]>", "author": "Scott", "published": "2016-06-03 21:48:17+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>JimV #89:</p>\n<ul>I\u2019m probably missing something in Dr. Penrose\u2019s argument, but if he is saying computers can\u2019t be conscious because humans do it by using gravitized QM in microtubes, isn\u2019t the answer to make computers with gravitized QM microtubes?</ul>\n<p>Yes!  Penrose said explicitly during the discussion&#8212;as he&#8217;s said before, in <i>Shadows of the Mind</i> for example&#8212;that it&#8217;s entirely possible that &#8220;some future Dr. Frankenstein&#8221; (as he put it) will create a conscious AI by building it with gravitized quantum microtubules.  He added that he doesn&#8217;t <i>want</i> for that to happen, but that his own wants are irrelevant to what his proposal implies is possible.</p>\n<ul>Anyway, as I forgot to say last time, thanks for the interesting post. And please add a donations button so I can reciprocate.</ul>\n<p>Aw, but I have a comfortable academic salary (and have to file paperwork for any external income).  Everyone: if you support this blog, then your praise is the only payment I need! \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-06-03 21:56:03+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #83</p>\n<p>> It\u2019s merely the observation that a Turing machine can emulate any other hardware, so there could be many layers of \u201creality\u201d, existing at various levels of abstraction, and there\u2019s no reason to think we\u2019re \u201cspecial\u201d and are at the very bottom of this recursion.</p>\n<p>Scott #65:</p>\n<p>> Arguably, this question is orthogonal to the question of the Church-Turing Thesis, since even if our universe was a simulation, who\u2019s to say that the simulating gods/aliens wouldn\u2019t have access to super-Turing hypercomputers? And conversely, even if we never get any evidence that our universe is being \u201crun\u201d for any computational purpose, we could get (and I\u2019d say, have gotten) very good evidence that it satisfies the Church-Turing Thesis.</p>\n<p>Well, but if we are inside an emulation, probably our emulators have real energy constraints (which still might be so ridiculous high as to appear as if it were infinite to us).<br />\nBut there are physical features to an emulated universe that could help economize energy needed for the emulations to run, like for example the Holographic Principle&#8230;</p>\n]]>", "author": "Flavio Botelho", "published": "2016-06-03 21:56:44+00:00", "title": "By: Flavio Botelho"}, {"content": "<![CDATA[<p>>Great, now try to think through how you\u2019d make decisions, as a rational agent, if your indexical pointer could split in two or split into a million, and recombine, or point to two widely-separated physical objects that only become you when recombined, or point to an inert piece of software in transit from earth to Mars, or \u2026</p>\n<p>If you sever a few connections in the brain, the corpus callosum, you lose perception of half of your visual field.   The brain is still one object connected by other brain regions and by vascular tissue, yet suddenly half the tissue responsible for consciousness either is nonconscious or if it is conscious must either share or not share your unique identity.    So either a new identity emerges out of the ether merely by affecting a few functional macroscopic connections or your identity leaves a large chunk of tissue or your identity divides into two identical identities or it doesn&#8217;t the illusion of identity occurs because of nonshared memory.</p>\n<p>My take is there is a possibility that all conscious things share the same unique identity, and this is not realized by conscious individuals due to nonshared memory giving the illusion of there being distinct identities.   If two brains were properly functionally connected, perhaps they&#8217;d say &#8220;wow, we&#8217;re the same &#8216;me&#8217; but with different memories and personalities&#8221;.</p>\n]]>", "author": "Darien S", "published": "2016-06-03 22:27:23+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>#Scott 82, Fred #83,</p>\n<p>The ideas of different levels of abstraction all being equally &#8216;real&#8217; and the universe not being totally coherent is exactly what I was suggesting in my own theory of metaphysics (see other thread)</p>\n<p>Peter Shor&#8217;s &#8216;joke&#8217; that GM and QM may *not* in fact totally mesh with each other in &#8216;reality&#8217; may in fact be correct.  Why *should* the universe be totally consistent?   My idea is that &#8216;existence&#8217; is not an all-or-nothing thing, but there are &#8216;degrees&#8217; or &#8216;strengths&#8217; of existence, and the universe is still in the process of coming into existence!</p>\n<p>I&#8217;m suggesting that the &#8216;code&#8217; for the universe is indeed being changed on the fly during run-time!  And the &#8216;software patches&#8217; are what we interpret as consciousness!  \ud83d\ude09</p>\n<p>(The programmers of the universe are working hard to correct the inconsistencies, so &#8216;software patches&#8217; are going on all the time.  The theory of &#8216;quantum gravity&#8217; is coming along nicely and improving with each patch)</p>\n<p>There&#8217;s actually an easy rebuttal to the hard-core eliminativism of Dennett.  Here it is:  if consciousness is not real, then nothing is.  Because if you &#8216;eliminate&#8217; consciousness by reducing it to signals in the brain, there is no reason to stop the process of elimination there &#8211; after all we can &#8216;eliminate&#8217; brains by reducing them to neurons.  And we can &#8216;eliminate&#8217; neurons by reducing them to molecules.  And so on and on.  Finally, we &#8216;eliminate&#8217; the physical world altogether by reducing it to the pure mathematics of wave-functions.</p>\n<p>It does seem that we have to grant that reality can &#8216;exist&#8217; at more than one level of abstraction.  And when we do that, you end up with something just like the metaphysics I posted on the other thread.</p>\n]]>", "author": "mjgeddes", "published": "2016-06-03 23:05:54+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>Scott #79: &#8220;Newtonian mechanics, Maxwell\u2019s electrodynamics, special and general relativity, quantum mechanics, quantum field theory\u2014have had the property that they appear to be simulable on a computer (at least, a computer with a random number generator) to any desired precision.&#8221;</p>\n<p>That&#8217;s a little bit of a strange statement to make when we don&#8217;t even have a rigorous mathematical construction for nontrivial quantum field theories at the level of, for instance, the existence part of the million dollar Yang-Mills existence and mass gap problem. I don&#8217;t believe nature allows hypercomputation, but one piece of evidence making the problem interesting has to be that the relevant functional integrals of QFT exist in the physical world yet despite enormous effort apparently cannot be defined by taking the limit of lattice approximations.</p>\n]]>", "author": "Mark D.", "published": "2016-06-03 23:11:50+00:00", "title": "By: Mark D."}, {"content": "<![CDATA[<p>Mark D. #95: I agree that the problem is interesting, and points like yours are very much why I hedged with &#8220;appear to be simulable&#8221;!</p>\n<p>In the case of QFT, though, we do have (for example) <a href=\"http://arxiv.org/abs/1111.3633\" rel=\"nofollow\">the work by Jordan, Lee, and Preskill</a>, which shows explicitly how to simulate interacting scalar field theories to any desired precision on a qubit-based quantum computer.  (See also their <a href=\"http://arxiv.org/abs/1404.7115\" rel=\"nofollow\">extension to the fermionic case</a>.)  They haven&#8217;t yet extended these results to the full Standard Model, but the difficulties in doing so <i>seem</i> more technical than fundamental, and don&#8217;t seem to require solving, e.g., the Yang-Mills mass gap problem.  (Someone can correct me if I&#8217;m wrong.)</p>\n<p>The truth, though, is that if someone proved tomorrow that QFT (as currently formulated) lets you solve the halting problem in finite time, I would say that it&#8217;s almost certainly just like the constructions of &#8220;hypercomputers&#8221; in Newtonian mechanics&#8212;i.e., an artifact of pushing an approximate theory beyond its domain of validity.  I&#8217;d point out that QFT has to break down at the latest when you get to the Planck scale, to be replaced by some other theory that satisfies the Bekenstein bound (i.e., that uses a finite number of qubits to describe the state of a bounded region), and that therefore presumably satisfies the Church-Turing Thesis as well.  At the end of the day, the Bekenstein bound is the <i>real</i> physics reason why I think Nature satisfies the Church-Turing Thesis, though that fact can also be manifested in effective theories if we&#8217;re careful enough in how we formulate them.</p>\n]]>", "author": "Scott", "published": "2016-06-04 00:08:40+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>This cogent essay shreds a lot of AI hype.</p>\n<p><a href=\"https://aeon.co/essays/your-brain-does-not-process-information-and-it-is-not-a-computer\" rel=\"nofollow\">https://aeon.co/essays/your-brain-does-not-process-information-and-it-is-not-a-computer</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Byrne:Peter.html\">Peter Byrne</a>", "published": "2016-06-04 05:30:21+00:00", "title": "By: Peter Byrne"}, {"content": "<![CDATA[<p>Looking through the comments I see that Wolfgang at #55 said, &#8220;And if one thinks that the Copenhagen reduction of the wavefunction is associated with the switch from objective (wavefunction) to subjective (conscious observation) then it is natural to conclude that \u201cgravitized quantum mechanics\u201d has something to do with consciousness.&#8221;</p>\n<p>I thought I had heard that experiments have shown that conscious observations are not necessary, just the mere fact of having a detector which could tell whether the photon went through either slit (in the the two slit experiment) is enough to prevent interference fringes, whether or not the measurement is recorded or ever reviewed by a conscious observer (which I assume &#8211; perhaps wrongly &#8211; that we all agree that an electronic detector is not).</p>\n]]>", "author": "JimV", "published": "2016-06-04 05:31:09+00:00", "title": "By: JimV"}, {"content": "<![CDATA[<p>Peter Byrne #97: I didn&#8217;t find that article cogent at all.  In fact, the entire thing seems based on a trivial language confusion.</p>\n<p>In saying that &#8220;your brain is not a computer,&#8221; the author turns out to mean something true but pedestrian: namely, that the brain isn&#8217;t <i>organized</i> the way existing digital computers are organized.  Nowhere does the author even try to show why the brain <i>couldn&#8217;t be simulated by a computer</i>&#8212;i.e., why the brain violates the Physical Church-Turing Thesis, which is what it would need to do for simulating it to be <i>impossible</i> rather than merely <i>complicated</i> or <i>hard</i>.  Worse, the author gives zero indication of understanding what computational universality or the Church-Turing Thesis even <i>are</i>&#8212;meaning that the actual questions at issue here, the ones that Roger Penrose realizes he has to answer for the AI-is-impossible-in-principle thesis to stand a chance, never even cross the horizon of this author&#8217;s consciousness.</p>\n<p>Related to that, the author never even tries to grapple with deep learning algorithms, which <i>do</i> have a vaguely brain-like organization, and which of course have enjoyed spectacular successes over the last five years.  It&#8217;s as if someone published a philosophical article, in June 2016, entitled &#8220;Why American Democracy is Inherently Stable Against Authoritarian Demagogues,&#8221; without even showing <i>awareness</i> of any potential recent counterexample, let alone trying to explain it away.  I&#8217;d call that intellectual dishonesty, if not for my strong suspicion that the author really does have no more awareness about machine learning than about anything else in CS.</p>\n<p>Peter, you wrote a fine biography of Hugh Everett.  Do you not see that Everett would&#8217;ve ripped this article to shreds, and would&#8217;ve been totally right to do so (whatever else he was right or wrong about)?</p>\n]]>", "author": "Scott", "published": "2016-06-04 06:19:01+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>I read, some time ago, the neuron manipulations of genetic modified c. elegans, to modify the behavior and their senses.<br />\nIf this is possible, then I don&#8217;t understand the quantum behavior of a brain: if a laser can change the behavior, then the neurons are a macroscopic objects with chemical reactions, so that many near classical objects have an equal behavior, so that the cloning could be possible.<br />\nIf it is possible to write in a c. elegans, I guess it is possible to read the behavior; there is the complete sequencing of the c. elegans and a partial computer cellular simulation (openworm) to predict in the future the worm thoughts and actions.</p>\n]]>", "author": "domenico", "published": "2016-06-04 09:23:00+00:00", "title": "By: domenico"}, {"content": "<![CDATA[<p>Hi Scott and thanks for this great post. I have read both Penrose&#8217;s books and many posts about your viewpoints in the last few years, but I admit that I have only superficial knowledge about the whole issue of &#8220;quantum consciousness&#8221;, and I feel a bit dumb by posting in this thread amongst people much smarter than me \ud83d\ude42 </p>\n<p>However, there is something I&#8217;ve never really understood. If the whole issue breaks down to &#8220;classical AIs might be conscious&#8221; vs. &#8220;no, they can&#8217;t because they lack the quantum effect of nanotubules&#8221;, wouldn&#8217;t it be reasonable to reconcile both arguments by considering AIs running on a quantum computer?</p>\n<p>Let me explain better: even *if* one assumes that quantum effects are somehow necessary for consciousness to evolve, wouldn&#8217;t an AI running on a quantum computer be eligible for being considered conscious? Or, put in another way, would both you and Penrose agree that this is theoretically possible? Does the issue only concern AIs running on &#8220;classical&#8221; (i.e. non-quantum) hardware?</p>\n<p>I&#8217;m asking because, as far as I can see it, this would solve at least part of the problem. Even from an ethical perspective, as you put it, killing such an AI would be wrong because you are destroying something inherently non-replicable &#8211; i.e., you could not beam one&#8217;s mind on Mars without destroying the one on Earth, or make copies of one&#8217;s mind in general, exactly because of the quantum effects given by the nanotubules.</p>\n<p>On the other hand, this would give a somewhat strict criteria to assess consciousness: if your hardware (or wetware) shows quantum behaviour, then you are eligible for being considered a sentient being, otherwise not.</p>\n<p>So, the question is: would you consider such a viewpoint philosophically sound? Would Penrose?</p>\n]]>", "author": "Tommy", "published": "2016-06-04 11:11:06+00:00", "title": "By: Tommy"}, {"content": "<![CDATA[<p>To me, the most compelling argument for Penrose&#8217;s side of this debate comes from experiments in which &#8220;quantum randomness&#8221; is shown to be subject to the influence of intention.  Robert Jahn, while Dean of Engineering at Princeton, conducted such experiments and found 5-sigma significance.  More recently, Dean Radin has found consistent, overwhelmingly significant results from an experiment of very different design.</p>\n<p>This vitiates the central claim about &#8220;90 years of unbroken successes of Quantum theory.&#8221;  Now we have not only the Copenhagen Interpretation, which explicitly evokes conscious perception to collapse the wave function, we also have the interpretation-free results of several experiments.  </p>\n<p>Both Jahn and Radin are supremely conscious that the burden of proof is high, and they have been meticulous and thorough in eliminating every possible confounding influence that might provide an excuse for considering their results an artifact.</p>\n<p>In fact, Jahn and Radin are only the least interesting and most careful tip of a huge body of experimental data in psi research.  Once we grant that the results of these two are incontrovertible, it opens our minds to this much larger corpus, that we may have dismissed as improbable.  </p>\n<p>I recommend Liz Mayer&#8217;s book, <a href=\"https://books.google.com/books/about/Extraordinary_Knowing.html?id=iHz4cjWW7jIC\" rel=\"nofollow\">Extraordinary Knowing</a>.</p>\n]]>", "author": "Josh Mitteldorf", "published": "2016-06-04 12:14:02+00:00", "title": "By: Josh Mitteldorf"}, {"content": "<![CDATA[<p>irt. <b>Scott</b>:</p>\n<p>&#8220;now try to think through how you\u2019d make decisions, as a rational agent, if your indexical pointer could split in two or split into a million, and recombine, or point to two widely-separated physical objects that only become you when recombined, or point to an inert piece of software in transit from earth to Mars, or \u2026</p>\n<p>And please come back to me when you have a coherent theory for all this!&#8221;</p>\n<p>There&#8217;s the passing flame intuition that works well enough for all cases you&#8217;ve given (in particular, it includes the possibility to destroy the indexical pointer when no individual can be recognized as priviliged to be the original from the copy process, and once destroyed an indexical pointer must not be relied on to come back). And that&#8217;s just one way.</p>\n<p>Conversely, hinging consciousness (and by your definition of it, a good chunk of moral debate) on non-copyability seems dangerous. Not even QM would preclude the existence of &#8220;pretty good&#8221; copies that would behave pretty much exactly like the original, for any amount of time. The brain is likely sufficiently robust (a-la error codes) that whatever makes you you doesn&#8217;t depend on quantum twitches. And is it really a putative ability to pick up start-of-the-universe static the thing that makes a person valuable? Now that I&#8217;d find weird.</p>\n<p>Also, if I remember correctly your ghost in the Turing machine post was filled with caveats about those being not completely rigorous philosophical musings and a request to not treat and argue against them as if they were. So to your speculations we should only answer with coherence. Tsk. Tsk I say!</p>\n]]>", "author": "BLANDCorporatio", "published": "2016-06-04 12:57:17+00:00", "title": "By: BLANDCorporatio"}, {"content": "<![CDATA[<p>Scott #72:</p>\n<blockquote><p>All that happens is that a photon escapes past your dS boundary&#8230;</p></blockquote>\n<p>Okay, so tell me if I have this wrong. The positive cosmological constant will make us roughly a flat de Sitter universe when time is larger, positively curved even if it is <i>spatially</i> not curved. (I misinterpreted \u03a9_K as the spacetime curvature, but now I have gotten the idea and realize that it is only the spatial curvature and that a positive cosmological constant really does mean a de Sitter future.)</p>\n<p>A point in a de Sitter universe has a cosmological horizon, i.e. a maximum distance that it can transmit information to, and this horizon is constantly shrinking. Gallant and Goofus are sitting in chairs on Earth next to each other playing Cookie Clicker with neurological processes that could correspond to qualia. Goofus thinks deterministically; Gallant thinks randomly with true quantum noise. Their neurologies get entangled with photons radiated from Earth into space, and those travel outward to the future cosmological horizon.</p>\n<p>The photons never actually cross the future horizon, but after a certain amount of time (about ten billion years?) they have gone so far that they are causally disconnected; at some point they cross the <i>past</i> horizon and they can never get <i>back</i> to affect our two heroes. We decide that those photons have left the quantum system as far as we are concerned and do a partial trace over them to get a mixed state.</p>\n<p>Then we decompose the mixed state into pure states with a probability distribution, and pick one at random. This choice collapses the superposition and tells us something about what happened ten billion years ago. Gallant&#8217;s thought processes depend on the mixed state, so he was conscious and had qualia. But poor Goofus had deterministic thought processes that do not depend on the mixed state, so he did not have any qualia. Is that the right idea?</p>\n]]>", "author": "Hannah", "published": "2016-06-04 13:17:29+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<p>Hannah #104: Yes, that&#8217;s close.  (Except that what would what matter, on this account, is not Gallant&#8217;s mere dependence on quantum randomness, but rather dependence on quantum initial states about which we have Knightian uncertainty&#8212;see <a href=\"http://www.scottaaronson.com/papers/giqtm3.pdf\" rel=\"nofollow\">GIQTM</a> Section 3 for more on the distinction.)</p>\n<p>And yes, it sounds insane when you put it the way you did, but there&#8217;s an alternative perspective that makes this view seem <i>natural</i> and <i>inevitable</i>, whether or not it ends up being correct!</p>\n<p>Namely, an outside observer can &#8220;read Goofus&#8217;s code.&#8221;  Given the right technology, the other people around Goofus know everything he&#8217;s going to do before he does it.  If they kill Goofus by accident, they can restore him from backup.  They can keep a local copy of him when he&#8217;s out of town.  They can modify their local copies to see what happens (assuming Goofus is under a Creative Commons license or whatever \ud83d\ude42 ).  If they can&#8217;t figure out how to tell Goofus they think he&#8217;s a robot without angering him, they just need to try 100 different ways in simulation.  Etc.</p>\n<p>With Gallant, outside observers can&#8217;t do any of these things.  Just like with us, people who Gallant better can predict him more accurately than those who know him less well, but if you want <i>extremely</i> accurate knowledge of what Gallant would say about something, the only way to get it is to ask him.</p>\n<p>Notice that none of these are wifty metaphysical distinctions, about Gallant having some magical quantum pixie dust that Goofus lacks.  Rather, they&#8217;re actual empirical distinctions about how you can interact with them.</p>\n<p>Yet I claim that these distinctions, if you trace through what they actually entail, boil down to the cosmological considerations that I mentioned.  If Gallant weren&#8217;t amplifying quantum states subject to Knightian uncertainty, then given sufficiently advanced technology, Gallant <i>would</i> be predictable by outside observers just like Goofus is.  And as for what it means to &#8220;amplify&#8221; a state&#8212;well, there could be some other principled criterion for that; the cosmological criterion involving our deSitter boundary is merely the most &#8220;conservative&#8221; one I know about, the one that doesn&#8217;t do any violence to orthodox linear QM.</p>\n]]>", "author": "Scott", "published": "2016-06-04 14:45:48+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Tommy #101:</p>\n<ul>If the whole issue breaks down to \u201cclassical AIs might be conscious\u201d vs. \u201cno, they can\u2019t because they lack the quantum effect of nanotubules\u201d, wouldn\u2019t it be reasonable to reconcile both arguments by considering AIs running on a quantum computer?</ul>\n<p>For whatever it&#8217;s worth, that&#8217;s exactly Penrose&#8217;s position.  (Except that a mere quantum computer is <i>way</i> less than what he needs!  He needs a device that would be sensitive to uncomputable effects from gravity-induced state vector collapse.)  See my <a href=\"http://www.scottaaronson.com/blog/?p=2756#comment-1135806\">comment #91</a>.</p>\n<p>The general issue many participants in this discussion are trying to answer (and are answering differently) is this: besides passing the Turing test, what (if anything) does a computational process need to do before we ought to consider it conscious?</p>\n<p>And yes, several of the proposed answers mention quantum mechanics for one reason or another, but they&#8217;re still extremely different from one another (as Penrose&#8217;s is different from mine)!  In any case, though, mere &#8220;quantum behavior&#8221; can&#8217;t possibly give us a non-vacuous criterion, since everything in the universe shows quantum behavior! \ud83d\ude42  So at some point, one needs to say something about what kind of behavior, and what role it plays in the computation.</p>\n]]>", "author": "Scott", "published": "2016-06-04 15:00:54+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Vadim #81 and domenico #100: My understanding is that a &#8220;clean digital abstraction&#8221; layer, of the sort I&#8217;m talking about, has <i>not</i> been shown for the C. elegans worm, even though we now know its entire connectome.  I.e., that people have built neuron-by-neuron models, but that they currently fail to reproduce the worm&#8217;s behavior, suggesting that lower-level or otherwise unmodeled degrees of freedom must be important.  Any experts who can correct me or fill in details, please do so!</p>\n<p>Let me, as Vadim put it, &#8220;put my neck on the line&#8221; and say: when biologists manage to isolate the digital abstraction layer for C. elegans&#8212;or better yet, when they show how to model and predict a <i>specific</i> C. elegans, with whatever idiosyncrasies it has (worms <i>must</i> have idiosyncrasies&#8230; \ud83d\ude42 ), without killing the worm in the process&#8212;that won&#8217;t refute the picture I&#8217;m discussing, but it will be clear progress in the direction of refuting it.</p>\n]]>", "author": "Scott", "published": "2016-06-04 15:50:18+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Freebit picture: Do you see a relationship to Henry Stapp&#8217;s discussion of Figure 1 in his 2007 &#8220;Whitehead, James, and the Ontology of Quantum Theory&#8221;? <a href=\"http://www-physics.lbl.gov/~stapp/WJQO.pdf\" rel=\"nofollow\">http://www-physics.lbl.gov/~stapp/WJQO.pdf</a></p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Augustyn:Kenneth.html\">Kenneth Augustyn</a>", "published": "2016-06-04 16:15:04+00:00", "title": "By: Kenneth Augustyn"}, {"content": "<![CDATA[<p>Vadim #81:</p>\n<ul>This seems similar to the theist who says \u201cmaybe I haven\u2019t proved god exists but none of your arguments prove god *doesn\u2019t* exist.\u201d If we can manage equally well with concept X and without it then Occam\u2019s razor says we should do without.</ul>\n<p>FWIW, even among the most rock-ribbed atheist reductionists (Richard Dawkins, etc.), very few have suggested that we can manage without the concept of consciousness.  Of course, sharp disagreement persists as to what <i>kind</i> of concept we need (does it need to be a basic feature of reality, or can it be emergent, etc.), and a related but orthogonal question, which physical entities we should or shouldn&#8217;t take to be associated with it.</p>\n<ul>Imagine that the world would already be populated by some sort of artificial humans that violate your consciousness criteria but that are a part of society as ordinary as \u201cwild type\u201d humans. In such a world, would you still be tempted to articulate a theory of consciousness which rules that a large portion of the world\u2019s population (consisting of normative, often likable and even admirable people) is unconscious?</ul>\n<p>See my response to Hannah, comment #105.  Again, though, I <i>completely reject</i> any view that has the implication that, if two human populations A and B are behaviorally identical, except that B lacks &#8220;magic quantum pixie-dust&#8221; or whatever, then for that reason alone we&#8217;re justified in treating B as unconscious.  That&#8217;s one of my reasons (not the only one) for rejecting the microtubule view.  I suspect you and I are in agreement here.</p>\n<p>For me, though, the crucial point is that in your scenario, the &#8220;wild type&#8221; and &#8220;artificial&#8221; humans would <i>not</i> be behaviorally identical, because the artificial ones could be predicted and copied and reset to their initial states while the wild-type ones couldn&#8217;t be.  And so, for example, if you were on trial for murdering one of the artificial humans, you almost certainly <i>wouldn&#8217;t need</i> to convince the jury that your victim lacked quantum pixie-dust and was therefore unconscious&#8212;a scenario that I find repugnant and that you probably do too.  Instead, you could simply restore the victim from backup (along with 10 more copies for good measure), pay a fine or whatever, and everyone could go home!</p>\n<p>In short, I see it as a central selling point for the picture I&#8217;m discussing that it would <i>not</i> lead to any class of intelligent beings being arbitrarily discriminated against, because of magical/metaphysical criteria of no empirical relevance (&#8220;quantum pixie-dust&#8221;).  Rather, the beings in question would <i>already</i> have a radically unfamiliar status in law and morality, before we even entered into theoretical questions about consciousness, for purely empirical reasons related to the beings&#8217; copyability.</p>\n]]>", "author": "Scott", "published": "2016-06-04 16:21:06+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>@Scott #65</p>\n<p>>> the probability that we\u2019ll get convincing empirical evidence that we\u2019re living in a computer simulation &#8230; is close to zero</p>\n<p>If The Donald wins the election I would take it as strong evidence that we are trapped in a cheap video game.<br />\nApprentice: The Presidency 3.0 &#8211;  now with more 3D realism and reduced artificial intelligence.</p>\n]]>", "author": "wolfgang", "published": "2016-06-04 16:38:38+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>(I must admit that I haven&#8217;t read through the entirety of the thread, but I did search to see that this had not yet come up)</p>\n<p>You bring up the no-cloning theorem as an impediment to non-destructively copying a brain state (supposing that there is something quantum going on). I&#8217;m curious as to what you have to say about the argument presented <a href=\"http://algorithmicassertions.com/2016/04/24/eves-quantum-clone-computer.html\" rel=\"nofollow\">here</a> (with pretty pictures), which can be summarized as follows: by observing sufficiently many measurements, one can infer the current quantum state of something that began in an unknown quantum state without violating the no-cloning theorem; this means that copying brains is not physically impossible, merely computationally intractable (exponential in the number of qbits).</p>\n<p>I could be doing a poor job summarizing, though.</p>\n]]>", "author": "Alex R", "published": "2016-06-04 16:57:56+00:00", "title": "By: Alex R"}, {"content": "<![CDATA[<p>Alex R #111: Thanks for the link!  While I appreciate that post for seriously engaging the question, one thing it ignores is that the quantum system you&#8217;d be trying to learn here is an <i>open</i> system&#8212;i.e., one that&#8217;s constantly getting refreshed by new microscopic degrees of freedom from its environment, which interact with the old ones in some complicated way.  So the relevant timescale is less like whatever&#8217;s needed for all the qubits in some isolated brain to decohere, than like whatever&#8217;s needed for all the qubits in the universe to decohere!</p>\n<p>On the other hand, even if we <i>were</i> just talking about an isolated brain, the relevant timescale for this sort of tomography (which incidentally, is closely related to what&#8217;s done in my <a href=\"http://theoryofcomputing.org/articles/v001a001/v001a001.pdf\" rel=\"nofollow\">BQP/qpoly paper</a>) could easily be orders of magnitude longer than an ~80-year human lifespan.</p>\n<p>Conversely, I explicitly noted in GIQTM that, in a deSitter patch with ~10<sup>122</sup> qubits, all of the qubits from the early universe <i>will</i> eventually either recede past our horizon or else get amplified to macroscopic scale: eventually, there will be no Knightian uncertainty left, so on the picture suggested here, no &#8220;opportunity for free will&#8221; either!  But ~10<sup>100</sup> years, the time for black holes at galactic centers to evaporate, seems like a lower bound on how long that would take.</p>\n]]>", "author": "Scott", "published": "2016-06-04 17:17:55+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>wolfgang #110:</p>\n<ul>If The Donald wins the election I would take it as strong evidence that we are trapped in a cheap video game.</ul>\n<p>Just yesterday, as it happens, Matt Damon made closely-related comments in his <a href=\"https://www.youtube.com/watch?v=b9nU5oKtFyo\" rel=\"nofollow\">MIT commencement speech</a>&#8212;a speech that explicitly discussed the simulation hypothesis and the views of Nick Bostrom and Max Tegmark, as well as the possibility of moving to a different simulated universe where Trump didn&#8217;t win the primary.</p>\n<p>Damon reasoned, correctly I think, that we should try to live interesting, awesome lives regardless of whether we&#8217;re living in a simulation or not.  Personally, I&#8217;d go even further than him, and say that the simulation hypothesis has no consequences for anything whatsoever&#8212;<i>until</i> it&#8217;s coupled with a proposal for testing it, at which point it has to play by the rules of any other kind of science (&#8220;reason to take seriously, rooted in actual details of the observed world, or GTFO&#8221;).</p>\n<p>In a yet further coincidence (evidence for the simulation hypothesis? \ud83d\ude42 ), yesterday <i>Vox</i> <a href=\"http://www.vox.com/2016/6/3/11837888/simulation-problem\" rel=\"nofollow\">ran an article</a> that explains the same positivist insight very nicely.  (Though the ending veers into philosophy that&#8217;s much more tendentious and arguable.)</p>\n]]>", "author": "Scott", "published": "2016-06-04 17:32:07+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Forgetting the &#8220;how is this related to consciousness&#8221; problem for a moment, how about a simulation scenario where the simulation maintainers, although not having anything superior to BQP, affect our decisions based on what happened in previous simulations; information we can&#8217;t have because it doesn&#8217;t exist in our universe? We can&#8217;t recreate that information because someone running loads of universes will always have better data than we do. Perhaps we can&#8217;t ever get enough data to nail down what they&#8217;re trying to achieve.</p>\n]]>", "author": "JollyJoker", "published": "2016-06-04 18:18:08+00:00", "title": "By: JollyJoker"}, {"content": "<![CDATA[<p>Following up on my #25,</p>\n<p>&#8220;I\u2019d expected to be roasted alive over my attempt to relate consciousness and free will to unpredictability, the No-Cloning Theorem, irreversible decoherence, microscopic degrees of freedom left over from the Big Bang, and the cosmology of de Sitter space.  Sure, my ideas might be orders of magnitude less crazy than anything Penrose proposes, but they\u2019re still pretty crazy!  But that entire section of my talk attracted only minimal interest.  With the Seven Pines crowd, what instead drew fire were the various offhand \u201cpro-AI / pro-computationalism\u201d comments I\u2019d made\u2014comments that, because I hang out with Singularity types so much, I had ceased to realize could even possibly be controversial.&#8221;</p>\n<p>I don&#8217;t know about consciousness and in my opinion predictability is only one aspect needed for understanding the free will issue. But predictability is, of course, an important issue on its own.  A possible explanation for non-predictability, a couple orders of magnitude less crazy than irreversible decoherence and microscopic degrees of freedom left over from the Big Bang (whatever it means), is a failure of quantum fault-tolerance and &#8220;quantum supremacy.&#8221; Such a possibility proposes a description for how do local quantum systems behave, a topic not settled from first principles from QM. (Moreover,  this explanation is supported by the standard noise models for noisy quantum circuits.) </p>\n<p>Of course, this possibility will be tested (and could be refuted) by various  experimental efforts in the next few years.</p>\n<p>(Regarding #96 it is indeed a plausible conjecture that QC can perform efficiently computations based on the  standard model, but proving it, even just for early basic such computations  from the 60s, will be a formidable task related and possibly of a similar difficulty to the gap mass problem.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2016-06-04 18:32:27+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Wonderful posts all , but I feel obliged to rain on the parade a little bit here and remind everyone that there is a YouTube video of Richard Feynman being asked by a journalist to explain in simple terms the attraction and repulsion of magnets (action at a distance) and was unable to do so. So if one of the greatest scientists of the 20th century can&#8217;t even explain magnets, FORGET about trying to explain consciousness , it&#8217;s laughable. Sure we have electro-magnetic theory that can give accurate results of various experiments but that doesn&#8217;t necessarily mean that we UNDERSTAND what the underlying principals of nature &#8220;really are&#8221;.</p>\n]]>", "author": "William Hird", "published": "2016-06-04 17:05:01+00:00", "title": "By: William Hird"}, {"content": "<![CDATA[<p>Hmm. So I have advanced technology that can sneak into &#8220;wild&#8221; people&#8217;s brains and look at what they are doing in detail, but I can&#8217;t predict their behaviour in advance because there are unpredictable random numbers coming in.</p>\n<p>What if I sneak into the room of a wild-type human one night, use my sufficiently advanced technology to replace the unpredictable RNG in her brain with a pseudorandom number generator so that she is now predictable, wait 24 hours, and then copy her brain, shoot her, and resurrect her? Would a court consider that murder, or criminal identity tampering equivalent to murder, and if so, when did I murder her: today, when I shot her, or yesterday, when I destroyed her unpredictable RNG?</p>\n<p>(There&#8217;s a jurisdictional issue. Today we were at a philosophy conference in New York, and yesterday we were at a philosophical electronics expo in Indiana. Indiana has the death penalty\u2015New York doesn&#8217;t. Will I go to the chair?)</p>\n<p>If I murder her when I turn off the unpredictability:</p>\n<p>1. Will she die if I turn it off and back on right away?</p>\n<p>2. Will she die if I turn it off, back her up, shoot her, resurrect her from backup and then turn it back on?</p>\n<p>3. Will she die if I replace her random number generator with a <i>different</i> random number generator?</p>\n]]>", "author": "Hannah", "published": "2016-06-04 19:48:26+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<p>William Hird #112: On the contrary, I&#8217;d say that we understand an enormous amount, probably more than almost any intelligent person before the scientific revolution would&#8217;ve imagined it possible to understand.  To complain that we don&#8217;t know the &#8220;true natures&#8221; of things seems like begging the question to me, because it ignores the central insight that made the scientific revolution possible in the first place&#8212;namely, that to know what a thing does, under all possible circumstances, <b>is</b> to know its true nature!</p>\n<p>Feynman, to take your example, <i>did</i> know something about the electromagnetic field, and even wrote whole books on the subject&#8212;have you looked at any of them? \ud83d\ude09  I don&#8217;t know the details of the incident, but if he declined to explain E&#038;M to a TV interviewer, doesn&#8217;t it seem likely that that had less to do with his inability to explain it at all, than with his inability to explain it <i>in one or two minutes</i>?</p>\n<p>(I do know that, when someone asked Feynman to explain in 15 seconds what he&#8217;d won the Nobel Prize for, he replied, &#8220;buddy, if I could do that, it wouldn&#8217;t have been worth the prize.&#8221;)</p>\n]]>", "author": "Scott", "published": "2016-06-04 19:57:06+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>@Scott</p>\n<p>Thank you for the link to the Vox article, I like the part where it says &#8220;What humans can assess for themselves is always partial, always provisional, always a matter of probabilities.&#8221;<br />\nWe had a debate about that a while ago, when I asked about the probability that 3*5 is not 15 &#8211; as the sheeple in this Matrix believe.<br />\n\ud83d\ude0e</p>\n]]>", "author": "wolfgang", "published": "2016-06-04 20:06:00+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Hannah #117: Personally, I&#8217;d say that your original tampering with the person&#8217;s brain could justly be prosecuted as murder.  There&#8217;s a wide spectrum of defensible views about personal identity, uploading, AI, etc., and my speculations in this post might be completely wrong.</p>\n<p>But to render someone&#8217;s brain mechanistically predictable, you&#8217;d essentially have to have nanorobots rebuild it neuron-by-neuron out of predictable components&#8212;something that seems <i>physically</i> much more extreme and invasive than just scooping out their cortex with an ice cream scoop!  (To reverse the ice cream scoop would &#8220;merely&#8221; require neurosurgery far beyond anything doable today.  To reverse the nanorobots would take an entirely different order of technology.)</p>\n<p>Now, presumably we agree that the ice cream scoop counts as murder!  In the nanorobot case, the harm is claimed to be mitigated by your creation of a new, mechanistically-predictable being, who&#8217;s behaviorally almost identical to the one you destroyed.  But is it <i>really</i> behaviorally almost identical?  How could you prove that?  Even if you could, the idea that you extinguished (or perhaps vastly altered or impoverished?) the person&#8217;s consciousness&#8212;that for one reason or another, consciousness would fail to transfer smoothly from the original substrate to the new, predictable one&#8212;seems well within the range of reasonable opinions.  Even if the person you did this to happened to think otherwise, still, you had no right to make a possibly-life-or-death metaphysical judgment on the person&#8217;s behalf.</p>\n<p>Verdict: Guilty. \ud83d\ude42</p>\n]]>", "author": "Scott", "published": "2016-06-04 20:17:36+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #90</p>\n<p>Thanks for clarifying your motive, e.g. that you feel rationality can&#8217;t hold for computable agents. All we&#8217;re saying (Vadim made a similar comment in #81) is that this thought represents a very personal contribution, not a mainstream idea.</p>\n<p>//</p>\n<p>Unrelated completly, you said you explained a bit how alphago and Watson do work. Alphago, it&#8217;s easy to find any technical detail one may dream of. But finding the technical details for Watson seems far more challenging. Do you know (or anyone!) where I can find it?</p>\n]]>", "author": "Jay", "published": "2016-06-04 22:02:49+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>@Scott #118<br />\n&#8220;I don&#8217;t know the details of the incident, but if he declined to explain E&M to a TV interviewer, doesn&#8217;t it seem likely that that had less to do with his inability to explain it at all, than with his inability to explain it in one or two minutes?&#8221;</p>\n<p>Well Scott no, did you see the video ( sorry I can&#8217;t do hyperlinks on my computer), it seems to me that he his clearly stating that he can&#8217;t explain action at a distance in general, not because he thinks the answer would be too long.<br />\n Of course he (Feynman) is also famous for saying that no one understands quantum mechanics either. So I reiterate my previous comment that it is silly to speculate on the physics of consciousness when ( according to RPF) we can&#8217;t really explain QM or magnets, or maybe lots of other things that would be pre-requisites for understanding consciousness.</p>\n]]>", "author": "William Hird", "published": "2016-06-04 22:27:30+00:00", "title": "By: William Hird"}, {"content": "<![CDATA[<p>Jay #121: I don&#8217;t actually know what you mean by &#8220;rationality can&#8217;t hold for computable agents.&#8221;  (For one thing, I don&#8217;t think anything in our universe violates the Church-Turing Thesis.)</p>\n<p>A better statement would be: I <i>don&#8217;t know</i> how to discuss rational decision-making for <i>copyable</i> agents.  (It might be possible, but I don&#8217;t know how, and I think people severely underestimate the difficulties.)</p>\n<p>Yes, I agree that whatever is original in what I said represents a personal contribution (have I ever made any other kind? \ud83d\ude09 ).</p>\n<p>On your other question: I attended a couple of talks by the Watson creators, and was mostly going on that, but <a href=\"https://www.scribd.com/doc/88582174/Ferrucci-Watson2010-Build-Watson-An-Overview-of-DeepQA-Project\" rel=\"nofollow\">here&#8217;s</a> a paper that seems helpful.</p>\n]]>", "author": "Scott", "published": "2016-06-04 22:33:59+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>William #122: It feels weird to debate what Feynman said or didn&#8217;t say if you can&#8217;t give me a link to the video.</p>\n<p>But if I do get to see it, my prediction is that I&#8217;ll find what you said to be a serious mischaracterization of what he said.  (Or <i>if</i> I&#8217;m wrong about that, then I&#8217;ll have no hesitation in saying that Feynman was wrong in this instance!)</p>\n<p>We really can go much deeper than &#8220;action at a distance,&#8221; by explaining it in terms of ripples in fields that propagate outward from a source and travel no faster than light.  And magnetism is just the logical consequence of combining the Coulomb force with special relativity.  And obviously Feynman knew all that.  And those are true, substantive things that he could have said in a minute or two.</p>\n]]>", "author": "Scott", "published": "2016-06-04 22:43:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott, this is a beautiful talk, summing up many of the relevant arguments in this debate. I especially liked that you point out that Penrose&#8217;s objection would not only ask for him to provide an argument for functionality that cannot be realized computationally but could be achieved in other ways, but that Penrose actually requires us to go beyond current physics, thereby showing how bold and daunting his proposal really is, and how far he is willing to go in his rejection of AI&#8217;s premises.</p>\n<p>I also agree with you and with the anti-priestly audience member that you would have deserved to be grilled primarily for hinging your notions of free will and identity on determinism and non-copyability. After all, free will and identity originate in our subjective feeling of agency, and our subjective construction of identity. It is not clear that these mental representations are in any way indicative of a deeper metaphysical reality that reflects cosmological properties. </p>\n<p>In other words, it is unconvincing to me that my agency would feel subjectively different if my cognitive processes supervene on a probabilistic or a deterministic universe computation. &#8216;Free will&#8217; should probably be treated as a label on my own mental representations of intentional actions that indicates &#8216;causally embedded with the discursive levels of cognition&#8217; or something like that, not as the amplification of probabilistic quantum processes. </p>\n<p>Likewise, my sense of identity seems not to hinge on the fact that I am unaware of successful low-level cloning experiments, but on mental representations that encodes my own personal narrative as an individual with a certain biography, a world-line that allows me to learn from previous experiences and extrapolate future developments. For this kind of identity, it seems to be necessary and sufficient that I believe to be sharing a biography with previous and future instances of what I consider to be me. If someone goes ahead and changes my mental representation to make me believe that I am Scott Aaronson, then I cannot see how I will not identify as Scott Aaronson, regardless of how well Scott Aaronson is cloneable. (It seems to be somewhat superfluous to point out that the Joscha that wakes up tomorrow will not be an exact clone of the Joscha that goes to bed tonight, and that I fully expect tomorrow&#8217;s Joscha to not care about that when it comes to experiencing his sense of identity.)</p>\n]]>", "author": "Joscha", "published": "2016-06-05 01:14:27+00:00", "title": "By: Joscha"}, {"content": "<![CDATA[<blockquote><p>&#8230;something that seems physically much more extreme and invasive than just scooping out their cortex with an ice cream scoop!</p></blockquote>\n<p>Okay, that is fair. The death penalty for me. But I think that that is relying on the intuition that the human brain is fragile and difficult to modify, and we want ideas that apply even in a machine intelligence era. So let me change the question to get rid of this problem. (Actually, I was originally going to say it like this, but the setup was too elaborate.)</p>\n<p>Suppose that even the wild people don&#8217;t have normal human brains any more. Everyone&#8217;s brain is modular. The main piece is a brain simulation running on a computer with no source of true randomness. There is a thermal noise module that generates unpredictable random numbers for the brain program to use. If the module is missing or broken, the computer uses pseudorandom numbers instead.</p>\n<p>The wild and tame people have identical brain architecture, except that the wild people have a functioning module that generates an unpredictable stream of random numbers, and the tame people don&#8217;t have a module and they are working with a predictable stream.</p>\n<p>So now I want to ask the same questions. Suppose that I have the kind of technology necessary to predict predictable people under predictable sensory input, and I do so on a regular basis for my hit reality TV show, &#8220;I Know What You&#8217;ll Do.&#8221; If I break someone&#8217;s unpredictability module so that I can predict them, is that murder, or just great television?</p>\n]]>", "author": "Hannah", "published": "2016-06-05 01:22:46+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<p>Hannah #126: Check out <a href=\"http://www.scottaaronson.com/papers/giqtm3.pdf\" rel=\"nofollow\">GIQTM</a> Section 5.3 (&#8220;The Gerbil Objection&#8221;), which puzzles over exactly this sort of issue.  Briefly, though, on the account we&#8217;re discussing, it&#8217;s not clear that <i>either</i> of the two types of humans would be conscious in your scenario!  Obviously, pure random numbers (let alone pseudorandom ones) aren&#8217;t enough for interesting unpredictability; instead we want irreducible <a href=\"https://en.wikipedia.org/wiki/Knightian_uncertainty\" rel=\"nofollow\">Knightian uncertainty</a>.  But even Knightian uncertainty seems like it can&#8217;t be enough either, if whatever produces it can be &#8220;cleanly decoupled&#8221; from the intelligent information processing&#8212;so that it&#8217;s feasible just to swap out the Knightian unpredictability source for something else, while leaving the cognitive part unaffected.  If you want it in slogan form, this is an account according to which consciousness <i>requires</i> fragility.</p>\n]]>", "author": "Scott", "published": "2016-06-05 01:51:23+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>Well , I think, at the end of the day&#8230;. the simplest hypothesis is that there&#8217;s no quantum magic: no quantum-gravity microtubule Penrose nonsense, no uncomputability and no &#8216;Knightian unpredictability&#8217; either.  I really think people are tying themselves in knots over this, and massively over-complicating and over-thinking this.  They want something that makes them &#8216;special&#8217; and &#8216;magical&#8217;, but the harsh reality is&#8230;.well&#8230;it&#8217;s probable that there really isn&#8217;t any ghost in the Turing machine.</p>\n<p>Consciousness is probably generated by a good old-fashioned algorithm describable as a classical Turing machine, probably quite a simple one.</p>\n<p>But the &#8216;bad news&#8217; (no quantum mystery-magic that makes us special) is also, if you think about it, &#8216;good news&#8217; in another sense: it means that creating AGI may actually be much simpler than is commonly believed!  It means that we can generate consciousness simply by typing in the right java program on our PC! \ud83d\ude00</p>\n<p>So why not just, for the sake of argument, *assume* that the solution to consciousness is a very simple algorithm, and see where that gets us?</p>\n<p>I&#8217;m inclined to think that the stuff you deal with in your own field (information, complexity) is probably highly relevant.  My strong suspicion is that consciousness is probably directly describable as some sort of practical complexity issue, which should be right up your ally!</p>\n<p>Have you considered investigating various algorithms to find ones where some sort of weird complexity limitations quickly come to the fore? &#8211; these sorts of algorithms would be the ones I&#8217;d suspect as having something to do with consciousness.</p>\n]]>", "author": "mjgeddes", "published": "2016-06-05 07:11:16+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>Nothing to comment on the current subject, Dr. Aaronson, but I write to shortly thank you. I read yesterday a couple of your posts and interviews + one thesis I think you linked. They really unlocked the QC for me.</p>\n<p>Even if your views of humankind seem to be somewhat pessimistic, sometimes \ud83d\ude42 &#8211; you seem to be a remarkable populariser of your science. Were already as a young man, it seems. Keep up the good work both in your educational as well as in your scientific efforts.</p>\n<p>And this oracle &#8211; the best I managed to get in long sessions was < 55%. Slightly annoying, as the program appears to be very dumb. Like losing every game to your PocketFritz&#8230; But I put the link forward to annoy my friends, instead.</p>\n<p>Greets from Finland.</p>\n]]>", "author": "J. Sketter", "published": "2016-06-05 10:13:40+00:00", "title": "By: J. Sketter"}, {"content": "<![CDATA[<p>Ah, sorry, thank you. Okay, it seems like that definition is thought-experiment-proof. Actually I think we are practically saying &#8220;if there is a thought experiment that causes a philosophical problem, then it&#8217;s not consciousness.&#8221; So let me go in a different direction. What if it is physically possible in theory to predict someone, but practically impossible, so that these philosophical problems never come up in real life?</p>\n<p>I&#8217;m not sure if these concrete examples are interesting or annoying, but&#8230; Suppose that it is 2100, we have a complete description of physical law (and we know that somehow), and it is possible to predict or copy a human brain, but you need a solid sphere of detectors, computronium, supports, and cooling systems extending out to about a light-minute, with a little seat in the middle for the person, and that is the theoretical best you can do. And there is no chance of building something like that any time soon.</p>\n<p>(Even assuming perfect technology, a solid sphere of that size would mass something like 12000-32000 times the mass of the sun, and it would take hundreds of years just to collect enough mass together for relativistic reasons.)</p>\n<p>However, there&#8217;s a remote possibility that a Kardashev III civilisation with peculiar motivations have built an intelligent-being-predictor out of a few thousand of their solar systems and it is now on its way to Earth.</p>\n<p>Am I conscious, or is it necessary to eliminate this remote possibility? If I manage to die without being predicted or copied, and my brain is unrecoverable after my death, then can we say that I was conscious in retrospect?</p>\n<p>(If I can get away with that, then here&#8217;s a followup question: what if it is physically possible and easy to predict a human brain with the technology available to my civilization, but it is very illegal, and so it never actually happens to anyone? What if I work at the only company that can do it, and we are strictly prohibited from using the machines to do that? &#8220;No philosophical crises about consciousness for 196 days!&#8221;)</p>\n]]>", "author": "Hannah", "published": "2016-06-05 13:36:25+00:00", "title": "By: Hannah"}, {"content": "<![CDATA[<p>Scott #123</p>\n<p>Yes, I meant copyable agents&#8230; although, on second thought, isn&#8217;t any copyable agent computable, and any computable agent copyable? Can you provide a counterexample?</p>\n<p>No, sometime you make a contribution (such as &#8220;Shor I&#8217;ll do it&#8221;) that I wouldn&#8217;t call &#8220;very personal&#8221;, because the science behind it is already mainstream even if the presentation is deliciously original. The point is, saying that there is a difficulty for copyable agent (such as a computer program) to behave rationnaly is something that is not mainstream at all. But sometime you talk as if this was a given. Maybe you should dedicate a paper just on this topic.  </p>\n<p>Thank you for the link. That&#8217;s the best I read on Watson, even though the lack of meat is completly frustrating.</p>\n]]>", "author": "Jay", "published": "2016-06-05 13:50:44+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>If free photons turn out to have a mass of a pico-femto-eV then it will break the argument-from-principle that recoherence is forbidden.  It would probably leave an argument from practicality intact. That the speed-of-light is an absolute barrier is better put that the speed-of-massless-particles is an absolute barrier.  There is nothing in quantum mechanics that requires there to be massless particles.  </p>\n<p>The thought experiment that goes with this would be: can you make a conscious entity out of particles that don&#8217;t couple to any massless degrees of freedom?</p>\n]]>", "author": "Andrew Foland", "published": "2016-06-05 14:01:39+00:00", "title": "By: Andrew Foland"}, {"content": "<![CDATA[<p>Andrew #132: Thanks; that&#8217;s another possibility for falsifying this account that I hadn&#8217;t thought of!  Or perhaps more precisely: I suppose the &#8220;cosmological/multiverse interpretation of quantum mechanics&#8221; would be falsified if, not only were there no massless particles, but there were no single particle of maximum speed, only an infinite hierarchy of particles that get closer and closer to c.</p>\n]]>", "author": "Scott", "published": "2016-06-05 14:25:19+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Jay #131: The account I&#8217;m discussing here is <i>precisely</i> one according to which agents would be &#8220;computable but not copyable&#8221;&#8212;in the sense that, if you knew their state, then there&#8217;d be no obstruction whatsoever to simulating them on a computer, but you <i>can&#8217;t</i> learn their state to a high enough accuracy without destroying them.  I don&#8217;t know whether <i>our</i> world is like that, but it&#8217;s very clearly a logically possible world.</p>\n<p>Conversely, we can also imagine a world where agents would be copyable but not computable!  (E.g., a world where we were all pieces of software running on classical digital computers, <i>but</i> ones that had the ability to tap into an oracle for the halting problem&#8230;)</p>\n]]>", "author": "Scott", "published": "2016-06-05 14:31:06+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>So many comments here that I may be hitting topics already touched on.</p>\n<p>&#8220;And what\u2019s done with wetware, there\u2019s no reason to think couldn\u2019t also be done with silicon.  If your neurons were to be replaced one-by-one, by functionally-equivalent silicon chips, is there some magical moment at which your consciousness would be extinguished? &#8221;</p>\n<p>I really never understood how this would actually be done. Communication between neurons is done with flows of ions (sodium, potassium I think primarily) through membranes. The silicon neuron would need to have a similar interface if it were to communicate with other living neurons although later it might be converted to wire or some other form of interface. What would power the silicon neurons? Living neurons derive there power from chemicals. The chip would need to be able power itself from the same source. So for both power and input/output it would need to have something that is quasi-biological if not actually biological. What would the boundary be like between silicon and living material to enable the silicon chip to actually replace the biological neuron.</p>\n<p>I think part of the problem is that we are looking neurons as simple input and output machines. Perhaps they are but how do we go from that assumption or belief to the idea that consciousness arises simply from these actions of input and output?</p>\n<p>In some ways we are thinking too hard about this. Consciousness is something that arises precisely from the complex carbon molecules that constitute living material. In that case it would have an evolutionary origin and couldn&#8217;t be replaced by silicon.</p>\n<p>I think there is also frequently a lack of clarity in many different ways the term &#8220;consciousness&#8221; is used.</p>\n<p>Consciousness is frequently associated with intelligence but intelligent behavior can even be found in slime molds.</p>\n<p><a href=\"http://www.nature.com/news/how-brainless-slime-molds-redefine-intelligence-1.11811\" rel=\"nofollow\">http://www.nature.com/news/how-brainless-slime-molds-redefine-intelligence-1.11811</a></p>\n<p>Consciousness is often taken to mean self-awareness. In this case we use things like the mirror test to distinguish conscious creatures. This limits consciousness to a select group &#8211; humans, some other primates, dolphins and some whales, and bizarrely (according to Wikipedia) ants.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Mirror_test\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Mirror_test</a></p>\n<p>Others want to think of consciousness associated with an advanced capability of symbol manipulation. In this case, only humans would likely be conscious and the origin of this ability probably goes back to use of tools and development of language. Mathematics arises from this ability at symbol manipulation and the idea is just an inadvertent side-effect is probably not correct since logic and structure are inherent in language, ritual activity, and social structure. Numbers are language and mathematical concepts.</p>\n<p>Consciousness, as I think of it, arose as a control mechanism for the organism. The brain is near the mouth, the eyes, and the ears and the spinal cord runs the length of the digestive system. It isn&#8217;t hard to imagine the purpose it serves. Its operation certainly involves algorithmic-like activities but that doesn&#8217;t mean it can be reduced to them.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2016-06-05 14:36:12+00:00", "title": "By: James Cross"}, {"content": "<![CDATA[<p>Scott #79</p>\n<p>Thanks for the reply and I see you handled what I really wanted to ask like the true zen master that you are \ud83d\ude42</p>\n<p>I simply feel that TMs are too powerful a concept to be useful in understanding the mind and its too early to commit to the kind of math needed to talk about the mind. We need to do more neuroscience.</p>\n<p>On the other hand, there is a new preprint out: <a href=\"http://biorxiv.org/content/early/2016/05/26/055624\" rel=\"nofollow\">Eric Jonas, Konrad Kording, Could a neuroscientist understand a microprocessor? [doi: </a><a href=\"http://dx.doi.org/10.1101/055624%5D\" rel=\"nofollow\">http://dx.doi.org/10.1101/055624%5D</a> that you may find interesting.</p>\n<p>Here&#8217;s the abstract:</p>\n<blockquote><p>There is a popular belief in neuroscience that we are primarily data limited, that producing large, multimodal, and complex datasets will, enabled by data analysis algorithms, lead to fundamental insights into the way the brain processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. Here we take a simulated classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the processor. This suggests that current approaches in neuroscience may fall short of producing meaningful models of the brain.</p></blockquote>\n]]>", "author": "unapologetically_procrastinating", "published": "2016-06-05 14:40:45+00:00", "title": "By: unapologetically_procrastinating"}, {"content": "<![CDATA[<p>@Scott #133</p>\n<p>>> no massless particles</p>\n<p>But this shows that something is not quite right with your interpretation imho.<br />\nThe interpretation of quantum theory depends on whether photons have exactly zero mass or almost zero mass?<br />\nAnd understanding the consciousness of some apes on a tiny planet living usually less than 100 years significantly changed when the redshift of far away galaxies was measured in the late 90s ?</p>\n]]>", "author": "wolfgang", "published": "2016-06-05 15:32:01+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>Scott #134</p>\n<p>Ok, so let&#8217;s try to recap the worldview you suggest:</p>\n<p>1) human mind can have an effective description, computable and copyable, so that a computer can pass the Turing test but would not be trully conscious (notwithstanding whether we *should* treat it as if it was). </p>\n<p>2) human mind is best described by a quantum computer which use a source of freebits, so that it is computable but not copyable, and, critically, the contribution of the freebits is non trivial (notwithstanding the precise mechanism that then provides consciousness). </p>\n<p>We can certainly *imagine* that this is the reality. However, it would be far easier if you could provide an example for which one can *demonstrate* that this set of properties is indeed possible (namely, a quantum algorithm that does something non trivial using freebits, but for which an effective, computable description holds even without the freebits contribution).</p>\n<p>In the same vein, your point that there are situations in which a computer program would find hard to decide rationaly would be far easier to understand if you could provide a concrete example (free from self-contradictions). Extra Turing points if it depends on freebits. \ud83d\ude42</p>\n]]>", "author": "Jay", "published": "2016-06-05 15:48:19+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>Another thing related to predictability that was raised in my 2012 debate with Aram Harrow Aram&#8217;s second thought experiment (from the <a href=\"https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/\" rel=\"nofollow\">debate&#8217;s 4th post</a>). Of course, a noiseless quantum computer is predictable, and Aram proposed that starting with a noisy quantum computer (or another quantum system) we can embed it into a noiseless larger quantum computer of a sort, by including the environment that governs the noise in the description of the &#8220;computer.&#8221;  (This argument is similar to some arguments in this discussion.) After a long exchange of comments (ending <a href=\"https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/#comment-19153\" rel=\"nofollow\">with this one</a>) we came to the conclusion that pretty much the only way to identify a non-trivial noiseless (or predictable) quantum system using this idea is to do something as drastic as taking the entire universe.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2016-06-05 19:49:12+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Scott, you mention that you weren&#8217;t roasted alive about your speculation in the Ghost article, about Knightian uncertainty from some cosmological phenomenon being a source of free will.  Part of this might be because the topic of this double talk was Penrose&#8217;s theories, not yours, and the audience was too well-behaved to bring up your crazy theories, for it would count as an ad hominem attack unless you mentioned them first.  But I&#8217;d like to mention why I am not roasting you about those theories.</p>\n<p>I do think that both of your theories are crazy.  I have read Penrose&#8217;s book: I found it when searching for Martin Gardner in the library catalog, shortly after Gardner died in 2010, and found &#8221;The Emperor&#8217;s New Mind&#8221; which has a foreword by Gardner.  It&#8217;s a nice book that tries to explain a lot of science concepts in a popular way.  But that thing about humans being able to break out of the limits of G\u00f6del&#8217;s theorem, and solving uncomputable problems, that sounded totally crazy to me at that time.  It still sounds crazy after this blog entry.  And as for your Ghost paper, I&#8217;m not qualified to judge the physical part that there are particles left over from the big bang whose quantum states have not been examined since then, but I don&#8217;t think interpreting these as bringing Knightian uncertainty is not a useful notion, and I don&#8217;t think it&#8217;s relevant for trying to predict that you can&#8217;t simulate humans accurately, and I don&#8217;t think it helps understand free will either. </p>\n<p>But what saves both Penrose&#8217;s book and your Ghost paper is that you presented them as a humble speculation, not as some undisputable truth and revelation.  Penrose was very clear in his book, he distinguished which parts of what he tells are accepted scientifical fact, and which part are just his speculation that even he wasn&#8217;t sure about.  Your article was similarly clear.  Neither of you tried to do anything malicious with these speculation: you weren&#8217;t trying to set up yourself as humanity&#8217;s next prophet, nor did you try to sell cosmic radiation sensor enhancing free-will balm.  You weren&#8217;t trying to tell that Einstein was wrong, or accuse the whole institution of academia with conspiring to make your results hidden, or make insulting statements like \u201ccubeless americans deserve &#8211; and shall be exterminated\u201d.  You didn&#8217;t even try to dub your speculation \u201ca new kind of science\u201d.  This is the reason why I didn&#8217;t call for burning you on stake, I didn&#8217;t stop reading your blog when you wrote Ghost, and I hope it&#8217;s also the reason why the spectators liked your panel with Penrose.</p>\n<p>&#8212;-</p>\n<p>Now I have a question for you, Scott.  You say that part of the reason why you disagree with Penrose is that you are sure the rules of physics are computable, and gravitational quantum effects won&#8217;t let you give physical tools to actually solve the halting problem.  I guess from your previous entries about black firewall paradox and its information theory connections that you also think the rules of physics must also be computable in quantum polynomial time, and that the physical reality won&#8217;t just let you solve PSPACE problems by using time travel based on general relativity.  Do you believe this one? Is your belief in the former (computable physics) much stronger than your belief in the latter (quantum polynomial time physics)?</p>\n]]>", "author": "jonas", "published": "2016-06-05 20:21:27+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>I read your philosophical essays a couple of years back, great stuff! I was convinced that unitarily evolving quantum processes don&#8217;t seem to be alive. But aren&#8217;t your arguments for that position also obvious and serious criticisms of Many-worlds interpretation, which (I imagine) is about positing unitary quantum theory as the fundamental stuff of the world?</p>\n]]>", "author": "Esso", "published": "2016-06-05 21:00:32+00:00", "title": "By: Esso"}, {"content": "<![CDATA[<p>Esso #141: Reread the post (or try <a href=\"http://www.scottaaronson.com/blog/?p=1951\">Could A QC Have Subjective Experience?</a>).  In the &#8220;cosmological interpretation,&#8221; the whole point of talking about our deSitter boundary is to give a definite criterion for when a measurement has happened, in a completely unitary picture of physics that would otherwise become unadulterated Many-Worlds.</p>\n]]>", "author": "Scott", "published": "2016-06-05 21:20:14+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>jonas #140: Yes, I do conjecture that BQP is the limit of what the physical world lets us compute in polynomial time (or at least, I regard <i>investigating the truth or falsehood of that conjecture</i> as one of the great scientific quests of our time).  More strongly, I conjecture that no physical process lets us solve NP-complete problems in polynomial time.  And more strongly still, I conjecture that no physical process lets us solve uncomputable problems.  I don&#8217;t know the exact rate at which the beliefs become stronger as you go down the list.</p>\n]]>", "author": "Scott", "published": "2016-06-05 21:23:38+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>wolfgang #137:</p>\n<ul>The interpretation of quantum theory depends on whether photons have exactly zero mass or almost zero mass?</ul>\n<p>All else equal, I&#8217;d <i>rather</i> have an interpretation of QM that depends on nontrivial facts about the physical world, and that could be falsified if those facts turned out otherwise, than one that&#8217;s isolated by design from everything else we know about the universe.  (Though I wouldn&#8217;t say that&#8217;s the goal with the cosmological view.  The goal is just to give a definite criterion for when a measurement has happened, without breaking the rules of unitary QM.  The vulnerability to future empirical findings then comes out as a byproduct.)</p>\n<ul>And understanding the consciousness of some apes on a tiny planet living usually less than 100 years significantly changed when the redshift of far away galaxies was measured in the late 90s ?</ul>\n<p>Our understanding of where the apes came from significantly changed when Charles Darwin examined the beaks of finches in the Galapagos islands.  Our understanding of what the apes are made of changed significantly when people in early 20th-century Europe did experiments on radioactive ores (and also, as it happens, spectroscopy on distant stars).  Understanding, you might say, &#8220;doesn&#8217;t follow the rules of causality,&#8221; in the sense that learning about A can suddenly illuminate B even though B is far in the past or the future, or billions of light-years away.</p>\n]]>", "author": "Scott", "published": "2016-06-05 21:38:25+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #143:</p>\n<p>I agree with you on &#8220;no physical process lets us solve uncomputable problems&#8221;, but I don&#8217;t agree about the others. Could you elaborate why you feel NP-complete problems should not be solvable in polynomial time? Inductive reasoning? What about major theories in Physics that might change things (provide new operators)?</p>\n]]>", "author": "Flavio Botelho", "published": "2016-06-05 21:47:28+00:00", "title": "By: Flavio Botelho"}, {"content": "<![CDATA[<p>Hannah #130:</p>\n<ul>Actually I think we are practically saying \u201cif there is a thought experiment that causes a philosophical problem, then it\u2019s not consciousness.\u201d</ul>\n<p>Exactly. \ud83d\ude42</p>\n<p>(Or we might say: as long as the known laws of physics make it totally unclear whether the thought experiment could even be done to humans, <i>first clarify that issue</i>, before the philosophical problem urgently presses itself on our attention&#8230;)</p>\n<ul>What if it is physically possible in theory to predict someone, but practically impossible, so that these philosophical problems never come up in real life?</ul>\n<p>In all my writing about these issues, my working assumption has been that whatever criteria we give had better be rooted in fundamental physics, rather than in contingent facts about what is or isn&#8217;t technologically feasible for humans.  And you&#8217;re absolutely right that that influences the choices I make: someone who rejected that assumption would choose differently.</p>\n<p>For me, the decision tree looks something like this:</p>\n<p>(1) If consciousness somehow reflects a fundamental aspect of reality, then our criteria for it had <i>better</i> not be rooted in the contingencies of present-day technology!</p>\n<p>(2) Conversely, if consciousness doesn&#8217;t reflect a fundamental aspect of reality, then any attempt to give criteria like these is doomed from the start.  The universe is then just one damn quantum field configuration after another, and certain computations in these fields are what we elect to call &#8220;consciousness.&#8221;  <i>However,</i> you don&#8217;t get the liberty of saying this without then worrying about all the thought experiments my Singularity friends worry about, and that I mentioned in the post: would you get into the teleportation machine or not?  would you consent to be painlessly euthanized and then replaced by a giant lookup table?  If it were a thousand lookup tables, would that be a &#8220;net win&#8221; for you?  Etc.</p>\n<p>Having said that, even if you accepted view (2), you could still re-ask many of the same questions that I asked in these writings, except now no longer &#8220;absolute&#8221; but &#8220;relativized to a particular level of technology.&#8221;  (Exactly as you were doing in your comment.)  E.g., even if it&#8217;s physically possible to predict everything a given person will say or think without harming them&#8212;they can just sit in a seat in the middle of the prediction contraption, as you said&#8212;still, <i>how big</i> would the prediction contraption need to be?  This sort of question would have roughly the same relation to the questions I was asking, as complexity has to computability.</p>\n]]>", "author": "Scott", "published": "2016-06-05 22:07:56+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Jay #138: Sorry, you went somewhat off the rails at (2).  I <i>don&#8217;t</i> think there&#8217;s evidence that the brain is a quantum computer in any interesting sense.  What it appears to be, is a classical computer with chaotic sensitivity to amplified microscopic events (also known as an analog computer).  To this view, which you might call the 100%-standard neuroscience view, all I add is the further question of whether the microscopic events can described completely by a thermal noise source that &#8220;cleanly decouples&#8221; from the digital part, or whether there&#8217;s also a Knightian component.</p>\n]]>", "author": "Scott", "published": "2016-06-05 22:19:55+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Flavio #145: Read my <a href=\"http://www.scottaaronson.com/papers/npcomplete.pdf\" rel=\"nofollow\">NP-complete Problems and Physical Reality</a> (10 years old, but still reflects a lot of my thinking about these things).</p>\n<p>By far the biggest thing missing from our picture of fundamental physics, of course, is quantum gravity.  But far from creating possibilities for hypercomputation, quantum gravity (because of the Bekenstein bound) seems to close off hypercomputation proposal opened up by na&iuml;ve consideration of previous theories!  AdS/CFT also played a large role in convincing many physicists that, whatever is the right quantum theory of gravity for our world, it ought to be describable as an &#8220;ordinary quantum theory,&#8221; which would then presumably be efficiently simulable by a quantum computer.</p>\n]]>", "author": "Scott", "published": "2016-06-05 22:37:13+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott re #146: The problem is, it&#8217;s difficult to regard those problems in abstract, rather than connecting to our present or near future technology level and other realistic complications.  I wouldn&#8217;t get into a teleportation machine (unless I&#8217;m really desperate), but that&#8217;s nothing to do with how consciousness works.  I wouldn&#8217;t get into it because I beleive the teleportation machine is made by a profit-hungry company who pushed an early prototype to production without making enough steps for security, and there&#8217;s a high chance that using the teleportation machine has side effects harming my body and mind, possibly in a way that the symptoms won&#8217;t be obvious until two decades later.</p>\n]]>", "author": "jonas", "published": "2016-06-05 23:41:20+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<p>>In short, I see it as a central selling point for the picture I\u2019m discussing that it would not lead to any class of intelligent beings being arbitrarily discriminated against, because of magical/metaphysical criteria of no empirical relevance (\u201cquantum pixie-dust\u201d). Rather, the beings in question would already have a radically unfamiliar status in law and morality, before we even entered into theoretical questions about consciousness, for purely empirical reasons related to the beings\u2019 copyability.</p>\n<p>The thing with predictability here is, how far back are you posting the necessary predictability? nanoseconds, microseconds, milliseconds, seconds, minutes, hours, days, years? If it is just a few microseconds of predictability, once the spine has sent down the action potentials barring noise in muscular junctions or muscular variability, the prediction should be 100% with or without any quantum effect occurring in the brain, it should also be indistinguishable from that of a machine activating the spine&#8217;s nerves directly in terms of follow up unpredictability.</p>\n<p>There are things that might make indefinitely back predictability impossible even if the system were entirely deterministic even in a computer, a cosmic ray could flip some value or result in a mutation killing some neuron(for the biological case).</p>\n<p>Also resting the distinction of consciousness on predictability, that would only be a functional distinction if it was absolutely impossible to predict the evolution of a system with the postulated quantum phenomena.   But it is not impossible, it would only be impossible if there was an infinity of possible states at each transition, but it is claimed that the number of possible configurations is finite.   Thus even though the probability is relatively low there is always a possibility of actually successfully predicting the evolution of any possible sequence no matter what&#8217;s causing it.  </p>\n<p>After time has passed and it lay in the unchanging solid as rock past, it will either prove false, partially correct or hundred percent correct.   In the cases were it proves one hundred percent correct, it is a successful prediction that might have indefinite length.</p>\n<p>>the person\u2019s consciousness\u2014that for one reason or another, consciousness would fail to transfer smoothly from the original substrate to the new, predictable one\u2014seems well within the range of reasonable opinions. </p>\n<p>It&#8217;s not just predictability.  For example the number of possible utterances is finite, even a random sampling could turn out to produce a prediction, even an arbitrarily long one, though the probability is low.   So it is not just the ability to predict, as that is possible albeit by chance(unless true randomness does not exist in which there may exists a mode to do so with absolute certainty), but the ability to predict with a certain justification of whether or not some specific quantum phenomena is present.</p>\n<p>And again with regards to prediction we apply it in the future direction, not the backwards direction as looking towards the past it is easy to &#8216;predict&#8217; all the prior actions.   Isn&#8217;t this assuming that past, present and future are different in kind?   Aren&#8217;t we bringing absolute simultaneity in to create this division, some would have issue with that?</p>\n<p>>In some ways we are thinking too hard about this. Consciousness is something that arises precisely from the complex carbon molecules that constitute living material. In that case it would have an evolutionary origin and couldn\u2019t be replaced by silicon.</p>\n<p>This depends on what the actual cause of consciousness is.   Is it due to some form of information processing , storage or a combination of storage and processing?  If so billiard boards, electrons, water, it doesn&#8217;t matter the substrate it will only change the performance but not the nature of information processing.   Now if it depends on some form of phenomena, perhaps a physical property, then it may truly need something that taps into that to actually be conscious.<br />\nWay I see it, it is already &#8216;known&#8217; that what the brain receives through the senses can be reproduced by an entirely digital system.   So all that we know from primary senses can actually come in principle from digital data and algorithms operating on it.   The supposition that conceptions about entirely nonrepresentable ideas is real, with &#8216;special&#8217; phenomena, undefinable things, well those might simply be imaginary with no correspondence in reality.</p>\n<p>PS</p>\n<p>Regards Boltzmann brain, which I think it was suggested wouldn&#8217;t be conscious even if it was biologically and physically identical.   Some have suggested the universe pop-ed out of the vacuum in a similar way, perhaps I&#8217;ve misheard.       But why would we consider a collection of matter able to become conscious after emerging from the vacuum, and another collection of matter not be able to do so after doing the same?    Is it the volume of matter involved? the time?  The inflation field that accompanied the universe? are we assuming all of time and everything started with the universe&#8217;s origin making it different from an isolated event such as a future Boltzmann brain?</p>\n]]>", "author": "Darien S", "published": "2016-06-05 23:54:26+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>Scott #148: [Quantum gravity seems to close off hypercomputation.]</p>\n<p>From our limited knowledge of effective quantum gravity it appears different from renormalizable quantum field theories in requiring an infinite number of measurements to determine all couplings and make predictions at very high energies. Isn&#8217;t that itself already at least vaguely analogous to hypercomputation, where we must run a computer program for an infinite number of steps to determine it doesn&#8217;t halt?</p>\n]]>", "author": "Anonymous", "published": "2016-06-06 02:41:57+00:00", "title": "By: Anonymous"}, {"content": "<![CDATA[<p>#150 </p>\n<p>&#8220;Way I see it, it is already \u2018known\u2019 that what the brain receives through the senses can be reproduced by an entirely digital system. So all that we know from primary senses can actually come in principle from digital data and algorithms operating on it. &#8221;</p>\n<p>Reproduced seemly means being about to produce the same digital output from the same input. It doesn&#8217;t mean that it produces the same qualia that is involved with consciousness.</p>\n<p>I think there is a good deal algorithmic processing involved in seeing, for example. But almost all of it occurs below the level of consciousness.</p>\n<p><a href=\"https://broadspeculations.com/2015/08/30/blindsight/\" rel=\"nofollow\">https://broadspeculations.com/2015/08/30/blindsight/</a></p>\n<p>&#8220;The supposition that conceptions about entirely nonrepresentable ideas is real, with \u2018special\u2019 phenomena, undefinable things, well those might simply be imaginary with no correspondence in reality.&#8221;</p>\n<p>Not sure what is meant here but it seems to me you are on shaky ground if you are arguing that sensual perceptions are more real than conceptions or nonrepresentable ideas. The eyes and the brain do not see reality but actively shape it. See Visual Intelligence: How We Create What We See.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2016-06-06 09:27:44+00:00", "title": "By: James Cross"}, {"content": "<![CDATA[<p>Anonymous #151: No, you&#8217;re conflating two completely different things.  The non-renormalizability of GR is why it&#8217;s so hard to <i>guess</i> the right quantum theory of gravity by applying standard &#8220;quantization&#8221; procedures; it&#8217;s a sign that new ideas are needed.  It says nothing about the computational complexity of simulating a quantum gravity theory once you did have it.</p>\n]]>", "author": "Scott", "published": "2016-06-06 12:57:42+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>[&#8230;] Or, here\u2019s my personal favorite, as popularized by the philosopher Adam Elga: can you blackmail an AI by saying to it, \u201clook, either you do as I say, or else I\u2019m going to run a thousand copies of your code, and subject all of them to horrible tortures\u2014and you should consider it overwhelmingly likely that you\u2019ll be one of the copies\u201d? (Of course, the AI will respond to such a threat however its code dictates it will. But that tautological answer doesn\u2019t address the question: how should the AI respond?) [&#8230;]</p>\n]]>", "author": "AI | An Interior Forest", "published": "2016-06-06 14:06:27+00:00", "title": "By: AI | An Interior Forest"}, {"content": "<![CDATA[<p>>Not sure what is meant here but it seems to me you are on shaky ground if you are arguing that sensual perceptions are more real than conceptions or nonrepresentable ideas. The eyes and the brain do not see reality but actively shape it. See Visual Intelligence: How We Create What We See.</p>\n<p>My point is, that the brain could easily be connected to machinery that through some manner of stimulation reproduces all the sensory input.  Aka, our &#8216;known&#8217; reality.   To postulate that within reality lay unknown perhaps unrepresentable phenomena, is what I take lay on less solid footing.</p>\n]]>", "author": "Darien S", "published": "2016-06-06 14:29:57+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>Scott #90<br />\n&#8220;thinking through the full strangeness of a world with copyable minds!&#8221;</p>\n<p>But would it be any stranger than a world where we could clone dog turds perfectly?<br />\nIf a mind/brain is nothing more than a certain arrangement of atoms, still following the same laws of physics as the atoms in a dog turd, why would it matter?<br />\n&#8220;Making decisions as a rational agent&#8221; is still nothing more than the atoms of my brain following their dynamics, unless you do believe that the mind is a secret sauce having causal power on the matter that instantiates it, somehow taking unremarkable initial conditions and turning them into some special state.</p>\n<p>Does the nature of a CPU change based on what high level language/algorithm it&#8217;s running?<br />\nAre the algorithms telling the CPU what to do or are the transistors just going about their business (as per spec of the hardware designers), whether they&#8217;re running &#8220;hello world&#8221; or some fancy deep learning algo?</p>\n<p>All matter is interconnected, in time and space, so systems don&#8217;t magically exist/appear in isolation. The problem is that &#8220;systems&#8221; as a finite clump of space/time/matter are a leaky abstraction, the boundary of a system is the initial condition of another. But we try to ignore the initial conditions!</p>\n<p>Whatever property of consciousness/rational-decision-making matter exhibits right now, it must have been present all along, in the initial conditions of the universe.</p>\n]]>", "author": "fred", "published": "2016-06-06 14:38:54+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>fred #156:</p>\n<ul>But would it be any stranger than a world where we could clone dog turds perfectly?</ul>\n<p>This will be my last comment in this thread, since I&#8217;d like to move on to a new topic rather than going around in circles repeating what I said in GIQTM.</p>\n<p>I don&#8217;t want to know &#8220;the nature of consciousness&#8221; as a matter of inert metaphysical curiosity.  Rather, I want to know the answers to questions like: <b>should I get into the teleportation machine, or shouldn&#8217;t I?  should I agree to having myself scanned and uploaded into a computer?  what about having myself replaced by a huge lookup table?  should I sign up for cryonics, expecting to &#8216;wake up&#8217; in a far future where nanobots have reconstructed me?</b></p>\n<p>Indeed, as far as I&#8217;m concerned, there might be nothing that it <i>means</i> to understand consciousness, other than to be able to answer all possible questions of that kind.</p>\n<p>And if there&#8217;s a dog turd that&#8217;s capable of formulating these sorts of questions, then let it worry about whether <i>it</i> should get into the teleportation machine.  Indeed, even if the dog turd were merely capable of intelligent behavior, I might worry about these questions on the dog turd&#8217;s behalf.</p>\n<p>But one thing that I know for certain: you can&#8217;t escape the need for <i>some</i> criterion to decide which physical realizations of &#8220;your computer program&#8221; are or aren&#8217;t able to instantiate your consciousness.  If you think you <i>can</i> escape this, then why not simply kill yourself now?  After all, the laws of physics are time-reversible, so the state of the universe will still contain all the information needed to reconstruct you.  In that sense, we could say that the universe will continue to contain a program that perfectly simulates you; indeed, even a program that simulates you living a fulfilling life and having a wonderful time (as well as programs that simulate you having a horrible time, etc.).  Someone could even claim that the universe is &#8220;executing&#8221; that program; they just need to apply a method of interpretation to the output that involves uncomputing everything that&#8217;s happened between when you killed yourself and the current time, then running the equations forward under a different condition.</p>\n<p>So, again: some criterion is necessary.  You could try for a complexity-based criterion, like I did in Section 6 of <a href=\"http://www.scottaaronson.com/papers/philos.pdf\" rel=\"nofollow\">Why Philosophers Should Care About Computational Complexity</a>.  Or you could try for an unclonability-based criterion, like I did in GIQTM.  But if you want to take the line that we&#8217;re just evanescent patterns of computation, and <i>therefore</i> nothing more needs to be said about us than about dog turds&#8212;well then, a sorcerer comes along and offers to transform you into an astronomical-sized dog turd, one that happens to contain a lookup table caching your responses to all possible questions you could be asked within (say) a 100-year lifespan.  Do you agree to that?</p>\n<p>If you don&#8217;t, then you&#8217;ve implicitly conceded that something more <i>does</i> need to be said.</p>\n]]>", "author": "Scott", "published": "2016-06-06 17:29:15+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #157</p>\n<p>&#8220;you can\u2019t escape the need for some criterion to decide which physical realizations of \u201cyour computer program\u201d are or aren\u2019t able to instantiate your consciousness.&#8221;</p>\n<p>According to Hofstadter in &#8220;I Am a Strange Loop&#8221;, instantiating a consciousness is probably not a binary thing, but a continuous spectrum.</p>\n<p>E.g. when someone dies they don&#8217;t totally disappear instantly, but a tiny bit of who they are lives on for a while through the consciousness/memories of those who knew him/her.</p>\n<p>And as you start copying your own brain better and better, you&#8217;ll end up with versions of yourself doing a better and better job at proving they&#8217;re you and debating your ideas as to why they should be terminated!</p>\n]]>", "author": "fred", "published": "2016-06-06 18:14:21+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>For the record, I&#8217;m not terribly interested in the question &#8220;should I get into a teleportation machine or not?&#8221;.</p>\n<p>I&#8217;m more interested in what it means to be conscious/alive as one&#8217;s body and brain degrade.<br />\nIt could alter the way we treat the less fortunate among us and animals.</p>\n]]>", "author": "fred", "published": "2016-06-06 18:47:37+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>I do not believe the kind of nihilism that equates humans and dog turds can be answered purely by logical argument. It requires introspection.  I know that there is a deeper question to consciousness just by looking around (or &#8220;experiencing qualia.&#8221;) It seems perfectly obvious that &#8220;I&#8221; am experiencing something rather than nothing. I am certain this is a mystery that will never be dispelled by science.</p>\n]]>", "author": "Jair", "published": "2016-06-06 20:44:13+00:00", "title": "By: Jair"}, {"content": "<![CDATA[<p>I really don&#8217;t see why copying is paradoxical ; weird-yes, puzzling implications for ethics and laws-yes, paradoxical-no.</p>\n<p>In object-oriented programming, you have the abstract &#8216;class&#8217; , and the &#8216;objects&#8217; themselves, which are concrete instantiations of the class.  If I could be copied, presumably it would  be the same thing as that &#8211; there would be one abstract class &#8216;Marc Geddes&#8217;, which would be the main entity recognized as a single &#8216;person&#8217; in terms of law, and multiple separate concrete objects &#8216;MJG1&#8217;, &#8216;MJG2&#8217; etc., that would have some lesser rights as separate entities with conscious experiences.</p>\n<p>Scott has made a valiant try, and I highly recommend his paper &#8216;GIQTM&#8217;, which is a fantastic read!    At the end of the day though, I&#8217;m just not buying it.</p>\n<p>The &#8216;free-bit&#8217; idea is certainly intriguing, but just doesn&#8217;t seem that likely to me, because I just find it hard to believe that entirely isolating myself from these &#8216;free-bits&#8217; is going to  turn me into an unconscious automation.</p>\n<p>I have already posted a  general sketch of my own solution to the puzzle of consciousness  in the comments here on Scott&#8217;s blog and elsewhere.</p>\n<p>I need to clarify one idea I suggested, which was a break-down of reductionism.  Some people might think I was suggesting uncomputability, but that&#8217;s definitely not the case!</p>\n<p>In fact, I do totally agree with Scott that the physical world is entirely computable.  A failure of reductionism does NOT mean physical uncomputability, I want to make that point absolutely clear.</p>\n<p>In a failure of reductionism what you would actually have is separate layers A, B, C, each of which can be entirely computable.  Any uncomputability would NOT make an appearance in empirical reality &#8211; it would be confined  to the abstract &#8216;bridging laws&#8217; that explain how the layers connect &#8211; any &#8216;uncomputability&#8217; is just a wholly abstract mathematical property that can&#8217;t ever appear physically.  In short, if something is physical, it&#8217;s computable.</p>\n<p>To summarize my own view on consciousness:  it can be generated by a fairly simply Turing machine and is entirely computable, with no quantum elements needed.  I think the program needs to be a recursive self-modelling program with 3 levels of abstraction (that mirror the 3-level split in reality): the 3 levels are:  an evaluation system, a decision-making system and a planning system.  Any program that has those systems and is doing information transmission across the 3 layers of abstraction, I think is conscious.</p>\n]]>", "author": "mjgeddes", "published": "2016-06-07 02:39:08+00:00", "title": "By: mjgeddes"}, {"content": "<![CDATA[<p>I know it\u2019s tempting to make fun of \u201cquantum pixie-dust&#8221;, yet we might just as well make fun of &#8220;classical pixie-dust&#8221;. If our ordinary understanding of matter and energy as set out in the Standard Model is correct, then consciousness ought to be impossible. We should all be p-zombies.  Nor can consciousness &#8220;arise&#8221; at some level of computational abstraction in a digital computer on pain of spooky &#8220;strong&#8221; emergence (How? When? Where? Why?] At least one \u201cobvious\u201d presupposition or background assumption that scientifically literate people are making must be mistaken. The challenge is to work out what this error might possibly be.</p>\n<p>In recent years, a minority of theorists have explored the prospects of non-materialist physicalism. (cf. Galen Strawson <a href=\"http://www.nytimes.com/2016/05/16/opinion/consciousness-isnt-a-mystery-its-matter.html\" rel=\"nofollow\">http://www.nytimes.com/2016/05/16/opinion/consciousness-isnt-a-mystery-its-matter.html</a>) Non-materialist physicalism isn\u2019t old-fashioned panpsychist property-dualism, but rather the conjecture that experience discloses the intrinsic nature of the physical, the mysterious \u201cfire\u201d in the equations on which physics is silent. This proposal is bizarre, but not demonstrably false. However, as David Chalmers (cf. <a href=\"http://consc.net/papers/combination.pdf\" rel=\"nofollow\">http://consc.net/papers/combination.pdf</a>) and others have recognised, neither panpsychism nor non-materialist physicalism seem capable of explaining why we\u2019re not just patterns of classical Jamesian mind-dust &#8211; so-called \u201cmicro-experiential zombies\u201d with no more experiential unity than a termite colony or the population of the USA. Regardless of whether experience is fundamental to the world, the phenomenal binding of a pack of discrete, decohered, membrane-bound feature-processing neurons into perceptual objects, let alone an entire classical world-simulation, is classically impossible. Hence Chalmersian dualism.</p>\n<p>Giving up on monistic physicalism is surely a last resort. Unfortunately, the prospects of a quantum-theoretic explanation of phenomenal binding look dire too. If (fancifully!) the effective lifetime of coherent superpositions of distributed neuronal feature-processors (edge-detectors, motion-detectors, colour-neurons, etc) in the CNS were milliseconds, then there would be an obvious candidate for the missing structural match between the formalism of physics and the phenomenology of our minds: binding-by-synchrony is actually binding-by-superposition. But of course that kind of extended lifetime is off by a dozen orders of magnitude or more. (cf. Max Tegmark\u2019s <a href=\"http://www.sciencedirect.com/science/article/pii/S0020025500000517\" rel=\"nofollow\">http://www.sciencedirect.com/science/article/pii/S0020025500000517</a>) Decoherence timescales of neuronal superpositions in the CNS must be insanely rapid &#8211; femtoseconds or less. Intuitively, such timescales are the reductio ad absurdum of quantum mind.</p>\n<p>Well maybe. One man\u2019s reductio ad absurdum is another man\u2019s experimentally falsifiable prediction. For what it&#8217;s worth, I think if we combine (1) non-materialist physicalism with (2) Zurek\u2019s &#8220;quantum Darwinism\u201d (cf. <a href=\"https://arxiv.org/pdf/0903.5082v1.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/0903.5082v1.pdf</a>) applied to the CNS (i.e. the decoherence program of post-Everett QM) then we\u2019ll find that selection pressure ensures a perfect structural match between the classically impossible phenomenology of our minds and the formalism of QFT. Phenomenally-bound biological minds have been quantum computers not just since Democritus but since the early Cambrian. Such a perfect structural match is insanely implausible, for sure; but I look forward to tomorrow\u2019s molecular matter-wave interferometry that puts our naive commonsense intuitions to the test.<br />\nAnd classical digital computers? Just invincibly ignorant zombies, IMO.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pearce:David.html\">David Pearce</a>", "published": "2016-06-07 09:18:02+00:00", "title": "By: David Pearce"}, {"content": "<![CDATA[<p>> I know that there is a deeper question to consciousness just by looking around (or \u201cexperiencing qualia.\u201d) It seems perfectly obvious that \u201cI\u201d am experiencing something rather than nothing. I am certain this is a mystery that will never be dispelled by science.</p>\n<p>>And classical digital computers? Just invincibly ignorant zombies, IMO.</p>\n<p>Thing is unless you take consciousness to be epiphenomenal, and such luck that nature happened upon a process that produced such an epiphenomenon, then we must take consciousness to be functional in nature.   We also know that conscious experience, or qualia, has content, variable possible very rich content implying a need for memory to store such content, vast memory.</p>\n<p>In explaining consciousness you need not only explain why there is consciousness, but what gives the different qualia their specific quality and makes these qualia different from one another.  You also need to explain how the various conscious chunks of experience are put together into a coherent whole.</p>\n<p>The vast amount of content of consciousness implies it cannot be stored within a single neuron, but throughout a large ensemble probably spanning a large quantity of brain tissue.   Consciousness also does not correspond to the present but to the recent past, it is also not synonymous with an ongoing physical flow or process as there is evidence of postdiction, implying the contents of consciousness are computed somehow after the fact.</p>\n<p>Computers can incorporate physical random number sources making them as unpredictable as anything can be, assuming physical sources can produce the mythical true randomness.   If it turns out there is some quantum process giving some functional advantage to brains, it should be seen in future experiments, but if the brain is matched or surpassed in terms of function in the real world, it will be doubtful that consciousness has not occurred if processes similar to those of the brain have been simulated.</p>\n<p>If as I and many others believe consciousness is functional, then as we gain knowledge of the function of the brain it will elucidate its nature and perhaps due away with the mystery whatever the cause may be.   Vitalism and the mystery of life is said to have had a similar view in the past with philosophical debates about it, but our present understanding of biological life mostly explained away the mystery, perhaps similar can occur with consciousness as more is understood about the brain.</p>\n]]>", "author": "Darien S", "published": "2016-06-07 10:35:00+00:00", "title": "By: Darien S"}, {"content": "<![CDATA[<p>I would have settled for a simple yes or no \ud83d\ude09</p>\n]]>", "author": "Albert", "published": "2016-06-07 13:14:57+00:00", "title": "By: Albert"}, {"content": "<![CDATA[<p>For me one difficulty with consciousness being rooted in the physical is that our definition of matter is a collection of point particles &#8211; atoms, quarks, electrical/magnetic fields (photons), etc.</p>\n<p>If that is all there is to physical reality, how can a &#8220;global&#8221; property such as consciousness emerge from a soup of point particles?<br />\nIf one atom, taken in isolation, isn&#8217;t a conscious system, then why would *any* number of atoms be conscious? (you start with one, add another, then another, then another&#8230; why would adding one more particle at any point make a difference?).<br />\nIt&#8217;s the equivalent of those starling flocks<br />\n<a href=\"https://www.youtube.com/watch?v=eakKfY5aHmY\" rel=\"nofollow\">https://www.youtube.com/watch?v=eakKfY5aHmY</a><br />\nIt looks like there&#8217;s a global &#8220;object&#8221; there, but when you look closely you realize it&#8217;s an illusion.</p>\n<p>I would think that if consciousness is truly an emergent property, it would have to be something that&#8217;s a property of the system as a whole, and be continuous.<br />\nThe wave function of a QM system seems to fit the bill, but apparently it&#8217;s just a mathematical tool (?)</p>\n<p>The other approach is to say that consciousness is pure information (digital), but then it could just be instantiated by the mere concept of numbers (then physical reality is an illusion, the universe is mathematical, etc).</p>\n]]>", "author": "fred", "published": "2016-06-07 14:14:35+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Darien S #163,</p>\n<p>Do you take consciousness to be a side effect of a functional thing or a functioning thing itself?  Your comment seems to imply the former and I take it that you believe the functioning thing would be the brain, yes?</p>\n<p>However, the brain &#8211; and the body that it relies upon &#8211; have many different functions.  Can you isolate which one(s) produce the side effect of consciousness?  I don&#8217;t think so.  But perhaps you think that in principle this should be possible.  That future advances will let us draw a circle around exactly those necessary and sufficient functions of the brain &#8211; and the body it depends upon &#8211; that give rise to the side effect of consciousness, yes?</p>\n]]>", "author": "adamt", "published": "2016-06-07 15:09:05+00:00", "title": "By: adamt"}, {"content": "<![CDATA[<p>fred</p>\n<p>&#8220;If that is all there is to physical reality, how can a \u201cglobal\u201d property such as consciousness emerge from a soup of point particles?&#8221;</p>\n<p>Take an eddy in a river for example. The eddy isn&#8217;t a property of the water molecule but arises during the flow of many water molecules. The eddy is in a sense unsubstantial but still real.</p>\n<p>Darien S.</p>\n<p>&#8220;The vast amount of content of consciousness implies it cannot be stored within a single neuron, but throughout a large ensemble probably spanning a large quantity of brain tissue.&#8221;</p>\n<p>An open question how large a quantity. Are birds conscious? Very small brains and some have estimated intelligence of crows equivalent to 7 year old humans. Intelligence isn&#8217;t consciousness but their behavior suggests consciousness as much the behavior of other humans we interact with suggest they are conscious.</p>\n<p>My thought has always been that most of the brain is taken with monitoring internal state, mapping sensory input, and coordinating movement. The amount of brain actually spent on consciousness may be relatively small and that most maybe all organisms with brains have some degree of consciousness.</p>\n<p>&#8220;In explaining consciousness you need not only explain why there is consciousness, but what gives the different qualia their specific quality and makes these qualia different from one another.&#8221;</p>\n<p>Never have quite bought the idea that we need to explain the specify quality of qualia. Take the qualia of redness. We probably developed an ability to discriminate redness from its advantage to select ripe fruit. As to why redness looks the way it does probably involves whatever path evolution took to generate it from the predecessor genes and structures in earlier primates without color vision. Other species that took a different path to color vision may not see the same red we do. For that matter, you and I may not see the same red either if the actual quality of qualia is dependent on relatively small genetic differences. So short answer I think is that the quality of qualia is somewhat arbitrary.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2016-06-07 17:24:30+00:00", "title": "By: James Cross"}, {"content": "<![CDATA[<p>adamt </p>\n<p>&#8220;Can you isolate which one(s) produce the side effect of consciousness?&#8221;</p>\n<p>Actually you can. It is a small group of cells in the brain stem. If you damage them there is permanent coma even with the rest of the brain intact.</p>\n<p>The cells are what was formerly known as the reticular activating system and have a long evolutionary history. They play a role in integrating external stimuli and internal state. They regulate wakefulness and sleep. The coordination and control of the rest of the brain by these cells probably is what produces consciousness.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cross:James.html\">James Cross</a>", "published": "2016-06-07 17:42:20+00:00", "title": "By: James Cross"}, {"content": "<![CDATA[<p>Scott #147</p>\n<p>I really don&#8217;t know ho to answer that. Whether we should call that a quantum computer is a point of details which has no impact on the substance of my post, plus&#8230; it&#8217;s not my convention, it&#8217;s the convention you used for GIQTM&#8217;s title! </p>\n<p>BTW, if that was a question, no, I wouldn&#8217;t call that a standard neuroscience view. First, because most neuroscientists just don&#8217;t know don&#8217;t care enough to form an opinion. Second, because many key neural processes involve discrete quantities (for example: the number of synaptic vesicules that fuse to release neurotransmitters in the synaptic cleft). It&#8217;s hard to see how small analog errors could survive and spread from one neuron to the next despite these mechanism.</p>\n]]>", "author": "Jay", "published": "2016-06-07 18:36:09+00:00", "title": "By: Jay"}, {"content": "<![CDATA[<p>All thinking that involves problem-solving and/or decision-making is a type of math. Example: I need to do three things in the next hour &#8211; buy some groceries and ice cream, pick up my dry-cleaning, and get a prescription filled at a drug store; where should I go in what order? (I could repose the problem in set theory to make it seem mathier if necessary.) Computers can do such problems as well or better than humans given the necessary data and rules, and they can learn data and rules from experience like babies do.</p>\n<p>Then there is motivation, drive, purpose. Ours is programmed into us by evolution and by our upbringings. Computers would have to have some prime directives programmed in. (Basic survival is not a universal drive &#8211; you have to want to survive.) But as evolution programmed us, we could program it into computers</p>\n<p>Then there are feelings: the scent of a rose, accomplishment, hormonal drives. How to program the functional equivalent of positive and negative and descriptive sensations into a computer (to recognize the scent of a rose, for example) does not seem like an insurmountable problem to me. Will they &#8220;feel&#8221; the same to computer as they do to us? No. This is the where I think most of the arguments from incredulity given above stem from. The key point, I think, is not to be a chauvinist and assume that they way humans do it is the &#8220;right&#8221; or only way it is possible.</p>\n]]>", "author": "JimV", "published": "2016-06-07 20:41:48+00:00", "title": "By: JimV"}, {"content": "<![CDATA[<p>Btw, the Feynman thing about magnets is this:</p>\n<p><a href=\"https://www.youtube.com/watch?v=MO0r930Sn_8\" rel=\"nofollow\">https://www.youtube.com/watch?v=MO0r930Sn_8</a></p>\n<p>The guy asks if he could explain what you feel when you try to press two magnets against each other, what&#8217;s going on there.<br />\nFeynman answers by looking at the nature understanding and explanation, i.e the difficulty of a &#8220;why?&#8221; question.</p>\n]]>", "author": "fred", "published": "2016-06-07 21:01:05+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>James Cross #168,</p>\n<p>&#8220;Actually you can. It is a small group of cells in the brain stem. If you damage them there is permanent coma even with the rest of the brain intact.&#8221;</p>\n<p>So these cells are necessary, but are they sufficient?  Are there no other parts of the brain/body that are necessary for consciousness to arise?  If there are, then it can&#8217;t be said that consciousness arises from just these cells, right?</p>\n<p>Also, can we find these same cells or analogous ones in all other  things we conventionally regard as consciousness?</p>\n]]>", "author": "adamt", "published": "2016-06-07 23:22:23+00:00", "title": "By: adamt"}]