[{"content": "<![CDATA[<p>next_prime(1) fails.</p>\n<p>Thanks for the very readable intro to Julia.</p>\n]]>", "author": "Quantum Mechanic", "published": "2016-07-22 18:35:47+00:00", "title": "By: Quantum Mechanic"}, {"content": "<![CDATA[<p>You can just do `next_prime(x::Integer)` and that would allow and specialize on any kind of integer (Int32, BigInt, etc.)</p>\n<p>With Julia meta programming you can still do a lot of stuff yourself instead of waiting for the language developers to implement and merge into Julia itself, as a Lisper you must love this I think? :)</p>\n<p>Here is a @vcomp (vector comprehension) macro that let&#8217;s you filter a la Python, with this syntax:</p>\n<p>julia> @vcomp Int[i^2 for i in 1:10] when i % 2 == 0<br />\n5-element Array{Int,1}:<br />\n   4<br />\n  16<br />\n  36<br />\n  64<br />\n 100</p>\n<p>* <a href=\"https://git.io/vwjO2\" rel=\"nofollow\">@vcomp macro</a></p>\n<p>It may not be the best implementation, but it works for me.</p>\n]]>", "author": "Ismael Venegas Castell", "published": "2016-07-22 20:39:58+00:00", "title": "By: Ismael Venegas Castell\u00f3"}, {"content": "<![CDATA[<p>I think your plot() example can be generalized slightly to provide an instance where multiple dispatch is truly useful.</p>\n<p>In my work, we often want to output data in different modalities. For example, I might want to plot a sparse matrix, or save it in an HDF5 file. Thus there are many kinds of output objects and also many kinds of matrix formats (or other data structures) that you want to output. Multiple dispatch provides a clean way to organize the largely independent code in all these choices.</p>\n]]>", "author": "Matthew Knepley", "published": "2016-07-23 01:50:13+00:00", "title": "By: Matthew Knepley"}, {"content": "<![CDATA[<p>&#8220;I remain somewhat befuddled about how best to exploit multiple dispatch&#8221;. Then you remain befuddled about why Julia is fast! Multiple dispatch isn&#8217;t just part of Julia, multiple dispatch is the core of Julia which allows it to get the performance that it.</p>\n<p>Julia uses a JIT to compile code. That&#8217;s fine, but you still won&#8217;t get major performance improvements if you don&#8217;t have type-stability because the compiled code would have to have a lot of cruft to deal with changing representations. However, with multiple dispatch you can easily write a function which compiles into many different methods, and multiple dispatch will choose the appropriate compiled method. </p>\n<p>For example, you can make a foo(::Float64) command which works on floats. The compiler can then do a bunch of float specific optimizations. Then you can have a foo(::Int64) method. It can be a completely different underlying algorithm, or it might just convert the int to a float and call foo(::Float64). However, if you were to just make a foo(::Number), then the compiled code would have to be able to handle floats and ints, and have to do a bunch of type-checking at each method call, etc. However, by using multiple dispatch with foo(::Float64) and foo(::Int64), we can call foo(x) when x is a number without thinking about it, but in each case it&#8217;s actually calling a compiler-optimized function (and sometimes type-specific optimized algorithm).</p>\n<p>So multiple dispatch with together with type-stable functions makes every thing &#8220;look like a scripting language&#8221;, but in actuality all of the actual code compiles down to pretty much optimal C functions. That is why Julia works so well, and that is the design choice that allows it to excel in performance over the other languages.</p>\n]]>", "author": "Christopher Rackauckas", "published": "2016-07-23 05:33:48+00:00", "title": "By: Christopher Rackauckas"}, {"content": "<![CDATA[<p>That&#8217;s not quite right, is it? You can make a foo(::Number) method and still have the compiler automatically generate specialized code for each concrete input type. You do not generally have to make a separate (and identical)  implementation for each type, which seems to be exactly the misunderstanding the OP is labouring under.</p>\n]]>", "author": "DNF", "published": "2016-07-23 07:37:05+00:00", "title": "By: DNF"}, {"content": "<![CDATA[<p>Yes, <code>next_prime(1)</code> fails. In the context of my program it can&#8217;t happen, but it&#8217;s an ugly wart all the same, especially given how I was going on about mathematical purity and all.</p>\n<p>Is it even worthwhile to sieve out even numbers? One could just leave that to <code>isprime(n)</code>, where the very first operation of the method for <code>n::Integer</code> is: <code>(n < 3 || iseven(n)) && return n == 2</code>.</p>\n<p>But I&#8217;m mostly concerned about performance with <code>n::BigInt</code>. Here the issue is not avoiding a primality check for an even number; it&#8217;s avoiding constructing the number at all. Suppose <code>n</code> is a 2,000-bit number. For each successive value of <code>n</code>, we&#8217;ve got to allocate a block of memory and build the representation of the number; that&#8217;s expensive enough to be worth the trouble of sieving out small divisors, I think.</p>\n<p>Here&#8217;s a more general question. The underlying GMP engine that does bignum arithmetic for Julia is capable of doing an update in place. That is, when you evaluate <code>n += 2</code>, GMP can reuse the existing location of <code>n</code> rather than allocate new memory. But, if I understand correctly, Julia does not exploit this shortcut because all numbers, including BigInts, are considered immutable. Is there a workaround?</p>\n<p>Finally, I believe that the right way to fix <code>next_prime(n)</code> is to get rid of it altogether and use the built-in function <code>primes(lo, hi)</code>. I didn&#8217;t do that because I didn&#8217;t want all primes between <code>lo</code> and <code>hi</code> but rather the next <code>k</code> primes after <code>lo</code>. But most likely it would have been simpler and perhaps faster to use <code>primes(lo, hi)</code> and afterwards trim or extend the list as needed.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Brian.html\">Brian Hayes</a>", "published": "2016-07-23 13:01:02+00:00", "title": "By: Brian Hayes"}, {"content": "<![CDATA[<p>Thanks for that. I didn&#8217;t get around to mentioning metaprogramming, so I&#8217;m glad you brought it up.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Brian.html\">Brian Hayes</a>", "published": "2016-07-23 13:54:20+00:00", "title": "By: Brian Hayes"}, {"content": "<![CDATA[<p>I&#8217;m the befuddled OP, though growing a little less befuddled with the help provided here. Thanks.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Brian.html\">Brian Hayes</a>", "published": "2016-07-23 13:55:56+00:00", "title": "By: Brian Hayes"}, {"content": "<![CDATA[<p>I was just trying to make it as explicit as possible [my example in mind was implementing +, which has to call different machine instructions]. But yes, if you make a function where all of the functions it calls inside are defined on the abstract type Number, then foo(::Number) works by essentially making a foo(::T) for each subtype of number that you give it (compiling the first type you give it a new type, or using a precompiled version if in a package). And this is the feature that then makes Julia build up like it is a scripting language. But while having this foo(::Number) as a very different in implementation than what you&#8217;d get from other scripting languages.</p>\n<p>But there is still an issue if if you make a foo(::Number) and then do a type-conversion of all of the numbers to a concrete type. It still works by multiple dispatch, but if at the top you type check and convert things to either Floats or Rationals depending on whether what comes in is an Integer or Float, then you&#8217;ll have a type instability. Instead you should make your function call a function which works on foo(::Number) without having to do any conversions and it will optimize via multiple dispatch. See &#8220;Separate kernel functions&#8221; in <a href=\"http://docs.julialang.org/en/release-0.4/manual/performance-tips/\" rel=\"nofollow\">http://docs.julialang.org/en/release-0.4/manual/performance-tips/</a> . </p>\n<p>So I should&#8217;ve added a detail: at the bottom each dispatch had to be defined, but when you build up, you have +(::Number,::Number) and the like already defined on each number, so if you just call +, the compiler will be able to choose the right + function and make it efficient (if your types are stable).</p>\n]]>", "author": "Christopher Rackauckas", "published": "2016-07-23 14:18:00+00:00", "title": "By: Christopher Rackauckas"}, {"content": "<![CDATA[<p>Here are a couple of your examples in Haskell.</p>\n<p>factorial n = product [1 .. n]</p>\n<p>she_loves_me petals<br />\n  | petals == 0 = True<br />\n  | otherwise = she_loves_me_not (petals - 1);</p>\n<p>she_loves_me_not petals<br />\n  | petals == 0 = False<br />\n  | otherwise = she_loves_me (petals - 1)</p>\n<p>Neither had any problem executing<br />\n> factorial 21<br />\n51090942171709440000<br />\n> she_loves_me 1000000<br />\nTrue</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abbott:Russ.html\">Russ Abbott</a>", "published": "2016-07-23 17:25:24+00:00", "title": "By: Russ Abbott"}, {"content": "<![CDATA[<p>(Sorry. I didn&#8217;t realize I would have to put in the extra new lines and spaces explicitly.)<br />\n&nbsp;<br />\nHere are a couple of your examples in Haskell.<br />\n&nbsp;<br />\nfactorial n = product [1 .. n]<br />\n&nbsp;<br />\nshe_loves_me petals<br />\n&nbsp;&nbsp;| petals == 0 = True<br />\n&nbsp;&nbsp;| otherwise = she_loves_me_not (petals - 1)<br />\n&nbsp;<br />\nshe_loves_me_not petals<br />\n&nbsp;&nbsp;| petals == 0 = False<br />\n&nbsp;&nbsp;| otherwise = she_loves_me (petals - 1)<br />\n&nbsp;&nbsp;<br />\nNeither had any problem executing<br />\n> factorial 21<br />\n51090942171709440000<br />\n> she_loves_me 1000000<br />\nTrue</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abbott:Russ.html\">Russ Abbott</a>", "published": "2016-07-23 17:31:35+00:00", "title": "By: Russ Abbott"}, {"content": "<![CDATA[<p>Sorry to put you through such formatting torture.</p>\n<p>Haskell is a special case. As a &#8220;lazy&#8221; language, it doesn&#8217;t evaluate arguments until the values are needed, whereas all the other languages I discuss here are &#8220;strict,&#8221; evaluating all arguments before the function is applied to them. I&#8217;m a little vague on the exact mechanics of this, but I think it means that Haskell can sometimes avoid growing the stack without actually doing tail-call elimination.</p>\n<p>More conventional tail-call optimization has been a feature of Scheme since before 1980, and it has been standard in most other Lisps since the 1990s. Lua also does it, and the new JavaScript (ES6.0). The LLVM compiler framework, which is Julia&#8217;s infrastructure, is equipped to do tail-call elimination, and indeed it provides that option for C programs in the clang compiler. The Julia developers have so far decided not to implement that optimization.</p>\n<p>In saying all this I don&#8217;t mean to suggest that the Julia folks have made the wrong decision here. I don&#8217;t know nearly enough about the tradeoffs to make that judgment. I&#8217;m just saying that I&#8217;d like everything Julia offers already, plus tail recursion (and also a pony, please).</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Brian.html\">Brian Hayes</a>", "published": "2016-07-23 18:08:33+00:00", "title": "By: Brian Hayes"}]