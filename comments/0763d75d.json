[{"content": "<![CDATA[<p>0. A novel of a reply, just for one last time (I promise!)</p>\n<p>1. Playing a devil&#8217;s advocate to the devil&#8217;s advocate (i.e. arguing in favour of QC):</p>\n<p>This point was mainly motivated by Scott&#8217;s observation in the essay: &#8220;Classically, this goal seems hopeless, since n^2 steps would be needed even to examine all the entries of [A].&#8221; That is, focusing on the *space* part.</p>\n<p>How do you square off Scott&#8217;s observation with the fact that, as reported in the literature, MG gives you O(N), and not O(N^2)? </p>\n<p>For one thing, the reported MG complexity refers to the number of flops, not of memory references. (May be Scott needs to clarify this issue a bit.)</p>\n<p>For another thing, MG has been developed in the context of the FEM-like equations, which produce only a *sparse* matrix. In these cases, as the Matrix Market database should make it clear, the &#8220;oracle&#8221; to tell the value of A[i][j] doesn&#8217;t have to possess the prodigious O(N^2) memory; for FEM, the number of filled entries is just O(N). This fact may have a bearing on the time-complexity of MG. &#8230; Unfortunately, except for some broad conceptual outlines, I really don&#8217;t know the MG all that well&#8212;I haven&#8217;t studied the nuts-and-bolts of the algorithm. But, may be, this could be the reason for its reported O(N) time-complexity.</p>\n<p>And, so, I thought, how about the cases where the [A] matrix is both large and *dense*? </p>\n<p>Just the way the tridiagonal system is one extreme example (1D truss => sparse [A]), what kind of [A] matrix would be lie on the other extreme end of the spectrum, even if only for bench-marking purposes? Obviously, it has to be a 100% filled matrix. How do you generate that? </p>\n<p>CS guys would know: Say, take a circle, put N number of nodes on its circumference, and then, join each node to *every* other node. This will fill the entire [A] matrix. For an even more extreme case, have the to- and fro- edges between the same pair of nodes carry different weights (which doesn&#8217;t happen in FEM-like contexts, but it might occur in some other graph-theoretic contexts from CS). And, if you wish (if it helps in algorithm analysis), in either case (sparse or dense) make the filled entries random in some way (not necessarily with a uniform PDF but one with spikes and all, too).</p>\n<p>For this kind of a fully dense [A] matrix, how well does the MG fare? &#8230; I have absolutely no idea! </p>\n<p>But, thinking aloud, the algorithm couldn&#8217;t now skip over most of the O(N^2) entries, because they aren&#8217;t zero&#8217;s any longer. And, so, I thought, may be, the convergence behaviour of the MG algorithm would get challenged. May be, it could still &#8220;theoretically&#8221; have O(N), but the factor to stick ahead of that O(N) would be so large as to effectively land the whole thing into O(N^2) or worse, anyway. &#8230; As I said, I don&#8217;t really know (and so should keep my mouth shut), but still, that&#8217;s how I happened to think. </p>\n<p>And therefore, here, a QC could have some kind of an advantage, I thought, because it would cost at most only O(N) (for uploading |b>, and downloading and working with |x>). The DD-advocacy is over.</p>\n<p>2. Yet, something else also struck me in the meanwhile, once again, against a QC.</p>\n<p>QC is approximate, just like MG. However, QC also is *stochastic*, unlike MG. Implication: the {x} entries for two different runs wouldn&#8217;t be repeatable&#8212;even if you run some kind of a smoothing operation such as the wavelets processing (which itself runs &#8220;only&#8221; in O(N)). This unrepeatability feature is unlike the classical stochastic algorithms, which rely on the pseudo-RNGs (basically deterministic).</p>\n<p>Engineers are fine with approximations, but for mass-market applications, but they would still insist on repeatability. Implementation of ISO standards, for exchanging data between different parties, e.g. between designers and users of the designs, or for a product-integrator coordinating different third-party supplies, repeatability would practically become a very important concern. </p>\n<p>Hence, QC won&#8217;t be very suitable here. &#8230; Not very surprising. These aren&#8217;t problem areas for which the classical complexity itself is like k^N; it simply is N^k. So, you can&#8217;t possibly expect highly dramatic improvements here anyway.</p>\n<p>3. However, for the very-large-and-dense matrix applications (which aren&#8217;t mass-market and don&#8217;t require coordination to out-of-house parties), and perhaps even for certain niche and very-stupendously-large-and-sparse matrix applications, QCs could perhaps have a clear-cut edge. For instance, for in-house consumptions like drugs discovery in the pharma industry, or for very large data processing/mining (think Google/analytics/etc.), and so on.</p>\n<p>4. Overall, for these reasons, I think that the inevitable conclusion is to agree with Scott: Apart from simulating QM, QCing wouldn&#8217;t transform the computational land-scape the way PCs, and classical parallel processors (GPGPUs, clusters, supercomputers) have. </p>\n<p>5. OK, so&#8230; Let me now shut up and hurry back into the wings (and into the audience quickly thereafter), lest Peter&#8217;s Principle kicks in&#8212;if it hasn&#8217;t, already!.</p>\n<p>Best,</p>\n<p>&#8211;Ajit<br />\n[E&OE]</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jadhav:Ajit_R=.html\">Ajit R. Jadhav</a>", "published": "2015-02-06 14:53:45+00:00", "title": "By: Ajit R. Jadhav"}, {"content": "<![CDATA[<p>Gil Kalai doesn&#8217;t believe that quantum computers will work because of noise, but he believes that HLL will work. Makes perfect sense&#8230;</p>\n]]>", "author": "rrtucci", "published": "2015-02-06 18:35:56+00:00", "title": "By: rrtucci"}, {"content": "<![CDATA[<p>errata: I meant HHL not HLL. My apologies to the letter L. This show was brought to you by the letter L</p>\n]]>", "author": "rrtucci", "published": "2015-02-06 18:38:29+00:00", "title": "By: rrtucci"}, {"content": "<![CDATA[<p>Re #21, wouldn&#8217;t it be possible to experiment with at least a 4\u00d74 matrix by simulating the quantum computer on a classical computer with exponential slowdown?</p>\n]]>", "author": "jonas", "published": "2015-02-06 20:28:13+00:00", "title": "By: jonas"}, {"content": "<![CDATA[<blockquote><p><b>rrtucci</b> questions &#8220;Gil Kalai doesn\u2019t believe that quantum computers will work because of noise, but he believes that HHL will work. Makes perfect sense&nbsp;[?]&nbsp;&hellip;&#8221;</p></blockquote>\n<p>Gil&#8217;s view <i>does</i> make sense if we reflect that the worked example in Clader, Jacobs, and Sprouse &#8220;Preconditioned quantum linear system algorithm&#8221; (arXiv:1301.2340 [quant-ph], 2013)&nbsp;&mdash; an article that Scott&#8217;s <i>Nature Physics</i> essay features prominently&nbsp;&mdash; solves a specialized QED scattering problem by an algorithm that relies essentially upon a specialized class of matrix preconditioners, known as sparse approximate inverse (SPAI) preconditioners, that were developed to solve (with transformational efficiency) specialized QED scattering problems via classical computation.</p>\n<p><b>Summary</b>&nbsp; It&#8217;s consistent to envision a world in which quantum linear solvers <i>are</i> exponentially more efficient than classical solvers, but <i>only</i> for restricted classes of problems; classes that in particular are not BQP-complete.  And it is consistent too, to envision that preconditioners that are effective in quantum linear solvers, are effective too in classical linear solvers. </p>\n<p>The QED-scattering solver of Clader, Jacobs, and Sprouse&#8217; justly-praised work resides naturally in this world.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidles:John.html\">John Sidles</a>", "published": "2015-02-06 21:11:57+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>jonas #42: Yes, for sure you could do that.  You could probably even do a 20&#215;20 matrix.  But exactly what question would you be hoping to answer that way?</p>\n<p>(Of course, one can ask the same thing about the physics experiment, but there the answer is: you just want a demonstration platform for experimental techniques that hopefully are of independent interest.)</p>\n]]>", "author": "Scott", "published": "2015-02-06 21:59:49+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>John Sidles, if an algorithm requires a QC, but the QC doesn&#8217;t work, then the algorithm doesn&#8217;t work.</p>\n]]>", "author": "rrtucci", "published": "2015-02-07 03:25:37+00:00", "title": "By: rrtucci"}, {"content": "<![CDATA[<p>@Gil:</p>\n<p>Since you seem the resident expert on noise & how it affects scaling up a QC: Do you expect the same noise swamping issues to prevail in HHL? </p>\n<p>i.e. If the experimental demos of HHL move to larger matrices from the current 2&#215;2 toy systems will they be able to preserve reasonable fidelity in their estimated solutions?</p>\n]]>", "author": "Rahul", "published": "2015-02-07 05:29:12+00:00", "title": "By: Rahul"}, {"content": "<![CDATA[<p>@rrtucc:</p>\n<p>So what&#8217;s your bet on A, B or C: </p>\n<p>(A) (Universal) QC&#8217;s will work (i.e. scale) & so will HHL on QC&#8217;s</p>\n<p>(B) QC&#8217;s will work but HHL will not</p>\n<p>(C) Neither QC&#8217;s nor HHL will work. </p>\n<p>Is there a (D)?</p>\n]]>", "author": "Rahul", "published": "2015-02-07 11:35:08+00:00", "title": "By: Rahul"}, {"content": "<![CDATA[<p>Rahul, I would get a B grade, although I would prefer an A so I move that you swap the A and B categories</p>\n<p>D is of course &#8220;QC&#8217;s won&#8217;t work but HHL will&#8221;. it&#8217;s the grade that Gil Kalai and John Sidles get , although I would give them an F</p>\n]]>", "author": "rrtucci", "published": "2015-02-07 15:13:48+00:00", "title": "By: rrtucci"}, {"content": "<![CDATA[<p>rrtuci, </p>\n<p>I understand Gil&#8217;s position as: in practice neither QC nor HHL will ever work; in theory QC implicates HHL; the latter is interesting (for CT&#8217;s reasons) even if no QC can ever be built. </p>\n<p>I don&#8217;t understand your position that: QC will work but HHL won&#8217;t. If we have a candidate QC, and it fails to run some quantum algorithm, then we won&#8217;t call it a QC. We&#8217;d call it a failure and search for what&#8217;s going wrong and how to fix it. Or maybe you think there&#8217;s some problem specific to HHL, such as a mathematical mistake in Aram et al.?</p>\n]]>", "author": "Jay", "published": "2015-02-08 18:31:29+00:00", "title": "By: Jay"}]