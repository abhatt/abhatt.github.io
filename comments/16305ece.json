[{"content": "<![CDATA[<p>David Brown #37: Gil should speak to whether his conjectures as presented on Wikipedia are adequate representations of what he believes.  The &#8220;rebuttal conjectures,&#8221; which imply quantum computing is possible, would basically just be:</p>\n<p>(a) Quantum mechanics is exactly true.</p>\n<p>(b) It is possible to prepare a collection of qubits in the all-0 state, then apply 1- and 2-qubit gates to qubits of one&#8217;s choice, then measure a qubit.</p>\n<p>(c) Nature has no &#8220;correlated noise source&#8221; that diabolically (and unavoidably) conspires to kill quantum computation.</p>\n<p>Gil himself doesn&#8217;t dispute (a), and (b) I&#8217;d say has already been experimentally demonstrated, so the dispute is about (c).  And the position of most QC researchers would be that the burden is on the skeptics at this point to <i>derive from the laws of physics</i> what this diabolical noise source is, and show why it kills QC.  It&#8217;s not enough just to postulate noise models out of thin air&#8212;especially if it&#8217;s not even clear whether the models you&#8217;ve postulated actually <i>would</i> kill QC!</p>\n]]>", "author": "Scott", "published": "2014-07-24 11:41:26+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<blockquote><p><b>Juan Miguel</b> remarks &#8220;No mention of quantum metrology? Remember, it\u2019s already helping us do really cool stuff, like&nbsp;[list follows &hellip;]&#8220;</p></blockquote>\n<p>To Juan Miguel&#8217;s fine list we can add quantum metrology triangles (QMTs).  Outstanding reviews include:</p>\n<p>\u2022 &#8220;Metrology and microscopic picture of the integer quantum Hall effect&#8221; (Weis and von Klitzing, 2011)</p>\n<p>\u2022 &#8220;Quantum metrology triangle experiments: a status review&#8221; (Gallop, 2012)</p>\n<p><b>QMT naturality</b>&nbsp; QMT comprises a quantum dynamical model in which many elements of scalable error-corrected computing <i>already</i> are substantially fulfilled: topological protection, robustness against noise, invariant reproducibility, and unbounded precision.</p>\n<p><b>QMT centrality</b>&nbsp; QMT also provides a wonderful <i>social</i> model, in that its strategic implications are sufficiently important as to be regulated by one of the longest-standing and most successful intergovernmental treaties: the <i>Conf\u00e9rence g\u00e9n\u00e9rale des poids et mesures</i> (CGPM, 1875).  </p>\n<p><b>QMT openness</b>&nbsp; QMT technologies&nbsp;&mdash; as codified in <i>mises en pratique</i>&nbsp;&mdash; are substantially free of trade-secrets, state-secrets, cryptolects, and paywalls.  This openness is good news for students especially. </p>\n<p><b>QMT puzzles</b>&nbsp; Furthermore, Vladimir Arnold&#8217;s critique of thermodynamics applies particularly to QMTs<br />\n<blockquote>Every mathematician knows that it is impossible to understand any elementary course in thermodynamics.</p></blockquote>\n<p>Just because we use QMTs, doesn&#8217;t mean that we adequately understand them!  QMTs promise  unbounded precision in principle, but we are far from achieving unbounded precision in practice; the (many) open problems associated to QMT metrology are good news for young quantum researchers.</p>\n<p><b>Prediction 1</b>&nbsp; It is reasonable to foresee&nbsp;&mdash; because the CGPM is taking concrete steps to ensure it&nbsp;&mdash; that by 2040 the entirety of the world&#8217;s metrology system will be entirely based upon QMT technologies; this programme is the so-called &#8220;new&#8221; <i>Syst\u00e8me International d&#8217;Unit\u00e9s</i> (new SI). </p>\n<p><b>Prediction 2</b>&nbsp; If we are <i>really</i> optimistic, then we can foresee that we will understand in 2040&nbsp;&mdash; both individually and as a STEM community&nbsp;&mdash; how QMT devices work.  Here &#8220;understand&#8221; is to be realized in the full mathematical and social senses of Bill Thurston&#8217;s great essay &#8220;On Proof and Progress in Mathematics&#8221; (1994).  Perhaps we will even be able to simulate QMT device performance, both in principle and in practice, with sufficient accuracy to help guide experiments and optimize <i>mises en pratique</i>.</p>\n<p><b>Prediction 3</b>&nbsp; Fuller understanding of QMTs in coming decades will carry us far toward an appreciation of the feasibility (or not) of scalable quantum computing and the feasibility (or not) of simulating quantum systems with PTIME resources.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidles:John.html\">John Sidles</a>", "published": "2014-07-24 12:07:35+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Scott #32</p>\n<p>&#8220;I\u2019m not sure if it\u2019s true that advances in algorithms have paralleled advances in hardware that closely.&#8221;</p>\n<p>That&#8217;s a really complex question.<br />\nIf you look closely at the frameworks that support many of the current revolutions, like being able to query the internet in seconds, or do any sort of massive data processing, it&#8217;s clear that algorithms and hardware go hand in hand. And advances in hardware is all about cost as well, usually cost of doing the processing locally (put RAM/CPU on the cellphone) vs cost of decentralizing the processing which depends on network cost and cost of running server farms (cloud).<br />\nLike this tech article from Facebook about working on graphs with a trillion nodes <a href=\"https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920\" rel=\"nofollow\">https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920</a> (itself relying on services like MapReduce which takes advantage of distributed processing).<br />\nMost big advances in data processing are about combining the right building blocks (like some recent big improvement in image classification/matching from Google).</p>\n]]>", "author": "fred", "published": "2014-07-24 13:00:59+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Scott #32<br />\nAnother area where algos and hardware have been clearly feeding off each other is computer graphics.<br />\nIn the 80s, in the case of off-line rendering, people could afford to come up with more &#8220;theoretical&#8221; algos to compute things like global illumination all in software (using ray tracing and whatnot).<br />\nBut in the field of real-time rendering (e.g. video games), once hardware acceleration appeared, very interesting algorithms were made specifically based on the current hardware available at the time. For example, &#8220;Carmack&#8217;s reverse&#8221; which was very specific to the hardware capabilities <a href=\"http://en.wikipedia.org/wiki/Shadow_volume\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Shadow_volume</a> (there were even patent disputes about it).<br />\nNow the GPUs are so flexible that the two domains have pretty much fused, and everything is coded in terms of very generic and more physically correct shaders.</p>\n]]>", "author": "fred", "published": "2014-07-24 17:48:02+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>David (#37) Scott (#39 )</p>\n<p>A simple way to state my thesis is that noise rate scales up for complicated quantum evolutions. (The &#8220;diabolic&#8221; correlations that Scott mentioned are indeed part of the picture but the &#8220;first order term&#8221; is simply the noise rate.)</p>\n<p>A few more remarks:</p>\n<p>(1) To a large extent (as far as I know) the assumption of fixed error-rate which can be pushed below the threshold allowing quantum fault-tolerance is also taken out of &#8220;thin air&#8221; and not derived from some fundamental laws of physics.</p>\n<p>(2) The asymptotic behaviors of models is very important but ultimately \u00a0when we ask if computationally superior quantum computation can be demonstrated the question is largely about constants. (Asymptotic considerations gives us strong insights about the behavior of these constants. The point of view that every constant can be pushed arbitrary close to zero by some appropriate engineering is not correct and not useful.)</p>\n<p>(3) You can divide my view into two parts:</p>\n<p>(A) Quantum computational speed-up requires quantum fault tolerance.</p>\n<p>(B) Quantum fault tolerance is not possible.</p>\n<p>A stronger statement is that the <strong>only</strong> mechanism for computation in nature (alas, only classical) is the &#8220;repetition mechanism,&#8221; which allow robust classical information to emerge.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2014-07-25 08:08:50+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>On a lighter note let me mention that Video II of my Simons Institute videotaped lectures contains a short respond to Scott&#8217;s 100,000$ challenge (49:30-50:30). The twenty minutes of Video II (from 40:00 or so) give some pictures related to the quantum debate and describe some of its entertaining moments&#8230;</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2014-07-25 08:37:23+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Something that I think most people do not notice about quantum computation is that it presumes a one to one function between physical QM and mathematical model of QM.<br />\nit is possible that every QM state can be described well in the mathematical model we all thing is good.<br />\nHowever, some mathematical states do not have physicaly possible state, thus making some sort of theoretical QC compuatuon impossible in practice.</p>\n<p>It is a bit same as some told me here it is not possible to have wave function with no variance and mean, or that strong law of large numbers do not hold.</p>\n<p>Another question is how can grover algorithem work in practice, for it to be effective vs classical computer we need huge quantum database if i am not wrong.<br />\nSomething like 1M qubits DB does not seem  practicle in the next 40 years.</p>\n]]>", "author": "Itai", "published": "2014-07-25 11:40:43+00:00", "title": "By: Itai"}, {"content": "<![CDATA[<p>I apologize if this question was asked and answered above &#8211; it&#8217;s a bit hard to read everything in detail. </p>\n<p>My question is simply this: having a universal quantum computer, that would allow us to simulate a lot of quantum processes that presumably are intractable with classical computers today, no? </p>\n<p>The article seems to say as much. I&#8217;d expect that alone with have huge and visible effects on technology, no? The article seems to really downplay this though, and I couldn&#8217;t understand why.</p>\n]]>", "author": "Vlad", "published": "2014-07-26 02:33:20+00:00", "title": "By: Vlad"}, {"content": "<![CDATA[<p>Vlad #46: My view is that, <i>if</i> QC has a major practical effect, then quantum simulation will probably be the main reason why.  It&#8217;s certainly something of practical importance, and certainly something that QCs could plausibly help with.  On the other hand, there are also two difficulties:</p>\n<p>- Very often, for the quantum systems that people actually care about, it&#8217;s possible to make simplifying assumptions that make them tractable to simulate classically&#8212;at least if you only want to know basic things like the ground state energy, as is often the case.  (E.g., a lot can be treated using Quantum Monte Carlo and DMRG.)  Furthermore, even in a world where QCs become practical, we have to expect that classical simulation algorithms will continue to improve, as they have for decades.</p>\n<p>- Recent studies by Matthias Troyer and others suggested that there will be very large polynomial overheads in simulating quantum chemistry using a qubit-based quantum computer.  I&#8217;m sure the simulation algorithms will be improved (indeed, they already have been to some extent), but the ones we know right now look like they could require millions of qubits (and even more gate operations) before they&#8217;d start giving any useful information about chemistry.</p>\n<p>Despite the above points, I&#8217;m a guarded optimist about quantum simulation, and I tried to convey my optimism several times in the article. <img src=\"http://www.scottaaronson.com/blog/wp-includes/images/smilies/icon_smile.gif\" alt=\":-)\" class=\"wp-smiley\" /> </p>\n]]>", "author": "Scott", "published": "2014-07-26 03:07:24+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Vlad, Scott doesn&#8217;t discuss the use of QCs to do MCMC and learning the structure of Bayesian networks. Those would give only quadratic speedups over classical methods, but that is good enough for me.</p>\n]]>", "author": "rrtucci", "published": "2014-07-26 07:12:25+00:00", "title": "By: rrtucci"}, {"content": "<![CDATA[<p>Itai #45: The way you use Grover&#8217;s algorithm &#8220;in practice&#8221; is to replace the database with a one-way function; the difficulties then are that while the classical machine needs to evaluate the function more often, it can also do so more quickly, and that there may be some clever method to invert the function classically without a brute-force search.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Standeven:Ben.html\">Ben Standeven</a>", "published": "2014-07-27 21:38:20+00:00", "title": "By: Ben Standeven"}, {"content": "<![CDATA[<p>Gil Kalai #43: I think that&#8217;s what he meant by &#8220;diabolic correlations&#8221;: The error rate for each individual piece of a complicated process might be very low, but when the pieces are combined the error rate is much higher.</p>\n<p>I don&#8217;t see why this would block error correction, though. Surely the error rate can only grow linearly with the length of the process (so that the total amount of error grows quadratically)? You could compensate by doing more error correction.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Standeven:Ben.html\">Ben Standeven</a>", "published": "2014-07-27 22:16:42+00:00", "title": "By: Ben Standeven"}]