[{"content": "<br />About the statistical confidence in proof correctness based on the authors&#39; identity, Suresh&#39;s argument is:  &quot;And if the authors don&#39;t provide full proofs, and I need to know the authors to determine if the result is believable, isn&#39;t that the very definition of bias?&quot;<br /><br />Sure, that&#39;s the definition of &quot;bias.&quot;  But it&#39;s not &quot;bias&quot; that&#39;s generally considered negative or unfair (lest you start disliking anti-bias bias, say), it&#39;s bias for or against things that shouldn&#39;t matter.<br /><br />One might argue that this data is not used responsibly, but it&#39;s hard for me to understand--on the face of it--how the expertise of the author is not relevant in making a statistical judgement about correctness.<br /><br />Here is a thought experiment.  We all have only limited time.  Most of us can&#39;t read, for instance, every proof that claims to resolve the P vs. NP question.  I don&#39;t read those papers at all, but if Razborov posted such a preprint to the arxiv, I would start reading it that night.  Am I making a sound decision in basing allocation of my attention on credibility in a field?  Isn&#39;t the role of conferences essentially &quot;attention allocation&quot;?", "author": "James R Lee", "published": "2018-01-10 05:32:51.546000-05:00", "title": ""}, {"content": "James --<br /><br />When you say that that&#39;s not bias that&#39;s considered negative or unfair, I think you&#39;ll find a good number of people that disagree with you.  Particularly the ones that are being biased against.  <br /><br />I would say that blindly trusting the expertise of the author is not a good idea for our long-term science.  You try to dress it up by saying just that it is relevant in making a &quot;statistical judgement&quot;, but in reality, I don&#39;t believe that&#39;s how it works.  I&#39;ve never heard anyone say at a PC meeting, &quot;My prior odds for believing this result are only 1:1, but because XXX wrote it, I&#39;m updating my odds to 3:1, and that&#39;s really good enough, isn&#39;t it?&quot;  <br /><br />You have gone on to posit an extreme case, regarding P vs NP proofs.  You&#39;ll notice that such proofs are generally NOT handled by conferences, as a matter of course, precisely because they require such attention.  They are more properly -- and fairly -- handled outside the conference mechanism.  So I think your example doesn&#39;t shed light on this situation. <br /><br />In short, your argument is pretty much the standard sort of argument I&#39;ve heard in response to promoting double-blind reviewing, which I find deeply uncompelling.<br /><br /><br /> ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2018-01-10 07:59:40.632000-05:00", "title": ""}, {"content": "James, just to add to Michael&#39;s response, consider a scenario where it&#39;s not as &quot;clear cut&quot; as P vs NP. The fundamental problem with reasoning based on author identity is not that it provides no signal. It&#39;s that it isn&#39;t applied consistently. In other words, imagine we had a numerical confidence score for each author, a rule that says that the confidence of a paper is some function of the confidence scores of the authors, and a well defined rule to update our prior confidence in the paper based on these scores. And that each and every one of us agreed on this scoring and also agreed on the same update model for our beliefs. And had the same beliefs. <br /><br />Then I might be willing to entertain the idea even briefly that author identity might be of some value. <br /><br />But of course such a scenario doesn&#39;t exist in reality. We have different ways in which we might update priors based on author identity and that lack of consistency is a real problem, because that&#39;s precisely where subjective implicit biases appear to kick in. ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkatasubramanian:Suresh.html\">Suresh Venkatasubramanian</a>", "published": "2018-01-10 10:41:52.755000-05:00", "title": ""}, {"content": "The argument about correctness has nothing to do with &quot;xxx is an author so surely it is correct.&quot; The point is the following: for conferences, correctness is the responsibility of authors rather than the PC. This works because it is very embarrassing to publish faulty proofs - you lose reputation. But this only works if you have a reputation within the community to lose. For everybody else, the PC should work harder to verify the proof. In addition, even within the community, some authors have an history of bugs. It make perfect sense to hold it against them. There are many more arguments against double-blind reviewing, and I have stories to back them up (from my experience reviewing in crypto). Nevertheless, there is an argument in the other direction as well.", "author": "omereingold", "published": "2018-01-10 12:26:49.830000-05:00", "title": ""}, {"content": "To add to this discussion, I think that focusing on the example of determining correctness obscures a more important issue: author identity may affect reviewer&#39;s general credulousness when evaluating author assertions regarding issues like:<br /><br />1) novelty of ideas and techniques<br />2) generally arguing for the &quot;importance&quot; of whatever direction the paper is pursuing. <br />3) reviewer optimism regarding future applications or progress that the new ideas may enable<br />4) making sure the authors haven&#39;t missed some prior work that solves or nearly solves the problem, or missed a much simpler/obvious solution<br /><br />I can see the argument for letting author identity affect issue 4), since an expert on a topic may be less likely to miss prior work or simple solutions. But it seems much more dangerous to let author identity affect the other issues: these aspects are inherently somewhat subjective, and in the absence of an error, these are precisely the issues that papers get evaluated on.<br /><br />In short, if well-known researchers&#39; claims of novelty and importance are treated with more credulousness than others, then it&#39;s easier for them to sell their papers. And that&#39;s a huge part of the game. So I think that a major argument for blinding is to help keep the playing field level in this regard.", "author": "Anonymous", "published": "2018-01-10 12:31:46.677000-05:00", "title": ""}, {"content": "<br />Michael:<br /><br />I realize I was unclear:  My comment about &quot;bias&quot; is only that &quot;bias&quot; is generally used as shorthand for certain negative types of bias.  &quot;Bias&quot; itself cannot be negative (hence my joke about &quot;anti-bias bias&quot;), and thus instances of bias need to be argued on their merits.  I did not see the argument.  I still don&#39;t see you making one, and &quot;I&#39;ve heard all this before&quot; is not a great way of dismissing a position.<br /><br />Positing an extreme case is what one does in an existence proof.  I exhibited the existence of a situation in which such bias is productive.  The point of the extremity is so that everyone can agree.  From there, one can argue about the relative merits, and whether the value of such bias outweighs its potential harm.  But I find it disingenuous to act as if this bias holds no value whatsoever for the stated mission of the program committee.<br /><br />Saying that people don&#39;t make statistical judgements just because they don&#39;t assign explicit probabilities doesn&#39;t seem right to me.  The conference deliberation process has never been intended to confirm correctness, but reviewers are asked to give their &quot;confidence&quot; about the likelihood that a paper is correct.  I would only argue that such confidence is legitimately increased by the author being an expert in the underlying area.<br /><br />I would personally never advocate for accepting a paper at a theory conference without it being accompanied by full proofs, but that&#39;s because I don&#39;t think scientific progress needs to be so fast that people can&#39;t write their arguments down carefully.  Even given full proofs, it is infeasible (and has never been a goal) for the PC to verify them, and so at the end of the day, one is trading off many factors, one of them being the likelihood that the underlying argument is correct.<br /><br />Suresh:<br /><br />I have no problem with the supposition that the utility of author identity is outweighed by its allowance for harmful bias.  I just think that one should acknowledge the useful aspects openly (as Omer expressed much more succinctly than me).", "author": "James R Lee", "published": "2018-01-10 15:19:54.767000-05:00", "title": ""}, {"content": "&gt;  The theory community hasn&#39;t historically taken &quot;conflicts of interest&quot; issues seriously, as I&#39;ve written about before (I guess a rather long time ago!). <br /><br />That was certainly true historically, but things have changed considerably. In particular, SODA had some forms of conflict of interest management over the last few years. The details varied, mostly due to the idiosyncrasies of the TCS program committee format, but the process seems to be converging.  The same (I believe) holds for other major TCS conferences.", "author": "Piotr", "published": "2018-01-10 17:08:12.285000-05:00", "title": ""}, {"content": "1)  Piotr:  Thank you, Piotr, for the reminder that there have in fact been some beneficial changes.  <br />2)  James:  I was responding to your argument, rather than making one about bias, as my post was just a pointer.    What I pointed to contains relevant arguments, and I believe the bias arguments have been well laid out in the past..  In particular, I might point out:  <br /><br />From Suresh&#39;s blog:<br /><br />&quot;...there is now a large body of evidence suggesting that:<br /><br />All people are susceptible to implicit biases, whether it be regarding institutional status, individual status, or demographic stereotyping. And what&#39;s worse that we are incredibly bad at assessing or detecting our own biases. At this point, a claim that a community is not susceptible to bias is the one that needs evidence.&quot;<br /><br />To be clear, I think Suresh is talking about negative biases here (as in the Tomkins quote below), which would include giving the same paper a higher score based on knowledge if it was written by a &quot;famous&quot; author, and potentially biases against underrepresented groups including women.  This would also include potential for biases that might be seen as forms of conflict of interest.  <br /><br />From the paper by Tomkins et al:<br /><br />&quot;Our second point with respect to reviewing is that, whatever<br />the process that resulted in the reviewers being assigned the paper,<br />the single-blind reviewers with knowledge of the authors and<br />affiliations are much more positive regarding papers from famous<br />authors and top institutions. Again the implications are not cut<br />and dried, but it is reasonable to raise the concern that authors<br />who are not famous and not from a top institution may see lower<br />likelihood for acceptance of <i> exactly the same work </i>.&quot;<br /><br />They also discuss the (negative) effects (of single-blind reviewing) on female authors.  <br /><br />", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2018-01-10 17:23:48.045000-05:00", "title": ""}, {"content": "Omer, I&#39;d be interested in hearing your critique of double blind review as well as your experiences from crypto. It&#39;s definitely good to learn from other experiences, especially since there aren&#39;t too many theory-adjacent communities that use double blind. <br /><br />Sariel in a different thread points to the discussion that ACL had. That&#39;s an interesting case because they started off with double blind review, realized the the arxiv undermines this, and now have to decide how to deal with this - which they did by blocking arxiv submissions - a controversial position. <br /><br />In a sense, because we&#39;ve waited long enough to deal with double blind review, we&#39;re being forced to deal with the arxiv subversion of blinding and double-blind review all at the same time. <br /><br />James, I fully agree that one should not undersell the potential useful signal from author identity. It is definitely about tradeoffs, and making them explicit perhaps makes the discussion and pressure points clearer. ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkatasubramanian:Suresh.html\">Suresh Venkatasubramanian</a>", "published": "2018-01-11 01:07:14.174000-05:00", "title": ""}, {"content": "Since Suresh just sort of agreed with James about tradeoffs, let me clarify my disagreements with James.  (Again, I think these arguments are standard, but I&#39;ll relate them.)  Some arguments relate to how we weight certain problems, and are perhaps more subjective.  Some are less so.<br /><br />My understanding is James is perfectly happy in a world where a paper that is some delta better by unknown author X is regularly rejected in favor of a less good paper by known, famous, trusted person Y, because he believes that&#39;s necessary for the system.  Otherwise, the tradeoff is we&#39;ll regularly accept too many buggy or problematic papers by unknown authors, and that&#39;s a worse problem.  I disagree, and I am unhappy with such a system.  <br /><br />First, I don&#39;t think this is really a worse problem, in terms of frequency, or in terms of how it is or can be dealt with by the community after the fact (once bugs are found, have a mechanism for dealing with them).  But I don&#39;t think either of us have anything more than anecdotal evidence to back the questions of frequency and importance up, so let&#39;s chalk that up to subjective judgment.  (Of course, it&#39;s my blog, so my bias is we should assume that my subjective judgment is correct.)<br /><br />Second, I think it&#39;s clear how to fix this problem in terms of double-blinding.  As a community, we need to decide that it&#39;s important to spend more time/effort reviewing to avoid the buggy papers.  Meanwhile, it&#39;s not clear how to solve what I see the bias problem in the other direction without double-blinding.  We can&#39;t decide as a community to reduce our implicit biases that we don&#39;t understand (in particular if some people explicitly think those biases are a perfectly reasonable thing).<br /><br />Third, I think James and others are ignoring the meta-issues that such biases close off the community, which is not healthy in the long term.  Do you think young, bright students want to work in an area where the established incumbents have an inherent advantage in conference acceptances, or that you have to have the right advisor to have a better shot of getting your papers in?  This is a variant of the &quot;what works are we never going to see&quot; argument, where we don&#39;t realize what we&#39;re missing out on because we don&#39;t recognize the long-term effects of bias on the community.  <br /><br />Fourth, going back to the back and forth James and I had on statistical thinking, I think he ignores the tendency people have to overweight these biases in decision-making, either implicitly or explicitly.  We are not statistical machines, we are individuals with flawed judgments that overreact to past information.  (See the works of Kahenman or any behavioral economist author you like.)  I think people just naturally overweight the &quot;I&#39;m comfortable with Y, I don&#39;t know X&quot; aspect in their judgments, in ways they don&#39;t recognize, and I believe here there&#39;s scientific evidence (at a general level) to back that up.<br /><br />I&#39;m sure there are other arguments that I&#39;m forgetting.  <br />", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2018-01-11 08:33:48.901000-05:00", "title": ""}, {"content": "Whoops, I can&#39;t seem to edit that last comment, but I realize that part of James&#39;s argument is possibly we need to know author names because there are not only unknown authors but known authors X whose work, for whatever reason, we trust less than even an unknown author.  I don&#39;t think this substantially changes my points, except perhaps the first one, where again it&#39;s a perhaps subjective and at least non well quantified question of how often that information is important.  ", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html\">Michael Mitzenmacher</a>", "published": "2018-01-11 09:02:57.136000-05:00", "title": ""}, {"content": "Wrote my own post about this https://windowsontheory.org/2018/01/11/on-double-blind-reviews-in-theory-conferences/ <br /><br />Given my experiences in STOC/FOCS and CRYPTO, I don&#39;t think trusting proofs is the reason we can&#39;t use anonymous submissions, but there are several other problems with that model. In particular, CRYPTO moved to double-blind submissions before the age of arxiv and eprint, but I don&#39;t think that model really makes sense today.<br /><br />--Boaz Barak<br />", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barak:Boaz.html\">Boaz Barak</a>", "published": "2018-01-11 17:21:43.430000-05:00", "title": ""}, {"content": "&gt; imagine we had a numerical confidence score for each author, a rule that says that the confidence of a paper is some function of the confidence scores of the authors, and a well defined rule to update our prior confidence in the paper based on these scores. And that each and every one of us agreed on this scoring and also agreed on the same update model for our beliefs. And had the same beliefs. <br /><br />&gt; But of course such a scenario doesn&#39;t exist in reality. We have different ways in which we might update priors based on author identity and that lack of consistency is a real problem, because that&#39;s precisely where subjective implicit biases appear to kick in.<br /><br />@Suresh, I&#39;m in favor of double-blind (he said, anonymously), but this seems like funny argument to give as the ultimate justification of it.<br /><br />After all, there are lots of kinds of scenarios where multiple agents collaborate on a joint task, more or less successfully, despite their not sharing identical, formally specified understandings / decision-making methods: think of wisdom-of-crowds stuff like counting jelly beans, or even just of informal language (we don&#39;t share formally identical definitions of all the words in our heads, but we often can communicate reasonably well).<br /><br />Indeed, think of reviewing more generally: nobody would insist that all reviewers share &quot;a rule that says that the confidence of a paper is some function of [some fixed list of paper attributes], and a well defined rule to update our prior confidence in the paper based on these scores.&quot; Nobody cites the nonexistence of such a universal scoring function &quot;that each and every one of us agreed on&quot; as a knock-down argument against the idea of collaborative peer review itself.<br /><br />Instead, isn&#39;t the argument against (inappropriate) bias going to have to rest on concerns like A) the concrete injustices done to the individuals involved in false negatives and (less concretely) B) arguments about the net harm done to the system as a whole?", "author": "Anonymous", "published": "2018-01-11 21:59:18.799000-05:00", "title": ""}, {"content": "From my perspective, the issue is rather simple: a conference should move to the DB system if the majority of the conference community is willing to put up with (minor, but non-negligible) inconveniences resulting from the change. I am referring to  (a) specifying conflicts with (sub)-reviewers before the submission (can take about 10-15 minutes for large conferences) and (b) anonymizing the paper (again, a few minutes). Essentially, If most of the members of the conference community believe that the existing process unfairly favors well-known authors and other groups (and there is some evidence to back this up, even if it was obtained for different conferences), then continuing the non-DB process is unsustainable. Ultimately, people will end up submitting their papers to venues where they  expect a fair reviewing process, and there are many conferences to choose from these days.<br /><br />That said, it is good to remember that DB reviewing is not a silver bullet, and there are limitations (notably arxiv) and side effects, as listed in other comments. Here are a few more points to keep in mind:<br /><br />- regarding the issue of &quot;untrusted authors&quot;: note that, in the DB system, this reasoning can still be applied, albeit only at the PC chair level. Which might be a good thing, for consistency reasons.<br /> <br />Also, from my experience, there are many tale tell signs of an incorrect paper: exaggerated but vague claims, lack of complete proofs, etc. In fact, I am not sure that we are really losing that much information by anonymizing papers.<br /><br />- it is also good to point out that the DB process puts an onus on the PC chair to ensure that any conflict of interest rules are followed. In the current system, any PC member can point out that a reviewer is obviously conflicted with the author(s) or that a group of papers is being reviewed by a &quot;mutual admiration circle&quot;. In the DB system only PC chairs can identify such cases, which means either more work for the chair, or (if the chair drops the ball), no enforcement.  <br /><br />  (This could also be viewed as an argument for having co-chairs, to share the workload).", "author": "Piotr", "published": "2018-01-12 00:50:05.787000-05:00", "title": ""}]