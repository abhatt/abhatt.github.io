[{"content": "<![CDATA[<p>Craig #38 The simulation does work for the construction used in the paper, where the Toffolis are used to build the permutation of fig. 4. It is correct that the construction does not work for every gate array that corresponds to a certain function. But there are even quantum unitaries that give the correct function map in the computational basis, but give the wrong phase relation, and subsequently the wrong output for these algorithms. We give an example in Section 5 of our paper in which the quantum unitary has the correct function output, but for which the quantum D-J algorithm gives no information about the function, just as your example for QSL above. One phase rotation is enough. When taking this possibility into account, most quantum unitaries that give the correct function map give the wrong phase relation, similar to QSL. It is extremely important that the phase relation is preserved in the quantum unitary, which is part of the difficulty of building a quantum computer.</p>\n<p>Mapping this into our model, we find that &#8220;The QSL framework presented above is deliberately chosen as simple as possible, &#8230;. A direct consequence of this simplicity is that the phase relation requirement of quantum computation, that enables phase kick-back, is translated into a simple requirement on the QSL oracles, presence or absence of a CNOT between query- and answer-register.&#8221; This is the reason the simulation only works for the construction used in our paper.</p>\n<p>We do have another more advanced version of the QSL Toffoli in the works, that eases the rather harsh requirement on oracle structure, and enables small instances of Shor and Grover to be run in QSL. Only small instances, mind, we do not expect to be able to factor efficiently. Our intent is to learn more on the resources used in a quantum computer, learn more about what is the real difficulty in building a quantum computer. As far as is possible.</p>\n<p>And we agree wholeheartedly with Scott #44: Typically, the hope with quantum information is sometimes to do better than the best classical strategy, and for the \u201csometimes\u201d to include cases that someone might actually care about.</p>\n]]>", "author": "Jan-ke Larsson", "published": "2018-02-07 15:58:43+00:00", "title": "By: Jan-\u00c5ke Larsson"}, {"content": "<![CDATA[<p>Hi Scott,<br />\nThank you very much for checking out the Calude Stay paper, which I just learned about and am just starting to try to understand. But clearly the secret,  good or bad , is in the measure.  And of course you can devise measures where the odd numbers are much more common than the even numbers or vice versa.<br />\nA similar paper which I have been aware of longer is Hamkins and Miasnikov, The halting problem is decidable on a set of asymptotic probability one,  arXiv:math/0504351.  The weakness here, which H&M point out is that it only applies to Turing machines with semi-infinite tapes.<br />\n((A very old joke:  All of mathematics is trivial or untrue.))<br />\nNevertheless I wonder if Calude-Stay and Hamkins-Miasnikov are still true (although  unproved) for more reasonable measures.<br />\nThat is, the average proof is short, and long proofs (as well as Goedel-Rosser statements and busy beavers) are rare.<br />\nSemi-evidence for this speculation comes from Wolfram\u2019s search for the minimal universal Turing machine as well as the busy beavers work.<br />\nI don\u2019t even know what is known or widely believed on the question of typical proof lengths (or typical halting times) despite having googled around and being aware of (but not claiming to understand) references such as Plaisted and Zhu and also Kroening and Strichman.<br />\nAny other good references or further thoughts?<br />\nThanks again and TIA<br />\nJim Graber</p>\n]]>", "author": "Jim Graber", "published": "2018-02-07 16:26:32+00:00", "title": "By: Jim Graber"}, {"content": "<![CDATA[<p>Dear Scott, did you see this paper?</p>\n<p>&#8216;Simulating boson sampling in lossy architectures&#8217; ( \tarXiv:1712.10037 )</p>\n<p>&#8220;Losses are probably the most damaging imperfections challenging boson sampling. Despite its importance, little is know about the resilience of boson sampling to losses, except that it remains hard in the regime of a constant number of lost photons. In this work we show that all current architectures that suffer from an exponential decay of the transmission with the depth of the circuit, such as integrated photonic circuits or optical fibers, can be nearly efficiently simulated classically. Either because the depth of the circuit is large enough that it can be simulated by thermal noise with an algorithm running in polynomial time, or the depth of the circuit is short enough that a tensor network simulation runs in quasi-polynomial time.&#8221;</p>\n<p>I know that you replied to comment that was long similar lines (exponential loss in photon numbers gives exponential running time of a boson sampler), and your reply was something like that boson sampling might become fault tolerant in the future. To me though, it seems like the only way to introduce fault tolerance is some kind of feed forward and then you&#8217;re not in linear optics anymore. Or to have loss that doesn&#8217;t scale exponentially (how?).</p>\n<p>Of course this paper doesn&#8217;t say you can&#8217;t make a specific instance of a boson sampler that cannot be simulated by any available classical computer (that might happen), but it seems to question the asymptotic scaling.</p>\n]]>", "author": "eot", "published": "2018-02-07 16:27:42+00:00", "title": "By: eot"}, {"content": "<![CDATA[<p>Jim #46: If we consider (say) theorems of ZF set theory that are n bits long, then the <i>average</i> length of their proofs will be mind-bogglingly enormous.  But that&#8217;s like Christos Papadimitriou&#8217;s quip that the average net worth of his coauthors is more than $1 billion.  (One of them was Bill Gates, then a freshman at Harvard.)  In the ZF case, the average will be dominated by the few theorems&#8212;which we know to exist by an argument of G&ouml;del&#8212;whose shortest proofs have Busy Beaver length.</p>\n<p>So presumably we really want to be asking about the <i>median</i> proof length of an n-bit theorem&#8212;or analogously, and for exactly the same reasons, the <i>median</i> time taken by an n-bit halting program to halt.  In this case, the answer could depend a lot on messy details of how you do the enumeration, but I could easily believe it&#8217;s extremely small: O(n) or maybe even O(1).  I don&#8217;t know what that tells you about anything else, but it would be fun to work it out if no one&#8217;s done so already.  Anyone have ideas?</p>\n]]>", "author": "Scott", "published": "2018-02-07 18:40:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>eot #47: Sure, I saw that paper.  Look, I don&#8217;t think <i>any</i> QC architecture has acceptable asymptotic scaling in the absence of fault-tolerance.  With BosonSampling, the idea has always been</p>\n<p>(1) <i>if</i> you could do it near-perfectly (say, using fault-tolerance), then there are very interesting arguments that you&#8217;d doing something classically hard, and</p>\n<p>(2) even in the world of the near future, where you&#8217;re not going to do it near-perfectly, you might be able to do it with 50 or 60 photons well enough to get a clear speedup over the best classical simulations known or believed to exist.</p>\n<p>We&#8217;ve never claimed more.  (Note also that, even if you <i>could</i> scale BosonSampling to arbitrary photon numbers, as far as we know it wouldn&#8217;t be good for anything, among other reasons because we&#8217;d no longer know how to verify the answers classically!)</p>\n<p>If you care about more detailed numbers, as long as the beamsplitters don&#8217;t need to be nearest-neighbor, I see no reason why BosonSampling shouldn&#8217;t be classically hard with a beamsplitter network of depth ~log(n).  <i>If</i> BosonSampling remains hard with a constant fraction of lost photons&#8212;something we don&#8217;t yet know, but which is consistent with current knowledge&#8212;that would mean that to solve a classically hard problem, it would be enough to get the loss rate down to ~1/log(n) per beamsplitter, which looks like it could be achieved with plenty of margin to spare for the range of n&#8217;s we&#8217;re talking about.  Or is there something in the Garcia-Patron et al. paper that suggests otherwise?</p>\n]]>", "author": "Scott", "published": "2018-02-07 18:49:38+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott, on your reply to my comment #43, I have to disagree that quantum game theory and quantum computation have nothing in common. After all quantum game theory or game theory in general has two or more players competing against each other via quantum or classical strategies. These strategies are nothing but quantum algorithms with a finite number of steps to perform a desired action in lieu of some payoffs at the end. In fact quantum game theory can be seen as a test bed for quantum vs classical algorithms or quantum vs quantum algorithms, in order to find out which one is better at a certain task.</p>\n]]>", "author": "COLIN BENJAMIN", "published": "2018-02-08 00:38:26+00:00", "title": "By: COLIN BENJAMIN"}, {"content": "<![CDATA[<p>Colin #50: I didn&#8217;t say they had <i>nothing</i> in common.</p>\n]]>", "author": "Scott", "published": "2018-02-08 00:42:35+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>There&#8217;s another paper by Calude and J\u00fcrgensen claiming that almost all arithmetically true statements are unprovable, over a reasonably natural distribution based on the lengths of the statements.</p>\n<p><a href=\"http://www.cs.auckland.ac.nz/~cristian/aam.pdf\" rel=\"nofollow\">http://www.cs.auckland.ac.nz/~cristian/aam.pdf</a></p>\n]]>", "author": "asdf", "published": "2018-02-08 02:23:32+00:00", "title": "By: asdf"}, {"content": "<![CDATA[<p>Scott, how do you feel about 1802.02175, appearing on the arXiv tonight, which claims to be based mainly on work you did but did not publish?</p>\n]]>", "author": "clayton", "published": "2018-02-08 03:45:47+00:00", "title": "By: clayton"}, {"content": "<![CDATA[<p>clayton #53: Lenny asked me, and I happily gave him my blessing to post that.  It feels like a huge weight off my shoulders.</p>\n<p>After I&#8217;d dragged my feet for two years with writing our paper, and Lenny (who at more than twice my age has more than 50 times my energy) got more and more impatient with me, I had no right whatsoever to tell him not to post whatever the hell he wanted!</p>\n<p>I haven&#8217;t read Lenny&#8217;s current manuscript carefully to see if there&#8217;s stuff in it that I disagree with.  That&#8217;s completely intentional&#8212;if I did read it, I&#8217;m sure I <i>would</i> find stuff to disagree with, but then I&#8217;d drag my feet on providing the necessary revisions for another two years!</p>\n<p>Instead, I&#8217;m simply hoping that once the pile of stuff that I&#8217;ve been suffocating under clears up enough that I can breathe, I&#8217;ll write up the results more formally and then we&#8217;ll put both of our names on the resulting paper.</p>\n<p>In the meantime, if you&#8217;d like to read my version of these results, then please see Chapter 7 of my <a href=\"https://www.scottaaronson.com/barbados-2016.pdf\" rel=\"nofollow\">Barbados lecture notes</a>&#8212;it&#8217;s pretty much all there.</p>\n]]>", "author": "Scott", "published": "2018-02-08 06:35:53+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #53: very cool! I wondered about the connection to the Barbados lecture, but I&#8217;m glad to hear that nothing unhappy is happening behind the scenes</p>\n]]>", "author": "clayton", "published": "2018-02-08 14:30:33+00:00", "title": "By: clayton"}, {"content": "<![CDATA[<p>[&#8230;] to just restate one of their research targets, albeit succinctly.\u201d The computer scientist Scott Aaronson wrote on his [&#8230;]</p>\n]]>", "author": "The last questions | Alec Nevala-Lee", "published": "2018-02-08 14:44:29+00:00", "title": "By: The last questions | Alec Nevala-Lee"}, {"content": "<![CDATA[<p>Jan-\u00c5ke Larsson #45: I guess I don&#8217;t understand the point of the paper if QSL can only simulate such a limited gate set with so many restrictions around how they can be used.</p>\n<p>Stabilizer simulations could efficiently simulate larger gate sets over a decade ago, without such restrictions. What does QSL do that GraphSim couldn&#8217;t do in 2005?</p>\n]]>", "author": "Craig Gidney", "published": "2018-02-08 18:44:19+00:00", "title": "By: Craig Gidney"}, {"content": "<![CDATA[<blockquote><p><b>Scott</b> deposes (<i>circa</i> <a href=\"#comment-1753209\" rel=\"nofollow\">#49</a>) I&nbsp;don\u2019t think any QC architecture has acceptable asymptotic scaling in the absence of fault-tolerance &#8230; We\u2019ve never claimed more.</p></blockquote>\n<p>Searching my own BibTeX database for comparable assertions, I found no such statement in the peer-reviewed literature prior to September 2017, when Aram Harrow and Ashley Montanaro&#8217;s <i>Nature</i> survey article &#8220;Quantum computational supremacy&#8221; opined:</p>\n<blockquote><p>The question of how to model simulability in the presence of noise is subtle and still under debate.&nbsp;[&hellip;] Quantum-supremacy experiments may need to make use of some form of error correction, but this might be substantially simpler than the machinery required for full quantum fault-tolerance.&nbsp;[&hellip;] In these early days of the field, the focus on quantum supremacy is a way to ensure that quantum computers solve clearly defined problems for which the classical competition can be well understood.</p></blockquote>\n<p>It&#8217;s lamentable that Harrow and Montanaro&#8217;s <i>Nature</i> survey does not stipulate which &#8220;classical competition&#8221; quantum simulation algorithms can reasonably be regarded as &#8220;well understood.&#8221; </p>\n<p>Instead, it&#8217;s far from obvious (to me anyway) that &#8220;classical competition&#8221; algorithms are well understood by <i>anyone</i>.   As Cristian Calude rightly says in <a href=\"https://www.quantamagazine.org/quantum-computers-struggle-against-classical-algorithms-20180201/\" rel=\"nofollow\">a recent <i>Quanta</i> article</a> (hopefully in the part of the <i>Quanta</i> article that Scott calls &#8220;quite good&#8221;):</p>\n<blockquote><p>Most of the time when people talk about quantum computing, classical computing is dismissed, like something that is past its prime.  But that is not the case. This is an ongoing competition.</p></blockquote>\n<p>Even today, does there exist anywhere in the peer-reviewed Quantum Supremacy literature, any <i>explicit</i> acknowledgement that scalable demonstrations of Quantum Supremacy plausibly may require scalably fault-tolerant general quantum dynamics?  Such that, in the absence of experimental demonstrations of scalably fault-tolerant quantum dynamics, and in the presence of ongoing improvements in classical simulation efficiency, it is entirely plausible that demonstrating Quantum Supremacy, in any form whatsoever, will prove to be infeasible, now and forever?</p>\n<p>In summary, when it comes to the feasibility vs infeasiblity of demonstrating Quantum Supremacy, neither side&#8217;s &#8220;bailey&#8221; is secure, and the fertile &#8220;motte&#8221; of quantum knowledge extends farther than either side can reasonably see.</p>\n]]>", "author": "John Sidles", "published": "2018-02-08 19:52:59+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Since people are talking about Calude-Jurgensen, maybe people can help me understand it. Nine years ago, the paper asdf links came up in <a href=\"https://mathoverflow.net/a/7902/297\" rel=\"nofollow\">this Mathoverflow thread</a> and I argued that it couldn&#8217;t be true. For a grammatical sentence X in some formal theory, let f(X) be the sentence &#8220;0=0 or X&#8221;. Every sentence of the form f(X) is provable. I argued that, for any reasonable probability distribution on grammatical sentences, a positive proportion of them are of the form f(X). </p>\n<p>I couldn&#8217;t follow the definition of the distribution in the Calude-Jurgensen paper, so I couldn&#8217;t nail down the issue for certain, and writing Calude didn&#8217;t clarify matters. It could be that I am making some basic error. Can anyone clarify this issue for me? Or just suggest some natural probability measure for which this issue (and easy variants of it) don&#8217;t arise?</p>\n<p>It seems to me the same same issue also applies to Scott&#8217;s comment 48. I have no idea about the median ZF theorem, but some positive proportion of ZF theorems should be of the form f(X). Analogously, some positive proportion of Turing machines should execute the algorithm &#8220;If 0=0, halt, else (arbitrary code block).&#8221;</p>\n<p>Are there any good ways to avoid these issues?</p>\n]]>", "author": "David Speyer", "published": "2018-02-08 21:08:59+00:00", "title": "By: David Speyer"}, {"content": "<![CDATA[<p>My third paragraph should have pointed out explicitly that f(X) has a proof of length O(|X|).</p>\n]]>", "author": "David Speyer", "published": "2018-02-08 21:09:48+00:00", "title": "By: David Speyer"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>will a Quantum Computer give any sort of advantage for bitcoin mining?<br />\nAnd if so, where can I buy two dozens of them?</p>\n]]>", "author": "fred", "published": "2018-02-08 21:53:08+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>Scott,</p>\n<p>regarding Boson Sampling, is it conceivable that nature made it so that quantum supremacy exists only for non Turing complete systems?</p>\n]]>", "author": "fred", "published": "2018-02-08 21:57:55+00:00", "title": "By: fred"}, {"content": "<![CDATA[<p>fred #61: You&#8217;re about the 5000th person to have asked.  I&#8217;ll give you the same answer I gave everyone else, which is to read <a href=\"https://arxiv.org/abs/1710.10377\" rel=\"nofollow\">this recent survey</a>.  Long story short:</p>\n<p>(1) Sure, a QC could give you a square-root (Grover) speedup for the proof-of-work involved in bitcoin mining, though almost certainly no more than that.</p>\n<p>(2) If you&#8217;re the only entity in the world with full fault-tolerant QCs, this could give you a significant advantage.  If a bunch of entities have QCs that they use for bitcoin mining, then the hardness parameter automatically gets adjusted to compensate and we&#8217;re right back where we started.</p>\n<p>(3) If people cared about this, there are simple ways they could modify the proof-of-work to reduce QCs&#8217; advantage for it, probably to where it no longer mattered at all.</p>\n<p>(4) With bitcoin as it now exists, the <i>biggest</i> threat from QCs actually involves the signature scheme (i.e., the way you prove that given bitcoins are under your control), which is currently based on elliptic-curve crypto and is therefore fully breakable by Shor&#8217;s algorithm.  Again, if people cared enough, they could migrate that aspect of bitcoin to quantum-resistant signature schemes.</p>\n<p>(5) <i>None</i> of this is going to be relevant in what John Preskill calls the &#8220;NISQ era&#8221;&#8212;i.e., the coming era of noisy, non-fault-tolerant intermediate-scale QCs, with 50 to a few hundred qubits.  It only really starts to matter in the era of full fault-tolerant QC, whose date of arrival is left to the reader to determine.</p>\n]]>", "author": "Scott", "published": "2018-02-08 22:06:08+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>fred #62: Sure, a priori it&#8217;s conceivable that the class of feasible problems in the physical world could exceed BPP (or its sampling analog), while still not being all of BQP&#8212;I think that&#8217;s tantamount to what you&#8217;re asking.</p>\n<p>It&#8217;s just hard for me to see any such scenario that&#8217;s consistent with what we already know.  E.g., we <i>know</i> that it&#8217;s possible to get outside the &#8220;self-contained little playground&#8221; defined by BosonSampling, by simply adding nonlinear elements or feedforward measurements to your optical network.  Similarly for IQP, DQC1, and the other non-universal models.  Of course, every resource you add makes the engineering requirements all the more demanding, which is why it&#8217;s plausible that we&#8217;ll see non-universal quantum supremacy well before we see universal QC.  But given what&#8217;s already been demonstrated, I personally don&#8217;t feel like there&#8217;s any mathematically natural and physically plausible stopping point beyond BPP that&#8217;s short of all of BQP&#8212;or at least, none that I know of.</p>\n]]>", "author": "Scott", "published": "2018-02-08 22:14:44+00:00", "title": "By: Scott"}]