[{"content": "<![CDATA[<p>Raoul #34:</p>\n<ul>There is no reason to think it could be lowered to even n^999999, other than the fact in some cases it has happened.</p>\n<p>So, it might have world changing theoretical importance, but it will continue to have zero practical importance.</p>\n<p>Pretty much everyone agrees that P = NP is the top TCS question. We are all on board with that. But why are so many unwilling to let it just be a great theoretical problem? Claiming it has practical significance is irresponsible BS.</ul>\n<p>Suppose someone built a controlled nuclear fusion generator, which put out way more power than was needed to run it, but the one caveat was that the current model cost ten billion dollars per day to operate, making it completely economically impractical.</p>\n<p>By your standards of argument, we would need to say: this discovery is purely theoretical; it has <i>zero</i> practical significance (and claiming that it does is irresponsible BS).  We can&#8217;t say that the cost will probably come down, since logically, no one can <i>prove</i> that the cost will come down by even a cent.</p>\n<p>But I think the most hardheaded businessperson would say that&#8217;s completely absurd.  If we&#8217;re talking about practical significance at all, then ipso facto we&#8217;ve left the realm of proof and entered the realm of Bayesian likelihood.  And all of our experience in theoretical computer science tells us that exponents, particularly huge exponents, are a lot like prices.  I.e., they&#8217;re numbers whose hugeness is <i>way</i> more likely to reflect the messy compromises of a proof than some Platonic reality, and that (like the cost of a brand-new technology) can come down dramatically if people care enough about bringing them down, and invest enough blood and sweat into optimizing them.</p>\n<p>Must that <i>always</i> be the case?  Of course not.  And believe me that I&#8217;m perfectly capable of distinguishing what we can prove from what&#8217;s merely in keeping with all our previous experience.  But if I&#8217;m asked to speculate about the <i>likely practical implications</i> of such-and-such a result (as opposed to the logically provable implications), then why on earth should I ignore previous experience?  It&#8217;s not what people do in any other domain, making the insistence on it in theoretical computer science an <a href=\"http://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/\" rel=\"nofollow\">isolated demand for rigor</a>.</p>\n]]>", "author": "Scott", "published": "2015-07-25 03:37:39+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>gentzen #46: If you really want to be pedantic, the point I was trying over and over to explain to vzn boils down to saying that the language</p>\n<p>L = {&lang;S,0<sup>n</sup>&rang; : S has a ZF proof &le;n symbols long}</p>\n<p>is in NP.  Which, I hope you&#8217;ll agree, is a true statement, and which suffices for the conceptual point I was trying to make (that if P=NP, proofs of length n could be searched for in poly(n) time).</p>\n<p>I think what&#8217;s going on here, honestly, is what SMBC once labeled the <a href=\"http://www.smbc-comics.com/?id=2475\" rel=\"nofollow\">&#8220;Mount Stupid&#8221; phenomenon</a>.  If you know almost nothing about complexity theory, you can just accept that the P vs. NP question asks whether there&#8217;s a general way to avoid the brute-force enumeration of exponentially many possibilities when searching for short proofs of theorems&#8212;as G&ouml;del put it in 1956, and as Cook put it again in 1971.  If you know more about complexity theory, but still not enough, you can think of objections to that view (&#8220;who says searching for proofs is even an NP problem?  what&#8217;s the exact problem statement, anyway&#8212;how is the upper bound on proof length encoded?&#8221; etc).  If you know still more, then you immediately know how to answer those objections, thereby returning you to the original, &#8220;na&iuml;ve&#8221; view of what P vs. NP was asking about.</p>\n<p>For this reason, I think my suggestion to vzn, to read or reread a complexity textbook, is fine.  There <i>are</i> plenty of questions that completely stump experts, or that are philosophical in nature, with the expert&#8217;s feeling or hunch barely better than the layperson&#8217;s.  But, not just here but in <a href=\"http://cstheory.stackexchange.com/questions/12377/applicability-of-church-turing-thesis-to-interactive-models-of-computation/12405#12405\" rel=\"nofollow\">previous discussions</a> (e.g. about quantum computing), vzn has had a bad habit of raising as devastating objections to an entire field things that he doesn&#8217;t know are <i>completely, totally, 100%</i> addressed in the standard textbooks, and then continuing to treat those objections as profound and under-studied even after this is pointed out to him&#8212;refusing to accept &#8220;like seriously, RTFTB&#8221; as an answer.</p>\n]]>", "author": "Scott", "published": "2015-07-25 04:14:13+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>With respect to quantum &#8230;, vzn&#8217;s views are indeed questionable, but his TCS background is solid (in my opinion).</p>\n<p>On a general note, I like the fact that you criticize &#8220;isolated demand for rigor&#8221;. How else could we distinguish between the facts that we know for sure, like that PA is consistent, that fact we could declare as dogmas like N != NP, and facts like that consistency of ZFC is a totally open question, which we will probably never be able to answer?</p>\n]]>", "author": "gentzen", "published": "2015-07-25 05:02:52+00:00", "title": "By: gentzen"}, {"content": "<![CDATA[<blockquote><p><b>Raoul</b> asserts (#34)&nbsp; &#8220;Pretty much everyone agrees that \\(\\mathsf{P}\\overset{\\scriptscriptstyle\\mathsf{?}}{=}\\mathsf{NP}\\) is the top TCS question. We are all on board with that.&#8221;</p></blockquote>\n<p>The Fall 2015 Simons Institute/Berkeley program <b><a href=\"http://simons.berkeley.edu/programs/complexity2015\" rel=\"nofollow\">Fine-Grained Complexity and Algorithm Design</a></b> (FGCAD, Aug&nbsp;19&nbsp;&ndash;&nbsp;Dec&nbsp;18, 2015) shows that a <i>marvelous</i> program in cutting-edge complexity research can be advanced that <i>doesn&#8217;t</i> directly tackle the vexatious \\(\\mathsf{P}\\overset{\\scriptscriptstyle\\mathsf{?}}{=}\\mathsf{NP}\\) question.  </p>\n<p>Rather, the focus of FGCAD&#8217;s four (star-studded) complexity theory workshops is less to <i>solve</i> \\(\\mathsf{P}\\overset{\\scriptscriptstyle\\mathsf{?}}{=}\\mathsf{NP}\\) than to <i>dissolve</i> it&nbsp;&mdash; or&nbsp;dissolve at least some edge cases of it&nbsp;&mdash;  in the &#8220;universal solvent&#8221; of fine-grained class-structure (as the <b><a href=\"http://simons.berkeley.edu/sites/default/files/styles/program_main/public/complexity_logo_final.png?itok=Fk2D7HQC\" rel=\"nofollow\">FGCAD logo</a></b> ingeniously depicts).</p>\n<p><b>Safe prediction</b>&nbsp;  The proceedings of the FGCAD workshops will be read with avid enjoyment by fans (well, me at least) of practical &#8220;Knuthian&#8221; algorithms for attacking NP-complete (and harder) problems.  </p>\n<p>One hopes that the FGCAD organizers have extended a special invitation to Donald Knuth to attend at least some of the FGCAD workshops.  To&nbsp;borrow Raoul&#8217;s phrase &#8220;we are all on-board with that.&#8221;</p>\n]]>", "author": "John Sidles", "published": "2015-07-25 06:04:01+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Scott:<br />\nDo you think a ST lower bound on SAT assuming NP is in P/Poly is useful?</p>\n]]>", "author": "a", "published": "2015-07-25 10:31:16+00:00", "title": "By: a"}, {"content": "<![CDATA[<p>a #54: What&#8217;s an &#8220;ST lower bound&#8221;?  A space/time tradeoff?</p>\n<p>In general, conditional results are useful, not always directly, but for helping to clarify the space of possibilities.</p>\n]]>", "author": "Scott", "published": "2015-07-25 10:41:26+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>JS that univalent foundations stuff/ HoTT is very intriguing & thx much for the ref, shows some of the state-of-the-art research in the area.</p>\n<p>lol G thx for the &#8220;support&#8221;. some useful/ applicable stuff/ refs. kinda. &#8220;damned by faint praise&#8221;</p>\n<p>am not able to easily articulate my objections but basically think the concept of complexity of theorem proving is not a very well nailed down area &#8220;yet&#8221;. research continues. it seems to cross cut fields and sit in a sort of limbo area of research. ATP research tends to be very applied & not look at complexity. complexity theory tends to be more theoretical. P=?NP does maybe both effectively and ineffectively capture some of this crosscutting.</p>\n<p>my big objection might be boiled down to &#8220;blowup&#8221;. there seem to be unexamined basic &#8220;blowups&#8221; in converting what we consider human-readable proofs into machine readable ones, before even the issue of verification is considered. and then there seem to be other &#8220;blowups&#8221; lurking in verification that make the idea of linear time verification a verging-on-naive simplification. but do believe these issues will be examined and addressed in years ahead based on current research trends.</p>\n<p>re blowup also along lines quoted by G, here is a semifamous paper maybe relevant<br />\n<a href=\"http://people.csail.mit.edu/meyer/stock-circuit-jacm.pdf\" rel=\"nofollow\">Cosmological Lower Bound on the Circuit Complexity of a Small Problem in Logic</a> Stockmeyer/ Meyer</p>\n<p>would luv to engage in a further &#8220;free for all no holds barred&#8221; discussion on this topic but feel scott hits below the intellectual belt sometimes, think veers outside of collegial/ respectful boundaries, & have suffered consequences in the past for expressing too much free speech on this blog, & every comment here is moderated etc.; invite others to drop by stackexchange chat rooms for more freewheeling/ uninhibited chats.</p>\n]]>", "author": "vzn", "published": "2015-07-25 18:50:27+00:00", "title": "By: vzn"}, {"content": "<![CDATA[<p>As a follow-up to my comment #45, I don&#8217;t know the relationship between BQP and NP but I&#8217;d love to see a highly nonconstructive proof that P=BQP&#8230; a breakthrough suggesting that the power of ZFC might be equivalent to the non-feasibility of quantum computing&#8230;</p>\n<p>Regarding univalent foundations, they look like a nice way to build computerized versions of proofs first imagined within a set theoretical context. I doubt we&#8217;ll have soon mathematicians who think only in HoTT. Too restrictive&#8230;</p>\n]]>", "author": "Serge", "published": "2015-07-26 12:02:17+00:00", "title": "By: Serge"}, {"content": "<![CDATA[<p>Has anyone ever even formalized the statement of P=NP or other millenium questions in coq, hol light, or other proof assistants? Even with a miraculous SAT solver this would still need to be done and agreed upon by humans, and might be nontrivial since computer formalized proofs make rigorous delta epsilon proofs look like flaky hand waving. As far as I can tell there are formalizations of the correctness of Cook-Levin reduction and AKS primality test, but not of polynomial running time, which is apparently hard to formalize. If I&#8217;m overstating the difficulty then just paste the coq code for the the Poincar\u00e9 conjecture in the comments.</p>\n]]>", "author": "Dewey", "published": "2015-07-26 20:45:19+00:00", "title": "By: Dewey"}, {"content": "<![CDATA[<p>The connection between NP=!P and between proving vs verification of mathematical theorem in real life mathematics is quite fascinating. Boaz Barak and I had discussed it on a previous blog post by Boaz (<a href=\"http://windowsontheory.org/2013/05/06/reasons-to-care-in-honor-of-scott-aaronson/#comment-6293\" rel=\"nofollow\">from this comment down</a>). Certainly, we are talking about <em>related</em> phenomena but perhaps the following can help clarifying the connection in more precise terms.</p>\n<p>Consider the following three statements:</p>\n<p>1) In mathematics, as practiced in real-life, it is easier to verify a mathematical proof than to find a proof.</p>\n<p>2) It is easier to verify that a certain collection of edges in a graph forms\u00a0a perfect matching than to find a perfect matching.</p>\n<p>3)\u00a0It is easier to verify that a certain collection of edges in a graph forms\u00a0a Hamiltonian cycle than to find a Hamiltonian cycle.</p>\n<p>All these three statements are very plausible, and they all part of some general phenomenon. The question is if when we zoom in, is statement 1) closer to statement 2) or to statement 3)? In real-life mathematics, is the gap between finding a proof and verifying it closer to the gap between finding a matching and verifying a matching, or to the gap between finding a Hamiltonian cycle and \u00a0verifying one?</p>\n<p>(Of course, when it comes to \u00a0general mathematical statements and not to real-life mathematical theorems, the gap between proving and verifying a proof manifests P =! NP. But the interesting issue is about real-life mathematical theorems.)</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalai:Gil.html\">Gil Kalai</a>", "published": "2015-07-26 22:59:34+00:00", "title": "By: Gil Kalai"}, {"content": "<![CDATA[<p>Here is a natural question (which is not addressed in any CT textbooks familiar to me), that is so constructed as to blend two recent remarks of Donald Knuth and Gil Kalai:<br />\n<blockquote>Almost all polynomial time algorithms are so complicated that they are beyond human comprehension, and could never be programmed for an actual computer in the real world. Existence is different from embodiment.<br />\n&nbsp;&mdash; Donald Knuth (per comment #7)</p>\n<p>The interesting issue is about real-life mathematical theorems.<br />\n&nbsp;&mdash; Gil Kalai (per comment #59)</p></blockquote>\n<p><b>Alice&#8217;s Claim</b>&nbsp; There exists a Turing machine \\(\\mathsf{TM}\\) that runs in PTIME (but not necessarily <i>provably</i> so) that infallibly separates <b><a href=\"http://dl.acm.org/citation.cfm?id=282271\" rel=\"nofollow\">mortal matrices</a></b> from non-mortal matrices (but the separation is not necessarily <i>provably</i> infallible).</p>\n<p>Which of the following responses by Bob is correct?</p>\n<p><b>Bob&#8217;s response A</b>&nbsp; Existing complexity theory theorems suffice to prove that Alice&#8217;s claim is false.</p>\n<p><b>Bob&#8217;s response B</b>&nbsp; Existing complexity theory conjectures (if&nbsp;true) suffice to prove that Alice&#8217;s claim is false.</p>\n<p><b>Bob&#8217;s response C</b>&nbsp; Complexity theory, as presently conceived, has nothing to say in regard to Alice&#8217;s claim.</p>\n<p><b>Question</b>&nbsp; Is separating PTIME \\(\\mathsf{TM}\\)s from the set of all \\(\\mathsf{TM}\\)s any easier than than separating mortal matrix-sets from the set of all matrix-sets?</p>\n]]>", "author": "John Sidles", "published": "2015-07-27 04:36:28+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>Scott #51: I&#8217;m not sure how pedantic I really want to be, or more precisely how pedantic I should strive to be.</p>\n<blockquote><p>the point I was trying over and over to explain to vzn boils down to saying that the language</p>\n<p>L = {\u27e8S,0n\u27e9 : S has a ZF proof \u2264n symbols long}</p>\n<p>is in NP. Which, I hope you\u2019ll agree, is a true statement\n</p></blockquote>\n<p>You have omitted the used proof calculus here. Possible choices include natural deduction, sequent calculus, Hilbert systems, semantic tableaux methods, &#8230; You also were not explicit about the fact that only systems for first-order should be used. But I have to agree that if you had been explicit about those details, then described language would have been in NP.</p>\n<p>My own feeling is that I should be at least a bit pedantic here. The shortest proofs using ZF with an appropriate formulation of a semantic tableaux method for 1st order logic will often be more than exponentially longer than the shortest proofs using the 2nd order variant of NGB together with an appropriate formulation of a sequent calculus for 2nd order logic.</p>\n<p>Please note that formal systems behave different than machine models (like single-tape single-head Turing machines vs. multi-head multi-tape Turing machines), where the resource usage for one (reasonable) machine model is polynomially related to the resource usage of any other (reasonable) machine model.</p>\n]]>", "author": "gentzen", "published": "2015-07-27 08:03:31+00:00", "title": "By: gentzen"}, {"content": "<![CDATA[<p>Following Scott&#8217;s excellent suggestion (in regard to past <i>Shtetl Optimized</i> comments), I&#8217;ve posted #60 as a <i>TCS StackExchange</i> question <b>&#8220;<a href=\"http://cstheory.stackexchange.com/questions/32094/the-mortal-matrix-problem-how-hard-is-deciding-class-membership\" rel=\"nofollow\">The Mortal Matrix problem: how hard is deciding class membership?</a>&#8220;</b>  </p>\n<p>If the answers are illuminating&nbsp;&mdash; as I hope they will be&nbsp;&mdash; then two days from now I&#8217;ll award a bounty to the best answer, in grateful appreciation of the creative collegial effort that is required to write good answers.</p>\n]]>", "author": "John Sidles", "published": "2015-07-27 13:33:54+00:00", "title": "By: John Sidles"}, {"content": "<![CDATA[<p>@Dewey 58: &#8220;Has anyone ever even formalized the statement of P=NP or other millenium questions in coq, hol light, or other proof assistants?&#8221;</p>\n<p>Inspired by this question, I decided to write a formalization of the P vs. NP statement in Agda. It may be found here:</p>\n<p><a href=\"http://pastebin.com/nCE92XUd\" rel=\"nofollow\">http://pastebin.com/nCE92XUd</a></p>\n<p>The whole thing is only 173 lines, and includes basic definitions such as the definition of the natural numbers. However, I suspect the Millenium problems would be longer to define, as P vs. NP is the only problem whose statement does not involve the real numbers, and those can be finicky to define and manipulate.</p>\n]]>", "author": "Itai Bar-Natan", "published": "2015-07-27 15:39:36+00:00", "title": "By: Itai Bar-Natan"}]