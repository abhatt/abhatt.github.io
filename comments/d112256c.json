[{"content": "<![CDATA[<p>Miguel #29: OK, thanks for the backstory.  It would gratify me if this post played a role in mediating a friendly resolution&#8212;where Slofstra reworded his abstract and introduction to be more in line with how the relevant community has used the phrase &#8220;Tsirelson&#8217;s problem&#8221; (rather than what someone reading Tsirelson&#8217;s 2006 note without that social context might have construed to be his problem), the community recognized Slofstra&#8217;s groundbreaking contribution, and everyone went home happy.</p>\n]]>", "author": "Scott", "published": "2016-06-21 11:56:02+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>To someone who&#8217;s not in this field the terminology sounds confusing indeed. I find names strong and weak Tsirelson&#8217;s problem also a bit confusing, because usually one would think that solution of strong version of a problem would imply solution of the weak but if I understood correctly, that wouldn&#8217;t necessarily be the case here.</p>\n<p>Also, since no-one has asked: what were/are the highlights of STOC&#8217;2016?</p>\n]]>", "author": "anon", "published": "2016-06-21 16:23:23+00:00", "title": "By: anon"}, {"content": "<![CDATA[<p>@anon31 the resolution of the strong question in the other direction (1=4, now ruled out by Slofstra) would imply the resolution of the weak question (as 3=4). There is always this danger when naming things &#8220;strong&#8221; and &#8220;weak&#8221; &#8212; if you guess wrong which way the answer will be, your terminology will confuse everyone.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Speyer:David.html\">David Speyer</a>", "published": "2016-06-21 16:50:27+00:00", "title": "By: David Speyer"}, {"content": "<![CDATA[<p>anon #31: The best paper talks were Babai on graph isomorphism, the awesome new two-source extractor by Eshan Chattopadhyay and David Zuckerman (who I&#8217;ll join soon at UT Austin), and the Reed-Muller code achieving capacity.  Another result that I and many others loved was &#8220;A polylog shaved is a lower bound made,&#8221; showing that if you could compute Edit Distance even in n<sup>2</sup>/log<sup>k</sup>(n) time for sufficiently large k&#8212;a tiny improvement over what&#8217;s known&#8212;That would imply a subexponential-time algorithm for FormulaSAT, which in turn would imply a new circuit lower bound (NEXP not in NC<sup>1</sup>).  I also really liked a result that &#8220;almost&#8221; derandomizes the fast parallel algorithms for finding a maximum matching in a bipartite graph&#8212;they do it in log<sup>2</sup> time with n<sup>log(n)</sup> parallel processors.  What else?  We now know that to store all the pairwise distances in an n-vertex graph, to constant additive error, requires &Omega;(n<sup>4/3</sup>) bits, which is tight (that was one of the Lewin Best Student Paper talks).  And there&#8217;s a new way to prove hardness of PAC-learning, based on the assumed hardness of random SAT (that was both a STOC talk and a tutorial).  And we now have super-polynomial lower bounds on Frege proofs for depth up to &radic;(log n) (the previous record was loglog(n)).  For completeness, Dana spoke on her and Subhash Khot&#8217;s candidate hard unique game, Troy Lee spoke on the new separations in query complexity, and my student Shalev Ben-David spoke on the followup work that separates randomized and quantum query complexities for a total Boolean function by the 2.5th power, more than the quadratic separation of Grover&#8217;s algorithm (the latter two things were discussed on my blog).  Anyone else who was at STOC should feel free to share more highlights.</p>\n]]>", "author": "Scott", "published": "2016-06-21 23:03:09+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>>> whether the universe was discrete or continuous</p>\n<p>Perhaps this is a stupid question, but assume that we finally find the mathematical description of fundamental physics and it suggests that the world is indeed continuous;<br />\nThe Loewenheim-Skolem theorem would then tell us that there is a countable model of that mathematical system and would this not suggest that the world is somehow discrete after all?</p>\n]]>", "author": "wolfgang", "published": "2016-06-22 00:42:42+00:00", "title": "By: wolfgang"}, {"content": "<![CDATA[<p>wolfgang #34: The Lowenheim-Skolem theorem is about models of first-order sentences, and probably not everyone would accept that our world is such a model.  But yes, your basic point stands: even if the world were fundamentally continuous, there would still be some discrete approximation to it that accounted for everything we could see or hear (to within the limits of visual and auditory perception), everything we could write a paper about, etc.  So at some point, as Tobias Fritz points out in the nice paper I linked to in the OP, the believer in continuity needs to appeal to Occam&#8217;s Razor, and say that the continuous model is simpler or more elegant, that the discretization is just an arbitrary imposition.</p>\n<p>My point was that, <i>if</i> the Connes embedding problem had a negative answer, and <i>if</i> the requisite game were actually winnable with probability 1, then this appeal to Occam&#8217;s Razor would be on very strong ground.  For in that case, accounting for the winning of the game using only finite-dimensional Hilbert spaces would mean giving up on locality, or some other equally-basic principle.  Of course, none of this has actually happened.</p>\n]]>", "author": "Scott", "published": "2016-06-22 02:07:48+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>I think that it is important to distinguish these two versions of Tsirelson&#8217;s conjectures, i.e., weak versus strong, when you want to communicate these ideas to mathematicians.  It just helps to clarify everyone&#8217;s thinking, especially to those of us new to the area. </p>\n<p>It also helps us outsiders to understand that whether or not all games achieve their quantum values is another, separate question. </p>\n<p>The result that Tsirelson proved in 1987 implies that 1=4 for n input, 2 output games, provided that you require that the marginal probabilities are all 1/2. So it is natural for those of us new to the area, to assume that Tsirelson&#8217;s conjecture is about 1=4 more generally and has nothing to do with closures or limits.</p>\n<p>Another interesting problem to me is whether or not 2=3.</p>\n<p>An important point that hasn&#8217;t been discussed: So far we are really only focusing on Tsirelson&#8217;s bivariate conjectures. What we really have is that 3=4 in the bivariate case is equivalent to Connes&#8217; embedding problem having  a positive answer.  But currently, we don&#8217;t know what 3=4 in multivariate cases might mean for operator algebras.</p>\n<p>What would it mean for physics if 3=4 in the bivariate case but not in the multivariate case?</p>\n<p>In any case, Slofstra has made a major advance in our understanding. </p>\n<p>Kudos, William!</p>\n]]>", "author": "Vern Paulsen", "published": "2016-06-22 14:14:03+00:00", "title": "By: Vern Paulsen"}, {"content": "<![CDATA[<p>Vern #36: Thanks!!</p>\n<p>Thinking about it more, there&#8217;s another basic problem here that I haven&#8217;t seen discussed: namely, can <i>Slofstra&#8217;s specific game</i> (the one based on Higman&#8217;s group) be won with probability approaching 1, using larger and larger finite amounts of entanglement?</p>\n<p>If the answer is no, then 3&ne;4 and the Connes embedding problem has a negative answer.</p>\n<p>If the answer is yes, then that seems like significant evidence in favor of 3=4 and Connes having a positive answer.</p>\n<p>But unlike the Connes embedding problem itself (in its usual formulations), this is an <i>extremely</i> concrete question, one that in principle could even be investigated using computer search for the optimal strategies (though I&#8217;m guessing that such searches would probably crap out before they told us anything interesting).</p>\n]]>", "author": "Scott", "published": "2016-06-22 16:25:10+00:00", "title": "By: Scott"}, {"content": "<![CDATA[<p>Scott #37: I would also really like to know the answer to this question. Since a negative answer would solve a major open problem, I bet that the answer is either yes or unknown =)</p>\n]]>", "author": "Mateus Arajo", "published": "2016-06-22 16:43:19+00:00", "title": "By: Mateus Ara\u00fajo"}, {"content": "<![CDATA[<p>Let me try to give some extra insight into Scott&#8217;s last question. Roughly, a group is hyperlinear if it has maps into the unitary matrices that are nearly multiplicative, growing more nearly multiplicative as the size of the matrices tends to infinity. </p>\n<p>If one had such near representations of Higman&#8217;s group, then that would give the strategies with probabilities approaching one.<br />\nDoes Higman&#8217;s group have such near representations?</p>\n<p>Well,  Connes&#8217; is equivalent to every countable discrete group being hyperlinear. So yes if Connes&#8217; is true. Moreover, Higman&#8217;s group is considered a good test case for this hyperlinear conjecture. William was aware of this and this is undoubtedly one reason that he chose HIgman&#8217;s group in his construction.</p>\n<p>&#8230;plus \u00e7a change, plus c&#8217;est la m\u00eame chose&#8230;</p>\n<p>So if one follows Scott&#8217;s approach and  finds optimal strategies in each dimension, one could then try to check, maybe using the 2nd order NPA hierarchy, their multiplicative behaviours on products of two generators. This might give some computational evidence for deciding if Higman&#8217;s group is hyperlinear.</p>\n<p>A nice reference for these connections between hyperlinear groups and Connes&#8217; embedding conjeccture is Capraro and Lupini&#8217;s:</p>\n<p>arXiv:1309.2034v6</p>\n]]>", "author": "Vern Paulsen", "published": "2016-06-23 01:38:44+00:00", "title": "By: Vern Paulsen"}, {"content": "<![CDATA[<p>Mateus #27: Yes, the game is completely explicit, just large. In a linear system game, Alice receives an equation, and must output a consistent assignment for all the variables in the equation. Bob receives a variable, and outputs a value for the variable. Thus the input sets for the game based on Higman&#8217;s group are roughly of size 300 and 400 after fine-tuning, while the output sets have size 8 (all equations in this case contain exactly 3 variables) and size 2 respectively. I expect that further fine-tuning could be done, but that any game constructed via this method would still be relatively large. The smallest game showing 2 != 4 could be I3322; I don&#8217;t see any reason to count it out. </p>\n<p>#37 and #38: we don&#8217;t know the answer to this question. If the answer is yes, then it would imply that 2 != 3, so resolving the question in either direction would be interesting.</p>\n]]>", "author": "<a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Slofstra:William.html\">William Slofstra</a>", "published": "2016-06-23 06:12:45+00:00", "title": "By: William Slofstra"}, {"content": "<![CDATA[<p>Slofstra #40: Thanks for the answer. So there is really no hope of attacking your specific game with numerical methods.</p>\n<p>But I&#8217;m skeptical that 2 can be different than 4 for I3322: The best upper bound we know is 0.250 875 38, which is equal to the best lower bound we know within numerical precision (see <a href=\"http://arxiv.org/abs/1006.3032\" rel=\"nofollow\">http://arxiv.org/abs/1006.3032</a> ). That paper shows also some inequalities in the 4422 scenario for which there is still a gap between the upper and lower bounds, so that is not ruled out.</p>\n]]>", "author": "Mateus Arajo", "published": "2016-06-23 11:02:47+00:00", "title": "By: Mateus Ara\u00fajo"}]