<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="/css/twocolumn.v1.css" type="text/css" media="screen">
<link rel="stylesheet" href="/css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="/favicon.ico">
<script type="text/javascript" src="/library/MochiKit.js"></script> 
<script type="text/javascript" src="/js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
 <script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="https://blog.xrds.acm.org/tag/theory/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.xrds.acm.org" title="Theory – XRDS">ACM Crossroads student magazine</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/25562705/posts/default" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://nanoexplanations.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nanoexplanations.wordpress.com" title="Nanoexplanations">Aaron Sterling</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Aleksander Madry</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/19908808/posts/default" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://andysresearch.blogspot.com/" title="Andy's Math/CS page">Andy's Math/CS page</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a title="">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange Community Blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/4068183698747623113/posts/default/-/TCS" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://teachingintrotocs.blogspot.com/search/label/TCS" title="A CS Professor's blog">Claire Mathieu</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default?alt=rss" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="http://blog.oddhead.com/feed/atom/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.oddhead.com" title="Oddhead Blog">David Pennock</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="http://grigory.github.io/blog/feed.xml" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://jsaia.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://jsaia.wordpress.com" title="Machinations">Jared Saia</a>
<br>
<a class="feedlink" href="https://ontopo.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ontopo.wordpress.com" title="on Topology">John Moeller</a>
<br>
<a class="feedlink" href="https://jonkatz.wordpress.com/category/tcs/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://jonkatz.wordpress.com" title="TCS – Random bits">Jonathan Katz</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/27705661/posts/default" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Manoj Prabhakaran</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/8890204/posts/default" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastian Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons institute blog</a>
<br>
<a class="feedlink" href="https://speedupblogger.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://speedupblogger.wordpress.com" title="Speedup in Computational Complexity">Speedup in Computational Complexity</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/WebdiariosDeMotocicleta" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://infoweekly.blogspot.com/" title="WebDiarios de Motocicleta">WebDiarios de Motocicleta</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/3455785628713238703/posts/default" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://kdphd.blogspot.com/" title="kd-PhD">kd-phd</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">my slice of pizza</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="/images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">tcs math</a>
<br>
</div>

<p>
Maintained by <A href="http://randomwalker.info/">Arvind Narayanan</a> (<a href="mailto:arvindn@cs.princeton.edu">email</a>).
</p>

<p>
Last updated <span class="datestr">at December 16, 2018 04:44 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.planetplanet.org/"><img src="/images/planetplanet.png" alt="Planet" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05577">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05577">The Glauber dynamics for edges colourings of trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Delcourt:Michelle.html">Michelle Delcourt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heinrich:Marc.html">Marc Heinrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perarnau:Guillem.html">Guillem Perarnau</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05577">PDF</a><br /><b>Abstract: </b>Let $T$ be a tree on $n$ vertices and with maximum degree $\Delta$. We show
that for $k\geq \Delta+1$ the Glauber dynamics for $k$-edge-colourings of $T$
mixes in polynomial time in $n$. The bound on the number of colours is best
possible as the chain is not even ergodic for $k \leq \Delta$. Our proof uses a
recursive decomposition of the tree into subtrees; we bound the relaxation time
of the original tree in terms of the relaxation time of its subtrees using
block dynamics and chain comparison techniques. Of independent interest, we
also introduce a monotonicity result for Glauber dynamics that simplifies our
proof.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05577"><span class="datestr">at December 16, 2018 04:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05528">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05528">3-Manifold triangulations with small treewidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Husz=aacute=r:Krist=oacute=f.html">Kristóf Huszár</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spreer:Jonathan.html">Jonathan Spreer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05528">PDF</a><br /><b>Abstract: </b>Motivated by fixed-parameter tractable (FPT) problems in computational
topology, we consider the treewidth of a compact, connected 3-manifold $M$
defined by \[
</p>
<p>\operatorname{tw}(M) =
\min\{\operatorname{tw}(\Gamma(\mathcal{T})):\mathcal{T}~\text{is a
triangulation of }M\}, \] where $\Gamma(\mathcal{T})$ denotes the dual graph of
$\mathcal{T}$. In this setting the relationship between the topology of a
3-manifold and its treewidth is of particular interest.
</p>
<p>First, as a corollary of work of Jaco and Rubinstein, we prove that for any
closed, orientable 3-manifold $M$ the treewidth $\operatorname{tw}(M)$ is at
most $4\mathfrak{g}(M)-2$ where $\mathfrak{g}(M)$ denotes the Heegaard genus of
$M$. In combination with our earlier work with Wagner, this yields that for
non-Haken manifolds the Heegaard genus and the treewidth are within a constant
factor.
</p>
<p>Second, we characterize all 3-manifolds of treewidth one: These are precisely
the lens spaces and a single other Seifert fibered space. Furthermore, we show
that all remaining orientable Seifert fibered spaces over the 2-sphere or a
non-orientable surface have treewidth two. In particular, for every spherical
3-manifold we exhibit a triangulation of treewidth at most two.
</p>
<p>Our results further validate the parameter of treewidth (and other related
parameters such as cutwidth, or congestion) to be useful for topological
computing, and also shed more light on the scope of existing FPT algorithms in
the field.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05528"><span class="datestr">at December 16, 2018 04:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05524">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05524">A Polynomial Time Algorithm for Maximum Likelihood Estimation of Multivariate Log-concave Densities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidiropoulos:Anastasios.html">Anastasios Sidiropoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:Alistair.html">Alistair Stewart</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05524">PDF</a><br /><b>Abstract: </b>We study the problem of computing the maximum likelihood estimator (MLE) of
multivariate log-concave densities. Our main result is the first
computationally efficient algorithm for this problem. In more detail, we give
an algorithm that, on input a set of $n$ points in $\mathbb{R}^d$ and an
accuracy parameter $\epsilon&gt;0$, it runs in time $\text{poly}(n, d,
1/\epsilon)$, and outputs a log-concave density that with high probability
maximizes the log-likelihood up to an additive $\epsilon$. Our approach relies
on a natural convex optimization formulation of the underlying problem that can
be efficiently solved by a projected stochastic subgradient method. The main
challenge lies in showing that a stochastic subgradient of our objective
function can be efficiently approximated. To achieve this, we rely on
structural results on approximation of log-concave densities and leverage
classical algorithmic tools on volume approximation of convex bodies and
uniform sampling from convex sets.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05524"><span class="datestr">at December 16, 2018 04:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05419">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05419">Shortest Reconfiguration of Matchings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hatanaka:Tatsuhiko.html">Tatsuhiko Hatanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=uuml=hlenthaler:Moritz.html">Moritz Mühlenthaler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05419">PDF</a><br /><b>Abstract: </b>Imagine that unlabelled tokens are placed on the edges of a graph, such that
no two tokens are placed on incident edges. A token can jump to another edge if
the edges having tokens remain independent. We study the problem of determining
the distance between two token configurations (resp., the corresponding
matchings), which is given by the length of a shortest transformation. We give
a polynomial-time algorithm for the case that at least one of the two
configurations is not inclusion-wise maximal and show that otherwise, the
problem admits no polynomial-time sublogarithmic-factor approximation unless P
= NP. Furthermore, we show that the distance of two configurations in bipartite
graphs is fixed-parameter tractable parameterized by the size $d$ of the
symmetric difference of the source and target configurations, and obtain a
$d^\varepsilon$-factor approximation algorithm for every $\varepsilon &gt; 0$ if
additionally the configurations correspond to maximum matchings. Our two main
technical tools are the Edmonds-Gallai decomposition and a close relation to
the Directed Steiner Tree problem. Using the former, we also characterize those
graphs whose corresponding configuration graphs are connected. Finally, we show
that deciding if the distance between two configurations is equal to a given
number $\ell$ is complete for the class $D^P$, and deciding if the diameter of
the graph of configurations is equal to $\ell$ is $D^P$-hard.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05419"><span class="datestr">at December 16, 2018 04:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05410">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05410">Peeling Digital Potatoes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b>Loïc Crombez, Guilherme D. da Fonseca, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=eacute=rard:Yan.html">Yan Gérard</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05410">PDF</a><br /><b>Abstract: </b>The potato-peeling problem (also known as convex skull) is a fundamental
computational geometry problem and the fastest algorithm to date runs in
$O(n^8)$ time for a polygon with $n$ vertices that may have holes. In this
paper, we consider a digital version of the problem. A set $K \subset
\mathbb{Z}^2$ is digital convex if $conv(K) \cap \mathbb{Z}^2 = K$, where
$conv(K)$ denotes the convex hull of $K$. Given a set $S$ of $n$ lattice
points, we present polynomial time algorithms to the problems of finding the
largest digital convex subset $K$ of $S$ (digital potato-peeling problem) and
the largest union of two digital convex subsets of $S$. The two algorithms take
roughly $O(n^3)$ and $O(n^9)$ time, respectively. We also show that those
algorithms provide an approximation to the continuous versions.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05410"><span class="datestr">at December 16, 2018 04:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05352">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05352">Improved Dispersion of Mobile Robots on Arbitrary Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molla:Anisur_Rahaman.html">Anisur Rahaman Molla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Gokarna.html">Gokarna Sharma</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05352">PDF</a><br /><b>Abstract: </b>The dispersion problem on graphs asks $k\leq n$ robots placed initially
arbitrarily on the nodes of an $n$-node graph to reposition autonomously to
reach a configuration in which each robot is at a distinct node of the graph.
This problem is of significant interest due to its relationship to other
fundamental robot coordination problems, such as exploration, scattering, load
balancing, etc. The goal is to develop both memory- and time-efficient
algorithms. We provide an algorithm solving dispersion in $O(\min\{m,\Delta
k\})$ time using $O(\log (\max\{\Delta, k\}))$-bits at each robot in the {\em
robot-only memory} model -- the robots have memory but not the nodes of the
graph, where $m$ is the number of edges and $\Delta$ is the maximum degree of
any node in the graph. The runtime is optimal for bounded-degree graphs
($\Delta=O(1)$) and improves significantly the $O(mn)$ time of the best
previously known algorithm. We provide two algorithms solving dispersion in the
{\em whiteboard} model -- each node of the graph also has memory in addition to
the memory at each robot. The first algorithm has $O(m)$ time with $O(\log
\Delta)$-bits at each node and $O(\log k)$-bits at each robot. The second
algorithm has $O(\min\{m,\Delta k\})$ time with $O(\log
(\max\{\Delta,k\}))$-bits at each node and $O(\log k)$-bits at each robot.
These are the first terminating algorithms for dispersion. The second algorithm
is time-optimal for bounded-degree graphs. We provide an algorithm solving
dispersion in $O(k)$ time in the whiteboard model enhanced with {\em local
messaging} -- a robot visiting a node can send messages to the neighbors of
that node, with $O(\Delta)$-bits at each node and $O(\log k)$-bits at each
robot. This is the first time-optimal algorithm for arbitrary graphs with
termination guarantees.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05352"><span class="datestr">at December 16, 2018 04:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05316">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05316">Mind the Independence Gap</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b>Tınaz Ekim, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml=z=uuml=pek:Didem.html">Didem Gözüpek</a>, Ademir Hujdurović, Martin Milanič <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05316">PDF</a><br /><b>Abstract: </b>The independence gap of a graph was introduced by Ekim et al. (2018) as a
measure of how far a graph is from being well-covered. It is defined as the
difference between the maximum and minimum size of a maximal independent set.
</p>
<p>We investigate the independence gap of a graph from structural and
algorithmic points of view, with a focus on classes of perfect graphs.
Generalizing results on well-covered graphs due to Dean and Zito (1994) and
Hujdurovi\'c et al. (2018), we express the independence gap of a perfect graph
in terms of clique partitions and use this characterization to develop a
polynomial-time algorithm for recognizing graphs of constant independence gap
in any class of perfect graphs of bounded clique number. Next, we introduce a
hereditary variant of the parameter, which we call hereditary independence gap
and which measures the maximum independence gap over all induced subgraphs of
the graph. We show that determining whether a given graph has hereditary
independence gap at most $k$ is polynomial-time solvable if $k$ is fixed and
co-NP-complete if $k$ is part of input. We also investigate the complexity of
the independent set problem in graph classes related to independence gap,
showing that the problem is NP-complete in the class of graphs of independence
gap at most one and polynomial-time solvable in any class of graphs with
bounded hereditary independence gap. Combined with some known results on
claw-free graphs, our results imply that the independent domination problem is
solvable in polynomial time in the class of $\{$claw, 2$P_3\}$-free graphs.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05316"><span class="datestr">at December 16, 2018 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05306">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05306">Optimal Algorithm for Profiling Dynamic Arrays with Finite Values</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Dingcheng.html">Dingcheng Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Wenjian.html">Wenjian Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Junhui.html">Junhui Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Shenghua.html">Shenghua Liu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05306">PDF</a><br /><b>Abstract: </b>How can one quickly answer the most and top popular objects at any time,
given a large log stream in a system of billions of users? It is equivalent to
find the mode and top-frequent elements in a dynamic array corresponding to the
log stream. However, most existing work either restrain the dynamic array
within a sliding window, or do not take advantages of only one element can be
added or removed in a log stream. Therefore, we propose a profiling algorithm,
named S-Profile, which is of $O(1)$ time complexity for every updating of the
dynamic array, and optimal in terms of computational complexity. With the
profiling results, answering the queries on the statistics of dynamic array
becomes trivial and fast. With the experiments of various settings of dynamic
arrays, our accurate S-Profile algorithm outperforms the well-known methods,
showing at least 2X speedup to the heap based approach and 13X or larger
speedup to the balanced tree based approach.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05306"><span class="datestr">at December 16, 2018 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05282">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05282">The Relationship Between the Intrinsic Cech and Persistence Distortion Distances for Metric Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gasparovic:Ellen.html">Ellen Gasparovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gommel:Maria.html">Maria Gommel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Purvine:Emilie.html">Emilie Purvine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sazdanovic:Radmila.html">Radmila Sazdanovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Bei.html">Bei Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yusu.html">Yusu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Ziegelmeier:Lori.html">Lori Ziegelmeier</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05282">PDF</a><br /><b>Abstract: </b>Metric graphs are meaningful objects for modeling complex structures that
arise in many real-world applications, such as road networks, river systems,
earthquake faults, blood vessels, and filamentary structures in galaxies. To
study metric graphs in the context of comparison, we are interested in
determining the relative discriminative capabilities of two topology-based
distances between a pair of arbitrary finite metric graphs: the persistence
distortion distance and the intrinsic Cech distance. We explicitly show how to
compute the intrinsic Cech distance between two metric graphs based solely on
knowledge of the shortest systems of loops for the graphs. Our main theorem
establishes an inequality between the intrinsic Cech and persistence distortion
distances in the case when one of the graphs is a bouquet graph and the other
is arbitrary. The relationship also holds when both graphs are constructed via
wedge sums of cycles and edges.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05282"><span class="datestr">at December 16, 2018 04:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05189">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05189">Massively scalable Sinkhorn distances via the Nystr\"om method</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Altschuler:Jason.html">Jason Altschuler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bach:Francis.html">Francis Bach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudi:Alessandro.html">Alessandro Rudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weed:Jonathan.html">Jonathan Weed</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05189">PDF</a><br /><b>Abstract: </b>The Sinkhorn distance, a variant of the Wasserstein distance with entropic
regularization, is an increasingly popular tool in machine learning and
statistical inference. We give a simple, practical, parallelizable algorithm
NYS-SINK, based on Nystr\"om approximation, for computing Sinkhorn distances on
a massive scale. As we show in numerical experiments, our algorithm easily
computes Sinkhorn distances on data sets hundreds of times larger than can be
handled by state-of-the-art approaches. We also give provable guarantees
establishing that the running time and memory requirements of our algorithm
adapt to the intrinsic dimension of the underlying data.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05189"><span class="datestr">at December 16, 2018 04:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1812.05143">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1812.05143">Topological Time Series Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perea:Jose_A=.html">Jose A. Perea</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1812.05143">PDF</a><br /><b>Abstract: </b>Time series are ubiquitous in our data rich world. In what follows I will
describe how ideas from dynamical systems and topological data analysis can be
combined to gain insights from time-varying data. We will see several
applications to the live sciences and engineering, as well as some of the
theoretical underpinnings.
</p></div><div class="commentbar"><p></p></div></div>







<p class="date">
<a href="http://arxiv.org/abs/1812.05143"><span class="datestr">at December 16, 2018 04:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>This is my penultimate link roundup before I give up on Google+, rather than holding out for its <a href="https://www.theverge.com/2018/12/10/18134541/google-plus-privacy-api-data-leak-developers">rapidly-approaching demise</a>.</p>

<ul>
  <li>
    <p><a href="https://www.heise.de/newsticker/meldung/Urteil-gegen-Wikipedia-Keine-rufschaedigende-Kritik-ohne-Recherche-4209610.html">State Court of Berlin orders German Wikipedia to remove claims linking CS prof Alex Waibel to US intelligence</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101168679601881508"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/bZz9rbwxGyy">G+</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2018-12-01/In_the_media">via</a>). “Whether the claims were justified or not was not taken into account by the court” — instead it seems the court disagrees with Wikipedia’s policy of repeating claims from published sources, and insists that potentially-harmful claims can only be published by people who have researched them directly.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2018/11/21/how-to-make-a-hollow-geodesic.html">How to make a hollow geodesic plywood ball</a> (<a href="https://mathstodon.xyz/@11011110/101181005688834045"></a>, <a href="https://plus.google.com/100003628603413742554/posts/hezBmdrQEby">G+</a>). I don’t actually care about the how-to part of the linked video, but the malachite-like patterns that emerge from the plywood layers on the resulting ball are quite pretty. If you think about it, it’s reversed from actual malachite, where the 3d structure involves nested spheres, and you get the patterns from a flat cut. Here, the 3d structure involves flat layers, and you get the patterns from a spherical cut.</p>
  </li>
  <li>
    <p><a href="https://www.ceu.edu/article/2018-12-03/ceu-forced-out-budapest-launch-us-degree-programs-vienna-september-2019">The Hungarian far right forces the eviction of an entire university</a> (<a href="https://mathstodon.xyz/@11011110/101187102149104603"></a>, <a href="https://plus.google.com/100003628603413742554/posts/8Jtp8p7D3or">G+</a>, <a href="https://www.metafilter.com/178034/Chasing-away-individual-academics-is-so-20th-century">via</a>). They’ve also <a href="https://www.cnn.com/2018/10/19/europe/hungary-bans-gender-study-at-colleges-trnd/index.html">forbidden universities in the country from teaching gender studies</a>, using binary gender-essentialist rhetoric to do so.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1812.01160">Rigid foldability is NP-hard</a> (<a href="https://mathstodon.xyz/@11011110/101192738067042040"></a>, <a href="https://plus.google.com/100003628603413742554/posts/6UzJZZ9mrR5">G+</a>). It was previously known that folding a purported origami folding pattern to a flat state is NP-hard, because you can encode logic in the way the paper gets in the way of itself. But this paper proves that it’s hard even to tell whether you can make any rigid motion at all starting from completely unfolded paper, well before self-interference kicks in. Instead, the difficulty involves getting sums of angles to come out right.</p>
  </li>
  <li>
    <p><a href="https://www.acm.org/media-center/2018/december/fellows-2018">ACM announces their 2018 class of fellows</a> (<a href="https://mathstodon.xyz/@11011110/101198112257554333"></a>, <a href="https://plus.google.com/100003628603413742554/posts/g2WBXQiXJVC">G+</a>). Congratulations, new fellows! See also <a href="https://en.wikipedia.org/wiki/List_of_Fellows_of_the_Association_for_Computing_Machinery">Wikipedia’s coverage of all the ACM fellows</a>.
Quite a few are still missing articles, so if you want to improve Wikipedia’s coverage of computer scientists there’s still plenty to do.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/technology/2018/dec/08/australias-war-on-encryption-the-sweeping-new-powers-rushed-into-law">Australia’s war on encryption: the sweeping new powers rushed into law</a> (<a href="https://mathstodon.xyz/@11011110/101203721468845168"></a>, <a href="https://plus.google.com/100003628603413742554/posts/bnDjwLdSwzb">G+</a>). With all the vague “end of the internet!” or “why is everyone so upset at such good idea” stories elsewhere on the new Australian backdoor-your-apps law, it’s good to see a piece that explains what it actually does. The moral seems to be: don’t allow or agree to any automatic updates while in Australia. Australians, if you want security from government snooping and from security flaws, tough luck.</p>
  </li>
  <li>
    <p>“<a href="https://www.latimes.com/business/hiltzik/la-fi-hiltzik-uc-elsevier-20181207-story.html">In UC’s battle with the world’s largest scientific publisher, the future of information is at stake</a>” (<a href="https://mathstodon.xyz/@11011110/101206931146105182"></a>, <a href="https://plus.google.com/100003628603413742554/posts/bqo3gBpLKpG">G+</a>, <a href="http://retractionwatch.com/2018/12/08/weekend-reads-prominent-doctors-who-dont-disclose-conflicts-and-the-journals-that-enable-them-a-nudge-study-faces-scrutiny/">via</a>). Michael Hiltzik of the LA Times on the negotiations between the University of California and Elsevier over open access publishing. See also <a href="https://osc.universityofcalifornia.edu/scholarly-publishing/publisher-negotiations/">UC’s official summary of the negotiations</a>.</p>
  </li>
  <li>
    <p><a href="https://gowers.wordpress.com/2018/12/09/taylor-and-francis-doing-trumps-dirty-work-for-him/">Taylor and Francis refuse to publish a mathematics paper after its editors and referees accepted it, because one ot its authors is Iranian</a> (<a href="https://mathstodon.xyz/@11011110/101218345151063193"></a>, <a href="https://plus.google.com/100003628603413742554/posts/7M1QGM5g3Lc">G+</a>). The paper in question appears to be “<a href="https://arxiv.org/abs/1408.1835">Saturation of generalized partially hyperbolic attractors</a>” by A. Fakhari and M. Soufi. The decision was <a href="http://euro-math-soc.eu/news/18/12/12/ems-condemns-taylor-franciss-attack-freedom-science">condemned by the European Mathematical Society</a> and <a href="https://www.insidehighered.com/quicktakes/2018/12/12/reversal-article-rejected-due-iran-sanctions">reversed after creating an uproar</a>, but it’s not clear from the reversal statement whether the publisher might try doing this again later.</p>
  </li>
  <li>
    <p><a href="https://pudding.cool/2018/12/3d-cities-story/">Population mountains</a> (<a href="https://mathstodon.xyz/@11011110/101223944003938781"></a>, <a href="https://plus.google.com/100003628603413742554/posts/PTxsYK14jyA">G+</a>, <a href="https://www.metafilter.com/178163/Population-Mountains">via</a>). Nice 3d visualization of global urban population patterns, by Matt Daniels.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">Flip graphs of matroids are expanders</a> (<a href="https://mathstodon.xyz/@11011110/101229867536898045"></a>, <a href="https://plus.google.com/100003628603413742554/posts/idPdFLjsDHp">G+</a>, <a href="https://plus.google.com/117271457236114081433/posts/BBWDnosHkqy">via</a>). Gil Kalai reports on a new <a href="https://arxiv.org/abs/1811.01816">proof by Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant</a> of a conjecture by Milena Mihail and Umesh Vazirani that any subset  of at most half of the bases of a matroid has at least  flips to a base outside .</p>
  </li>
  <li>
    <p><a href="http://www.citypages.com/news/this-data-map-of-minnesota-wolves-is-incredible/502160411">Map of the tracks of six wolf packs shows them carefully partitioning the wilderness into non-overlapping territories, and staying within their own</a> (<a href="https://mathstodon.xyz/@11011110/101237968215679261"></a>, <a href="https://plus.google.com/100003628603413742554/posts/LPuJdsJ8vAd">G+</a>). Higher resolution version at the linked reddit page.</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2085/">xkcd on arXiv vs the commercial journals</a> (<a href="https://mathstodon.xyz/@11011110/101240953192359476"></a>, <a href="https://plus.google.com/100003628603413742554/posts/U7WxbHrPHoK">G+</a>). Infer what you will from the fact that xkcd is published open-access.</p>
  </li>
  <li>
    <p><a href="https://www.metafilter.com/178225/Focus-on-the-Science-Not-the-Scientist">A move to double-blind reviewing fixes huge gender bias in acceptance rates for space telescope allocation competition</a> (<a href="https://mathstodon.xyz/@11011110/101242747864078086"></a>, <a href="https://plus.google.com/100003628603413742554/posts/8XTaw7uRPSv">G+</a>)</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/15/linkage.html"><span class="datestr">at December 15, 2018 04:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15507">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/">Explaining The Jaccard Metric</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Why is it a metric?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/TwoJaccards.png"><img src="https://rjlipton.files.wordpress.com/2018/12/TwoJaccards.png?w=150&amp;h=140" alt="" width="150" class="alignright wp-image-15508" height="140" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://alchetron.com/Paul-Jaccard">source 1</a>, <a href="https://orepic.com/paul.jaccard">source 2</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Jaccard was a botanist who worked at ETH in Zurich during much of the first half of the 20th century. He created, or discovered, the similarity notion that became the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard metric</a>. Very neat having a metric named after you. </p>
<p>
Today we discuss proofs and explanations that the metric is indeed a metric.</p>
<p>
The Jaccard metric is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7B%5B%2A%5D%7D%5Cqquad+J%28A%2CB%29+%3D+1+-+%5Cfrac%7B%7CA+%5Ccap+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{[*]}\qquad J(A,B) = 1 - \frac{|A \cap B|}{|A \cup B|} " class="latex" title="\displaystyle  \text{[*]}\qquad J(A,B) = 1 - \frac{|A \cap B|}{|A \cup B|} " /></p>
<p>provided <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> are not both empty sets. If <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> are both empty then <img src="https://s0.wp.com/latex.php?latex=%7BJ%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J(A,B)}" class="latex" title="{J(A,B)}" /> by definition is <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />.  Generally we can assume that all the sets are non-empty.</p>
<p>
The key question is to show that this satisfies the <b>triangle inequality</b>. That is, we must show that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7B%5B%2A%2A%5D%7D%5Cqquad+J%28A%2CC%29+%5Cle+J%28A%2CB%29+%2B+J%28B%2CC%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{[**]}\qquad J(A,C) \le J(A,B) + J(B,C). " class="latex" title="\displaystyle  \text{[**]}\qquad J(A,C) \le J(A,B) + J(B,C). " /></p>
<p>
Many proofs of this are known, and it has been remarked that some are fairly complicated. Some are short, but <a href="https://www.tandfonline.com/doi/abs/10.1080/07468342.2018.1526020">continued</a> <a href="https://arxiv.org/pdf/1612.02696.pdf">recent</a> <a href="https://www.researchgate.net/publication/326912768_Distance_Between_Sets_-_A_survey">interest</a> seems to say they haven’t satisfied as <em>explanations</em>. </p>
<p>
We think we can supply a quick explanation, if you are already familiar with the triangle inequality holding for Hamming distance on sets: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA+%5Coplus+C%7C+%5Cleq+%7CA+%5Coplus+B%7C+%2B+%7CB+%5Coplus+C%7C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A \oplus C| \leq |A \oplus B| + |B \oplus C|, " class="latex" title="\displaystyle  |A \oplus C| \leq |A \oplus B| + |B \oplus C|, " /></p>
<p>
where <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Coplus+B+%3D+%28A+%5Ccup+B%29+%5Csetminus+%28A+%5Ccap+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \oplus B = (A \cup B) \setminus (A \cap B)}" class="latex" title="{A \oplus B = (A \cup B) \setminus (A \cap B)}" /> is symmetric difference. By rewriting [*] as <img src="https://s0.wp.com/latex.php?latex=%7BJ%28A%2CB%29+%3D+%7CA+%5Coplus+B%7C%2F%7CA+%5Ccup+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J(A,B) = |A \oplus B|/|A \cup B|}" class="latex" title="{J(A,B) = |A \oplus B|/|A \cup B|}" /> we can see that [**] becomes similar but includes denominators. If [**] is <em>false</em> then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7B%5B%2A%2A%2A%5D%7D%5Cqquad+%5Cfrac%7B%7CA+%5Coplus+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%3E+%5Cfrac%7B%7CA+%5Coplus+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5Coplus+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{[***]}\qquad \frac{|A \oplus C|}{|A \cup C|} &gt; \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " class="latex" title="\displaystyle  \text{[***]}\qquad \frac{|A \oplus C|}{|A \cup C|} &gt; \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " /></p>
<p>Now if we have <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> then replacing both right-hand denominators by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> cannot make the right-hand side of [***] bigger. But then we have a common denominator, and we can see from Hamming distance that [**] must be true. </p>
<p>
So suppose <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> includes <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> elements not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. The left-hand side of [***] is at most <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, so each right-hand fractions must be of the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{q}}" class="latex" title="{\frac{p}{q}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3C+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p &lt; q}" class="latex" title="{p &lt; q}" />. But then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D+%3E+%5Cfrac%7Bp+-+b%7D%7Bq+-+b%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{q} &gt; \frac{p - b}{q - b}}" class="latex" title="{\frac{p}{q} &gt; \frac{p - b}{q - b}}" />, so removing those elements from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> would also make the right-hand side of [***] smaller. That brings us back to the <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> case and the previous contradiction. So [**] must be true. That’s our proof and explanation in brief. </p>
<p>
</p><p></p><h2> A Careful Take </h2><p></p>
<p></p><p>
We will do the above proof more slowly and carefully, to ensure it is really clear. A convention: to make the formulas a bit more readable we use <img src="https://s0.wp.com/latex.php?latex=%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AB}" class="latex" title="{AB}" /> to denote the intersection of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />. So the Jaccard metric is now 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J%28A%2CB%29+%3D+1+-+%5Cfrac%7B%7CAB%7C%7D%7B%7CA+%5Ccup+B%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  J(A,B) = 1 - \frac{|AB|}{|A \cup B|}. " class="latex" title="\displaystyle  J(A,B) = 1 - \frac{|AB|}{|A \cup B|}. " /></p>
<p>First we explain the main ideas:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> We will argue that the intermediate set <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> in the triangle inequality can be constrained. The set <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> can be a subset of <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. The intuition is that any extra elements in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> can only make the triangle inequality weaker.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> We will replace the definition of the Jaccard metric by equivalent one. This new definition is much closer to a known metric.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> We will reduce the triangle inequality finally to a known triangle inequality.</p>
<p>
<em>Proof:</em> </p>
<p>
Let’s assume that <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" /> are the sets, and we wish to prove the triangle inequality: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+-+%5Cfrac%7B%7CA+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cle+1-%5Cfrac%7B%7CA+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+1-%5Cfrac%7B%7CB+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " class="latex" title="\displaystyle  1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " /></p>
<p>
<b>Claim</b>: We can assume that <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" />. Suppose there was an element <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> but not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. Then removing <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> would only tighten the triangle inequality. That is the LHS 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+-+%5Cfrac%7B%7CA+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1 - \frac{|A C|}{|A \cup C|} " class="latex" title="\displaystyle  1 - \frac{|A C|}{|A \cup C|} " /></p>
<p>stays the same and the RHS terms 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Cfrac%7B%7CA+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%5Ctext%7B+and+%7D+1-%5Cfrac%7B%7CB+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\frac{|A B|}{|A \cup B|} \text{ and } 1-\frac{|B C|}{|B \cup C|}, " class="latex" title="\displaystyle  1-\frac{|A B|}{|A \cup B|} \text{ and } 1-\frac{|B C|}{|B \cup C|}, " /></p>
<p>can only decrease.</p>
<p>
<b>Claim</b>: We can re-write <img src="https://s0.wp.com/latex.php?latex=%7BJ%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{J(X,Y)}" class="latex" title="{J(X,Y)}" /> as 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CX+%5Coplus+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|X \oplus Y|}{|X \cup Y|}. " class="latex" title="\displaystyle  \frac{|X \oplus Y|}{|X \cup Y|}. " /></p>
<p>As noted above, <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Coplus+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \oplus Y}" class="latex" title="{X \oplus Y}" /> is the set of elements that are in <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> but not both. </p>
<p>
<b>Claim</b>: We note that after applying the last claim three times, [**] becomes: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5Coplus+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cle+%5Cfrac%7B%7CA+%5Coplus+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5Coplus+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|A \oplus C|}{|A \cup C|} \le \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " class="latex" title="\displaystyle  \frac{|A \oplus C|}{|A \cup C|} \le \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " /></p>
<p>
<b>Claim</b>	: Since <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> we can multiply by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> and get that the triangle inequality is implied by 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA+%5Coplus+C%7C+%5Cle+%7CA+%5Coplus+B%7C+%2B+%7CB+%5Coplus+C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C|. " class="latex" title="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C|. " /></p>
<p>Note this uses that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA+%5Coplus+B%7C+%2B+%7CB+%5Coplus+C%7C+%5Cle+%7CA+%5Coplus+B%7C+%5Cfrac%7B%7CA+%5Ccup+C%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%7CB+%5Coplus+C%7C%5Cfrac%7B%7CA+%5Ccup+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A \oplus B| + |B \oplus C| \le |A \oplus B| \frac{|A \cup C|}{|A \cup B|} + |B \oplus C|\frac{|A \cup C|}{|B \cup C|}, " class="latex" title="\displaystyle  |A \oplus B| + |B \oplus C| \le |A \oplus B| \frac{|A \cup C|}{|A \cup B|} + |B \oplus C|\frac{|A \cup C|}{|B \cup C|}, " /></p>
<p>which follows from 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+%5Cfrac%7B%7CA+%5Ccup+C%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%5Ctext%7B+and+%7D+1+%5Cle+%5Cfrac%7B%7CA+%5Ccup+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1 \le \frac{|A \cup C|}{|A \cup B|} \text{ and } 1 \le \frac{|A \cup C|}{|B \cup C|}. " class="latex" title="\displaystyle  1 \le \frac{|A \cup C|}{|A \cup B|} \text{ and } 1 \le \frac{|A \cup C|}{|B \cup C|}. " /></p>
<p>
<b>Claim</b>	: But the last step is that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA+%5Coplus+C%7C+%5Cle+%7CA+%5Coplus+B%7C+%2B+%7CB+%5Coplus+C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C| " class="latex" title="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C| " /></p>
<p>is just the triangle inequality for the Hamming distance. It uses that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x+%5Coplus+y%29+%5Cle+%28x+%5Coplus+z%29+%2B+%28z+%5Coplus+y%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (x \oplus y) \le (x \oplus z) + (z \oplus y) " class="latex" title="\displaystyle  (x \oplus y) \le (x \oplus z) + (z \oplus y) " /></p>
<p>holds for any single bits <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y,z}" class="latex" title="{x,y,z}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> How We Found The Proof </h2><p></p>
<p></p><p>
If you’re curious how we found the above, we were trying to check a different kind of proof.  We started with the statement of the triangle inequality: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7B%5B%2A%2A%5D%7D%5Cqquad+1+-+%5Cfrac%7B%7CA+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cle+1-%5Cfrac%7B%7CA+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+1-%5Cfrac%7B%7CB+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{[**]}\qquad 1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " class="latex" title="\displaystyle  \text{[**]}\qquad 1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " /></p>
<p>
This looks a bit scary, with its multiple ratios and addition and subtraction. But the following feature jumps out: </p>
<blockquote><p><b> </b> <em>The right side depends on <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> but the left side does not. </em>
</p></blockquote>
<p>This suggests the idea of asking what happens if we change <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> one element at a time? Can we “walk” it to an extreme point at which the truth of [**] is obvious? A promising start was that we could remove any elements from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> that are not in <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />, as shown above. So we can assume <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" />. Can we move <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> toward <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> or at least <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Coplus+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \oplus C}" class="latex" title="{A \oplus C}" /> while preserving the implication of truth for [**]? </p>
<p>
Seen in this light, our above proof’s replacing the denominators by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" /> is an “illegal move”—not a change to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />—so less interesting. But we happened to notice it worked. Let’s follow the train of thought from where we got that <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" /> can be assumed. Okay, what the next move to make with <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />? Look again at the key expression: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+-+%5Cfrac%7B%7CA+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cle+1-%5Cfrac%7B%7CA+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+1-%5Cfrac%7B%7CB+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " class="latex" title="\displaystyle  1 - \frac{|A C|}{|A \cup C|} \le 1-\frac{|A B|}{|A \cup B|} + 1-\frac{|B C|}{|B \cup C|}. " /></p>
<p>Can we simplify this in some way? The answer is yes. The structure of <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> minus an expression suggested that perhaps we could combine the <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> and the ratios. Indeed it is not too hard to note that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Cfrac%7B%7CXY%7C%7D%7B%7CX+%5Ccup+Y%7C%7D+%3D+%5Cfrac%7B%7CX+%5Coplus+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\frac{|XY|}{|X \cup Y|} = \frac{|X \oplus Y|}{|X \cup Y|}. " class="latex" title="\displaystyle  1-\frac{|XY|}{|X \cup Y|} = \frac{|X \oplus Y|}{|X \cup Y|}. " /></p>
<p>Okay perhaps this is not obvious. It is not trivial, but it is a standard idea that <img src="https://s0.wp.com/latex.php?latex=%7B1+-+p%2Fq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 - p/q}" class="latex" title="{1 - p/q}" /> looks like the complementation of the “probabilty” ratio <img src="https://s0.wp.com/latex.php?latex=%7Bp%2Fq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p/q}" class="latex" title="{p/q}" />. Once you think of this the exact formula follows. Thus we can re-write the required triangle inequality now as 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5Coplus+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cle+%5Cfrac%7B%7CA+%5Coplus+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5Coplus+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{|A \oplus C|}{|A \cup C|} \le \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " class="latex" title="\displaystyle  \frac{|A \oplus C|}{|A \cup C|} \le \frac{|A \oplus B|}{|A \cup B|} + \frac{|B \oplus C|}{|B \cup C|}. " /></p>
<p>We are almost done. The ratios are annoying, so can we get rid of them? We have assumed that <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \subseteq A \cup C}" class="latex" title="{B \subseteq A \cup C}" />. So it seems like a good idea to assume—for the moment—that <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is actually equal to <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" />. But then it is easy to see that <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+B+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup B = A \cup C}" class="latex" title="{A \cup B = A \cup C}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Ccup+C+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \cup C = A \cup C}" class="latex" title="{B \cup C = A \cup C}" />. So the above becomes after multiplying by <img src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|A \cup C|}" class="latex" title="{|A \cup C|}" />, 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA+%5Coplus+C%7C+%5Cle+%7CA+%5Coplus+B%7C+%2B+%7CB+%5Coplus+C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C|. " class="latex" title="\displaystyle  |A \oplus C| \le |A \oplus B| + |B \oplus C|. " /></p>
<p>This looks really nice, no more ratios. Wait what is this expression? The <img src="https://s0.wp.com/latex.php?latex=%7B%5Coplus%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\oplus}" class="latex" title="{\oplus}" /> is the exclusive-or function and it is not hard to note that this is the classic Hamming distance. So this inequality is a fact. Recall the Hamming distance records the number of differences between two bit-vectors, but sets are really just bit vectors.</p>
<p>
Are we there yet? Almost. We only need to argue that if <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is less than <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \cup C}" class="latex" title="{A \cup C}" /> the inequality we need is actually stronger. So we are done. </p>
<p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Do you like our proof? Is it clear from the intro—or from the second section? Or are you still unsure why the Jaccard metric satisfies the triangle inequality? We may follow up with more about other proofs.</p>
<p>
We don’t think the photo used by this online Alchetron <a href="https://alchetron.com/Paul-Jaccard">bio</a> of Paul Jaccard is the botanist. It looks too modern, for one. No other photo seems extant. Google Images guesses Alchetron’s image to be Adrian Herzog, but we think its highest Jaccard index is to <a href="https://orepic.com/">Orepic</a> user <a href="https://orepic.com/paul.jaccard">paul.jaccard</a>, as shown at top. Can you solve the mystery of who? </p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/"><span class="datestr">at December 15, 2018 01:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/14/faculty-at-duke-university-apply-by-december-15-2018/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/14/faculty-at-duke-university-apply-by-december-15-2018/">Faculty at Duke University (apply by December 15, 2018)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Dec 15 deadline is soft. Applications submitted in the next couple of weeks would also receive consideration. All ranks. All areas in theoretical computer science including algorithms, complexity, and cryptography.</p>
<p>Website: <a href="https://www.cs.duke.edu/openings_faculty">https://www.cs.duke.edu/openings_faculty</a><br />
Email: jschmidt@cs.duke.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/14/faculty-at-duke-university-apply-by-december-15-2018/"><span class="datestr">at December 14, 2018 05:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/14/head-of-school-in-computer-science-and-engineering-at-unsw-sydney-australia-apply-by-january-18-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/14/head-of-school-in-computer-science-and-engineering-at-unsw-sydney-australia-apply-by-january-18-2019/">Head of School in Computer Science and Engineering at UNSW Sydney, Australia (apply by January 18, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>UNSW Sydney is recruiting a Head of School for the School of Computer Science &amp; Engineering.<br />
This is a continuing position, normally at the level of professor.</p>
<p>Website: <a href="http://external-careers.jobs.unsw.edu.au/cw/en/job/495688/head-of-school-cse">http://external-careers.jobs.unsw.edu.au/cw/en/job/495688/head-of-school-cse</a><br />
Email: sergeg@cse.unsw.edu.au</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/14/head-of-school-in-computer-science-and-engineering-at-unsw-sydney-australia-apply-by-january-18-2019/"><span class="datestr">at December 14, 2018 06:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6351">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/13/ising-perceptron-under-gaussian-disorder-and-k-nae-sat/">Ising Perceptron under Gaussian Disorder, and k-NAE-SAT</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>Blog Post By: Patrick Guo, Vinh-Kha Le, Shyam Narayanan, and David Stoner</strong></p>
<p>Methods in statistical physics are known to be extremely useful for understanding certain problems in theoretical computer science. Physical observations can motivate the underlying theoretical models, which in turn explain some of the physical phenomena.</p>
<p>This post is based on Professor Nike Sun’s guest lecture on the Ising Perceptron model and regular NAE-SAT for CS 229R: Physics and Computation. These are both examples of random constraint satisfaction problems, where we have <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> variables <img src="https://s0.wp.com/latex.php?latex=x_1%2C+...%2C+x_n+%5Cin+%5C%7B-1%2C+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, ..., x_n \in \{-1, 1\}" class="latex" title="x_1, ..., x_n \in \{-1, 1\}" /> and certain relations, or constraints, between the <img src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_i" class="latex" title="x_i" />, and we wish to approximate the number of solutions or visualize the geometry of the solutions. For both problems, the problem instance can be random: for example, the linear constraints in the Ising perceptron model are random, and the clauses in the NAE-SAT instance are chosen at random. As in the previous blog posts, to understand the geometry of solutions, statistical physicists think of sampling random solutions from <img src="https://s0.wp.com/latex.php?latex=%5C%7B-1%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{-1, 1\}^n" class="latex" title="\{-1, 1\}^n" />, which introduces a second type of randomness.</p>
<p>This post is meant to be expository. For interested readers, we point to useful references at the end for more rigorous treatments of these topics.</p>
<p><strong>1. Perceptron Model</strong></p>
<p>The Ising Perceptron under Gaussian disorder asks how many points in <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" /> survive <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> half-plane bisections (i.e. are satisfying assignments for <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> constraints), where the planes’ coefficients are drawn from standard Gaussians. Like many problems in statistical physics, there is likely a critical capacity of constraints where having more constraints yields no survivors with high probability, and having fewer constraints yields survivors with high probability. This lecture gives an overview of a proof for one side of this physics prediction, i.e. the existence of a lower bound critical capacity, where having fewer constraints yields survivors with positive probability. Briefly, we use the <em>Cavity method</em> to approximate the distribution of the number of satisfying assignments, then attempt to use the second moment method on that distribution to get our lower bound. A direct application fails, however, due to the variance of the Gaussian constraints. The solution is to carefully choose exactly what to condition on without destroying the model. Specifically, we iteratively compute values related to the Gaussian disorder, after which we are able remove enough variance for the second moment method to work and thus establish the lower bound for the Ising Perceptron’s critical capacity. The result holds subject to an analytical condition which is detailed in the paper (Condition 1.2 in [6]) and which remains to be rigorously verified.</p>
<p><strong>1.1. Problem</strong></p>
<p>We pick a random direction in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}^n" class="latex" title="\mathbb{R}^n" />, and delete all vertices in the hypercube <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" /> which are in the half-space negatively correlated with that direction. We repeat this process of picking a random half space and deleting points <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> times, and see if any points in the hypercube survive. Formally, we define the perceptron model as follows:</p>
<p><strong>Definition 1:</strong> Let <img src="https://s0.wp.com/latex.php?latex=G+%3D+%28g_%7B%5Cmu%7B%7Di%7D%29_%7B%5Cmu%5Cge+1%2C+i%5Cge+1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G = (g_{\mu{}i})_{\mu\ge 1, i\ge 1}" class="latex" title="G = (g_{\mu{}i})_{\mu\ge 1, i\ge 1}" /> array of i.i.d. standard Gaussians. Let <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> be the largest integer such that:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7BJ%5Cin+%5C%7B%5Cpm+1%5C%7D%5EN%3A%5Csum_%7Bi%3D1%7D%5EN%5Cfrac%7Bg_%7B%5Cmu%7B%7Di%7DJ_i%7D%7B%5Csqrt%7BN%7D%7D%5Cge+0+%5Chspace%7B0.1cm%7D+%5Cforall+%5Cmu%5Cle+M%5Cright%5C%7D%5Cneq+%5Cemptyset.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left\{J\in \{\pm 1\}^N:\sum_{i=1}^N\frac{g_{\mu{}i}J_i}{\sqrt{N}}\ge 0 \hspace{0.1cm} \forall \mu\le M\right\}\neq \emptyset." class="latex" title="\left\{J\in \{\pm 1\}^N:\sum_{i=1}^N\frac{g_{\mu{}i}J_i}{\sqrt{N}}\ge 0 \hspace{0.1cm} \forall \mu\le M\right\}\neq \emptyset." /></p>
<p>More compactly, <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> is the largest integer such that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7BJ%5Cin+%5C%7B%5Cpm+1%5C%7D%5EN%3A%5Cfrac%7BGJ%7D%7B%5Csqrt%7BN%7D%7D%5Cge+0%5Cright%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left\{J\in \{\pm 1\}^N:\frac{GJ}{\sqrt{N}}\ge 0\right\}" class="latex" title="\left\{J\in \{\pm 1\}^N:\frac{GJ}{\sqrt{N}}\ge 0\right\}" /></p>
<p>is nonempty, where the inequality is taken pointwise, <img src="https://s0.wp.com/latex.php?latex=G+%5Cin+%5Cmathbb%7BR%7D%5E%7BM+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G \in \mathbb{R}^{M \times N}" class="latex" title="G \in \mathbb{R}^{M \times N}" /> is an array of i.i.d. std. Gaussians, and <img src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J" class="latex" title="J" /> is treated as a vector in <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5EN+%5Csubset+%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\pm 1\}^N \subset \mathbb{R}^N" class="latex" title="\{\pm 1\}^N \subset \mathbb{R}^N" />.</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/CS229-Pic-1.png?w=600" alt="CS229 Pic 1" class="alignnone size-full wp-image-6353" /></p>
<p>In the late 80’s, physicists conjectured that there is a critical capacity <img src="https://s0.wp.com/latex.php?latex=%5Calpha_%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha_{*}" class="latex" title="\alpha_{*}" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BM%7D%7BN%7D+%5Coverset%7BP%7D%7B%5Cto%7D+%5Calpha_%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{M}{N} \overset{P}{\to} \alpha_{*}" class="latex" title="\frac{M}{N} \overset{P}{\to} \alpha_{*}" /> where <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> is a function of <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N" class="latex" title="N" />. The predicted critical capacity has been studied, for example in [7,9]. Our goal is to establish a lower bound on <img src="https://s0.wp.com/latex.php?latex=%5Calpha_%2A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha_*" class="latex" title="\alpha_*" /> for the Ising Perceptron under Gaussian disorder. To do this, let <img src="https://s0.wp.com/latex.php?latex=Z%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)" class="latex" title="Z(G)" /> denote the random variable which measures how many choices of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> variables survive <img src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M" class="latex" title="M" /> Gaussian constraints in <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> (this is the partition function). We want to show <img src="https://s0.wp.com/latex.php?latex=Z+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z &gt; 0" class="latex" title="Z &gt; 0" /> with high probability when there are <img src="https://s0.wp.com/latex.php?latex=M+%3C+%5Calpha_%7B%2A%7DN&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M &lt; \alpha_{*}N" class="latex" title="M &lt; \alpha_{*}N" /> constraints. To this end, the second moment method seems promising:</p>
<p><strong>Second Moment Method: </strong>If <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> is a nonnegative random variable with finite variance, then</p>
<p><img src="https://s0.wp.com/latex.php?latex=P%28Z+%3E+0%29+%5Cge+%5Cfrac%7B%5Cleft%28%5Cmathbb%7BE%7D%5BZ%5D%5Cright%29%5E2%7D%7B%5Cmathbb%7BE%7D%5BZ%5E2%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z &gt; 0) \ge \frac{\left(\mathbb{E}[Z]\right)^2}{\mathbb{E}[Z^2]}" class="latex" title="P(Z &gt; 0) \ge \frac{\left(\mathbb{E}[Z]\right)^2}{\mathbb{E}[Z^2]}" /></p>
<p>However, this method actually fails due to various sources of variance in the perceptron model. We will briefly sketch the fix as given in [6].</p>
<p>Before we can start, however, what does the distribution of <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> even look like? This is actually quite computationally intensive; we will use the <strong>cavity equations</strong>, a technique developed in [12,13], to approximate <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" />‘s distribution.</p>
<p><strong>1.2. Cavity Method</strong></p>
<p>The goal of the cavity method is to see how the solution space changes as we remove a row or a column of the matrix <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> with i.i.d. standard Gaussian entries, assuming that <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is fixed. Since our matrix <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is big and difficult to deal with, we try to see how the solution space changes as we add one row or one column at a time. Why is this valuable? We can think of the system of variables and constraints as an interaction between the rows (constraints) and columns (variables), so the number of solutions should behave proportionally to the product of the solutions attributed to each variable and each constraint. With this as motivation, define <img src="https://s0.wp.com/latex.php?latex=G_%7B-%5Cmu%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G_{-\mu}" class="latex" title="G_{-\mu}" /> as the matrix obtained by removing row <img src="https://s0.wp.com/latex.php?latex=%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu" class="latex" title="\mu" /> and <img src="https://s0.wp.com/latex.php?latex=G%5E%7B-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{-i}" class="latex" title="G^{-i}" /> as the matrix obtained by removing column <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />. We can approximate</p>
<p><img src="https://s0.wp.com/latex.php?latex=Z%28G%29+%5Capprox+%5Cprod%5Climits_%7B%5Cmu+%3D+1%7D%5E%7BM%7D+%5Cfrac%7BZ%28G%29%7D%7BZ%28G_%7B-%5Cmu%7D%29%7D+%5Ccdot+%5Cprod%5Climits_%7Bi+%3D+1%7D%5E%7BN%7D+%5Cfrac%7BZ%28G%29%7D%7BZ%28G%5E%7B-i%7D%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G) \approx \prod\limits_{\mu = 1}^{M} \frac{Z(G)}{Z(G_{-\mu})} \cdot \prod\limits_{i = 1}^{N} \frac{Z(G)}{Z(G^{-i})}" class="latex" title="Z(G) \approx \prod\limits_{\mu = 1}^{M} \frac{Z(G)}{Z(G_{-\mu})} \cdot \prod\limits_{i = 1}^{N} \frac{Z(G)}{Z(G^{-i})}" /></p>
<p>since we can think of the partition function as receiving a multiplicative factor from each addition of a row and each addition of a column. Thus, the cavity method seeks to compute <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G_%7B-%5Cmu%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G_{-\mu})" class="latex" title="Z(G)/Z(G_{-\mu})" /> and <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G%5E%7B-i%7D%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G^{-i})." class="latex" title="Z(G)/Z(G^{-i})." /></p>
<p><strong>1.2.1. Removing a constraint</strong></p>
<p>Our goal in computing <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G_%7B-%5Cmu%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G_{-\mu})" class="latex" title="Z(G)/Z(G_{-\mu})" /> is to understand how the solution space <img src="https://s0.wp.com/latex.php?latex=SOL%28G_%7B-%5Cmu%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SOL(G_{-\mu})" class="latex" title="SOL(G_{-\mu})" /> changes when we add in the constraint <img src="https://s0.wp.com/latex.php?latex=%5Cmu.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu." class="latex" title="\mu." /> Recalling that <img src="https://s0.wp.com/latex.php?latex=J+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J \in \{\pm 1\}^n" class="latex" title="J \in \{\pm 1\}^n" /> is our vector that is potentially in the solution space, if we define</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu+%3A%3D+%5Csum_%7Bi+%3D+1%7D%5E%7BN%7D%5Cfrac%7Bg_%7B%5Cmu%7B%7Di%7DJ_i%7D%7B%5Csqrt%7BN%7D%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu := \sum_{i = 1}^{N}\frac{g_{\mu{}i}J_i}{\sqrt{N}}," class="latex" title="\Delta_\mu := \sum_{i = 1}^{N}\frac{g_{\mu{}i}J_i}{\sqrt{N}}," /></p>
<p>then adding the constraint <img src="https://s0.wp.com/latex.php?latex=%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu" class="latex" title="\mu" /> is equivalent to forcing <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu+%5Cge+0.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu \ge 0." class="latex" title="\Delta_\mu \ge 0." /> We will try to understand the distribution of <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu" class="latex" title="\Delta_\mu" /> under the Gibbs measure <img src="https://s0.wp.com/latex.php?latex=%5Cnu_%7B-%5Cmu%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\nu_{-\mu}" class="latex" title="\nu_{-\mu}" />, which is the uniform measure on the solution space without the constraint <img src="https://s0.wp.com/latex.php?latex=%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu" class="latex" title="\mu" />. This way, we can determine the probability of <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu \ge 0" class="latex" title="\Delta_\mu \ge 0" /> under the Gibbs measure, which will equal <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G_%7B-%5Cmu%7D%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G_{-\mu})." class="latex" title="Z(G)/Z(G_{-\mu})." /> To do so, we will use the <strong>Replica Symmetric Cavity Assumption</strong> (which we will abbreviate as RS cavity assumption). The RS cavity assumption lets us assume that the <img src="https://s0.wp.com/latex.php?latex=J_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i" class="latex" title="J_i" />‘s for <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+i+%5Cle+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1 \le i \le N" class="latex" title="1 \le i \le N" /> are independent under <img src="https://s0.wp.com/latex.php?latex=%5Cnu_%7B-%5Cmu%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\nu_{-\mu}" class="latex" title="\nu_{-\mu}" />. As the <img src="https://s0.wp.com/latex.php?latex=J_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i" class="latex" title="J_i" />‘s are some discrete sample space that depend on our constraints, we do not actually have full independence, but the RS cavity assumption tells us there is very little dependence between the <img src="https://s0.wp.com/latex.php?latex=J_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i" class="latex" title="J_i" />‘s, so we pretend they are independent.</p>
<p>Note that <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu" class="latex" title="\Delta_\mu" /> should be approximately normally distributed, since it is the sum of many “independent” terms <img src="https://s0.wp.com/latex.php?latex=g_%7B%5Cmu+i%7D+J_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_{\mu i} J_i" class="latex" title="g_{\mu i} J_i" /> by the RS Cavity assumption. Now, define <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu" class="latex" title="h_\mu" /> as the expectation of <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu" class="latex" title="\Delta_\mu" /> under the Gibbs measure without the constraint <img src="https://s0.wp.com/latex.php?latex=%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu" class="latex" title="\mu" />, and <img src="https://s0.wp.com/latex.php?latex=v_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v_\mu" class="latex" title="v_\mu" /> as the variance of <img src="https://s0.wp.com/latex.php?latex=%5CDelta_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta_\mu" class="latex" title="\Delta_\mu" /> under the Gibbs measure without the constraint <img src="https://s0.wp.com/latex.php?latex=%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mu" class="latex" title="\mu" />. It will also turn out that the variance <img src="https://s0.wp.com/latex.php?latex=v_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v_\mu" class="latex" title="v_\mu" /> will concentrate around a constant <img src="https://s0.wp.com/latex.php?latex=%5Csigma%5E2.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^2." class="latex" title="\sigma^2." /> Thus,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BZ%28G%29%7D%7BZ%28G_%7B-%5Cmu%7D%29%7D+%5Capprox+%5Cnu_%7B-%5Cmu%7D%28%5CDelta_%7B%5Cmu%7D+%5Cge+0%29+%3D+%5Coverline%7B%5CPhi%7D+%28%5Cfrac%7B-h_%5Cmu%7D%7B%5Csigma%7D%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{Z(G)}{Z(G_{-\mu})} \approx \nu_{-\mu}(\Delta_{\mu} \ge 0) = \overline{\Phi} (\frac{-h_\mu}{\sigma})." class="latex" title="\frac{Z(G)}{Z(G_{-\mu})} \approx \nu_{-\mu}(\Delta_{\mu} \ge 0) = \overline{\Phi} (\frac{-h_\mu}{\sigma})." /></p>
<p>Here, <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7B%5CPhi%7D%28%5Cfrac%7B-h_%5Cmu%7D%7B%5Csigma%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\overline{\Phi}(\frac{-h_\mu}{\sigma})" class="latex" title="\overline{\Phi}(\frac{-h_\mu}{\sigma})" /> equals the probability that a random <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BN%7D%28h_%5Cmu%2C+%5Csigma%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{N}(h_\mu, \sigma^2)" class="latex" title="\mathcal{N}(h_\mu, \sigma^2)" /> Gaussian distribution is positive, or equivalently, the probability that a standard Gaussian <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BN%7D%280%2C+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{N}(0, 1)" class="latex" title="\mathcal{N}(0, 1)" /> distribution is greater than <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B-h_%5Cmu%7D%7B%5Csigma%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{-h_\mu}{\sigma}." class="latex" title="\frac{-h_\mu}{\sigma}." /></p>
<p><strong>1.2.2. Removing a spin</strong></p>
<p>To calculate the cavity equation for removing one column, we think of removing a column as deleting one spin from <img src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J" class="latex" title="J" />. Define <img src="https://s0.wp.com/latex.php?latex=J%5E%7B-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J^{-i}" class="latex" title="J^{-i}" /> as the vector resulting from removing spin <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> from <img src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J" class="latex" title="J" />. We want to calculate <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G%5E%7B-i%7D%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G^{-i})." class="latex" title="Z(G)/Z(G^{-i})." /> Note that it is possible for <img src="https://s0.wp.com/latex.php?latex=J%5E%7B-i%7D+%5Cnot%5Cin+SOL%28G%5E%7B-i%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J^{-i} \not\in SOL(G^{-i})" class="latex" title="J^{-i} \not\in SOL(G^{-i})" /> but <img src="https://s0.wp.com/latex.php?latex=J+%5Cin+SOL%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J \in SOL(G)" class="latex" title="J \in SOL(G)" /> now, which complicates this calculation. It is possible to overcome this difficulty by passing to positive temperature, though this makes the calculations incredibly difficult. We do not worry about these issues here, and just briefly sketch how <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G%5E%7B-i%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G^{-i})" class="latex" title="Z(G)/Z(G^{-i})" /> is computed.</p>
<p>To compute <img src="https://s0.wp.com/latex.php?latex=Z%28G%29%2FZ%28G%5E%7B-i%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)/Z(G^{-i})" class="latex" title="Z(G)/Z(G^{-i})" />, we will split the numerator into a sum of two terms based on the sign of <img src="https://s0.wp.com/latex.php?latex=J_i%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i," class="latex" title="J_i," /> which will allow us to compute not only <img src="https://s0.wp.com/latex.php?latex=Z%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G)" class="latex" title="Z(G)" /> but also <img src="https://s0.wp.com/latex.php?latex=%5Clangle+J_i+%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle J_i \rangle" class="latex" title="\langle J_i \rangle" />, which represents the magnetization at spin <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />. A series of complicated calculations (see the lecture notes for the details) will give us</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BZ%28G%29%7D%7BZ%28G%5E%7B-i%7D%29%7D+%3D+%5Cfrac%7B%5Cexp%28H_i%29%2B%5Cexp%28-H_i%29%7D%7Bexp%28c%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{Z(G)}{Z(G^{-i})} = \frac{\exp(H_i)+\exp(-H_i)}{exp(c)}" class="latex" title="\frac{Z(G)}{Z(G^{-i})} = \frac{\exp(H_i)+\exp(-H_i)}{exp(c)}" /></p>
<p>for some constant <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />, where <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" /> is a quantity that compares how much more correlated spin <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> is to the constraints than all other spins. The <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28%2BH_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exp(+H_i)" class="latex" title="\exp(+H_i)" /> will come from the solutions for <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> with <img src="https://s0.wp.com/latex.php?latex=J_i+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i = 1" class="latex" title="J_i = 1" /> and the <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-H_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\exp(-H_i)" class="latex" title="\exp(-H_i)" /> will come from the solutions with <img src="https://s0.wp.com/latex.php?latex=J_i+%3D+-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="J_i = -1" class="latex" title="J_i = -1" />.</p>
<p>The above equations allow us to deduce that</p>
<p><img src="https://s0.wp.com/latex.php?latex=Z%28G%29+%5Capprox+%5Cprod%5Climits_%7B%5Cmu+%3D+1%7D%5E%7BM%7D+%5Coverline%7B%5CPhi%7D%5Cleft%28-%5Cfrac%7Bh_%5Cmu%7D%7B%5Csigma%7D%5Cright%29+%5Ccdot+%5Cprod%5Climits_%7Bi+%3D+1%7D%5E%7BN%7D+%5Cfrac%7B%5Cexp%28H_i%29+%2B+%5Cexp%28-H_i%29%7D%7B%5Cexp%28c%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z(G) \approx \prod\limits_{\mu = 1}^{M} \overline{\Phi}\left(-\frac{h_\mu}{\sigma}\right) \cdot \prod\limits_{i = 1}^{N} \frac{\exp(H_i) + \exp(-H_i)}{\exp(c)}." class="latex" title="Z(G) \approx \prod\limits_{\mu = 1}^{M} \overline{\Phi}\left(-\frac{h_\mu}{\sigma}\right) \cdot \prod\limits_{i = 1}^{N} \frac{\exp(H_i) + \exp(-H_i)}{\exp(c)}." /></p>
<p><strong>1.3. The Randomness of G</strong></p>
<p>In the previous section, we regarded <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> as fixed. We now use the these results but allow for <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> to be random again. Recall <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />‘s entries were i.i.d. Gaussians. We thus get that <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu" class="latex" title="h_\mu" />, as a linear combination of the <img src="https://s0.wp.com/latex.php?latex=g_%7B%5Cmu%7B%7Di%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_{\mu{}i}" class="latex" title="g_{\mu{}i}" />‘s, is a Gaussian. We thus can write <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu+%5Csim+%5Cmathcal%7BN%7D%280%2C+q%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu \sim \mathcal{N}(0, q)." class="latex" title="h_\mu \sim \mathcal{N}(0, q)." /> Similarly, <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" /> is a linear combination of the <img src="https://s0.wp.com/latex.php?latex=g_%7B%5Cmu%7B%7Di%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_{\mu{}i}" class="latex" title="g_{\mu{}i}" />‘s and must be Gaussian. We thus write <img src="https://s0.wp.com/latex.php?latex=H_i+%5Csim+%5Cmathcal%7BN%7D%280%2C+%5Cpsi%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i \sim \mathcal{N}(0, \psi)" class="latex" title="H_i \sim \mathcal{N}(0, \psi)" />.</p>
<p>With some calculations detailed in the lecture notes and [12], we get <em>Gardner’s Formula</em>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cln+Z%7D%7BN%7D+%5Crightarrow+%5Calpha+%5Cint+%5Cln+%5Coverline%7B%5CPhi%7D%5Cleft%28-%5Cfrac%7B%5Csqrt%7Bq%7D+z%7D%7B%5Csigma%7D%5Cright%29+%5Cvarphi%28z%29+dz+%2B+%5Cint+%5Cln+%5Cleft%282+%5Ccosh%28%5Csqrt%7B%5Cpsi+z%7D%29%5Cright%29%5Cvarphi%28z%29+dz&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{\ln Z}{N} \rightarrow \alpha \int \ln \overline{\Phi}\left(-\frac{\sqrt{q} z}{\sigma}\right) \varphi(z) dz + \int \ln \left(2 \cosh(\sqrt{\psi z})\right)\varphi(z) dz" class="latex" title="\frac{\ln Z}{N} \rightarrow \alpha \int \ln \overline{\Phi}\left(-\frac{\sqrt{q} z}{\sigma}\right) \varphi(z) dz + \int \ln \left(2 \cosh(\sqrt{\psi z})\right)\varphi(z) dz" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> is our capacity, <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BM%7D%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{M}{N}" class="latex" title="\frac{M}{N}" />. It turns out that <img src="https://s0.wp.com/latex.php?latex=%5Csigma%5E2+%3D+1-q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma^2 = 1-q" class="latex" title="\sigma^2 = 1-q" /> and <img src="https://s0.wp.com/latex.php?latex=c+%3D+%5Cpsi%281-q%29%2F2%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c = \psi(1-q)/2," class="latex" title="c = \psi(1-q)/2," /> so the above equation only depends on two parameters, <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cpsi.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\psi." class="latex" title="\psi." /> It will turn out that <img src="https://s0.wp.com/latex.php?latex=q%2C+%5Cpsi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q, \psi" class="latex" title="q, \psi" /> have relations dependent on each other based on our definitions of <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu" class="latex" title="h_\mu" /> and <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />, and these will give us a fixed point equation for <img src="https://s0.wp.com/latex.php?latex=%28q%2C+%5Cpsi%29%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(q, \psi)," class="latex" title="(q, \psi)," /> which has two solutions: one near <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Capprox+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha \approx 1" class="latex" title="\alpha \approx 1" /> and one near <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Capprox+0.83.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha \approx 0.83." class="latex" title="\alpha \approx 0.83." /> It is believed that the second point is correct, meaning that the critical capacity should equal <img src="https://s0.wp.com/latex.php?latex=%5Calpha_%2A+%3D+0.83.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha_* = 0.83." class="latex" title="\alpha_* = 0.83." /></p>
<p><strong>1.4. Second Moment Method</strong></p>
<p>Now that we have Gardner’s formula, solving for <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> gives us an approximation for its distribution as</p>
<p><img src="https://s0.wp.com/latex.php?latex=Z+%5Csim+%5Cexp%5C%7BN%5Cmathcal%7BG%7D%28%5Calpha%29+%2B+%5Cmathcal%7BN%7D%280%2C+N%5Cvarepsilon%5E2%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z \sim \exp\{N\mathcal{G}(\alpha) + \mathcal{N}(0, N\varepsilon^2)\}" class="latex" title="Z \sim \exp\{N\mathcal{G}(\alpha) + \mathcal{N}(0, N\varepsilon^2)\}" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BG%7D%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{G}(\alpha)" class="latex" title="\mathcal{G}(\alpha)" /> is Gardner’s formula, and the Gaussian noise <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BN%7D%280%2CN%5Cvarepsilon%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{N}(0,N\varepsilon^2)" class="latex" title="\mathcal{N}(0,N\varepsilon^2)" /> arises from the Gaussian distribution of the <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu" class="latex" title="h_\mu" />‘s and <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />‘s. Again, we are interested in the probability that <img src="https://s0.wp.com/latex.php?latex=Z+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z &gt; 0" class="latex" title="Z &gt; 0" />, but due to the approximate nature of the above equation, we cannot work with this distribution directly, and instead can try the second moment method. However, the exponentiated Gaussian makes <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5BZ%5E2%5D+%5Cgg+%5Cmathbb%7BE%7D%5BZ%5D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{E}[Z^2] \gg \mathbb{E}[Z]^2" class="latex" title="\mathbb{E}[Z^2] \gg \mathbb{E}[Z]^2" /> and the moment method just gives <img src="https://s0.wp.com/latex.php?latex=P%28Z%3E0%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z&gt;0) \ge 0" class="latex" title="P(Z&gt;0) \ge 0" />, whereas we need <img src="https://s0.wp.com/latex.php?latex=P%28Z%3E0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z&gt;0)" class="latex" title="P(Z&gt;0)" /> with high probability.</p>
<p>The fault here lies with Gaussian noise due to the <img src="https://s0.wp.com/latex.php?latex=h_%5Cmu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_\mu" class="latex" title="h_\mu" />‘s and <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />‘s, so it is natural to consider what happens when we condition on them, getting rid of the noise. We denote</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D+%3D+%28h_%5Cmu%29_%7B%5Cmu+%3D+1%7D%5EM+%5Ctext%7B+and+%7D+%5Cunderline%7BH%7D+%3D+%28H_i%29_%7Bi%3D1%7D%5EN.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h} = (h_\mu)_{\mu = 1}^M \text{ and } \underline{H} = (H_i)_{i=1}^N." class="latex" title="\underline{h} = (h_\mu)_{\mu = 1}^M \text{ and } \underline{H} = (H_i)_{i=1}^N." /></p>
<p>Then, we can compute that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7BN%7D%5Clog+%5Cmathbb%7BE%7D%5BZ+%7C+%5Cunderline%7BH%7D%2C%5Cunderline%7Bh%7D%5D+%5Cto+%5Cmathcal%7BG%7D%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{N}\log \mathbb{E}[Z | \underline{H},\underline{h}] \to \mathcal{G}(\alpha)" class="latex" title="\frac{1}{N}\log \mathbb{E}[Z | \underline{H},\underline{h}] \to \mathcal{G}(\alpha)" /></p>
<p>in probability as <img src="https://s0.wp.com/latex.php?latex=N%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N\to \infty" class="latex" title="N\to \infty" />. (This is not an exact equality becacuse of the approximations made in the derivation of Gardner’s formula.) Moreover, we will have <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5BZ%5E2%7C%5Cunderline%7BH%7D%2C%5Cunderline%7Bh%7D%5D+%5Capprox+%5Cmathbb%7BE%7D%5BZ%7C%5Cunderline%7BH%7D%2C%5Cunderline%7Bh%7D%5D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{E}[Z^2|\underline{H},\underline{h}] \approx \mathbb{E}[Z|\underline{H},\underline{h}]^2" class="latex" title="\mathbb{E}[Z^2|\underline{H},\underline{h}] \approx \mathbb{E}[Z|\underline{H},\underline{h}]^2" />. The second moment method gives us the desired lower bound on <img src="https://s0.wp.com/latex.php?latex=P%28Z%3E0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z&gt;0)" class="latex" title="P(Z&gt;0)" />. However, note that these <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7BH%7D%2C%5Cunderline%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{H},\underline{h}" class="latex" title="\underline{H},\underline{h}" /> must satisfy the equations that defined them. In vector form, we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN%7D%7DG%5Ctanh+%5Cunderline%7BH%7D+%3D+%5Cunderline%7Bh%7D+%2B+b_%2AF%28%5Cunderline%7Bh%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{N}}G\tanh \underline{H} = \underline{h} + b_*F(\underline{h})" class="latex" title="\frac{1}{\sqrt{N}}G\tanh \underline{H} = \underline{h} + b_*F(\underline{h})" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN%7D%7DG%5ET%5Ctanh+F%28%5Cunderline%7Bh%7D%29+%3D+%5Cunderline%7BH%7D+%2B+d_%2A%5Ctanh%5Cunderline%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{N}}G^T\tanh F(\underline{h}) = \underline{H} + d_*\tanh\underline{H}" class="latex" title="\frac{1}{\sqrt{N}}G^T\tanh F(\underline{h}) = \underline{H} + d_*\tanh\underline{H}" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=b_%2A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b_*" class="latex" title="b_*" />, <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" />, and <img src="https://s0.wp.com/latex.php?latex=d_%2A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_*" class="latex" title="d_*" /> are constants and functions that appear in the rigorous definitions of <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{\mu}" class="latex" title="h_{\mu}" /> and <img src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_i" class="latex" title="H_i" />.<br />
Here arises a problem, however. We cannot solve these equations easily, and furthermore when we condition on <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{H}" class="latex" title="\underline{H}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h}" class="latex" title="\underline{h}" />, the <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />‘s that satisfy the above are not necessarily representative of matrices of standard Gaussians. Hence, simply conditioning on knowing the values of <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D%2C%5Cunderline%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h},\underline{H}" class="latex" title="\underline{h},\underline{H}" /> destroys the model and will not prove the lower bound on <img src="https://s0.wp.com/latex.php?latex=P%28Z%3E0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z&gt;0)" class="latex" title="P(Z&gt;0)" /> for Gaussian disorder.</p>
<p>To solve this problem, we introduce iteration: first, initialize <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D%5E%7B%280%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h}^{(0)}" class="latex" title="\underline{h}^{(0)}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7BH%7D%5E%7B%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{H}^{(1)}" class="latex" title="\underline{H}^{(1)}" /> (initialized to specific values detailed in [6]. Then, a simplified version of each time step’s update looks like</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D%5E%7B%28t%29%7D+%3D+%5Cfrac%7BG%5Ctanh%27%7B%5Cunderline%7BH%7D%5E%7B%28t%29%7D%7D%7D%7B%5Csqrt%7BN%7D%7D+-+b_%2AF%28%5Cunderline%7Bh%7D%5E%7B%28t+-+1%29%7D%29%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h}^{(t)} = \frac{G\tanh'{\underline{H}^{(t)}}}{\sqrt{N}} - b_*F(\underline{h}^{(t - 1)})," class="latex" title="\underline{h}^{(t)} = \frac{G\tanh'{\underline{H}^{(t)}}}{\sqrt{N}} - b_*F(\underline{h}^{(t - 1)})," /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7BH%7D%5E%7B%28t+%2B+1%29%7D+%3D+%5Cfrac%7BG%5ETF%28%5Cunderline%7Bh%7D%5Et%29%7D%7B%5Csqrt%7BN%7D%7D+-+d_%2A%5Ctanh%7B%5Cunderline%7BH%7D%5E%7B%28t+%2B+1%29%7D%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{H}^{(t + 1)} = \frac{G^TF(\underline{h}^t)}{\sqrt{N}} - d_*\tanh{\underline{H}^{(t + 1)}}." class="latex" title="\underline{H}^{(t + 1)} = \frac{G^TF(\underline{h}^t)}{\sqrt{N}} - d_*\tanh{\underline{H}^{(t + 1)}}." /></p>
<p>It has been proven (see [2,4]) that <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D%5E%7B%28t%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h}^{(t)}" class="latex" title="\underline{h}^{(t)}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7BH%7D%5E%7B%28t%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{H}^{(t)}" class="latex" title="\underline{H}^{(t)}" /> converge as <img src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\to\infty" class="latex" title="t\to\infty" />, and moreover the convergent values are distributed by what looks like a Gaussian at each time step. Since this sequence of <img src="https://s0.wp.com/latex.php?latex=%5Cunderline%7Bh%7D%2C%5Cunderline%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\underline{h},\underline{H}" class="latex" title="\underline{h},\underline{H}" /> converge (at a rate that is independent of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />) and are representative of Gaussian <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, for a special kind of truncated partition function <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tilde Z" class="latex" title="\tilde Z" />, conditioning on these iteration values allows the second moment method to work and gives</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5B%5Ctilde+Z+%7C+%5Cunderline%7Bh%7D%5E%7B%280%29%7D%2C%5Cunderline%7BH%7D%5E%7B%280%29%7D%2C%5Cdots%2C%5Cunderline%7Bh%7D%5E%7B%28t%29%7D%2C%5Cunderline%7BH%7D%5E%7B%28t%29%7D%5D%5E2+%5Capprox+%5Cmathbb%7BE%7D%5B%5Ctilde+Z%5E2+%7C+%5Cunderline%7Bh%7D%5E%7B%280%29%7D%2C%5Cunderline%7BH%7D%5E%7B%280%29%7D%2C%5Cdots%2C%5Cunderline%7Bh%7D%5E%7B%28t%29%7D%2C%5Cunderline%7BH%7D%5E%7B%28t%29%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{E}[\tilde Z | \underline{h}^{(0)},\underline{H}^{(0)},\dots,\underline{h}^{(t)},\underline{H}^{(t)}]^2 \approx \mathbb{E}[\tilde Z^2 | \underline{h}^{(0)},\underline{H}^{(0)},\dots,\underline{h}^{(t)},\underline{H}^{(t)}]" class="latex" title="\mathbb{E}[\tilde Z | \underline{h}^{(0)},\underline{H}^{(0)},\dots,\underline{h}^{(t)},\underline{H}^{(t)}]^2 \approx \mathbb{E}[\tilde Z^2 | \underline{h}^{(0)},\underline{H}^{(0)},\dots,\underline{h}^{(t)},\underline{H}^{(t)}]" /></p>
<p>which is then enough to establish the lower bound <img src="https://s0.wp.com/latex.php?latex=P%28Z%3E0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(Z&gt;0)" class="latex" title="P(Z&gt;0)" /> for the non-truncated partition function <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> (see [6] for details, see also [3] for closely related computations).</p>
<p><strong>2. <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAE-SAT</strong></p>
<p>This lecture also gave a brief overview of results in <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAESAT. In the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-SAT problem, we ask whether a boolean formula in <img src="https://s0.wp.com/latex.php?latex=CNF&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="CNF" class="latex" title="CNF" /> form, with each clause containing exactly <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> literals, has a satisfying solution. For <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAESAT, we instead require that the satisfying solution is not uniform on any clause; equivalently, each clause must contain at least one true and at least one false value. Finally, we will restrict our set of possible boolean formulae to those for which every variable is contained in exactly <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> clauses; we call this model <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAESAT. We briefly outline the critical capacities of clauses where the solution space changes. For more background on the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAESAT probem and its variants, see [10].</p>
<p>As with the perceptron model, we are concerned with the expected number of solutions <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> of this system where the <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-regular formula is chosen uniformly at random. It turns out that for any fixed <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D%5Cfrac%7Bd%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha=\frac{d}{k}" class="latex" title="\alpha=\frac{d}{k}" />, the expected proportion of satisfiable solutions as <img src="https://s0.wp.com/latex.php?latex=n%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n\to\infty" class="latex" title="n\to\infty" /> converges to some <img src="https://s0.wp.com/latex.php?latex=f%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(\alpha)" class="latex" title="f(\alpha)" />. More on this, the model in general and the critical <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> constants mentioned below can be found in [15]. Via an application of Markov’s inequality and Jensen’s Inequality for the convex function <img src="https://s0.wp.com/latex.php?latex=x%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^n" class="latex" title="x^n" />, <img src="https://s0.wp.com/latex.php?latex=f%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(\alpha)" class="latex" title="f(\alpha)" /> may be bounded above by <img src="https://s0.wp.com/latex.php?latex=f%5E%7BRS%7D%28%5Calpha%29%3D%28%5Cmathbb%7BE%7D+Z%29%5E%7B%5Cfrac%7B1%7D%7Bn%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f^{RS}(\alpha)=(\mathbb{E} Z)^{\frac{1}{n}}" class="latex" title="f^{RS}(\alpha)=(\mathbb{E} Z)^{\frac{1}{n}}" />, shown graphically below.</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/CS-229-Pic-2.png?w=600" alt="CS 229 Pic 2" class="alignnone size-full wp-image-6352" /><br />
The diagram also shows the nature of the expected assortment of the solutions of a random <img src="https://s0.wp.com/latex.php?latex=d-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-" class="latex" title="d-" />regular <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-NAESAT for ranges of values of <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" />. Namely, physics analysis suggests the following:</p>
<ul>
<li>For <img src="https://s0.wp.com/latex.php?latex=0%3C%5Calpha%3C%5Calpha_d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0&lt;\alpha&lt;\alpha_d" class="latex" title="0&lt;\alpha&lt;\alpha_d" />, w.h.p. the solutions are concentrated in a single large cluster.</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=%5Calpha_d%3C%5Calpha%3C%5Calpha_%7B%5Ctext%7Bcond%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha_d&lt;\alpha&lt;\alpha_{\text{cond}}" class="latex" title="\alpha_d&lt;\alpha&lt;\alpha_{\text{cond}}" />, w.h.p. the solutions are distributed among a large number of clusters.</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=%5Calpha_%7B%5Ctext%7Bcond%7D%7D%3C%5Calpha_%7B%5Ctext%7Bsat%7D%7D%3C0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha_{\text{cond}}&lt;\alpha_{\text{sat}}&lt;0" class="latex" title="\alpha_{\text{cond}}&lt;\alpha_{\text{sat}}&lt;0" />, the function <img src="https://s0.wp.com/latex.php?latex=f%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(\alpha)" class="latex" title="f(\alpha)" /> breaks away from <img src="https://s0.wp.com/latex.php?latex=f%5E%7BRS%7D%28%5Calpha%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f^{RS}(\alpha)" class="latex" title="f^{RS}(\alpha)" />, and w.h.p. the solutions are concentrated in a small number of clusters.</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3E%5Calpha_%7B%5Ctext%7Bsat%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha&gt;\alpha_{\text{sat}}" class="latex" title="\alpha&gt;\alpha_{\text{sat}}" />, w.h.p. there are no satisfiable solutions.</li>
</ul>
<p>One final note for this model: the solutions to satisfiability problems tend to be more clumpy than in the perceptron model, so correlation decay methods won’t immediately work. See [15] for how this is handled.</p>
<p><strong>References</strong></p>
<ol>
<li>N. Bansal. Constructive algorithms for discrepancy minimization. In <em>Proc. FOCS</em> 2010, pages 3–10.</li>
<li>M. Bayati and A. Montanari. The dynamics of message passing on dense graphs, with applications to compressed sensing. <em>IEEE Trans. Inform. Theory</em>, 57(2):764-785, 2011.</li>
<li>Bolthausen, E., 2018. A Morita type proof of the replica-symmetric formula for SK. arXiv preprint arXiv:1809.07972.</li>
<li>E. Bolthausen. An iterative construction of solutions of the TAP equations for the Sherrington-Kirkpatrick model. <em>Commun. Math. Phys.</em>, 325(1):333-366, 2014.</li>
<li>T. Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. <em>IEEE Trans. Electron. Comput.</em> 14(3):326-334.</li>
<li>J. Ding and N. Sun. Capacity lower bound for the Ising perceptron. <a href="https://arxiv.org/pdf/1809.07742.pdf" rel="nofollow">https://arxiv.org/pdf/1809.07742.pdf</a></li>
<li>E. Gardner and B. Derrida. Optimal storage properties of neural network models. <em>J. Phys. A.</em>, 21(1): 271–284, 1988.</li>
<li>J. H. Kim and J. R. Roche. Covering cubes by random half cubes, with applications to binary neural networks. <em>J. Comput. Syst. Sci.</em>, 56(2):223–252, 1998</li>
<li>W. Krauth and M. Mézard. Storage capacity of memory networks with binary couplings. <em>J. Phy.</em> 50(20): 3057-3066, 1989.</li>
<li>F. Krzakala et al. “Gibbs states and the set of solutions of random constraint satisfaction problems.” <i>Proc. Natl. Acad. Sci.</i> 104.25 (2007): 10318-10323.</li>
<li>S. Lovett and R. Meka. Constructive discrepancy minimization by walking on the edges. <em>SIAM J. Comput.</em>, 44(5):1573-1582.</li>
<li>M. Mézard. The space of interactions in neural networks: Gardner’s computation with the cavity method. <em>J. Phys. A.</em>, 22(12):2181, 1989</li>
<li>M. Mézard and G. Parisi and M. Virasoro. SK Model: The Replica Solution without Replicas. <em>Europhys. Lett.</em>, 1(2): 77-82, 1986.</li>
<li>M. Shcherbina and B. Tirozzi. Rigorous solution of the Gardner problem. <em>Commun. Math. Phys.</em>, 234(3):383-422, 2003.</li>
<li>A. Sly and N. Sun and Y. Zhang. The Number of Solutions for Random Regular NAE-SAT. In <em>Proc. FOCS</em> 2016, pages 724-731.</li>
<li>J. Spencer. Six standard deviations suffice. <em>Trans. Amer. Math. Soc.</em> 289 (1985), 679-706</li>
<li>M. Talagrand. Intersecting random half cubes. <em>Random Struct. Algor.</em>, 15(3-4):436–449, 1999.</li>
</ol></div>







<p class="date">
by degeneratetriangle <a href="https://windowsontheory.org/2018/12/13/ising-perceptron-under-gaussian-disorder-and-k-nae-sat/"><span class="datestr">at December 14, 2018 04:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2536467445996425170">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2018/12/inverting-onto-functions.html">Inverting Onto Functions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>Here's an open question that goes back to a <a href="https://doi.org/10.1016/S0890-5401(03)00119-6">2003 paper</a>  that I wrote with Steve Fenner, John Rogers and Ashish Naik. The <a href="https://doi.org/10.1109/CCC.1996.507683">conference paper</a> goes back to 1996.<br />
<br />
In that paper we discuss two hypothesis we badly called Q and Q' and it still remains open whether the two hypotheses are equivalent.<br />
<br />
Q has a number of equivalent definitions, including<br />
<br />
<ul>
<li>For all NP machines M that accepting all strings, there is polynomial-time computable function f such that f(x) is an accepting path of M(x) for all x.</li>
<li>For every onto honest polynomial-time computable function g there is a polynomial-time computable function f such that f finds an inverse of g, more precisely g(f(g(x))) = g(x) for all x.</li>
<li><a href="https://en.wikipedia.org/wiki/TFNP">TFNP</a> is computable in FP.</li>
</ul>
<div>
For lots more equivalences see <a href="https://lance.fortnow.com/papers/files/q.pdf">the paper</a>. </div>
<div>
<br /></div>
<div>
Q' is the bit version of Q. For example</div>
<br />
<ul>
<li>For all NP machines M that accepting all strings, there is polynomial-time computable function f such that f(x) outputs the first bit of an accepting path of M(x) for all x.</li>
<li>For every onto honest polynomial-time computable function g there is a polynomial-time computable function f such that f finds the first bit of an inverse of g, more precisely for all x there is a y such that g(y) = g(x) and f(x) is the first bit of y.</li>
</ul>
<div>
Now Q implies Q', if you can find an accepting path of M(x) you can just read off the first bit. Does Q' imply Q? </div>
<div>
<br /></div>
<div>
If P = NP you can find solutions using self-reductions. For Q' self-reduction gets stuck because as you start filling in bits you may lose the "onto" promise. </div>
<div>
<br /></div>
<div>
On the other hand we don't even know any relativized worlds where Q' is true and Q is false. So either prove that Q' implies Q or show a relativized world where Q' is true and Q is false.</div>
<div>
<br /></div>
<div>
How often can I dole out 22-year old open problems that don't require deep complexity to understand. Can't promise what techniques you'll need to solve it.</div></div><div class="commentbar"><p></p></div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2018/12/inverting-onto-functions.html"><span class="datestr">at December 13, 2018 02:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/13/postdoc-at-national-university-of-singapore-nus-apply-by-march-15-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/13/postdoc-at-national-university-of-singapore-nus-apply-by-march-15-2019/">Postdoc at National University of Singapore (NUS) (apply by March 15, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>One post-doctoral research fellow fellow position is available at the School of Computing, National University of Singapore, Singapore for the project: Beyond NP Revolution.</p>
<p>Interested candidates should send their resume and statement about their research to Kuldeep Meel (meel@comp.nus.edu.sg).</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~meel/theory-postdoc.html">https://www.comp.nus.edu.sg/~meel/theory-postdoc.html</a><br />
Email: meel@comp.nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/13/postdoc-at-national-university-of-singapore-nus-apply-by-march-15-2019/"><span class="datestr">at December 13, 2018 07:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/211">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/211">TR18-211 |  Parametric Shortest Paths in Planar Graphs | 

	Kshitij Gajjar, 

	Jaikumar  Radhakrishnan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We construct a family of planar graphs $(G_n: n\geq 4)$, where $G_n$ has $n$ vertices including a source vertex $s$ and a sink vertex $t$, and edge weights that change linearly with a parameter $\lambda$ such that, as $\lambda$ increases, the cost of the shortest path from $s$ to $t$ has $n^{\Omega(\log n)}$ break points. This shows that lower bounds obtained earlier by Carstensen (1983) and Mulmuley & Shah (2000) for general graphs also hold for planar graphs. A conjecture of Nikolova (2009) states that the number of break points in $n$-vertex planar graphs is bounded by a polynomial in $n$; our result refutes this conjecture.

Gusfield (1980) and Dean (2009) showed that the number of break points for an $n$-vertex graph is $n^{\log n + O(1)}$ assuming linear edge weights; we show that if the edge weights are allowed to vary as a polynomial of degree at most $d$, then the number of break points is $n^{\log n + O(\alpha(n)^d)}$, where $\alpha(n)$ is the slowly growing inverse Ackermann function. This upper bound arises from Davenport-Schinzel sequences.<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/211"><span class="datestr">at December 12, 2018 03:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-7727782887784240943">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2018/12/csgssi-highlights-for-2018.html">CS@GSSI: Highlights for 2018</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>It is the time of the year when one sees "Best of 2018 in <i>X</i> (for some <i>X</i>)"/"Year in Review" articles appear just about everywhere in print and on the internet. Since I need to deliver a ten-minute presentation to the Scientific Advisory Board of the  <a href="http://www.gssi.it/" target="_blank">Gran Sasso Science Institute (GSSI)</a> discussing the highlights in 2018 for the <a href="https://cs.gssi.it/" target="_blank">computer science group</a>, I thought that it might be a good idea to prepare for that task by following the trend and dumping some of my thoughts in this post.<br /><br />So what were the main achievements of the CS@GSSI group in 2018? With only ten minutes at my disposal, I needed to make some hard choices and I decided to focus on the kudos that were bestowed on our students. After all, "our students' success is our success" and the GSSI is also an international PhD school.<br /><br />Before I do so, however, let me give a bird's eye view of the research activity of the group and of the changes in personnel we have had in 2018. In November 2017, the group consisted of two full professors (one, <a href="http://www.di.univaq.it/flammini/" target="_blank">Michele Flammini</a>,  on loan from the University of L'Aquila), one tenure-track assistant professor, two non-tenute-track assistant professors and one postdoc. Those six people had to manage about 40 PhD students at various stages in their doctoral studies and this task could only be achieved with the help of external supervisors. Today, the faculty members in the group have not changed, but  the number of postdocs has grown to eight from November 2018. (We have been very lucky in hiring some superb young scientists!) At the same time, we have admitted eight new PhD students, seven of whom are from outside Italy and three are women, and are happy to have <a href="http://pageperso.lif.univ-mrs.fr/~shantanu.das/en/" target="_blank">Shantanu Das</a> (Marseille) as a visiting professor for a few months. <br /><br /><b>Publications</b><br /><br />Despite the work resulting from having to manage a fairly large number of PhD students, give courses and deal with the administrative red tape that accompanies just about everything at an Italian university, my colleagues at CS@GSSI and our students managed to produce a substantial number of high-quality publications including 16 journal papers, 52 conference papers, four book chapters, two edited volumes and five refereed short abstracts/posters. (Note that these are publications with GSSI affiliation, so there is only one paper authored by one of the new seven postdocs.)<br /><br />Essentially every high-quality conference in the fields of research covered by CS@GSSI has seen the presentation of at least one paper from the group. To wit, my colleagues published seven papers in top AI conferences (AAAI, AAMAS, IJCAI), seven papers in high-quality TCS conferences (including STOC and ICALP), two papers in the top SE conference (ICSE) and one in the top conference on foundations of programming languages (POPL). All the journal papers are in high-class outlets. Here let me just highlight that I have covered the result of a collaborative effort between researchers in algorithms and software engineering <a href="https://processalgebra.blogspot.com/2018/09/shortest-path-algorithms-applied-to.html" target="_blank">elsewhere</a>.<br /><br />Two of the papers are co-authored with researchers from the Urban Studies group at at the GSSI, and  witness the cross-disciplinary work carried out by my colleagues in topics such as Smart Cities.<br /><br /><b>Student awards and honours</b><br /><br />It is hard to choose what student achievements to highlight, so let me say that all our PhD students had  an excellent year and that the three contributions below are just a small sample of the work done by the PhD  students at the institute.<br /><ul><li>CS@GSSI student <a href="http://www.gssi.it/people/students/students-computer-science/item/897-abdelsalam-ahmed-mohamed-ahmed" target="_blank">Ahmed Abdelsalam</a> has contributed to  the proposal that won the first prize at the <a href="https://www.softfire.eu/open-calls/softfire-challenge/" target="_blank">Interworking stream at the SoftFIRE Challenge 2018</a>, which carries a 40,000 € prize. Ahmed's work on IPv6 Segment Routing (SRv6) and his recently developed SRv6-aware version of the network intrusion and detection system Snort played a key role in the award-winning proposal. Every Linux user is  running GSSI software! Ahmed's network intrusion and detection system might well be the work carried out at the GSSI that is most widely used worldwide and has the most impact on a day to day basis. Ahmed now works for Cisco in Rome. </li><li>CS@GSSI student <a href="https://sites.google.com/view/emiliocruciani/" target="_blank">Emilio Cruciani </a>has published papers in the top conference in software engineering (ICSE) (jointly with  fellow student <a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, <a href="http://cin.ufpe.br/~bafm/" target="_blank">Breno Miranda</a> and <a href="http://bertolino.isti.cnr.it/" target="_blank">Antonia Bertolino</a>; see <a href="http://processalgebra.blogspot.com/2017/12/first-year-computer-science-students-at.html" target="_blank">here</a> for a post I wrote on one of the two papers), and in two of the three top conferences in the theory of artificial intelligence (AAAI and AAMAS). To put these achievements in perspective, a conference like AAAI has over 7,000 submissions and an acceptance rate of around 16%. </li><li>CS@GSSI student <a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, whom I already mentioned in the previous highlight, has received the Early Career Researcher Award from the International Conference on Software Architectures. </li></ul>Let me also mention that my colleagues also receive awards for their sterling service to the community. By way of example, <a href="http://cs.gssi.infn.it/catia.trubiani/" target="_blank">Catia Trubiani</a> received an Exceptional Reviewer Award from ICSA.   <br /><ul></ul><b>Software tools</b><br /><br />Despite its very limited size, CS@GSSI devotes a substantial amount of effort to tool development. I have already mentioned the contribution given by Ahmed to the Linux kernel (IPv6 SHR). Other software tools developed by my colleagues include:<br /><ul><li><a href="https://dblp.org/pers/hd/i/Inverso:Omar" target="_blank">Omar Inverso</a>'s <a href="https://github.com/omainv/cseq" target="_blank">Lazy-CSeq</a>, an award-winning automated analysis of complex concurrent programs, and his CSeq-fpmath and CSeq-fpmath-ILP, for the automated verification of data-intensive programs such as control system software; </li><li>a prototype tool for the automated analysis of multi-agent-based models, developed by <a href="https://dblp.org/pers/hd/s/Stefano:Luca_Di" target="_blank">Luca Di Stefano</a>, Omar and Rocco De Nicola. </li></ul><b>Addendum dated 16 December 2018:</b>  <a href="https://dblp.org/pers/hd/i/Inverso:Omar" target="_blank">Omar Inverso</a>'s <a href="https://github.com/omainv/cseq" target="_blank">Lazy-CSeq</a> has just received yet another accolade! It has won a Silver Medal at the <a href="https://sv-comp.sosy-lab.org/2019/" target="_blank">2019 8th International Competition on Software Verification (SV-COMP 2019).</a> As can be seen from the results of the competition available <a href="https://sv-comp.sosy-lab.org/2019/results/results-verified/" target="_blank">here</a>,   Omar's tool <a href="https://github.com/omainv/cseq/releases" target="_blank">Lazy-CSeq</a> came second in the category ConcurrencySafety and was beaten only by a <a href="https://github.com/yinliangze/yogar-cbmc" target="_blank">tool</a> developed by a Chinese team from Tsinghua University (which is widely considered the best technical university in China). <br /><ul></ul><b>Events</b><br /><br />The CS@GSSI group organized the following events in 2018: <br /><ul><li><a href="https://cs.gssi.it/sea2018/" target="_blank">SEA 2018 - 17th International Symposium on Experimental Algorithms</a>, </li><li><a href="http://icities2018.disim.univaq.it/" target="_blank">I-CiTies 2018</a>  and </li><li><a href="http://icetcs.ru.is/" target="_blank">ICE-TCS</a>/GSSI Workshop 2018  </li></ul>All the events were well attended and fruitful. (To whet you appetite, let me say that we will be organizing <a href="https://cs.gssi.it/sirocco2019/" target="_blank">SIROCCO 2019</a>.)<br /><br /><b>Collaborations with other groups at the GSSI</b><br /><br />I think that it is fair to say that the CS group at the GSSI is playing the role of glue within the institute: like Nokia claimed it used to do, it is connecting people! In fact, I do believe that CS is and will increasingly become the hub of the institute. Here are some examples to substantiate my claim, in addition to the two papers published jointly with researchers in Urban Studies. <br /><ul><li>We have run joint seminars with Urban Studies and Mathematics (and brought <a href="https://www2.mathematik.tu-darmstadt.de/~kohlenbach/" target="_blank">an ICM 2018 invited section speaker</a> to the GSSI). </li><li>We have a joint postdoc with Urban Studies (Geotouch project on tourist flow). </li><li>We have submitted two joint project proposals with Urban Studies. </li><li>Catia Trubiani participates in a  COST action related to machine learning with researchers in the Astroparticle Physics group. </li></ul><b>Submission of grant proposals</b><br /><br />We have at least eight grant proposals under evaluation, submitted to funding agencies in Italy, European Union and Iceland. Moreover, we have received funding for one PhD position from a local start-up company and from the municipality of L'Aquila for a project on an innovative platform for tourism.<br /><br />Of course, I hope that some of those grant applications will be successful. However, money isn’t an end in itself. Lots of it does not necessarily lead to good, let alone great, science! In my career, I have seen richly funded projects produce much less than expected (and sometimes no science at all), whereas some grassroots projects with little or no funding have led to great advances.<br /><br />I do hope that, regardless of the funding situation, my colleagues will go from strength to strength, produce the best work they can and serve as role models for the PhD students at the GSSI. One cannot ask for more.<br /><br /><b>Self-evaluation for 2018</b><br /><ul><li>The CS group is already a productive and internationally respected group, despite its very limited size.</li><li>We are lucky to have excellent students, and brilliant postdocs and young faculty.</li><li>CS is already a hub at GSSI, but is grossly over-committed. We need to hire a good number of excellent faculty soon! If you are interested, send an <a href="https://processalgebra.blogspot.com/2018/11/calls-for-expressions-of-interest-in.html" target="_blank">expression of interest</a>. </li></ul><br /><b>The future</b><br /><br />I think that 2019 will be a key year for the growth of CS@GSSI. I looked at my crystal ball and made a few predictions, but I prefer to air them during the meeting with the Scientific Advisory Board of the GSSI on Saturday without making them public on the internet. After all, "verba volant, scripta manent!"<br /><br />I just hope that the GSSI will continue to give us the freedom to hire the best people we can find and allow us to do our work.  <br /><br /><br /><br /><br /><br /><ul></ul><br /><ul> </ul></div><div class="commentbar"><p></p><span href="http://processalgebra.blogspot.com/feeds/7727782887784240943/comments/default" class="commentbutton"></span><a href="http://processalgebra.blogspot.com/feeds/7727782887784240943/comments/default"><img src="/images/feed-icon.png" class="commenticon" /> Subscribe to comments</a>  | <a href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=7727782887784240943"><img src="/images/post-icon.png" class="commenticon" /> Post a comment</a></div></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2018/12/csgssi-highlights-for-2018.html"><span class="datestr">at December 12, 2018 02:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16618">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant Solved the Mihail-Vazirani Conjecture for Matroids!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p> </p>
<p><strong><span style="color: #ff0000;"><img src="https://gilkalai.files.wordpress.com/2018/12/milenaumesh.png?w=640" alt="Milena+Umesh" class="alignnone size-full wp-image-16635" /><br />
Milena Mihail and Umesh Vazirani</span></strong></p>
<p>I thank Nati Linial, Dan Spielman and Karim Adiprasito for telling me about the news.</p>
<h2>The Mihail-Vazirani conjecture for matroids and the Feder-Mihail’s theorem</h2>
<p>Consider a collection <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vectors. A basis is a subset of <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> of linearly independent vectors that span the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" />.  We can define a graph whose vertices are all bases and two bases are adjacent if their symmetric difference has two elements. Mihail and Vazirani conjectured that for every set <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> of vertices in this graph the number of edges between <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> to its complement <img src="https://s0.wp.com/latex.php?latex=%5Cbar+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bar Y" class="latex" title="\bar Y" /> is at least <img src="https://s0.wp.com/latex.php?latex=%5Cmin+%28%7CY%7C+%7C%2C%5Cbar+Y%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\min (|Y| |,\bar Y|)" class="latex" title="\min (|Y| |,\bar Y|)" />.</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> consists of the elements of the standard basis in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^d" class="latex" title="\mathbb R^d" /> and their negatives then the graph we obtain is the graph of the discrete <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> dimensional discrete cube and the assertion of the Mihail-Vazirani conjecture is well known.</p>
<p>The Mihail-Vazirani conjecture was formulated (and have now been proved) for arbitrary matroids. Think about a matroid as a collection <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> of subsets (the independent sets of the matroid) of some ground set <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> that closed under taking subsets (hence a simplicial complex) with the following property: For every <img src="https://s0.wp.com/latex.php?latex=Y+%5Csubset+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y \subset X" class="latex" title="Y \subset X" />, the induced simplicial complex on <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> denoted by <img src="https://s0.wp.com/latex.php?latex=K%28Y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K(Y)" class="latex" title="K(Y)" />  is pure. In other words, for every <img src="https://s0.wp.com/latex.php?latex=Y+%5Csubset+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y \subset X" class="latex" title="Y \subset X" />, all maximal independent subsets of <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> have the same cardinality.</p>
<p>In a pioneering 1992 paper Tomás Feder and Milena Mihail proved the conjecture for balanced matroids.</p>
<h2>Mihail and Vazirani conjecture for 0-1 polytopes.</h2>
<p>An even more general conjecture by Mihail and Vazirani is still open. It asserts that for every 0-1 polytope, for every set <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> of vertices, the number of edges between <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> to its complement <img src="https://s0.wp.com/latex.php?latex=%5Cbar+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\bar Y" class="latex" title="\bar Y" /> is at least <img src="https://s0.wp.com/latex.php?latex=%5Cmin+%28%7CY%7C%2C+%7C%5Cbar+Y%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\min (|Y|, |\bar Y|)" class="latex" title="\min (|Y|, |\bar Y|)" />.</p>
<h2>The new breakthrough</h2>
<p>Here is the link to the paper.</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1811.01816">Log-Concave Polynomials II: High-Dimensional Walks and an FPRAS for Counting Bases of a Matroid</a> by Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant</p>
<p>Let me mention that there was simultaneously another paper by a subset of the authors on related questions, another paper by Brändén and Huh who independently proved the strong log-concavity of several of the polynomials that appear in the ALOV  paper, and there will be several forthcoming papers by these two groups.</p>
<p><strong>Here is the abstract:</strong> We design an FPRAS to count the number of bases of any matroid given by an independent set oracle, and to estimate the partition function of the random cluster model of any matroid in the regime where <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mn" id="MathJax-Span-3">0</span><span class="mo" id="MathJax-Span-4">&lt;</span><span class="mi" id="MathJax-Span-5">q</span><span class="mo" id="MathJax-Span-6">&lt;</span><span class="mn" id="MathJax-Span-7">1</span></span></span></span>. Consequently, we can sample random spanning forests in a graph and (approximately) compute the reliability polynomial of any matroid. We also prove the thirty year old conjecture of Mihail and Vazirani that the bases exchange graph of any matroid has expansion at least 1. One of our key observations is a close connection between pure simplicial complexes and multiaffine homogeneous polynomials. Specifically, if <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10">X</span></span></span></span> is a pure simplicial complex with positive weights on its maximal faces, we can associate with <span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-11"><span class="mrow" id="MathJax-Span-12"><span class="mi" id="MathJax-Span-13">X</span></span></span></span> a multiaffine homogeneous polynomial <img src="https://s0.wp.com/latex.php?latex=p_X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_X" class="latex" title="p_X" /> such that the eigenvalues of the localized random walks on <span class="MathJax" id="MathJax-Element-5-Frame"><span class="math" id="MathJax-Span-21"><span class="mrow" id="MathJax-Span-22"><span class="mi" id="MathJax-Span-23">X</span></span></span></span> correspond to the eigenvalues of the Hessian of derivatives of <img src="https://s0.wp.com/latex.php?latex=p_X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_X" class="latex" title="p_X" />.</p>
<h2>Spectral negative dependence and Hodge-Riemann</h2>
<p>A key paragraph regarding the method is the following:</p>
<p>“Our approach has a close connection to the original plan of Feder and Mihail (1992) who used the negative correlation property of balanced matroids to show that the bases exchange walk mixes rapidly. Unfortunately, most interesting matroids do not satisfy negative correlation. But it was observed [AKH18; HW16; AOV18] that all matroids satisfy a spectral negative dependence property.” AKH18 (a typo, it should be AHK18) is the solution for the Rota-Heron conjecture by Adiprasito, Huh and Katz that relies on the Hodge-Riemann property for matroids that we mentioned <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">in this post</a>. (I still feel in debt for a more detailed blog post about Adiprasito, Huh and Katz’ breakthrough!).”</p>
<p>I think that high dimensional expanders and random walks on them also plays a role in the new development.</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/"><span class="datestr">at December 11, 2018 09:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4010">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4010">The NP genie</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Hi from the <a href="https://q2b2018.qcware.com/">Q2B</a> conference!</p>
<p>Every nerd has surely considered the scenario where an all-knowing genie—or an enlightened guru, or a superintelligent AI, or God—appears and offers to answer any question of your choice.  (Possibly subject to restrictions on the length or complexity of the question, to prevent glomming together every imaginable question.)  What do you ask?</p>
<p>(Standard joke: “What question <em>should</em> I ask, oh wise master, and what is its answer?”  “The question you should ask me is the one you just asked, and its answer is the one I am giving.”)</p>
<p>The other day, it occurred to me that theoretical computer science offers a systematic way to generate interesting variations on the genie scenario, which have been contemplated less—variations where the genie is no longer omniscient, but “merely” more scient than any entity that humankind has ever seen.  One simple example, which I gather is often discussed in the AI-risk and rationality communities, is an oracle for the halting problem: what computer program can you write, such that knowing whether it halts would provide the most useful information to civilization?  Can you solve global warming with such an oracle?  Cure cancer?</p>
<p>But there are many other examples.  Here’s one: suppose what pops out of your lamp is a genie for <em>NP</em> questions.  Here I don’t mean NP in the technical sense (that would just be a pared-down version of the halting genie discussed above), but in the human sense.  The genie can only answer questions by pointing you to ordinary evidence that, once you know where to find it, makes the answer to the question clear to every competent person who examines the evidence, with no further need to trust the genie.  Or, of course, the genie could <em>fail</em> to provide such evidence, which itself provides the valuable information that there’s no such evidence out there.</p>
<p>More-or-less equivalently (because of binary search), the genie could do what my parents used to do when my brother and I searched the house for Hanukkah presents, and give us “hotter” or “colder” hints as we searched for the evidence ourselves.</p>
<p>To make things concrete, let’s assume that the NP genie will only provide answers of 1000 characters or fewer, in plain English text with no fancy encodings.  Here are the candidates for NP questions that I came up with after about 20 seconds of contemplation:</p>
<ul>
<li>Which pieces of physics beyond the Standard Model and general relativity can be experimentally confirmed with the technology of 2018? What are the experiments we need to do?</li>
<li>What’s the current location of the Ark of the Covenant, or its remains, if any still exist?  (Similar: where can we dig to find physical records, if any exist, pertaining to the Exodus from Egypt, or to Jesus of Nazareth?)</li>
<li>What’s a sketch of a resolution of P vs. NP, from which experts would stand a good chance of filling in the details?  (Similar for other any famous unsolved math problem.)</li>
<li>Where, if anywhere, can we point radio telescopes to get irrefutable evidence for the existence of extraterrestrial life?</li>
<li>What happened to Malaysia Flight 370, and where are the remains by which it could be verified?  (Similar for Amelia Earhart.)</li>
<li>Where, if anywhere, can we find intact DNA of non-avian dinosaurs?</li>
</ul>
<p>Which NP questions would <em>you</em> ask the genie?  And what other complexity-theoretic genies would be interesting to consider?  (I thought briefly about a <a href="https://en.wikipedia.org/wiki/Parity_P">⊕P</a> genie, but I’m guessing that the yearning to know whether the number of sand grains in the Sahara is even or odd is limited.)</p>
<hr />
<p><font color="red"><b>Update:</b></font> I just read Lenny Susskind’s <a href="https://blog.ycombinator.com/leonard-susskind-on-richard-feynman-the-holographic-principle-and-unanswered-questions-in-physics/">Y Combinator interview</a>, and found it delightful—pure Lenny, and covering tons of ground that should interest anyone who reads this blog.



</p><p></p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4010"><span class="datestr">at December 11, 2018 07:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/10/faculty-at-university-of-california-at-riverside-apply-by-january-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/10/faculty-at-university-of-california-at-riverside-apply-by-january-1-2019/">Faculty at University of California at Riverside (apply by January 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the University of California, Riverside (UCR) invites applications for two tenure-track/tenured faculty positions beginning the 2019/20 academic year. Algorithmics is among the areas of interest. Other areas include machine learning, artificial intelligence, visualization, human-computer interaction, and virtual reality.</p>
<p>Website: <a href="https://www1.cs.ucr.edu">https://www1.cs.ucr.edu</a><br />
Email: marek@cs.ucr.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/10/faculty-at-university-of-california-at-riverside-apply-by-january-1-2019/"><span class="datestr">at December 10, 2018 10:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3060288792037164348">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2018/12/super-asymmetry-on-big-bang-theory-how.html">Super Asymmetry on The Big Bang Theory: How Realistic?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>The TV show <b>The Big Bang Theory</b> portrays academia so I am naturally curious how realistic it is. I have posted about this before (see <a href="https://blog.computationalcomplexity.org/2014/04/the-big-bang-theory-hits-close-to-home.html">here</a>) in the context of whether actual things they say about physics are true. Today I post about a recent arc where Amy and Sheldon are working on Super asymmetry.<br />
<br />
<br />
SPOILER ALERT<br />
<br />
1) The name: Super Asymmetry. Its not a field but it could be. I assume its about particle physics but I'm not sure they ever say this. A fine name!<br />
<br />
2) Amy is a neurobiologist (this was flagged as not being word, but I think it  is) working with Sheldon on a physical theory that I would assume requires hard math.  Physics is hard! So I wonder how realistic this is. Actually, more important than being hard is that you need a lot of background knowledge. So the questions of interest is: Can an amateur still help in a discovery of a new physical theory? This may depend on the definitions of <b>amateur, discovery, new, and physical.</b>  Alone I would doubt it. But with help from Sheldon, I can believe it. Still, making new discoveries in an old field is hard.<br />
<br />
3) Amy and Sheldon first had the idea for super asymmetry on their honeymoon. Most married couples have other things to do on their honeymoon. (I did ask my darling to prove the primes were infinite on our wedding day before I married her. She was nervous so couldn't do it, but normally she could. I know a mathematician who made her spouse memorize the definition of a Banach Space before they got married, and recite it to her on their wedding day before they got married.)<br />
<br />
4) After they do most of the work they THEN go track down references. This seems stupid but not unrealistic. You can get excited about a theory and work on it at breakneck speed and not want to slow down to check references. But see next point.<br />
<br />
5) Sheldon was counting on this for a Nobel Prize. I would think you would check refs before even thinking in those terms.<br />
<br />
6) An article in Russian was found that proved the theory could not work. There are a few things wrong with this:<br />
<br />
a) The article used the exact same phrase ``Super Asymmetry'' - that seems unlikely.<br />
<br />
b) They seemed to not READ the article, just the first page, and then say. DARN, all that work down the tubes.<br />
<br />
c) They seemed to not even try to say `OKAY, they did BLAH, we did BLAH BLAH, how do they compare and contrast' (ADDED LATER- I just saw the episode afterwards. They probably DO have something after all. They should have listened to my advice before going into a funk.)<br />
<br />
d) If they did all of that work I am sure SOMETHING can be recovered from it.<br />
<br />
7) This is not really a post about The Big Bang Theory. I want to know more about your experiences with research: have you worked on a problem and found out it didn't work or was already done, or something like that. And what happened?<br />
<br />
<br /></div><div class="commentbar"><p></p></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2018/12/super-asymmetry-on-big-bang-theory-how.html"><span class="datestr">at December 10, 2018 05:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15499">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2018/12/09/transposing/">Transposing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>On the arithmetic complexity of the matrix transpose</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2018/12/09/transposing/kkb/" rel="attachment wp-att-15501"><img src="https://rjlipton.files.wordpress.com/2018/12/kkb.png?w=250" alt="" class="alignright wp-image-15501" width="250" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ KKB ]</font></td>
</tr>
</tbody>
</table>
<p>
Michael Kaminski, David Kirkpatrick, and Nader Bshouty are complexity theorists who together and separately have proved many wonderful theorems. They wrote an interesting <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.3626&amp;rep=rep1&amp;type=pdf">paper</a> recently—well not quite—in 1988 about the transpose operation.</p>
<p>
Today we want to discuss an alternative proof of the main result of that paper.<br />
<span id="more-15499"></span></p>
<p>
</p><p></p><h2> The Transpose </h2><p></p>
<p></p><p>
The operation that maps a <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \times n}" class="latex" title="{n \times n}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> to its transpose <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7BT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^{T}}" class="latex" title="{A^{T}}" /> is quite important in many aspects of linear algebra. Recall that the transpose is defined by 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A%5E%7BT%7D%28i%2Cj%29+%3D+A%28j%2Ci%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A^{T}(i,j) = A(j,i) " class="latex" title="\displaystyle  A^{T}(i,j) = A(j,i) " /></p>
<p>for all indices <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i,j}" class="latex" title="{i,j}" />. A non-trivial issue arises already in proving this: </p>
<blockquote><p><b> </b> <em> <i>If <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> has an inverse then so does <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7BT%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A^{T}}" class="latex" title="{A^{T}}" /></i>. </em>
</p></blockquote>
<p>There are many proofs of this basic fact about the transpose, but it is not simple to prove it from first principles. For example look at William Wardlaw’s proof <a href="https://www.maa.org/sites/default/files/3004418139737.pdf.bannered.pdf">here</a>. Or <a href="http://www.doc.ic.ac.uk/~ae/papers/lecture04.pdf">here</a> for another.</p>
<p>
</p><p></p><h2> A Theorem </h2><p></p>
<p></p><p>
The paper of Kaminski, Kirkpatrick, and Bshouty (KKB) came up the other day, while I visited the computer science department at University of Buffalo. Atri Rudra told about some of his recent work on various complexity issues around matrix computations. One was an interesting question about the transpose operation on matrices. The result is the following: </p>
<blockquote><p><b>Theorem 1</b> <em> If the arithmetic complexity of <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+Ax%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x \rightarrow Ax}" class="latex" title="{x \rightarrow Ax}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> then the arithmetic complexity of <img src="https://s0.wp.com/latex.php?latex=%7By+%5Crightarrow+A%5E%7BT%7Dy%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y \rightarrow A^{T}y}" class="latex" title="{y \rightarrow A^{T}y}" /> is at most <img src="https://s0.wp.com/latex.php?latex=%7BO%28S+%2B+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{O(S + n)}" class="latex" title="{O(S + n)}" />. </em>
</p></blockquote>
<p>KKB had a nice proof of this theorem over forty years ago. Indeed they can get a precise expression for the complexity that is tighter than the above statement. Their proof is a careful examination of the structure of any arithmetic circuit that computes <img src="https://s0.wp.com/latex.php?latex=%7BAx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Ax}" class="latex" title="{Ax}" />. Essentially they show one can in a sense “run the computation backwards.” </p>
<p>
</p><p></p><h2> Another Proof </h2><p></p>
<p></p><p>
Anyway in my discussion with Atri, the other day, he described another proof of this basic theorem. He said consider the function that maps <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BAx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Ax}" class="latex" title="{Ax}" /> for a fixed matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. Suppose this linear map has arithmetic complexity <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />: that is the minimum number of arithmetic operations that are needed to compute <img src="https://s0.wp.com/latex.php?latex=%7BAx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Ax}" class="latex" title="{Ax}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. Note, <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> can vary greatly with the structure of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. Even for nonsingular matrices the complexity can vary quite a bit: for a random matrix is likely to be order <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^{2}}" class="latex" title="{n^{2}}" />; for a Fourier transform matrix it is order <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\log n}" class="latex" title="{n\log n}" />.</p>
<p>
He said it is known that the arithmetic complexity of <img src="https://s0.wp.com/latex.php?latex=%7BAx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Ax}" class="latex" title="{Ax}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7BT%7Dx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^{T}x}" class="latex" title="{A^{T}x}" /> are about the same. But proving this, while not hard, requires some care. Atri told me about a quite neat argument that proves it. Further, the proof is “two-lines” as Atri said:</p>
<p>
<em>Proof:</em>  Consider the function <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dy%5E%7BT%7DAx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)=y^{T}Ax}" class="latex" title="{f(x)=y^{T}Ax}" /> as a function of <img src="https://s0.wp.com/latex.php?latex=%7Bx%3D%28x_%7B1%7D%2C%5Cdots%2Cx_%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x=(x_{1},\dots,x_{n})}" class="latex" title="{x=(x_{1},\dots,x_{n})}" />. The gradient <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cnabla+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \nabla f(x)}" class="latex" title="{ \nabla f(x)}" /> is equal to all the partial derivatives of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" />. This means that it allows us to compute <img src="https://s0.wp.com/latex.php?latex=%7By%5E%7BT%7DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y^{T}A}" class="latex" title="{y^{T}A}" />, since the function is linear in each variable <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i}}" class="latex" title="{x_{i}}" />. The famous <a href="https://core.ac.uk/download/pdf/82480031.pdf">Derivative</a> <a href="https://rjlipton.wordpress.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">Lemma</a> of Walter Baur and Volker Strassen shows that a single arithmetical circuit of size order <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> plus the complexity of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> can compute <img src="https://s0.wp.com/latex.php?latex=%7B%5Cnabla+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\nabla f}" class="latex" title="{\nabla f}" />. It follows that we can compute all the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> partial derivatives in <img src="https://s0.wp.com/latex.php?latex=%7BO%28S%2Bn%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(S+n)}" class="latex" title="{O(S+n)}" /> arithmetic steps. But for our function <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> this is equal to <img src="https://s0.wp.com/latex.php?latex=%7By%5E%7BT%7DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y^{T}A}" class="latex" title="{y^{T}A}" />. Transposing the resulting vector gives <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7BT%7Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^{T}y}" class="latex" title="{A^{T}y}" /> in the required number of steps. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
I like this proof quite a bit. Can this argument be used to prove the basic fact about inverses of a matrix and its transpose? </p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2018/12/09/transposing/"><span class="datestr">at December 10, 2018 04:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/210">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/210">TR18-210 |  On Closest Pair in Euclidean Metric: Monochromatic is as Hard as Bichromatic | 

	Karthik  C. S., 

	Pasin Manurangsi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Given a set of $n$ points in $\mathbb R^d$, the (monochromatic) Closest Pair problem asks to find a pair of distinct points in the set that are closest in the $\ell_p$-metric. Closest Pair is a fundamental problem in Computational Geometry and understanding its fine-grained complexity in the Euclidean metric when $d=\omega(\log n)$ was raised as an open question in recent works (Abboud-Rubinstein-Williams [FOCS'17], Williams [SODA'18], David-Karthik-Laekhanukit [SoCG'18]).

In this paper, we show that for every $p\in\mathbb R_{\ge 1}\cup\{0\}$, under the Strong Exponential Time Hypothesis (SETH), for every  $\varepsilon>0$, the following holds:

$\bullet$  No algorithm running in time $O(n^{2-\varepsilon})$ can solve the Closest Pair problem in $d=(\log n)^{\Omega_{\varepsilon}(1)}$ dimensions in the $\ell_p$-metric.

$\bullet$  There exists $\delta = \delta(\varepsilon)>0$ and $c = c(\varepsilon)\ge 1$ such that no algorithm running in time $O(n^{1.5-\varepsilon})$ can approximate Closest Pair problem to a factor of $(1+\delta)$ in $d\ge c\log n$ dimensions in the $\ell_p$-metric.


In particular, our first result is shown by establishing the computational equivalence of the bichromatic Closest Pair problem and the (monochromatic) Closest Pair problem (up to $n^{\varepsilon}$ factor in the running time) for $d=(\log n)^{\Omega_\varepsilon(1)}$ dimensions.

Additionally, under SETH, we rule out nearly-polynomial  factor approximation algorithms  running in subquadratic time for the (monochromatic) Maximum Inner Product problem where we are given a set of $n$ points in $n^{o(1)}$-dimensional Euclidean space and are required to find a pair of distinct points in the set that maximize the inner product. 


At the heart of all our proofs is the construction of a dense bipartite graph with low contact dimension, i.e., we construct a balanced bipartite graph on $n$ vertices with $n^{2-\varepsilon}$ edges whose vertices can be realized as points in a $(\log n)^{\Omega_\varepsilon(1)}$-dimensional Euclidean space  such that every pair of vertices which have an edge in the graph are at distance exactly 1 and every other pair of vertices are at distance greater than 1. This graph construction is inspired by the construction of locally dense codes introduced by Dumer-Miccancio-Sudan [IEEE Trans. Inf. Theory'03].<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/210"><span class="datestr">at December 10, 2018 12:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://corner.mimuw.edu.pl/?p=1043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/banach.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://corner.mimuw.edu.pl/?p=1043">Do nominate talks for HALG 2019!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I hope the next year HALG will be an exciting event that will be very interesting for many of you. So if you think that some paper is worth to be included into the program please email halg2019.nominations@gmail.com your nomination as soon as possible. It would be cool to get many nominations so that setting up the program will be easy for us. </p></div>







<p class="date">
by sank <a href="http://corner.mimuw.edu.pl/?p=1043"><span class="datestr">at December 08, 2018 08:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/08/general-position-hypercube">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html">General-position hypercube projections</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I recently posted about finding solutions to the <a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">no-three-in-line problem</a> of finding large general-position subsets of grids, by <a href="https://11011110.github.io/blog/2018/11/10/random-no-three.html">using the probabilistic method</a> or by <a href="https://11011110.github.io/blog/2018/11/12/gurobi-vs-no.html">throwing an integer linear program solver at the problem</a>. Another potential method for finding solutions involves finding large general-position subsets in higher dimensions, where it’s easier (there’s more room to move the points out of the way of each other), and then projecting back down while being careful not to introduce any new collinearities.</p>

<p>A particularly nice family of general-position subsets is given by the hypercubes. The vertices of a -dimensional hypercube can be described as the points in -dimensional space all of whose coordinates are zeros and ones. There’s no way for three such points to lie on a line, because the middle of the three points would have to have fractional coordinates somewhere between the zero-one coordinates of the outer two points. So for the purposes of the no-three-in-line problem these points are in general position.</p>

<p>A projection of a hypercube onto the integer grid can be described (up to translations) by choosing  two-dimensional vectors and letting the projected points be all sums of subsets of these vectors. There are  subsets (including the empty subset and the subset of all vectors), and their sums give  points in the plane. It’s always possible to choose a -tuple of vectors that causes these  points to remain in general position, but the question is how small we can make these vectors in order to make the projection stay within a small grid.</p>

<p>For  the answer is that we can fit the points into a grid of size . This is optimal because any smaller grid would cause more than two points to lie on the same horizontal or vertical grid line.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/gen-pos-cubes.svg" alt="hypercubes of dimension 2, 3, and 4, projected in general position into optimally-small grid squares" /></p>

<p>The simplicity of the -dimensional projection ( points in an  grid with no three in line) makes me wonder whether this solution was the one Dudeney was trying to avoid in his <a href="https://archive.org/stream/amusementsinmath00dude#page/94/mode/2up">1917 statement of the problem</a>, when he added the extra condition that the solutions (described in terms of pawns on a chessboard) must include pawns at e4 and d5.</p>

<p>Unfortunately the -dimensional hypercube doesn’t have a general-position projection onto a  grid. The best <a href="https://11011110.github.io/blog/assets/2018/projcube.py">my search software</a> could find were several different  solutions. Here’s one of them:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/5cube-18x19.svg" alt="hypercube of dimension 5, projected in general position into an 18x19 grid" /></p>

<p>Beyond these specific examples, it would be interesting to obtain asymptotic bounds on how big a grid is needed for all hypercubes.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101208363611245952"></a>, <a href="https://plus.google.com/100003628603413742554/posts/iADVC9CsL1b">G+</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html"><span class="datestr">at December 08, 2018 04:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/209">TR18-209 |  AC0 unpredictability | 

	Emanuele Viola</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that for every distribution $D$ on $n$ bits with Shannon
entropy $\ge n-a$ at most $O(2^{d}a\log^{d+1}g)/\gamma{}^{5}$ of
the bits $D_{i}$ can be predicted with advantage $\gamma$ by an
AC$^{0}$ circuit of size $g$ and depth $d$ that is a function of
all the bits of $D$ except $D_{i}$. This answers a question by Meir
and Wigderson (2017) who proved a corresponding result for decision
trees.

We also show that there are distributions $D$ with entropy $\ge n-O(1)$
such that any subset of $O(n/\log n)$ bits of $D$ on can be distinguished
from uniform by a circuit of depth $2$ and size $\poly(n)$. This
separates the notions of predictability and distinguishability in
this context.<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/209"><span class="datestr">at December 08, 2018 12:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=6311">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2018/12/07/quantum-error-correction/">Peter Shor on Quantum Error Correction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[Guest post by Annie Wei who scribed Peter Shor’s lecture in our <a href="https://www.boazbarak.org/fall18seminar/">physics and computation seminar</a>. See <a href="https://windowsontheory.org/category/physics/">here</a> for all the posts of this seminar. –Boaz]</em></p>
<p>On October 19, we were lucky enough to have Professor Peter Shor give a guest lecture about quantum error correcting codes. In this blog post, I (Annie Wei) will present a summary of this guest lecture, which builds up quantum error correcting codes starting from classical coding theory. We will start by reviewing an example from classical error correction to motivate the similarities and differences when compared against the quantum case, before moving into quantum error correction and quantum channels. Note that we do assume a very basic familiarity with quantum mechanics, such as that which might be found <a href="https://people.eecs.berkeley.edu/~vazirani/f16quantum/lec1.pdf">here</a> or <a href="http://www.theory.caltech.edu/people/preskill/ph229/notes/chap2.pdf">here</a>.</p>
<p><strong>1. Motivation</strong><br />
We are interested in quantum error correction, ultimately, because any real-world computing device needs to be able to tolerate noise. Theoretical work on quantum algorithms has shown that quantum computers have the potential to offer speedups for a variety of problems, but in practice we’d also like to be able to eventually build and operate real quantum computers. We need to be able to protect against any decoherence that occurs when a quantum computer interacts with the environment, and we need to be able to protect against the accumulation of small gate errors since quantum gates need to be unitary operators.</p>
<p>In error correction the idea is to protect against noise by encoding information in a way that is resistant to noise, usually by adding some redundancy to the message. The redundancy then ensures that enough information remains, even after noise corruption, so that decoding will allow us to recover our original message. This is what is done in classical error correction schemes.</p>
<p>Unfortunately, it’s not obvious that quantum error correction is possible. One obstacle is that errors are continuous, since a continuum of operations can be applied to a qubit, so a priori it might seem like identifying and correcting an error would require infinite resources. In a later section we show how this problem, that of identifying quantum errors, can be overcome. Another obstacle is the fact that, as we’ve stated, classical error correction works by adding redundancy to a message. This might seem impossible to perform in a quantum setting due to the No Cloning Theorem, which states the following:</p>
<p><strong>Theorem</strong> (<em>No Cloning Theorem</em>): Performing the mapping</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle%7C0%5Crangle%5Cmapsto%7C%5Cpsi%5Crangle%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle|0\rangle\mapsto|\psi\rangle|\psi\rangle" class="latex" title="|\psi\rangle|0\rangle\mapsto|\psi\rangle|\psi\rangle" /></p>
<p>is not a permissible quantum operation.</p>
<p><strong>Proof</strong>: We will use unitarity, which says that a quantum operation specified by a unitary matrix <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> must satisfy</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7CU%5E%7B%5Cdagger%7DU%7C%5Cpsi%5Crangle+%3D+%5Clangle%5Cphi%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\phi|U^{\dagger}U|\psi\rangle = \langle\phi|\psi\rangle" class="latex" title="\langle\phi|U^{\dagger}U|\psi\rangle = \langle\phi|\psi\rangle" />.</p>
<p>(This ensures that the normalization of the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> is always preserved, i.e. that <img src="https://s0.wp.com/latex.php?latex=%7C%5Clangle%5Cpsi%7C%5Cpsi%5Crangle%7C%5E2%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\langle\psi|\psi\rangle|^2=1" class="latex" title="|\langle\psi|\psi\rangle|^2=1" />, which is equivalent to the conservation of probability.)</p>
<p>Now suppose that we can perform the operation</p>
<p><img src="https://s0.wp.com/latex.php?latex=U%28%7C%5Cpsi%5Crangle%7C0%5Crangle%29%3D%7C%5Cpsi%5Crangle%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(|\psi\rangle|0\rangle)=|\psi\rangle|\psi\rangle" class="latex" title="U(|\psi\rangle|0\rangle)=|\psi\rangle|\psi\rangle" />.</p>
<p>Then, letting</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Clangle%5Cphi%7C%5Clangle+0%7C%29%28%7C%5Cpsi%5Crangle%7C0%5Crangle%29%3D%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\langle\phi|\langle 0|)(|\psi\rangle|0\rangle)=\alpha" class="latex" title="(\langle\phi|\langle 0|)(|\psi\rangle|0\rangle)=\alpha" />,</p>
<p>we note that by unitarity</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Clangle%5Cphi%7C%5Clangle+0%7C%29%28%7C%5Cpsi%5Crangle+%7C0%5Crangle%29%3D%5Calpha%28%5Clangle%5Cphi%7C%5Clangle+0%7C%29U%5E%7B%5Cdagger%7DU%28%7C%5Cpsi%5Crangle%7C0%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\langle\phi|\langle 0|)(|\psi\rangle |0\rangle)=\alpha(\langle\phi|\langle 0|)U^{\dagger}U(|\psi\rangle|0\rangle)" class="latex" title="(\langle\phi|\langle 0|)(|\psi\rangle |0\rangle)=\alpha(\langle\phi|\langle 0|)U^{\dagger}U(|\psi\rangle|0\rangle)" />.</p>
<p>But</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Clangle%5Cphi%7C%5Clangle+0%7C%29U%5E%7B%5Cdagger%7DU%28%7C%5Cpsi%5Crangle%7C0%5Crangle%29%3D%28%5Clangle%5Cphi%7C%5Clangle%5Cphi%7C%29%28%7C%5Cpsi%5Crangle%7C%5Cpsi%5Crangle%29%3D%5Calpha%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\langle\phi|\langle 0|)U^{\dagger}U(|\psi\rangle|0\rangle)=(\langle\phi|\langle\phi|)(|\psi\rangle|\psi\rangle)=\alpha^2" class="latex" title="(\langle\phi|\langle 0|)U^{\dagger}U(|\psi\rangle|0\rangle)=(\langle\phi|\langle\phi|)(|\psi\rangle|\psi\rangle)=\alpha^2" />,</p>
<p>and in general <img src="https://s0.wp.com/latex.php?latex=%5Calpha%5Cneq%5Calpha%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha\neq\alpha^2" class="latex" title="\alpha\neq\alpha^2" />, so we have a contradiction.</p>
<p>How do we get around this apparent contradiction? To do so, note that the no-cloning theorem only prohibits the copying of non-orthogonal quantum states. With orthogonal quantum states, either <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha=0" class="latex" title="\alpha=0" /> or <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha=1" class="latex" title="\alpha=1" />, so we don’t run into a contradiction. This also explains why it is possible to copy classical information, which we can think of as orthogonal quantum states.</p>
<p>So how do we actually protect quantum information from noise? In the next section we first review classical error correction, as ideas from the classical setting re-appear in the quantum setting, and then we move into quantum error correction.</p>
<p><strong>2. Review of Classical Error Correction</strong><br />
First we start by reviewing classical error correction. In classical error correction we generally have a message that we encode, send through a noisy channel, and then decode, in the following schematic process:</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/fig1.png?w=600" alt="fig1.png" class="alignnone size-full wp-image-6312" /><br />
In an effective error correction scheme, the decoding process should allow us to identify any errors that occurred when our message passed through the noisy channel, which then tells us how to correct the errors. The formalism that allows us to do so is the following: we first define a <img src="https://s0.wp.com/latex.php?latex=r%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r\times n" class="latex" title="r\times n" /> encoding matrix <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> that takes a message <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> of length <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" /> and converts it to a codeword <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> of length <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, where the codewords make up the span of the rows of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. An example of such a matrix is</p>
<p><img src="https://s0.wp.com/latex.php?latex=G%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bccccccc%7D0%260%260%261%261%261%261%5C%5C1%260%261%260%261%260%261%5C%5C0%261%261%260%260%261%261%5C%5C1%261%261%261%261%261%261%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=\left(\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\\1&amp;1&amp;1&amp;1&amp;1&amp;1&amp;1\end{array}\right)" class="latex" title="G=\left(\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\\1&amp;1&amp;1&amp;1&amp;1&amp;1&amp;1\end{array}\right)" />,</p>
<p>corresponding to the 7-bit Hamming codes, which encodes a 4-bit message as a 7-bit codeword. Note that this code has distance 3 since each of the rows in <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> differ in at most 3 spots, which means that it can correct at most 1 error (the number of errors that can be corrected is given by half the code distance).</p>
<p>We also define the parity check matrix <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> to be the matrix that satisfies</p>
<p><img src="https://s0.wp.com/latex.php?latex=GH%5ET%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="GH^T=0" class="latex" title="GH^T=0" />.</p>
<p>For example, to define <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> corresponding to the <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> we defined for the 7-bit Hamming code, we could take</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bccccccc%7D0%260%260%261%261%261%261%5C%5C1%260%261%260%261%260%261%5C%5C0%261%261%260%260%261%261%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H=\left(\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\end{array}\right)" class="latex" title="H=\left(\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\end{array}\right)" />.</p>
<p>Then we may decode <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, a 7-bit string, in the following manner. Say that</p>
<p><img src="https://s0.wp.com/latex.php?latex=x%3Dc%2Be&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=c+e" class="latex" title="x=c+e" />,</p>
<p>where <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> is a codeword and <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" /> is the 1-bit error we wish to correct. Then</p>
<p><img src="https://s0.wp.com/latex.php?latex=xH%5ET%3D%28c%2Be%29H%5ET%3DeH%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="xH^T=(c+e)H^T=eH^T" class="latex" title="xH^T=(c+e)H^T=eH^T" />.</p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=eH%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="eH^T" class="latex" title="eH^T" /> uniquely identifies the error and is known as the <em>error syndrome</em>. Having it tells us how to correct the error. Thus our error correction scheme consists of the following steps:</p>
<ol>
<li>Encode a <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r" class="latex" title="r" />-bit message <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> by multiplying by <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> to obtain codeword <img src="https://s0.wp.com/latex.php?latex=mG%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="mG=c" class="latex" title="mG=c" />.</li>
<li>Send the message through channel generating error <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" />, resulting in the string <img src="https://s0.wp.com/latex.php?latex=x%3Dc%2Be&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=c+e" class="latex" title="x=c+e" />.</li>
<li>Multiply by <img src="https://s0.wp.com/latex.php?latex=H%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^T" class="latex" title="H^T" /> to obtain the <em>error syndrome</em> <img src="https://s0.wp.com/latex.php?latex=eH%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="eH^T" class="latex" title="eH^T" />.</li>
<li>Correct error <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" /> to obtain <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />.</li>
</ol>
<p>Having concluded our quick review of classical error correction, we now look at the theory of quantum error correction.</p>
<p><strong>3. Quantum Error Correction</strong><br />
In this section we introduce quantum error correction by directly constructing the 9-qubit code and the 7-qubit code. Then we introduce the more general formalism of CSS codes, which encompasses both the 9-qubit and 7-qubit codes, before introducing the stabilizer formalism, which tells us how we might construct a CSS code.</p>
<p><strong>3.1. Preliminaries</strong><br />
First we introduce some tools that we will need in this section.</p>
<p><strong>3.1.1. Pauli Matrices</strong><br />
The Pauli matrices are a set of 2-by-2 matrices that form an orthogonal basis for the 2-by-2 Hermitian matrices, where a Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> satisfies <img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cdagger%7D%3DH&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\dagger}=H" class="latex" title="H^{\dagger}=H" />. Note that we can form larger Hilbert spaces by taking the tensor product of smaller Hilbert spaces, so in particular taking the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-fold tensor product of Pauli matrices gives us a basis for the <img src="https://s0.wp.com/latex.php?latex=2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k" class="latex" title="2^k" />-by-<img src="https://s0.wp.com/latex.php?latex=2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^k" class="latex" title="2^k" /> Hermitian matrices. Note also that generally, in quantum mechanics, we are interested in Hermitian matrices because they can be used to represent measurements, and because unitary matrices, which can be used to represent probability-preserving quantum operations, can be obtained by exponentiating Hermitian matrices (that is, every unitary matrix <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> can be written in the form <img src="https://s0.wp.com/latex.php?latex=U%3De%5E%7BiH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U=e^{iH}" class="latex" title="U=e^{iH}" /> for <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> a Hermitian matrix).</p>
<p>The Pauli matrices are given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma_x%5Cequiv+X%5Cequiv%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D0%261%5C%5C1%260%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x\equiv X\equiv\left(\begin{array}{cc}0&amp;1\\1&amp;0\end{array}\right)" class="latex" title="\sigma_x\equiv X\equiv\left(\begin{array}{cc}0&amp;1\\1&amp;0\end{array}\right)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma_y%5Cequiv+Y%5Cequiv%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D0%26-i%5C%5Ci%260%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y\equiv Y\equiv\left(\begin{array}{cc}0&amp;-i\\i&amp;0\end{array}\right)" class="latex" title="\sigma_y\equiv Y\equiv\left(\begin{array}{cc}0&amp;-i\\i&amp;0\end{array}\right)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma_z%5Cequiv+Z%5Cequiv%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D1%260%5C%5C0%26-1%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z\equiv Z\equiv\left(\begin{array}{cc}1&amp;0\\0&amp;-1\end{array}\right)" class="latex" title="\sigma_z\equiv Z\equiv\left(\begin{array}{cc}1&amp;0\\0&amp;-1\end{array}\right)" />.</p>
<p>By direction computation we can show that they satisfy the relations</p>
<p><img src="https://s0.wp.com/latex.php?latex=X%5E2%3DY%5E2%3DZ%5E2%3DI&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X^2=Y^2=Z^2=I" class="latex" title="X^2=Y^2=Z^2=I" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=ZX%3D-XZ%3DiY&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="ZX=-XZ=iY" class="latex" title="ZX=-XZ=iY" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=YZ%3D-ZY%3DiX&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="YZ=-ZY=iX" class="latex" title="YZ=-ZY=iX" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=XY%3D-YX%3DiZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="XY=-YX=iZ" class="latex" title="XY=-YX=iZ" />.</p>
<p><strong>3.1.2. Von Neumann Measurements</strong><br />
We will also need the concept of a Von Neumann measurement. A Von Neumann measurement is given by a set of projection matrices <img src="https://s0.wp.com/latex.php?latex=%5C%7BE_1%2C+E_2%2C+...%2C+E_k%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{E_1, E_2, ..., E_k\}" class="latex" title="\{E_1, E_2, ..., E_k\}" /> satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5Ek+E_i%3DI&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{i=1}^k E_i=I" class="latex" title="\sum_{i=1}^k E_i=I" />.</p>
<p>That is, the projectors partition a Hilbert space <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\cal H}" class="latex" title="{\cal H}" /> into <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> subspaces. Then, given any state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle%5Cin%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle\in{\cal H}" class="latex" title="|\psi\rangle\in{\cal H}" />, when we perform a measurement using these projectors we obtain the measurement result corresponding to <img src="https://s0.wp.com/latex.php?latex=E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_i" class="latex" title="E_i" />, with corresponding post-measurement state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BE_i%7C%5Cpsi%5Crangle%7D%7B%7C%7CE_i%7C%5Cpsi%5Crangle%7C%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{E_i|\psi\rangle}{||E_i|\psi\rangle||}" class="latex" title="\frac{E_i|\psi\rangle}{||E_i|\psi\rangle||}" />,</p>
<p>with probability <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi%7CE_i%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\psi|E_i|\psi\rangle" class="latex" title="\langle\psi|E_i|\psi\rangle" />.</p>
<p><strong>3.2. First Attempt at a Quantum Code</strong><br />
Now we make a first attempt at coming up with a quantum code, noting that our efforts and adjustments will ultimately culminate in the 9-qubit code. Starting with the simplest possible idea, we take inspiration from the classical repetition code, which maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=0%5Cmapsto+000&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0\mapsto 000" class="latex" title="0\mapsto 000" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=1%5Cmapsto+111&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1\mapsto 111" class="latex" title="1\mapsto 111" /></p>
<p>and decodes by taking the majority of the 3 bits. We consider the quantum analog of this, which maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Cmapsto%7C000%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle\mapsto|000\rangle" class="latex" title="|0\rangle\mapsto|000\rangle" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle%5Cmapsto%7C111%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle\mapsto|111\rangle" class="latex" title="|1\rangle\mapsto|111\rangle" />.</p>
<p>We will take our quantum errors to be the Pauli matrices <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" />, <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" />, and <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" />. Then the encoding process, where our message is a quantum state <img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle%2B%5Cbeta%7C1%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle+\beta|1\rangle" class="latex" title="\alpha|0\rangle+\beta|1\rangle" />, looks like the following:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle%2B%5Cbeta%7C1%5Crangle%5Cmapsto%5Calpha%7C000%5Crangle%2B%5Cbeta%7C111%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|000\rangle+\beta|111\rangle" class="latex" title="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|000\rangle+\beta|111\rangle" />.</p>
<p>We claim that this code can correct bit errors but not phase errors, which makes it equivalent to the original classical repetition code for error correction. To see this, note that applying an <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> error results in the mapping</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle%2B%5Cbeta%7C1%5Crangle%5Cmapsto%5Calpha%7C100%5Crangle%2B%5Cbeta%7C011%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|100\rangle+\beta|011\rangle" class="latex" title="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|100\rangle+\beta|011\rangle" />.</p>
<p>This can be detected by the von Neumann measurement which projects onto the subspaces</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C000%5Crangle%2C%7C111%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|000\rangle,|111\rangle\}" class="latex" title="\{|000\rangle,|111\rangle\}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C011%5Crangle%2C%7C100%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|011\rangle,|100\rangle\}" class="latex" title="\{|011\rangle,|100\rangle\}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C010%5Crangle%2C%7C101%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|010\rangle,|101\rangle\}" class="latex" title="\{|010\rangle,|101\rangle\}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C110%5Crangle%2C%7C001%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|110\rangle,|001\rangle\}" class="latex" title="\{|110\rangle,|001\rangle\}" /></p>
<p>We could then apply <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x" class="latex" title="\sigma_x" /> to the first qubit to correct the error. To see that this doesn’t work for phase errors, note that applying a <img src="https://s0.wp.com/latex.php?latex=Z_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_2" class="latex" title="Z_2" /> error results in the mapping</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle%2B%5Cbeta%7C1%5Crangle%5Cmapsto%5Calpha%7C000%5Crangle-%5Cbeta%7C111%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|000\rangle-\beta|111\rangle" class="latex" title="\alpha|0\rangle+\beta|1\rangle\mapsto\alpha|000\rangle-\beta|111\rangle" />.</p>
<p>This is a valid encoding of the state <img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle-%5Cbeta%7C1%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle-\beta|1\rangle" class="latex" title="\alpha|0\rangle-\beta|1\rangle" />, so the error is undetectable.</p>
<p>What adjustments can we make so that we’re able to also correct <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z" class="latex" title="Z" /> errors? For this we will introduce the Hadamard matrix, defined as</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D1%261%5C%5C1%26-1%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}1&amp;1\\1&amp;-1\end{array}\right)" class="latex" title="H=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}1&amp;1\\1&amp;-1\end{array}\right)" /></p>
<p>and satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=HX%3DZH&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="HX=ZH" class="latex" title="HX=ZH" />.</p>
<p>Note in particular that, because <img src="https://s0.wp.com/latex.php?latex=HX%3DZH&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="HX=ZH" class="latex" title="HX=ZH" />, the Hadamard matrix turns bit errors into phase errors, and vice versa. This allows us to come up with a code that corrects phase errors by mapping</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%7C0%5Crangle%5Cmapsto+H%5E%7B%5Cotimes+3%7D%7C000%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H|0\rangle\mapsto H^{\otimes 3}|000\rangle" class="latex" title="H|0\rangle\mapsto H^{\otimes 3}|000\rangle" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=H%7C1%5Crangle%5Cmapsto+H%5E%7B%5Cotimes+3%7D%7C111%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H|1\rangle\mapsto H^{\otimes 3}|111\rangle" class="latex" title="H|1\rangle\mapsto H^{\otimes 3}|111\rangle" /></p>
<p>or equivalently,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Cmapsto%5Cfrac%7B1%7D%7B2%7D%28%7C000%5Crangle%2B%7C011%5Crangle%2B%7C101%5Crangle%2B%7C110%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle\mapsto\frac{1}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)" class="latex" title="|0\rangle\mapsto\frac{1}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle%5Cmapsto%5Cfrac%7B1%7D%7B2%7D%28%7C111%5Crangle%2B%7C100%5Crangle%2B%7C010%5Crangle%2B%7C001%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle\mapsto\frac{1}{2}(|111\rangle+|100\rangle+|010\rangle+|001\rangle)" class="latex" title="|1\rangle\mapsto\frac{1}{2}(|111\rangle+|100\rangle+|010\rangle+|001\rangle)" /></p>
<p>Now we can concatenate our bit flip code with our phase flip code to take care of both errors. This gives us the 9-qubit code, also known as the Shor code.</p>
<p><strong>3.3. 9-Qubit Code</strong><br />
In the previous section, we went through the process of constructing the 9-qubit Shor code by considering how to correct both bit flip errors and phase flip errors. Explicitly, the 9-qubit Shor code is given by the following mapping:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Cmapsto%7C0%5Crangle_L%5Cequiv%5Cfrac%7B1%7D%7B2%7D%28%7C000000000%5Crangle%2B%7C000111111%5Crangle%2B%7C111000111%5Crangle%2B%7C111111000%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle\mapsto|0\rangle_L\equiv\frac{1}{2}(|000000000\rangle+|000111111\rangle+|111000111\rangle+|111111000\rangle)" class="latex" title="|0\rangle\mapsto|0\rangle_L\equiv\frac{1}{2}(|000000000\rangle+|000111111\rangle+|111000111\rangle+|111111000\rangle)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle%5Cmapsto%7C1%5Crangle_L%5Cequiv%5Cfrac%7B1%7D%7B2%7D%28%7C111111111%5Crangle%2B%7C111000000%5Crangle%2B%7C000111000%5Crangle%2B%7C000000111%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle\mapsto|1\rangle_L\equiv\frac{1}{2}(|111111111\rangle+|111000000\rangle+|000111000\rangle+|000000111\rangle)" class="latex" title="|1\rangle\mapsto|1\rangle_L\equiv\frac{1}{2}(|111111111\rangle+|111000000\rangle+|000111000\rangle+|000000111\rangle)" />.</p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> and <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" /> are known as <em>logical qubits</em>; note that our 9-qubit code essentially represents 1 logical qubit with 9 physical qubits.</p>
<p>Note that by construction this code can correct <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x" class="latex" title="\sigma_x" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y" class="latex" title="\sigma_y" />, and <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z" class="latex" title="\sigma_z" /> errors on any one qubit (we’ve already shown by construction that it can correct <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x" class="latex" title="\sigma_x" /> and <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z" class="latex" title="\sigma_z" /> errors, and <img src="https://s0.wp.com/latex.php?latex=%5Csigma_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y" class="latex" title="\sigma_y" /> can be obtained as a product of the two). This is also equivalent to the statement that the states <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x%5E%7B%28i%29%7D%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x^{(i)}|0\rangle_L" class="latex" title="\sigma_x^{(i)}|0\rangle_L" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_y%5E%7B%28i%29%7D%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y^{(i)}|0\rangle_L" class="latex" title="\sigma_y^{(i)}|0\rangle_L" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z%5E%7B%28i%29%7D%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z^{(i)}|0\rangle_L" class="latex" title="\sigma_z^{(i)}|0\rangle_L" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x%5E%7B%28i%29%7D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x^{(i)}|1\rangle_L" class="latex" title="\sigma_x^{(i)}|1\rangle_L" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_y%5E%7B%28i%29%7D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y^{(i)}|1\rangle_L" class="latex" title="\sigma_y^{(i)}|1\rangle_L" />, and <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z%5E%7B%28i%29%7D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z^{(i)}|1\rangle_L" class="latex" title="\sigma_z^{(i)}|1\rangle_L" /> are all orthogonal.</p>
<p>Now we have a 1-error quantum code. We claim that such a code can in fact correct any error operation, and that this is a property of all 1-error quantum codes:</p>
<p><strong>Theorem: </strong>Given any possible unitary, measurement, or quantum operation on a one-error quantum code, the code can correct it.</p>
<p><strong>Proof: </strong><img src="https://s0.wp.com/latex.php?latex=%5C%7BI%2C+%5Csigma_x%2C+%5Csigma_y%2C+%5Csigma_z%5C%7D%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" class="latex" title="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" /> forms a basis for the <img src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\times 2" class="latex" title="2\times 2" /> matrices. For errors on <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> qubits, the code can correct these errors if it can individually correct errors <img src="https://s0.wp.com/latex.php?latex=%5Csigma_%7Bw_i%7D%5E%7B%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_{w_i}^{(i)}" class="latex" title="\sigma_{w_i}^{(i)}" /> for <img src="https://s0.wp.com/latex.php?latex=w_i%5Cin%5C%7Bx%2Cy%2Cz%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_i\in\{x,y,z\}" class="latex" title="w_i\in\{x,y,z\}" />, <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5C%7B1%2C...%2Ct%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\in\{1,...,t\}" class="latex" title="i\in\{1,...,t\}" />, since <img src="https://s0.wp.com/latex.php?latex=%5C%7BI%2C+%5Csigma_x%2C+%5Csigma_y%2C+%5Csigma_z%5C%7D%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" class="latex" title="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" /> forms a basis for <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5E%7B2t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{C}^{2t}" class="latex" title="\mathbb{C}^{2t}" />.</p>
<p><strong>Example: Phase Error</strong> Next we’ll do an example where we consider how we might correct an arbitrary phase error applied to the <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> state. Since quantum states are equivalent up to phases, the error operator is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D1%260%5C%5C0%26e%5E%7Bi%5Ctheta%7D%5Cend%7Barray%7D%5Cright%29%5Cequiv%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7De%5E%7B-i%5Ctheta%2F2%7D%260%5C%5C0%26e%5E%7Bi%5Ctheta%2F2%7D%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left(\begin{array}{cc}1&amp;0\\0&amp;e^{i\theta}\end{array}\right)\equiv\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)" class="latex" title="\left(\begin{array}{cc}1&amp;0\\0&amp;e^{i\theta}\end{array}\right)\equiv\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)" />.</p>
<p>Note that this can be rewritten in the <img src="https://s0.wp.com/latex.php?latex=%5C%7BI%2C+%5Csigma_x%2C+%5Csigma_y%2C+%5Csigma_z%5C%7D%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" class="latex" title="\{I, \sigma_x, \sigma_y, \sigma_z\}^{\otimes t}" /> basis as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7De%5E%7B-i%5Ctheta%2F2%7D%260%5C%5C0%26e%5E%7Bi%5Ctheta%2F2%7D%5Cend%7Barray%7D%5Cright%29%3D%5Ccos%5Cfrac%7B%5Ctheta%7D%7B2%7DI-i%5Csin%5Cfrac%7B%5Ctheta%7D%7B2%7D%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)=\cos\frac{\theta}{2}I-i\sin\frac{\theta}{2}\sigma_z" class="latex" title="\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)=\cos\frac{\theta}{2}I-i\sin\frac{\theta}{2}\sigma_z" />.</p>
<p>Now, applying this error to <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" />, we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7De%5E%7B-i%5Ctheta%2F2%7D%260%5C%5C0%26e%5E%7Bi%5Ctheta%2F2%7D%5Cend%7Barray%7D%5Cright%29%5Cfrac%7B1%7D%7B2%7D%28%7C000%5Crangle%2B%7C011%5Crangle%2B%7C101%5Crangle%2B%7C110%5Crangle%29%3D%5Cfrac%7B1%7D%7B2%7D%5Ccos%5Cfrac%7B%5Ctheta%7D%7B2%7D%28%7C000%5Crangle%2B%7C011%5Crangle%2B%7C101%5Crangle%2B%7C110%5Crangle%29-%5Cfrac%7Bi%7D%7B2%7D%5Csin%5Cfrac%7B%5Ctheta%7D%7B2%7D%28%7C000%5Crangle-%7C011%5Crangle%2B%7C101%5Crangle-%7C110%5Crangle%29%3D%5Ccos%5Cfrac%7B%5Ctheta%7D%7B2%7D%7C0%5Crangle_L-i%5Csin%5Cfrac%7B%5Ctheta%7D%7B2%7D%5Csigma_z%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)\frac{1}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)=\frac{1}{2}\cos\frac{\theta}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)-\frac{i}{2}\sin\frac{\theta}{2}(|000\rangle-|011\rangle+|101\rangle-|110\rangle)=\cos\frac{\theta}{2}|0\rangle_L-i\sin\frac{\theta}{2}\sigma_z|0\rangle_L" class="latex" title="\left(\begin{array}{cc}e^{-i\theta/2}&amp;0\\0&amp;e^{i\theta/2}\end{array}\right)\frac{1}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)=\frac{1}{2}\cos\frac{\theta}{2}(|000\rangle+|011\rangle+|101\rangle+|110\rangle)-\frac{i}{2}\sin\frac{\theta}{2}(|000\rangle-|011\rangle+|101\rangle-|110\rangle)=\cos\frac{\theta}{2}|0\rangle_L-i\sin\frac{\theta}{2}\sigma_z|0\rangle_L" />.</p>
<p>After performing a projective measurement, we get state <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Ccos%5E2%5Cfrac%7B%5Ctheta%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cos^2\frac{\theta}{2}" class="latex" title="\cos^2\frac{\theta}{2}" />, in which case we do not need to perform any error correction, and we get <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z|0\rangle_L" class="latex" title="\sigma_z|0\rangle_L" /> with probability <img src="https://s0.wp.com/latex.php?latex=%5Csin%5E2%5Cfrac%7B%5Ctheta%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sin^2\frac{\theta}{2}" class="latex" title="\sin^2\frac{\theta}{2}" />, in which case we would know to correct the <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z" class="latex" title="\sigma_z" /> error.</p>
<p><strong>3.4. 7-Qubit Code</strong><br />
Now that we’ve constructed the 9-qubit code and shown that quantum error correction is possible, we might wonder whether it’s possible to do better. For example, we’d like a code that requires fewer qubits. We’ll construct a 7-qubit code that corrects 1 error, defining a mapping to <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> and <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" /> by taking inspiration from a classical code, as we did for the 9-qubit case.</p>
<p>For this we will need to go back to the example we used to illustration classical error correction. Recall that in classical error correction, we have an encoding matrix <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> and a parity check matrix <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> satisfying <img src="https://s0.wp.com/latex.php?latex=GH%5ET%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="GH^T=0" class="latex" title="GH^T=0" />, with <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7Brank%7D%28G%29%2B%5Ctext%7Brank%7D%28H%29%3Dn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{rank}(G)+\text{rank}(H)=n" class="latex" title="\text{rank}(G)+\text{rank}(H)=n" />. We encode a message <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> to obtain codeword <img src="https://s0.wp.com/latex.php?latex=mG%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="mG=c" class="latex" title="mG=c" />. After error <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" /> is applied, this becomes <img src="https://s0.wp.com/latex.php?latex=c%2Be&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c+e" class="latex" title="c+e" />, from which we can extract the error syndrome <img src="https://s0.wp.com/latex.php?latex=%28c%2Be%29H%5ET%3DeH%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(c+e)H^T=eH^T" class="latex" title="(c+e)H^T=eH^T" />. We can then apply the appropriate correction to extract <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> from <img src="https://s0.wp.com/latex.php?latex=c%2Be&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c+e" class="latex" title="c+e" />.</p>
<p>Now we will use the encoding matrix from our classical error correction example, and we will divide our codewords into two sets, <img src="https://s0.wp.com/latex.php?latex=C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1" class="latex" title="C_1" /> and <img src="https://s0.wp.com/latex.php?latex=C_1%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1'" class="latex" title="C_1'" />, given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=C_1%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bccccccc%7D0%260%260%261%261%261%261%5C%5C1%260%261%260%261%260%261%5C%5C0%261%261%260%260%261%261%5Cend%7Barray%7D%5Cright.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1=\left\{\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\end{array}\right." class="latex" title="C_1=\left\{\begin{array}{ccccccc}0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1\\0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1\end{array}\right." /></p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=C_1%27%3DC_1%2B1111111&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1'=C_1+1111111" class="latex" title="C_1'=C_1+1111111" />.</p>
<p>Similar to how we approached the 9-qubit case, we will start by defining our code as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L%5Cequiv%5Cfrac%7B1%7D%7B%5Csqrt%7B8%7D%7D%5Csum_%7Bv%5Cin+C_1%7D%7Cv%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L\equiv\frac{1}{\sqrt{8}}\sum_{v\in C_1}|v\rangle" class="latex" title="|0\rangle_L\equiv\frac{1}{\sqrt{8}}\sum_{v\in C_1}|v\rangle" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L%5Cequiv%5Cfrac%7B1%7D%7B%5Csqrt%7B8%7D%7D%5Csum_%7Bw%5Cin+C_1%27%7D%7Cw%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L\equiv\frac{1}{\sqrt{8}}\sum_{w\in C_1'}|w\rangle" class="latex" title="|1\rangle_L\equiv\frac{1}{\sqrt{8}}\sum_{w\in C_1'}|w\rangle" />.</p>
<p>Note that this corrects bit flip errors by construction. How can we ensure that we are also able to correct phase errors? For this we again turn to the Hadamard matrix, which allows us to toggle between bit and phase errors. We claim that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7C0%5Crangle_L%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C0%5Crangle_L%2B%7C1%5Crangle_L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L+|1\rangle_L)" class="latex" title="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L+|1\rangle_L)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7C1%5Crangle_L%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C0%5Crangle_L-%7C1%5Crangle_L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|1\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L-|1\rangle_L)" class="latex" title="H^{\otimes 7}|1\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L-|1\rangle_L)" />.</p>
<p><strong>Proof: </strong>We will show that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7C0%5Crangle_L%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C0%5Crangle_L%2B%7C1%5Crangle_L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L+|1\rangle_L)" class="latex" title="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}(|0\rangle_L+|1\rangle_L)" />,</p>
<p>noting that the argument for <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" /> is similar. First we will need the fact that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7Cv%5Crangle%3D%5Cfrac%7B1%7D%7B2%5E%7B7%2F2%7D%7D%5Csum_%7Bw%5Cin%5C%7B0%2C1%5C%7D%5E7%7D%28-1%29%5E%7Bw%5Ccdot+v%7D%7Cw%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|v\rangle=\frac{1}{2^{7/2}}\sum_{w\in\{0,1\}^7}(-1)^{w\cdot v}|w\rangle" class="latex" title="H^{\otimes 7}|v\rangle=\frac{1}{2^{7/2}}\sum_{w\in\{0,1\}^7}(-1)^{w\cdot v}|w\rangle" />.</p>
<p>To see that this fact is true, note that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C0%5Crangle%5Clangle+0%7C%2B%7C0%5Crangle%5Clangle+1%7C%2B%7C1%5Crangle%5Clangle+0%7C-%7C1%5Crangle%5Clangle+1%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H=\frac{1}{\sqrt{2}}(|0\rangle\langle 0|+|0\rangle\langle 1|+|1\rangle\langle 0|-|1\rangle\langle 1|)" class="latex" title="H=\frac{1}{\sqrt{2}}(|0\rangle\langle 0|+|0\rangle\langle 1|+|1\rangle\langle 0|-|1\rangle\langle 1|)" /></p>
<p>and that <img src="https://s0.wp.com/latex.php?latex=w%5Ccdot+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\cdot v" class="latex" title="w\cdot v" /> is equal to the number of bits in which <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w" class="latex" title="w" /> and <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" /> are both 1. Now we can start by directly calculating</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7C0%5Crangle_L%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B8%7D%7D%5Cfrac%7B1%7D%7B%5Csqrt%7B128%7D%7D%5Csum_%7Bv%5Cin+C_1%7D%5Csum_%7Bw%5Cin%5C%7B0%2C1%5C%7D%5E7%7D%28-1%29%5E%7Bv%5Ccdot+w%7D%7Cw%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{8}}\frac{1}{\sqrt{128}}\sum_{v\in C_1}\sum_{w\in\{0,1\}^7}(-1)^{v\cdot w}|w\rangle" class="latex" title="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{8}}\frac{1}{\sqrt{128}}\sum_{v\in C_1}\sum_{w\in\{0,1\}^7}(-1)^{v\cdot w}|w\rangle" />.</p>
<p>Note that for <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> two codewords, assuming that <img src="https://s0.wp.com/latex.php?latex=w%5Ccdot+y%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\cdot y=1" class="latex" title="w\cdot y=1" />, we must have that <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+w%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot w=0" class="latex" title="x\cdot w=0" /> iff <img src="https://s0.wp.com/latex.php?latex=%28x%2By%29%5Ccdot+w%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x+y)\cdot w=1" class="latex" title="(x+y)\cdot w=1" />. Thus we can break the codespace up into an equal number of codewords <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> satisfying <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+w%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot w=0" class="latex" title="x\cdot w=0" /> and <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+w%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot w=1" class="latex" title="x\cdot w=1" />. This means that we must have that the sum <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bv%5Cin+C_1%7D%5Csum_%7Bw%5Cin%5C%7B0%2C1%5C%7D%5E7%7D%28-1%29%5E%7Bw%5Ccdot+v%7D%7Cw%5Crangle%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{v\in C_1}\sum_{w\in\{0,1\}^7}(-1)^{w\cdot v}|w\rangle=0" class="latex" title="\sum_{v\in C_1}\sum_{w\in\{0,1\}^7}(-1)^{w\cdot v}|w\rangle=0" /> unless we have <img src="https://s0.wp.com/latex.php?latex=w%5Cperp+C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\perp C_1" class="latex" title="w\perp C_1" />. But those <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w" class="latex" title="w" /> that satisfy <img src="https://s0.wp.com/latex.php?latex=w%5Cperp+C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\perp C_1" class="latex" title="w\perp C_1" /> are exactly all the codewords by definition, so we must have that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5E%7B%5Cotimes+7%7D%7C0%5Crangle_L%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%7C0%5Crangle_L%2B%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}|0\rangle_L+\frac{1}{\sqrt{2}}|1\rangle_L" class="latex" title="H^{\otimes 7}|0\rangle_L=\frac{1}{\sqrt{2}}|0\rangle_L+\frac{1}{\sqrt{2}}|1\rangle_L" /></p>
<p>as the sum in <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L%2B%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L+|1\rangle_L" class="latex" title="|0\rangle_L+|1\rangle_L" /> runs equally over all codewords.</p>
<p>Thus we have constructed a 7-qubit quantum code that corrects 1 error, and moreover we see that for both the 9-qubit and 7-qubit codes, both of which are 1-error quantum codes, the fact that they can correct 1-error comes directly from the fact that the original classical codes we used to construct them can themselves correct 1 error. This suggests that we should be able to come up with a more general procedure for constructing quantum codes from classical codes.</p>
<p><strong>3.5. CSS Codes</strong><br />
<em>CSS (Calderbank-Shor-Steane) codes</em> generalize the process by which we constructed the 9-qubit and 7-qubit codes, and they give us a general framework for constructing quantum codes from classical codes. In a CSS code, we require groups <img src="https://s0.wp.com/latex.php?latex=C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1" class="latex" title="C_1" />, <img src="https://s0.wp.com/latex.php?latex=C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2" class="latex" title="C_2" /> satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=%C2%A0C_1%5Csubseteq+C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt=" C_1\subseteq C_2" class="latex" title=" C_1\subseteq C_2" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=C_2%5E%7B%5Cperp%7D%5Csubseteq+C_1%5E%7B%5Cperp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2^{\perp}\subseteq C_1^{\perp}" class="latex" title="C_2^{\perp}\subseteq C_1^{\perp}" /></p>
<p>Then we can define codewords to correspond to cosets of <img src="https://s0.wp.com/latex.php?latex=C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1" class="latex" title="C_1" /> in <img src="https://s0.wp.com/latex.php?latex=C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2" class="latex" title="C_2" />, so that the number of codewords is equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Ctext%7Bdim%7D%28C_2%29-%5Ctext%7Bdim%7D%28C_1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{\text{dim}(C_2)-\text{dim}(C_1)}" class="latex" title="2^{\text{dim}(C_2)-\text{dim}(C_1)}" />. Thus by this definition we can say that codewords <img src="https://s0.wp.com/latex.php?latex=w_1%2C+w_2%5Cin+C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_1, w_2\in C_2" class="latex" title="w_1, w_2\in C_2" /> are in the same coset if <img src="https://s0.wp.com/latex.php?latex=w_1-w_2%5Cin+C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w_1-w_2\in C_1" class="latex" title="w_1-w_2\in C_1" />. Explicitly, the codeword for coset <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w" class="latex" title="w" /> is given by the state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%7CC_1%7C%5E%7B1%2F2%7D%7D%5Csum_%7Bx%5Cin+C_1%7D%7Cx%2Bw%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{|C_1|^{1/2}}\sum_{x\in C_1}|x+w\rangle" class="latex" title="\frac{1}{|C_1|^{1/2}}\sum_{x\in C_1}|x+w\rangle" />,</p>
<p>and under the Hadamard transformation applied to each qubit this state is in turn mapped to the state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%7CC_1%5E%7B%5Cperp%7D%7C%5E%7B1%2F2%7D%7D%5Csum_%7Bx%5Cin+C_1%5E%7B%5Cperp%7D%7D%7Cx%2Bw%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{|C_1^{\perp}|^{1/2}}\sum_{x\in C_1^{\perp}}|x+w\rangle" class="latex" title="\frac{1}{|C_1^{\perp}|^{1/2}}\sum_{x\in C_1^{\perp}}|x+w\rangle" />.</p>
<p>That is to say, the Hadamard “dualizes” our original code, toggling bit errors to phase errors and vice versa. (This can be seen by direct calculation, as in the case of the 7-qubit code, where we used the fact that <img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bv%5Cin+C_1%7D%28-1%29%5E%7Bv%5Ccdot+w%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{v\in C_1}(-1)^{v\cdot w}=0" class="latex" title="\sum_{v\in C_1}(-1)^{v\cdot w}=0" /> for <img src="https://s0.wp.com/latex.php?latex=w%5Cnot%5Cin+C_1%5E%7B%5Cperp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\not\in C_1^{\perp}" class="latex" title="w\not\in C_1^{\perp}" />.)</p>
<p>Note also that this code can correct a number of bit errors equal to the minimum weight of <img src="https://s0.wp.com/latex.php?latex=%5C%7Bv%5Cin+C_2-C_1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{v\in C_2-C_1\}" class="latex" title="\{v\in C_2-C_1\}" />.</p>
<p>With the CSS construction we have thus reduced the problem of finding a quantum error correcting code to the problem of finding appropriate <img src="https://s0.wp.com/latex.php?latex=C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1" class="latex" title="C_1" />, <img src="https://s0.wp.com/latex.php?latex=C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2" class="latex" title="C_2" />. Note that the special case of <img src="https://s0.wp.com/latex.php?latex=C_2%5E%7B%5Cperp%7D%3DC_1%3DC&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2^{\perp}=C_1=C" class="latex" title="C_2^{\perp}=C_1=C" /> corresponds to weakly self-dual codes, which are well studied classically. Doubly even, weakly self-dual codes additionally have the requirement that all codewords have Hamming weights that are multiples of 4; they satisfy the requirement</p>
<p><img src="https://s0.wp.com/latex.php?latex=1%5En%5Csubseteq+C%5E%7B%5Cperp%7D%5Csubseteq+C%5Csubseteq%5Cmathbb%7BZ%7D_2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1^n\subseteq C^{\perp}\subseteq C\subseteq\mathbb{Z}_2^n" class="latex" title="1^n\subseteq C^{\perp}\subseteq C\subseteq\mathbb{Z}_2^n" /></p>
<p>and are also well studied classically.</p>
<p><strong>3.6. Gilbert-Varshamov Bound</strong><br />
In the previous section we introduced CSS codes and demonstrated that the problem of constructing a quantum code could be reduced to the problem of finding two groups <img src="https://s0.wp.com/latex.php?latex=C_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1" class="latex" title="C_1" />, <img src="https://s0.wp.com/latex.php?latex=C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2" class="latex" title="C_2" /> satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=C_1%5Csubseteq+C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1\subseteq C_2" class="latex" title="C_1\subseteq C_2" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=C_2%5E%7B%5Cperp%7D%5Csubseteq+C_1%5E%7B%5Cperp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2^{\perp}\subseteq C_1^{\perp}" class="latex" title="C_2^{\perp}\subseteq C_1^{\perp}" />.</p>
<p>The next natural question is to ask whether such groups can in fact be found.</p>
<p>The Gilbert-Varshamov bound answers this question in the affirmative, ensuring that there do exist good CSS codes (the bound applies to both quantum and classical codes). It can be stated in the following way:</p>
<p><strong>Theorem </strong>(<em>Gilbert-Varshamov Bound</em>): There exist CSS codes with rate <img src="https://s0.wp.com/latex.php?latex=R%3D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R=" class="latex" title="R=" />(number of encoded bits)/(length of code) given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=R%5Cgeq+1-2H_2%28d%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R\geq 1-2H_2(d/n)" class="latex" title="R\geq 1-2H_2(d/n)" />,</p>
<p>where <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> is the minimum distance of the code, <img src="https://s0.wp.com/latex.php?latex=d%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d/2" class="latex" title="d/2" /> is the number of errors it can correct, and <img src="https://s0.wp.com/latex.php?latex=H_2%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_2(x)" class="latex" title="H_2(x)" /> is the Shannon entropy, defined as</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_2%28x%29%3D-x%5Clog_2x-%281-x%29%5Clog_2%281-x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_2(x)=-x\log_2x-(1-x)\log_2(1-x)" class="latex" title="H_2(x)=-x\log_2x-(1-x)\log_2(1-x)" />.</p>
<p><strong>Proof:</strong> Note that we can always take a code, apply a random linear transformation to it, and get another code. Thus each vector is equally likely to appear in a random code. Given this fact, we can estimate the probability that a code of dimension <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> contains a word of weight <img src="https://s0.wp.com/latex.php?latex=%5Cleq+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\leq d" class="latex" title="\leq d" /> using the union bound:</p>
<p><img src="https://s0.wp.com/latex.php?latex=P%28&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(" class="latex" title="P(" />code of dimension <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> has word of weight <img src="https://s0.wp.com/latex.php?latex=%5Cleq+d%29%5Cleq%28&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\leq d)\leq(" class="latex" title="\leq d)\leq(" />number of words<img src="https://s0.wp.com/latex.php?latex=%29%5Ctimes+P%28&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt=")\times P(" class="latex" title=")\times P(" />word has weight <img src="https://s0.wp.com/latex.php?latex=%5Cleq+d%29%3D2%5Ek%5Ccdot%5Cfrac%7B%5Csum_%7Bi%3D0%7D%5Ed+%5Cbinom%7Bn%7D%7Bi%7D%7D%7B2%5En%7D%5Capprox+%5Cfrac%7B2%5Ek%5Ccdot+2%5E%7BnH%28d%2Fn%29%7D%7D%7B2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\leq d)=2^k\cdot\frac{\sum_{i=0}^d \binom{n}{i}}{2^n}\approx \frac{2^k\cdot 2^{nH(d/n)}}{2^n}" class="latex" title="\leq d)=2^k\cdot\frac{\sum_{i=0}^d \binom{n}{i}}{2^n}\approx \frac{2^k\cdot 2^{nH(d/n)}}{2^n}" /></p>
<p>For this to be a valid probability we need to have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28k%2Fn%29%2BH%28d%2Fn%29%3C+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(k/n)+H(d/n)&lt; 1" class="latex" title="(k/n)+H(d/n)&lt; 1" />.</p>
<p>We can calculate rate by noting that for a CSS code, given by <img src="https://s0.wp.com/latex.php?latex=C_1%5Csubseteq+C_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1\subseteq C_2" class="latex" title="C_1\subseteq C_2" />, <img src="https://s0.wp.com/latex.php?latex=C_2%5E%7B%5Cperp%7D%5Csubseteq+C_1%5E%7B%5Cperp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_2^{\perp}\subseteq C_1^{\perp}" class="latex" title="C_2^{\perp}\subseteq C_1^{\perp}" />, with <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bdim%7D%28C_1%29%3Dn-k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{dim}(C_1)=n-k" class="latex" title="\text{dim}(C_1)=n-k" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bdim%7D%28C_2%29%3Dk&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{dim}(C_2)=k" class="latex" title="\text{dim}(C_2)=k" />, the expression for rate is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=R%3D%5Cfrac%7Bn-2k%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R=\frac{n-2k}{n}" class="latex" title="R=\frac{n-2k}{n}" />.</p>
<p>Combining this with the bound we obtained by considering probabilities, we get that</p>
<p><img src="https://s0.wp.com/latex.php?latex=R%5Cgeq+1-2H%28d%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R\geq 1-2H(d/n)" class="latex" title="R\geq 1-2H(d/n)" />.</p>
<p>Thus there exist good CSS codes.</p>
<p><strong>3.7. Stabilizer Codes</strong><br />
Having discussed and constructed some examples of CSS codes, we will now discuss the stabilizer formalism. Note that this formalism allows us to construct codes without having to work directly with the states representing <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> and <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" />, as this can quickly get unwieldy. Instead, we will work with stabilizers, operators that leave these states invariant.</p>
<p>To see how working directly with states can get unwieldy, we can consider the 5-qubit code. We can define it the way we defined the 9-qubit and 7-qubit codes, by directly defining the basis vectors <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> and <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" />,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L%5Cequiv%5Cfrac%7B1%7D%7B4%7D%28%7C00000%5Crangle-%7C01100%5Crangle%2B%7C00101%5Crangle%2B%7C01010%5Crangle-%7C01111%5Crangle%2B%28&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L\equiv\frac{1}{4}(|00000\rangle-|01100\rangle+|00101\rangle+|01010\rangle-|01111\rangle+(" class="latex" title="|0\rangle_L\equiv\frac{1}{4}(|00000\rangle-|01100\rangle+|00101\rangle+|01010\rangle-|01111\rangle+(" />symmetric under cyclic permutations<img src="https://s0.wp.com/latex.php?latex=%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="))" class="latex" title="))" />,</p>
<p>with <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" /> defined similarly. But we can also define this code more succinctly using the stabilizer formalism. To do so, we start by choosing a commutative subgroup of the Pauli group, with generators <img src="https://s0.wp.com/latex.php?latex=g_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_i" class="latex" title="g_i" /> satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=g_i%5E2%3DI&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_i^2=I" class="latex" title="g_i^2=I" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=g_ig_j%3Dg_jg_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_ig_j=g_jg_i" class="latex" title="g_ig_j=g_jg_i" /></p>
<p>For example, for the 5-qubit code, the particular choice of generators we would need is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=g_1%5Cequiv+IXZZX&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1\equiv IXZZX" class="latex" title="g_1\equiv IXZZX" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=g_2%5Cequiv+XIXZZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_2\equiv XIXZZ" class="latex" title="g_2\equiv XIXZZ" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=g_3%5Cequiv+ZXIXZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_3\equiv ZXIXZ" class="latex" title="g_3\equiv ZXIXZ" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=g_4%5Cequiv+ZZXIX&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_4\equiv ZZXIX" class="latex" title="g_4\equiv ZZXIX" />.</p>
<p>Now we consider states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi\rangle\}" class="latex" title="\{|\psi\rangle\}" /> that are stabilized by the <img src="https://s0.wp.com/latex.php?latex=%5C%7Bg_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{g_i\}" class="latex" title="\{g_i\}" />. That is, they satisfy</p>
<p><img src="https://s0.wp.com/latex.php?latex=g_i%7C%5Cpsi%5Crangle%3D%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_i|\psi\rangle=|\psi\rangle" class="latex" title="g_i|\psi\rangle=|\psi\rangle" />.</p>
<p>Note that the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=%5Csigma_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x" class="latex" title="\sigma_x" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_y" class="latex" title="\sigma_y" />, and <img src="https://s0.wp.com/latex.php?latex=%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_z" class="latex" title="\sigma_z" /> are <img src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pm 1" class="latex" title="\pm 1" />, so in the case of the 5-qubit code, there exists a <img src="https://s0.wp.com/latex.php?latex=2%5E5%2F2%3D16&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^5/2=16" class="latex" title="2^5/2=16" />-dimensional space of <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi\rangle\}" class="latex" title="\{|\psi\rangle\}" /> satisfying <img src="https://s0.wp.com/latex.php?latex=g_1%7C%5Cpsi%5Crangle%3D%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1|\psi\rangle=|\psi\rangle" class="latex" title="g_1|\psi\rangle=|\psi\rangle" />. Recalling that two commuting matrices are simultaneously diagonalizable, there exists a <img src="https://s0.wp.com/latex.php?latex=16%2F2%3D8&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="16/2=8" class="latex" title="16/2=8" />-dimensional space of <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi\rangle\}" class="latex" title="\{|\psi\rangle\}" /> satisfying <img src="https://s0.wp.com/latex.php?latex=g_1%7C%5Cpsi%5Crangle%3Dg_2%7C%5Cpsi%5Crangle%3D%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1|\psi\rangle=g_2|\psi\rangle=|\psi\rangle" class="latex" title="g_1|\psi\rangle=g_2|\psi\rangle=|\psi\rangle" />, and so on, where we cut the dimension of the subspace in half each time we add a generator. Finally, there exists a <img src="https://s0.wp.com/latex.php?latex=2%5E5%2F2%5E4%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^5/2^4=2" class="latex" title="2^5/2^4=2" />-dimensional space of <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi\rangle\}" class="latex" title="\{|\psi\rangle\}" /> satisfying <img src="https://s0.wp.com/latex.php?latex=g_i%7C%5Cpsi%5Crangle%3D%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_i|\psi\rangle=|\psi\rangle" class="latex" title="g_i|\psi\rangle=|\psi\rangle" /> for all <img src="https://s0.wp.com/latex.php?latex=i%3D1%2C...%2C4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i=1,...,4" class="latex" title="i=1,...,4" />. This 2-dimensional space is exactly the subspace spanned by <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> and <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle_L" class="latex" title="|1\rangle_L" />. Thus fixing the stabilizers is enough to give us our code.</p>
<p>Next we will consider all elements in the Pauli group that commute with all elements in our stabilizer group <img src="https://s0.wp.com/latex.php?latex=G%3D%5C%7Bg_1%2C...%2Cg_4%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=\{g_1,...,g_4\}" class="latex" title="G=\{g_1,...,g_4\}" />. As we shall see, this will give us our logical operators, where a <em>logical operator</em> performs an operation on a logical qubit (for example, the logical <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> operator, <img src="https://s0.wp.com/latex.php?latex=X_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_L" class="latex" title="X_L" />, would act on the logical qubit <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle_L" class="latex" title="|0\rangle_L" /> by mapping <img src="https://s0.wp.com/latex.php?latex=X_L%7C0%5Crangle_L%3D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_L|0\rangle_L=|1\rangle_L" class="latex" title="X_L|0\rangle_L=|1\rangle_L" />, and so on). In the 5-qubit case we end up with a 6-dimensional nonabelian group <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BG%7D%3D%5Clangle+g_1%2C...%2Cg_4%2C+h_1%2C+h_2%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tilde{G}=\langle g_1,...,g_4, h_1, h_2\rangle" class="latex" title="\tilde{G}=\langle g_1,...,g_4, h_1, h_2\rangle" /> by adding the following two elements to those elements that are in <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=h_1%3DXXXXX&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_1=XXXXX" class="latex" title="h_1=XXXXX" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=h_2%3DZZZZZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_2=ZZZZZ" class="latex" title="h_2=ZZZZZ" /></p>
<p>These will be our logical operators</p>
<p><img src="https://s0.wp.com/latex.php?latex=X_L%5Cequiv+h_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_L\equiv h_1" class="latex" title="X_L\equiv h_1" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=Z_L%5Cequiv+h_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_L\equiv h_2" class="latex" title="Z_L\equiv h_2" /></p>
<p>so that</p>
<p><img src="https://s0.wp.com/latex.php?latex=X_L%7C0%5Crangle_L%3D%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_L|0\rangle_L=|1\rangle_L" class="latex" title="X_L|0\rangle_L=|1\rangle_L" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=X_L%7C1%5Crangle_L%3D%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_L|1\rangle_L=|0\rangle_L" class="latex" title="X_L|1\rangle_L=|0\rangle_L" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=Z_L%7C1%5Crangle_L%3D-%7C1%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_L|1\rangle_L=-|1\rangle_L" class="latex" title="Z_L|1\rangle_L=-|1\rangle_L" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=Z_L%7C0%5Crangle_L%3D%7C0%5Crangle_L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_L|0\rangle_L=|0\rangle_L" class="latex" title="Z_L|0\rangle_L=|0\rangle_L" />.</p>
<p>Note that this code has distance 3 and corrects 1 error because 3 is the minimum Hamming weight in the group <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tilde{G}" class="latex" title="\tilde{G}" />. (To see this, note that <img src="https://s0.wp.com/latex.php?latex=XXXXX%5Ccdot+IXZZX%3DXIYYI&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="XXXXX\cdot IXZZX=XIYYI" class="latex" title="XXXXX\cdot IXZZX=XIYYI" /> has Hamming weight 3.)</p>
<p>Why is Hamming weight 2 not enough to correct one error? If we had, for example, <img src="https://s0.wp.com/latex.php?latex=XZIII%5Cin%5Ctilde%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="XZIII\in\tilde{G}" class="latex" title="XZIII\in\tilde{G}" />, then we would have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csigma_x%5E%7B%281%29%7D%7C%5Cpsi_1%5Crangle%3D%5Csigma_z%5E%7B%282%29%7D%7C%5Cpsi_2%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sigma_x^{(1)}|\psi_1\rangle=\sigma_z^{(2)}|\psi_2\rangle" class="latex" title="\sigma_x^{(1)}|\psi_1\rangle=\sigma_z^{(2)}|\psi_2\rangle" /></p>
<p>for <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_1%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_1\rangle" class="latex" title="|\psi_1\rangle" />, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_2%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_2\rangle" class="latex" title="|\psi_2\rangle" /> both in the code, which means that we wouldn’t be able to distinguish an <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" /> error from a <img src="https://s0.wp.com/latex.php?latex=Z_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_2" class="latex" title="Z_2" /> error.</p>
<p>Note that, in general, when <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5Ctilde%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\tilde{G}" class="latex" title="x\in\tilde{G}" />, <img src="https://s0.wp.com/latex.php?latex=x%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x|\psi\rangle" class="latex" title="x|\psi\rangle" /> will be in the code, so elements of <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\tilde{G}" class="latex" title="\tilde{G}" /> map codewords to codewords. We can prove this fact by noting that</p>
<p><img src="https://s0.wp.com/latex.php?latex=xg_i%7C%5Cpsi%5Crangle%3Dx%7C%5Cpsi%5Crangle%3Dg_ix%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="xg_i|\psi\rangle=x|\psi\rangle=g_ix|\psi\rangle" class="latex" title="xg_i|\psi\rangle=x|\psi\rangle=g_ix|\psi\rangle" />.</p>
<p>Note also that in the examples we’ve been dealing with so far, where we have a commuting subgroup of the Pauli group, our codes correspond to classical, additive, weakly self-dual codes over <img src="https://s0.wp.com/latex.php?latex=GF%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="GF(4)" class="latex" title="GF(4)" />. Here <img src="https://s0.wp.com/latex.php?latex=GF%284%29%3D%5C%7B0%2C1%2C%5Comega%2C%5Cbar%7B%5Comega%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="GF(4)=\{0,1,\omega,\bar{\omega}\}" class="latex" title="GF(4)=\{0,1,\omega,\bar{\omega}\}" /> (with group elements <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Comega%2C+%5Cbar%7B%5Comega%7D%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\omega, \bar{\omega},1\}" class="latex" title="\{\omega, \bar{\omega},1\}" /> corresponding to the third roots of unity) is the finite field on 4 elements, and multiplying Pauli matrices corresponds to group addition. Specifically,</p>
<p><img src="https://s0.wp.com/latex.php?latex=X%5Cequiv+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X\equiv 1" class="latex" title="X\equiv 1" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=Y%5Cequiv+%5Comega&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y\equiv \omega" class="latex" title="Y\equiv \omega" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=Z%5Cequiv+%5Cbar%7B%5Comega%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z\equiv \bar{\omega}" class="latex" title="Z\equiv \bar{\omega}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=I%5Cequiv+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I\equiv 0" class="latex" title="I\equiv 0" /></p>
<p>satisfying</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%5Comega%3D%5Cbar%7B%5Comega%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H\omega=\bar{\omega}" class="latex" title="H\omega=\bar{\omega}" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=2X%3D2Y%3D2Z%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2X=2Y=2Z=0" class="latex" title="2X=2Y=2Z=0" />.</p>
<p>We have now concluded our discussion of quantum error-correcting codes. In the next section we will shift gears and look at quantum channels and channel capacities.</p>
<p><strong>4. Quantum Channels</strong><br />
In this final section we will look at quantum channels and channel capacities.</p>
<p><strong>4.1. Definition and Examples</strong></p>
<p><strong>4.1.1. Definition</strong><br />
We know that we want to define a quantum channel to take a quantum state as input. What should the output be? As a first attempt we might imagine having the output be a probability distribution <img src="https://s0.wp.com/latex.php?latex=%5C%7Bp_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{p_i\}" class="latex" title="\{p_i\}" /> over states <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_i%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|\psi_i\rangle\}" class="latex" title="\{|\psi_i\rangle\}" />. It turns out that for a more succinct description, we can have both the input and output be a density matrix.</p>
<p>Recall that a density matrix takes the form</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%3D%5Csum_i+p_i%7C%5Cpsi_i%5Crangle%5Clangle%5Cpsi_i%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho=\sum_i p_i|\psi_i\rangle\langle\psi_i|" class="latex" title="\rho=\sum_i p_i|\psi_i\rangle\langle\psi_i|" /></p>
<p>representing a probability distribution over pure states <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_i\rangle" class="latex" title="|\psi_i\rangle" />. <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> must also be Hermitian, and it must satisfy <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28%5Crho%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{Tr}(\rho)=1" class="latex" title="\text{Tr}(\rho)=1" /> (equivalently, we must have <img src="https://s0.wp.com/latex.php?latex=%5Csum_i+p_i%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_i p_i=1" class="latex" title="\sum_i p_i=1" />).</p>
<p>Now we may define a quantum channel as the map <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta" class="latex" title="\eta" /> that takes</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Ceta%3A%5Crho%5Cmapsto%5Csum_i+E_i%5Crho+E_i%5E%7B%5Cdagger%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta:\rho\mapsto\sum_i E_i\rho E_i^{\dagger}" class="latex" title="\eta:\rho\mapsto\sum_i E_i\rho E_i^{\dagger}" />,</p>
<p>where</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csum_i+E_i%5E%7B%5Cdagger%7DE_i%3DI&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_i E_i^{\dagger}E_i=I" class="latex" title="\sum_i E_i^{\dagger}E_i=I" />.</p>
<p>To see that the output is in fact a density matrix, note that the output expression is clearly Hermitian and can be shown to have unit trace using the cyclical property of traces. Note also that the decomposition into <img src="https://s0.wp.com/latex.php?latex=%5C%7BE_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{E_i\}" class="latex" title="\{E_i\}" /> need not be unique.</p>
<p><strong>4.1.2. Example Quantum Channels</strong><br />
Next we give a few examples of quantum channels. The dephasing channel is given by the map</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%5Cmapsto%281-p%29%5Crho%2Bp%5Csigma_z%5Crho%5Csigma_z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho\mapsto(1-p)\rho+p\sigma_z\rho\sigma_z" class="latex" title="\rho\mapsto(1-p)\rho+p\sigma_z\rho\sigma_z" />.</p>
<p>It maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D%5Calpha%26%5Cbeta%5C%5C%5Cgamma%26%5Cdelta%5Cend%7Barray%7D%5Cright%29%5Cmapsto+%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D%5Calpha%26%281-2p%29%5Cbeta%5C%5C%281-2p%29%5Cgamma%26%5Cdelta%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left(\begin{array}{cc}\alpha&amp;\beta\\\gamma&amp;\delta\end{array}\right)\mapsto \left(\begin{array}{cc}\alpha&amp;(1-2p)\beta\\(1-2p)\gamma&amp;\delta\end{array}\right)" class="latex" title="\left(\begin{array}{cc}\alpha&amp;\beta\\\gamma&amp;\delta\end{array}\right)\mapsto \left(\begin{array}{cc}\alpha&amp;(1-2p)\beta\\(1-2p)\gamma&amp;\delta\end{array}\right)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D%5Calpha%26%5Cbeta%5C%5C%5Cgamma%26%5Cdelta%5Cend%7Barray%7D%5Cright%29%5Cmapsto+%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D%5Calpha%26%281-2p%29%5Cbeta%5C%5C%281-2p%29%5Cgamma%26%5Cdelta%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\left(\begin{array}{cc}\alpha&amp;\beta\\\gamma&amp;\delta\end{array}\right)\mapsto \left(\begin{array}{cc}\alpha&amp;(1-2p)\beta\\(1-2p)\gamma&amp;\delta\end{array}\right)" class="latex" title="\left(\begin{array}{cc}\alpha&amp;\beta\\\gamma&amp;\delta\end{array}\right)\mapsto \left(\begin{array}{cc}\alpha&amp;(1-2p)\beta\\(1-2p)\gamma&amp;\delta\end{array}\right)" />,</p>
<p>so it multiplies off-diagonal elements by a factor that is less than 1. Note that when <img src="https://s0.wp.com/latex.php?latex=p%3D1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p=1/2" class="latex" title="p=1/2" />, it maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha%7C0%5Crangle%2B%5Cbeta%7C1%5Crangle%5Cmapsto%7C%5Calpha%7C%5E2%7C0%5Crangle%5Clangle+0%7C%2B%7C%5Cbeta%7C%5E2%7C1%5Crangle%5Clangle+1%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha|0\rangle+\beta|1\rangle\mapsto|\alpha|^2|0\rangle\langle 0|+|\beta|^2|1\rangle\langle 1|" class="latex" title="\alpha|0\rangle+\beta|1\rangle\mapsto|\alpha|^2|0\rangle\langle 0|+|\beta|^2|1\rangle\langle 1|" />,</p>
<p>which means that it turns superpositions into classical mixtures (hence the name “dephasing”).</p>
<p>Another example is the amplitude damping channel, which models an excited state decaying to a ground state. It is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=E_1%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D0%26%5Csqrt%7Bp%7D%5C%5C0%260%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_1=\left(\begin{array}{cc}0&amp;\sqrt{p}\\0&amp;0\end{array}\right)" class="latex" title="E_1=\left(\begin{array}{cc}0&amp;\sqrt{p}\\0&amp;0\end{array}\right)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=E_2%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D1%260%5C%5C0%26%5Csqrt%7B1-p%7D%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E_2=\left(\begin{array}{cc}1&amp;0\\0&amp;\sqrt{1-p}\end{array}\right)" class="latex" title="E_2=\left(\begin{array}{cc}1&amp;0\\0&amp;\sqrt{1-p}\end{array}\right)" /></p>
<p>Here we let the vector <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%3D%281%2C+0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle=(1, 0)" class="latex" title="|0\rangle=(1, 0)" /> denote the ground state, and we let the vector <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle%3D%280%2C+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle=(0, 1)" class="latex" title="|1\rangle=(0, 1)" /> denote the excited state. Thus we can see that the channel maps the ground state to itself, <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Cmapsto%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle\mapsto|0\rangle" class="latex" title="|0\rangle\mapsto|0\rangle" />, while the excited state <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle" class="latex" title="|1\rangle" /> gets mapped to <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle" class="latex" title="|0\rangle" /> with probability <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and stays at <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|1\rangle" class="latex" title="|1\rangle" /> with probability <img src="https://s0.wp.com/latex.php?latex=1-p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1-p" class="latex" title="1-p" />.</p>
<p><strong>4.2 Quantum Channel Capacities</strong><br />
Now we consider the capacity of quantum channels, where the capacity quantifies how much information can make it through the channel. We consider classical channels, classical information sent over quantum channels, and quantum information sent over quantum channels. First we start off with the example of the quantum erasure channel to demonstrate that quantum channels behave differently from classical channels, and then we give the actual expressions for the channel capacities before revisiting the example of the quantum erasure channel.</p>
<p><strong>4.2.1 Example: Quantum Erasure Channel</strong><br />
First we start with the example of the quantum erasure channel, which given a state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> replaces it by an orthogonal state <img src="https://s0.wp.com/latex.php?latex=%7CE%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|E\rangle" class="latex" title="|E\rangle" /> with probability <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> and returns the same state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> with probability <img src="https://s0.wp.com/latex.php?latex=1-p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1-p" class="latex" title="1-p" />. We claim that the erasure channel can’t transmit quantum information when <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+0.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 0.5" class="latex" title="p\geq 0.5" />, behavior that is markedly different from that of classical information. That is to say, for <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+0.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 0.5" class="latex" title="p\geq 0.5" />, there is no way to encode quantum information to send it through the channel and then decode it so the receiver gets a state close to the state that was sent.</p>
<p>To see why this is the case, assume the contrary, that there do exist encoding and decoding protocols that send quantum information through quantum erasure channels with erasure rate <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+0.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 0.5" class="latex" title="p\geq 0.5" />. We will show that this violates the no-cloning theorem. Now, suppose that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> does the following: For each qubit in the encoded state, she tosses a fair coin. If the coin lands heads, she send <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> the state <img src="https://s0.wp.com/latex.php?latex=%7CE%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|E\rangle" class="latex" title="|E\rangle" /> and sends <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> the channel input with probability <img src="https://s0.wp.com/latex.php?latex=2p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2p-1" class="latex" title="2p-1" /> and the erasure state <img src="https://s0.wp.com/latex.php?latex=%7CE%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|E\rangle" class="latex" title="|E\rangle" /> otherwise. If the coin lands tails, she sends <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> the state <img src="https://s0.wp.com/latex.php?latex=%7CE%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|E\rangle" class="latex" title="|E\rangle" /> and sends <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> the channel input with probability <img src="https://s0.wp.com/latex.php?latex=2p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2p-1" class="latex" title="2p-1" /> and the erasure state otherwise. This implements a <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+0.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 0.5" class="latex" title="p\geq 0.5" /> channel to both receivers <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> and <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" />, which means that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> can use this channel to transmit an encoding of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" /> to both receivers, which in turn means that both receivers will be able to decode <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" />. But this means that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> has just used this channel to clone the quantum state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle" class="latex" title="|\psi\rangle" />, resulting in a contradiction. Thus no quantum information can be transmitted through a channel with <img src="https://s0.wp.com/latex.php?latex=p%5Cgeq+0.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p\geq 0.5" class="latex" title="p\geq 0.5" />. Note, however, that we can send classical information over this channel, so the behavior of quantum and classical information is markedly different.</p>
<p>It turns out that the rate of quantum information sent over the erasure channel, as a function of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, is given by the following graph:</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/fig4.png?w=600" alt="fig4.png" class="alignnone size-full wp-image-6318" /><br />
while the rate of classical information sent over the erasure channel, as a function of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, is given by the following graph:</p>
<p><img src="https://windowsontheory.files.wordpress.com/2018/12/fig5.png?w=600" alt="fig5.png" class="alignnone size-full wp-image-6319" /></p>
<p>Next we will formally state the definition of channel capacity, and then we will return to the quantum erasure channel example and derive the curve that plots rate against <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />.</p>
<p><strong>4.2.2. Definition of Channel Capacities</strong><br />
Channel capacity is defined as the maximum rate at which information can be communicated over many independent uses of a channel from sender to receiver. Here we list the expressions for channel capacity for classical channels, classical information over a quantum channel, and quantum information over a quantum channel.</p>
<p><strong>Classical Channel Capacity</strong> For a classical channel this expression is just the maximum mutual information over all input-output pairs,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmax_X+H%28%5Ceta%28X%29%29-H%28%5Ceta%28X%29%7CX%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\max_X H(\eta(X))-H(\eta(X)|X)" class="latex" title="\max_X H(\eta(X))-H(\eta(X)|X)" />,</p>
<p>where <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> is the input information and <img src="https://s0.wp.com/latex.php?latex=%5Ceta%28X%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta(X)" class="latex" title="\eta(X)" /> is the output information after having gone through the channel <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta" class="latex" title="\eta" />.</p>
<p><strong>Classical Information Over a Quantum Channel </strong>The capacity for classical information sent over a quantum channel is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmax_%7B%5C%7Bp_i%2C%5Crho_i%5C%7D%7D+H%28%5Ceta%28%5Crho%29%29-%5Csum_i+p_iH%28%5Ceta%28%5Crho_i%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\max_{\{p_i,\rho_i\}} H(\eta(\rho))-\sum_i p_iH(\eta(\rho_i))" class="latex" title="\max_{\{p_i,\rho_i\}} H(\eta(\rho))-\sum_i p_iH(\eta(\rho_i))" /></p>
<p>up to regularization, where <img src="https://s0.wp.com/latex.php?latex=%5Crho%3D%5Csum_i+p_i%5Crho_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho=\sum_i p_i\rho_i" class="latex" title="\rho=\sum_i p_i\rho_i" /> is the average input state, and <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta" class="latex" title="\eta" /> is the channel.</p>
<p>Note that we would regularize this by using <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> copies of the state (that is to say, we want the output of <img src="https://s0.wp.com/latex.php?latex=%5Ceta%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta^{\otimes n}" class="latex" title="\eta^{\otimes n}" />) and then dividing by <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, to get an expression like the following for the regularized capacity of classical information over a quantum channel:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bn%5Crightarrow%5Cinfty%7D%5Cmax_%7B%5C%7Bp_i%2C%5Crho_i%5C%7D%7D+%5BH%28%5Ceta%28%5Crho%29%5E%7B%5Cotimes+n%7D%29-%5Csum_i+p_i+H%28%5Ceta%28%5Crho_i%29%5E%7B%5Cotimes+n%7D%29%5D%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lim_{n\rightarrow\infty}\max_{\{p_i,\rho_i\}} [H(\eta(\rho)^{\otimes n})-\sum_i p_i H(\eta(\rho_i)^{\otimes n})]/n" class="latex" title="\lim_{n\rightarrow\infty}\max_{\{p_i,\rho_i\}} [H(\eta(\rho)^{\otimes n})-\sum_i p_i H(\eta(\rho_i)^{\otimes n})]/n" />.</p>
<p><strong>Quantum Information</strong> The capacity for quantum information is given by the expression</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmax_%5Crho+H%28%5Ceta%28%5Crho%29%29-H%28%28%5Ceta%5Cotimes+I%29%5CPhi_%5Crho%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\max_\rho H(\eta(\rho))-H((\eta\otimes I)\Phi_\rho)" class="latex" title="\max_\rho H(\eta(\rho))-H((\eta\otimes I)\Phi_\rho)" />,</p>
<p>also up to regularization. Here <img src="https://s0.wp.com/latex.php?latex=%5Ceta%28%5Crho%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta(\rho)" class="latex" title="\eta(\rho)" /> is the output when channel <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> acts on input state <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />, while <img src="https://s0.wp.com/latex.php?latex=%5CPhi_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Phi_\rho" class="latex" title="\Phi_\rho" /> is the purification of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> (that is, it is a pure state containing <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> that we can obtain by enlarging the Hilbert space). The regularized capacity for quantum information looks like the following:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%C2%A0%5Clim_%7Bn%5Crightarrow%5Cinfty%7D%5Cmax_%5Crho+%5BH%28%5Ceta%28%5Crho%29%5E%7B%5Cotimes+n%7D%29-H%28%28%5Ceta%5Cotimes+I%29%28%5CPhi_%5Crho%29%5E%7B%5Cotimes+n%7D%29%5D%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt=" \lim_{n\rightarrow\infty}\max_\rho [H(\eta(\rho)^{\otimes n})-H((\eta\otimes I)(\Phi_\rho)^{\otimes n})]/n" class="latex" title=" \lim_{n\rightarrow\infty}\max_\rho [H(\eta(\rho)^{\otimes n})-H((\eta\otimes I)(\Phi_\rho)^{\otimes n})]/n" />.</p>
<p>Now that we have the exact expression that allows us to calculate the quantum channel capacity, we will revisit our example of the quantum erasure channel and reproduce the plot of channel rate vs erasure probability.</p>
<p><strong>4.2.3. Example Revisited: Quantum Erasure Channel</strong><br />
Recall that, up to regularization, the capacity of a quantum channel is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmax_%5Crho+H%28%5Ceta%28%5Crho%29%29-H%28%28%5Ceta%5Cotimes+I%29%5CPhi_%5Crho%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\max_\rho H(\eta(\rho))-H((\eta\otimes I)\Phi_\rho)" class="latex" title="\max_\rho H(\eta(\rho))-H((\eta\otimes I)\Phi_\rho)" />.</p>
<p>We will directly calculate this expression for the example of the quantum erasure channel. Let the input <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> be given by the density matrix for the completely mixed state,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D%5Cfrac%7B1%7D%7B2%7D%260%5C%5C0%26%5Cfrac%7B1%7D%7B2%7D%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho=\left(\begin{array}{cc}\frac{1}{2}&amp;0\\0&amp;\frac{1}{2}\end{array}\right)" class="latex" title="\rho=\left(\begin{array}{cc}\frac{1}{2}&amp;0\\0&amp;\frac{1}{2}\end{array}\right)" />,</p>
<p>so that the purification of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" /> is given by the state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle%2B%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2}}(|00\rangle+|11\rangle)" class="latex" title="\frac{1}{\sqrt{2}}(|00\rangle+|11\rangle)" />.</p>
<p>Recall that the erasure channel replaces our state with <img src="https://s0.wp.com/latex.php?latex=%7CE%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|E\rangle" class="latex" title="|E\rangle" /> with probability <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" />, while with probability <img src="https://s0.wp.com/latex.php?latex=1-p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1-p" class="latex" title="1-p" /> it leaves the input state unchanged. Then, in the basis <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C0%5Crangle%2C+%7C1%5Crangle%2C+%7CE%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|0\rangle, |1\rangle, |E\rangle\}" class="latex" title="\{|0\rangle, |1\rangle, |E\rangle\}" />, the matrix corresponding to <img src="https://s0.wp.com/latex.php?latex=%5Ceta%28%5Crho%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta(\rho)" class="latex" title="\eta(\rho)" /> is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Ceta%28%5Crho%29%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bccc%7D%5Cfrac%7B1-p%7D%7B2%7D%260%260%5C%5C0%26%5Cfrac%7B1-p%7D%7B2%7D%260%5C%5C0%260%26p%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\eta(\rho)=\left(\begin{array}{ccc}\frac{1-p}{2}&amp;0&amp;0\\0&amp;\frac{1-p}{2}&amp;0\\0&amp;0&amp;p\end{array}\right)" class="latex" title="\eta(\rho)=\left(\begin{array}{ccc}\frac{1-p}{2}&amp;0&amp;0\\0&amp;\frac{1-p}{2}&amp;0\\0&amp;0&amp;p\end{array}\right)" /></p>
<p>while in the basis <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7C00%5Crangle%2C+%7C01%5Crangle%2C+%7C10%5Crangle%2C+%7C11%5Crangle%2C+%7C0E%5Crangle%2C+%7C1E%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{|00\rangle, |01\rangle, |10\rangle, |11\rangle, |0E\rangle, |1E\rangle\}" class="latex" title="\{|00\rangle, |01\rangle, |10\rangle, |11\rangle, |0E\rangle, |1E\rangle\}" />, the matrix corresponding to <img src="https://s0.wp.com/latex.php?latex=%28%5Ceta%5Cotimes+I%29%5CPhi_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\eta\otimes I)\Phi_\rho" class="latex" title="(\eta\otimes I)\Phi_\rho" /> is given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Ceta%5Cotimes+I%29%5CPhi_%5Crho%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bcccccc%7D%5Cfrac%7B1-p%7D%7B2%7D%260%260%26%5Cfrac%7B1-p%7D%7B2%7D%260%260%5C%5C0%260%260%260%260%260%5C%5C0%260%260%260%260%260%5C%5C%5Cfrac%7B1-p%7D%7B2%7D%260%260%26%5Cfrac%7B1-p%7D%7B2%7D%260%260%5C%5C0%260%260%260%26%5Cfrac%7Bp%7D%7B2%7D%260%5C%5C0%260%260%260%260%26%5Cfrac%7Bp%7D%7B2%7D%5Cend%7Barray%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\eta\otimes I)\Phi_\rho=\left(\begin{array}{cccccc}\frac{1-p}{2}&amp;0&amp;0&amp;\frac{1-p}{2}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0\\\frac{1-p}{2}&amp;0&amp;0&amp;\frac{1-p}{2}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;\frac{p}{2}&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;\frac{p}{2}\end{array}\right)" class="latex" title="(\eta\otimes I)\Phi_\rho=\left(\begin{array}{cccccc}\frac{1-p}{2}&amp;0&amp;0&amp;\frac{1-p}{2}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0\\\frac{1-p}{2}&amp;0&amp;0&amp;\frac{1-p}{2}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;\frac{p}{2}&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;\frac{p}{2}\end{array}\right)" /></p>
<p>We can directly calculate that</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%28%5Ceta%28%5Crho%29%29%3DH_2%28p%29%2B%281-p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H(\eta(\rho))=H_2(p)+(1-p)" class="latex" title="H(\eta(\rho))=H_2(p)+(1-p)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=H%28%28%5Ceta%5Cotimes+I%29%5CPhi_%5Crho%29%3DH_2%28p%29%2Bp&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H((\eta\otimes I)\Phi_\rho)=H_2(p)+p" class="latex" title="H((\eta\otimes I)\Phi_\rho)=H_2(p)+p" />.</p>
<p>Then, subtracting the two entropies, we can calculate the rate to be</p>
<p><img src="https://s0.wp.com/latex.php?latex=R%3D1-2p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R=1-2p" class="latex" title="R=1-2p" />,</p>
<p>which corresponds exactly to the line we saw on the diagram that plotted rate as a function of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p" class="latex" title="p" /> for the quantum erasure channel.</p>
<p><strong>References</strong></p>
<ol>
<li>Bennett, C. H., DiVencenzo, D. P., and Smolin, J. A. Capacities of quantum erasure channels. <em>Phys. Rev. Lett</em>., 78:3217-3220 (1997). quant-ph/9701015.</li>
<li>Bennett, C. H., DiVencenzo, D. P., Smolin, J. A., and Wootters, W. K. Mixed state entanglement and quantum error correction. <em>Phys. Rev. A,</em> 54:3824 (1996). quant-ph/9604024.</li>
<li>Calderbank, A. R. and Shor, P. W. Good quantum error-correcting codes exist. <em>Phys. Rev. A</em>, 54:1098 (1996). quant-ph/9512032.</li>
<li>Devetak, I. The Private Classical Capacity and Quantum Capacity of a Quantum Channel. <em>IEEE Trans. Inf. Theor</em>., 51:44-45 (2005). quant-ph/0304127</li>
<li>Devetak, I. and Winter, A. Classical data compression with quantum side information. <em>Phys. Rev. A</em>, 68(4):042301 (2003).</li>
<li>Gottesman, D. Class of quantum error-correcting codes saturating the quantum Hamming bound. <em>Phys. Rev. A</em>, 54:1862 (1996).</li>
<li>Laflamme, R., Miquel, C., Paz, J.-P., and Zurek, W. H. Perfect quantum error correction code. <em>Phys. Rev. Lett</em>., 77:198 (1996). quant-ph/9602019.</li>
<li>Lloyd, S. Capacity of the noisy quantum channel. <em>Phys. Rev. A</em>., 55:3 (1997). quant-ph/9604015.</li>
<li>Nielsen, M. A. and Chuang, I. L. <em>Quantum Computation and Quantum Information</em>., Cambridge University Press, New York (2011).</li>
<li>Shor, P. W. Scheme for reducing decoherence in quantum computer memory. <em>Phys. Rev. A</em>., 52:2493 (1995).</li>
<li>Shor, P. W. The quantum channel capacity and coherent information. <em>MSRI Workshop on Quantum Computation</em> (2002).</li>
<li>Steane, A. M. Error correcting codes in quantum theory. <em>Phys. Rev. Lett</em>., 77:793 (1996).</li>
<li>Steane, A. M. Multiple particle interference and quantum error correction. <em>Proc. R. Soc. London A</em>, 452:2551-76 (1996).</li>
</ol></div>







<p class="date">
by anniewei <a href="https://windowsontheory.org/2018/12/07/quantum-error-correction/"><span class="datestr">at December 07, 2018 03:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2018/12/07/faculty-at-university-of-bristol-apply-by-january-13-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2018/12/07/faculty-at-university-of-bristol-apply-by-january-13-2019/">Faculty at University of Bristol (apply by January 13, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Computer Science department of the University of Bristol invites applications for a full-time faculty member at the Lecturer/Senior Lecturer level (comparable to tenure-track Assistant/Associate Professorships). We are looking for exceptional candidates in the areas of algorithms and complexity.</p>
<p>Website: <a href="https://goo.gl/ngvAw9">https://goo.gl/ngvAw9</a><br />
Email: raphael.clifford@bristol.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2018/12/07/faculty-at-university-of-bristol-apply-by-january-13-2019/"><span class="datestr">at December 07, 2018 11:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=332">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2018/12/06/tcs-talk-wednesday-december-12-julia-chuzhoy-ttic/">TCS+ talk: Wednesday, December 12 — Julia Chuzhoy, TTIC</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, December 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Julia Chuzhoy</strong> from TTIC will speak about “<em>Almost Polynomial Hardness of Node-Disjoint Paths in Grids</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In the classical Node-Disjoint Paths (NDP) problem, we are given an n-vertex graph G, and a collection of pairs of its vertices, called demand pairs. The goal is to route as many of the demand pairs as possible, where to route a pair we need to select a path connecting it, so that all selected paths are disjoint in their vertices.</p>
<p>The best current algorithm for NDP achieves an <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(\sqrt{n})" class="latex" title="O(\sqrt{n})" />-approximation, while, until recently, the best negative result was a roughly <img src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Csqrt%7B%5Clog+n%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\Omega(\sqrt{\log n})" class="latex" title="\Omega(\sqrt{\log n})" />-hardness of approximation. Recently, an improved <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5COmega%28%5Csqrt%7B%5Clog+n%7D%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" alt="2^{\Omega(\sqrt{\log n})}" class="latex" title="2^{\Omega(\sqrt{\log n})}" />-hardness of approximation for NDP was shown, even if the underlying graph is a subgraph of a grid graph, and all source vertices lie on the boundary of the grid. Unfortunately, this result does not extend to grid graphs.</p>
<p>The approximability of NDP in grids has remained a tantalizing open question, with the best upper bound of <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BO%7D%28n%5E%7B1%2F4%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\tilde{O}(n^{1/4})" class="latex" title="\tilde{O}(n^{1/4})" />, and the best lower bound of APX-hardness. In this talk we come close to resolving this question, by showing an almost polynomial hardness of approximation for NDP in grid graphs.</p>
<p>Our hardness proof performs a reduction from the 3COL(5) problem to NDP, using a new graph partitioning problem as a proxy. Unlike the more standard approach of employing Karp reductions to prove hardness of approximation, our proof is a Cook-type reduction, where, given an input instance of 3COL(5), we produce a large number of instances of NDP, and apply an approximation algorithm for NDP to each of them. The construction of each new instance of NDP crucially depends on the solutions to the previous instances that were found by the approximation algorithm.</p>
<p>Joint work with David H.K. Kim and Rachit Nimavat.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2018/12/06/tcs-talk-wednesday-december-12-julia-chuzhoy-ttic/"><span class="datestr">at December 06, 2018 09:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=602">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2018/12/06/symmetry/">Symmetry</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: justify;">Yesterday at the Simon institute there was a fun talk about <em>T<a href="https://www.amazon.com/Edge-Physics-Journey-Extremes-Universe/dp/0547394527">he edge of physics</a></em> by its author, <span class="a-size-large a-text-bold">Anil Ananthaswamy. To divulgate the theory of computation isn’t as easy, since you can’t talk about mega experiments done at the South Pole or massive telescopes built on top of mountains.  (It would also be a lot easier if we could resolve P vs. NP.)  For some inspiration we can look at books related to mathematics.  Here I would like to recommend <em><a href="https://www.amazon.com/Symmetry-Journey-into-Patterns-Nature/dp/0060789417">Symmetry</a></em>, by <span class="author notFaded"><span class="a-size-small a-color-secondary">Marcus du Sautoy</span>.  I enjoyed very much reading and re-reading this book, much more than his previous book <em>The music of the primes</em>, which I don’t really recommend.  <em>Symmetry</em> is a gripping history of group theory.  The purpose isn’t so much explaining the math as making you excited about the historical developments of the theory and the people that worked and are working on it.</span></span></p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2018/12/06/symmetry/"><span class="datestr">at December 06, 2018 08:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/208">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/208">TR18-208 |  Placing Conditional Disclosure of Secrets in the Communication Complexity Universe | 

	Benny Applebaum, 

	Prashant Nalini Vasudevan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In the *Conditional Disclosure of Secrets* (CDS) problem (Gertner et al., J. Comput. Syst. Sci., 2000) Alice and Bob, who hold $n$-bit inputs $x$ and $y$ respectively, wish to release a common secret $z$ to Carol (who knows both $x$ and $y$) if and only if the input $(x,y)$ satisfies some predefined predicate $f$. Alice and Bob are allowed to send a single message to Carol which may depend on their inputs and some shared randomness, and the goal is to minimize the communication complexity while providing information-theoretic security.

Despite the growing interest in this model, very few lower-bounds are known. In this paper, we relate the CDS complexity of a predicate $f$ to its communication complexity under various communication games. For several basic predicates our results yield tight, or almost tight, lower-bounds of $\Omega(n)$ or $\Omega(n^{1-\epsilon})$, providing an exponential improvement over previous logarithmic lower-bounds.

We also define new communication complexity classes that correspond to different variants of the CDS model and study the relations between them and their complements. Notably, we show that allowing for imperfect correctness can significantly reduce communication -- a seemingly new phenomenon in the context of information-theoretic cryptography. Finally, our results show that proving explicit super-logarithmic lower-bounds for imperfect CDS protocols is a necessary step towards proving explicit lower-bounds against the class AM, or even $\text{AM}\cap \text{co-AM}$ -- a well known open problem in the theory of communication complexity. Thus imperfect CDS forms a new minimal class which is placed just beyond the boundaries of the ``civilized'' part of the communication complexity world for which explicit lower-bounds are known.<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/208"><span class="datestr">at December 06, 2018 10:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-2031725340443367810">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/FmlDMOKnc-4/the-theorycs-aggregator.html">The theoryCS aggregator</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>As you all might now, the cstheory blog aggregator is currently down. Many people have been wondering what's going on and when it will be back up so here's a short summary.<br /><br />The aggregator has been thus far maintained by Arvind Narayanan who deserves a HUGE thanks for setting up the aggregator, lots of custom code and the linked twitter account. Arvind has been planning to hand it over and the domain going down was a good motivator for him to do that.<br /><br />Currently I have all the code that is used to generate the feed, as well as control over the twitter feed. <a href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</a> has kindly volunteered to be the co-manager of the aggregator. What remains to be done now is<br /><br /><ul><li>set up a new location to run the aggregator code from</li><li>set up hosting for the website</li><li>link this to the twitter account. </li></ul><div>None of these seem too difficult and the main bottleneck is merely having Arnab and I put together a few hours of work to get this all organized (we have a domain registered already). We hope to have it done fairly soon so you can all get back to reading papers and blogs again. </div><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=FmlDMOKnc-4:67hweawgAKc:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=FmlDMOKnc-4:67hweawgAKc:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img src="http://feeds.feedburner.com/~r/TheGeomblog/~4/FmlDMOKnc-4" alt="" width="1" height="1" /></div><div class="commentbar"><p></p><span href="http://blog.geomblog.org/feeds/2031725340443367810/comments/default" class="commentbutton"></span><a href="http://blog.geomblog.org/feeds/2031725340443367810/comments/default"><img src="/images/feed-icon.png" class="commenticon" /> Subscribe to comments</a>  | <a href="http://blog.geomblog.org/2018/12/the-theorycs-aggregator.html#comment-form"><img src="/images/post-icon.png" class="commenticon" /> Post a comment</a></div></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/FmlDMOKnc-4/the-theorycs-aggregator.html"><span class="datestr">at December 06, 2018 07:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-385620425457535916">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2018/12/nips-2018-post.html">NeurIPS 2018 Post</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>Today was my first day at a NeurIPS conference.  Advertising note, before my thoughts on the experience:<br />Tomorrow I'll be stationed at a poster 10:45 AM -- 12:45 PM @ Room 517 AB #169<br />A Model for Learned Bloom Filters and Optimizing by Sandwiching<br />and at the same time Diana Cai will be stationed at a poster I'm involved with:<br />Room 210 #26<br />A Bayesian Nonparametric View on Count-Min Sketch<br />Please stop by to talk to me if you're around -- Room 517 seems to be a bit off the beaten path and I'm concerned I'll be lonely with nobody to talk to.  And of course stop by to see Diana too.<br /><br />NeurIPS is just huge.  It's like an extremely large academic conference (of 1000-2000 people) glued together to an extremely large industry conference (of more than that).   Just the academic part (talks and poster sessions, 3 parallel sessions for talks) is a lot, and then there's a trade show with booths from 50+ companies there too.<br /><br />I think I'd like the academic part more if I was in the area -- I'm coming in from the algorithms perspective, and there's a bit of language gap.  It seems to me that conference suffers from some of the standard aspects of large conferences -- with scope and size that big, you have to look and find the things that are interesting and important to you, because a fair bit probably isn't.  And while I can't tell entirely myself, I'm told by others that, given the size, there's not a lot of "junk" -- the work seems good-on-average.  Also, given the conference size, it seems well organized -- staff managing the people flow, they keep things on time, plenty of room in the poster session (with appropriate food and drink stuff).  I can appreciate the work that must go into to making something this big work.<br /><br />Because the conference is so big, I've run into a good number of "theory people" here.  As a percentage of attendees, we're probably small, but it's a good number because it's so big.  I kept running into people at the poster sessions, which was nice.<br /><br />The trade show part is impressive in its own way.  If you didn't know AI was big, this would tell you.  All the big players are there, but there are at least a dozen machine-learning focused companies I haven't heard of, and that's not including the dozen or more consulting/Wall Street/hedge fund firms that are big enough into AI that they want to have a presence here.  I understand there's lots of networking and pre-interviewing and interviewing going on.  On the positive side, I feel like if I wanted to leave academia, I could land a job with a variety of AI-based companies, beyond the big companies.    <br /><br />Hopefully tomorrow will be interesting as well.<br /><br /><br /></div><div class="commentbar"><p></p><span href="http://mybiasedcoin.blogspot.com/feeds/385620425457535916/comments/default" class="commentbutton"></span><a href="http://mybiasedcoin.blogspot.com/feeds/385620425457535916/comments/default"><img src="/images/feed-icon.png" class="commenticon" /> Subscribe to comments</a>  | <a href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=385620425457535916"><img src="/images/post-icon.png" class="commenticon" /> Post a comment</a></div></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2018/12/nips-2018-post.html"><span class="datestr">at December 05, 2018 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16599">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2018/12/05/igor-pak-will-give-the-2018-erdos-lectures/">Igor Pak will give the 2018 Erdős Lectures</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2018/06/pak.jpg"><img src="https://gilkalai.files.wordpress.com/2018/06/pak.jpg?w=640" alt="" class="alignnone size-full wp-image-16201" /></a></p>
<p> </p>
<h3>Next week Igor Pak will give the 2018 Erdős Lectures (delayed from June)</h3>
<p>Here is the poster</p>
<p> </p>
<article class="node node-event node-teaser article event-start clearfix" id="node-56026">
<div class="event-content">
<header class="node-header">
<h2 class="node-title">Combinatorics — Erdos lecture: Igor Pak (UCLA) “Counting linear extensions”</h2>
</header>
<div class="node-content">
<div class="field field-name-field-date field-type-datetime field-label-hidden view-mode-teaser">
<div class="field-items">
<div class="field-item even">
<h3 class="event-start"><span class="event-year">Monday December 10  11:00-13:00</span></h3>
</div>
</div>
</div>
<section class="field field-name-field-event-location field-type-text field-label-inline clearfix view-mode-teaser">
<h3 class="field-label">Location:  <span class="event-year">IIAS Hall 130, Feldman building, </span> Givat Ram</h3>
<p> </p>
</section>
<div class="field field-name-body field-type-text-with-summary field-label-hidden view-mode-teaser">
<div class="field-items">
<p> </p>
<p class="field-item even">I will survey various known and recent results on counting the number of linear extensions of finite posets. I will emphasize the asymptotic and complexity aspects for special families, where the problem is especially elegant yet remains #P-complete.</p>
<div></div>
<div></div>
</div>
</div>
</div>
</div>
</article>
<article class="node node-event node-teaser article event-start clearfix" id="node-58788">
<div class="event-content">
<header class="node-header">
<h2 class="node-title">CS Theory — Erdős Lecture: Igor Pak (UCLA) “Counting Young tableaux”</h2>
</header>
<div class="node-content">
<section class="field field-name-field-lecturer field-type-text field-label-above view-mode-_custom_display">
<div class="field-items">
<div class="field-item even">
<h3 class="event-start"><span class="event-year">Wednesday, Dec. 12,  2018, <span class="date-display-single"><span class="date-display-start">10:30am</span> to <span class="date-display-end">12:00pm</span></span></span></h3>
</div>
</div>
</section>
<div class="field-items">
<div class="field-item even"></div>
</div>
<section class="field field-name-field-event-location field-type-text field-label-inline clearfix view-mode-teaser">
<h3 class="field-label">Location: Rothberg (CS building) B-220</h3>
</section>
<div class="field field-name-body field-type-text-with-summary field-label-hidden view-mode-teaser">
<div class="field-items">
<div class="field-item even">
<p>The number of standard Young tableaux of skew shape is a mesmerizing special case of the number of linear extensions of posets, that is important for applications in representation theory and algebraic geometry.  In this case there is a determinant formula, but finding their asymptotics is a difficult challenge.  I will survey some of the many beautiful result on the subject, explain some surprising product formulas, connections to Selberg integral, lozenge tilings and certain particle systems.</p>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="node node-event node-teaser article event-start clearfix" id="node-51625">
<div class="event-content">
<header class="node-header">
<h2 class="node-title">Colloquium: Erdos lecture – Igor Pak (UCLA) “Counting integer points in polytopes”</h2>
</header>
<div class="node-content">
<div class="field field-name-field-date field-type-datetime field-label-hidden view-mode-teaser">
<div class="field-items">
<div class="field-item even">
<h3 class="event-start"><span class="event-year">Thursday, </span><span class="event-start-day"> Dec 13, 2018 <span class="date-display-single"><span class="date-display-start">2:30pm</span> to <span class="date-display-end">3:30pm</span></span></span></h3>
</div>
</div>
</div>
<section class="field field-name-field-event-location field-type-text field-label-inline clearfix view-mode-teaser">
<h3 class="field-label">Location: Manchester Building (Hall 2), Hebrew University Jerusalem</h3>
</section>
<div class="field field-name-body field-type-text-with-summary field-label-hidden view-mode-teaser">
<div class="field-items">
<p class="field-item even">Given a convex polytope P, what is the number of integer points in P? This problem is of great interest in combinatorics and discrete geometry, with many important applications ranging from integer programming to statistics. From a computational point of view it is hopeless in any dimensions, as the knapsack problem is a special case. Perhaps surprisingly, in bounded dimension the problem becomes tractable. How far can one go? Can one count points in projections of P, finite intersections of such projections, etc.?</p>
</div>
</div>
</div>
</div>
</article></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2018/12/05/igor-pak-will-give-the-2018-erdos-lectures/"><span class="datestr">at December 05, 2018 04:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2018/207">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2018/207">TR18-207 |  On the Probabilistic Degree of OR over the Reals | 

	Tulasimohan Molli, 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Srikanth Srinivasan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the probabilistic degree over reals of the OR function on $n$ variables. For an error parameter $\epsilon$ in (0,1/3), the $\epsilon$-error probabilistic degree of any Boolean function $f$ over reals is the smallest non-negative integer $d$ such that the following holds: there exists a distribution $D$ of polynomials entirely supported on polynomials of degree at most $d$ such that for all $z \in \{0,1\}^n$, we have $Pr_{P \sim D} [P(z) = f(z) ] \geq 1- \epsilon$.  It is known from the works of Tarui (Theoret. Comput. Sci. 1993) and Beigel, Reingold, and Spielman ( Proc. 6th CCC 1991), that the $\epsilon$-error probabilistic degree of the OR function is at most $O(\log n.\log 1/\epsilon)$. Our first observation is that this can be improved to $O{\log {{n}\choose{\leq \log 1/\epsilon}}}$, which is better for small values of $\epsilon$. 

In all known constructions of probabilistic polynomials for the OR function (including the above improvement), the polynomials $P$ in the support of the distribution $D$ have the following special structure:$P = 1 - (1-L_1).(1-L_2)...(1-L_t)$, where each $L_i(x_1,..., x_n)$ is a linear form in the variables $x_1,...,x_n$, i.e., the polynomial $1-P(x_1,...,x_n)$ is a product of affine forms. We show that the $\epsilon$-error probabilistic degree of OR when restricted to polynomials of the above form is $\Omega ( \log a/\log^2 a )$ where $a = \log {{n}\choose{\leq \log 1/\epsilon}}$. Thus matching the above upper bound (up to poly-logarithmic factors).<p></p></div></div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2018/207"><span class="datestr">at December 05, 2018 03:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-952839314677870131">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2018/12/two-papers-by-gssi-researchers-at-aaai.html">Two papers by GSSI researchers at AAAI 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>The main track of <a href="https://aaai.org/Conferences/AAAI-19/" target="_blank">AAAI 2019 </a>will feature the presentation of two papers by <a href="https://cs.gssi.it/" target="_blank">CS@GSSI</a> researchers. The two papers are<br /><ul><li>"<a href="https://arxiv.org/abs/1811.04331" target="_blank">Coverage Centrality Maximization in Undirected Networks</a>" by <a href="http://informatica.ing.univaq.it/dangelo/" target="_blank">Gianlorenzo D'Angelo</a> (Gran Sasso Science Institute), Martin Olsen (Aarhus University) and Lorenzo Severini (ISI Foundation) and</li><li>"<a href="https://arxiv.org/abs/1805.01406" target="_blank">Distributed Community Detection via Metastability of the 2-Choices Dynamics</a>" by <a href="https://sites.google.com/view/emiliocruciani/" target="_blank">Emilio Cruciani </a>(Gran Sasso Science Institute), Emanuele Natale (MPII) and Giacomo Scornavacca (University of L'Aquila). </li></ul>The paper by Gianlorenzo, Martin and Lorenzo (who is a CS@GSSI alumnus)  contributes to the study of one of the main tools in the analysis of social networks, viz. <a href="https://en.wikipedia.org/wiki/Centrality" target="_blank">centrality metrics</a>. Since central nodes are very influential in their network, increasing the centrality of a network user is a widely studies optimization problem in network analysis. Gianlorenzo, Martin and Lorenzo have studied the centrality maximization problem in undirected networks for one of the most important shortest-path-based centrality measures, namely the coverage centrality. They give several hardness results, approximation algorithms and an experimental study of their effectiveness.<br /><br />The paper by Emilio, Emanuele and Giacomo analyzes the behaviour of a simple majority-based dynamics on a class of networks that present a clustered structure. By combining symmetry-breaking techniques and concentration of probability arguments with a linear algebraic approach, it provides the first symmetry-breaking analysis of dynamics for non-consensus problems on non-complete topologies. The analysis shows that, when the agents of the networks randomly initialize their states, the 2-Choices dynamics makes the network quickly converge to a configuration where the agents have a state that identifies the cluster to which  they belong.  The 2-Choices dynamics can be seen as a simple distributed Label Propagation Algorithm (a widely used class of heuristics for graph clustering) with quasi-linear message complexity. In this setting, the paper represents the first rigorous theoretical result. Moreover, in the context of evolutionary biology, it gives a proof of principle of <a href="https://en.wikipedia.org/wiki/Parapatric_speciation" target="_blank">sympatric/parapatric speciation,</a> in which there is no complete geographical isolation between the species: No simple dynamics was proposed before to explain such a fundamental phenomenon.<br /><div class="text_exposed_show"><br /><span style="color: #f1765e; font-weight: 600;" class="_ezo" id="u_jsonp_4_1b">Congratulations</span> to Emilio, Gianlorenzo and their coauthors! It is always a pleasure to see young researchers in one's group succeed and develop their careers. Emilio Cruciani is a beginning third-year student who already has an impressive track record of high-quality publications. Keep him in mind for postdoctoral and tenure-track positions, once he finishes his studies!<br /><br />The AAAI conference promotes research in artificial intelligence and is  one of the premier conferences in AI, where researchers, practitioners,  and scientists meet to present and discuss most recent trends and  results in the field of artificial intelligence. This year it received a  record number of over than 7,700 submissions of which 1,150 were  accepted (with an acceptance rate of 16.2%). The list of accepted papers  is at <a href="https://aaai.org/Conferences/AAAI-19/wp-content/uploads/2018/11/AAAI-19_Accepted_Papers.pdf?fbclid=IwAR0txxsExoZb6R_Gr4L-987wkSbFEOQlpJZtGQoZxgD78DYIiVQupGZP3n4" target="_blank" rel="noopener nofollow">https://aaai.org/…/uplo…/2018/11/AAAI-19_Accepted_Papers.pdf</a>.</div></div><div class="commentbar"><p></p><span href="http://processalgebra.blogspot.com/feeds/952839314677870131/comments/default" class="commentbutton"></span><a href="http://processalgebra.blogspot.com/feeds/952839314677870131/comments/default"><img src="/images/feed-icon.png" class="commenticon" /> Subscribe to comments</a>  | <a href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=952839314677870131"><img src="/images/post-icon.png" class="commenticon" /> Post a comment</a></div></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2018/12/two-papers-by-gssi-researchers-at-aaai.html"><span class="datestr">at December 05, 2018 02:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2055826519262637493">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2018/12/remembering-george-h-w-bush.html">Remembering George H. W. Bush</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><div style="clear: both; text-align: center;" class="separator">
<a style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" href="https://upload.wikimedia.org/wikipedia/commons/e/e8/George_H._W._Bush%2C_Vice_President_of_the_United_States%2C_official_portrait.jpg"><img width="158" src="https://upload.wikimedia.org/wikipedia/commons/e/e8/George_H._W._Bush%2C_Vice_President_of_the_United_States%2C_official_portrait.jpg" border="0" height="200" /></a></div>
Today is the national day of mourning for George Herbert Walker Bush, one of the best presidents for <a href="https://twitter.com/FYIscipolicy/status/1068867105867644928">science and computing</a>. He created PCAST, the President's Council of Advisors on Science and Technology. Bush signed the <a href="https://en.wikipedia.org/wiki/High_Performance_Computing_Act_of_1991">High Performance Computing Act</a> (introduced by Al Gore), that powered computing research and the Internet through the massive growth of the 90's. His administration started the Human Genome Project and the US Global Change Research Program. He appointed the first and so far only <a href="https://www.nsf.gov/about/history/bios/wemassey.jsp">African-American NSF Director</a>.<br />
<br />
Bush also started the the short-lived Presidential Faculty Fellows program. As a member of the first class of fellows I got invited to a ceremony in the Rose Garden in June of 1992. I didn't actually get to shake hands with President Bush; in that busy election year we had a joint ceremony with some high school award winners and the National Medal of Technology <a href="https://www.uspto.gov/learning-and-resources/ip-programs-and-awards/national-medal-technology-and-innovation/recipients/1992">recipients</a> that included Bill Gates and Joseph Woodland, who invented the bar code scanner used at supermarkets. George Bush famously <a href="https://www.nytimes.com/1992/02/05/us/bush-encounters-the-supermarket-amazed.html">may</a> or <a href="https://www.snopes.com/fact-check/bush-scanner-demonstration/">may not</a> have been amazed by this technology a few months earlier at a grocers convention and had no issues joking about it when introducing Woodland.<br />
<br />
Sipping lemonade on the White House lawn is not an experience one soon forgets. And I guess I haven't twenty-six years later. Thanks President Bush and God speed.<br />
<br />
<br /></div><div class="commentbar"><p></p></div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2018/12/remembering-george-h-w-bush.html"><span class="datestr">at December 05, 2018 02:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
