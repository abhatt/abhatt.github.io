<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-09-29T03:22:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13317</id>
    <link href="http://arxiv.org/abs/2009.13317" rel="alternate" type="text/html"/>
    <title>A note on differentially private clustering with large additive error</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13317">PDF</a><br/><b>Abstract: </b>In this note, we describe a simple approach to obtain a differentially
private algorithm for k-clustering with nearly the same multiplicative factor
as any non-private counterpart at the cost of a large polynomial additive
error. The approach is the combination of a simple geometric observation
independent of privacy consideration and any existing private algorithm with a
constant approximation.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13316</id>
    <link href="http://arxiv.org/abs/2009.13316" rel="alternate" type="text/html"/>
    <title>Explorable Uncertainty in Scheduling with Non-Uniform Testing Times</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckl:Alexander.html">Alexander Eckl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13316">PDF</a><br/><b>Abstract: </b>The problem of scheduling with testing in the framework of explorable
uncertainty models environments where some preliminary action can influence the
duration of a task. In the model, each job has an unknown processing time that
can be revealed by running a test. Alternatively, jobs may be run untested for
the duration of a given upper limit. Recently, D\"urr et al. [5] have studied
the setting where all testing times are of unit size and have given lower and
upper bounds for the objectives of minimizing the sum of completion times and
the makespan on a single machine. In this paper, we extend the problem to
non-uniform testing times and present the first competitive algorithms. The
general setting is motivated for example by online user surveys for market
prediction or querying centralized databases in distributed computing.
Introducing general testing times gives the problem a new flavor and requires
updated methods with new techniques in the analysis. We present constant
competitive ratios for the objective of minimizing the sum of completion times
in the deterministic case, both in the non-preemptive and preemptive setting.
For the preemptive setting, we additionally give a first lower bound. We also
present a randomized algorithm with improved competitive ratio. Furthermore, we
give tight competitive ratios for the objective of minimizing the makespan,
both in the deterministic and the randomized setting.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13257</id>
    <link href="http://arxiv.org/abs/2009.13257" rel="alternate" type="text/html"/>
    <title>Approximation algorithms for connectivity augmentation problems</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13257">PDF</a><br/><b>Abstract: </b>In Connectivity Augmentation problems we are given a graph $H=(V,E_H)$ and an
edge set $E$ on $V$, and seek a min-size edge set $J \subseteq E$ such that $H
\cup J$ has larger edge/node connectivity than $H$. In the Edge-Connectivity
Augmentation problem we need to increase the edge-connectivity by $1$. In the
Block-Tree Augmentation problem $H$ is connected and $H \cup S$ should be
$2$-connected. In Leaf-to-Leaf Connectivity Augmentation problems every edge in
$E$ connects minimal deficient sets. For this version we give a simple
combinatorial approximation algorithm with ratio $5/3$, improving the previous
$1.91$ approximation that applies for the general case. We also show by a
simple proof that if the Steiner Tree problem admits approximation ratio
$\alpha$ then the general version admits approximation ratio
$1+\ln(4-x)+\epsilon$, where $x$ is the solution to the equation
$1+\ln(4-x)=\alpha+(\alpha-1)x$. For the currently best value of $\alpha=\ln
4+\epsilon$ this gives ratio $1.942$. This is slightly worse than the best
ratio $1.91$, but has the advantage of using Steiner Tree approximation as a
"black box", giving ratio $&lt; 1.9$ if ratio $\alpha \leq 1.35$ can be achieved.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13198</id>
    <link href="http://arxiv.org/abs/2009.13198" rel="alternate" type="text/html"/>
    <title>Discrimination of attractors with noisy nodes in Boolean networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Xiaoqing.html">Xiaoqing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ching:Wai=Ki.html">Wai-Ki Ching</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Sini.html">Sini Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13198">PDF</a><br/><b>Abstract: </b>Observing the internal state of the whole system using a small number of
sensor nodes is important in analysis of complex networks. Here, we study the
problem of determining the minimum number of sensor nodes to discriminate
attractors under the assumption that each attractor has at most K noisy nodes.
We present exact and approximation algorithms for this minimization problem.
The effectiveness of the algorithms is also demonstrated by computational
experiments using both synthetic data and realistic biological data.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13184</id>
    <link href="http://arxiv.org/abs/2009.13184" rel="alternate" type="text/html"/>
    <title>The canonical directed tree decomposition and its applications to the directed disjoint paths problem</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giannopoulou:Archontia_C=.html">Archontia C. Giannopoulou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kreutzer:Stephan.html">Stephan Kreutzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwon:O=joung.html">O-joung Kwon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13184">PDF</a><br/><b>Abstract: </b>The canonical tree-decomposition theorem, given by Robertson and Seymour in
their seminal graph minors series, turns out to be one of the most important
tool in structural and algorithmic graph theory. In this paper, we provide the
canonical tree decomposition theorem for digraphs. More precisely, we construct
directed tree-decompositions of digraphs that distinguish all their tangles of
order $k$, for any fixed integer $k$, in polynomial time. As an application of
this canonical tree-decomposition theorem, we provide the following result for
the directed disjoint paths problem:
</p>
<p>For every fixed $k$ there is a polynomial-time algorithm which, on input $G$,
and source and terminal vertices $(s_1, t_1), \dots, (s_k, t_k)$, either
</p>
<p>1. determines that there is no set of pairwise vertex-disjoint paths
connecting each source $s_i$ to its terminal $t_i$, or
</p>
<p>2.finds a half-integral solution, i.e., outputs paths $P_1, \dots, P_k$ such
that $P_i$ links $s_i$ to $t_i$, so that every vertex of the graph is contained
in at most two paths. Given known hardness results for the directed disjoint
paths problem, our result cannot be improved for general digraphs, neither to
fixed-parameter tractability nor to fully vertex-disjoint directed paths. As
far as we are aware, this is the first time to obtain a tractable result for
the $k$-disjoint paths problem for general digraphs. We expect more
applications of our canonical tree-decomposition for directed results.
</p></div>
    </summary>
    <updated>2020-09-29T01:22:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13090</id>
    <link href="http://arxiv.org/abs/2009.13090" rel="alternate" type="text/html"/>
    <title>A note on weak near unanimity polymorphisms</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Arash.html">Arash Rafiey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13090">PDF</a><br/><b>Abstract: </b>We show that deciding whether a given relational structure $\mathcal{R}$
admits a weak near unanimity polymorphism is polynomial time solvable.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13071</id>
    <link href="http://arxiv.org/abs/2009.13071" rel="alternate" type="text/html"/>
    <title>$\epsilon$-net Induced Lazy Witness Complexes on Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arafat:Naheed_Anjum.html">Naheed Anjum Arafat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Debabrota.html">Debabrota Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bressan:St=eacute=phane.html">Stéphane Bressan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13071">PDF</a><br/><b>Abstract: </b>Computation of persistent homology of simplicial representations such as the
Rips and the C\v{e}ch complexes do not efficiently scale to large point clouds.
It is, therefore, meaningful to devise approximate representations and evaluate
the trade-off between their efficiency and effectiveness. The lazy witness
complex economically defines such a representation using only a few selected
points, called landmarks.
</p>
<p>Topological data analysis traditionally considers a point cloud in a
Euclidean space. In many situations, however, data is available in the form of
a weighted graph. A graph along with the geodesic distance defines a metric
space. This metric space of a graph is amenable to topological data analysis.
</p>
<p>We discuss the computation of persistent homologies on a weighted graph. We
present a lazy witness complex approach leveraging the notion of $\epsilon$-net
that we adapt to weighted graphs and their geodesic distance to select
landmarks. We show that the value of the $\epsilon$ parameter of the
$\epsilon$-net provides control on the trade-off between choice and number of
landmarks and the quality of the approximate simplicial representation.
</p>
<p>We present three algorithms for constructing an $\epsilon$-net of a graph. We
comparatively and empirically evaluate the efficiency and effectiveness of the
choice of landmarks that they induce for the topological data analysis of
different real-world graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12982</id>
    <link href="http://arxiv.org/abs/2009.12982" rel="alternate" type="text/html"/>
    <title>Quantum soundness of the classical low individual degree test</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Zhengfeng.html">Zhengfeng Ji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Anand.html">Anand Natarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vidick:Thomas.html">Thomas Vidick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wright:John.html">John Wright</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuen:Henry.html">Henry Yuen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12982">PDF</a><br/><b>Abstract: </b>Low degree tests play an important role in classical complexity theory,
serving as basic ingredients in foundational results such as $\mathsf{MIP} =
\mathsf{NEXP}$ [BFL91] and the PCP theorem [AS98,ALM+98]. Over the last ten
years, versions of these tests which are sound against quantum provers have
found increasing applications to the study of nonlocal games and the complexity
class~$\mathsf{MIP}^*$. The culmination of this line of work is the result
$\mathsf{MIP}^* = \mathsf{RE}$ [JNV+20].
</p>
<p>One of the key ingredients in the first reported proof of $\mathsf{MIP}^* =
\mathsf{RE}$ is a two-prover variant of the low degree test, initially shown to
be sound against multiple quantum provers in [Vid16]. Unfortunately a mistake
was recently discovered in the latter result, invalidating the main result of
[Vid16] as well as its use in subsequent works, including [JNV+20].
</p>
<p>We analyze a variant of the low degree test called the low individual degree
test. Our main result is that the two-player version of this test is sound
against quantum provers. This soundness result is sufficient to re-derive
several bounds on~$\mathsf{MIP}^*$ that relied on [Vid16], including
$\mathsf{MIP}^* = \mathsf{RE}$.
</p></div>
    </summary>
    <updated>2020-09-29T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12981</id>
    <link href="http://arxiv.org/abs/2009.12981" rel="alternate" type="text/html"/>
    <title>Parametric UMAP: learning embeddings with deep neural networks for representation and semi-supervised learning</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sainburg:Tim.html">Tim Sainburg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McInnes:Leland.html">Leland McInnes</a>, Timothy Q Gentner <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12981">PDF</a><br/><b>Abstract: </b>We propose Parametric UMAP, a parametric variation of the UMAP (Uniform
Manifold Approximation and Projection) algorithm. UMAP is a non-parametric
graph-based dimensionality reduction algorithm using applied Riemannian
geometry and algebraic topology to find low-dimensional embeddings of
structured data. The UMAP algorithm consists of two steps: (1) Compute a
graphical representation of a dataset (fuzzy simplicial complex), and (2)
Through stochastic gradient descent, optimize a low-dimensional embedding of
the graph. Here, we replace the second step of UMAP with a deep neural network
that learns a parametric relationship between data and embedding. We
demonstrate that our method performs similarly to its non-parametric
counterpart while conferring the benefit of a learned parametric mapping (e.g.
fast online embeddings for new data). We then show that UMAP loss can be
extended to arbitrary deep learning applications, for example constraining the
latent distribution of autoencoders, and improving classifier accuracy for
semi-supervised learning by capturing structure in unlabeled data. Our code is
available at https://github.com/timsainb/ParametricUMAP_paper.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12892</id>
    <link href="http://arxiv.org/abs/2009.12892" rel="alternate" type="text/html"/>
    <title>The Complexity of Connectivity Problems in Forbidden-Transition Graphs and Edge-Colored Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shaohua.html">Shaohua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okrasa:Karolina.html">Karolina Okrasa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sorge:Manuel.html">Manuel Sorge</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12892">PDF</a><br/><b>Abstract: </b>The notion of forbidden-transition graphs allows for a robust generalization
of walks in graphs. In a forbidden-transition graph, every pair of edges
incident to a common vertex is permitted or forbidden; a walk is compatible if
all pairs of consecutive edges on the walk are permitted. Forbidden-transition
graphs and related models have found applications in a variety of fields, such
as routing in optical telecommunication networks, road networks, and
bio-informatics.
</p>
<p>We initiate the study of fundamental connectivity problems from the point of
view of parameterized complexity, including an in-depth study of tractability
with regards to various graph-width parameters. Among several results, we prove
that finding a simple compatible path between given endpoints in a
forbidden-transition graph is W[1]-hard when parameterized by the
vertex-deletion distance to a linear forest (so it is also hard when
parameterized by pathwidth or treewidth). On the other hand, we show an
algebraic trick that yields tractability when parameterized by treewidth of
finding a properly colored Hamiltonian cycle in an edge-colored graph; properly
colored walks in edge-colored graphs is one of the most studied special cases
of compatible walks in forbidden-transition graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12809</id>
    <link href="http://arxiv.org/abs/2009.12809" rel="alternate" type="text/html"/>
    <title>Rank/Select Queries over Mutable Bitmaps</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanda:Shunsuke.html">Shunsuke Kanda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12809">PDF</a><br/><b>Abstract: </b>The problem of answering rank/select queries over a bitmap is of utmost
importance for many succinct data structures. When the bitmap does not change,
many solutions exist in the theoretical and practical side. In this work we
consider the case where one is allowed to modify the bitmap via a flip(i)
operation that toggles its i-th bit. By adapting and properly extending some
results concerning prefix-sum data structures, we present a practical solution
to the problem, tailored for modern CPU instruction sets. Compared to the
state-of-the-art, our solution improves runtime with no space degradation.
Moreover, it does not incur in a significant runtime penalty when compared to
the fastest immutable indexes, while providing even lower space overhead.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12685</id>
    <link href="http://arxiv.org/abs/2009.12685" rel="alternate" type="text/html"/>
    <title>The smoothed complexity of Frank-Wolfe methods via conditioning of random matrices and polytopes</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rademacher:Luis.html">Luis Rademacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shu:Chang.html">Chang Shu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12685">PDF</a><br/><b>Abstract: </b>Frank-Wolfe methods are popular for optimization over a polytope. One of the
reasons is because they do not need projection onto the polytope but only
linear optimization over it. To understand its complexity, Lacoste-Julien and
Jaggi introduced a condition number for polytopes and showed linear convergence
for several variations of the method. The actual running time can still be
exponential in the worst case (when the condition number is exponential). We
study the smoothed complexity of the condition number, namely the condition
number of small random perturbations of the input polytope and show that it is
polynomial for any simplex and exponential for general polytopes. Our results
also apply to other condition measures of polytopes that have been proposed for
the analysis of Frank-Wolfe methods: vertex-facet distance (Beck and Shtern)
and facial distance (Pe\~na and Rodr\'iguez).
</p>
<p>Our argument for polytopes is a refinement of an argument that we develop to
study the conditioning of random matrices. The basic argument shows that for
$c&gt;1$ a $d$-by-$n$ random Gaussian matrix with $n \geq cd$ has a $d$-by-$d$
submatrix with minimum singular value that is exponentially small with high
probability. This has consequences on results about the robust uniqueness of
tensor decompositions.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12457</id>
    <link href="http://arxiv.org/abs/2009.12457" rel="alternate" type="text/html"/>
    <title>A Block-Based Triangle Counting Algorithm on Heterogeneous Environments</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Abdurrahman Yaşar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajamanickam:Sivasankaran.html">Sivasankaran Rajamanickam</a>, Jonathan Berry, Ümit V. Çatalyürek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12457">PDF</a><br/><b>Abstract: </b>Triangle counting is a fundamental building block in graph algorithms. In
this paper, we propose a block-based triangle counting algorithm to reduce data
movement during both sequential and parallel execution. Our block-based
formulation makes the algorithm naturally suitable for heterogeneous
architectures. The problem of partitioning the adjacency matrix of a graph is
well-studied. Our task decomposition goes one step further: it partitions the
set of triangles in the graph. By streaming these small tasks to compute
resources, we can solve problems that do not fit on a device. We demonstrate
the effectiveness of our approach by providing an implementation on a compute
node with multiple sockets, cores and GPUs. The current state-of-the-art in
triangle enumeration processes the Friendster graph in 2.1 seconds, not
including data copy time between CPU and GPU. Using that metric, our approach
is 20 percent faster. When copy times are included, our algorithm takes 3.2
seconds. This is 5.6 times faster than the fastest published CPU-only time.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12442</id>
    <link href="http://arxiv.org/abs/2009.12442" rel="alternate" type="text/html"/>
    <title>Hypergraph $k$-cut for fixed $k$ in deterministic polynomial time</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Karthekeyan.html">Karthekeyan Chandrasekaran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12442">PDF</a><br/><b>Abstract: </b>We consider the Hypergraph-$k$-cut problem. The input consists of a
hypergraph $G=(V,E)$ with non-negative hyperedge-costs $c: E\rightarrow R_+$
and a positive integer $k$. The objective is to find a least-cost subset
$F\subseteq E$ such that the number of connected components in $G-F$ is at
least $k$. An alternative formulation of the objective is to find a partition
of $V$ into $k$ non-empty sets $V_1,V_2,\ldots,V_k$ so as to minimize the cost
of the hyperedges that cross the partition. Graph-$k$-cut, the special case of
Hypergraph-$k$-cut obtained by restricting to graph inputs, has received
considerable attention. Several different approaches lead to a polynomial-time
algorithm for Graph-$k$-cut when $k$ is fixed, starting with the work of
Goldschmidt and Hochbaum (1988). In contrast, it is only recently that a
randomized polynomial time algorithm for Hypergraph-$k$-cut was developed
(Chandrasekaran, Xu, Yu, 2018) via a subtle generalization of Karger's random
contraction approach for graphs. In this work, we develop the first
deterministic polynomial time algorithm for Hypergraph-$k$-cut for all fixed
$k$. We describe two algorithms both of which are based on a divide and conquer
approach. The first algorithm is simpler and runs in $n^{O(k^2)}$ time while
the second one runs in $n^{O(k)}$ time. Our proof relies on new structural
results that allow for efficient recovery of the parts of an optimum
$k$-partition by solving minimum $(S,T)$-terminal cuts. Our techniques give new
insights even for Graph-$k$-cut.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12413</id>
    <link href="http://arxiv.org/abs/2009.12413" rel="alternate" type="text/html"/>
    <title>Covering Tree-Based Phylogenetic Networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nathan Davidov, Amanda Hernandez, Justin Jian, Patrick McKenna, K. A. Medlin, Roadra Mojumder, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Owen:Megan.html">Megan Owen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quijano:Andrew.html">Andrew Quijano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodriguez:Amanda.html">Amanda Rodriguez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/John:Katherine_St=.html">Katherine St. John</a>, Katherine Thai, Meliza Uraga <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12413">PDF</a><br/><b>Abstract: </b>Tree-based phylogenetic networks, which may be roughly defined as
leaf-labeled networks built by adding arcs only between the original tree
edges, have elegant properties for modeling evolutionary histories. We answer
an open question of Francis, Semple, and Steel about the complexity of
determining how far a phylogenetic network is from being tree-based, including
non-binary phylogenetic networks. We show that finding a phylogenetic tree
covering the maximum number of nodes in a phylogenetic network can be be
computed in polynomial time via an encoding into a minimum-cost maximum flow
problem.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc / Senior Postdoc at Maynooth University (apply by October 25, 2020)</title>
    <summary>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland. Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing. Website: https://dna.hamilton.ie/join.html Email: dna.hamilton.ie@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland.</p>
<p>Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing.</p>
<p>Website: <a href="https://dna.hamilton.ie/join.html">https://dna.hamilton.ie/join.html</a><br/>
Email: dna.hamilton.ie@gmail.com</p></div>
    </content>
    <updated>2020-09-28T14:11:12Z</updated>
    <published>2020-09-28T14:11:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T03:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/" rel="alternate" type="text/html"/>
    <title>Scientific Staff  at OpenDP (Incubated by Harvard University with support from the Sloan Foundation) (apply by October 15, 2020)</title>
    <summary>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security – Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19) […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security<br/>
– Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19)</p>
<p>Website: <a href="https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff">https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff</a><br/>
Email: privacytools-info@seas.harvard.edu</p></div>
    </content>
    <updated>2020-09-28T03:47:53Z</updated>
    <published>2020-09-28T03:47:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T03:20:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9181146391897180370</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9181146391897180370/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html" rel="alternate" type="text/html"/>
    <title>A Quote from Tesla which is very predictive in one way, and perhaps not in another way</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Nikola Tesla, famous inventor, who lived 1856--1943 said the following:</p><p><br/></p><p>When wireless is perfectly applied the whole earth will be converted into</p><p>a huge brain, which in fact it is, all things being particles of a real</p><p>and rhythmic whole. We shall be able to communicate with one another</p><p>instantly, irrespective of distance. Not only this but through television</p><p>and telephony, we shall see and hear one another as perfectly as though</p><p>we were face to face, despite intervening distances of thousands of miles;</p><p>and the instruments through which we shall be able to do this will be</p><p>amazingly simple compared with our present telephone. A man will be able to</p><p>carry one in his vest pocket.</p><p><br/></p><p>The `vest pocket' at the end really impressed me.</p><p><br/></p><p>By `a man will be able to carry one...' I don't know if he mean all people or if he actually </p><p>meant that women would not need such a device. If that is what he meant then,</p><p>while high marks for tech-prediction, low marks for social-prediction. </p><p><br/></p><p>This quote is SO right-on for technology that I offer the following challenge: Find other quotes from year X that were very predictive for year X+Y for a reasonably large Y.</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-09-28T01:44:00Z</updated>
    <published>2020-09-28T01:44:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-28T23:09:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12369</id>
    <link href="http://arxiv.org/abs/2009.12369" rel="alternate" type="text/html"/>
    <title>On Two-Handed Planar Assembly Partitioning</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aronov:Boris.html">Boris Aronov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geft:Tzvika.html">Tzvika Geft</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Halperin:Dan.html">Dan Halperin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12369">PDF</a><br/><b>Abstract: </b>Assembly planning, which is a fundamental problem in robotics and automation,
aims to design a sequence of motions that will bring the separate constituent
parts of a product into their final placement in the product. It is convenient
to study assembly planning in reverse order, where the following key problem,
assembly partitioning, arises: Given a set of parts in their final placement in
a product, partition them into two sets, each regarded as a rigid body, which
we call a subassembly, such that these two subassemblies can be moved
sufficiently far away from each other, without colliding with one another. The
basic assembly planning problem is further complicated by practical
consideration such as how to hold the parts in a subassembly together.
Therefore, a desired property of a valid assembly partition is that each of the
two subassemblies will be connected.
</p>
<p>We show that even an utterly simple case of the
connected-assembly-partitioning problem is hard: Given a connected set $A$ of
unit squares in the plane, each forming a distinct cell of the uniform integer
grid, find a subset $S\subset A$ such that $S$ can be rigidly translated to
infinity along a prescribed direction without colliding with $A\setminus S$,
and both subassemblies $S$ and $A\setminus S$ are each connected. We show that
this problem is NP-Complete, and by that settle an open problem posed by Wilson
et al. (1995) a quarter of a century ago.
</p>
<p>We complement the hardness result with two positive results for the
aforementioned problem variant of grid squares. First, we show that it is fixed
parameter tractable and give an $O(2^k n^2)$-time algorithm, where $n=|A|$ and
$k=|S|$. Second, we describe a special case of this variant where a connected
partition can always be found in linear time. Each of the positive results
sheds further light on the special geometric structure of the problem at hand.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12309</id>
    <link href="http://arxiv.org/abs/2009.12309" rel="alternate" type="text/html"/>
    <title>An SPQR-Tree-Like Embedding Representation for Level Planarity</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Br=uuml=ckner:Guido.html">Guido Brückner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12309">PDF</a><br/><b>Abstract: </b>An SPQR-tree is a data structure that efficiently represents all planar
embeddings of a biconnected planar graph. It is a key tool in a number of
constrained planarity testing algorithms, which seek a planar embedding of a
graph subject to some given set of constraints.
</p>
<p>We develop an SPQR-tree-like data structure that represents all level-planar
embeddings of a biconnected level graph with a single source, called the
LP-tree, and give a simple algorithm to compute it in linear time. Moreover, we
show that LP-trees can be used to adapt three constrained planarity algorithms
to the level-planar case by using them as a drop-in replacement for SPQR-trees.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12225</id>
    <link href="http://arxiv.org/abs/2009.12225" rel="alternate" type="text/html"/>
    <title>Pebble-Depth</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jordon:Liam.html">Liam Jordon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moser:Philippe.html">Philippe Moser</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12225">PDF</a><br/><b>Abstract: </b>In this paper we introduce a new formulation of Bennett's logical depth based
on pebble transducers. This notion is defined based on the difference between
the minimal length descriptional complexity of strings from the perspective of
finite-state transducers and pebble transducers. Our notion of pebble-depth
satisfies the three fundamental properties of depth: i.e. easy sequences and
random sequences are not deep, and the existence of a slow growth law. We also
compare pebble-depth to other depth notions based on finite-state transducers,
pushdown compressors and the Lempel-Ziv $78$ compression algorithm. We first
demonstrate how there exists a normal pebble-deep sequence even though there is
no normal finite-state-deep sequence. We next build a sequence which has a
pebble-depth level of roughly $1$, a pushdown-depth level of roughly $1/2$ and
a finite-state-depth level of roughly $0$. We then build a sequence which has
pebble-depth level of roughly $1/2$ and Lempel-Ziv-depth level of roughly $0$.
</p></div>
    </summary>
    <updated>2020-09-28T23:20:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12205</id>
    <link href="http://arxiv.org/abs/2009.12205" rel="alternate" type="text/html"/>
    <title>A Note on Toroidal Maxwell-Cremona Correspondences</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Patrick.html">Patrick Lin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12205">PDF</a><br/><b>Abstract: </b>We explore toroidal analogues of the Maxwell-Cremona correspondence. Erickson
and Lin [<a href="http://export.arxiv.org/abs/2003.10057">arXiv:2003.10057</a>] showed the following correspondence for geodesic
torus graphs $G$: a positive equilibrium stress for $G$, an orthogonal
embedding of its dual graph $G^*$, and vertex weights such that $G$ is the
intrinsic weighted Delaunay graph of its vertices. We extend their results to
equilibrium stresses that are not necessarily positive, which correspond to
orthogonal drawings of $G^*$ that are not necessarily embeddings. We also give
a correspondence between equilibrium stresses and parallel drawings of the
dual.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12184</id>
    <link href="http://arxiv.org/abs/2009.12184" rel="alternate" type="text/html"/>
    <title>Finding a Maximum Minimal Separator: Graph Classes and Fixed-Parameter Tractability</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yagita:Tsuyoshi.html">Tsuyoshi Yagita</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12184">PDF</a><br/><b>Abstract: </b>We study the problem of finding a maximum cardinality minimal separator of a
graph. This problem is known to be NP-hard even for bipartite graphs. In this
paper, we strengthen this hardness by showing that for planar bipartite graphs,
the problem remains NP-hard. Moreover, for co-bipartite graphs and for line
graphs, the problem also remains NP-hard. On the positive side, we give an
algorithm deciding whether an input graph has a minimal separator of size at
least $k$ that runs in time $2^{O(k)}n^{O(1)}$. We further show that a
subexponential parameterized algorithm does not exist unless the Exponential
Time Hypothesis (ETH) fails. Finally, we discuss a lower bound for polynomial
kernelizations of this problem.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12127</id>
    <link href="http://arxiv.org/abs/2009.12127" rel="alternate" type="text/html"/>
    <title>The birth of the strong components</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panafieu:=Eacute=lie_de.html">Élie de Panafieu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dovgal:Sergey.html">Sergey Dovgal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ralaivaosaona:Dimbinaina.html">Dimbinaina Ralaivaosaona</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rasendrahasina:Vonjy.html">Vonjy Rasendrahasina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Stephan.html">Stephan Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12127">PDF</a><br/><b>Abstract: </b>Random directed graphs $D(n,p)$ undergo a phase transition around the point
$p = 1/n$, and the width of the transition window has been known since the
works of Luczak and Seierstad. They have established that as $n \to \infty$
when $p = (1 + \mu n^{-1/3})/n$, the asymptotic probability that the strongly
connected components of a random directed graph are only cycles and single
vertices decreases from 1 to 0 as $\mu$ goes from $-\infty$ to $\infty$.
</p>
<p>By using techniques from analytic combinatorics, we establish the exact
limiting value of this probability as a function of $\mu$ and provide more
properties of the structure of a random digraph around, below and above its
transition point. We obtain the limiting probability that a random digraph is
acyclic and the probability that it has one strongly connected complex
component with a given difference between the number of edges and vertices
(called excess). Our result can be extended to the case of several complex
components with given excesses as well in the whole range of sparse digraphs.
</p>
<p>Our study is based on a general symbolic method which can deal with a great
variety of possible digraph families, and a version of the saddle-point method
which can be systematically applied to the complex contour integrals appearing
from the symbolic method. While the technically easiest model is the model of
random multidigraphs, in which multiple edges are allowed, and where edge
multiplicities are sampled independently according to a Poisson distribution
with a fixed parameter $p$, we also show how to systematically approach the
family of simple digraphs, where multiple edges are forbidden, and where
2-cycles are either allowed or not.
</p>
<p>Our theoretical predictions are supported by numerical simulations, and we
provide tables of numerical values for the integrals of Airy functions that
appear in this study.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12080</id>
    <link href="http://arxiv.org/abs/2009.12080" rel="alternate" type="text/html"/>
    <title>Computing the covering radius of a polytope with an application to lonely runners</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cslovjecsek:Jana.html">Jana Cslovjecsek</a>, Romanos Diogenes Malikiosis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nasz=oacute=di:M=aacute=rton.html">Márton Naszódi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schymura:Matthias.html">Matthias Schymura</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12080">PDF</a><br/><b>Abstract: </b>We are concerned with the computational problem of determining the covering
radius of a rational polytope. This parameter is defined as the minimal
dilation factor that is needed for the lattice translates of the
correspondingly dilated polytope to cover the whole space. As our main result,
we describe a new algorithm for this problem, which is simpler, more efficient
and easier to implement than the only prior algorithm of Kannan (1992).
Motivated by a variant of the famous Lonely Runner Conjecture, we use its
geometric interpretation in terms of covering radii of zonotopes, and apply our
algorithm to prove the first open case of three runners with individual
starting points.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12022</id>
    <link href="http://arxiv.org/abs/2009.12022" rel="alternate" type="text/html"/>
    <title>Online Hypergraph Matching with Delays</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavone:Marco.html">Marco Pavone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saberi:Amin.html">Amin Saberi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schiffer:Maximilian.html">Maximilian Schiffer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsao:Matthew.html">Matthew Tsao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12022">PDF</a><br/><b>Abstract: </b>We study an online hypergraph matching problem with delays, motivated by
ridesharing applications. In this model, users enter a marketplace
sequentially, and are willing to wait up to $d$ timesteps to be matched, after
which they will leave the system in favor of an outside option. A platform can
match groups of up to $k$ users together, indicating that they will share a
ride. Each group of users yields a match value depending on how compatible they
are with one another. As an example, in ridesharing, $k$ is the capacity of the
service vehicles, and $d$ is the amount of time a user is willing to wait for a
driver to be matched to them.
</p>
<p>We present results for both the utility maximization and cost minimization
variants of the problem. In the utility maximization setting, the optimal
competitive ratio is $\frac{1}{d}$ whenever $k \geq 3$, and is achievable in
polynomial-time for any fixed $k$. In the cost minimization variation, when $k
= 2$, the optimal competitive ratio for deterministic algorithms is
$\frac{3}{2}$ and is achieved by a polynomial-time thresholding algorithm. When
$k&gt;2$, we show that a polynomial-time randomized batching algorithm is $(2 -
\frac{1}{d}) \log k$-competitive, and it is NP-hard to achieve a competitive
ratio better than $\log k - O (\log \log k)$.
</p></div>
    </summary>
    <updated>2020-09-28T23:24:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.11867</id>
    <link href="http://arxiv.org/abs/2009.11867" rel="alternate" type="text/html"/>
    <title>The Affiliate Matching Problem: On Labor Markets where Firms are Also Interested in the Placement of Previous Workers</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dooley:Samuel.html">Samuel Dooley</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dickerson:John_P=.html">John P. Dickerson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.11867">PDF</a><br/><b>Abstract: </b>In many labor markets, workers and firms are connected via affiliative
relationships. A management consulting firm wishes to both accept the best new
workers but also place its current affiliated workers at strong firms.
Similarly, a research university wishes to hire strong job market candidates
while also placing its own candidates at strong peer universities. We model
this affiliate matching problem in a generalization of the classic stable
marriage setting by permitting firms to state preferences over not just which
workers to whom they are matched, but also to which firms their affiliated
workers are matched. Based on results from a human survey, we find that
participants (acting as firms) give preference to their own affiliate workers
in surprising ways that violate some assumptions of the classical stable
marriage problem. This motivates a nuanced discussion of how stability could be
defined in affiliate matching problems; we give an example of a marketplace
which admits a stable match under one natural definition of stability, and does
not for that same marketplace under a different, but still natural, definition.
We conclude by setting a research agenda toward the creation of a centralized
clearing mechanism in this general setting.
</p></div>
    </summary>
    <updated>2020-09-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.11852</id>
    <link href="http://arxiv.org/abs/2009.11852" rel="alternate" type="text/html"/>
    <title>Learning Equality Constraints for Motion Planning on Manifolds</title>
    <feedworld_mtime>1601251200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sutanto:Giovanni.html">Giovanni Sutanto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fern=aacute=ndez:Isabel_M=_Rayas.html">Isabel M. Rayas Fernández</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Englert:Peter.html">Peter Englert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramachandran:Ragesh_K=.html">Ragesh K. Ramachandran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sukhatme:Gaurav_S=.html">Gaurav S. Sukhatme</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.11852">PDF</a><br/><b>Abstract: </b>Constrained robot motion planning is a widely used technique to solve complex
robot tasks. We consider the problem of learning representations of constraints
from demonstrations with a deep neural network, which we call Equality
Constraint Manifold Neural Network (ECoMaNN). The key idea is to learn a
level-set function of the constraint suitable for integration into a
constrained sampling-based motion planner. Learning proceeds by aligning
subspaces in the network with subspaces of the data. We combine both learned
constraints and analytically described constraints into the planner and use a
projection-based strategy to find valid points. We evaluate ECoMaNN on its
representation capabilities of constraint manifolds, the impact of its
individual loss terms, and the motions produced when incorporated into a
planner.
</p></div>
    </summary>
    <updated>2020-09-28T23:33:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=473</id>
    <link href="https://tcsplus.wordpress.com/2020/09/27/tcs-talk-wednesday-september-30-alex-wein-nyu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 30 — Alex Wein, NYU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Alex Wein from NYU will speak about “Low-Degree Hardness of Random Optimization Problems” (abstract below). You can reserve a spot as an individual or a group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Alex Wein</strong> from NYU will speak about “<em>Low-Degree Hardness of Random Optimization Problems</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our  website</a> on the day of the talk, so people who did not sign up will still be able to  watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: In high-dimensional statistical problems (including planted clique, sparse PCA, community detection, etc.), the class of “low-degree polynomial algorithms” captures many leading algorithmic paradigms such as spectral methods, approximate message passing, and local algorithms on sparse graphs. As such, lower bounds against low-degree algorithms constitute concrete evidence for average-case hardness of statistical problems. This method has been widely successful at explaining and predicting statistical-to-computational gaps in these settings. <br/>While prior work has understood the power of low-degree algorithms for problems with a “planted” signal, we consider here the setting of “random optimization problems” (with no planted signal), including the problem of finding a large independent set in a random graph, as well as the problem of optimizing the Hamiltonian of mean-field spin glass models. I will define low-degree algorithms in this setting, argue that they capture the best known algorithms, and explain new proof techniques for giving lower bounds against low-degree algorithms in this setting. The proof involves a variant of the so-called “overlap gap property”, which is a structural property of the solution space.<br/><br/>Based on joint work with David Gamarnik and Aukosh Jagannath, available at <a href="https://arxiv.org/abs/2004.12063">arXiv:2004.12063</a>.</p></div>
    </content>
    <updated>2020-09-27T17:15:50Z</updated>
    <published>2020-09-27T17:15:50Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-09-29T03:21:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17636</id>
    <link href="https://rjlipton.wordpress.com/2020/09/27/ibm-conference-on-the-informational-lens/" rel="alternate" type="text/html"/>
    <title>IBM Conference on the Informational Lens</title>
    <summary>Some differences from the Computational Lens Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The virtual workshop begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. Today we preview […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Some differences from the Computational Lens</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png"><img alt="" class="alignright wp-image-17638" height="193" src="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png?w=153&amp;h=193" width="153"/></a></p>
<p>
Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The <a href="https://sites.google.com/view/informational-lens-workshop-1/home">virtual workshop</a> begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. </p>
<p>
Today we preview the conference and discuss a few of the talks.</p>
<p>
The workshop’s name echoes the moniker “Through the Computational Lens” of <a href="https://simons.berkeley.edu/news/interdisciplinary-collaboration-at-simons">initiatives</a> led by the Simons Institute at Berkeley and used for a 2014 <a href="https://www.ias.edu/ideas/2015/computational-lens">workshop</a> organized by Avi Wigderson at IAS. A <a href="http://theory.cs.berkeley.edu/computational-lens.html">prospectus</a> by the theory group at U.C. Berkeley led off with quantum computing. So will Tuesday’s talks, a full day on quantum by seven leaders we say more about below.</p>
<p>
Then the meeting will branch in some different directions from the computational-lens themes. The preface on the workshop website says:</p>
<blockquote><p><b> </b> <em> Viewing the world through an informational lens, and understanding constraints and tradeoffs such as energy and parallelism versus reliability and speed, will have profound consequences throughout technology and science. This includes not only mathematics and the natural sciences like physics and biology, but also social sciences such as psychology and linguistics. We aim to bring together leading researchers in science and technology from across the globe to discuss ideas and future research directions through the informational lens. </em>
</p></blockquote>
<p/><p>
The other three days have talks that reach into all these areas, a dazzling array. We have made a collage of the twenty-six speakers currently listed on the schedule. Several faces are long familiar but others are novel to us.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/c1.png"><img alt="" class="aligncenter size-medium wp-image-17639" height="225" src="https://rjlipton.files.wordpress.com/2020/09/c1.png?w=300&amp;h=225" width="300"/></a></p>
<p>
</p><p/><h2> Quantum Tuesday </h2><p/>
<p/><p>
The opening morning has Alexander Holevo between Aram Harrow and Gil Kalai. Among many other accomplishments, Holevo is known for a <a href="https://en.wikipedia.org/wiki/Holevo's_theorem">theorem</a> that implies that <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits can yield at most <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits of classical information. In particular, any attempt to encode the edges of a general <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph via entanglements between pairs among <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits must be extremely lossy. He will talk about <em>quantum channels</em> and give a structure theorem for quantum Gaussian observables.</p>
<p>
We don’t have information yet on Aram’s talk. But Gil will update us on the state of his skepticism about the feasibility of large-scale quantum computing. This was the subject of the 2012 debate between Aram and Gil that <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">spanned</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">eight</a> <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">posts</a> on this blog. Here are Gil’s title and abstract:</p>
<p>
<font color="blue">Computational complexity, mathematical, and statistical aspects of NISQ computers.</font><br/>
<i>Noisy Intermediate-Scale Quantum (NISQ) Computers hold the key for important theoretical and experimental questions regarding quantum computers. In the lecture I will describe some questions about computational complexity, mathematics, and statistics which arose in my study of NISQ systems and are related to: <br/>
a) My general argument “against” quantum computers, <br/>
b) My analysis (with Yosi Rinot and Tomer Shoham) of the Google 2019 “huge quantum advantage” experiment. </i></p>
<p>
IBM have expressed their own skepticism of Google’s claims, which we mentioned in our own <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">review</a> of the experiment last year. IBM of course also have their own quantum computing initiative.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/q.jpeg"><img alt="" class="aligncenter size-medium wp-image-17640" height="169" src="https://rjlipton.files.wordpress.com/2020/09/q.jpeg?w=300&amp;h=169" width="300"/></a></p>
<p>
We may hear about its state from Charlie Bennett, whose talk leads off the afternoon but has yet to be measured, along with the following talk by Isaac Chuang. Then will come Scott Aaronson. If “tomography” in his title sounds to you like a <a href="https://en.wikipedia.org/wiki/CT_scan">CAT scan</a>, you could consider this a “Schrödinger’s Cat” scan. Well, we should let Scott tell it—the 2018 paper he mentions is <a href="https://arxiv.org/abs/1711.01053">this</a>.</p>
<p>
<font color="red">Shadow Tomography of Quantum States: Progress and Prospects. </font><br/>
<i>Given an unknown quantum state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, and a known list of two-outcome measurements <img alt="{E_1,...,E_M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_1%2C...%2CE_M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_1,...,E_M}"/>, “shadow tomography” is the task of estimating the probability that each <img alt="{E_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_i}"/> accepts <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, by carefully measuring only a few copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>. In 2018, I gave the first nontrivial protocol for this task. In 2019, Guy Rothblum and I exploited a new connection between gentle measurement of quantum states and the field of differential privacy, to give a protocol that requires fewer copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> in some cases, and has the additional advantage of being online (that is, the measurements are processed one at a time). Huge challenges remain in making shadow tomography practical with near-term devices; extremely recently Huang, Kueng, and Preskill took some promising steps in that direction. I’ll survey these developments and the challenges that remain.</i> </p>
<p>
Then Srinivasan Arunachalam, who also works at IBM T.J. Watson in Westchester, NY, will finish the day with another talk about inferring from samples:</p>
<p>
<font color="blue">Sample-efficient learning of quantum many-body systems.</font><br/>
<i>We study the problem of learning the Hamiltonian of a quantum many-body system given samples from its Gibbs (thermal) state. The classical analog of this problem, known as learning graphical models or Boltzmann machines, is a well-studied question in machine learning and statistics. In this work, we give the first sample-efficient algorithm for the quantum Hamiltonian learning problem. In particular, we prove that polynomially many samples in the number of particles (qudits) are necessary and sufficient for learning the parameters of a spatially local Hamiltonian in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-norm. Our main contribution is in establishing the strong convexity of the log-partition function of quantum many-body systems, which along with the maximum entropy estimation yields our sample-efficient algorithm. Our work paves the way toward a more rigorous application of machine learning techniques to quantum many-body problems.</i></p>
<p>
</p><p/><h2> B.Y.O.L. </h2><p/>
<p/><p>
The workshop has lunch breaks as usual but they are not lunch breaks. Lunch is served at IBM T.J. Watson, and I (Ken) can vouch from times I have been hosted there by Jon Lenchner that the food is wonderful, but attendees will not be on hand to partake. I have known Jon since we were part of the New York area chess scene in the 1970s. Among Jon’s activities in the past five years have been directing IBM’s research center in Nairobi, Kenya, and helping the Toronto Raptors assemble a championship basketball team via player analytics. The latter is not technically related to my chess analytics, but we have greater shared interests in ideas for lower bounds on uniform complexity classes.</p>
<p>
Instead of physical lunch, the lunch breaks are moderated panel discussions. So you can bring your own lunch while watching and listening via IBM’s WebEx or other portal. Maybe there will be time for remote attendees to ask questions—though not with your mouth full, as our mothers would say. A few years ago, my department began running catered Friday lunch forums under the name “UpBeat,” but those too are now remote and B.Y.O.L.  As for the other thing the “L.” can stand for besides “lunch,” we can mention that the pandemic has rendered onsite restrictions moot.</p>
<p>
There will also be Q &amp; A and panel discussion sessions for 45 minutes after each day’s last talk. </p>
<p>
</p><p/><h2> Some Other Talks </h2><p/>
<p/><p>
We wish we could attend all the talks. We imagine they will be available afterward as recordings, but especially when there is live Q &amp; A it is nice to experience them in the moment as at a physically intimate workshop. Rather than list all the speakers and titles here—you can find them on the abstracts <a href="https://sites.google.com/view/informational-lens-workshop-1/talk-abstracts">page</a>, after all—we will just highlight a few that catch our eye:</p>
<p>
<font color="red">Fun facts about polynomials, and applications to coding theory: Mary Wootters. </font><br/>
<i>Here are some (fun?) facts about polynomials you probably already know. First, given any three points, you can find a parabola through them. Second, if you look at any vertical “slice” of a paraboloid, you get a parabola. These facts, while simple, turn out to be extremely useful in applications! For example, these facts are behind the efficacy of classical Reed-Solomon and Reed-Muller codes, fundamental tools for communication and storage. But this talk is not about those facts — it’s about a few related facts that you might not know. Given less than three points’ worth of information, what can you learn about a parabola going through those points? Are there things other than paraboloids that you can “slice” and always get parabolas? In this talk, I will tell you some (fun!) facts that answer these questions, and discuss applications to error correcting codes.</i></p>
<p>
<font color="blue">Punch Cards and the Difference Engine: William Gibson and Bruce Sterling. </font><br/>
<i>We discuss the <a href="https://en.wikipedia.org/wiki/The_Difference_Engine">power</a> of the card concept. By storing a finite amount of data on a “punch card” we can structure data handling to be straightforward and safe. The machine we plan will be thousands of times slower than even the first vacuum-tube computers were. But our novel use of steam and punch cards does have merits: cards are physical and help solve security and also privacy issues.</i></p>
<p>
<font color="red">Reasoning about Generalization via Conditional Mutual Information: Lydia Zakynthinou. </font><br/>
<i>We provide a framework for studying the generalization properties of machine learning algorithms, which ties together existing approaches, using the unifying language of information theory. We introduce a new notion based on Conditional Mutual Information (CMI) which quantifies how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. Bounds on CMI can be obtained from several methods, including VC dimension, compression schemes, and differential privacy, and bounded CMI implies various forms of generalization guarantees. In this talk, I will introduce CMI, show how to obtain bounds on CMI from existing methods and generalization bounds from CMI, and discuss the capabilities of our framework. Joint work with Thomas Steinke.</i></p>
<p>
<font color="blue">Rebooting Mathematics: Doron Zeilberger. </font><br/>
<i>Mathematics is what it is today due to the accidental fact that it was developed before the invention of the computer, and, with a few exceptions, continues in the same vein, by inertia. It is time to start all over, remembering that math, is, or at least should be, the math that can be handled by computers, keeping in mind that they are both discrete and finite.</i></p>
<p>
Oh wait, one of these talks is both less novel and more <a href="https://www.amazon.com/Difference-Engine-Novel-William-Gibson/dp/0440423627">novel</a> than the others.  Can a virtual workshop have a virtual virtual talk?  The cards were arguably “the” informational lens for almost 100 years.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What have been your experiences with top-of-the-line virtual workshops? Our hats are off to the organizers of this one, and we are looking forward to it.</p>
<p/></font></font></div>
    </content>
    <updated>2020-09-27T15:24:46Z</updated>
    <published>2020-09-27T15:24:46Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="Aram Harrow"/>
    <category term="Chai Wah Wu"/>
    <category term="Charles Bennett"/>
    <category term="debate"/>
    <category term="Gil Kalai"/>
    <category term="IBM"/>
    <category term="informational lens"/>
    <category term="Jonathan Lenchner"/>
    <category term="Physics"/>
    <category term="quantum"/>
    <category term="workshop"/>
    <category term="Yuhai Tu"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-29T03:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=63</id>
    <link href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Friday, Oct 09 — Alexandr Andoni from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  Alexandr Andoni from Columbia University will speak about “Approximating Edit Distance in Near-Linear Time”. Abstract: Edit distance is a classic measure of similarity between strings, with<a class="more-link" href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/">Continue reading <span class="screen-reader-text">"Friday, Oct 09 — Alexandr Andoni from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  <strong>Alexandr Andoni </strong>from Columbia University will speak about “<em><strong>Approximating Edit Distance in Near-Linear Time</strong></em>”.</p>



<p><strong>Abstract</strong>: Edit distance is a classic measure of similarity between strings, with applications ranging from computational biology to coding. Computing edit distance is also a classic dynamic programming problem, with a quadratic run-time solution, often taught in the “Intro to Algorithms” classes. Improving this runtime has been a decades-old challenge, now ruled likely-impossible using tools from the modern area of fine-grained complexity. We show how to approximate the edit distance between two strings in near-linear time, up to a constant factor. Our result completes a research direction set forth in the breakthrough paper of [Chakraborty, Das, Goldenberg, Koucky, Saks; FOCS’18], which showed the first constant-factor approximation algorithm with a (strongly) sub-quadratic running time.</p>



<p>Joint work with Negev Shekel Nosatzki, available at<a href="https://arxiv.org/abs/2005.07678"> https://arxiv.org/abs/2005.07678</a>.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-09-26T15:46:40Z</updated>
    <published>2020-09-26T15:46:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-09-29T03:22:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by October 1, 2020)</title>
    <summary>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams. Website: https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/ Email: monika.henzinger@univie.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams.</p>
<p>Website: <a href="https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/">https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2020-09-25T07:23:35Z</updated>
    <published>2020-09-25T07:23:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T03:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/147</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/147" rel="alternate" type="text/html"/>
    <title>TR20-147 |  Batch Verification for Statistical Zero Knowledge Proofs | 

	Inbar Kaslasi, 

	Guy Rothblum, 

	Ron Rothblum, 

	Adam Sealfon, 

	Prashant Nalini Vasudevan</title>
    <summary>A statistical zero-knowledge proof (SZK) for a problem $\Pi$ enables a computationally unbounded prover to convince a polynomial-time verifier that $x \in \Pi$ without revealing any additional information about $x$ to the verifier, in a strong information-theoretic sense.

Suppose, however, that the prover wishes to convince the verifier that $k$ separate inputs $x_1,\dots,x_k$ all belong to $\Pi$ (without revealing anything else). A naive way of doing so is to simply run the SZK protocol separately for each input. In this work we ask whether one can do better -- that is, is efficient batch verification possible for SZK?

We give a partial positive answer to this question by constructing a batch verification protocol for a natural and important subclass of SZK -- all problems $\Pi$ that have a non-interactive SZK protocol (in the common random string model). More specifically, we show that, for every such problem $\Pi$, there exists an honest-verifier SZK protocol for batch verification of $k$ instances, with communication complexity $poly(n) + k \cdot poly(\log{n},\log{k})$, where $poly$ refers to a fixed polynomial that depends only on $\Pi$ (and not on $k$). This result should be contrasted with the naive solution, which has communication complexity $k \cdot poly(n)$.

Our proof leverages a new NISZK-complete problem, called Approximate Injectivity, that we find to be of independent interest. The goal in this problem is to distinguish circuits that are nearly injective, from those that are non-injective on almost all inputs.</summary>
    <updated>2020-09-24T13:41:26Z</updated>
    <published>2020-09-24T13:41:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T03:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/146</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/146" rel="alternate" type="text/html"/>
    <title>TR20-146 |  On the Hardness of Detecting Macroscopic Superpositions | 

	Scott Aaronson, 

	Yosi Atia, 

	Leonard Susskind</title>
    <summary>When is decoherence "effectively irreversible"? Here we examine this central question of quantum foundations using the tools of quantum computational complexity. We prove that, if one had a quantum circuit to determine if a system was in an equal superposition of two orthogonal states (for example, the $|$Alive$\rangle$ and $|$Dead$\rangle$ states of Schrodinger's cat), then with only a slightly larger circuit, one could also $\mathit{swap}$ the two states (e.g., bring a dead cat back to life). In other words, observing interference between the $|$Alive$\rangle$and $|$Dead$\rangle$ states is a "necromancy-hard" problem, technologically infeasible in any world where death is permanent. As for the converse statement (i.e., ability to swap implies ability to detect interference), we show that it holds modulo a single exception, involving unitaries that (for example) map $|$Alive$\rangle$ to $|$Dead$\rangle$ but $|$Dead$\rangle$ to -$|$Alive$\rangle$. We also show that these statements are robust---i.e., even a $\mathit{partial}$ ability to observe interference implies partial swapping ability, and vice versa. Finally, without relying on any unproved complexity conjectures, we show that all of these results are quantitatively tight. Our results have possible implications for the state dependence of observables in quantum gravity, the subject that originally motivated this study.</summary>
    <updated>2020-09-23T22:45:17Z</updated>
    <published>2020-09-23T22:45:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T03:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/145</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/145" rel="alternate" type="text/html"/>
    <title>TR20-145 |  An Improved Exponential-Time Approximation Algorithm for Fully-Alternating Games Against Nature | 

	Andrew Drucker</title>
    <summary>"Games against Nature" [Papadimitriou '85] are two-player games of perfect information, in which one player's moves are made randomly (here, uniformly); the final payoff to the non-random player is given by some $[0, 1]$-valued function of the move history.  Estimating the value of such games under optimal play, and computing near-optimal strategies, is an important goal in the study of decision-making under uncertainty, and has seen significant research in AI and allied areas [Hnich, Rossi, Tarim, Prestwich '11], with only experimental evaluation of most algorithms' performance.  The problem's PSPACE-completeness does not rule out nontrivial algorithms.  Improved algorithms with theoretical guarantees are known in various cases where the payoff function $F$ has special structure, and Littman, Majercik, and Pitassi [LMP'01] give a sampling-based improved algorithm for general $F$, for turn-orders which restrict the number of non-random player strategies.

We study the case of general $F$ for which the players strictly alternate with binary moves $(w_1, r_1, w_2, r_2, \ldots, w_{n/2}, r_{n/2})$---for which the approach of [LMP'01] does not improve over brute force.  We give a randomized algorithm to approximate the value of such games under optimal play, and to execute near-optimal strategies. Our algorithm achieves exponential savings over brute-force, making $2^{(1 - \delta) n}$ queries to $F$ for some absolute constant $\delta &gt; 0$, and certifies a lower bound $\hat{v}$ on the game value $v$ with additive expected error bounded as $E[v - \hat{v}] \leq \exp(-\Omega(n))$.  (On the downside, $\delta$ is tiny and the algorithm uses exponential space.)

Our algorithm is recursive, and bootstraps a "base case" algorithm for fixed-size inputs.  The method of recursive composition used, the specific base-case guarantees needed, and the steps to establish these guarantees are interesting and, we feel, likely to find uses beyond the present work.</summary>
    <updated>2020-09-23T21:48:34Z</updated>
    <published>2020-09-23T21:48:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T03:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7113260074896603448</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7113260074896603448/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html" rel="alternate" type="text/html"/>
    <title>Remembering 2000</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://www.cs.cmu.edu/~FOCS2000/">FOCS 2000</a> took place in Redondo Beach, just south of Los Angeles, November 12-14. Certainly some great results such as the Reingold-Vadhan-Wigderson <a href="https://doi.org/10.1109/SFCS.2000.892006">Zig-Zag Graph Product Expander construction</a> that would lead to Omer Reingold's <a href="https://blog.computationalcomplexity.org/2014/02/favorite-theorems-connecting-in-log.html">Undirected Connectivity in Log Space</a>. Mostly though I remember the discussions about the presidential election held the week before and whether we might find out our next president during the conference. Spoiler alert: <a href="https://en.wikipedia.org/wiki/2000_United_States_presidential_election_recount_in_Florida">We didn't</a>. </p><p>Consider the following viewpoints for a person X</p><p>1. Did X support Bush or Gore?</p><p>2. Did X interpret the rules of the election that Bush won or Gore won?</p><p>These should be independent events. Your interpretation of the rules should not depend on who you supported. But in fact they were nearly perfectly correlated. Whether you were a politician, a newspaper editorial page writer, a supreme court justice, a computer scientist or pretty much everyone else, if you supported Gore, you believed he won the election and vice-versa. Everyone had their logic why they were right and I'm sure my readers who remember that election still believe their logic was correct. </p><p>As this upcoming election gets messy, as it already has, take care with trying to justify your desired endgame by choosing the logic that makes it work. Would you use the same logic if the candidates were reversed? Everyone says "yes" but it's rarely true. Just like Mitch McConnell, you'll just find some excuse why the opposite situation is different. Trust me, my logic is impeccable. </p></div>
    </content>
    <updated>2020-09-23T21:33:00Z</updated>
    <published>2020-09-23T21:33:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-28T23:09:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20259</id>
    <link href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 12:  Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Update (Sept. 28): Yuval Wigderson has made a further improvement on the multicolor Ramsey number bound for more than three colors. Lower bounds for multicolor Ramsey numbers The Ramsey number r(t; ℓ) is the smallest natural number n such that … <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="title mathjax"><strong>Update (Sept. 28):</strong> Yuval Wigderson <a href="https://arxiv.org/abs/2009.12020">has made a further improvement on the multicolor Ramsey number bound for more than three colors.</a></p>
<h2><a href="https://arxiv.org/abs/2009.10458">Lower bounds for multicolor Ramsey numbers</a></h2>
<p>The Ramsey number <em>r(t; ℓ)</em> is the smallest natural number <em>n</em> such that every ℓ-coloring of the edges of the complete graph <img alt="K_n" class="latex" src="https://s0.wp.com/latex.php?latex=K_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_n"/> contains a monochromatic <img alt="K_t" class="latex" src="https://s0.wp.com/latex.php?latex=K_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_t"/>. (<em>r(t;2)</em> is often denoted by<em> R(t,t)</em> and <em>r(t;3)</em> by R<em>(t,t,t)</em> etc.) <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Famously</a>, <em>R(3,3)=6</em>; <em>R(4,4)=18</em>;  and <em>R(3,3,3)=17</em>. Understanding <em>R(t,t)</em> is among the most famous problems in combinatorics. (Understanding if r(3; <em> ℓ</em>) is exponential or superexponential in<em> ℓ</em> is also a very famous problem.)</p>
<p>It is known since the 1940s that <img alt="t/2 +o(1) \le log_2 R(t,t) \le 2t" class="latex" src="https://s0.wp.com/latex.php?latex=t%2F2+%2Bo%281%29+%5Cle+log_2+R%28t%2Ct%29+%5Cle+2t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t/2 +o(1) \le log_2 R(t,t) \le 2t"/>.</p>
<p>Lower bounds for <em>R(t,t)</em> where used by Lefmann in 1987 to give lower bounds on <em>r(t; ℓ)</em> for <em> ℓ</em>&gt;2. Asaf Ferber and David Conlon gave now <span style="color: #ff0000;"><strong>exponential</strong></span> improvement. This is truly remarkable and <a href="https://arxiv.org/abs/2009.10458">the paper is just 4-page long!</a> congratulations Asaf and David!</p>
<p>Expect more cheering news of discrete geometry nature from Oberwolfach. (I take part remotely in the traditional meeting on Discrete and computational geometry, see pictures below).</p>
<p>Update (Sept 24.): <a href="https://anuragbishnoi.wordpress.com/2020/09/23/improved-lower-bounds-for-multicolour-diagonal-ramsey-numbers/">An excellent blog post on Anurag math blog.</a> Anurag describes in details the construction, describes the connections with finite geometries, and improves the construction to get a better result. (See also there many cool posts, e.g., an earlier post with some connections of finite geometries and different Ramsey problems <a href="https://anuragbishnoi.wordpress.com/2020/09/10/heisenberg-groups-irreducible-cubics-and-minimal-ramsey/" rel="bookmark">Heisenberg groups, irreducible cubics and minimal Ramsey</a>.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/09/pak.png"><img alt="" class="alignnone size-medium wp-image-20264" height="188" src="https://gilkalai.files.wordpress.com/2020/09/pak.png?w=300&amp;h=188" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2020/09/ow2.png"><img alt="" class="alignnone size-medium wp-image-20265" height="188" src="https://gilkalai.files.wordpress.com/2020/09/ow2.png?w=300&amp;h=188" width="300"/></a></p></div>
    </content>
    <updated>2020-09-23T11:24:44Z</updated>
    <published>2020-09-23T11:24:44Z</published>
    <category term="Combinatorics"/>
    <category term="Asaf Ferber"/>
    <category term="David Conlon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-09-29T03:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17612</id>
    <link href="https://rjlipton.wordpress.com/2020/09/22/puzzle-reviews-by-a-puzzle-writer/" rel="alternate" type="text/html"/>
    <title>Puzzle Reviews by a Puzzle Writer</title>
    <summary>Not puzzling reviews Princeton University Press page Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums. The former includes a neat paper on expansion properties of a family of graphs associated to block designs, with two undergraduates […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Not puzzling reviews</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg"><img alt="" class="alignright wp-image-17615" height="160" src="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg?w=140&amp;h=160" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Princeton University Press <a href="https://press.princeton.edu/our-authors/rosenhouse-jason">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums.  The former includes a neat <a href="https://www.researchgate.net/publication/220620901_Expansion_Properties_Of_Levi_Graphs">paper</a> on expansion properties of a family of graphs associated to block designs, with two undergraduates among its authors.  But besides his “real” research, he has written a number of books on puzzles such as <i><a href="https://www.amazon.com/s?k=Jason+Rosenhouse&amp;i=stripbooks&amp;ref=nb_sb_noss_2">The Monty Hall Problem</a>: The Remarkable Story of Math’s Most Contentious Brain Teaser</i>. Soon his book <i><a href="https://www.amazon.co.uk/Games-Your-Mind-History-Puzzles/dp/0691174075">Games for Your Mind</a>: The History and Future of Logic Puzzles</i> is to be published.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png"><img alt="" class="aligncenter size-thumbnail wp-image-17626" height="150" src="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png?w=103&amp;h=150" width="103"/></a></p>
<p>
Today Ken and I thought we would highlight his recent review of a book on math puzzles.<br/>
<span id="more-17612"/></p>
<p>
I have mixed feelings about puzzles. I like them, and am happy when I can understand their solution. I am even happier when I can solve them. I sometimes feel that I should spend my limited brain cycles on “real” problems. But puzzles are fun. </p>
<p>
Rosenhouse’s <a href="https://www.ams.org/journals/notices/202009/rnoti-p1382.pdf">review</a> is in the recent <em>Notices of the AMS</em> on the book <i><a href="https://bookstore.ams.org/prb-36">Bicycles or Unicycles</a>: A Collection of Intriguing Mathematical Puzzles</i>. This book, the “Bicycle Book,” is authored by Daniel Velleman and Stan Wagon.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg"><img alt="" class="aligncenter wp-image-17617" height="145" src="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg?w=101&amp;h=145" width="101"/></a></p>
<p>
Their book is a collection of <img alt="{3 \times 5 \times 7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+5+%5Ctimes+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 5 \times 7}"/> mathematical puzzles. Rosenhouse likes their book, which means a lot coming from an author of so many puzzle books himself. </p>
<p>
</p><p/><h2> A Cool Problem </h2><p/>
<p/><p>
Rosenhouse presents this problem from the Bicycle Book. </p>
<blockquote><p><b> </b> <em> You are playing solitaire in the first quadrant of the Cartesian plane, the lower corner of which is shown in Figure 1. You begin with a single checker on square a1. On each turn, a legal move consists of removing one checker from the board and then placing two new checkers in the cells immediately above and to the right of the original checker. If either of those two cells is occupied, then the move is illegal, and a different checker must be selected for removal. </em>
</p></blockquote>
<p/><p>
<a href="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png"><img alt="" class="aligncenter size-full wp-image-17618" src="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png?w=600"/></a></p>
<p>
Show that you can never make all of the <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> lower-left squares empty. This is a complexity question. You describe a computation and assert that certain states cannot be reached. The challenge is two-fold: </p>
<ol>
<li>
The computation is nondeterministic. There can be more than one next state. <p/>
</li><li>
The computation can reach infinitely many states. The task is to prove that no reachable state has the lower nine squares empty.
</li></ol>
<p>
</p><p/><h2> A Cool Solution </h2><p/>
<p/><p>
I must admit I read the solution before I tried to solve the puzzle. I did find an alternative solution. It was not as clever as the one from the book. Let’s look at that solution first. </p>
<p>
The idea is to assign <i>magic</i> values to each square on the checkerboard. The value of a state is the sum over all the values of squares with a checker. We need these to hold: </p>
<ol>
<li>
The value of the initial square is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. <p/>
</li><li>
The value of a move leaves the total sum over all the checkers the same. <p/>
</li><li>
The value of the squares <b>not</b> in the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> is less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>.
</li></ol>
<p>Then there can never be a reachable state that avoids all the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/>. How can we do this? Assign the values as shown below. </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccl%7D+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5C%5C+1%2F8+%26+1%2F16+%26+1%2F32+%26+1%2F64+%26+%5Ccdots%5C%5C+1%2F4+%26+1%2F8+%26+1%2F16+%26+1%2F32+%26+%5Ccdots%5C%5C+1%2F2+%26+1%2F4+%26+1%2F8+%26+1%2F16+%26+%5Ccdots%5C%5C+1+%26+1%2F2+%26+1%2F4+%26+1%2F8+%26+%5Ccdots+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} "/></p>
<p>
Ken remembers, as a teenager, seeing this puzzle in a collection by the master Martin Gardner, with the same proof. Ken thought of it again when considering problems in physics and combinatorics that involve defining an appropriate potential function as the first step. </p>
<p>
</p><p/><h2> An Uncool Solution </h2><p/>
<p/><p>
Let <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> be the lower-right <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> corner board. Label the positions as usual with <img alt="{(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j)}"/> where <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> both are in <img alt="{\{1,2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,3\}}"/>.</p>
<p>
Let <img alt="{N(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)}"/> be the number of checkers in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. Of course <img alt="{N(0)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%280%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(0)=1}"/> and the checker is at <img alt="{(1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1,1)}"/>.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg"><img alt="" class="aligncenter wp-image-17621" height="107" src="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg?w=150&amp;h=107" width="150"/></a></p>
<p>
Suppose by way of contradiction that it is possible to make <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> empty. </p>
<p>
Our proof uses that the transition from <img alt="{N(t)&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)&gt;0}"/> to <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/> requires that <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/>. That is <img alt="{N(t)=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=2}"/> or even <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> is impossible. The rule cannot remove two or more checkers from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in one move. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg"><img alt="" class="aligncenter wp-image-17622" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg?w=150&amp;h=97" width="150"/></a></p>
<p>
Let <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/> and <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/>. So where is the checker? A simple case analysis shows it must be at <img alt="{(3,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,3)}"/>. So now we know the last placement. But how did we get to this position? It is easy to see that it had to be previously at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> or <img alt="{(2,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%282%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(2,3)}"/>. By symmetry we can assume was <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/>. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg"><img alt="" class="aligncenter wp-image-17623" height="98" src="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg?w=150&amp;h=98" width="150"/></a></p>
<p>
Our goal to show that we cannot place one checker at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> and no other in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. A little analysis shows that it must be the case that the previous state was one checker at <img alt="{(3,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,1)}"/>. But it is impossible to place a checker there and avoid having more checkers. This yields a contradiction. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg"><img alt="" class="aligncenter wp-image-17624" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg?w=150&amp;h=97" width="150"/></a></p>
<p/><h2> Another Solution </h2><p/>
<p/><p>
We could use finite state automata theory to supply another solution. The obvious issue is the full game is played on an infinite checkerboard. But we can use a standard trick to reduce the state space to a finite one. Imagine we play the game on just <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. When we have a move that creates checkers outside of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> just throw them away. It is simple to see that no move can place checkers inside <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Thus if we cannot empty <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in this finite version, then there is no way in the full game. </p>
<p>
Now the state space is bounded by <img alt="{2^{9}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B9%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{9}}"/>: each of the nine squares can have a checker or not. We know the initial state and we know the final state. So we can run a finite state search algorithm and decide the answer.</p>
<p>
The value of this solution is that it could handle more complex rules and larger squares. Well at least those within reason. </p>
<p>
</p><p/><h2> Other Puzzles </h2><p/>
<p/><p>
Rosenhouse covers nine other puzzles in his review. In our meta review of his review we will cover just two more. </p>
<p>
The third puzzle in his review comes from the challenge to prove that each matrix in a certain family <img alt="{\{C_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BC_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{C_n\}}"/> has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The particular matrices <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> look like they could have some strange determinant, one that even varies with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. The trick is to show that there are other families <img alt="{\{A_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BA_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{A_n\}}"/> and <img alt="{\{B_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_n\}}"/> of matrices, in which each matrix has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> and that 	</p>
<p align="center"><img alt="\displaystyle  C_n = A_n B_n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C_n+%3D+A_n+B_n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C_n = A_n B_n. "/></p>
<p>Of course this immediately proves that <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> also have determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The challenge is kind of a factorization problem. </p>
<p>
Another puzzle is to prove that a number <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime if and only if there is exactly one pair of positive integers <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/> such that </p>
<p align="center"><img alt="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bm%7D+-+%5Cfrac%7B1%7D%7Bn%7D+%3D+%5Cfrac%7B1%7D%7Bp%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. "/></p>
<p>This seems to be surprising in two ways: First who could think of this? Second who could think of this? Okay it should be why is it true? Indeed Rosenhouse says that the proof is complex. </p>
<p>
Rosenhouse adds that most puzzles in this book are less “bite-sized” than the ones typically posed by the master Gardner. This certainly goes for the title puzzle about whether a bicycle can possibly move along a curve—other than a straight line—that was made by a unicycle. It requires a foray into differential equations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
My “uncool solution” was left somewhat incomplete. Do you see how to complete the analysis?</p>
<p>
[some word fixes]</p></font></font></div>
    </content>
    <updated>2020-09-22T22:01:06Z</updated>
    <published>2020-09-22T22:01:06Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="book reviews"/>
    <category term="Daniel Velleman"/>
    <category term="Jason Rosenhouse"/>
    <category term="puzzles"/>
    <category term="Stan Wagon"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-29T03:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/144</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/144" rel="alternate" type="text/html"/>
    <title>TR20-144 |  Toward Probabilistic Checking against Non-Signaling Strategies with Constant Locality | 

	Mohammad Jahanara, 

	Sajin Koroth, 

	Igor Shinkar</title>
    <summary>Non-signaling strategies are a generalization of quantum strategies that have been studied in physics over the past three decades. Recently, they have found applications in theoretical computer science, including to proving inapproximability results for linear programming and to constructing protocols for delegating computation. A central tool for these applications is probabilistically checkable proof (PCPs) systems that are sound against non-signaling strategies.

In this paper we show, assuming a certain geometrical hypothesis about noise robustness of non-signaling proofs (or, equivalently, about robustness to noise of solutions to the Sherali-Adams linear program), that a slight variant of the parallel repetition of the exponential-length constant-query PCP construction due to Arora et al. (JACM 1998) is sound against non-signaling strategies with constant locality.

Our proof relies on the analysis of the linearity test and agreement test (also known as the direct product test) in the non-signaling setting.</summary>
    <updated>2020-09-22T11:49:39Z</updated>
    <published>2020-09-22T11:49:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T03:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/143</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/143" rel="alternate" type="text/html"/>
    <title>TR20-143 |  Characterizing Average-Case Complexity of PH by Worst-Case Meta-Complexity | 

	Shuichi Hirahara</title>
    <summary>We exactly characterize the average-case complexity of the polynomial-time hierarchy (PH) by the worst-case (meta-)complexity of GapMINKT(PH), i.e., an approximation version of the problem of determining if a given string can be compressed to a short PH-oracle efficient program.  Specifically, we establish the following equivalence:

  DistPH is contained in AvgP (i.e., PH is easy on average) if and only if GapMINKT(PH) is in P.

In fact, our equivalence is significantly broad: A number of statements on several fundamental notions of complexity theory, such as errorless and one-sided-error average-case complexity, sublinear-time-bounded and polynomial-time-bounded Kolmogorov complexity, and PH-computable hitting set generators, are all shown to be equivalent.

Our equivalence provides fundamentally new proof techniques for analyzing average-case complexity through the lens of *meta-complexity* of time-bounded Kolmogorov complexity and resolves, as immediate corollaries, questions of equivalence among different notions of average-case complexity of PH: low success versus high success probabilities (i.e., a hardness amplification theorem for DistPH against uniform algorithms) and errorless versus one-sided-error average-case complexity of PH.

Our results are based on a sequence of new technical results that further develops the proof techniques of the author's previous work on the non-black-box worst-case to average-case reduction and unexpected hardness results for Kolmogorov complexity (FOCS'18, CCC'20, ITCS'20, STOC'20).  Among other things, we prove the following.

  1.  If GapMINKT(NP) is in P, then P = BPP.
  At the core of the proof is a new black-box hitting set generator construction whose reconstruction algorithm uses few random bits, which also improves the approximation quality of the non-black-box worst-case to average-case reduction without using a pseudorandom generator.

  2.  If GapMINKT(PH) is in P, then DistPH is contained in AvgBPP = AvgP.

  3.  If MINKT(PH) is easy on a 1/poly(n)-fraction of inputs, then GapMINKT(PH) is in P.
  This improves the error tolerance of the previous non-black-box worst-case to average-case reduction.</summary>
    <updated>2020-09-21T10:16:37Z</updated>
    <published>2020-09-21T10:16:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T03:20:40Z</updated>
    </source>
  </entry>
</feed>
