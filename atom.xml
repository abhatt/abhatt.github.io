<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-04-18T21:21:34Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4286404438772500234</id>
    <link href="http://processalgebra.blogspot.com/feeds/4286404438772500234/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4286404438772500234" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-complexity-of-identifying.html" rel="alternate" type="text/html"/>
    <title>The Complexity of Identifying Characteristic Formulae</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the classic results in concurrency theory is the Hennessy-Milner Theorem. This result states that<br/><ol><li>two bisimilar states in a labelled transition system satisfy exactly the same formulae in a multi-modal logic now called Hennessy-Milner logic, and </li><li>two states in a labelled transition system that satisfy a mild finiteness constraint (called image finiteness)  and enjoy the same properties expressible in Hennessy-Milner logic are bisimilar.</li></ol>See, for instance, Section 1.2 in <a href="http://homepages.inf.ed.ac.uk/cps/chapbisim.pdf">these notes by Colin Stirling</a> for an exposition of that result. A consequence of the Hennessy-Milner Theorem is that whenever two states <i>p </i>and <i>q </i>in a labelled transition system are <i>not</i> bisimilar, one can come up with a formula in Hennessy-Milner logic that <i>p </i>satisfies, but<i> q </i>does not<i>. </i>Moreover, for each state <i>p </i>in a finite, loop-free labelled transition systems, it is possible to construct a formula <i>F(p) </i>in Hennessy-Milner logic that completely characterizes <i>p</i> up to bisimilarity. This means that, for each state <i>q</i>, <i>p</i> is bisimilar to <i>q</i> if, and only if, <i>q</i> satisfies <i>F(p)</i>. The formula<i> F(p) </i>is called a characteristic formula for<i> p </i>up to bisimilarity.<i> </i>One can obtain a similar result for states in finite labelled transition systems by extending Hennessy-Milner logic with greatest fixed points. <i><br/></i><br/><br/>Characteristic formulae have a long history in concurrency theory. However, to be best of my knowledge, the complexity of determining whether a formula is characteristic had not been studied before <a href="https://sites.google.com/view/antonisachilleos">Antonis Achilleos</a> first addressed the problem in <a href="https://arxiv.org/abs/1605.01004">this conference paper</a>. In that paper, Antonis focused on the complexity of the problem of determining whether a formula <i>F</i> is complete, in the sense that, for each formula <i>G</i>, it can derive either <i>G</i> or its negation.<br/><br/>Our recent preprint    <a href="http://icetcs.ru.is/theofomon/CharFormComplexity.pdf"><i>The   Complexity of Identifying Characteristic Formulae</i></a> extends the results originally obtained by Antonis to a variety of modal logics, possibly including least and greatest fixed-point operators. In the paper, we show that completeness, characterization, and validity have the same complexity — with some exceptions for which there are, in general, no complete formulae. So, for most modal logics of interest, the problem is coNP-complete or PSPACE-complete, and becomes EXPTIME-complete for modal logics with fixed points. To prove our upper bounds, we present a nondeterministic procedure with an oracle for validity that combines tableaux and a test for bisimilarity, and determines whether a formula is complete.<br/><br/>I think that there is still a lot of work that can be done in studying this problem, with respect to a variety of other notions of equivalence considered in concurrency theory, so stay tuned for further updates. </div>
    </content>
    <updated>2019-04-18T17:19:00Z</updated>
    <published>2019-04-18T17:19:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-04-18T17:19:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/060" rel="alternate" type="text/html"/>
    <title>TR19-060 |  Gentle Measurement of Quantum States and Differential Privacy | 

	Scott Aaronson, 

	Guy Rothblum</title>
    <summary>In differential privacy (DP), we want to query a database about $n$ users, in a way that "leaks at most $\varepsilon$ about any individual user," even conditioned on any outcome of the query.  Meanwhile, in gentle measurement, we want to measure $n$ quantum states, in a way that "damages the states by at most $\alpha$," even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects. Specifically, we show that on products of $n$ quantum states, any measurement that is $\alpha$-gentle for small $\alpha$ is also $O( \alpha)$-DP, and any product measurement that is $\varepsilon$-DP is also $O(\varepsilon\sqrt{n})$-gentle.

Illustrating the power of this connection, we apply it to the recently studied problem of shadow tomography.  Given an unknown $d$-dimensional quantum state $\rho$, as well as known two-outcome measurements $E_{1},\ldots,E_{m}$, shadow tomography asks us to estimate $\Pr\left[  E_{i}\text{ accepts }\rho\right]  $, for every $i\in\left[ m\right]  $, by measuring few copies of $\rho$. Using our connection theorem, together with a quantum analog of the so-called private multiplicative weights algorithm of Hardt and Rothblum, we give a protocol to solve this problem using $O\left( \left(  \log m\right)  ^{2}\left(  \log d\right)  ^{2}\right)$ copies of $\rho$, compared to Aaronson's previous bound of $\widetilde{O} \left(\left(  \log m\right) ^{4}\left( \log d\right)\right) $.  Our protocol has the advantages of being online (that is, the $E_{i}$'s are processed one at a time), gentle, and conceptually simple.

Other applications of our connection include new lower bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</summary>
    <updated>2019-04-18T12:48:21Z</updated>
    <published>2019-04-18T12:48:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-18T21:20:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2053726780224405945</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2053726780224405945/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html" rel="alternate" type="text/html"/>
    <title>Physics of Everday Life</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Based on <a href="https://www.scottaaronson.com/blog/?p=3654">Scott's review</a>, I read through Stephen Pinker's <a href="https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress-ebook/dp/B073TJBYTB/ref=as_li_ss_tl?crid=2O1U6VZR84R2Q&amp;keywords=enlightenment+now&amp;qid=1554897483&amp;s=gateway&amp;sprefix=engligh,aps,597&amp;sr=8-1&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=8f668f77297b7cd8b57a85dca27802b0&amp;language=en_US">Enlightenment Now</a>. I can't top Scott's exposition of the book, but it is pretty incredible how far humanity has gone when you step back to look at the big picture.<br/>
<br/>
One line intrigued me, one that Pinker credits to a book called <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=6c644c72e1d0c1f818a5907f9b221ce1&amp;language=en_US">The Big Picture</a> by Sean Carroll<br/>
<blockquote class="tr_bq">
The laws of physics underlying everyday life (that is excluding extreme values of energy and gravitation like black holes, dark matter and the Big Bang) are <i>completely known.</i></blockquote>
Hasn't this statement almost always been true, in the sense that the leading minds would make this claim at many times in history. The ancient Greeks probably believed they understood physics that underlies everyday life. So did physicists after Newton. Life back then not today. My everyday life involves using a GPS device that requires understanding relativistic effects and computer chips that needed other scientific advances.<br/>
<br/>
Is it possible we could do more in everyday life if we knew more physics? I'd certainly use a teleporter in everyday life.<br/>
<br/>
And is the statement even true today? We all use public key cryptography, even to read this blog. It's not completely clear if we understand the physics enough to know how or if large-scale quantum computers capable of breaking those systems can be built.<br/>
<br/>
Everday life is relative.</div>
    </content>
    <updated>2019-04-18T11:40:00Z</updated>
    <published>2019-04-18T11:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-18T20:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/059" rel="alternate" type="text/html"/>
    <title>TR19-059 |  Samplers and extractors for unbounded functions | 

	Rohit Agrawal</title>
    <summary>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler, defined as an averaging sampler for approximating the mean of functions $f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and asked for explicit constructions. In this work, we give the first explicit constructions of subgaussian samplers (and in fact averaging samplers for the broader class of subexponential functions) that match the best-known constructions of averaging samplers for $[0,1]$-bounded functions in the regime of parameters where the approximation error $\varepsilon$ and failure probability $\delta$ are subconstant. Our constructions are established via an extension of the standard notion of randomness extractor (Nisan and Zuckerman, JCSS'96) where the error is measured by an arbitrary divergence rather than total variation distance, and a generalization of Zuckerman's equivalence (Random Struct. Alg.'97) between extractors and samplers. We believe that the framework we develop, and specifically the notion of an extractor for the Kullback-Leibler (KL) divergence, are of independent interest. In particular, KL-extractors are stronger than both standard extractors and subgaussian samplers, but we show that they exist with essentially the same parameters (constructively and non-constructively) as standard extractors.</summary>
    <updated>2019-04-18T00:27:56Z</updated>
    <published>2019-04-18T00:27:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-18T21:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08391</id>
    <link href="http://arxiv.org/abs/1904.08391" rel="alternate" type="text/html"/>
    <title>Samplers and extractors for unbounded functions</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Rohit.html">Rohit Agrawal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08391">PDF</a><br/><b>Abstract: </b>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler,
defined as an averaging sampler for approximating the mean of functions
$f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and
asked for explicit constructions. In this work, we give the first explicit
constructions of subgaussian samplers (and in fact averaging samplers for the
broader class of subexponential functions) that match the best-known
constructions of averaging samplers for $[0,1]$-bounded functions in the regime
of parameters where the approximation error $\varepsilon$ and failure
probability $\delta$ are subconstant. Our constructions are established via an
extension of the standard notion of randomness extractor (Nisan and Zuckerman,
JCSS'96) where the error is measured by an arbitrary divergence rather than
total variation distance, and a generalization of Zuckerman's equivalence
(Random Struct. Alg.'97) between extractors and samplers. We believe that the
framework we develop, and specifically the notion of an extractor for the
Kullback-Leibler (KL) divergence, are of independent interest. In particular,
KL-extractors are stronger than both standard extractors and subgaussian
samplers, but we show that they exist with essentially the same parameters
(constructively and non-constructively) as standard extractors.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08382</id>
    <link href="http://arxiv.org/abs/1904.08382" rel="alternate" type="text/html"/>
    <title>A Faster Local Algorithm for Detecting Bounded-Size Cuts with Applications to Higher-Connectivity Problems</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Forster:Sebastian.html">Sebastian Forster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Liu.html">Liu Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08382">PDF</a><br/><b>Abstract: </b>Consider the following "local" cut-detection problem in a directed graph: We
are given a starting vertex $s$ and need to detect whether there is a cut with
at most $k$ edges crossing the cut such that the side of the cut containing $s$
has at most $\Delta$ interior edges. If we are given query access to the input
graph, then this problem can in principle be solved in sublinear time without
reading the whole graph and with query complexity depending on $k$ and
$\Delta$. We design an elegant randomized procedure that solves a slack variant
of this problem with $O(k^2 \Delta)$ queries, improving in particular a
previous bound of $O((2(k+1))^{k+2} \Delta)$ by Chechik et al. [SODA 2017]. In
this slack variant, the procedure must successfully detect a component
containing $s$ with at most $k$ outgoing edges and $\Delta$ interior edges if
such a component exists, but the component it actually detects may have up to
$O(k \Delta)$ interior edges.
</p>
<p>Besides being of interest on its own, such cut-detection procedures have been
used in many algorithmic applications for higher-connectivity problems. Our new
cut-detection procedure therefore almost readily implies (1) a faster vertex
connectivity algorithm which in particular has nearly linear running time for
polylogarithmic value of the vertex connectivity, (2) a faster algorithm for
computing the maximal $k$-edge connected subgraphs, and (3) faster property
testing algorithms for higher edge and vertex connectivity, which resolves two
open problems, one by Goldreich and Ron [STOC '97] and one by Orenstein and Ron
[TCS 2011].
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08380</id>
    <link href="http://arxiv.org/abs/1904.08380" rel="alternate" type="text/html"/>
    <title>Low-Latency Graph Streaming Using Compressed Purely-Functional Trees</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a>, Guy Blelloch <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08380">PDF</a><br/><b>Abstract: </b>Due to the dynamic nature of real-world graphs, there has been a growing
interest in the graph-streaming setting where a continuous stream of graph
updates is mixed with arbitrary graph queries. In principle, purely-functional
trees are an ideal choice for this setting due as they enable safe parallelism,
lightweight snapshots, and strict serializability for queries. However,
directly using them for graph processing would lead to significant space
overhead and poor cache locality.
</p>
<p>This paper presents C-trees, a compressed purely-functional search tree data
structure that significantly improves on the space usage and locality of
purely-functional trees. The key idea is to use a chunking technique over trees
in order to store multiple entries per tree-node. We design
theoretically-efficient and practical algorithms for performing batch updates
to C-trees, and also show that we can store massive dynamic real-world graphs
using only a few bytes per edge, thereby achieving space usage close to that of
the best static graph processing frameworks.
</p>
<p>To study the efficiency and applicability of our data structure, we designed
Aspen, a graph-streaming framework that extends the interface of Ligra with
operations for updating graphs. We show that Aspen is faster than two
state-of-the-art graph-streaming systems, Stinger and LLAMA, while requiring
less memory, and is competitive in performance with the state-of-the-art static
graph frameworks, Galois, GAP, and Ligra+. With Aspen, we are able to
efficiently process the largest publicly-available graph with over two hundred
billion edges in the graph-streaming setting using a single commodity multicore
server with 1TB of memory.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08355</id>
    <link href="http://arxiv.org/abs/1904.08355" rel="alternate" type="text/html"/>
    <title>JGraphT -- A Java library for graph data structures and algorithms</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michail:Dimitrios.html">Dimitrios Michail</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kinable:Joris.html">Joris Kinable</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naveh:Barak.html">Barak Naveh</a>, John V Sichi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08355">PDF</a><br/><b>Abstract: </b>Mathematical software and graph-theoretical algorithmic packages to
efficiently model, analyze and query graphs are crucial in an era where
large-scale spatial, societal and economic network data are abundantly
available. One such package is JGraphT, a programming library which contains
very efficient and generic graph data-structures along with a large collection
of state-of-the-art algorithms. The library is written in Java with stability,
interoperability and performance in mind. A distinctive feature of this library
is the ability to model vertices and edges as arbitrary objects, thereby
permitting natural representations of many common networks including
transportation, social and biological networks. Besides classic graph
algorithms such as shortest-paths and spanning-tree algorithms, the library
contains numerous advanced algorithms: graph and subgraph isomorphism; matching
and flow problems; approximation algorithms for NP-hard problems such as
independent set and TSP; and several more exotic algorithms such as Berge graph
detection. Due to its versatility and generic design, JGraphT is currently used
in large-scale commercial, non-commercial and academic research projects. In
this work we describe in detail the design and underlying structure of the
library, and discuss its most important features and algorithms. A
computational study is conducted to evaluate the performance of JGraphT versus
a number of similar libraries. Experiments on a large number of graphs over a
variety of popular algorithms show that JGraphT is highly competitive with
other established libraries such as NetworkX or the BGL.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08343</id>
    <link href="http://arxiv.org/abs/1904.08343" rel="alternate" type="text/html"/>
    <title>The power word problem</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lohrey:Markus.html">Markus Lohrey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei=szlig=:Armin.html">Armin Weiß</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08343">PDF</a><br/><b>Abstract: </b>In this work we introduce a new succinct variant of the word problem in a
finitely generated group $G$, which we call the power word problem: the input
word may contain powers $p^x$, where $p$ is a finite word over generators of
$G$ and $x$ is a binary encoded integer. The power word problem is a
restriction of the compressed word problem, where the input word is represented
by a straight-line program (i.e., an algebraic circuit over $G$). The main
result of the paper states that the power word problem for a finitely generated
free group $F$ is AC$^0$-Turing-reducible to the word problem for $F$.
Moreover, the following hardness result is shown: For a wreath product $G \wr
\mathbb{Z}$, where $G$ is either free of rank at least two or finite
non-solvable, the power word problem is complete for coNP. This contrasts with
the situation where $G$ is abelian: then the power word problem is shown to be
in TC$^0$.
</p></div>
    </summary>
    <updated>2019-04-18T01:21:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08255</id>
    <link href="http://arxiv.org/abs/1904.08255" rel="alternate" type="text/html"/>
    <title>Online Matching with General Arrivals</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamlath:Buddhima.html">Buddhima Gamlath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, Andreas Maggiori, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08255">PDF</a><br/><b>Abstract: </b>The online matching problem was introduced by Karp, Vazirani and Vazirani
nearly three decades ago. In that seminal work, they studied this problem in
bipartite graphs with vertices arriving only on one side, and presented optimal
deterministic and randomized algorithms for this setting. In comparison, more
general arrival models, such as edge arrivals and general vertex arrivals, have
proven more challenging and positive results are known only for various
relaxations of the problem. In particular, even the basic question of whether
randomization allows one to beat the trivially-optimal deterministic
competitive ratio of $\frac{1}{2}$ for either of these models was open. In this
paper, we resolve this question for both these natural arrival models, and show
the following.
</p>
<p>1. For edge arrivals, randomization does not help --- no randomized algorithm
is better than $\frac{1}{2}$ competitive.
</p>
<p>2. For general vertex arrivals, randomization helps --- there exists a
randomized $(\frac{1}{2}+\Omega(1))$-competitive online matching algorithm.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08178</id>
    <link href="http://arxiv.org/abs/1904.08178" rel="alternate" type="text/html"/>
    <title>Novel Dense Subgraph Discovery Primitives: Risk Aversion and Exclusion Queries</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsourakakis:Charalampos_E=.html">Charalampos E. Tsourakakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Tianyi.html">Tianyi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kakimura:Naonori.html">Naonori Kakimura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pachocki:Jakub.html">Jakub Pachocki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08178">PDF</a><br/><b>Abstract: </b>In the densest subgraph problem, given a weighted undirected graph
$G(V,E,w)$, with non-negative edge weights, we are asked to find a subset of
nodes $S\subseteq V$ that maximizes the degree density $w(S)/|S|$, where $w(S)$
is the sum of the edge weights induced by $S$. This problem is a well studied
problem, known as the {\em densest subgraph problem}, and is solvable in
polynomial time. But what happens when the edge weights are negative? Is the
problem still solvable in polynomial time? Also, why should we care about the
densest subgraph problem in the presence of negative weights?
</p>
<p>In this work we answer the aforementioned question. Specifically, we provide
two novel graph mining primitives that are applicable to a wide variety of
applications. Our primitives can be used to answer questions such as "how can
we find a dense subgraph in Twitter with lots of replies and mentions but no
follows?", "how do we extract a dense subgraph with high expected reward and
low risk from an uncertain graph"? We formulate both problems mathematically as
special instances of dense subgraph discovery in graphs with negative weights.
We study the hardness of the problem, and we prove that the problem in general
is NP-hard. We design an efficient approximation algorithm that works well in
the presence of small negative weights, and also an effective heuristic for the
more general case. Finally, we perform experiments on various real-world
uncertain graphs, and a crawled Twitter multilayer graph that verify the value
of the proposed primitives, and the practical value of our proposed algorithms.
</p>
<p>The code and the data are available at \url{https://github.com/negativedsd}.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08150</id>
    <link href="http://arxiv.org/abs/1904.08150" rel="alternate" type="text/html"/>
    <title>A Brief Note on Single Source Fault Tolerant Reachability</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Pranabendu.html">Pranabendu Misra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08150">PDF</a><br/><b>Abstract: </b>Let $G$ be a directed graph with $n$ vertices and $m$ edges, and let $s \in
V(G)$ be a designated source vertex. We consider the problem of single source
reachability (SSR) from $s$ in presence of failures of edges (or vertices).
Formally, a spanning subgraph $H$ of $G$ is a {\em $k$-Fault Tolerant
Reachability Subgraph ($k$-FTRS)} if it has the following property. For any set
$F$ of at most $k$ edges (or vertices) in $G$, and for any vertex $v\in V(G)$,
the vertex $v$ is reachable from $s$ in $G-F$ if and only if it is reachable
from $s$ in $H - F$. Baswana et.al. [STOC 2016, SICOMP 2018] showed that in the
setting above, for any positive integer $k$, we can compute a $k$-FTRS with
$2^k n$ edges. In this paper, we give a much simpler algorithm for computing a
$k$-FTRS, and observe that it extends to higher connectivity as well. Our
results follow from a simple application of \emph{important separators}, a well
known technique in Parameterized Complexity.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08112</id>
    <link href="http://arxiv.org/abs/1904.08112" rel="alternate" type="text/html"/>
    <title>A Lower Bound for Relaxed Locally Decodable Codes</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gur:Tom.html">Tom Gur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lachish:Oded.html">Oded Lachish</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08112">PDF</a><br/><b>Abstract: </b>A locally decodable code (LDC) C:{0,1}^k -&gt; {0,1}^n is an error correcting
code wherein individual bits of the message can be recovered by only querying a
few bits of a noisy codeword. LDCs found a myriad of applications both in
theory and in practice, ranging from probabilistically checkable proofs to
distributed storage. However, despite nearly two decades of extensive study,
the best known constructions of O(1)-query LDCs have super-polynomial
blocklength.
</p>
<p>The notion of relaxed LDCs is a natural relaxation of LDCs, which aims to
bypass the foregoing barrier by requiring local decoding of nearly all
individual message bits, yet allowing decoding failure (but not error) on the
rest. State of the art constructions of O(1)-query relaxed LDCs achieve
blocklength n = O(k^{1+ \gamma}) for an arbitrarily small constant \gamma.
</p>
<p>We prove a lower bound which shows that O(1)-query relaxed LDCs cannot
achieve blocklength n = k^{1+ o(1)}. This resolves an open problem raised by
Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (STOC 2004).
</p></div>
    </summary>
    <updated>2019-04-18T01:21:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08078</id>
    <link href="http://arxiv.org/abs/1904.08078" rel="alternate" type="text/html"/>
    <title>Approximating Cumulative Pebbling Cost is Unique Games Hard</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blocki:Jeremiah.html">Jeremiah Blocki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Seunghoon.html">Seunghoon Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08078">PDF</a><br/><b>Abstract: </b>The cumulative pebbling complexity of a directed acyclic graph $G$ is defined
as $\mathsf{cc}(G) = \min_P \sum_i |P_i|$, where the minimum is taken over all
legal (parallel) black pebblings of $G$ and $|P_i|$ denotes the number of
pebbles on the graph during round $i$. Intuitively, $\mathsf{cc}(G)$ captures
the amortized Space-Time complexity of pebbling $m$ copies of $G$ in parallel.
The cumulative pebbling complexity of a graph $G$ is of particular interest in
the field of cryptography as $\mathsf{cc}(G)$ is tightly related to the
amortized Area-Time complexity of the data-independent memory hard function
(iMHF) $f_{G,H}$ [AS15] defined using a constant indegree directed acyclic
graph (DAG) $G$ and a random oracle $H(\cdot)$. A secure iMHF should have
amortized Space-Time complexity as high as possible e.g., to deter brute-force
password attacker who wants to find $x$ such that $f_{G,H}(x) = h$. Thus, to
analyze the (in)security of a candidate iMHF $f_{G,H}$, it is crucial to
estimate the value $\mathsf{cc}(G)$ but currently, upper and lower bounds for
leading iMHF candidates differ by several orders of magnitude. Blocki and Zhou
recently showed that is $\mathsf{NP}$-Hard to compute $\mathsf{cc}(G)$, but
their techniques do not even rule out an efficient $(1+\epsilon)$-approximation
algorithm for any constant $\epsilon&gt;0$. We show that for any constant $c&gt;0$,
it is Unique Games hard to approximate $\mathsf{cc}(G)$ to within a factor of
$c$.
</p>
<p>(See the paper for the full abstract.)
</p></div>
    </summary>
    <updated>2019-04-18T01:20:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08053</id>
    <link href="http://arxiv.org/abs/1904.08053" rel="alternate" type="text/html"/>
    <title>A scaled space-filling curve index applied to tropical rain forest tree distributions</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Markus Wilhelm Jahn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bradley:Patrick_Erik.html">Patrick Erik Bradley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08053">PDF</a><br/><b>Abstract: </b>In order to be able to process the increasing amount of spatial data,
efficient methods for their handling need to be developed. One major challenge
for big spatial data is access. This can be achieved through space-filling
curves, as they have the property that nearby points on the curve are also
nearby in space. It is demonstrated on a tropical rain forest tree data set of
2.5 million points taken from a multi-dimensional space that the recently
constructed scaled Gray-Hilbert curve index performs better than its standard
static version, saving a significant amount of space for a projection of the
data set onto 8 attributes. The relative efficiency of the scaled Gray-Hilbert
curve in comparison with the best static version is seen to depend on the
distribution of the point cloud. A local sparsity measure derived from
properties of the corresponding trees can distinguish point clouds with
different tail distributions.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08037</id>
    <link href="http://arxiv.org/abs/1904.08037" rel="alternate" type="text/html"/>
    <title>Improved Distributed Expander Decomposition and Nearly Optimal Triangle Enumeration</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08037">PDF</a><br/><b>Abstract: </b>An $(\epsilon,\phi)$-expander decomposition of a graph $G=(V,E)$ is a
clustering of the vertices $V=V_{1}\cup\cdots\cup V_{x}$ such that (1) each
cluster $V_{i}$ induces subgraph with conductance at least $\phi$, and (2) the
number of inter-cluster edges is at most $\epsilon|E|$. In this paper, we give
an improved distributed expander decomposition in the CONGEST model.
Specifically, we construct an $(\epsilon,\phi)$-expander decomposition with
$\phi=(\epsilon/\log n)^{2^{O(k)}}$ in $O(n^{2/k}\cdot\text{poly}(1/\phi,\log
n))$ rounds for any $\epsilon\in(0,1)$ and positive integer $k$. For example, a
$(0.01,1/\text{poly}\log n)$-expander decomposition can be computed in
$O(n^{\gamma})$ rounds, for any constant $\gamma&gt;0$. Previously, the algorithm
by Chang, Pettie, and Zhang can construct a $(1/6,1/\text{poly}\log
n)$-expander decomposition using $\tilde{O}(n^{1-\delta})$ rounds for any
$\delta&gt;0$, with a caveat that the algorithm is allowed to throw away a set of
edges which forms a subgraph with arboricity at most $n^{\delta}$. Our
algorithm does not have this caveat.
</p>
<p>By modifying the distributed algorithm for routing on expanders by Ghaffari,
Kuhn and Su [PODC'17], we obtain a triangle enumeration algorithm using
$\tilde{O}(n^{1/3})$ rounds. This matches the lower bound by Izumi and Le Gall
[PODC'17] and Pandurangan, Robinson and Scquizzato [SPAA'18] of
$\tilde{\Omega}(n^{1/3})$ which holds even in the CONGESTED-CLIQUE model. To
the best of our knowledge, this provides the first non-trivial example for a
problem that has essentially the same complexity (up to a polylogarithmic
factor) in both CONGEST and CONGESTED-CLIQUE.
</p>
<p>The key technique in our proof is the first distributed approximation
algorithm for finding a low conductance cut that is as balanced as possible.
Previous distributed sparse cut algorithms do not have this nearly most
balanced guarantee.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07964</id>
    <link href="http://arxiv.org/abs/1904.07964" rel="alternate" type="text/html"/>
    <title>3D Shape Synthesis for Conceptual Design and Optimization Using Variational Autoencoders</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wentai.html">Wentai Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zhangsihao.html">Zhangsihao Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haoliang.html">Haoliang Jiang</a>, Suyash Nigam, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamakawa:Soji.html">Soji Yamakawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Furuhata:Tomotake.html">Tomotake Furuhata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimada:Kenji.html">Kenji Shimada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Levent_Burak.html">Levent Burak Kara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07964">PDF</a><br/><b>Abstract: </b>We propose a data-driven 3D shape design method that can learn a generative
model from a corpus of existing designs, and use this model to produce a wide
range of new designs. The approach learns an encoding of the samples in the
training corpus using an unsupervised variational autoencoder-decoder
architecture, without the need for an explicit parametric representation of the
original designs. To facilitate the generation of smooth final surfaces, we
develop a 3D shape representation based on a distance transformation of the
original 3D data, rather than using the commonly utilized binary voxel
representation. Once established, the generator maps the latent space
representations to the high-dimensional distance transformation fields, which
are then automatically surfaced to produce 3D representations amenable to
physics simulations or other objective function evaluation modules. We
demonstrate our approach for the computational design of gliders that are
optimized to attain prescribed performance scores. Our results show that when
combined with genetic optimization, the proposed approach can generate a rich
set of candidate concept designs that achieve prescribed functional goals, even
when the original dataset has only a few or no solutions that achieve these
goals.
</p></div>
    </summary>
    <updated>2019-04-18T01:33:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07957</id>
    <link href="http://arxiv.org/abs/1904.07957" rel="alternate" type="text/html"/>
    <title>Almost-Smooth Histograms and Sliding-Window Graph Algorithms</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, David Reitblat <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07957">PDF</a><br/><b>Abstract: </b>We study algorithms for the sliding-window model, an important variant of the
data-stream model, in which the goal is to compute some function of a
fixed-length suffix of the stream. We explore the smooth histogram framework of
Braverman and Ostrovsky (FOCS 2007) for reducing the sliding-window model to
the insertion-only streaming model, and extend it to the family of subadditive
functions. Specifically, we show that if a subadditive function can be
approximated in the ordinary (insertion-only) streaming model, then it could be
approximated also in the sliding-window model with approximation ratio larger
by factor $2+\epsilon$ and space complexity larger by factor
$O(\epsilon^{-1}\log w)$, where $w$ is the window size.
</p>
<p>We then consider graph streams and show that many graph problems are
subadditive, including maximum matching and minimum vertex-cover, thereby
deriving sliding-window algorithms for them almost for free (using known
insertion-only algorithms). One concrete example is a
$\mathrm{polylog}(n)$-space algorithm for estimating maximum-matching size in
bounded-arboricity graphs with $n$ vertices, whose approximation ratio differs
by a factor of $2$ from the insertion-only algorithm of McGregor and
Vorotnikova (SODA 2018).
</p>
<p>We also use the same framework to improve the analysis of a known
sliding-window algorithm for approximating minimum vertex-cover in general
graphs. We improve the approximation ratio $8+\epsilon$ of van Handel (MSc
Thesis 2016) to $4+\epsilon$ using the same space complexity
$\tilde{O}_\epsilon(n)$.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07949</id>
    <link href="http://arxiv.org/abs/1904.07949" rel="alternate" type="text/html"/>
    <title>Extractors for small zero-fixing sources</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pavel Pudlak, Vojtech Rodl <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07949">PDF</a><br/><b>Abstract: </b>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset
$V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$
that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for
$(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some
$m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the
uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$.
Zero-fixing sources were introduced by Cohen and Shinkar in [10] in connection
with the previously studied extractors for bit-fixing sources. They
constructed, for every $\mu&gt;0$, an efficiently computable extractor that
extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from
$(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$.
</p>
<p>In this paper we present two different constructions of extractors for
zero-fixing sources that are able to extract a positive fraction of entropy for
$k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq
C\log\log\log n$, for some constant $C$. The second extractor extracts a
positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in
\mathbb{N}$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The
fraction of extracted entropy decreases with $i$. The first extractor is a
function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too
small); the second one is computable in polynomial time when
$k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.
</p></div>
    </summary>
    <updated>2019-04-18T01:20:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07902</id>
    <link href="http://arxiv.org/abs/1904.07902" rel="alternate" type="text/html"/>
    <title>Heuristic algorithms for the Longest Filled Common Subsequence Problem</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mincu:Radu_Stefan.html">Radu Stefan Mincu</a>, Alexandru Popa University of Bucharest, Romania, National Institute for Research and Development in Informatics, Bucharest, Romania) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07902">PDF</a><br/><b>Abstract: </b>At CPM 2017, Castelli et al. define and study a new variant of the Longest
Common Subsequence Problem, termed the Longest Filled Common Subsequence
Problem (LFCS). For the LFCS problem, the input consists of two strings $A$ and
$B$ and a multiset of characters $\mathcal{M}$. The goal is to insert the
characters from $\mathcal{M}$ into the string $B$, thus obtaining a new string
$B^*$, such that the Longest Common Subsequence (LCS) between $A$ and $B^*$ is
maximized. Casteli et al. show that the problem is NP-hard and provide a
3/5-approximation algorithm for the problem.
</p>
<p>In this paper we study the problem from the experimental point of view. We
introduce, implement and test new heuristic algorithms and compare them with
the approximation algorithm of Casteli et al. Moreover, we introduce an Integer
Linear Program (ILP) model for the problem and we use the state of the art ILP
solver, Gurobi, to obtain exact solution for moderate sized instances.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07764</id>
    <link href="http://arxiv.org/abs/1904.07764" rel="alternate" type="text/html"/>
    <title>ProUM: Projection-based Utility Mining on Sequence Data</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gan:Wensheng.html">Wensheng Gan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Jerry_Chun=Wei.html">Jerry Chun-Wei Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jiexiong.html">Jiexiong Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chao:Han=Chieh.html">Han-Chieh Chao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fujita:Hamido.html">Hamido Fujita</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Philip_S=.html">Philip S. Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07764">PDF</a><br/><b>Abstract: </b>In recent decade, utility mining has attracted a great attention, but most of
the existing studies are developed to deal with itemset-based data. Different
from the itemset-based data, the time-ordered sequence data is more commonly
seen in real-world situations. Current utility mining algorithms have the
limitation when dealing with sequence data since they are time-consuming and
require large amount of memory usage. In this paper, we propose an efficient
Projection-based Utility Mining (ProUM) approach to discover high-utility
sequential patterns from sequence data. The utility-array structure is designed
to store necessary information of sequence-order and utility. By utilizing the
projection technique in generating utility-array, ProUM can significantly
improve the mining efficiency, and effectively reduce the memory consumption.
Besides, we propose a new upper bound named sequence extension utility. Several
pruning strategies are further applied to improve the efficiency of ProUM.
Experimental results show that the proposed ProUM algorithm significantly
outperforms the state-of-the-art algorithms.
</p></div>
    </summary>
    <updated>2019-04-18T00:30:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07700</id>
    <link href="http://arxiv.org/abs/1904.07700" rel="alternate" type="text/html"/>
    <title>p-Adic scaled space filling curve indices for high dimensional data</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bradley:Patrick_Erik.html">Patrick Erik Bradley</a>, Markus Wilhelm Jahn <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07700">PDF</a><br/><b>Abstract: </b>Space filling curves are widely used in Computer Science. In particular
Hilbert curves and their generalisations to higher dimension are used as an
indexing method because of their nice locality properties. This article
generalises this concept to the systematic construction of p-adic versions of
Hilbert curves based on affine transformations of the p-adic Gray code, and
develops an efficient scaled indexing method for data taken from
high-dimensional spaces based on these new curves, which with increasing
dimension is shown to be less space consuming than the optimal standard static
Hilbert curve index. A measure is derived which allows to assess the local
sparsity of a data set, and is tested on some data.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07683</id>
    <link href="http://arxiv.org/abs/1904.07683" rel="alternate" type="text/html"/>
    <title>Fast Commutative Matrix Algorithm</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Andreas Rosowski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07683">PDF</a><br/><b>Abstract: </b>We show that the product of an nx3 matrix and a 3x3 matrix over a commutative
ring can be computed using 6n+3 multiplications. For two 3x3 matrices this
gives us an algorithm using 21 multiplications. This is an improvement with
respect to Makarov algorithm using 22 multiplications[10]. We generalize our
result for nx3 and 3x3 matrices and present an algorithm for computing the
product of an lxn matrix and an nxm matrix over a commutative ring for odd n
using n(lm+l+m-1)/2 multiplications if m is odd and using (n(lm+l+m-1)+l-1)/2
multiplications if m is even. Waksman algorithm for odd n needs
(n-1)(lm+l+m-1)/2+lm multiplications[16], thus in both cases less
multiplications are required by our algorithm.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07467</id>
    <link href="http://arxiv.org/abs/1904.07467" rel="alternate" type="text/html"/>
    <title>Dynamic Packed Compact Tries Revisited</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsuruta:Kazuya.html">Kazuya Tsuruta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanda:Shunsuke.html">Shunsuke Kanda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07467">PDF</a><br/><b>Abstract: </b>Given a dynamic set $K$ of $k$ strings of total length $n$ whose characters
are drawn from an alphabet of size $\sigma$, a keyword dictionary is a data
structure built on $K$ that provides locate, prefix search, and update
operations on $K$. Under the assumption that $\alpha = \lg_{\sigma} n$
characters fit into a single machine word $w$, we propose a keyword dictionary
that represents $K$ in $n \lg \sigma + O(k w)$ bits of space, supporting all
operations in $O(m / \alpha + \lg \alpha)$ expected time on an input string of
length $m$ in the word RAM model. This data structure is underlined with an
exhaustive practical evaluation, highlighting the practical usefulness of the
proposed data structure.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07388</id>
    <link href="http://arxiv.org/abs/1904.07388" rel="alternate" type="text/html"/>
    <title>Point-width and Max-CSPs</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Clement Carbonnel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Romero:Miguel.html">Miguel Romero</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07388">PDF</a><br/><b>Abstract: </b>The complexity of (unbounded-arity) Max-CSPs under structural restrictions is
poorly understood. The two most general hypergraph properties known to ensure
tractability of Max-CSPs, $\beta$-acyclicity and bounded (incidence) MIM-width,
are incomparable and lead to very different algorithms.
</p>
<p>We introduce the framework of point decompositions for hypergraphs and use it
to derive a new sufficient condition for the tractability of (structurally
restricted) Max-CSPs, which generalises both bounded MIM-width and
\b{eta}-acyclicity. On the way, we give a new characterisation of bounded
MIM-width and discuss other hypergraph properties which are relevant to the
complexity of Max-CSPs, such as $\beta$-hypertreewidth.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07381</id>
    <link href="http://arxiv.org/abs/1904.07381" rel="alternate" type="text/html"/>
    <title>Approximation Algorithms for Distributionally Robust Stochastic Optimization with Black-Box Distributions</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Andre Linhares, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swamy:Chaitanya.html">Chaitanya Swamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07381">PDF</a><br/><b>Abstract: </b>Two-stage stochastic optimization is a framework for modeling uncertainty,
where we have a probability distribution over possible realizations of the
data, called scenarios, and decisions are taken in two stages: we make
first-stage decisions knowing only the underlying distribution and before a
scenario is realized, and may take additional second-stage recourse actions
after a scenario is realized. The goal is typically to minimize the total
expected cost. A criticism of this model is that the underlying probability
distribution is itself often imprecise! To address this, a versatile approach
that has been proposed is the {\em distributionally robust 2-stage model}:
given a collection of probability distributions, our goal now is to minimize
the maximum expected total cost with respect to a distribution in this
collection.
</p>
<p>We provide a framework for designing approximation algorithms in such
settings when the collection is a ball around a central distribution and the
central distribution is accessed {\em only via a sampling black box}.
</p>
<p>We first show that one can utilize the {\em sample average approximation}
(SAA) method to reduce the problem to the case where the central distribution
has {\em polynomial-size} support. We then show how to approximately solve a
fractional relaxation of the SAA (i.e., polynomial-scenario
central-distribution) problem. By complementing this via LP-rounding algorithms
that provide {\em local} (i.e., per-scenario) approximation guarantees, we
obtain the {\em first} approximation algorithms for the distributionally robust
versions of a variety of discrete-optimization problems including set cover,
vertex cover, edge cover, facility location, and Steiner tree, with guarantees
that are, except for set cover, within $O(1)$-factors of the guarantees known
for the deterministic version of the problem.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07272</id>
    <link href="http://arxiv.org/abs/1904.07272" rel="alternate" type="text/html"/>
    <title>Introduction to Multi-Armed Bandits</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Slivkins:Aleksandrs.html">Aleksandrs Slivkins</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07272">PDF</a><br/><b>Abstract: </b>Multi-armed bandits a simple but very powerful framework for algorithms that
make decisions over time under uncertainty. An enormous body of work has
accumulated over the years, covered in several books and surveys. This book
provides a more introductory, textbook-like treatment of the subject. Each
chapter tackles a particular line of work, providing a self-contained,
teachable technical introduction and a review of the more advanced results.
</p>
<p>The chapters are as follows: Stochastic bandits; Lower bounds; Bayesian
Bandits and Thompson Sampling; Lipschitz Bandits; Full Feedback and Adversarial
Costs; Adversarial Bandits; Linear Costs and Semi-bandits; Contextual Bandits;
Bandits and Zero-Sum Games; Bandits with Knapsacks; Incentivized Exploration
and Connections to Mechanism Design.
</p>
<p>Status of the manuscript: essentially complete (modulo some polishing),
except for last chapter, which the author plans to add over the next few
months.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07271</id>
    <link href="http://arxiv.org/abs/1904.07271" rel="alternate" type="text/html"/>
    <title>Stochastic Load Balancing on Unrelated Machines</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagarajan:Viswanath.html">Viswanath Nagarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Xiangkun.html">Xiangkun Shen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07271">PDF</a><br/><b>Abstract: </b>We consider the problem of makespan minimization on unrelated machines when
job sizes are stochastic. The goal is to find a fixed assignment of jobs to
machines, to minimize the expected value of the maximum load over all the
machines. For the identical machines special case when the size of a job is the
same across all machines, a constant-factor approximation algorithm has long
been known. Our main result is the first constant-factor approximation
algorithm for the general case of unrelated machines. This is achieved by (i)
formulating a lower bound using an exponential-size linear program that is
efficiently computable, and (ii) rounding this linear program while satisfying
only a specific subset of the constraints that still suffice to bound the
expected makespan. We also consider two generalizations. The first is the
budgeted makespan minimization problem, where the goal is to minimize the
expected makespan subject to scheduling a target number (or reward) of jobs. We
extend our main result to obtain a constant-factor approximation algorithm for
this problem. The second problem involves $q$-norm objectives, where we want to
minimize the expected q-norm of the machine loads. Here we give an $O(q/\log
q)$-approximation algorithm, which is a constant-factor approximation for any
fixed $q$.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07262</id>
    <link href="http://arxiv.org/abs/1904.07262" rel="alternate" type="text/html"/>
    <title>Distance-generalized Core Decomposition</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonchi:Francesco.html">Francesco Bonchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Arijit.html">Arijit Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Severini:Lorenzo.html">Lorenzo Severini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07262">PDF</a><br/><b>Abstract: </b>The $k$-core of a graph is defined as the maximal subgraph in which every
vertex is connected to at least $k$ other vertices within that subgraph. In
this work we introduce a distance-based generalization of the notion of
$k$-core, which we refer to as the $(k,h)$-core, i.e., the maximal subgraph in
which every vertex has at least $k$ other vertices at distance $\leq h$ within
that subgraph. We study the properties of the $(k,h)$-core showing that it
preserves many of the nice features of the classic core decomposition (e.g.,
its connection with the notion of distance-generalized chromatic number) and it
preserves its usefulness to speed-up or approximate distance-generalized
notions of dense structures, such as $h$-club.
</p>
<p>Computing the distance-generalized core decomposition over large networks is
intrinsically complex. However, by exploiting clever upper and lower bounds we
can partition the computation in a set of totally independent subcomputations,
opening the door to top-down exploration and to multithreading, and thus
achieving an efficient algorithm.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07234</id>
    <link href="http://arxiv.org/abs/1904.07234" rel="alternate" type="text/html"/>
    <title>Bounded and Approximate Strong Satisfiability in Workflows</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crampton:Jason.html">Jason Crampton</a>, Gregory Gutin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majumdar:Diptapriyo.html">Diptapriyo Majumdar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07234">PDF</a><br/><b>Abstract: </b>There has been a considerable amount of interest in recent years in the
problem of workflow satisfiability, which asks whether the existence of
constraints in a workflow specification makes it impossible to allocate
authorized users to each step in the workflow. Recent developments have seen
the workflow satisfiability problem (WSP) studied in the context of workflow
specifications in which the set of steps may vary from one instance of the
workflow to another. This, in turn, means that some constraints may only apply
to certain workflow instances. Inevitably, WSP becomes more complex for such
workflow specifications. Other approaches have considered the possibility of
associating costs with the violation of `soft' constraints and authorizations.
Workflow satisfiability in this context becomes a question of minimizing the
cost of allocating users to steps in the workflow. In this paper, we introduce
new problems, which we believe to be of practical relevance, that combine these
approaches. In particular, we consider the question of whether, given a
workflow specification with costs and a `budget', all possible workflow
instances have an allocation of users to steps that does not exceed the budget.
We design a fixed-parameter tractable algorithm to solve this problem
parameterized by the total number of steps, release points and xor branchings.
</p></div>
    </summary>
    <updated>2019-04-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1807.02740</id>
    <link href="http://arxiv.org/abs/1807.02740" rel="alternate" type="text/html"/>
    <title>Data-driven Upsampling of Point Clouds</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wentai.html">Wentai Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haoliang.html">Haoliang Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zhangsihao.html">Zhangsihao Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamakawa:Soji.html">Soji Yamakawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimada:Kenji.html">Kenji Shimada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Levent_Burak.html">Levent Burak Kara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1807.02740">PDF</a><br/><b>Abstract: </b>High quality upsampling of sparse 3D point clouds is critically useful for a
wide range of geometric operations such as reconstruction, rendering, meshing,
and analysis. In this paper, we propose a data-driven algorithm that enables an
upsampling of 3D point clouds without the need for hard-coded rules. Our
approach uses a deep network with Chamfer distance as the loss function,
capable of learning the latent features in point clouds belonging to different
object categories. We evaluate our algorithm across different amplification
factors, with upsampling learned and performed on objects belonging to the same
category as well as different categories. We also explore the desirable
characteristics of input point clouds as a function of the distribution of the
point samples. Finally, we demonstrate the performance of our algorithm in
single-category training versus multi-category training scenarios. The final
proposed model is compared against a baseline, optimization-based upsampling
method. Results indicate that our algorithm is capable of generating more
uniform and accurate upsamplings.
</p></div>
    </summary>
    <updated>2019-04-18T01:32:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4166</id>
    <link href="https://www.scottaaronson.com/blog/?p=4166" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4166#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4166" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Just says in P</title>
    <summary xml:lang="en-US">Recently a Twitter account started called justsaysinmice. The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them. Simple concept, but it already seems to be changing […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Recently a Twitter account started called <a href="https://twitter.com/justsaysinmice">justsaysinmice</a>.  The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them.  Simple concept, but it already seems to be changing the conversation about science reporting.</p>



<p>It occurred to me that we could do something analogous for quantum computing.  While my own deep-seated aversion to Twitter prevents me from doing it myself, which of my readers is up for starting an account that just reposts one overhyped QC article after another, while appending the words “A CLASSICAL COMPUTER COULD ALSO DO THIS” to each one?</p></div>
    </content>
    <updated>2019-04-17T19:14:17Z</updated>
    <published>2019-04-17T19:14:17Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-17T19:58:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17286</id>
    <link href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/" rel="alternate" type="text/html"/>
    <title>Gothenburg, Stockholm, Lancaster, Mitzpe Ramon, and Israeli Election Day 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii) Sweden I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin … <a href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg"><img alt="" class="alignnone size-medium wp-image-17287" height="200" src="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg?w=300&amp;h=200" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/hand.png"><img alt="" class="alignnone size-medium wp-image-17288" height="251" src="https://gilkalai.files.wordpress.com/2019/04/hand.png?w=300&amp;h=251" width="300"/></a></p>
<p><span style="color: #ff0000;">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii)</span></p>
<h3>Sweden</h3>
<p>I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin Palö Forsström (by now Dr. Malin Palö Forsström),  who wrote her excellent Ph. D. thesis under the supervision of Jeff Steif in Chalmers University. We also used the opportunity for a lovely mini-mini-workshop</p>
<p>From Gothenburg I took the train to Stockholm to spend the weekend with Anders Björner and we talked about some old projects regarding algebraic shifting.  We had dinner with several colleagues including Svante Linusson who is a candidate for the European parliament!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg"><img alt="" class="alignnone size-full wp-image-17296" src="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg?w=640"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg"><img alt="" class="alignnone size-medium wp-image-17297" height="168" src="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg?w=300&amp;h=168" width="300"/></a></p>
<p><span style="color: #ff0000;">Stockholm: With Anders and Cristins in the late 80s (left, I think this was also when I was an opponent), Svante Linusson ten days ago (right)</span></p>
<h3>The United Kingdom</h3>
<p>The <a href="https://www.lancaster.ac.uk/maths/bmc2019/">British Mathematical Colloquium at Lancaster</a> was a lovely 4-day general meeting, an opportunity to meet some old and new friends (and Internet MO friend <a href="https://mathoverflow.net/users/763/yemon-choi">Yemon Choi</a> in real life), and to learn about various new developments. I am aware of the fact that my list of unfulfilled promises is longer than those of most politicians, but I do hope to come back to some mathematics from this trip to Sweden and to Lancaster.</p>
<h3>Election Day</h3>
<p>Last week’s Tuesday was election day in Israel,  and as much as I like to participate (and to devote a post to election day here on the blog – in <a href="https://gilkalai.wordpress.com/2009/02/10/majority-rules-the-story-of-achnais-oven/">2009</a>, <a href="https://gilkalai.wordpress.com/2013/01/22/election-day/">2012</a>, and <a href="https://gilkalai.wordpress.com/2015/03/17/election-day-2/">2015</a>) I had to miss the election, for the first time since 1985. (I still tried to follow the outcomes in real time.)</p>
<h3>The Negev, Israel</h3>
<p>And we are now spending a three-day vacation and doing some mild hiking in Mitzpe Ramon, in the Negev, the Israeli desert.  The view around here is spectacular. I first fell in love with the sights of the Negev when I spent six months here when I was 19 (in the army). Since then we have been caming here many times over the years, and in 2002 the annual meeting of the Israeli Mathematical Union took place here, in the same hotel.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg"><img alt="" class="alignnone size-medium wp-image-17298" height="300" src="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg?w=169&amp;h=300" width="169"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg"> <img alt="" class="alignnone size-medium wp-image-17299" height="165" src="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg?w=300&amp;h=165" width="300"/></a></p>
<p><span style="color: #ff0000;">Ein Ovdat (left). The 2002 Annual meeting of the IMU (right). A large number of Israeli mathematicians come to a substantial fraction of these annual events.</span></p>
<h3>The stance of the main Israeli parties on quantum computing</h3>
<p>One anecdote about the Israeli election is that both major political parties of Israel, the Likud, led by Benjamin (Bibi) Netanyahu that won 35 seats in the parliament and will probably lead the coalition, and the newly formed “Blue-and-White” party, led by Benny (Benjamin) Gantz that also won 35 seats and will probably lead the opposition, stand behind quantum computing! <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png"><img alt="" class="alignnone size-medium wp-image-17121" height="233" src="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png?w=300&amp;h=233" width="300"/></a><a href="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png"> <img alt="" class="alignnone size-medium wp-image-17302" height="258" src="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png?w=300&amp;h=258" width="300"/></a></p>
<p><span style="color: #ff0000;">Left – A paragraph from “Blue and White’s” charter with a pledge to quantum computing (I thank Noam Lifshitz for telling me about it). Right –  a news item (<a href="https://en.globes.co.il/en/article-government-allocates-nis-300m-for-quantum-computing-1001244244">click for the article</a>) about the quantum computing vision of Netanyahu and the Likud party.</span></p>
<p> </p></div>
    </content>
    <updated>2019-04-17T19:10:12Z</updated>
    <published>2019-04-17T19:10:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Updates"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-18T21:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4227</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/" rel="alternate" type="text/html"/>
    <title>Online Optimization for Complexity Theorists</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was … <a href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was coming up in several papers that I wanted to understand, and I felt that I was missing out by not mastering an important tool. In particular, I wanted to understand: </p>
<ol>
<li> The <a href="https://dl.acm.org/citation.cfm?id=1496770.1496899">Barak-Hardt-Kale</a> proof of the <a href="https://ieeexplore.ieee.org/document/492584">Impagliazzo hard-core lemma</a>.
</li><li> The online convex optimization viewpoint on the <a href="https://ieeexplore.ieee.org/document/548459">Frieze-Kannan weak regularity lemma</a>, on the dense model theorem of <a href="https://ieeexplore.ieee.org/document/4690942">(RTTV)</a>, and on the abstract weak regularity lemma of <a href="https://ieeexplore.ieee.org/document/5231258">(TTV)</a> that were described to me by Madhur Tulsiani a few years ago. Furthermore, I wanted to see if Russel Impagliazzo’s subsequent improvements to the dense model theorem and to the abstract weak regularity lemma could be recovered from this point of view.
</li><li> The <a href="https://dl.acm.org/citation.cfm?doid=2906142.2837020">Arora-Kale</a> algorithms for semidefinite programming, including their nearly linear-time algorithm for approximating the Goemans-Williamson relaxation of Max Cut.
</li><li> The meaning of the sentence “multiplicative weights and gradient descent are both special cases of follow-the-regularized-leader, using negative entropy and <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> as regularizer, respectively.”
</li><li> The <a href="https://arxiv.org/abs/1506.04838">AllenZhu-Liao-Orecchia</a> online optimization proof of the Batson-Spielman-Srivastava sparsification result.
</li></ol>
<p>
I am happy to say that, except for the “furthermore” part of (2), I achieved my goals. To digest this material a bit better, I came up with the rather ambitious plan of writing a series of posts, in which I would alternate between (i) explaining a notion or theorem from online convex optimization (at a level that someone learning about optimization or machine learning might find useful) and (ii) explaining a complexity-theoretic application. Now that a very intense Spring semester is almost over, I plan to get started on this plan, although it is not clear that I will see it through the end. So stay tuned for the forthcoming first episode, which will be about the good old multiplicative weights algorithm.</p>
<p/></div>
    </content>
    <updated>2019-04-17T15:27:23Z</updated>
    <published>2019-04-17T15:27:23Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-18T21:20:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4224</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/" rel="alternate" type="text/html"/>
    <title>The Early Years of Computing in Italy</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here are in theory‘s first ever book reviews! The books are Giorgio Garuzzo Quando in Italia si facevano i computer Available for free at Amazon.com and Amazon.it. Giorgio Ausiello The Making of a New Science Available from Springer, as a … <a href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here are <i>in theory</i>‘s first ever book reviews! The books are</p>
<p>Giorgio Garuzzo<br/>
<i>Quando in Italia si facevano i computer</i><br/>
Available for free at <a href="https://www.amazon.com/gp/product/B017PTTUKY">Amazon.com</a> and <a href="https://www.amazon.it/Quando-facevano-computer-Giorgio-Garuzzo-ebook/dp/B017PTTUKY">Amazon.it</a>.</p>
<p>Giorgio Ausiello<br/>
<i>The Making of a New Science</i><br/>
Available from <a href="https://www.springer.com/us/book/9783319626796">Springer</a>, as a DRM-free PDF through your academic library.</p>
<p>Both books talk about the early years of computing in Italy, on the industrial and academic side, respectively. They briefly intersect with the story of Olivetti’s Elea computer.</p>
<p><span id="more-4224"/></p>
<p>Olivetti was a company that was founded in 1908 to make typewriters, and then branched out to other office/business machines and avionics. In the 1930s, Adriano Olivetti, a son of the founder Camillo Olivetti, took over the company. Adriano Olivetti was an unusual figure of entrepreneur deeply interested in arts, humanities and social sciences, with a utopian vision of a company reinvesting its profits in its community. In the 1950s, he led the company to develop the Elea, the first Italian computer. The Elea was made with transistors, and it came out before IBM had built its own first transistor-based computer.</p>
<p>The development of Elea was led by Mario Tchou. Mario Tchou was a Chinese-Italian born and raised in Rome, who studied electrical engineering at the Sapienza University of Rome and then at Brooklyn Polytechnic, eventually becoming an assistant professor at Columbia University. Olivetti persuaded Tchou to move back to Italy and lead the development of Elea, whose first prototype came out in 1957. </p>
<p>As production was ramping up, tragedy struck: Adriano Olivetti died in 1960, and Mario Tchou died in 1961. To shore up the finances of the company, the new CEO Roberto Olivetti brought in a series of new investors, who pushed to spin off the computer business.</p>
<p>At that point, Olivetti was working on another revolutionary machine, the P101, a programmable desktop calculator billed as the “first desktop computer,” which came out in 1964, attracting huge interest. Nonetheless the company spun off its “computer” division into a joint venture with GE, eventually divesting of it completely. Fortunately, they kept control of the P101 project, because those working on it were careful in branding it internally as a “calculator” (not part of the of deal with GE) rather than a “computer.”</p>
<p>These events are narrated, with a fascinating insider view, in Garuzzo’s book.</p>
<p>Giorgio Ausiello is one of the founding fathers of academic computer science in Italy. His book is a professional memoir that starts in the 1960s, at the time in which he started working on his undergraduate thesis at the Istituto Nazionale per le Applicazioni del Calcolo (INAC, later renamed IAC) at the National Research Council in Rome. At that point INAC had one of Italy’s few computers, a machine bought in 1954 from the Ferranti company in Manchester (when it was installed, it was Italy’s <i>second</i> computer).</p>
<p>As narrated in a <a href="https://lucatrevisan.wordpress.com/2017/10/23/corrado-bohm/">previous post</a>, Mauro Picone, the mathematician who was leading INAC, brought Corrado Bohm to Rome to work on this computer, and Ausiello started to work with Bohm at the time in which he was just starting to think about models of computation and lambda-calculus.</p>
<p>Later, Ausiello visited Berkeley in the 1968-69 academic year, when Manuel Blum and Dick Karp had just joined the faculty. Ausiello took part in the first STOC, which was held in Marina del Rey in May 1969, and, later that month, he witnessed the occupation of <a href="https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)">People’s Park</a> in Berkeley.</p>
<p>The Fall of 1969 marks the start of the first Italian undergraduate programs in Computer Science, in just four universities:  Bari, <del datetime="2019-04-17T11:04:18-07:00">Milan,</del> Pisa and Torino. Back in Italy from Berkeley, Ausiello continued to work at the National Research Council in Rome.</p>
<p>The book continues with a behind-the-scene narration of the events that led to the founding of the EATCS professional society, the ICALP conference and the TCS journal. There is also another trip to Berkeley in the 1980s, featuring Silvio Micali and Vijay Vazirani working on their matching algorithm, and Shafi Goldwasser just arriving in Berkeley.</p>
<p>Methodically documented and very detail-oriented, the book is a fascinating read, although it leaves you sometimes wanting to hear more about the personalities and the stories of the people involved and less about the attendance lists of certain meetings.</p>
<p>Even when it comes to the dryer details, however, I am happy that the books documents them and makes them available to future generations that will not have any living memory of the 1960s and 1970s.</p>
<p>I should also mention that Alon Rosen has recently interviewed <a href="https://www.youtube.com/watch?v=vKCE7QnsFcw&amp;t=67s">Christos Papadimitriou</a> and <a href="https://www.youtube.com/watch?v=-GQnK6ys6C0&amp;t=20s">Avi Wigderson</a> and those (<i>long</i>) interviews are full of good stories. Finally, the Simons Foundation site has an <a href="https://www.simonsfoundation.org/2013/02/14/laszlo-lovasz/">interview of Laszlo Lovasz</a> in conversation with Avi Wigderson which I very highly recommend everybody to watch.</p></div>
    </content>
    <updated>2019-04-17T00:52:21Z</updated>
    <published>2019-04-17T00:52:21Z</published>
    <category term="Berkeley"/>
    <category term="history"/>
    <category term="Italy"/>
    <category term="theory"/>
    <category term="Elea"/>
    <category term="Giorgio Ausiello"/>
    <category term="Giorgio Garuzzo"/>
    <category term="Mario Tchou"/>
    <category term="Olivetti"/>
    <category term="P101"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-18T21:20:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/058" rel="alternate" type="text/html"/>
    <title>TR19-058 |  Extractors for small zero-fixing sources | 

	Pavel Pudlak, 

	Vojtech Rodl</title>
    <summary>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset $V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$ that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for $(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some $m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$. Zero-fixing sources were introduced by Cohen and Shinkar in~2015 in connection with the previously studied extractors for bit-fixing sources. They constructed, for every $\mu&gt;0$, an efficiently computable extractor that extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from $(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$. 

In this paper we present two different constructions of extractors for zero-fixing sources that are able to extract a positive fraction of entropy for $k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq C\log\log\log n$, for some constant $C$. The second extractor extracts a positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in \N$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The fraction of extracted entropy decreases with $i$. The first extractor is a function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too small); the second one is computable in polynomial time when $k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.</summary>
    <updated>2019-04-16T15:10:03Z</updated>
    <published>2019-04-16T15:10:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-18T21:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/</id>
    <link href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/" rel="alternate" type="text/html"/>
    <title>Tensors: Algebra-Computation-Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 3-14, 2019 U. Colorado Boulder and Colorado State U https://thetensor.space/workshops/2019/02/13/TACA-2019.html The Department of Mathematics at Colorado State University and the Department of Computer Science at the University of Colorado, Boulder invite interested participants to attend a workshop and conference on Tensors: Algebra, Computation, and Applications (TACA). The central theme of tensors is meant to … <a class="more-link" href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/">Continue reading <span class="screen-reader-text">Tensors: Algebra-Computation-Applications</span></a></div>
    </summary>
    <updated>2019-04-16T15:01:44Z</updated>
    <published>2019-04-16T15:01:44Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-04-18T21:21:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?” And then Matthew Scroggs and Adam Townsend went ahead and did it ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://aperiodical.com/2019/03/realhats-writing-a-latex-package/">“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?”</a>
And then Matthew Scroggs and Adam Townsend went ahead and <a href="https://ctan.org/pkg/realhats">did it</a> (<a href="https://mathstodon.xyz/@11011110/101849504150959463"/>).</p>
  </li>
  <li>
    <p><a href="https://syntopia.github.io/Polytopia/polytopes.html">Generating 4d polyhedra from their symmetries</a> (<a href="https://mathstodon.xyz/@11011110/101860652773207990"/>, <a href="https://web.archive.org/web/20190306075446/https://plus.google.com/+RoiceNelson/posts/13EEovjAjh3">via</a>), by Mikael Hvidtfeldt Christensen.</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/04/03/focs-2019-real-website-and-submission-server/">Windows on Theory</a> and <a href="https://www.scottaaronson.com/blog/?p=4154">Scott Aaronson</a> both warn about a fake web site for <a href="http://focs2019.cs.jhu.edu/">FOCS 2019</a>, whose submission deadline just passed (<a href="https://mathstodon.xyz/@11011110/101864693573223236"/>).</p>
  </li>
  <li>
    <p><a href="http://service.ifam.uni-hannover.de/~geometriewerkstatt/gallery/index.html">GeometrieWerkstatt Gallery</a> (<a href="https://mathstodon.xyz/@11011110/101872198999374479"/>). A collection of weirdly-shaped mathematical surfaces, mostly of constant mean curvature.</p>
  </li>
  <li>
    <p><a href="http://focs2019.cs.jhu.edu/awards/">Sandi Irani wins IEEE TCMF Distinguished Service Award</a> (<a href="https://mathstodon.xyz/@11011110/101877216457233962"/>). The award recognizes her work chairing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">ad hoc committee to combat harassment and discrimination in the theory of computing community</a>, and then getting many theory conferences to follow its recommendations.</p>
  </li>
  <li>
    <p><a href="http://web.colby.edu/thegeometricviewpoint/2014/04/25/periodic-billiard-paths/">Periodic billiard paths</a> (<a href="https://mathstodon.xyz/@11011110/101883476235740072"/>). If the boundary of a given polygon is made of mirrors, these are paths that a laser beam could take that would eventually reflect back to the starting point and angle and then repeat infinitely. It remains a heavily-studied open question whether such paths exist in every triangle. This blog post from 2014 provides a proof that they do exist in polygons whose vertex angles are all rational multiples of .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/04/08/with-a-badly-handled-tweet-plos-angers-scientists-after-a-blog-disappears/">PLOS disappears one (or maybe more) of its hosted blogs</a> (<a href="https://mathstodon.xyz/@11011110/101894568161561631"/>) without any warning to the blog author, without any attempt at keeping old blog links still working, and with only a belated apology.</p>
  </li>
  <li>
    <p><a href="https://slate.com/news-and-politics/2019/03/scotus-gerrymandering-case-mathematicians-brief-elena-kagan.html">The Supreme Court’s math problem</a> (<a href="https://mathstodon.xyz/@11011110/101900050555580515"/>, <a href="https://www.metafilter.com/180163/The-Supreme-Courts-Math-Problem">via</a>). Jordan Ellenberg explains why, in testing for gerrymandering, asking about deviation from proportional representation is the wrong question. Democratic systems naturally concentrate power to the majority rather than being proportional. The right question is whether that concentration is at the natural level, or is artificially accelerated in one direction or another.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2019/04/10/official-eu-agencies-falsely-report-more-than-550-archive-org-urls-as-terrorist-content/">EU falsely calls Internet Archive’s major collection pages, scholarly articles, and copies of US government publications “terrorism” and demands they be taken down from the internet</a> (<a href="https://mathstodon.xyz/@11011110/101908397856087187"/>, <a href="https://boingboing.net/2019/04/11/one-hour-service.html">see also</a>). The EU is about to vote to require terrorism takedowns to happen within an hour, and these requests are coming on European times when all Internet Archive employees (in California) are asleep, making manual review of these bad takedowns difficult.</p>
  </li>
  <li>
    <p><a href="https://www.siam.org/Conferences/CM/Main/apocs20">SIAM-ACM Conference on Algorithmic Principles of Computer Systems, APOCS</a> (<a href="https://mathstodon.xyz/@11011110/101909431804808574"/>). This is a new conference to be held with SODA, next January in Salt Lake City, covering “all areas of algorithms and architectures that offer insight into the performance and design of computer systems”. Submission titles and abstracts are due August 9 (with full papers due a week later) so if this is an area you’re interested in there’s still plenty of time to come up with something to submit.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html">Sad news from Berkeley</a>: <a href="https://en.wikipedia.org/wiki/Elwyn_Berlekamp">Elwyn Berlekamp</a> has died (<a href="https://mathstodon.xyz/@11011110/101921251002340100"/>, <a href="https://aperiodical.com/2019/04/elwyn-berlekamp-has-left-us/">see also</a>). Berlekamp made significant contributions to combinatorial game theory (motivated, as I understand it, by the mathematical study of Go endgames), coding theory, and algorithms for polynomials.</p>
  </li>
  <li>
    <p><a href="https://www.berlintransitmap.de/">An unofficially-proposed new Berlin transit map replaces stylized axis-parallel and diagonal line segments with smooth curves</a> (<a href="https://mathstodon.xyz/@11011110"/>, <a href="https://www.metafilter.com/180431/Berlin-Transit-Map-now-with-pleasing-Curves">via</a>). The old design was seen as “out of style”, “too robotized”, and too difficult to follow routes. There’s still a strong preference for axis-parallel and diagonal lines in the new map, but the connections between them have been smoothed out.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-04-15T17:43:00Z</updated>
    <published>2019-04-15T17:43:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kintali.wordpress.com/?p=1225</id>
    <link href="https://kintali.wordpress.com/2019/04/15/a-personal-story-of-a-founder/" rel="alternate" type="text/html"/>
    <title>A Personal Story of a Founder</title>
    <summary>Disclaimer: This blog post is not intended to offend University of Pennsylvania or IIT Kharagpur or Yahoo or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing TrueCerts platform. The year was 2005. I was applying for a PhD program in Computer Science in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="graf graf--p graf-after--p" id="7e4b"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Disclaimer:</em></strong><em class="markup--em markup--p-em"> This blog post is not intended to offend </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/University_of_Pennsylvania" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">University of Pennsylvania</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Indian_Institute_of_Technology_Kharagpur" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">IIT Kharagpur</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Yahoo!" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Yahoo</em></a><em class="markup--em markup--p-em"> or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing </em><a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">TrueCerts</em></a><em class="markup--em markup--p-em"> platform.</em></p>
<p class="graf graf--p graf-after--p" id="822b">The year was 2005. I was applying for a PhD program in Computer Science in the top US universities. I have applied to 14 US universities. On Dec 2nd 2015, I received the following email (see the screenshot below) from the University of Pennsylvania (UPenn), Penn Engineering, Office of Academic Programs, Graduate Admissions. I have redacted the name, email address and the phone numbers in the emails, to preserve their privacy.</p>
<p><img alt="upenn1" class="alignnone size-full wp-image-1226" src="https://kintali.files.wordpress.com/2019/04/upenn1.png?w=660"/></p>
<p>Here are the photos of the original transcript (I received from IIT Kharagpur when I graduated) and the additional transcripts (I received from IIT Kharagpur when I requested them for my PhD application). They are all <strong class="markup--strong markup--p-strong">laminated by IIT Kharagpur</strong> and sent to me. Feel free to laugh at my appearance on the transcript. I do too <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p><img alt="kgp" class="alignnone size-full wp-image-1227" src="https://kintali.files.wordpress.com/2019/04/kgp.jpeg?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="e20e">IIT Kharagpur stated the following in their transcripts policy.</p>
<p class="graf graf--p graf--startsWithDoubleQuote graf-after--p" id="60be"><em class="markup--em markup--p-em">“Institute does not take responsibility of sending the duplicate copy of grade cards (transcripts) directly to other institutions/organizations, in connection with the applicants’ admission/employment etc.”</em></p>
<p class="graf graf--p graf-after--p" id="a381">My reply to the above email and the response from UPenn are shown in the following screenshot.</p>
<p><img alt="upenn2" class="alignnone size-full wp-image-1228" src="https://kintali.files.wordpress.com/2019/04/upenn2.png?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="1fc0">In Summary, UPenn was concerned that my transcript is laminated and opened. Surprised at their response (“Your application will not go any further with the opened transcript”), I have spent couple of hours searching online and discovered that there is a lot of scam involving fake degrees and fake transcripts. There are “professionals” in India and China creating the “highest quality fakes”. These fakes are often laminated. So, UPenn decided not to process any applications with opened and laminated credentials. All my credentials are valid and correct, but my application was not processed because IIT Kharagpur has no way to “securely send” valid transcripts and UPenn has no way to “efficiently validate applicants’ transcripts”.</p>
<p class="graf graf--p graf-after--p" id="0588">I have applied to 14 universities and some of them rejected me because ‘they found a better candidate’ or ‘the research group is not looking for new PhD students’ etc etc. But my UPenn application not going further because of an “inefficient and broken system” is frustrating, to say the least.</p>
<p class="graf graf--p graf-after--p" id="291f">After a week, I have recovered from this frustration and went back to my daily routine of reading research papers on Theoretical Computer Science. I said to myself “I will get into one of the remaining 13 universities and I have to focus on research and resolve the <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/P_versus_NP_problem" rel="nofollow noopener" target="_blank">P vs NP problem</a>” <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p class="graf graf--p graf-after--p" id="bc4f"><strong class="markup--strong markup--p-strong">On a lighter note:</strong> There is a simple way to verify that my transcript is valid — ‘Simply open it and look at my grades’. I have received several B’s, some C’s and even couple of D’s. My CGPA is just average. Nobody in their right senses would create a fake transcript with those grades <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> During the last decade, whenever I met any IITian I first set them up telling <a class="markup--anchor markup--p-anchor" href="http://shivakintali.org/" rel="nofollow noopener" target="_blank">my credentials</a> (B-Tech from IIT Kharagpur, Masters from USC, PhD from GeorgiaTech, Taught at Princeton) and after they say “wow”, I bet with them that their CGPA at IIT is greater than mine. I never lost till date. I take pride in this fact <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/> In my defense, I was an all-rounder at IIT Kharagpur, balancing studies, serving as a ‘secretary of fine arts, modeling and dramatics’ of my hostel, painting, learning guitar and many more things.</p>
<p class="graf graf--p graf-after--p" id="d9e1"><strong class="markup--strong markup--p-strong">A second incident:</strong> During summer 2010 (at the end of my fourth year as a PhD student at GeorgiaTech), I was offered an internship at Yahoo labs and the Yahoo HR team said they want to verify all my credentials (my IIT B-Tech degree, USC Master’s degree, work experience). Yahoo uses a third-party service to rigorously verify all credentials of potential employees / interns. <a class="markup--anchor markup--p-anchor" href="https://www.thedailybeast.com/farewell-yahoo-ceo-scott-thompson-ousted-for-a-resume-lie" rel="nofollow noopener" target="_blank">Yahoo fired their own CEO</a> when they found that he lied in his resume. This process is very rigorous, but very time-consuming. The <strong class="markup--strong markup--p-strong">verification of all my credentials took more than couple of months</strong>. Meanwhile, I was waiting with my fingers-crossed (figuratively speaking) and hoping these verifications happen soon, so that I can start my internship and earn some serious summer money for two months and see a bank balance of more than $1,000 dollars for the first time during my grad school <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p class="graf graf--p graf-after--p" id="f5fc">Later that year, when I discovered Bitcoin white paper and the underlying Blockchain, my first thought was to use the technology to build a ‘document integrity platform’ to issue tamper-proof credentials (degrees, transcripts, employment certificates, Visas, Identity documents, driver’s license etc), which can be verified instantaneously and securely on the blockchain.</p>
<p class="graf graf--p graf-after--p" id="96cb">Early 2011, I got busy with writing thesis and joined the CS department Princeton University in September 2011. I have spent the first couple of years teaching at Princeton, mining Bitcoin, keeping track of Blockchain news and hoping that somebody will develop a ‘document integrity platform’. To my relief, some entrepreneurs tried to develop a ‘credential verification solutions’. To my frustration, none of those solutions are perfect. So I started preparing myself to become a full-time entrepreneur and left Princeton in summer 2015.</p>
<p class="graf graf--p graf-after--p" id="5810">Today, I am very glad we have a complete data integrity solution (for universities, employers and enterprises) and I am very excited that we are preventing fraud and corruption in several areas using our <a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank">TrueCerts</a> platform.</p>
<p class="graf graf--p graf-after--p" id="e378">Every week I read several stories about fraud and corruption online (Eg: the recent <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/2019_college_admissions_bribery_scandal" rel="nofollow noopener" target="_blank">college admissions scandal</a>). I approach the involved parties and explain how such instances can be rigorously prevented using technology.</p>
<p class="graf graf--p graf-after--p graf--trailing" id="d84e">I feel very fortunate to have discovered an exciting vision towards a fraud-free and efficient future. This discovery happened through the above mentioned unfortunate events. Sometimes the lowest points in your life have the greatest potential to show you the right path to your highest points.</p></div>
    </content>
    <updated>2019-04-15T04:35:57Z</updated>
    <published>2019-04-15T04:35:57Z</published>
    <category term="blockchain"/>
    <category term="Education"/>
    <category term="IIT Kharagpur"/>
    <category term="upenn"/>
    <category term="Yahoo"/>
    <author>
      <name>kintali</name>
    </author>
    <source>
      <id>https://kintali.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/e1376dd220aa259d0efd0638d7619231?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://kintali.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kintali.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kintali.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kintali.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computational Complexity, Polyhedral Combinatorics, Algorithms and Graph Theory</subtitle>
      <title>My Brain is Open</title>
      <updated>2019-04-18T21:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3262168094346690140</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3262168094346690140/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html" rel="alternate" type="text/html"/>
    <title>Good article, terrible headline</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">About a month ago (after my P NP poll appeared) I got email from Jacob Aron asking me some questions about it. One thing he was excited about was that the number of people who thought P vs NP would be solved in the next decade had increased from 11% to 22%. I told him that this also surprised me and <i>there had been no major advances to warrant that increase.</i><br/>
<i><br/></i>
Then the article came out. Here is the pointer to the headline and the first few lines, the rest is behind a paywall<br/>
<br/>
<a href="https://www.newscientist.com/article/2198151-we-could-solve-the-biggest-problem-in-maths-in-the-next-decade/">here</a><br/>
<br/>
You may notice that the headline is<br/>
<br/>
<i>We could solve the biggest problem in math in the next decade</i><br/>
<i><br/></i>
I emailed Jacob to send me the article, which he did. The article was fine, even quoting me as saying that the increase of people who thought it would be solved soon was unwarranted.<br/>
<br/>
1) So, article fine, headline terrible.<br/>
<br/>
2)  A more honest headline would be<br/>
<br/>
<i>The Complexity Theory Community slightly more optimistic about when P vs NP will be resolved for no apparent reason.</i><br/>
<i><br/></i>
3) More bad science:<a href="https://www.newscientist.com/article/mg22329780-400-turings-oracle-the-computer-that-goes-beyond-logic/">here</a><br/>
<br/>
Headline is<br/>
<br/>
<i>Turing's Oracle: The computer that goes beyond logic</i><br/>
<br/>
I think the article was about how a Turing Machine with an oracle for HALT can solve HALT. (If I am wrong about this let me know in the comments and I'll correct it.)<br/>
<br/>
4) More bad science:<a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">here</a><br/>
<br/>
Headline<br/>
<br/>
<i>Finally, a problem that only Quantum Computers will ever be able to solve.</i><br/>
<i><br/></i>
This was about the oracle such that BQP is not in PH. Really!<br/>
<br/>
5) I invite you to add your own.<br/>
<br/>
6) OKAY, so why is the press SO BAD at reporting on our field? And is it just our field? I have one explanation, though I am sure there are many.<br/>
<br/>
Our field is about showing the LIMITS of computation. Its hard to make that sexy so they ... lie? exaggerate. They themselves don't really understand our field? Note:<br/>
<br/>
To explain to someone who does not really know CS why its important to have an oracle where BQP is not in PH is hard<br/>
<br/>
To explain this to someone IN CS but not in Theory is still hard!<br/>
<br/>
To explain this to someone IN CS and even in CS Theory, but not complexity (e.g., algorithms) might be hard, though it may depend on the person.<br/>
<br/>
7) The old saying is `I don't care if you get the story wrong so long as you spell my name right' And indeed, they did spell my name right. So there is that! But more seriously and less about me or even the article that refers to my poll--- is it bad that science reporting is often wrong?<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-04-15T04:08:00Z</updated>
    <published>2019-04-15T04:08:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-18T20:20:39Z</updated>
    </source>
  </entry>
</feed>
