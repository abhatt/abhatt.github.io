<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-02T23:56:28Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8952301722851173857</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8952301722851173857/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html" rel="alternate" type="text/html"/>
    <title>Local Kid Makes History</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<a href="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s1600/Huang.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s200/Huang.jpg" width="163"/></a>The <a href="https://www.scottaaronson.com/blog/?p=4229">blogosphere</a> is <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">blowing</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">up</a>Â over Hao Huang's just <a href="https://arxiv.org/abs/1907.00847">posted proof</a> of the sensitivity conjecture, what was one of the more <a href="https://blog.computationalcomplexity.org/2017/12/razors-edge.html">frustrating open questions</a> in complexity.<br/>
<br/>
Huang, an assistant professor in the math department at Emory, settled an open question about the hypercube. The hypercube is a graph on N=2<sup>n</sup> vertices where each vertex corresponds to an n-bit string and their are edges between vertices corresponding to strings that differ in a single bit. Think of the set of the strings of odd parity, N/2 vertices with no edges between them. Add any other vertex and it would have n neighbors. Huang showed that no matter how you placed those N/2+1 vertices in the hypercube, some vertex will have at least N<sup>1/2</sup> neighbors. By an <a href="https://doi.org/10.1016/0097-3165(92)90060-8">old result</a> of Gotsman and Linial, Huang's theorem implies the sensitivity conjecture.<br/>
<br/>
I won't go through the shockingly simple proof, the <a href="https://arxiv.org/abs/1907.00847">paper</a> is well written, or you can read the blogs I linked to above or even just Ryan O'Donnell's <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>.<br/>
<br/>
I have nothing more to say than wow, just wow.</div>
    </content>
    <updated>2019-07-02T17:05:00Z</updated>
    <published>2019-07-02T17:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-02T20:28:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7530</id>
    <link href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/" rel="alternate" type="text/html"/>
    <title>Sensitivity conjecture proved!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-jetpack-markdown"><p>In a recent breakthrough, <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> gave a <a href="https://arxiv.org/abs/1907.00847">6 page paper</a> proving the longstanding sensitivity conjecture. (Hat tip, <a href="https://www.scottaaronson.com/blog/?p=4229">Scott Aaronson</a> and <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Gil Kalai</a>. See this <a href="https://cstheory.stackexchange.com/questions/27714/sensitivity-block-sensitivity-conjecture-implications">stackexchange post</a> and <a href="https://eccc.weizmann.ac.il/report/2016/062/">this paper of Avishai</a> for some links to the literature on this.)</p>
<p>The proof is beautiful and simple. I will write a few words here, but it is probably easier for you to just read the <a href="https://arxiv.org/abs/1907.00847">paper</a>. The sensitivity conjecture <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">was known</a> to follow from the following statement: let <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> be the <em>Boolean Cube</em> which is the degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph on <img alt="N=2^n" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^n"/> vertices identified with <img alt="{0,1}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%2C1%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{0,1}^n"/> such that for every <img alt="x,y\in {0,1}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%7B0%2C1%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in {0,1}^n"/>, <img alt="x \sim y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Csim+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \sim y"/> if their Hamming distance is one. Then, the maximum degree of every subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> of size <img alt="&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt;N/2"/> is at least <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{n}"/>.</p>
<p>Hao proves the above statement by showing that there is a <em>signing</em> of the <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> that turns it into a matrix with <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/> and <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="-\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=-%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-\sqrt{n}"/>. That is, he shows (using a simple but clever inductive argument, see the 5 line proof of his Lemma 2.2) that there is an <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> with entries in <img alt="{ 0, \pm 1 }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0%2C+%5Cpm+1+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{ 0, \pm 1 }"/> whose nonzero entries correspond to the edges of the Boolean cube, and such that all the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/> and they sum up to zero. (Note that this makes sense since <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> should have the same <em>Frobenius norm</em> as  the adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/>. The Frobenius norm squared is both the sum of squares of entries, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> for <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> which is a degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph, and also equal to the sum of squares of the eigenvalues, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> if all eigenvalues are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/>.)</p>
<p>Once you have such a signing, the result follows from <a href="https://en.wikipedia.org/wiki/Min-max_theorem#Cauchy_interlacing_theorem">Cauchyâs Interlace Theorem</a> that says that for every <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and any <img alt="M\times M" class="latex" src="https://s0.wp.com/latex.php?latex=M%5Ctimes+M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M\times M"/> matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> that is a principle sub-matrix of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/></p>
<p><img alt="\lambda_{1+N-M} \leq \lambda_1(B) \leq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B1%2BN-M%7D+%5Cleq+%5Clambda_1%28B%29+%5Cleq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_{1+N-M} \leq \lambda_1(B) \leq \lambda_1(A)"/></p>
<p>where <img alt="\lambda_1 \geq \lambda_2 \cdots \geq \lambda_N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1+%5Cgeq+%5Clambda_2+%5Ccdots+%5Cgeq+%5Clambda_N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1 \geq \lambda_2 \cdots \geq \lambda_N"/> are the eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\lambda_1(B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B)"/> is the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>.</p>
<p>Indeed, suppose that <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a subgraph of the Boolean cube of size <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/>. Then the principle submatrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> corresponding to the vertices of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> satisfies <img alt="\lambda_1(B) \geq \lambda_{1+N-M}(B) = \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_%7B1%2BN-M%7D%28B%29+%3D+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_{1+N-M}(B) = \sqrt{n}"/> (since <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/> and the first <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/>).
But itâs easy to show that for every matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is upper bounded by the maximum <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_1"/> norm of its rows, which in our case is the maximum degree of the graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>
</div></div>
    </content>
    <updated>2019-07-02T16:18:34Z</updated>
    <published>2019-07-02T16:18:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-07-02T23:55:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3401</id>
    <link href="https://agtb.wordpress.com/2019/07/02/papafest-september-6-8-columbia/" rel="alternate" type="text/html"/>
    <title>PapaFest (September 6-8 @ Columbia)</title>
    <summary>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.Â  Registration is free.Â  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,Â  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala. More detailsÂ here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.Â  Registration is free.Â  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,Â  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>More detailsÂ <a href="http://papafest.cs.columbia.edu/">here.</a></p></div>
    </content>
    <updated>2019-07-02T12:47:57Z</updated>
    <published>2019-07-02T12:47:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-07-02T23:54:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/</id>
    <link href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/" rel="alternate" type="text/html"/>
    <title>The Autumn school on Machine Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">October 3-11, 2019 Tbilisi, Georgia https://cte.ibsu.edu.ge/autumn/ Registration deadline: October 3, 2019 The school will be organized by the International Black Sea University with the support of Shota Rustaveli National Science Foundation of Georgia (SRNSFG). The intended audience of the autumn school includes BSc, MSc and PhD students, researchers as well as industry professionals from the â¦ <a class="more-link" href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/">Continue reading <span class="screen-reader-text">The Autumn school on MachineÂ Learning</span></a></div>
    </summary>
    <updated>2019-07-02T09:09:23Z</updated>
    <published>2019-07-02T09:09:23Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-02T23:55:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/</id>
    <link href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/" rel="alternate" type="text/html"/>
    <title>PapaFest for Christosâ 70th birthday</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 6-8, 2019 Columbia University http://papafest.cs.columbia.edu/ We are happy to invite you to Columbia University to celebrate Christos Papadimitriouâs contributions to science on the occasion of his 70th birthday, through a mix of talks, panels, and fun activities. One of worldâs leading computer scientists, Christos is best known for his work in computational complexity, helping â¦ <a class="more-link" href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/">Continue reading <span class="screen-reader-text">PapaFest for Christosâ 70thÂ birthday</span></a></div>
    </summary>
    <updated>2019-07-02T08:32:49Z</updated>
    <published>2019-07-02T08:32:49Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-02T23:55:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4229</id>
    <link href="https://www.scottaaronson.com/blog/?p=4229" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4229#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4229" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sensitivity Conjecture resolved</title>
    <summary xml:lang="en-US">The Sensitivity Conjecture, which I blogged about here, says that, for every Boolean function f:{0,1}nâ{0,1}, the sensitivity of fâthat is, the maximum, over all 2n input strings xâ{0,1}n, of the number of input bits such that flipping them changes the value of fâis at most polynomially smaller than a bunch of other complexity measures of [â¦]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Sensitivity Conjecture, which I blogged about <a href="https://www.scottaaronson.com/blog/?p=453">here</a>, says that, for every Boolean function f:{0,1}<sup>n</sup>â{0,1}, the <em>sensitivity</em> of fâthat is, the maximum, over all 2<sup>n</sup> input strings xâ{0,1}<sup>n</sup>, of the number of input bits such that flipping them changes the value of fâis at most polynomially smaller than a bunch of other complexity measures of f, including fâs block sensitivity, degree as a real polynomial, and classical and quantum query complexities.  (For more, see for example <a href="http://www.cs.columbia.edu/~rocco/Teaching/S12/Readings/BdW.pdf">this survey</a> by Buhrman and de Wolf.  Or for quick definitions of the relevant concepts, <a href="https://cstheory.stackexchange.com/questions/19902/boolean-functions-where-sensitivity-equals-block-sensitivity">see here</a>.)</p>



<p>Ever since it was posed by Nisan and Szegedy in 1989, this conjecture has stood as one of the most frustrating and embarrassing open problems in all of combinatorics and theoretical computer science.  It seemed so easy, and so similar to other statements that had 5-line proofs.  But a lot of the best people in the field sank months into trying to prove it.  For whatever itâs worth, I also sank â¦ well, at least weeks into it.</p>



<p>Now <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a>, a mathematician at Emory University, has posted a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">6-page preprint</a> on his homepage that finally proves the Sensitivity Conjecture, in the form s(f)â¥âdeg(f).  (I thank Ryan OâDonnell for tipping me off to this.)  Within the preprint, the proof itself is about a page and a half.</p>



<p>Whenever thereâs an announcement like this, ~99% of the time either the proof is wrong, or at any rate itâs way too complicated for outsiders to evaluate it quickly.  This is one of the remaining 1% of cases.  Iâm rather confident that the proof is right.  Why?  Because I read and understood it.  It took me about half an hour.  If youâre comfortable with concepts like <em>induced subgraph</em> and <em>eigenvalue</em>, you can do the same.</p>



<p>From pioneering work by Gotsman and Linial in 1992, it was known that to prove the Sensitivity Conjecture, it suffices to prove the following even simpler combinatorial conjecture:</p>



<blockquote class="wp-block-quote"><p>Let S be any subset of the n-dimensional Boolean hypercube, {0,1}<sup>n</sup>, which has size 2<sup>n-1</sup>+1.  Then there must be a point in S with at least ~n<sup>c</sup> neighbors in S.</p></blockquote>



<p>Here c&gt;0 is some constant (say 1/2), and two points in S are âneighborsâ if and only they differ in a single coordinate.  Note that if S had size 2<sup>n-1</sup>, then the above statement would be falseâas witnessed, for example, by the set of all n-bit strings with an even number of 1âs.</p>



<p>Huang proceeds by proving the Gotsman-Linial Conjecture.  And the way he proves Gotsman-Linial is â¦ well, at this point maybe I should just let you <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">read the damn preprint</a> yourself.  I canât say it more simply than he does.</p>



<p>If I had to try anyway, Iâd say: Huang constructs a 2<sup>n</sup>Ã2<sup>n</sup> matrix, called A<sub>n</sub>, that has 0âs where there are no edges between the corresponding vertices of the Boolean hypercube, and either 1âs or -1âs where there <em>are</em> edgesâwith a simple, weird pattern of 1âs and -1âs that magically makes everything work.  He then lets H be an induced subgraph of the Boolean hypercube of size 2<sup>n-1</sup>+1.  He lower-bounds the maximum degree of H by the largest eigenvalue of the corresponding (2<sup>n-1</sup>+1)Ã(2<sup>n-1</sup>+1) submatrix of A<sub>n</sub>.  Finally, he lower-bounds that largest eigenvalue by â¦ no, I donât want to spoil it!  Read it yourself!</p>



<p>Paul ErdÃ¶s famously spoke of a book, maintained by God, in which was written the simplest, most beautiful proof of each theorem.  The highest compliment ErdÃ¶s could give a proof was that it âcame straight from the book.â  In this case, I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.</p>



<p>Indeed, the question is: how could such an elementary 1.5-page argument have been overlooked for 30 years?  I donât have a compelling answer to that, besides noting that âshortâ and âelementaryâ often have little to do with âobvious.â  Once you start looking at the spectral properties of this matrix A<sub>n</sub>, the pieces snap together in precisely the right wayâbut how would you know to look at that?</p>



<p>By coincidence, earlier today I finished reading my first PG Wodehouse novel (<em><a href="http://www.gutenberg.org/files/10554/10554-h/10554-h.htm">Right Ho, Jeeves!</a></em>), on the gushing recommendation of a friend.  I donât know how Iâd missed Wodehouse for 38 years.  His defining talent is his ability to tie together five or six plot threads in a way that feels perfect and inevitable even though you didnât see it coming.  This produces a form of pleasure thatâs nearly indistinguishable from the pleasure one feels in reading a âproof from the book.â  So my pleasure centers are pretty overloaded todayâbut in such depressing times for the world, Iâll take pleasure wherever I can get it.</p>



<p>Huge congratulations to Hao!</p>



<p><strong>Added thought:</strong> What this really is, is one of the purest illustrations Iâve seen in my career of the power and glory of the Pâ NP phenomenon.  We talk all the time about how proofs are easier to verify than to find.  In practice, though, it can be far from obvious that thatâs true.  Consider your typical STOC/FOCS paper: writing it probably took the authors several months, while fully understanding the thing from scratch would probably take â¦ <em>also</em> several months!  If thereâs a gap, itâs only by a factor of 4 or 5 or something.  Whereas in this case, I donât know how long Huang spent searching for the proof, but the combined search efforts of the community add up to years or decades.  The ratio of the difficulty of finding to the difficulty of completely grasping is in the hundreds of thousands or millions.</p>



<p><strong>Another added thought:</strong> Because Hao actually proves a stronger statement than the original Sensitivity Conjecture, it has additional implications, a few of which Hao mentions in his preprint.  Hereâs one he didnât mention: any randomized algorithm to guess the parity of an n-bit string, which succeeds with probability at least 2/3 on the majority of strings, must make at least ~ân queries to the string, while any such quantum algorithm must make at least ~n<sup>1/4</sup> queries.  For more, see the paper <a href="https://arxiv.org/pdf/1312.0036.pdf">Weak Parity</a> by me, Ambainis, Balodis, and Bavarian (Section 6).</p></div>
    </content>
    <updated>2019-07-02T05:15:43Z</updated>
    <published>2019-07-02T05:15:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-02T19:48:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17499</id>
    <link href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="alternate" type="text/html"/>
    <title>Amazing: Hao Huang Proved the Sensitivity Conjecture!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Todayâs arXived amazing paper by Hao Huangâs Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing â the sensitivity conjecture posed â¦ <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Continue reading <span class="meta-nav">â</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Todayâs arXived amazing paper by Hao Huangâs</p>
<p><a href="https://arxiv.org/abs/1907.00847">Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</a></p>
<p>Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing â the sensitivity conjecture posed by Noam Nisan and Mario Szegedi</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg"><img alt="" class="alignnone size-medium wp-image-17505" height="225" src="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg?w=300&amp;h=225" width="300"/></a></p>
<p><span style="color: #ff0000;"><strong>Hao Huang</strong></span></p>
<p><strong>Abstract: </strong>In this paper, we show that every <img alt="2^{n-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}+1"/>-vertex induced subgraph of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-dimensional cube graph has maximum degree at least <img alt="\sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt n"/>. This result is best possible, and improves a logarithmic lower bound shown by Chung, FÃ¼redi, Graham and Seymour in 1988. As a direct consequence, we prove that the sensitivity and degree of a boolean function are polynomially related, solving an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.</p>
<p>The proof relies on important relation between the two problemsÂ  by Gotsman and Linial. It uses beautifully Cauchyâs interlace theorem (for eigenvalues).</p>
<p>Thanks to Noga Alon for telling me about the breakthrough. For more on the conjecture and a polymath project devoted to solve it see <a href="https://www.scottaaronson.com/blog/?p=453">this post</a> on Aaronsonâs Shtetl Optimized (SO).Â  Updates: See also <a href="https://rjlipton.wordpress.com/2016/10/05/congratulations-noam/">this post on GLL</a>, and this <a href="https://www.scottaaronson.com/blog/?p=4229">new lovely post on SO;</a>Â andÂ <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">this post by Boaz Barak </a>on WOT, explains the main ingredient of Huangâs proof.</p>
<p>Also today on the arXive a paper by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pat%C3%A1kov%C3%A1%2C+Z">Zuzana (Zuzka) PatÃ¡kovÃ¡</a> and me: <a href="https://arxiv.org/abs/1907.00885">Intersection Patterns of Planar Sets</a>. Like one of my very first papers âIntersection patterns of convex setsâ the new paper deals with face numbers of nerves of geometric sets.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp1.png"><img alt="" class="alignnone size-full wp-image-17510" src="https://gilkalai.files.wordpress.com/2019/07/kp1.png?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp2.png"><img alt="" class="alignnone size-full wp-image-17511" src="https://gilkalai.files.wordpress.com/2019/07/kp2.png?w=640"/></a></p></div>
    </content>
    <updated>2019-07-02T04:07:15Z</updated>
    <published>2019-07-02T04:07:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Hao Huang"/>
    <category term="sensitivity conjecture"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-02T23:54:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00872</id>
    <link href="http://arxiv.org/abs/1907.00872" rel="alternate" type="text/html"/>
    <title>Improved hardness for H-colourings of G-colourable graphs</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wrochna:Marcin.html">Marcin Wrochna</a>, Stanislav Å½ivnÃ½ <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00872">PDF</a><br/><b>Abstract: </b>We present new results on approximate colourings of graphs and, more
generally, approximate H-colourings and promise constraint satisfaction
problems.
</p>
<p>First, we show NP-hardness of colouring $k$-colourable graphs with
$\binom{k}{\lfloor k/2\rfloor}-1$ colours for every $k\geq 4$. This improves
the result of Bul\'in, Krokhin, and Opr\v{s}al [STOC'19], who gave NP-hardness
of colouring $k$-colourable graphs with $2k-1$ colours for $k\geq 3$, and the
result of Huang [APPROX-RANDOM'13], who gave NP-hardness of colouring
$k$-colourable graphs with $2^{k^{1/3}}$ colours for sufficiently large $k$.
Thus, for $k\geq 4$, we improve from known linear/sub-exponential gaps to
exponential gaps.
</p>
<p>Second, we show that the topology of the box complex of H alone determines
whether H-colouring of G-colourable graphs is NP-hard for all (non-bipartite,
H-colourable) G. This formalises the topological intuition behind the result of
Krokhin and Opr\v{s}al [FOCS'19] that 3-colouring of G-colourable graphs is
NP-hard for all (3-colourable, non-bipartite) G. We use this technique to
establish NP-hardness of H-colouring of G-colourable graphs for H that include
but go beyond $K_3$, including square-free graphs and circular cliques (leaving
$K_4$ and larger cliques open).
</p>
<p>Underlying all of our proofs is a very general observation that adjoint
functors give reductions between promise constraint satisfaction problems.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00847</id>
    <link href="http://arxiv.org/abs/1907.00847" rel="alternate" type="text/html"/>
    <title>Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Hao.html">Hao Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00847">PDF</a><br/><b>Abstract: </b>In this paper, we show that every $(2^{n-1}+1)$-vertex induced subgraph of
the $n$-dimensional cube graph has maximum degree at least $\sqrt{n}$. This
result is best possible, and improves a logarithmic lower bound shown by Chung,
F\"uredi, Graham and Seymour in 1988. As a direct consequence, we prove that
the sensitivity and degree of a boolean function are polynomially related,
solving an outstanding foundational problem in theoretical computer science,
the Sensitivity Conjecture of Nisan and Szegedy.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00845</id>
    <link href="http://arxiv.org/abs/1907.00845" rel="alternate" type="text/html"/>
    <title>Graph-based Nearest Neighbor Search: From Practice to Theory</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Liudmila Prokhorenkova <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00845">PDF</a><br/><b>Abstract: </b>Graph-based approaches are empirically shown to be very successful for
approximate nearest neighbor (ANN) search. However, there has been very little
research on their theoretical guarantees. In this work, we consider both
low-dimensional (d &lt;&lt; log(n)) and high-dimensional (d &gt;&gt; log(n)) regimes and
rigorously analyze the performance of graph-based nearest neighbor algorithms
when the dataset is uniformly distributed on a d-dimensional sphere. For both
regimes, we provide the conditions which guarantee that a graph-based algorithm
solves the ANN problem in just one iteration. In the low-dimensional regime, we
also show that it is possible to solve the exact nearest neighbor problem.
Finally, we discuss how the "small-world" property affects the performance of
graph-based approaches.
</p></div>
    </summary>
    <updated>2019-07-02T23:43:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00817</id>
    <link href="http://arxiv.org/abs/1907.00817" rel="alternate" type="text/html"/>
    <title>The directed 2-linkage problem with length constraints</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bang=Jensen:J=oslash=rgen.html">JÃ¸rgen Bang-Jensen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeo:Anders.html">Anders Yeo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00817">PDF</a><br/><b>Abstract: </b>The {\sc weak 2-linkage} problem for digraphs asks for a given digraph and
vertices $s_1,s_2,t_1,t_2$ whether $D$ contains a pair of arc-disjoint paths
$P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path. This problem is NP-complete
for general digraphs but polynomially solvable for acyclic digraphs
\cite{fortuneTCS10}. Recently it was shown \cite{bercziESA17} that if $D$ is
equipped with a weight function $w$ on the arcs
</p>
<p>which satisfies that all edges have positive weight, then there is a
polynomial algorithm for the variant of the weak-2-linkage problem when both
paths have to be shortest paths in $D$. In this paper we consider the unit
weight case and prove that for every pair constants $k_1,k_2$, there is a
polynomial algorithm which decides whether the input digraph $D$ has a pair of
arc-disjoint paths $P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path and the
length of $P_i$ is no more than $d(s_i,t_i)+k_i$, for $i=1,2$, where
$d(s_i,t_i)$ denotes the length of the shortest $(s_i,t_i)$-path. We prove
that, unless the exponential time hypothesis (ETH) fails, there is no
polynomial algorithm for deciding the existence of a solution $P_1,P_2$ to the
{\sc weak 2-linkage} problem where each path $P_i$ has length at most
$d(s_i,t_i)+ c\log^{1+\epsilon}{}n$ for some constant $c$.
</p>
<p>We also prove that the {\sc weak 2-linkage} problem remains NP-complete if we
require one of the two paths to be a shortest path while the other path has no
restriction on the length.
</p></div>
    </summary>
    <updated>2019-07-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00676</id>
    <link href="http://arxiv.org/abs/1907.00676" rel="alternate" type="text/html"/>
    <title>Space-Efficient Vertex Separators for Treewidth</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kammer:Frank.html">Frank Kammer</a>, Johannes Meintrup, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sajenko:Andrej.html">Andrej Sajenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00676">PDF</a><br/><b>Abstract: </b>Practical applications that use treewidth algorithms have graphs with
treewidth k = O(\sqrt[3]n). Given such n-vertex graphs we present a word-RAM
algorithm to compute vertex separators using only O(n) bits of working memory.
As an application of our algorithm, we show an O(1)- approximation algorithm
for tree decomposition. Our algorithm computes a tree decomposition in c^k
n(log^* n) log log n time using O(n) bits for some constant c.
</p>
<p>We finally show that our tree-decomposition algorithm can be used to solve
several monadic second-order problems using O(n) bits as long as the treewidth
of the graph is smaller than c' log n for some constant 0 &lt; c' &lt; 1.
</p></div>
    </summary>
    <updated>2019-07-02T23:44:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00605</id>
    <link href="http://arxiv.org/abs/1907.00605" rel="alternate" type="text/html"/>
    <title>Online Multidimensional Packing Problems in the Random-Order Model</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>David Naori, Danny Raz Computer Science Department, Technion, Israel) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00605">PDF</a><br/><b>Abstract: </b>We study online multidimensional variants of the generalized assignment
problem which are used to model prominent real-world applications, such as the
assignment of virtual machines with multiple resource requirements to physical
infrastructure in cloud computing. These problems can be seen as an extension
of the well known secretary problem and thus the standard online worst-case
model cannot provide any performance guarantee. The prevailing model in this
case is the random-order model, which provides a useful realistic and robust
alternative. Using this model, we study the $d$-dimensional generalized
assignment problem, where we introduce a novel technique that achieves an
$O(d)$-competitive algorithms and prove a matching lower bound of $\Omega(d)$.
Furthermore, our algorithm improves upon the best-known competitive-ratio for
the online (one-dimensional) generalized assignment problem and the online
knapsack problem.
</p></div>
    </summary>
    <updated>2019-07-02T23:47:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00533</id>
    <link href="http://arxiv.org/abs/1907.00533" rel="alternate" type="text/html"/>
    <title>Learning to Link</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balcan:Maria=Florina.html">Maria-Florina Balcan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dick:Travis.html">Travis Dick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Manuel.html">Manuel Lang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00533">PDF</a><br/><b>Abstract: </b>Clustering is an important part of many modern data analysis pipelines,
including network analysis and data retrieval. There are many different
clustering algorithms developed by various communities, and it is often not
clear which algorithm will give the best performance on a specific clustering
task. Similarly, we often have multiple ways to measure distances between data
points, and the best clustering performance might require a non-trivial
combination of those metrics. In this work, we study data-driven algorithm
selection and metric learning for clustering problems, where the goal is to
simultaneously learn the best algorithm and metric for a specific application.
The family of clustering algorithms we consider is parameterized linkage based
procedures that includes single and complete linkage. The family of distance
functions we learn over are convex combinations of base distance functions. We
design efficient learning algorithms which receive samples from an
application-specific distribution over clustering instances and simultaneously
learn both a near-optimal distance and clustering algorithm from these classes.
We also carry out a comprehensive empirical evaluation of our techniques
showing that they can lead to significantly improved clustering performance.
</p></div>
    </summary>
    <updated>2019-07-02T23:44:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00529</id>
    <link href="http://arxiv.org/abs/1907.00529" rel="alternate" type="text/html"/>
    <title>Exponential-time quantum algorithms for graph coloring problems</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimizu:Kazuya.html">Kazuya Shimizu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mori:Ryuhei.html">Ryuhei Mori</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00529">PDF</a><br/><b>Abstract: </b>The fastest known classical algorithm deciding the $k$-colorability of
$n$-vertex graph requires running time $\Omega(2^n)$ for $k\ge 5$. In this
work, we present an exponential-space quantum algorithm computing the chromatic
number with running time $O(1.9140^n)$ using quantum random access memory
(QRAM). Our approach is based on Ambainis et al's quantum dynamic programming
with applications of Grover's search to branching algorithms. We also present a
polynomial-space quantum algorithm not using QRAM for the graph $20$-coloring
problem with running time $O(1.9575^n)$. In the polynomial-space quantum
algorithm, we essentially show $(4-\epsilon)^n$-time classical algorithms that
can be improved quadratically by Grover's search.
</p></div>
    </summary>
    <updated>2019-07-02T23:43:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00524</id>
    <link href="http://arxiv.org/abs/1907.00524" rel="alternate" type="text/html"/>
    <title>Approximate $\mathbb{F}_2$-Sketching of Valuation Functions</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaroslavtsev:Grigory.html">Grigory Yaroslavtsev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00524">PDF</a><br/><b>Abstract: </b>We study the problem of constructing a linear sketch of minimum dimension
that allows approximation of a given real-valued function $f \colon
\mathbb{F}_2^n \rightarrow \mathbb R$ with small expected squared error. We
develop a general theory of linear sketching for such functions through which
we analyze their dimension for most commonly studied types of valuation
functions: additive, budget-additive, coverage, $\alpha$-Lipschitz submodular
and matroid rank functions. This gives a characterization of how many bits of
information have to be stored about the input $x$ so that one can compute $f$
under additive updates to its coordinates.
</p>
<p>Our results are tight in most cases and we also give extensions to the
distributional version of the problem where the input $x \in \mathbb{F}_2^n$ is
generated uniformly at random. Using known connections with dynamic streaming
algorithms, both upper and lower bounds on dimension obtained in our work
extend to the space complexity of algorithms evaluating $f(x)$ under long
sequences of additive updates to the input $x$ presented as a stream. Similar
results hold for simultaneous communication in a distributed setting.
</p></div>
    </summary>
    <updated>2019-07-02T23:47:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00523</id>
    <link href="http://arxiv.org/abs/1907.00523" rel="alternate" type="text/html"/>
    <title>Geodesic Centroidal Voronoi Tessellations: Theories, Algorithms and Applications</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Zipeng.html">Zipeng Ye</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Ran.html">Ran Yi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Minjing.html">Minjing Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yong=Jin.html">Yong-Jin Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Ying.html">Ying He</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00523">PDF</a><br/><b>Abstract: </b>Nowadays, big data of digital media (including images, videos and 3D
graphical models) are frequently modeled as low-dimensional manifold meshes
embedded in a high-dimensional feature space. In this paper, we summarized our
recent work on geodesic centroidal Voronoi tessellations(GCVTs), which are
intrinsic geometric structures on manifold meshes. We show that GCVT can find a
widely range of interesting applications in computer vision and graphics, due
to the efficiency of search, location and indexing inherent in these intrinsic
geometric structures. Then we present the challenging issues of how to build
the combinatorial structures of GCVTs and establish their time and space
complexities, including both theoretical and algorithmic results.
</p></div>
    </summary>
    <updated>2019-07-02T23:50:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00484</id>
    <link href="http://arxiv.org/abs/1907.00484" rel="alternate" type="text/html"/>
    <title>Bayesian Generalized Network Design</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lavi:Ron.html">Ron Lavi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Yangguang.html">Yangguang Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00484">PDF</a><br/><b>Abstract: </b>We study network coordination problems, as captured by the setting of
generalized network design (Emek et al., STOC 2018), in the face of uncertainty
resulting from partial information that the network users hold regarding the
actions of their peers. This uncertainty is formalized using Alon et al.'s
Bayesian ignorance framework (TCS 2012). While the approach of Alon et al. is
purely combinatorial, the current paper takes into account computational
considerations: Our main technical contribution is the development of
(strongly) polynomial time algorithms for local decision making in the face of
Bayesian uncertainty.
</p></div>
    </summary>
    <updated>2019-07-02T23:45:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00465</id>
    <link href="http://arxiv.org/abs/1907.00465" rel="alternate" type="text/html"/>
    <title>Fast prototyping of an SDR WLAN 802.11b receiver for an indoor positioning system</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00465">PDF</a><br/><b>Abstract: </b>Indoor positioning systems (IPS) are emerging technologies due to an
increasing popularity and demand in location based service (LBS). Because
traditional positioning systems such as GPS are limited to outdoor
applications, many IPS have been proposed in literature. WLAN-based IPS are the
most promising due to its proven accuracy and infrastructure deployment.
Several WLAN-based IPS have been proposed in the past, from which the best
results have been shown by so-called fingerprint-based systems. This paper
proposes an indoor positioning system which extends traditional WLAN
fingerprinting by using received signal strength (RSS) measurements along with
channel estimates as an effort to improve classification accuracy for scenarios
with a low number of Access Points (APs). The channel estimates aim to
characterize complex indoor environments making it a unique signature for
fingerprinting-based IPS and therefore improving pattern recognition in
radio-maps. Since commercial WLAN cards offer limited measurement information,
software-defined radio (SDR) as an emerging trend for fast prototyping and
research integration is chosen as the best cost-effective option to extract
channel estimates. Therefore, this paper first proposes an 802.11b WLAN SDR
beacon receiver capable of measuring RSS and channel estimates. The SDR is
designed using LabVIEW (LV) environment and leverages several inherent platform
acceleration features that achieve real-time capturing. The receiver achieves a
fast-rate measurement capture of 9 packets per second per AP. The
classification of the propose IPS uses a support vector machine (SVM) for
offline training and online navigation. Several tests are conducted in a
cluttered indoor environment with a single AP in 802.11b legacy mode. Finally,
navigation accuracy results are discussed.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00463</id>
    <link href="http://arxiv.org/abs/1907.00463" rel="alternate" type="text/html"/>
    <title>Exploiting Acceleration Features of LabVIEW platform for Real-Time GNSS Software Receiver Optimization</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00463">PDF</a><br/><b>Abstract: </b>This paper presents the new generation of LabVIEW-based GPS receiver testbed
that is based on National Instruments' (NI) LabVIEW (LV) platform in
conjunction to C/C++ dynamic link libraries (DLL) used inside the platform for
performance execution. This GPS receiver has been optimized for real-time
operation and has been developed for fast prototyping and easiness on future
additions and implementations to the system. The receiver DLLs are divided into
three baseband modules: acquisition, tracking, and navigation. The openness of
received baseband modules allows for extensive research topics such as signal
quality improvement on GPS-denied areas, signal spoofing, and signal
interferences. The hardware used in the system was chosen with an effort to
achieve portability and mobility in the SDR receiver. Several acceleration
factors that accomplish real-time operation and that are inherent to LabVIEW
mechanisms, such as multithreading, parallelization and dedicated
loop-structures, are discussed. The proposed SDR also exploits C/C++
optimization techniques for single-instruction multiple-data (SIMD) capable
processors in software correlators for real-time operation of GNSS tracking
loops. It is demonstrated that LabVIEW-based solutions provide competitive
real-time solutions for fast prototyping of receiver algorithms.
</p></div>
    </summary>
    <updated>2019-07-02T23:25:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00460</id>
    <link href="http://arxiv.org/abs/1907.00460" rel="alternate" type="text/html"/>
    <title>A Reduced Complexity Cross-correlation Interference Mitigation Technique on a Real-time Software-defined Radio GPS L1 Receiver</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruble:Zach_A=.html">Zach A. Ruble</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pack:Daniel_J=.html">Daniel J. Pack</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00460">PDF</a><br/><b>Abstract: </b>The U.S. global position system (GPS) is one of the existing global
navigation satellite systems (GNSS) that provides position and time information
for users in civil, commercial and military backgrounds. Because of its
reliance on many applications nowadays, it's crucial for GNSS receivers to have
robustness to intentional or unintentional interference. Because most
commercial GPS receivers are not flexible, software-defined radio emerged as a
promising solution for fast prototyping and research on interference mitigation
algorithms. This paper provides a proposed minimum mean-squared error (MMSE)
interference mitigation technique which is enhanced for computational
feasibility and implemented on a real-time capable GPS L1 SDR receiver. The GPS
SDR receiver SW has been optimized for real-time operation on National
Instruments' LabVIEW (LV) platform in conjunction with C/C++ dynamic link
libraries (DLL) for improved efficiency. Performance results of said algorithm
with real signals and injected interference are discussed. The proposed SDR
receiver gains in terms of BER curves for several interferers are demonstrated.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00412</id>
    <link href="http://arxiv.org/abs/1907.00412" rel="alternate" type="text/html"/>
    <title>Upper bounds on the graph minor theorem</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Martin Krombholz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rathjen:Michael.html">Michael Rathjen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00412">PDF</a><br/><b>Abstract: </b>Lower bounds on the proof-theoretic strength of the graph minor theorem were
found over 30 years ago by Friedman, Robertson and Seymour 1987, but upper
bounds have always been elusive. We present recently found upper bounds on the
graph minor theorem and other theorems appearing in the Graph Minors series.
Further, we give some ideas as to how the lower bounds on some of these
theorems might be improved.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00317</id>
    <link href="http://arxiv.org/abs/1907.00317" rel="alternate" type="text/html"/>
    <title>Waiting is not easy but worth it: the online TSP on the line revisited</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pei-Chuan Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liao:Chung=Shou.html">Chung-Shou Liao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei:Hao=Ting.html">Hao-Ting Wei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00317">PDF</a><br/><b>Abstract: </b>We consider the online traveling salesman problem on the real line (OLTSPL)
in which a salesman begins at the origin, traveling at no faster than unit
speed along the real line, and wants to serve a sequence of requests, arriving
online over time on the real line and return to the origin as quickly as
possible. The problem has been widely investigated for more than two decades,
but was just optimally solved by a deterministic algorithm with a competitive
ratio of $(9+\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017,
pp.994--1005].
</p>
<p>In this study we present lower bounds and upper bounds for randomized
algorithms in the OLTSPL. Precisely, we show, for the first time, that a simple
randomized \emph{zealous} algorithm can improve the optimal deterministic
algorithm. Here an algorithm is called zealous if waiting strategies are not
allowed to use for the salesman as long as there are unserved requests.
Moreover, we incorporate a natural waiting scheme into the randomized
algorithm, which can even achieve the lower bound we propose for any randomized
algorithms, and thus it is optimal. We also consider randomized algorithms
against a \emph{fair} adversary, i.e. an adversary with restricted power that
requires the salesman to move within the convex hull of the origin and the
requests released so far. The randomized non-zealous algorithm can outperform
the optimal deterministic algorithm against the fair adversary as well.
</p></div>
    </summary>
    <updated>2019-07-02T23:29:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00309</id>
    <link href="http://arxiv.org/abs/1907.00309" rel="alternate" type="text/html"/>
    <title>Isomorphism problems for tensors, groups, and cubic forms: completeness and reductions</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grochow:Joshua_A=.html">Joshua A. Grochow</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiao:Youming.html">Youming Qiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00309">PDF</a><br/><b>Abstract: </b>In this paper we consider the problems of testing isomorphism of tensors,
$p$-groups, cubic forms, algebras, and more, which arise from a variety of
areas, including machine learning, group theory, and cryptography. These
problems can all be cast as orbit problems on multi-way arrays under different
group actions. Our first two main results are:
</p>
<p>1. All the aforementioned isomorphism problems are equivalent under
polynomial-time reductions, in conjunction with the recent results of
Futorny-Grochow-Sergeichuk (Lin. Alg. Appl., 2019).
</p>
<p>2. Isomorphism of $d$-tensors reduces to isomorphism of 3-tensors, for any $d
\geq 3$.
</p>
<p>Our results suggest that these isomorphism problems form a rich and robust
equivalence class, which we call Tensor Isomorphism-complete, or TI-complete.
We then leverage the techniques used in the above results to prove two
first-of-their-kind results for Group Isomorphism (GpI):
</p>
<p>3. We give a reduction from GpI for $p$-groups of exponent $p$ and small
class ($c &lt; p$) to GpI for $p$-groups of exponent $p$ and class 2. The latter
are widely believed to be the hardest cases of GpI, but as far as we know, this
is the first reduction from any more general class of groups to this class.
</p>
<p>4. We give a search-to-decision reduction for isomorphism of $p$-groups of
exponent $p$ and class 2 in time $|G|^{O(\log \log |G|)}$. While
search-to-decision reductions for Graph Isomorphism (GI) have been known for
more than 40 years, as far as we know this is the first non-trivial
search-to-decision reduction in the context of GpI.
</p>
<p>Our main technique for (1), (3), and (4) is a linear-algebraic analogue of
the classical graph coloring gadget, which was used to obtain the
search-to-decision reduction for GI. This gadget construction may be of
independent interest and utility. The technique for (2) gives a method for
encoding an arbitrary tensor into an algebra.
</p></div>
    </summary>
    <updated>2019-07-02T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00289</id>
    <link href="http://arxiv.org/abs/1907.00289" rel="alternate" type="text/html"/>
    <title>Conjugate Gradients and Accelerated Methods Unified: The Approximate Duality Gap View</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Jelena.html">Jelena Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orecchia:Lorenzo.html">Lorenzo Orecchia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00289">PDF</a><br/><b>Abstract: </b>This note provides a novel, simple analysis of the method of conjugate
gradients for the minimization of convex quadratic functions. In contrast with
standard arguments, our proof is entirely self-contained and does not rely on
the existence of Chebyshev polynomials. Another advantage of our development is
that it clarifies the relation between the method of conjugate gradients and
general accelerated methods for smooth minimization by unifying their analyses
within the framework of the Approximate Duality Gap Technique that was
introduced by the authors.
</p></div>
    </summary>
    <updated>2019-07-02T23:29:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00278</id>
    <link href="http://arxiv.org/abs/1907.00278" rel="alternate" type="text/html"/>
    <title>Most abundant isotope peaks and efficient selection on $Y=X_1+X_2+\cdots + X_m$</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Patrick Kreitzberg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lucke:Kyle.html">Kyle Lucke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Serang:Oliver.html">Oliver Serang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00278">PDF</a><br/><b>Abstract: </b>The isotope masses and relative abundances for each element are fundamental
chemical knowledge. Computing the isotope masses of a compound and their
relative abundances is an important and difficult analytical chemistry problem.
We demonstrate that this problem is equivalent to sorting
$Y=X_1+X_2+\cdots+X_m$. We introduce a novel, practically efficient method for
computing the top values in $Y$. then demonstrate the applicability of this
method by computing the most abundant isotope masses (and their abundances)
from compounds of nontrivial size.
</p></div>
    </summary>
    <updated>2019-07-02T23:27:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00253</id>
    <link href="http://arxiv.org/abs/1907.00253" rel="alternate" type="text/html"/>
    <title>Asynchronous Behavior Trees with Memory aimed at Aerial Vehicles with Redundancy in Flight Controller</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Safronov:Evgenii.html">Evgenii Safronov</a>, Michael Vilzmann, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsetserukou:Dzmitry.html">Dzmitry Tsetserukou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kondak:Konstantin.html">Konstantin Kondak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00253">PDF</a><br/><b>Abstract: </b>Complex aircraft systems are becoming a target for automation. For successful
operation, they require both efficient and readable mission execution system.
Flight control computer (FCC) units, as well as all important subsystems, are
often duplicated. Discrete nature of mission execution systems does not allow
small differences in data flow among redundant FCCs which are acceptable for
continuous control algorithms. Therefore, mission state consistency has to be
specifically maintained. We present a novel mission execution system which
includes FCC state synchronization. To achieve this result we developed a new
concept of Asynchronous Behavior Tree with Memory and proposed a state
synchronization algorithm. The implemented system was tested and proven to work
in a real-time simulation of High Altitude Pseudo Satellite (HAPS) mission.
</p></div>
    </summary>
    <updated>2019-07-02T23:43:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00239</id>
    <link href="http://arxiv.org/abs/1907.00239" rel="alternate" type="text/html"/>
    <title>QCSP monsters and the demise of the Chen Conjecture</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhuk:Dmitriy.html">Dmitriy Zhuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Martin:Barnaby.html">Barnaby Martin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00239">PDF</a><br/><b>Abstract: </b>We give a surprising classification for the computational complexity of
Quantified Constraint Satisfaction Problems, QCSP$(\Gamma)$, where $\Gamma$ is
a finite language over $3$ elements which contains all constants. In
particular, such problems are either in P, NP-complete, co-NP-complete or
Pspace-complete. Our classification refutes the hitherto widely-believed Chen
Conjecture. Additionally, we show that already on 4-element domain there exists
a constraint language $\Gamma$ such that QCSP$(\Gamma)$ is DP-complete (from
Boolean Hierarchy), and on 10-element domain there exists a constraint language
giving a complexity class different from all the above classes. Meanwhile, we
prove the Chen Conjecture for finite conservative languages $\Gamma$. If the
polymorphism clone of $\Gamma$ has the polynomially generated powers (PGP)
property then QCSP$(\Gamma)$ is in NP. Otherwise, the polymorphism clone of
$\Gamma$ has the exponentially generated powers (EGP) property and
QCSP$(\Gamma)$ is Pspace-complete.
</p></div>
    </summary>
    <updated>2019-07-02T23:25:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00236</id>
    <link href="http://arxiv.org/abs/1907.00236" rel="alternate" type="text/html"/>
    <title>Streaming Quantiles Algorithms with Small Space and Update Time</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ivkin:Nikita.html">Nikita Ivkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberty:Edo.html">Edo Liberty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Kevin.html">Kevin Lang</a>, Zohar Karnin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00236">PDF</a><br/><b>Abstract: </b>Approximating quantiles and distributions over streaming data has been
studied for roughly two decades now. Recently, Karnin, Lang, and Liberty
proposed the first asymptotically optimal algorithm for doing so. This
manuscript complements their theoretical result by providing a practical
variants of their algorithm with improved constants. For a given sketch size,
our techniques provably reduce the upper bound on the sketch error by a factor
of two. These improvements are verified experimentally. Our modified quantile
sketch improves the latency as well by reducing the worst case update time from
$O(1/\varepsilon)$ down to $O(\log (1/\varepsilon))$. We also suggest two
algorithms for weighted item streams which offer improved asymptotic update
times compared to na\"ive extensions. Finally, we provide a specialized data
structure for these sketches which reduces both their memory footprints and
update times.
</p></div>
    </summary>
    <updated>2019-07-02T23:47:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00227</id>
    <link href="http://arxiv.org/abs/1907.00227" rel="alternate" type="text/html"/>
    <title>On Asymmetric Unification for the Theory of XOR with a Homomorphism</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lynch:Christopher.html">Christopher Lynch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marshall:Andrew_M=.html">Andrew M. Marshall</a>, Catherine Meadows, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narendran:Paliath.html">Paliath Narendran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ravishankar:Veena.html">Veena Ravishankar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00227">PDF</a><br/><b>Abstract: </b>Asymmetric unification, or unification with irreducibility constraints, is a
newly developed paradigm that arose out of the automated analysis of
cryptographic protocols. However, there are still relatively few asymmetric
unification algorithms. In this paper we address this lack by exploring the
application of automata-based unification methods. We examine the theory of xor
with a homomorphism, ACUNh, from the point of view of asymmetric unification,
and develop a new automata-based decision procedure. Then, we adapt a recently
developed asymmetric combination procedure to produce a general asymmetric-
ACUNh decision procedure. Finally, we present a new approach for obtaining a
solution-generating asymmetric-ACUNh unification automaton. We also compare our
approach to the most commonly used form of asymmetric unification available
today, variant unification.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00216</id>
    <link href="http://arxiv.org/abs/1907.00216" rel="alternate" type="text/html"/>
    <title>Quadrilateral Mesh Generation II : Meromorphic Quartic Differentials and Abel-Jacobi Condition</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lei:Na.html">Na Lei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Xiaopeng.html">Xiaopeng Zheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Zhongxuan.html">Zhongxuan Luo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Feng.html">Feng Luo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Xianfeng.html">Xianfeng Gu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00216">PDF</a><br/><b>Abstract: </b>This work discovers the equivalence relation between quadrilateral meshes and
meromorphic quartic. Each quad-mesh induces a conformal structure of the
surface, and a meromorphic differential, where the configuration of singular
vertices correspond to the configurations the poles and zeros (divisor) of the
meroromorphic differential. Due to Riemann surface theory, the configuration of
singularities of a quad-mesh satisfies the Abel-Jacobi condition. Inversely, if
a satisfies the Abel-Jacobi condition, then there exists a meromorphic quartic
differential whose equals to the given one. Furthermore, if the meromorphic
quadric differential is with finite, then it also induces a a quad-mesh, the
poles and zeros of the meromorphic differential to the singular vertices of the
quad-mesh. Besides the theoretic proofs, the computational algorithm for
verification of Abel-Jacobi condition is explained in details. Furthermore,
constructive algorithm of meromorphic quartic differential on zero surfaces is
proposed, which is based on the global algebraic representation of meromorphic.
Our experimental results demonstrate the efficiency and efficacy of the
algorithm. This opens up a direction for quad-mesh generation using algebraic
geometric approach.
</p></div>
    </summary>
    <updated>2019-07-02T23:51:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00203</id>
    <link href="http://arxiv.org/abs/1907.00203" rel="alternate" type="text/html"/>
    <title>Upper Bounding GED via Transformations to LSAPE Based on Rings and Machine Learning</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blumenthal:David_B=.html">David B. Blumenthal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bougleux:S=eacute=bastien.html">SÃ©bastien Bougleux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamper:Johann.html">Johann Gamper</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brun:Luc.html">Luc Brun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00203">PDF</a><br/><b>Abstract: </b>The graph edit distance (GED) is a flexible distance measure which is widely
used for inexact graph matching. Since its exact computation is NP-hard,
heuristics are used in practice. A popular approach is to obtain upper bounds
for GED via transformations to the linear sum assignment problem with
error-correction (LSAPE). Typically, local structures and distances between
them are employed for carrying out this transformation, but recently also
machine learning techniques have been used. In this paper, we formally define a
unifying framework LSAPE-GED for transformations from GED to LSAPE. We
introduce rings as a new kind of local structures that are able to capture a
lot of information encoded in the input graphs at a low computational cost.
Furthermore, we propose two new ring based heuristics RING and RING-ML, which
instantiate LSAPE-GED using the traditional and the machine learning based
approach for transforming GED to LSAPE, respectively. Extensive experiments
show that using rings for upper bounding GED significantly improves the state
of the art on datasets where most information resides in the graphs'
topologies.
</p></div>
    </summary>
    <updated>2019-07-02T23:27:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00141</id>
    <link href="http://arxiv.org/abs/1907.00141" rel="alternate" type="text/html"/>
    <title>Approximate Inference in Structured Instances with Noisy Categorical Observations</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heidari:Alireza.html">Alireza Heidari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ilyas:Ihab_F=.html">Ihab F. Ilyas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rekatsinas:Theodoros.html">Theodoros Rekatsinas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00141">PDF</a><br/><b>Abstract: </b>We study the problem of recovering the latent ground truth labeling of a
structured instance with categorical random variables in the presence of noisy
observations. We present a new approximate algorithm for graphs with
categorical variables that achieves low Hamming error in the presence of noisy
vertex and edge observations. Our main result shows a logarithmic dependency of
the Hamming error to the number of categories of the random variables. Our
approach draws connections to correlation clustering with a fixed number of
clusters. Our results generalize the works of Globerson et al. (2015) and
Foster et al. (2018), who study the hardness of structured prediction under
binary labels, to the case of categorical labels.
</p></div>
    </summary>
    <updated>2019-07-02T23:28:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00117</id>
    <link href="http://arxiv.org/abs/1907.00117" rel="alternate" type="text/html"/>
    <title>Min-Max Correlation Clustering via MultiCut</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahmadi:Saba.html">Saba Ahmadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galhotra:Sainyam.html">Sainyam Galhotra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khuller:Samir.html">Samir Khuller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saha:Barna.html">Barna Saha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwartz:Roy.html">Roy Schwartz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00117">PDF</a><br/><b>Abstract: </b>Correlation clustering is a fundamental combinatorial optimization problem
arising in many contexts and applications that has been the subject of dozens
of papers in the literature. In this problem we are given a general weighted
graph where each edge is labeled positive or negative. The goal is to obtain a
partitioning (clustering) of the vertices that minimizes disagreements - weight
of negative edges trapped inside a cluster plus positive edges between
different clusters. Most of the papers on this topic mainly focus on minimizing
total disagreement, a global objective for this problem. In this paper, we
study a cluster-wise objective function that asks to minimize the maximum
number of disagreements of each cluster, which we call min-max correlation
clustering. The min-max objective is a natural objective that respects the
quality of every cluster. In this paper, we provide the first nontrivial
approximation algorithm for this problem achieving an $\mathcal{O}(\sqrt{\log
n\cdot\max\{\log(|E^-|),\log(k)\}})$ approximation for general weighted graphs,
where $|E^-|$ denotes the number of negative edges and $k$ is the number of
clusters in the optimum solution. To do so, we also obtain a corresponding
result for multicut where we wish to find a multicut solution while trying to
minimize the total weight of cut edges on every component. The results are then
further improved to obtain (i) $\mathcal{O}(r^2)$-approximation for min-max
correlation clustering and min-max multicut for graphs that exclude $K_{r,r}$
minors (ii) a 14-approximation for the min-max correlation clustering on
complete graphs.
</p></div>
    </summary>
    <updated>2019-07-02T23:48:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00102</id>
    <link href="http://arxiv.org/abs/1907.00102" rel="alternate" type="text/html"/>
    <title>The Complexity of Tiling Problems</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwarzentruber:Fran=ccedil=ois.html">FranÃ§ois Schwarzentruber</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00102">PDF</a><br/><b>Abstract: </b>In this document, we collected the most important complexity results of
tilings. We also propose a definition of a so-called deterministic set of tile
types, in order to capture deterministic classes without the notion of games.
We also pinpoint tiling problems complete for respectively LOGSPACE and
NLOGSPACE.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00033</id>
    <link href="http://arxiv.org/abs/1907.00033" rel="alternate" type="text/html"/>
    <title>Algorithms for weighted independent transversals and strong colouring</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Graf:Alessandra.html">Alessandra Graf</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harris:David_G=.html">David G. Harris</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haxell:Penny.html">Penny Haxell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00033">PDF</a><br/><b>Abstract: </b>An independent transversal (IT) in a graph with a given vertex partition is
an independent set consisting of one vertex in each partition class. Several
sufficient conditions are known for the existence of an IT in a given graph
with a given vertex partition, which have been used over the years to solve
many combinatorial problems. Some of these IT existence theorems have
algorithmic proofs, but there remains a gap between the best bounds given by
nonconstructive results, and those obtainable by efficient algorithms.
</p>
<p>Recently, Graf and Haxell (2018) described a new (deterministic) algorithm
that asymptotically closes this gap, but there are limitations on its
applicability. In this paper we develop a randomized version of this algorithm
that is much more widely applicable, and demonstrate its use by giving
efficient algorithms for two problems concerning the strong chromatic number of
graphs.
</p></div>
    </summary>
    <updated>2019-07-02T23:45:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4220</id>
    <link href="https://www.scottaaronson.com/blog/?p=4220" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4220#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4220" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum Sabinacy</title>
    <summary xml:lang="en-US">Sabine Hossenfelderâwell-known to readers of Shtetl-Optimized for opposing the building of a higher-energy collider, and various other thingsâhas weighed in on âquantum supremacyâ in this blog post and this video. Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with [â¦]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sabine Hossenfelderâwell-known to readers of <em>Shtetl-Optimized</em> for <a href="https://www.scottaaronson.com/blog/?p=4122">opposing the building</a> of a higher-energy collider, and various other thingsâhas weighed in on âquantum supremacyâ in <a href="http://backreaction.blogspot.com/2019/06/quantum-supremacy-what-is-it-and-what.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+Backreaction+(Backreaction)&amp;m=1">this blog post</a> and <a href="https://www.youtube.com/watch?time_continue=1&amp;v=GKnfVA1v5ow">this video</a>.  Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with what she has to say substantially more than I disagree.</p>



<p>I do, however, have a few quibbles:</p>



<p> 1. We donât know that millions of physical qubits will be needed for useful simulations of quantum chemistry.Â  It all depends on how much error correction is needed and how good the error-correcting codes and simulation algorithms become.  Like, sure, you can generate pessimistic forecasts by plugging numbers in to the best known codes and algorithms.  But âthe best knownâ is a rapidly moving targetâone where there have already been orders-of-magnitude improvements in the last decade.</p>



<p>2. To my mind, thereâs a big conceptual difference between a single molecule that you canât efficiently simulate classically, and a programmable computer that you canât efficiently simulate classically.Â  The difference, in short, is that only for the computer, and not for the molecule, would it ever make sense to say it had given you a <strong>wrong</strong> answer!  In other words, a physical system becomes a âcomputerâ when, and only when, you have sufficient understanding of, and control over, its state space and time evolution that you can ask the system to simulate something <em>other than itself</em>, and then judge whether it succeeded or failed at that goal.</p>



<p>3. The entire point of my recent work, on certified randomness generation (see for example <a href="https://www.scottaaronson.com/talks/certrand2.ppt">here</a> or <a href="https://www.quantamagazine.org/how-to-turn-a-quantum-computer-into-the-ultimate-randomness-generator-20190619/">here</a>), is that sampling random bits with a NISQ-era device <em>could</em> have a practical application.  That application is â¦ I hope youâre sitting down for this â¦ sampling random bits!  And then, more importantly and nontrivially, <strong>proving</strong> to a faraway skeptic that the bits really were randomly generated.</p>



<p>4. While I was involved in some of the first proposals for NISQ quantum supremacy experiments (such as <a href="https://en.wikipedia.org/wiki/Boson_sampling">BosonSampling</a>), I certainly canât take sole credit for the idea of quantum supremacy! Â The term, incidentally, <a href="https://arxiv.org/abs/1203.5813">was coined by John Preskill</a>.</p>



<p>5. The term âNISQâ (Noisy Intermediate Scale Quantum) was also <a href="https://arxiv.org/abs/1801.00862">coined by John Preskill</a>.Â  He had no intention of misleading investorsâhe just needed a term to discuss the quantum computers that will plausibly be available in the near future.Â  As readers of this blog know, there certainly <em>has</em> been some misleading of investors (and journalists, and the publicâ¦) about the applications of near-term QCs.  But I donât think you can lay it at the feet of the term âNISQ.â</p></div>
    </content>
    <updated>2019-07-01T18:30:10Z</updated>
    <published>2019-07-01T18:30:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-02T19:48:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7054757178293557182</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7054757178293557182/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html" rel="alternate" type="text/html"/>
    <title>A proof that 22/7 - pi &gt; 0 and more</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
My father was a High School English teacher who did not know much math. As I was going off to college, intending to major in math, he gave me the following sage advice:<br/>
<br/>
1) <i>Take Physics as well as Math since Physics and Math go well together.</i> This was good advice. I took the first year of Physics for Physics Majors, and I later took a senior course in Mechanics since that was my favorite part of the first year course. Kudos to Dad!<br/>
<br/>
2) Ï <i>is exactly </i>22/7. I knew this was not true, but I also keow that I had no easy way to show him this. In fact, I wonder if I could have proven it myself back then.<br/>
<br/>
I had not thought about this in many years when I came across the following:<br/>
<br/>
Problem A-1 on the 1968 Putnam exam:<br/>
<br/>
Prove 22/7 - Ï = â«<sub>0</sub><sup>1</sup> (x<sup>4</sup>(1-x)<sup>4</sup>)/(1+ x<sup>2</sup> )dx<br/>
<br/>
(I can easily do his by partial fractions and remembering that â« 1/(1+x^2) dx = tan<sup>-1</sup>x  which is tan inverse, not 1/tan. See <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pi.pdf">here</a>.)<br/>
<br/>
(ADDED LATER---I have added conjectures on getting integrals of the form above except with 4 replaced by any natural number. Be the first on your block to solve my conjectures! It has to be easier than the Sensitivity Conjecture!)<br/>
<br/>
<br/>
<br/>
Let n &amp;in N which we will choose later. By looking at the circle that is inscribed in a regular n-polygon (n even) one finds that <br/>
<br/>
<br/>
n tan(Ï/n) &gt;  Ï <br/>
<br/>
<br/>
So we seek an even  value of n such that<br/>
<br/>
<br/>
n tan(Ï/n) &lt; 22/7<br/>
<br/>
<br/>
Using Wolfram alpha the smallest such n is 92.<br/>
<br/>
Would that convince Dad? Would he understand it? Probably not. Oh well.<br/>
<br/>
Some misc points.<br/>
<br/>
<br/>
1)  While working on this post I originally wanted to find tan(Ï/2<sup>7</sup>) by using the half-angle formula many times, and get an exact answer in terms of radicals,  rather than using Wolfram Alpha. <br/>
<br/>
a) While I have lots of combinatorics books, theory of comp books, and more Ramsey Theory books than one person should own in my house, I didn't have a SINGLE book with any trig in it.<br/>
<br/>
b) I easily found it on the web: <br/>
<br/>
tan(x/2) = sqrt( (1-cos x)/(1+cos x) ) = sin x/(1+cos x) = (1-cos x)/(sin x).<br/>
<br/>
None of these seems like it would get me a nice expression for tan(Ï/2<sup>7</sup>). But I don't know. Is there a nice expression for tan(Ï/2<sup>k</sup>) ? If you know of one then leave a polite comment.<br/>
<br/>
2) I assumed that there was a more clever and faster way to do the integral. I could not find old Putnam exams and their solutions  the web (I'm sure they are there someplace! --- if you know then comment politely with a pointer). So I got a book out of the library <i>The William Lowell Putnam Mathematical Competition Problems and Solutions 1965--1984</i> by Alexanderson, Klosinski, and Larson. Here is the clever solution:<br/>
<br/>
<i>The standard approach from Elementary Calculus applies.<br/>
<br/>
</i><br/>
<br/>
Not as clever as I as hoping for.<br/>
<br/>
3) I also looked at the integral with 4 replaced by 1,2,3,4,...,16. The results are in the writeup I pointed to before. It looks like I can use this sequence to get  upper and lower bound on i, ln(2), pi+2ln(2), and pi-2ln(2). I have not proven any of this. But take a look! And as noted above I have conjectures!<br/>
<br/>
<br/>
4) When I looked up INSCRIBING a circle in a regular n-polygon, Google kept giving me CIRCUMSCRIBING. Why? I do not know but I can speculate. Archimedes had a very nice way of using circumscribed circles to approximate pi. Its on youtube <a href="https://www.youtube.com/watch?v=_rJdkhlWZVQ">here</a>.  Hence people are used to using circumscribed rather than inscribed circles.<br/>
<br/></div>
    </content>
    <updated>2019-07-01T02:34:00Z</updated>
    <published>2019-07-01T02:34:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-02T20:28:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2019/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see Lanceâs post.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see <a href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html">Lanceâs post</a>.</p>

<ul>
  <li>
    <p><a href="https://uhills.org/the-university-hills-section-marker-a-history-of-maps-markers-and-monuments-that-eventually-created-university-hills/">Squaring the spherical earth</a> (<a href="https://mathstodon.xyz/@11011110/102285188426196734"/>). For surveying purposes, Orange County is divided into âsectionsâ, typically one square mile (not axis-aligned!) with small brass markers at their corners. One corner lands in the UCI faculty housing development where I live, and the housing association took the opportunity to make a larger decorative marker for it.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Integer linear programming, change-making, and Presburger arithmetic</a> (<a href="https://mathstodon.xyz/@11011110/102291138538406550"/>). Integer arithmetic problems with a constant number of variables and one level of quantifiers (example: given a constant number of coin types, find the largest amount of money for which you cannot make change) have long been known to be polynomially solvable, but <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">in FOCS 2017 Nguyen and Pak proved that only two levels of quantifiers make the problem hard</a>.</p>
  </li>
  <li>
    <p><a href="https://tomas.rokicki.com/dottri.html">Dots and triangles</a> (<a href="https://mathstodon.xyz/@christianp/102297036146535876"/>). Online variant of dots and boxes by Tomas Rikicki.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2019/06/19/combinatorics-at-strathclyde/">University of Strathclyde proposes to axe combinatorics and their three strong combinatorics faculty members</a> (<a href="https://mathstodon.xyz/@11011110/102301038310925223"/>, <a href="https://gowers.wordpress.com/2019/06/19/the-fate-of-combinatorics-at-strathclyde/">via</a>). This comes despite the group being both strong in research and important in undergraduate education. The apparent cause is Strathclydeâs placement of combinatorics in computer science rather than in mathematics and in their use of standards aimed more at computer science than mathematics (like bringing in large grants). Thereâs an <a href="https://britishcombinatorial.wordpress.com/2019/06/20/combinatorics-at-strathclyde-2/">online petition against the cuts</a> closing very soon: 5pm British time, July 1.</p>
  </li>
  <li>
    <p>Catherine Greenhill is setting up a new network for women in combinatorics, meaning âanyone who identifies as a woman, is non-binary, two-spirit, or gender diverseâ (<a href="https://mathstodon.xyz/@11011110/102311965002907932"/>). <a href="https://womenincombinatorics.com/">Their website</a> currently only has a sign-up form, but expect more to come.</p>
  </li>
  <li>
    <p>Slides from three of my recent conference talks (<a href="https://mathstodon.xyz/@11011110/102319479687501682"/>):
<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-many-lines-slides.pdf">Cubic planar graphs that cannot be drawn on few lines</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-counting-slides.pdf">Counting polygon triangulations is hard</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SPAA-19-slides.pdf">NC algorithms for perfect matching and maximum flow in one-crossing-minor-free graphs</a>.</p>
  </li>
  <li>
    <p>Certain conference speakers need to be told that using sans-serif â for one central notation and sans-serif bold â for a different central notation is a bad idea. That decorating both of them by the same subscripts and the same hats doesnât help. And that when someone asks for clarification of the notation, answering with âWe should move onâ¦this is a thing you can compute on your ownâ rather than actually explaining is rude (<a href="https://mathstodon.xyz/@11011110/102323855724493135"/>).</p>
  </li>
  <li>
    <p>The STOC Wikipedia edit-a-thon was called off because the convention center was locked up and participants couldnât get into the room it was scheduled for (<a href="https://mathstodon.xyz/@11011110/102330434291269046"/>). But <a href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/">it was successfully rescheduled for the next day</a>, unfortunately too late in the conference for me to participate.</p>

    <p>In other news from STOC, spammy journal publishers have found a new way to spam us: fund student authors with travel awards (laudable and non-spammy!) but then require the student presenters to display a whole slide of advertising for the journal by way of acknowledgements (spammy!).</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2168/">xkcd on reading Wikipedia in the original Greek</a> (<a href="https://mathstodon.xyz/@11011110/102339055555301837"/>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.10668">Discrete logarithms in quasi-polynomial time in finite fields of fixed characteristic</a> (<a href="https://mathstodon.xyz/@erou/102337004608271854"/>). New preprint by Kleinjung and Weselowski.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=OerQAsqEOLc">Short video on interleaving multiple copies of the infinite Laves graph</a> (<a href="https://mathstodon.xyz/@11011110/102353592823020968"/>). Sound not necessary.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/06/two-new-papers-explore-the-complicated-physics-behind-bubbles-and-foams/">Two new papers explore the complicated physics behind bubbles and foams</a> (<a href="https://mathstodon.xyz/@11011110/102356874963380843"/>).
Juanes et al find <a href="http://dx.doi.org/10.1073/pnas.1819744116">universality in pinching off uniformly sized bubbles</a> from a tube much like drops from a dripping faucet. And Yanagisawa and Kurita discover <a href="http://dx.doi.org/10.1038/s41598-019-41486-6">two mechanisms for breaking bubbles to propagate through a foam</a>. As it contracts, the breaking bubble can hit other bubbles, and it can also scatter off droplets which hit other bubbles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1902.07622">Centrality analysis of Wikipedia links between mathematicians</a> (<a href="https://mathstodon.xyz/@11011110/102361585031049847"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-06-30/Recent_research">via</a>). None of the names listed are surprising, but the ordering might be a little. Noether makes the top 10; Bourbaki, Grothendieck, and Turing are farther down. Martin Gardner makes the cut (barely), at #35.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-06-30T16:16:00Z</updated>
    <published>2019-06-30T16:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-30T23:47:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16046</id>
    <link href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/" rel="alternate" type="text/html"/>
    <title>A Prime Breakthrough</title>
    <summary>A breakthrough on the Riemann Hypothesis [ Composite of various sources ] Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH). Today we will discuss their work and its connection to P=NP. Their paper is titled, âJensen polynomials for [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A breakthrough on the Riemann Hypothesis</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/gorz/" rel="attachment wp-att-16067"><img alt="" class="alignright size-medium wp-image-16067" height="300" src="https://rjlipton.files.wordpress.com/2019/06/gorz.png?w=261&amp;h=300" width="261"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Composite of various sources ]</font></td>
</tr>
</tbody>
</table>
<p>
Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH).</p>
<p>
Today we will discuss their work and its connection to P=NP.</p>
<p>
Their <a href="https://arxiv.org/pdf/1902.07321.pdf">paper</a> is titled, âJensen polynomials for the Riemann zeta function and other sequences.â The final <a href="https://doi.org/10.1073/pnas.1902572116">version</a> is in the Proceedings of the National Academy of Sciences (PNAS).</p>
<p>
The RH is still open. We are not aware of any update on the status of Michael Atiyahâs claim to have solved it since this <a href="https://blogs.ams.org/blogonmathblogs/2018/10/01/on-michael-atiyah-and-the-riemann-hypothesis/">note</a> on an AMS blog and our own <a href="https://rjlipton.wordpress.com/2018/09/26/reading-into-atiyahs-proof/">discussion</a> of his papersâ contents.</p>
<p>
Recall the RH is a central conjecture in number theory, and it has the following properties: </p>
<ul>
<li>
If true, it would greatly enhance our understanding of the structure of the primes: <img alt="{2,3,5,7,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C3%2C5%2C7%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2,3,5,7,\dots}"/> <p/>
</li><li>
It has resisted attacks for 160 years and counting. <p/>
</li><li>
There are an immense number of statements equivalent to the RH.
</li></ul>
<p>See, for example, the survey <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.3584&amp;rep=rep1&amp;type=pdf">paper</a>, âThe Riemann Hypothesis,â by Brian Conrey. </p>
<p>
Complexity theory has the P=NP question; number theory has the RH. Both seem to be beyond reach, and both are fundamental questions. The recent work of GORZ has created buzz among number theoristsâperhaps they are on the verge of a breakthrough? Is there hope that we might see progress on P=NP? Or must we wait 160 years? </p>
<p>
The buzz is reflected in a May 28 <a href="https://www.livescience.com/65577-riemann-hypothesis-big-step-math.html">story</a> in the online journal <i>LiveScience</i>. It quotes Enrico Bombieri, who wrote the official Clay Prize <a href="https://www.claymath.org/sites/default/files/official_problem_description.pdf">description</a> of RH, as saying:</p>
<blockquote><p><b> </b> <em> âAlthough this remains far away from proving the Riemann hypothesis, it is a big step forward. There is no doubt that this paper will inspire further fundamental work in other areas of number theory as well as in mathematical physics.â </em>
</p></blockquote>
<p/><p>
Bombieri wrote an accompanying <a href="https://www.pnas.org/content/early/2019/05/22/1906804116">paper</a> in PNAS, in which the above quoted sentences also appear. We will try to explain what the excitement is about.</p>
<p>
</p><p/><h2> The Approach and Results </h2><p/>
<p/><p>
RH is equivalent to the hyperbolicity of Jensen polynomials for the Riemann zeta function. Note: A real, polynomial <img alt="{p(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(x)}"/> is <i>hyperbolic</i> if all its roots are realâa fancy name for a simple concept.</p>
<p>
There is an analytic function <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  RH \iff E(z) \text{ has all real roots}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++RH+%5Ciff+E%28z%29+%5Ctext%7B+has+all+real+roots%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  RH \iff E(z) \text{ has all real roots}. "/></p>
<p>Almost a hundred years ago, Johan Jensen and George PÃ³lya created an approach to the RH based on <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/>. Rather than prove <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> has only real roots, they showed it is enough to show that a family of polynomials <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> all are hyperbolic. The point is that polynomials are âsimplerâ than analytic functionsâat least that is the hope.</p>
<p>
What GORZ prove is this: </p>
<blockquote><p><b>Theorem 1</b> <em> For each <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d}"/> and almost all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>, the polynomial <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> is hyperbolic. </em>
</p></blockquote>
<p>Of course, âalmost allâ means that there at most a finite number of polynomials that are not hyperbolic. They also show that for degree <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> fixed, 	</p>
<p align="center"><img alt="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+J%28n%2C+d%29%28x%29+%3D+H_%7Bd%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). "/></p>
<p>Where the polynomials <img alt="{H_{d}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH_%7Bd%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H_{d}(x)}"/> have only real roots.</p>
<p>
This is explained further in a <a href="http://people.oregonstate.edu/~petschec/ONTD/Talk1.pdf">talk</a> by Ono, which has this table showing how the polynomials converge:</p>
<p><a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/hyper/" rel="attachment wp-att-16049"><img alt="" class="aligncenter size-medium wp-image-16049" height="187" src="https://rjlipton.files.wordpress.com/2019/06/hyper.png?w=300&amp;h=187" width="300"/></a></p>
<p>Note: they use different notation for the polynomials.</p>
<p>
</p><p/><h2> The Approximation Property </h2><p/>
<p>There are many equivalent formulations of the RH.  While all are equivalent, some are more equivalent than others.  Some seem to be a more plausible path toward a resolution of the RH. Of course to date none have worked. </p>
<p>There is a way to distinguish equivalent formulations of the RH. Suppose that <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> depends on some parameter <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>. Suppose that as <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/> increases the statement <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> becomes a weaker version of the RH.<br/>
Then let us informally say that the formulation <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> has the âApproximation Propertyâ (AP). The point is that progress in proving caes of <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/>âeven as partial progressâis exciting. But if the equivalence only holds for <img alt="\beta=0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta=0"/>, with no connections for higher <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>, then the partial progress could be seen as morally usefulâbut it is not really mathematically useful.</p>
<p>There are equivalences of the RH that have AP and some that seem not to have it. The approximation for the RH is natural. The RH states that there is no zero <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> of the Riemann zeta function with <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/> above <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>. The weaker statement: If <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> is a zero, then <img alt="\sigma &gt;  \alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%3E++%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma &gt;  \alpha"/> is unknown for any <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> in the open interval <img alt="(1/2,1)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2,1)"/>. This can be used to get a property with the AP.</p>
<p>For example, this 2003 <a href="http://\href{https://arxiv.org/abs/math/0307215}">paper</a> by Luis Baez-Duarte, titled âA new necessary and sufficient condition for the Riemann hypothesis,â has the AP. He notes, in our terminology, that his property is an AP.</p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
Does the approach of GORZ have the AP? The issue is that while we get a universal statement in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, the âall but finitely manyâ condition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> works against its being an approximationâwhat if the finite sets of exceptions grow in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> in ways that offset the purpose behind the equivalence?</p>
<p/></font></font></div>
    </content>
    <updated>2019-06-29T14:50:42Z</updated>
    <published>2019-06-29T14:50:42Z</published>
    <category term="History"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="hyperbolic"/>
    <category term="PNAS"/>
    <category term="polynomial"/>
    <category term="Proof"/>
    <category term="real roots"/>
    <category term="RH"/>
    <category term="Riemann Hypothesis"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>GÃ¶delâs Lost Letter and P=NP</title>
      <updated>2019-07-02T23:54:55Z</updated>
    </source>
  </entry>
</feed>
