<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-11-12T22:21:49Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/12/postdoc-at-university-of-bergen-apply-by-january-15-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/12/postdoc-at-university-of-bergen-apply-by-january-15-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Bergen (apply by January 15, 2020)</title>
    <summary>At the Department of Informatics of the University of Bergen (UiB), Norway, there is a vacancy of up to two positions as postdoctoral researcher in algorithmic foundations of data science, associated with the newly founded Center for Data Science (CEDAS). Each position is for a fixed period of 2 years. Website: https://www.jobbnorge.no/en/available-jobs/job/177613/researcher-in-informatics-algorithmic-foundations-of-data-science Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>At the Department of Informatics of the University of Bergen (UiB), Norway, there is a vacancy of up to two positions as postdoctoral researcher in algorithmic foundations of data science, associated with the newly founded Center for Data Science (CEDAS). Each position is for a fixed period of 2 years.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/177613/researcher-in-informatics-algorithmic-foundations-of-data-science">https://www.jobbnorge.no/en/available-jobs/job/177613/researcher-in-informatics-algorithmic-foundations-of-data-science</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2019-11-12T15:32:57Z</updated>
    <published>2019-11-12T15:32:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-12T22:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4409</id>
    <link href="https://www.scottaaronson.com/blog/?p=4409" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4409#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4409" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Annual recruitment post</title>
    <summary xml:lang="en-US">Just like I did last year, and the year before, I’m putting up a post to let y’all know about opportunities in our growing Quantum Information Center at UT Austin. I’m proud to report that we’re building something pretty good here. This fall Shyam Shankar joined our Electrical and Computer Engineering (ECE) faculty to do […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Just like I did <a href="https://www.scottaaronson.com/blog/?p=3964">last year</a>, and <a href="https://www.scottaaronson.com/blog/?p=3508">the year before</a>, I’m putting up a post to let y’all know about opportunities in our growing <a href="https://www.cs.utexas.edu/~qic/">Quantum Information Center</a> at UT Austin.</p>



<p>I’m proud to report that we’re building something pretty good here.  This fall <a href="http://sites.utexas.edu/shyamshankar/">Shyam Shankar</a> joined our Electrical and Computer Engineering (ECE) faculty to do experimental superconducting qubits, while (as I <a href="https://www.scottaaronson.com/blog/?p=4233">blogged</a> in the summer) the quantum complexity theorist <a href="http://www.mit.edu/~jswright/">John Wright</a> will join me on the CS faculty in Fall 2020.  Meanwhile, <a href="https://sites.google.com/utexas.edu/potter/home">Drew Potter</a>, an expert on topological qubits, rejoined our physics faculty after a brief leave.  Our weekly quantum information group meeting now regularly attracts around 30 participants—from the turnout, you wouldn’t know it’s not MIT or Caltech or Waterloo.  My own group now has five postdocs and six PhD students—as well as some amazing undergrads striving to meet the bar set by <a href="https://www.scottaaronson.com/blog/?p=3880">Ewin Tang</a>.  Course offerings in quantum information currently include Brian La Cour’s <a href="https://cns.utexas.edu/component/cobalt/item/3138-quantum-computing?Itemid=1971">Freshman Research Initiative</a>, my own undergrad <a href="https://www.scottaaronson.com/blog/?p=3943">Intro to Quantum Information Science</a> honors class, and graduate classes on quantum complexity theory, experimental realizations of QC, and topological matter (with more to come).  We’ll also be starting an undergraduate Quantum Information Science concentration next fall.</p>



<p>So without further ado:</p>



<p>(1) If you’re interested in pursuing a PhD focused on quantum computing and information (and/or classical theoretical computer science) at UT Austin: please apply!  If you want to work with me or John Wright on quantum algorithms and complexity, <a href="https://www.cs.utexas.edu/graduate/prospective-students/apply">apply to CS</a> (I can also supervise physics students in rare cases).  Also apply to CS, of course, if you want to work with our other CS theory faculty: David Zuckerman, Dana Moshkovitz, Adam Klivans, Anna Gal, Eric Price, Brent Waters, Vijaya Ramachandran, or Greg Plaxton.  If you want to work with Drew Potter on nonabelian anyons or suchlike, or with <a href="https://web2.ph.utexas.edu/~macdgrp/">Allan MacDonald</a>, <a href="http://order.ph.utexas.edu/people/Reichl.htm">Linda Reichl</a>, <a href="https://sites.cns.utexas.edu/liopticsut/home">Elaine Li</a>, or others on many-body quantum theory, <a href="https://ph.utexas.edu/prospective-graduate-students/admissions">apply to physics</a>.  If you want to work with Shyam Shankar on superconducting qubits, <a href="http://www.ece.utexas.edu/graduate/admissions">apply to ECE</a>.  Note that the deadline for CS and physics is <strong>December 1</strong>, while the deadline for ECE is <strong>December 15</strong>.</p>



<p>You don’t need to ask me whether I’m on the lookout for great students: I always am!  If you say on your application that you want to work with me, I’ll be sure to see it.  Emailing individual faculty members is not how it works and won’t help.  Admissions are extremely competitive, so I strongly encourage you to apply broadly to maximize your options.</p>



<p>(2) If you’re interested in a postdoc in my group, I’ll have approximately two openings starting in Fall 2020.  To apply, just send me an email by <strong>January 1, 2020</strong> with the following info:<br/>– Your CV<br/>– 2 or 3 of your best papers (links or PDF attachments)<br/>– The names of two recommenders (who should email me their letters separately)</p>



<p>(3) If you’re on the faculty job market in quantum computing and information—well, please give me a heads-up if you’re potentially interested in Austin!  Our CS, physics, and ECE departments are all open to considering additional candidates in quantum information, both junior and senior.  I can’t take credit for this—it surely has to do with developments beyond my control, both at UT and beyond—but I’m happy to relay that, in the three years since I arrived in Texas, the appetite for strengthening UT’s presence in quantum information has undergone jaw-dropping growth at every level of the university.</p>



<p>Also, Austin-Bergstrom International Airport now has direct flights to London, Frankfurt, and (soon) Amsterdam and Paris.</p>



<p>Hook ’em Hadamards!</p></div>
    </content>
    <updated>2019-11-12T07:02:25Z</updated>
    <published>2019-11-12T07:02:25Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-11-12T21:05:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04415</id>
    <link href="http://arxiv.org/abs/1911.04415" rel="alternate" type="text/html"/>
    <title>Revisiting the Approximate Carath\'eodory Problem via the Frank-Wolfe Algorithm</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Combettes:Cyrille_W=.html">Cyrille W. Combettes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pokutta:Sebastian.html">Sebastian Pokutta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04415">PDF</a><br/><b>Abstract: </b>The approximate Carath\'eodory theorem states that given a polytope
$\mathcal{P}$, each point in $\mathcal{P}$ can be approximated within
$\epsilon$-accuracy in $\ell_p$-norm as the convex combination of
$\mathcal{O}(pD_p^2/\epsilon^2)$ vertices, where $p\geq2$ and $D_p$ is the
diameter of $\mathcal{P}$ in $\ell_p$-norm. A solution satisfying these
properties can be built using probabilistic arguments [Barman, 2015] or by
applying mirror descent to the dual problem [Mirrokni et al., 2017]. We revisit
the approximate Carath\'eodory problem by solving the primal problem via the
Frank-Wolfe algorithm, providing a simplified analysis and leading to an
efficient practical method. Sublinear to linear sparsity bounds are derived
naturally using existing convergence results of the Frank-Wolfe algorithm in
different scenarios.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04382</id>
    <link href="http://arxiv.org/abs/1911.04382" rel="alternate" type="text/html"/>
    <title>GRASS: Spectral Sparsification Leveraging Scalable Spectral Perturbation Analysis</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Zhuo.html">Zhuo Feng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04382">PDF</a><br/><b>Abstract: </b>Spectral graph sparsification aims to find ultra-sparse subgraphs whose
Laplacian matrix can well approximate the original Laplacian eigenvalues and
eigenvectors. In recent years, spectral sparsification techniques have been
extensively studied for accelerating various numerical and graph-related
applications. Prior nearly-linear-time spectral sparsification methods first
extract low-stretch spanning tree from the original graph to form the backbone
of the sparsifier, and then recover small portions of spectrally-critical
off-tree edges to the spanning tree to significantly improve the approximation
quality. However, it is not clear how many off-tree edges should be recovered
for achieving a desired spectral similarity level within the sparsifier.
Motivated by recent graph signal processing techniques, this paper proposes a
similarity-aware spectral graph sparsification framework that leverages
efficient spectral off-tree edge embedding and filtering schemes to construct
spectral sparsifiers with guaranteed spectral similarity (relative condition
number) level. An iterative graph densification scheme is also introduced to
facilitate efficient and effective filtering of off-tree edges for highly
ill-conditioned problems. The proposed method has been validated using various
kinds of graphs obtained from public domain sparse matrix collections relevant
to VLSI CAD, finite element analysis, as well as social and data networks
frequently studied in many machine learning and data mining applications. For
instance, a sparse SDD matrix with 40 million unknowns and 180 million nonzeros
can be solved (1E-3 accuracy level) within two minutes using a single CPU core
and about 6GB memory.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04372</id>
    <link href="http://arxiv.org/abs/1911.04372" rel="alternate" type="text/html"/>
    <title>Information carefull worstcase DecreaseKey heaps with simple nonMeld variant</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majerech:Vladan.html">Vladan Majerech</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04372">PDF</a><br/><b>Abstract: </b>We analyze priority queues including DecreaseKey method in its interface. The
paper is inspired by Strict Fibonacci Heaps [2], where G. S. Brodal, G.
Lagogiannis, and R. E. Tarjan implemented the heap with DecreaseKey and Meld
interface in assymptotically optimal worst case times (based on key
comparisons). At the end of the paper there are mentioned possible variants of
other structural properties an violations than they have used in the analysis.
In the main variant a lot of information is wasted during violation reduction
steps. Our goal is to concentrate on other variants and to invent natural
strategy not losing that much in the information value. In other words we try
to choose among them one which corresponds to superexpensive comparision
principle as much as possible. The principle was described in [5] of myself,
but after publication I have found these ideas in [4] of H. Kaplan, R. E.
Tarjan, and U. Zwick.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04249</id>
    <link href="http://arxiv.org/abs/1911.04249" rel="alternate" type="text/html"/>
    <title>A polynomial kernel for $3$-leaf power deletion</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jungho Ahn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwon:O=joung.html">O-joung Kwon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oum:Sang=il.html">Sang-il Oum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04249">PDF</a><br/><b>Abstract: </b>A graph $G$ is an $\ell$-leaf power of a tree $T$ if $V(G)$ is equal to the
set of leaves of $T$, and distinct vertices $v$ and $w$ of $G$ are adjacent if
and only if the distance between $v$ and $w$ in $T$ is at most $\ell$. Given a
graph $G$, the $3$-leaf Power Deletion problem asks whether there is a set
$S\subseteq V(G)$ of size at most $k$ such that $G\setminus S$ is a $3$-leaf
power of some tree $T$. We provide a polynomial kernel for this problem. More
specifically, we present a polynomial-time algorithm for an input instance
$(G,k)$ to output an equivalent instance $(G',k')$ such that $k'\le k$ and $G'$
has at most $O(k^{14}\log^{12}k)$ vertices.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04202</id>
    <link href="http://arxiv.org/abs/1911.04202" rel="alternate" type="text/html"/>
    <title>Dv2v: A Dynamic Variable-to-Variable Compressor</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fari=ntilde=a:Antonio.html">Antonio Fariña</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oacute=mez=Brand=oacute=n:Adri=aacute=n.html">Adrián Gómez-Brandón</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodeiro:Tirso_V=.html">Tirso V. Rodeiro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04202">PDF</a><br/><b>Abstract: </b>We present Dv2v, a new dynamic (one-pass) variable-to-variable compressor.
Variable-to-variable compression aims at using a modeler that gathers
variable-length input symbols and a variable-length statistical coder that
assigns shorter codewords to the more frequent symbols. In Dv2v, we process the
input text word-wise to gather variable-length symbols that can be either
terminals (new words) or non-terminals, subsequences of words seen before in
the input text. Those input symbols are set in a vocabulary that is kept sorted
by frequency. Therefore, those symbols can be easily encoded with dense codes.
Our Dv2v permits real-time transmission of data, i.e. compression/transmission
can begin as soon as data become available. Our experiments show that Dv2v is
able to overcome the compression ratios of the v2vDC, the state-of-the-art
semi-static variable-to-variable compressor, and to almost reach p7zip values.
It also draws a competitive performance at both compression and decompression.
</p></div>
    </summary>
    <updated>2019-11-12T02:32:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04198</id>
    <link href="http://arxiv.org/abs/1911.04198" rel="alternate" type="text/html"/>
    <title>GraCT: A Grammar-based Compressed Index for Trajectory Data</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oacute=mez=Brand=oacute=n:Adri=aacute=n.html">Adrián Gómez-Brandón</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Param=aacute=:Jos=eacute=_R=.html">José R. Paramá</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04198">PDF</a><br/><b>Abstract: </b>We introduce a compressed data structure for the storage of free trajectories
of moving objects (such as ships and planes) that efficiently supports various
spatio-temporal queries. Our structure, dubbed GraCT, stores the absolute
positions of all the objects at regular time intervals (snapshots) using a
$k^2$-tree, which is a space- and time-efficient version of a region quadtree.
Positions between snapshots are represented as logs of relative movements and
compressed using Re-Pair, a grammar-based compressor. The nonterminals of this
grammar are enhanced with MBR information to enable fast queries.
</p>
<p>The GraCT structure of a dataset occupies less than the raw data compressed
with a powerful traditional compressor such as p7zip. Further, instead of
requiring full decompression to access the data like a traditional compressor,
GraCT supports direct access to object trajectories or to their position at
specific time instants, as well as spatial range and nearest-neighbor queries
on time instants and/or time intervals.
</p>
<p>Compared to traditional methods for storing and indexing spatio-temporal
data, GraCT requires two orders of magnitude less space, and is competitive in
query times. In particular, thanks to its compressed representation, the GraCT
structure may reside in main memory in situations where any classical
uncompressed index must resort to disk, thereby being one or two orders of
magnitude faster.
</p></div>
    </summary>
    <updated>2019-11-12T02:44:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04122</id>
    <link href="http://arxiv.org/abs/1911.04122" rel="alternate" type="text/html"/>
    <title>Classification on the Computational Complexity of Spin Models</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Shi=Xin.html">Shi-Xin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04122">PDF</a><br/><b>Abstract: </b>In this note, we provide a unifying framework to investigate the
computational complexity of classical spin models and give the full
classification on spin models in terms of system dimensions, randomness,
external magnetic fields and types of spin coupling. We further discuss about
the implications of NP-complete Hamiltonian models in physics and the
fundamental limitations of all numerical methods imposed by such models. We
conclude by a brief discussion on the picture when quantum computation and
quantum complexity theory are included.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04112</id>
    <link href="http://arxiv.org/abs/1911.04112" rel="alternate" type="text/html"/>
    <title>Dependency Stochastic Boolean Satisfiability: A Logical Formalism for NEXPTIME Decision Problems with Uncertainty</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Nian=Ze.html">Nian-Ze Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Jie=Hong_R=.html">Jie-Hong R. Jiang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04112">PDF</a><br/><b>Abstract: </b>Stochastic Boolean Satisfiability (SSAT) is a logical formalism to model
decision problems with uncertainty, such as Partially Observable Markov
Decision Process (POMDP). SSAT, however, is limited by its descriptive power
within the PSPACE complexity class. More complex problems, such as the
NEXPTIME-complete Decentralized POMDP (Dec-POMDP), cannot be succinctly encoded
with SSAT. To provide a logical formalism of such problems, we generalize
Dependency Quantified Boolean Formula (DQBF), a representative problem in the
NEXPTIME-complete class, to its stochastic variant, named Dependency SSAT
(DSSAT), and show that DSSAT is also NEXPTIME-complete. To demonstrate the
descriptive power of DSSAT, we further establish a polynomial-time reduction
from Dec-POMDP to DSSAT. Our results may encourage DSSAT solver development to
enable potential broad applications.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04063</id>
    <link href="http://arxiv.org/abs/1911.04063" rel="alternate" type="text/html"/>
    <title>A*SLAM: A Dual Fisheye Stereo Edge SLAM</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Guoxuan.html">Guoxuan Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04063">PDF</a><br/><b>Abstract: </b>This paper proposes an A*SLAM system that features combining two sets of
fisheye stereo cameras and taking the image edge as the SLAM features. The dual
fisheye stereo camera sets cover the full environmental view of the SLAM
system. From each fisheye stereo image pair, a panorama depth image can be
directly extracted for initializing the SLAM feature. The edge feature is an
illumination invariant feature. The paper presents a method of the edge-based
simultaneous localization and mapping process using both the normal and
inverted images interchangeably.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04026</id>
    <link href="http://arxiv.org/abs/1911.04026" rel="alternate" type="text/html"/>
    <title>A generic imperative language for polynomial time</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leivant:Daniel.html">Daniel Leivant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04026">PDF</a><br/><b>Abstract: </b>We propose a generic imperative programming language STR that captures PTime
computations, on both infinite inductive structures and families of finite
structures. The approach, set up in [29] for primitive-recursive complexity,
construes finite partial-functions as a universal canonical form of data, and
uses structure components for loop variants. STR is obtained by the further
refinement that assigns ranks to finite partial-functions, which regulate the
interaction of loops, yielding programs that run in polynomial time. STR
captures algorithms that have eluded ramified recurrence, and is promising as
an artifact of Implicit Complexity which is malleable to static analysis
implementations.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.04014</id>
    <link href="http://arxiv.org/abs/1911.04014" rel="alternate" type="text/html"/>
    <title>Interaction is necessary for distributed learning with privacy or communication constraints</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dagan:Yuval.html">Yuval Dagan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Vitaly.html">Vitaly Feldman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.04014">PDF</a><br/><b>Abstract: </b>Local differential privacy (LDP) is a model where users send privatized data
to an untrusted central server whose goal it to solve some data analysis task.
In the non-interactive version of this model the protocol consists of a single
round in which a server sends requests to all users then receives their
responses. This version is deployed in industry due to its practical advantages
and has attracted significant research interest. Our main result is an
exponential lower bound on the number of samples necessary to solve the
standard task of learning a large-margin linear separator in the
non-interactive LDP model. Via a standard reduction this lower bound implies an
exponential lower bound for stochastic convex optimization and specifically,
for learning linear models with a convex, Lipschitz and smooth loss. These
results answer the questions posed in \citep{SmithTU17,DanielyF18}. Our lower
bound relies on a new technique for constructing pairs of distributions with
nearly matching moments but whose supports can be nearly separated by a large
margin hyperplane. These lower bounds also hold in the model where
communication from each user is limited and follow from a lower bound on
learning using non-adaptive \emph{statistical queries}.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03990</id>
    <link href="http://arxiv.org/abs/1911.03990" rel="alternate" type="text/html"/>
    <title>Implementing geometric complexity theory: On the separation of orbit closures via symmetries</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ikenmeyer:Christian.html">Christian Ikenmeyer</a>, Umangathan Kandasamy <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03990">PDF</a><br/><b>Abstract: </b>Understanding the difference between group orbits and their closures is a key
difficulty in geometric complexity theory (GCT): While the GCT program is set
up to separate certain orbit closures, many beautiful mathematical properties
are only known for the group orbits, in particular close relations with
symmetry groups and invariant spaces, while the orbit closures seem much more
difficult to understand. However, in order to prove lower bounds in algebraic
complexity theory, considering group orbits is not enough.
</p>
<p>In this paper we tighten the relationship between the orbit of the power sum
polynomial and its closure, so that we can separate this orbit closure from the
orbit closure of the product of variables by just considering the symmetry
groups of both polynomials and their representation theoretic decomposition
coefficients. In a natural way our construction yields a multiplicity
obstruction that is neither an occurrence obstruction, nor a so-called
vanishing ideal occurrence obstruction. All multiplicity obstructions so far
have been of one of these two types.
</p>
<p>Our paper is the first implementation of the ambitious approach that was
originally suggested in the first papers on geometric complexity theory by
Mulmuley and Sohoni (SIAM J Comput 2001, 2008): Before our paper, all existence
proofs of obstructions only took into account the symmetry group of one of the
two polynomials (or tensors) that were to be separated. In our paper the
multiplicity obstruction is obtained by comparing the representation theoretic
decomposition coefficients of both symmetry groups.
</p>
<p>Our proof uses a semi-explicit description of the coordinate ring of the
orbit closure of the power sum polynomial in terms of Young tableaux, which
enables its comparison to the coordinate ring of the orbit.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03989</id>
    <link href="http://arxiv.org/abs/1911.03989" rel="alternate" type="text/html"/>
    <title>On the Equivalence of SDP Feasibility and a Convex Hull Relaxation for System of Quadratic Equations</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalantari:Bahman.html">Bahman Kalantari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03989">PDF</a><br/><b>Abstract: </b>We show {\it semidefinite programming} (SDP) feasibility problem is
equivalent to solving a {\it convex hull relaxation} (CHR) for system of
quadratic equations. On the one hand this offers a simple description of SDP.
On the other hand, this equivalence makes it possible to describe a version of
the {\it Triangle Algorithm} for SDP feasibility based on solving CHR.
Specifically, the Triangle Algorithm either computes an approximation to the
least-norm feasible solution of SDP, or using its {\it distance duality},
provides a separation when no solution within a prescribed norm exists. The
worst-case complexity of each iteration is computing largest eigenvalue of a
symmetric matrix arising in that iteration. Alternate complexity bounds on the
total number of iterations are derived. Further applications includes solving
an SDP optimization problem. The Triangle Algorithm thus provides an
alternative to the existing interior-point algorithms for SDP. Finally, gaining
from these results and insights, we discuss potential extension to solving
general system of polynomial equations.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03858</id>
    <link href="http://arxiv.org/abs/1911.03858" rel="alternate" type="text/html"/>
    <title>Ar{\i}kan meets Shannon: Polar codes with near-optimal convergence to channel capacity</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Riazanov:Andrii.html">Andrii Riazanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Min.html">Min Ye</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03858">PDF</a><br/><b>Abstract: </b>Let $W$ be a binary-input memoryless symmetric (BMS) channel with Shannon
capacity $I(W)$ and fix any $\alpha &gt; 0$. We construct, for any sufficiently
small $\delta &gt; 0$, binary linear codes of block length
$O(1/\delta^{2+\alpha})$ and rate $I(W)-\delta$ that enable reliable
communication on $W$ with quasi-linear time encoding and decoding. Shannon's
noisy coding theorem established the existence of such codes (without efficient
constructions or decoding) with block length $O(1/\delta^2)$. This quadratic
dependence on the gap $\delta$ to capacity is known to be best possible. Our
result thus yields a constructive version of Shannon's theorem with
near-optimal convergence to capacity as a function of the block length. This
resolves a central theoretical challenge associated with the attainment of
Shannon capacity. Previously such a result was only known for the erasure
channel.
</p>
<p>Our codes are a variant of Ar{\i}kan's polar codes based on multiple
carefully constructed local kernels, one for each intermediate channel that
arises in the decoding. A crucial ingredient in the analysis is a strong
converse of the noisy coding theorem when communicating using random linear
codes on arbitrary BMS channels. Our converse theorem shows extreme
unpredictability of even a single message bit for random coding at rates
slightly above capacity.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03757</id>
    <link href="http://arxiv.org/abs/1911.03757" rel="alternate" type="text/html"/>
    <title>Universal Communication, Universal Graphs, and Graph Labeling</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harms:Nathaniel.html">Nathaniel Harms</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03757">PDF</a><br/><b>Abstract: </b>We introduce a communication model called universal SMP, in which Alice and
Bob receive a function $f$ belonging to a family $\mathcal{F}$, and inputs $x$
and $y$. Alice and Bob use shared randomness to send a message to a third party
who cannot see $f, x, y$, or the shared randomness, and must decide $f(x,y)$.
Our main application of universal SMP is to relate communication complexity to
graph labeling, where the goal is to give a short label to each vertex in a
graph, so that adjacency or other functions of two vertices $x$ and $y$ can be
determined from the labels $\ell(x),\ell(y)$. We give a universal SMP protocol
using $O(k^2)$ bits of communication for deciding whether two vertices have
distance at most $k$ on distributive lattices (generalizing the $k$-Hamming
Distance problem in communication complexity), and explain how this implies an
$O(k^2\log n)$ labeling scheme for determining $\mathrm{dist}(x,y) \leq k$ on
distributive lattices with size $n$; in contrast, we show that a universal SMP
protocol for determining $\mathrm{dist}(x,y) \leq 2$ in modular lattices (a
superset of distributive lattices) has super-constant $\Omega(n^{1/4})$
communication cost. On the other hand, we demonstrate that many graph families
known to have efficient adjacency labeling schemes, such as trees,
low-arboricity graphs, and planar graphs, admit constant-cost communication
protocols for adjacency. Trees also have an $O(k)$ protocol for deciding
$\mathrm{dist}(x,y) \leq k$ and planar graphs have an $O(1)$ protocol for
$\mathrm{dist}(x,y) \leq 2$, which implies a new $O(\log n)$ labeling scheme
for the same problem on planar graphs.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03748</id>
    <link href="http://arxiv.org/abs/1911.03748" rel="alternate" type="text/html"/>
    <title>Quantum speedups need structure</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keller:Nathan.html">Nathan Keller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Ohad.html">Ohad Klein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03748">PDF</a><br/><b>Abstract: </b>We prove the following conjecture, raised by Aaronson and Ambainis in 2008:
Let $f:\{-1,1\}^n \rightarrow [-1,1]$ be a multilinear polynomial of degree
$d$. Then there exists a variable $x_i$ whose influence on $f$ is at least
$\mathrm{poly}(\mathrm{Var}(f)/d)$.
</p>
<p>As was shown by Aaronson and Ambainis, this result implies the following
well-known conjecture on the power of quantum computing, dating back to 1999:
Let $Q$ be a quantum algorithm that makes $T$ queries to a Boolean input and
let $\epsilon,\delta &gt; 0$. Then there exists a deterministic classical
algorithm that makes $\mathrm{poly}(T,1/\epsilon,1/\delta)$ queries to the
input and that approximates $Q$'s acceptance probability to within an additive
error $\epsilon$ on a $1-\delta$ fraction of inputs. In other words, any
quantum algorithm can be simulated on most inputs by a classical algorithm
which is only polynomially slower, in terms of query complexity.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03683</id>
    <link href="http://arxiv.org/abs/1911.03683" rel="alternate" type="text/html"/>
    <title>A Polynomial Kernel for Paw-Free Editing</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03683">PDF</a><br/><b>Abstract: </b>For a fixed graph $H$, the $H$-free-editing problem asks whether we can
modify a given graph $G$ by adding or deleting at most $k$ edges such that the
resulting graph does not contain $H$ as an induced subgraph. The problem is
known to be NP-complete for all fixed $H$ with at least $3$ vertices and it
admits a $2^{O(k)}n^{O(1)}$ algorithm. Cai and Cai showed that the
$H$-free-editing problem does not admit a polynomial kernel whenever $H$ or its
complement is a path or a cycle with at least $4$ edges or a $3$-connected
graph with at least $1$ edge missing. Their results suggest that if $H$ is not
independent set or a clique, then $H$-free-editing admits polynomial kernels
only for few small graphs $H$, unless $\textsf{coNP} \in \textsf{NP/poly}$.
Therefore, resolving the kernelization of $H$-free-editing for small graphs $H$
plays a crucial role in obtaining a complete dichotomy for this problem. In
this paper, we positively answer the question of compressibility for one of the
last two unresolved graphs $H$ on $4$ vertices. Namely, we give the first
polynomial kernel for paw-free editing with $O(k^{6})$vertices.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03620</id>
    <link href="http://arxiv.org/abs/1911.03620" rel="alternate" type="text/html"/>
    <title>Adaptivity in Adaptive Submodularity</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esfandiari:Hossein.html">Hossein Esfandiari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a>, Vahab Mirrokni <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03620">PDF</a><br/><b>Abstract: </b>Adaptive sequential decision making is one of the central challenges in
machine learning and artificial intelligence. In such problems, the goal is to
design an interactive policy that plans for an action to take, from a finite
set of $n$ actions, given some partial observations. It has been shown that in
many applications such as active learning, robotics, sequential experimental
design, and active detection, the utility function satisfies adaptive
submodularity, a notion that generalizes the notion of diminishing returns to
policies. In this paper, we revisit the power of adaptivity in maximizing an
adaptive monotone submodular function. We propose an efficient batch policy
that with $O(\log n \times\log k)$ adaptive rounds of observations can achieve
an almost tight $(1-1/e-\epsilon)$ approximation guarantee with respect to an
optimal policy that carries out $k$ actions in a fully sequential setting. To
complement our results, we also show that it is impossible to achieve a
constant factor approximation with $o(\log n)$ adaptive rounds. We also extend
our result to the case of adaptive stochastic minimum cost coverage where the
goal is to reach a desired utility $Q$ with the cheapest policy. We first prove
the conjecture by Golovin and Krause that the greedy policy achieves the
asymptotically tight logarithmic approximation guarantee without resorting to
stronger notions of adaptivity. We then propose a batch policy that provides
the same guarantee in polylogarithmic adaptive rounds through a similar
information-parallelism scheme. Our results shrink the adaptivity gap in
adaptive submodular maximization by an exponential factor.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03605</id>
    <link href="http://arxiv.org/abs/1911.03605" rel="alternate" type="text/html"/>
    <title>How bad is worst-case data if you know where it comes from?</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Justin Y. Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Gregory.html">Gregory Valiant</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Paul.html">Paul Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03605">PDF</a><br/><b>Abstract: </b>We introduce a framework for studying how distributional assumptions on the
process by which data is partitioned into a training and test set can be
leveraged to provide accurate estimation or learning algorithms, even for
worst-case datasets. We consider a setting of $n$ datapoints, $x_1,\ldots,x_n$,
together with a specified distribution, $P$, over partitions of these
datapoints into a training set, test set, and irrelevant set. An algorithm
takes as input a description of $P$ (or sample access), the indices of the test
and training sets, and the datapoints in the training set, and returns a model
or estimate that will be evaluated on the datapoints in the test set. We
evaluate an algorithm in terms of its worst-case expected performance: the
expected performance over potential test/training sets, for worst-case
datapoints, $x_1,\ldots,x_n.$ This framework is a departure from more typical
distributional assumptions on the datapoints (e.g. that data is drawn
independently, or according to an exchangeable process), and can model a number
of natural data collection processes, including processes with dependencies
such as "snowball sampling" and "chain sampling", and settings where test and
training sets satisfy chronological constraints (e.g. the test instances were
observed after the training instances).
</p>
<p>Within this framework, we consider the setting where datapoints are bounded
real numbers, and the goal is to estimate the mean of the test set. We give an
efficient algorithm that returns a weighted combination of the training
set---whose weights depend on the distribution, $P$, and on the training and
test set indices---and show that the worst-case expected error achieved by this
algorithm is at most a multiplicative $\pi/2$ factor worse than the optimal of
such algorithms. The algorithm, and its proof, leverage a surprising connection
to the Grothendieck problem.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03542</id>
    <link href="http://arxiv.org/abs/1911.03542" rel="alternate" type="text/html"/>
    <title>Space Efficient Construction of Lyndon Arrays in Linear Time</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ellert:Jonas.html">Jonas Ellert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Johannes.html">Johannes Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurpicz:Florian.html">Florian Kurpicz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munro:Ian.html">Ian Munro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rotenberg:Eva.html">Eva Rotenberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03542">PDF</a><br/><b>Abstract: </b>We present the first linear time algorithm to construct the $2n$-bit version
of the Lyndon array using only $o(n)$ bits of working space. A simpler variant
of this algorithm computes the plain ($n\lg n$-bit) version of the Lyndon array
using only $\mathcal{O}(1)$ words of additional working space. All previous
algorithms are either not linear, or use at least $n\lg n$ bits of additional
working space. Also in practice, our new algorithms outperform the previous
best ones by an order of magnitude, both in terms of time and space.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03456</id>
    <link href="http://arxiv.org/abs/1911.03456" rel="alternate" type="text/html"/>
    <title>Parallel Data Distribution Management on Shared-Memory Multiprocessors</title>
    <feedworld_mtime>1573516800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marzolla:Moreno.html">Moreno Marzolla</a>, Gabriele D'Angelo <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03456">PDF</a><br/><b>Abstract: </b>The problem of identifying intersections between two sets of d-dimensional
axis-parallel rectangles appears frequently in the context of agent-based
simulation studies. For this reason, the High Level Architecture (HLA)
specification -- a standard framework for interoperability among simulators --
includes a Data Distribution Management (DDM) service whose responsibility is
to report all intersections between a set of subscription and update regions.
The algorithms at the core of the DDM service are CPU-intensive, and could
greatly benefit from the large computing power of modern multi-core processors.
In this paper we propose two parallel solutions to the DDM problem that can
operate effectively on shared-memory multiprocessors. The first solution is
based on a data structure (the Interval Tree) that allows concurrent
computation of intersections between subscription and update regions. The
second solution is based on a novel parallel extension of the Sort Based
Matching algorithm, whose sequential version is considered among the most
efficient solutions to the DDM problem. Extensive experimental evaluation of
the proposed algorithms confirm their effectiveness on taking advantage of
multiple execution units in a shared-memory architecture.
</p></div>
    </summary>
    <updated>2019-11-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/160</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/160" rel="alternate" type="text/html"/>
    <title>TR19-160 |  Tractable Unordered 3-CNF Games | 

	Md Lutfar Rahman, 

	Thomas Watson</title>
    <summary>The classic TQBF problem can be viewed as a game in which two players alternate turns assigning truth values to a CNF formula's variables in a prescribed order, and the winner is determined by whether the CNF gets satisfied. The complexity of deciding which player has a winning strategy in this game is well-understood: it is NL-complete for 2-CNFs and PSPACE-complete for 3-CNFs.

We continue the study of the unordered variant of this game, in which each turn consists of picking any remaining variable and assigning it a truth value. The complexity of deciding who can win on a given CNF is less well-understood; prior work by the authors showed it is in L for 2-CNFs and PSPACE-complete for 5-CNFs. We conjecture it may be efficiently solvable on 3-CNFs, and we make progress in this direction by proving the problem is in P, indeed in L, for 3-CNFs with a certain restriction, namely that each width-3 clause has at least one variable that appears in no other clause. Another (incomparable) restriction of this problem was previously shown to be tractable by Kutz.</summary>
    <updated>2019-11-11T22:26:59Z</updated>
    <published>2019-11-11T22:26:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-12T22:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/159</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/159" rel="alternate" type="text/html"/>
    <title>TR19-159 |  SETH-hardness of Coding Problems | 

	Noah Stephens-Davidowitz, 

	Vinod Vaikuntanathan</title>
    <summary>We show that assuming the strong exponential-time hypothesis (SETH), there are no non-trivial algorithms for the nearest codeword problem (NCP), the minimum distance problem (MDP), or the nearest codeword problem with preprocessing (NCPP) on linear codes over any finite field. More precisely, we show that there are no NCP, MDP, or NCPP algorithms running in time $q^{(1-\epsilon)n}$ for any constant $\epsilon&gt;0$ for codes with $q^n$ codewords. (In the case of NCPP, we assume non-uniform SETH.)

We also show that there are no sub-exponential-time algorithms for $\gamma$-approximate versions of these problems for some constant $\gamma &gt; 1$, under different versions of the exponential-time hypothesis.</summary>
    <updated>2019-11-11T19:23:19Z</updated>
    <published>2019-11-11T19:23:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-12T22:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/11/faculty-any-rank-at-penn-state-apply-by-january-1-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/11/faculty-any-rank-at-penn-state-apply-by-january-1-2020/" rel="alternate" type="text/html"/>
    <title>FACULTY (ANY RANK)  at PENN STATE (apply by January 1, 2020)</title>
    <summary>Applications are invited for multiple tenure-track positions at all levels across all areas of theoretical computer science. Our department is looking to grow rapidly in several areas, and theory is one of them. Website: https://academicjobsonline.org/ajo/jobs/14482 Email: ablanca@cse.psu.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for multiple tenure-track positions at all levels across all areas of theoretical computer science. Our department is looking to grow rapidly in several areas, and theory is one of them.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/14482">https://academicjobsonline.org/ajo/jobs/14482</a><br/>
Email: ablanca@cse.psu.edu</p></div>
    </content>
    <updated>2019-11-11T18:50:24Z</updated>
    <published>2019-11-11T18:50:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-12T22:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/158</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/158" rel="alternate" type="text/html"/>
    <title>TR19-158 |  Sorting Can Exponentially Speed Up Pure Dynamic Programming | 

	Stasys Jukna, 

	Hannes Seiwert</title>
    <summary>Many discrete minimization problems, including various versions of the shortest path problem, can be efficiently solved by dynamic programming (DP) algorithms that are ``pure'' in that they only perform basic operations, as $\min$, $\max$, $+$, but no conditional branchings via if-then-else in their recursion equations. It is known that any pure $(\min,+)$ DP algorithm solving the minimum weight spanning tree problem on undirected $n$-vertex graphs must perform at least $2^{\Omega(\sqrt{n})}$ operations. We show  that this problem \emph{can} be solved by a pure  $(\min,\max,+)$ DP algorithm performing only $O(n^3)$ operations. The algorithm is essentially a $(\min,\max)$ algorithm: addition operations are only used to output the final values. The presence of both $\min$ and $\max$ operations means that now DP algorithms can sort: this explains the title of the paper.</summary>
    <updated>2019-11-11T18:19:07Z</updated>
    <published>2019-11-11T18:19:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-12T22:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3435</id>
    <link href="https://agtb.wordpress.com/2019/11/11/msr-internship-opportunities-in-economics-economics-and-computation/" rel="alternate" type="text/html"/>
    <title>MSR internship opportunities in Economics/Economics and Computation</title>
    <summary>Microsoft Research has multiple research intern positions in the Economics and Computation group and Microeconomics group for the Summer of 2020. Positions are available in both the New England and New York City labs. Research areas include market design, algorithmic game theory, social network theory, prediction markets, connections between economics and machine learning, applied and theoretical microeconomics, public economics, industrial organization, behavioral economics, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Microsoft Research has multiple research intern positions in the <a href="https://www.microsoft.com/en-us/research/group/economics-and-computer-science/" rel="noopener" target="_blank">Economics and Computation</a> group and <a href="https://www.microsoft.com/en-us/research/group/microeconomics/" rel="noopener" target="_blank">Microeconomics</a> group for the Summer of 2020. Positions are available in both the <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/" rel="noopener" target="_blank">New England</a> and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-york/" rel="noopener" target="_blank">New York City</a> labs.</p>
<p>Research areas include market design, algorithmic game theory, social network theory, prediction markets, connections between economics and machine learning, applied and theoretical microeconomics, public economics, industrial organization, behavioral economics, and applied and theoretical econometrics (including <a href="https://www.microsoft.com/en-us/research/project/alice/" rel="noopener" target="_blank">ALICE</a>).</p>
<p>Potential mentors in MSR NE include  Hunt Allcott, Greg Lewis, Brendan Lucier, Markus Mobius, and Vasilis Syrgkanis.  Potential mentors in MSR NYC include Nicole Immorlica, David Rothschild, Alex Slivkins and Jenn Wortman Vaughan.</p>
<p>Candidates must be currently enrolled in a PhD program in Computer Science, Economics, or a related field.  Please apply by December 13 for full consideration.  The application for MSR NE can be found <a href="https://careers.microsoft.com/us/en/job/741381/Research-Intern-Economics-Economics-and-Computation-MSR-NE" rel="noopener" target="_blank">here</a>; the application for MSR NYC can be found <a href="https://careers.microsoft.com/us/en/job/740998/Research-Intern-Economics-Economics-and-Computation-MSR-NYC" rel="noopener" target="_blank">here</a>.  Candidates are encouraged to apply to both postings.</p></div>
    </content>
    <updated>2019-11-11T18:08:48Z</updated>
    <published>2019-11-11T18:08:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Yannai A. Gonczarowski</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-11-12T22:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16378</id>
    <link href="https://rjlipton.wordpress.com/2019/11/11/goldbach-a-curious-conjecture/" rel="alternate" type="text/html"/>
    <title>Goldbach: A Curious Conjecture</title>
    <summary>Models of the primes [ Montreal ] Andrew Granville writes brilliant papers that explain hard results in number theory. He also proves hard results in number theory. Today, Ken and I use the famous Goldbach conjecture to discuss a third rail: how to identify which results “should be” true even though they have been too […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Models of the primes</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/11/11/goldbach-a-curious-conjecture/newseventsimages/" rel="attachment wp-att-16393"><img alt="" class="alignright  wp-image-16393" src="https://rjlipton.files.wordpress.com/2019/11/newseventsimages.jpeg?w=150" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Montreal ]</font></td>
</tr>
</tbody>
</table>
<p>
Andrew Granville writes brilliant papers that explain hard results in number theory. He also proves hard results in number theory. </p>
<p>
Today, Ken and I use the famous Goldbach conjecture to discuss a third rail: how to identify which results “should be” true even though they have been too hard to prove.</p>
<p>
Granville has just recently published a graphic novel, <i>Prime Suspects: The Anatomy of Integers and Permutations</i>, with his sister Jennifer Granville and illustrator Robert Lewis. It features constables named Green and Tao, a detective Jack von Neumann, and students named Emmy Germain and Sergei Langer among other allusions to real (and complex) mathematicians. It grew out of a 2009 musical <a href="https://dms.umontreal.ca/~andrew/PDF/MSIProgram.pdf">play</a> that premiered at IAS. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/11/11/goldbach-a-curious-conjecture/graphic/" rel="attachment wp-att-16380"><img alt="" class="aligncenter  wp-image-16380" height="300" src="https://rjlipton.files.wordpress.com/2019/11/graphic.jpg?w=240&amp;h=300" width="240"/></a></p>
<p>
The driver of the plot is a deep connection between the frequency of primes below a number <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and that of permutations in <img alt="{S_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_N}"/> that are “prime” in the sense of having only one cycle. Substituting <img alt="{\log(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(x)}"/> for <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> and vice-versa tends to create correspondences of known results in number theory vis-à-vis permutation group theory. See this MAA <a href="https://www.maa.org/press/maa-reviews/prime-suspects-the-anatomy-of-integers-and-permutations">review</a>. Going beyond the known theorems described in the novel, we wonder how far such heuristic sleuthing methods can go on long-unsolved cases.</p>
<p>
</p><p/><h2> The Goldbach Reminder </h2><p/>
<p/><p>
The statement we know as the (Strong) Goldbach Conjecture is that every even number <img alt="{n \ge 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cge+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \ge 4}"/> can be written as the sum of two prime numbers. It was made in 1742 by Christian Goldbach. He wrote to Leonhard Euler:</p>
<blockquote><p><b> </b> <em> “Every integer that can be written as the sum of two primes can also be written as the sum of as many primes as desired, until all terms are <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/>.” </em>
</p></blockquote>
<p/><p>
Well, that is not what we call Goldbach’s conjecture. He and many others at the time considered <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> to be a prime number. What he’s getting at can be seen from this snippet of his letter:</p>
<p><a href="https://rjlipton.wordpress.com/2019/11/11/goldbach-a-curious-conjecture/goldbachsnippet/" rel="attachment wp-att-16388"><img alt="" class="aligncenter size-medium wp-image-16388" src="https://rjlipton.files.wordpress.com/2019/11/goldbachsnippet.png?w=300"/></a></p>
<p>
Above his sums, Goldbach put an asterisk * to the note in the margin, in which he asserts his conjecture:</p>
<blockquote><p><b> </b> <em> “Every integer greater than 2 can be written as the sum of three primes.” </em>
</p></blockquote>
<p/><p>
Wait—that is not the Goldbach conjecture either. It is the “Weak” one and was apparently <a href="https://arxiv.org/abs/1312.7748">proved</a> in 2013 by Harald Helfgott. We discussed this in a 2014 <a href="https://rjlipton.wordpress.com/2014/06/06/is-this-a-proof-2/">post</a> whose larger theme we are continuing here. It also proves the first conjecture, but not the strong conjecture.</p>
<p>
But what Goldbach seems to be driving at with his drawing of sums is having one of the “primes” be <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Then the strong conjecture is needed. Euler pointed this out in his reply to Goldbach’s letter. But Euler, who was a <a href="https://luthscitech.org/saintly-scientists/">saint</a> in many ways, charitably reminded Goldbach of a communication earlier that year when Goldbach had observed that his first conjecture followed from the strong statement. Euler went on to say:</p>
<blockquote><p><b> </b> <em> “That every even number should be a sum of two primes I hold to be a completely certain theorem, irrespective of my not being able to prove it.” </em>
</p></blockquote>
<p/><p>
Ken has translated this a little differently from Wikipedia’s <a href="https://en.wikipedia.org/wiki/Goldbach's_conjecture#Origins">article</a> and its <a href="https://web.archive.org/web/20030616020619/http://claymath.org/Popular_Lectures/U_Texas/Riemann_1.pdf">source</a>, reading into Euler’s words the stance of truth shining apart from proof. How one can justify this stance is what we want to discuss.</p>
<p>
</p><p/><h2> A Curious Conjecture </h2><p/>
<p/><p>
The conjecture is curious on several fronts. For one it is usually said to be “obviously correct.” It has been checked to about <img alt="{10^{18}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B10%5E%7B18%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{10^{18}}"/> or so by computation. There are many open conjectures in number theory that are likely to be true. But few are claimed to be “true” with such a strong bias. Many other conjectures are likely to be true, but none as likely as the Goldbach. </p>
<p>
In 1975, Hugh Montgomery and Robert Vaughan proved that the Goldbach is true for most even numbers. That is that the number of possible even numbers <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> less than some <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> are not sums of two primes grows like <img alt="{o(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(N)}"/>. Thus if one picks a random even number <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> it is likely to be the sum of two primes. Here the “likely” is a mathematical certainty.</p>
<p>
How do we “know” that it is likely to be true? One source is the method of prime models. Primes are quite mysterious and hard to understand. So there are heuristic models that suggest we think of the primes as “random”. Of course this is silly, since the primes are a deterministic fixed sequence of numbers. But the hope is that the following is true. </p>
<blockquote><p><b> </b> <em> If <img alt="{\Gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Gamma}"/> is a statement about the primes that is with high probability in the random model, then it is true. </em>
</p></blockquote>
<p/><p>
Of course this is nonsense. </p>
<p>
But it is interesting nonsense. Harald Cramér has a model that is simple. Granville add some refinements to this model <a href="https://projecteuclid.org/download/pdf_1/euclid.facm/1229618748">here</a> and <a href="https://www.dartmouth.edu/~chance/chance_news/for_chance_news/Riemann/cramer.pdf">here</a>. More recently William Banks and Kevin Ford and Terence Tao have a new model for the primes <a href="https://arxiv.org/pdf/1908.08613.pdf">here</a>. </p>
<p>
These models are useful for making and thinking about number theory conjectures. Perhaps one day they will be able to really be used to determine truth. They are certainly good heuristics to have when studying the prime numbers. We are jealous. In complexity theory it would be wonderful to have anything like these models. Perhaps <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> </p>
<p>
</p><p/><h2> A Model Example </h2><p/>
<p/><p>
Cramér’s model is simple to state. Imagine that the primes <img alt="{\cal P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal P}"/> are replaced by a random set <img alt="{\cal R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal R}"/> by placing <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> in with probability <img alt="{1/\ln n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cln+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/\ln n}"/>. And we make these choices independently. The Fermat numbers are those 	</p>
<p align="center"><img alt="\displaystyle  2^{2^{n}} + 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7B2%5E%7Bn%7D%7D+%2B+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  2^{2^{n}} + 1. "/></p>
<p>The first of these 	</p>
<p align="center"><img alt="\displaystyle  3, 5, 17, 257, 65537 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2C+5%2C+17%2C+257%2C+65537+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  3, 5, 17, 257, 65537 "/></p>
<p>are prime. Fermat thought this continued but it is not true. Euler showed that the next is not a prime 	</p>
<p align="center"><img alt="\displaystyle  641 \times 6,700,417. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++641+%5Ctimes+6%2C700%2C417.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  641 \times 6,700,417. "/></p>
<p>An interesting problem is are there any more prime Fermat numbers? Many believe that there are no more, or art most there are a finite number in total. Let’s look at using the model to understand the Fermat <a href="https://en.wikipedia.org/w/index.php?title=Fermat_number&amp;action=edit&amp;section=4">numbers</a>: </p>
<p align="center"><img alt="\displaystyle\sum_{n=0}^{\infty} \frac{1}{\ln F_{n}} = \frac{1}{\ln 2} \sum_{n=0}^{\infty} \frac{1}{\log_{2}\left(2^{2^{n}}+1 \right)} = \frac{1}{\ln 2} \sum_{n=0}^{\infty} 2^{-n}  = \frac{2}{\ln 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5Csum_%7Bn%3D0%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7B%5Cln+F_%7Bn%7D%7D+%3D+%5Cfrac%7B1%7D%7B%5Cln+2%7D+%5Csum_%7Bn%3D0%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7B%5Clog_%7B2%7D%5Cleft%282%5E%7B2%5E%7Bn%7D%7D%2B1+%5Cright%29%7D+%3D+%5Cfrac%7B1%7D%7B%5Cln+2%7D+%5Csum_%7Bn%3D0%7D%5E%7B%5Cinfty%7D+2%5E%7B-n%7D++%3D+%5Cfrac%7B2%7D%7B%5Cln+2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle\sum_{n=0}^{\infty} \frac{1}{\ln F_{n}} = \frac{1}{\ln 2} \sum_{n=0}^{\infty} \frac{1}{\log_{2}\left(2^{2^{n}}+1 \right)} = \frac{1}{\ln 2} \sum_{n=0}^{\infty} 2^{-n}  = \frac{2}{\ln 2}"/>. </p>
<p>Therefore, the total expected number of Fermat primes is at most finite. Of course this is assuming the model is predictive. </p>
<p>
</p><p/><h2> Proved? </h2><p/>
<p/><p>
Our friends at Wikipedia <a href="https://en.wikipedia.org/wiki/Goldbach%27s_conjecture">say</a>: </p>
<blockquote><p><b> </b> <em> As with many famous conjectures in mathematics, there are a number of purported proofs of the Goldbach conjecture, none of which are accepted by the mathematical community. </em>
</p></blockquote>
<p/><p>
Try a Google search yourself for “Goldbach conjecture proved”. The top hits include several “proofs” that the conjecture is true. The proofs are all short and simple. All are believed to be wrong. I find it interesting that the proofs, in many cases, use a random like argument in there “proofs”. The trouble is that the above models are only heuristics. So the proofs seem to be incomplete. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can we imagine getting heuristic models for complexity theory? For quantum algorithms perhaps. What would such heuristic models even look like? We wonder.</p></font></font></div>
    </content>
    <updated>2019-11-11T16:25:17Z</updated>
    <published>2019-11-11T16:25:17Z</published>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="conjecture"/>
    <category term="Goldbach"/>
    <category term="models"/>
    <category term="primes"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-11-12T22:20:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7340761877463675609</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7340761877463675609/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/a-non-moral-dilemma-about-cheating-but.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7340761877463675609" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7340761877463675609" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/a-non-moral-dilemma-about-cheating-but.html" rel="alternate" type="text/html"/>
    <title>A non-moral dilemma about cheating, but it brings up some points</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I often give two versions of an exam and TELL THE STUDENTS I am doing this so that they don't even try to cheat. I've even had two different classes take the midterm at the same time, same room, every other seat, so the person next to you is in a different course. And I TELL THE STUDENTS that I am doing this.  A colleague of mine says I shouldn't TELL THE STUDENTS. Here are our arguments<br/>
<br/>
1) Don't tell: students cheat a lot and this is a way to catch them.<br/>
<br/>
2) Tell:  Dealing with cheating distracts from our mission of teaching so best to be preventative so it does not happen. Less noble- tell them so that you don't have to deal with the cheating issue.<br/>
<br/>
I have heard of the following case at a diff school some years ago and want your take on it:<br/>
there was one question on the midterm that was different on the two exams- the prof changed the key number, but they were the same question really. The prof was in a hurry for some reason and <i>FORGOT TO TELL THE STUDENTS</i>. You can probably guess what happened next, but not what happened after that<br/>
<br/>
One of the students exams had the solution to THE OTHER PROBLEM on it. Clearly cheating. When called in the student said:<br/>
<br/>
<i>Since you didn't tell us that they were different exams the cheating claim is unfair!</i><br/>
<i><br/>
</i> They DID admit their guilt, but they DID NOT have any contrition.<br/>
<br/>
 Options for what penalty to go for:<br/>
<br/>
1) A 0 on the exam itself<br/>
<br/>
2) An F in the course<br/>
<br/>
3) A notation on the transcript indicating Failed-because-cheated. I don't know what that notation was at the schol the story took place, but at UMCP its XF. (Side Note- not clear if someone outside of UMCP looks at a transcript and sees an XF they'll know what the means. But the F part makes it look bad.)<br/>
<br/>
4) Expulsion from school. (This might not be the profs call- this may depend on if its a first offense.)<br/>
<br/>
The lack of contrition bothers me, though the prof who told me the story said that the student may have said it out of shock- the first thing that came into their mind. I asked the prof how the student was doing in the class and the prof said, CORRECTLY, that that is irrelevant.<br/>
<br/>
SO- what penalty would you go for?<br/>
<br/>
The professor went for XF. The student, at the hearing, once again said<br/>
<br/>
<br/>
<i>Since you didn't tell us that they were different exams the cheating claim is unfair!</i><br/>
<br/>
The professor told me that he thinks the student was trying to claim it was entrapment, though he had a hard time expressing this coherently. If the student had been a coherent thinker, he probably wouldn't have needed to cheat.<br/>
<br/>
He got the equivalent of an XF. <br/>
<br/>
But here is my real question: Should we TELL THE STUDENTS that they are different exams (I think yes) or<br/>
should we NOT tell them so can catch them?<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-11-11T15:09:00Z</updated>
    <published>2019-11-11T15:09:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-11-12T21:17:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03449</id>
    <link href="http://arxiv.org/abs/1911.03449" rel="alternate" type="text/html"/>
    <title>Fully-dynamic Planarity Testing in Polylogarithmic Time</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Holm:Jacob.html">Jacob Holm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rotenberg:Eva.html">Eva Rotenberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03449">PDF</a><br/><b>Abstract: </b>Given a dynamic graph subject to insertions and deletions of edges, a natural
question is whether the graph presently admits a planar embedding. We give a
deterministic fully-dynamic algorithm for general graphs, running in amortized
$O(\log^3 n)$ time per edge insertion or deletion, that maintains a bit
indicating whether or not the graph is presently planar. This is an exponential
improvement over the previous best algorithm [Eppstein, Galil, Italiano,
Spencer, 1996] which spends amortized $O(\sqrt{n})$ time per update.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03427</id>
    <link href="http://arxiv.org/abs/1911.03427" rel="alternate" type="text/html"/>
    <title>Induced arithmetic removal: complexity 1 patterns over finite fields</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fox:Jacob.html">Jacob Fox</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tidor:Jonathan.html">Jonathan Tidor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Yufei.html">Yufei Zhao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03427">PDF</a><br/><b>Abstract: </b>We prove an arithmetic analog of the induced graph removal lemma for
complexity 1 patterns over finite fields. Informally speaking, we show that
given a fixed collection of $r$-colored complexity 1 arithmetic patterns over
$\mathbb F_q$, every coloring $\phi \colon \mathbb F_q^n \setminus\{0\} \to
[r]$ with $o(1)$ density of every such pattern can be recolored on an
$o(1)$-fraction of the space so that no such pattern remains.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03424</id>
    <link href="http://arxiv.org/abs/1911.03424" rel="alternate" type="text/html"/>
    <title>Approximation Bounds for Interpolation and Normals on Triangulated Surfaces and Manifolds</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khoury:Marc.html">Marc Khoury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shewchuk:Jonathan_Richard.html">Jonathan Richard Shewchuk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03424">PDF</a><br/><b>Abstract: </b>How good is a triangulation as an approximation of a smooth curved surface or
manifold? We provide bounds on the {\em interpolation error}, the error in the
position of the surface, and the {\em normal error}, the error in the normal
vectors of the surface, as approximated by a piecewise linearly triangulated
surface whose vertices lie on the original, smooth surface. The interpolation
error is the distance from an arbitrary point on the triangulation to the
nearest point on the original, smooth manifold, or vice versa. The normal error
is the angle separating the vector (or space) normal to a triangle from the
vector (or space) normal to the smooth manifold (measured at a suitable point
near the triangle). We also study the {\em normal variation}, the angle
separating the normal vectors (or normal spaces) at two different points on a
smooth manifold. Our bounds apply to manifolds of any dimension embedded in
Euclidean spaces of any dimension, and our interpolation error bounds apply to
simplices of any dimension, although our normal error bounds apply only to
triangles. These bounds are expressed in terms of the sizes of suitable medial
balls (the {\em empty ball size} or {\em local feature size} measured at
certain points on the manifold), and have applications in Delaunay
triangulation-based algorithms for provably good surface reconstruction and
provably good mesh generation. Our bounds have better constants than the prior
bounds we know of---and for several results in higher dimensions, our bounds
are the first to give explicit constants.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03360</id>
    <link href="http://arxiv.org/abs/1911.03360" rel="alternate" type="text/html"/>
    <title>Local Search for Group Closeness Maximization on Big Graphs</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angriman:Eugenio.html">Eugenio Angriman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grinten:Alexander_van_der.html">Alexander van der Grinten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyerhenke:Henning.html">Henning Meyerhenke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03360">PDF</a><br/><b>Abstract: </b>In network analysis and graph mining, closeness centrality is a popular
measure to infer the importance of a vertex. Computing closeness efficiently
for individual vertices received considerable attention. The NP-hard problem of
group closeness maximization, in turn, is more challenging: the objective is to
find a vertex group that is central as a whole and state-of-the-art heuristics
for it do not scale to very big graphs yet.
</p>
<p>In this paper, we present new local search heuristics for group closeness
maximization. By using randomized approximation techniques and dynamic data
structures, our algorithms are often able to perform locally optimal decisions
efficiently. The final result is a group with high (but not optimal) closeness
centrality.
</p>
<p>We compare our algorithms to the current state-of-the-art greedy heuristic
both on weighted and on unweighted real-world graphs. For graphs with hundreds
of millions of edges, our local search algorithms take only around ten minutes,
while greedy requires more than ten hours. Overall, our new algorithms are
between one and two orders of magnitude faster, depending on the desired group
size and solution quality. For example, on weighted graphs and $k = 10$, our
algorithms yield solutions of $12,4\%$ higher quality, while also being
$793,6\times$ faster. For unweighted graphs and $k = 10$, we achieve solutions
within $99,4\%$ of the state-of-the-art quality while being $127,8\times$
faster.
</p></div>
    </summary>
    <updated>2019-11-11T23:25:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03297</id>
    <link href="http://arxiv.org/abs/1911.03297" rel="alternate" type="text/html"/>
    <title>Structural Parameterizations for Equitable Coloring</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gomes:Guilherme_C=_M=.html">Guilherme C. M. Gomes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guedes:Matheus_R=.html">Matheus R. Guedes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Vin=iacute=cius_F=_dos.html">Vinícius F. dos Santos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03297">PDF</a><br/><b>Abstract: </b>An $n$-vertex graph is equitably $k$-colorable if there is a proper coloring
of its vertices such that each color is used either
$\left\lfloor{n/k}\right\rfloor$ or $\left\lceil{n/k}\right\rceil$ times. While
classic Vertex Coloring is fixed parameter tractable under well established
parameters such as pathwidth and feedback vertex set, equitable coloring is
W[1]-hard. We prove that Equitable Coloring is fixed parameter tractable when
parameterized by distance to cluster or co-cluster graphs, improving on the FPT
algorithm of Fiala et al. (2011) parameterized by vertex cover. In terms of
intractability, we adapt the proof of Fellows et al. (2011) to show that
Equitable Coloring is W[1]-hard when simultaneously parameterized by distance
to disjoint paths and number of colors. We also revisit the literature and
derive other results on the parameterized complexity of the problem through
minor reductions or other simple observations.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03272</id>
    <link href="http://arxiv.org/abs/1911.03272" rel="alternate" type="text/html"/>
    <title>The Complexity of Verifying Circuits as Differentially Private</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gaboardi:Marco.html">Marco Gaboardi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nissim:Kobbi.html">Kobbi Nissim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Purser:David.html">David Purser</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03272">PDF</a><br/><b>Abstract: </b>We study the problem of verifying differential privacy for straight line
programs with probabilistic choice. Programs in this class can be seen as
randomized Boolean circuits. We focus on two different questions: first,
deciding whether a program satisfies a prescribed level of privacy; second,
approximating the privacy parameters a program realizes.
</p>
<p>We show that the problem of deciding whether a program satisfies
$\varepsilon$-differential privacy is $coNP^{\#P}$-complete. In fact, this is
the case when either the input domain or the output range of the program is
large. Further, we show that deciding whether a program is
$(\varepsilon,\delta)$-differentially private is $coNP^{\#P}$-hard, and in
$coNP^{\#P}$ for small output domains, but always in $coNP^{\#P^{\#P}}$.
Finally, we show that the problem of approximating the level of differential
privacy is both $NP$-hard and $coNP$-hard.
</p></div>
    </summary>
    <updated>2019-11-11T23:22:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03204</id>
    <link href="http://arxiv.org/abs/1911.03204" rel="alternate" type="text/html"/>
    <title>Treewidth-Pliability and PTAS for Max-CSPs</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Romero:Miguel.html">Miguel Romero</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wrochna:Marcin.html">Marcin Wrochna</a>, Stanislav Živný <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03204">PDF</a><br/><b>Abstract: </b>We identify a sufficient condition, treewidth-pliability, that gives a
polynomial-time approximation scheme (PTAS) for a large class of Max-2-CSPs
parametrised by the class of allowed constraint graphs (with arbitrary
constraints on an unbounded alphabet). Our result applies more generally to the
maximum homomorphism problem between two rational-valued structures.
</p>
<p>The condition unifies the two main approaches for designing PTASes. One is
Baker's layering technique, which applies to sparse graphs such as planar or
excluded-minor graphs. The other is based on Szemer\'{e}di's regularity lemma
and applies to dense graphs. Albeit with some limitations, we extend the
applicability of both techniques to new classes of Max-CSPs.
</p>
<p>Treewidth-pliability turns out to be a robust notion that can be defined in
several equivalent ways, including characterisations via size, treedepth, or
the Hadwiger number. We show connections to the notions of
fractional-treewidth-fragility from structural graph theory, hyperfiniteness
from the area of property testing, and regularity partitions from the theory of
dense graph limits. These may be of independent interest. In particular we show
that a monotone class of graphs is hyperfinite if and only if it is
fractionally-treewidth-fragile and has bounded degree.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03195</id>
    <link href="http://arxiv.org/abs/1911.03195" rel="alternate" type="text/html"/>
    <title>On dynamic succinct graph representations</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coimbra:Miguel_E=.html">Miguel E. Coimbra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francisco:Alexandre_P=.html">Alexandre P. Francisco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Russo:Lu=iacute=s_M=_S=.html">Luís M. S. Russo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bernardo:Guillermo_de.html">Guillermo de Bernardo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Ladra:Susana.html">Susana Ladra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03195">PDF</a><br/><b>Abstract: </b>We address the problem of representing dynamic graphs using $k^2$-trees. The
$k^2$-tree data structure is one of the succinct data structures proposed for
representing static graphs, and binary relations in general. It relies on
compact representations of bit vectors. Hence, by relying on compact
representations of dynamic bit vectors, we can also represent dynamic graphs.
In this paper we follow instead the ideas by Munro {\em et al.}, and we present
an alternative implementation for representing dynamic graphs using
$k^2$-trees. Our experimental results show that this new implementation is
competitive in practice.
</p></div>
    </summary>
    <updated>2019-11-11T23:42:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03071</id>
    <link href="http://arxiv.org/abs/1911.03071" rel="alternate" type="text/html"/>
    <title>Balancing covariates in randomized experiments using the Gram-Schmidt walk</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harshaw:Christopher.html">Christopher Harshaw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/S=auml=vje:Fredrik.html">Fredrik Sävje</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spielman:Daniel.html">Daniel Spielman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Peng.html">Peng Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03071">PDF</a><br/><b>Abstract: </b>The paper introduces a class of experimental designs that allows
experimenters to control the robustness and efficiency of their experiments.
The designs build on a recently introduced algorithm in discrepancy theory, the
Gram-Schmidt walk. We provide a tight analysis of this algorithm, allowing us
to prove important properties of the designs it produces. These designs aim to
simultaneously balance all linear functions of the covariates, and the variance
of an estimator of the average treatment effect is shown to be bounded by a
quantity that is proportional to the loss function of a ridge regression of the
potential outcomes on the covariates. No regression is actually conducted, and
one may see the procedure as regression adjustment by design. The class of
designs is parameterized so to give experimenters control over the worse case
performance of the treatment effect estimator. Greater covariate balance is
attained by allowing for a less robust design in terms of worst case variance.
We argue that the trade-off between robustness and efficiency is an inherent
aspect of experimental design. Finally, we provide non-asymptotic tail bounds
for the treatment effect estimator under the class of designs we describe.
</p></div>
    </summary>
    <updated>2019-11-11T23:25:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.03043</id>
    <link href="http://arxiv.org/abs/1911.03043" rel="alternate" type="text/html"/>
    <title>Estimating Normalizing Constants for Log-Concave Distributions: Algorithms and Lower Bounds</title>
    <feedworld_mtime>1573430400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ge:Rong.html">Rong Ge</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Holden.html">Holden Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Jianfeng.html">Jianfeng Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.03043">PDF</a><br/><b>Abstract: </b>Estimating the normalizing constant of an unnormalized probability
distribution has important applications in computer science, statistical
physics, machine learning, and statistics. In this work, we consider the
problem of estimating the normalizing constant $Z=\int_{\mathbb{R}^d}
e^{-f(x)}\,\mathrm{d}x$ to within a multiplication factor of $1 \pm
\varepsilon$ for a $\mu$-strongly convex and $L$-smooth function $f$, given
query access to $f(x)$ and $\nabla f(x)$. We give both algorithms and
lowerbounds for this problem. Using an annealing algorithm combined with a
multilevel Monte Carlo method based on underdamped Langevin dynamics, we show
that $\widetilde{\mathcal{O}}\Bigl(\frac{d^{4/3}\kappa +
d^{7/6}\kappa^{7/6}}{\varepsilon^2}\Bigr)$ queries to $\nabla f$ are
sufficient, where $\kappa= L / \mu$ is the condition number. Moreover, we
provide an information theoretic lowerbound, showing that at least
$\frac{d^{1-o(1)}}{\varepsilon^{2-o(1)}}$ queries are necessary. This provides
a first nontrivial lowerbound for the problem.
</p></div>
    </summary>
    <updated>2019-11-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-11T01:30:00Z</updated>
    </source>
  </entry>
</feed>
