<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-22T04:21:41Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1791</id>
    <link href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/" rel="alternate" type="text/html"/>
    <title>(Free) Registeration to TCS Women Rising Star talks</title>
    <summary>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be on the job market this year. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:https://sigact.org/tcswomen/.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be <em><strong>on the job market this year</strong></em>. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:<br/><a href="https://sigact.org/tcswomen/" rel="noreferrer noopener" target="_blank">https://sigact.org/tcswomen/</a>. </p></div>
    </content>
    <updated>2020-06-22T04:16:26Z</updated>
    <published>2020-06-22T04:16:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-06-22T04:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11262</id>
    <link href="http://arxiv.org/abs/2006.11262" rel="alternate" type="text/html"/>
    <title>Universal Geometric Graphs</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frati:Fabrizio.html">Fabrizio Frati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11262">PDF</a><br/><b>Abstract: </b>We introduce and study the problem of constructing geometric graphs that have
few vertices and edges and that are universal for planar graphs or for some
sub-class of planar graphs; a geometric graph is \emph{universal} for a class
$\mathcal H$ of planar graphs if it contains an embedding, i.e., a
crossing-free drawing, of every graph in $\mathcal H$.
</p>
<p>Our main result is that there exists a geometric graph with $n$ vertices and
$O(n \log n)$ edges that is universal for $n$-vertex forests; this extends to
the geometric setting a well-known graph-theoretic result by Chung and Graham,
which states that there exists an $n$-vertex graph with $O(n \log n)$ edges
that contains every $n$-vertex forest as a subgraph. Our $O(n \log n)$ bound on
the number of edges cannot be improved, even if more than $n$ vertices are
allowed.
</p>
<p>We also prove that, for every positive integer $h$, every $n$-vertex convex
geometric graph that is universal for $n$-vertex outerplanar graphs has a
near-quadratic number of edges, namely $\Omega_h(n^{2-1/h})$; this almost
matches the trivial $O(n^2)$ upper bound given by the $n$-vertex complete
convex geometric graph.
</p>
<p>Finally, we prove that there exists an $n$-vertex convex geometric graph with
$n$ vertices and $O(n \log n)$ edges that is universal for $n$-vertex
caterpillars.
</p></div>
    </summary>
    <updated>2020-06-22T01:28:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11182</id>
    <link href="http://arxiv.org/abs/2006.11182" rel="alternate" type="text/html"/>
    <title>$\lambda$-Regularized A-Optimal Design and its Approximation by $\lambda$-Regularized Proportional Volume Sampling</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tantipongpipat:Uthaipon.html">Uthaipon Tantipongpipat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11182">PDF</a><br/><b>Abstract: </b>In this work, we study the $\lambda$-regularized $A$-optimal design problem
and introduce the $\lambda$-regularized proportional volume sampling algorithm,
generalized from [Nikolov, Singh, and Tantipongpipat, 2019], for this problem
with the approximation guarantee that extends upon the previous work. In this
problem, we are given vectors $v_1,\ldots,v_n\in\mathbb{R}^d$ in $d$
dimensions, a budget $k\leq n$, and the regularizer parameter $\lambda\geq0$,
and the goal is to find a subset $S\subseteq [n]$ of size $k$ that minimizes
the trace of $\left(\sum_{i\in S}v_iv_i^\top + \lambda I_d\right)^{-1}$ where
$I_d$ is the $d\times d$ identity matrix. The problem is motivated from optimal
design in ridge regression, where one tries to minimize the expected squared
error of the ridge regression predictor from the true coefficient in the
underlying linear model. We introduce $\lambda$-regularized proportional volume
sampling and give its polynomial-time implementation to solve this problem. We
show its $(1+\frac{\epsilon}{\sqrt{1+\lambda'}})$-approximation for
$k=\Omega\left(\frac d\epsilon+\frac{\log 1/\epsilon}{\epsilon^2}\right)$ where
$\lambda'$ is proportional to $\lambda$, extending the previous bound in
[Nikolov, Singh, and Tantipongpipat, 2019] to the case $\lambda&gt;0$ and
obtaining asymptotic optimality as $\lambda\rightarrow \infty$.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11155</id>
    <link href="http://arxiv.org/abs/2006.11155" rel="alternate" type="text/html"/>
    <title>Full complexity classification of the list homomorphism problem for bounded-treewidth graphs</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okrasa:Karolina.html">Karolina Okrasa</a>, Marta Piecyk, Paweł Rzążewski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11155">PDF</a><br/><b>Abstract: </b>A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping
from $V(G)$ to $V(H)$. Let $H$ be a fixed graph with possible loops. In the
list homomorphism problem, denoted by LHom($H$), we are given a graph $G$,
whose every vertex $v$ is assigned with a list $L(v)$ of vertices of $H$. We
ask whether there exists a homomorphism $h$ from $G$ to $H$, which respects
lists $L$, i.e., for every $v \in V(G)$ it holds that $h(v) \in L(v)$.
</p>
<p>The complexity dichotomy for LHom($H$) was proven by Feder, Hell, and Huang
[JGT 2003]. We are interested in the complexity of the problem, parameterized
by the treewidth of the input graph. This problem was investigated by Egri,
Marx, and Rz\k{a}\.zewski [STACS 2018], who obtained tight complexity bounds
for the special case of reflexive graphs $H$.
</p>
<p>In this paper we extend and generalize their results for \emph{all} relevant
graphs $H$, i.e., those, for which the LHom{H} problem is NP-hard. For every
such $H$ we find a constant $k = k(H)$, such that LHom($H$) on instances with
$n$ vertices and treewidth $t$
</p>
<p>* can be solved in time $k^{t} \cdot n^{\mathcal{O}(1)}$, provided that the
input graph is given along with a tree decomposition of width $t$,
</p>
<p>* cannot be solved in time $(k-\varepsilon)^{t} \cdot n^{\mathcal{O}(1)}$,
for any $\varepsilon &gt;0$, unless the SETH fails.
</p>
<p>For some graphs $H$ the value of $k(H)$ is much smaller than the trivial
upper bound, i.e., $|V(H)|$.
</p>
<p>Obtaining matching upper and lower bounds shows that the set of algorithmic
tools we have discovered cannot be extended in order to obtain faster
algorithms for LHom($H$) in bounded-treewidth graphs. Furthermore, neither the
algorithm, nor the proof of the lower bound, is very specific to treewidth. We
believe that they can be used for other variants of LHom($H$), e.g. with
different parameterizations.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11152</id>
    <link href="http://arxiv.org/abs/2006.11152" rel="alternate" type="text/html"/>
    <title>Common equivalence and size after forgetting</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberatore:Paolo.html">Paolo Liberatore</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11152">PDF</a><br/><b>Abstract: </b>Forgetting variables from a propositional formula may increase its size.
Introducing new variables is a way to shorten it. Both operations can be
expressed in terms of common equivalence, a weakened version of equivalence. In
turn, common equivalence can be expressed in terms of forgetting. An algorithm
for forgetting and checking common equivalence in polynomial space is given for
the Horn case; it is polynomial-time for the subclass of single-head formulae.
Minimizing after forgetting is polynomial-time if the formula is also acyclic
and variables cannot be introduced, NP-hard when they can.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11148</id>
    <link href="http://arxiv.org/abs/2006.11148" rel="alternate" type="text/html"/>
    <title>An Online Matching Model for Self-Adjusting ToR-to-ToR Networks</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Avin:Chen.html">Chen Avin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Griner:Chen.html">Chen Griner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salem:Iosif.html">Iosif Salem</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Stefan.html">Stefan Schmid</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11148">PDF</a><br/><b>Abstract: </b>This is a short note that formally presents the matching model for the
theoretical study of self-adjusting networks as initially proposed in [1].
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.11009</id>
    <link href="http://arxiv.org/abs/2006.11009" rel="alternate" type="text/html"/>
    <title>Fair clustering via equitable group representations</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abbasi:Mohsen.html">Mohsen Abbasi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhaskara:Aditya.html">Aditya Bhaskara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkatasubramanian:Suresh.html">Suresh Venkatasubramanian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.11009">PDF</a><br/><b>Abstract: </b>What does it mean for a clustering to be fair? One popular approach seeks to
ensure that each cluster contains groups in (roughly) the same proportion in
which they exist in the population. The normative principle at play is balance:
any cluster might act as a representative of the data, and thus should reflect
its diversity.
</p>
<p>But clustering also captures a different form of representativeness. A core
principle in most clustering problems is that a cluster center should be
representative of the cluster it represents, by being "close" to the points
associated with it. This is so that we can effectively replace the points by
their cluster centers without significant loss in fidelity, and indeed is a
common "use case" for clustering. For such a clustering to be fair, the centers
should "represent" different groups equally well. We call such a clustering a
group-representative clustering.
</p>
<p>In this paper, we study the structure and computation of group-representative
clusterings. We show that this notion naturally parallels the development of
fairness notions in classification, with direct analogs of ideas like
demographic parity and equal opportunity. We demonstrate how these notions are
distinct from and cannot be captured by balance-based notions of fairness. We
present approximation algorithms for group representative $k$-median clustering
and couple this with an empirical evaluation on various real-world data sets.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10957</id>
    <link href="http://arxiv.org/abs/2006.10957" rel="alternate" type="text/html"/>
    <title>When Is Amplification Necessary for Composition in Randomized Query Complexity?</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=David:Shalev.html">Shalev Ben-David</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml==ouml=s:Mika.html">Mika Göös</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Robin.html">Robin Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watson:Thomas.html">Thomas Watson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10957">PDF</a><br/><b>Abstract: </b>Suppose we have randomized decision trees for an outer function $f$ and an
inner function $g$. The natural approach for obtaining a randomized decision
tree for the composed function $(f\circ
g^n)(x^1,\ldots,x^n)=f(g(x^1),\ldots,g(x^n))$ involves amplifying the success
probability of the decision tree for $g$, so that a union bound can be used to
bound the error probability over all the coordinates. The amplification
introduces a logarithmic factor cost overhead. We study the question: When is
this log factor necessary? We show that when the outer function is parity or
majority, the log factor can be necessary, even for models that are more
powerful than plain randomized decision trees. Our results are related to, but
qualitatively strengthen in various ways, known results about decision trees
with noisy inputs.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10916</id>
    <link href="http://arxiv.org/abs/2006.10916" rel="alternate" type="text/html"/>
    <title>Probabilistic Fair Clustering</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esmaeili:Seyed_A=.html">Seyed A. Esmaeili</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brubach:Brian.html">Brian Brubach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsepenekas:Leonidas.html">Leonidas Tsepenekas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dickerson:John_P=.html">John P. Dickerson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10916">PDF</a><br/><b>Abstract: </b>In clustering problems, a central decision-maker is given a complete metric
graph over vertices and must provide a clustering of vertices that minimizes
some objective function. In fair clustering problems, vertices are endowed with
a color (e.g., membership in a group), and the features of a valid clustering
might also include the representation of colors in that clustering. Prior work
in fair clustering assumes complete knowledge of group membership. In this
paper, we generalize prior work by assuming imperfect knowledge of group
membership through probabilistic assignments. We present clustering algorithms
in this more general setting with approximation ratio guarantees. We also
address the problem of "metric membership", where different groups have a
notion of order and distance. Experiments are conducted using our proposed
algorithms as well as baselines to validate our approach and also surface
nuanced concerns when group membership is not known deterministically.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10847</id>
    <link href="http://arxiv.org/abs/2006.10847" rel="alternate" type="text/html"/>
    <title>New Bounds for the Vertices of the Integer Hull</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berndt:Sebastian.html">Sebastian Berndt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Kim=Manuel.html">Kim-Manuel Klein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10847">PDF</a><br/><b>Abstract: </b>The vertices of the integer hull are the integral equivalent to the
well-studied basic feasible solutions of linear programs. In this paper we give
new bounds on the number of non-zero components -- their support -- of these
vertices matching either the best known bounds or improving upon them. While
the best known bounds make use of deep techniques, we only use basic results
from probability theory to make use of the concentration of measure effect. To
show the versatility of our techniques, we use our results to give the best
known bounds on the number of such vertices and an algorithm to enumerate them.
We also improve upon the known lower bounds to show that our results are nearly
optimal. One of the main ingredients of our work is a generalization of the
famous Hoeffding bound to vector-valued random variables that might be of
general interest.
</p></div>
    </summary>
    <updated>2020-06-22T01:24:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10804</id>
    <link href="http://arxiv.org/abs/2006.10804" rel="alternate" type="text/html"/>
    <title>Karp's patching algorithm on dense digraphs</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alan Frieze <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10804">PDF</a><br/><b>Abstract: </b>We consider the following question. We are given a dense digraph $D$ with
minimum in- and out-degree at least $\alpha n$, where $\alpha&gt;1/2$ is a
constant. The edges of $D$ are given edge costs $C(e),e\in E(D)$, where $C(e)$
is an independent copy of the uniform $[0,1]$ random variable $U$. Let
$C(i,j),i,j\in[n]$ be the associated $n\times n$ cost matrix where
$C(i,j)=\infty$ if $(i,j)\notin E(D)$. We show that w.h.p. the patching
algorithm of Karp finds a tour for the asymmetric traveling salesperson problem
that is asymptotically equal to that of the associated assignment problem.
Karp's algorithm runs in polynomial time.
</p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.11238</id>
    <link href="http://arxiv.org/abs/2003.11238" rel="alternate" type="text/html"/>
    <title>Zeroth-order Optimization on Riemannian Manifolds</title>
    <feedworld_mtime>1592784000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jiaxiang.html">Jiaxiang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balasubramanian:Krishnakumar.html">Krishnakumar Balasubramanian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Ma:Shiqian.html">Shiqian Ma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.11238">PDF</a><br/><b>Abstract: </b>Stochastic zeroth-order optimization concerns problems where only noisy
function evaluations are available. Such problems arises frequently in many
important applications. In this paper, we consider stochastic zeroth-order
optimization over Riemannian submanifolds embedded in an Euclidean space, an
important but less studied area, and propose four algorithms for solving this
class of problems under different settings. Our algorithms are based on
estimating the Riemannian gradient and Hessian from noisy objective function
evaluations, based on a Riemannian version of the Gaussian smoothing technique.
In particular, we consider the following settings for the objective function:
(i) stochastic and gradient-Lipschitz (in both nonconvex and geodesic convex
settings), (ii) sum of gradient-Lipschitz and non-smooth functions, and (iii)
Hessian-Lipschitz. For these settings, we characterize the oracle complexity of
our algorithms to obtain appropriately defined notions of $\epsilon$-stationary
point or $\epsilon$-approximate local minimizer. Notably, our complexities are
independent of the dimension of the ambient Euclidean space and depend only on
the intrinsic dimension of the manifold under consideration. We demonstrate the
applicability of our algorithms by simulation results.
</p></div>
    </summary>
    <updated>2020-06-22T01:28:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/21/subpract</id>
    <link href="https://11011110.github.io/blog/2020/06/21/subpract.html" rel="alternate" type="text/html"/>
    <title>Subpract</title>
    <summary>I’ve written here before about subtraction games, two-player games in which the players remove tokens from a pile of tokens, the number of removed tokens is required to belong to a designated subtraction set, and the goal is to make the last move. For instance, subtract a square, a game I studied at FUN 2018, is of this type, with the subtraction set being the square numbers.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve <a href="https://11011110.github.io/blog/2018/04/18/subtraction-games.html">written here before</a> about <a href="https://en.wikipedia.org/wiki/Subtraction_game">subtraction games</a>, two-player games in which the players remove tokens from a pile of tokens, the number of removed tokens is required to belong to a designated <em>subtraction set</em>, and the goal is to make the last move. For instance, <a href="https://en.wikipedia.org/wiki/Subtract_a_square">subtract a square</a>, a game <a href="https://doi.org/10.4230/LIPIcs.FUN.2018.20">I studied at FUN 2018</a>, is of this type, with the subtraction set being the square numbers.</p>

<p>At some point in studying these games I also briefly looked at the subtraction game whose subtraction set is the set of <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, the numbers whose sums of divisors include all values up to the given numbers. The sequence of these numbers begins</p>



<p>and it turns out to be important here that, after the first one, they’re all even. Let’s call the subtraction game with this subtraction set <em>subpract</em>.</p>

<p>For a subtraction game, or more generally any <a href="https://en.wikipedia.org/wiki/Impartial_game">impartial game</a>, the game states can be partitioned into -positions (where the player who played previously is winning with optimal play) and -positions (where the next player to move can force a win); the -positions tend to be rarer than the -positions, and it’s important to know where they are because the optimal strategy in the game is to move to a -position whenever possible.</p>

<p><a href="http://oeis.org/A275432">OEIS A275432</a> lists the -positions for subpract. They are:</p>



<p>For instance, it’s a winning move in subpract to move to a pile of ten tokens (if you can), because  whatever move your opponent makes from there lets you win. If your opponent takes an even number of tokens, you will be able to take all the remaining tokens and win immediately. And if your opponent takes one token, leaving a pile of nine tokens, you can win by taking six more and leaving a pile of three tokens. Then, regardless of how your opponent responds, you will be able to take all the tokens on your next move.</p>

<p>An obvious pattern jumps out from this list of -positions: they come in pairs, spaced three apart. More precisely, an even number  is a -position if and only if the odd number  is a -position. It’s not just a coincidence, true at the start of the sequence and then false later on: it carries on throughout the entire sequence of -positions. More strongly, this same three-apart pairing of  -positions holds for any subtraction game whose subtraction set contains <span style="white-space: nowrap;">, , and ,</span> and does not contain any other odd numbers.</p>

<h1 id="proof-of-the-pairing-property">Proof of the pairing property</h1>

<p>To prove this, I need to show that  is a -position if and only if  is a winning position. We can prove this by induction, where we assume that all the -positions below  and  are paired up in the same way, and use it to prove that the same pairing holds for  and . The basic idea of the proof is to assume that one of the two players has a winning strategy for the <span style="white-space: nowrap;">position ,</span> and to copy that strategy for , most of the time playing the same moves and responses that you would play for the smaller position. Whenever a sequence of moves is applicable to both  and  and preserves the parity of the starting position, the induction hypothesis shows that it has the same outcome for both starting positions. However, there are a few cases where you may be forced to deviate from this strategy:</p>

<ul>
  <li>
    <p>If  is an -position, but its winning move is to subtract one token leading to an odd -position , then copying that move from the starting position  would lead to the position  which may not be a -position. Instead you should subtract four tokens to get to the position  directly.</p>
  </li>
  <li>
    <p>If  is a -position, and you’re trying to copy its winning strategy in the position , your opponent may be able to subtract , a move that is not possible in , so you have no response to copy. But in this case the result is a pile of just one token, from which you can immediately win.</p>
  </li>
  <li>
    <p>Again, if you’re trying to copy the winning strategy for -position  in the position , your opponent may subtract only one token. In this case, the winning response when starting from  might be to subtract an even number, leading to an odd -position . If you copy this response, you will end up at  which may not be a -position. But instead of copying the -strategy, you can simply subtract two tokens, leading to the position  itself.</p>
  </li>
  <li>
    <p>Similarly, it may be the case that the winning response to an opponent’s even move from  is to take a single token, leading to odd -position . Copying this strategy from the starting position  would again lead to . But in this case you can subtract four tokens leading to  again.</p>
  </li>
</ul>

<p>It’s tempting to guess that, more strongly than pairing -positions and -positions in this way, subpract and similar subtraction games have a pairing of their <a href="https://en.wikipedia.org/wiki/Sprague%E2%80%93Grundy_theorem">nim-values</a>, where the nim-value of an odd position always equals the nim-value of the even position three units smaller. But it’s not true. For instance, in subpract, a pile of four tokens has nim-value 1 while a pile of seven tokens has nim-value 4.</p>

<h1 id="other-subtraction-sets">Other subtraction sets</h1>

<p>Probably the most obvious choice of another subtraction set that begins  and has no larger odd numbers would be the powers of two, but they don’t give rise to an interesting subtraction game: the -positions are just the multiples of three. The same thing happens whenever there are no multiples of three in the subtraction set, as happens for instance with the <a href="https://11011110.github.io/blog/2020/06/21/Telephone number (mathematics)">telephone numbers</a> and <a href="http://oeis.org/A003422">left factorials</a>.</p>

<p>Another natural subtraction set to which this theory applies is the sequence of <a href="http://oeis.org/A025487">Hardy–Ramanujan integers (A025487)</a>, the numbers whose prime factorization  has a non-increasing sequence of exponents . They are:</p>



<p>These are a subset of the practical numbers so one would expect their subtraction game to have more-dense -positions. My implementation found that these -positions are:</p>



<p>again obeying the offset-by-three pairing as it should, and otherwise having somewhat irregular intervals between its -positions.</p>

<p>The <a href="http://oeis.org/A000084">enumeration function of the series-parallel graphs and the cographs</a> is even after its first term because of series-parallel duality; it begins</p>



<p>These are not all practical; for instance, 10, 1532, and 43930 are not practical. The sequence of -positions for their subtraction game begins</p>



<p>mostly differing by three between consecutive values but with occasional glitches where the larger multiple-of-three subtraction set values kick in.</p>

<p>And finally, if we subtract numbers that are one less than a prime, we get the subtraction set</p>



<p>and the sequence of -positions</p>



<p>Its small values have many five-unit gaps but that pattern appears to die out after the quadruple of -positions .</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104384624632242432">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-21T16:29:00Z</updated>
    <published>2020-06-21T16:29:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-21T23:43:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17214</id>
    <link href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/" rel="alternate" type="text/html"/>
    <title>Some Real and Some Virtual News</title>
    <summary>Gossip and more. Composite of , src1, src3 Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the paper, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (SIR) model—to discuss gossip. Their work was done before the present pandemic, in 2017–2019. It is also described in a nice profile of Aguiar. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Gossip and more.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png"><img alt="" class="alignright size-full wp-image-17221" src="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://jessicadeters.wordpress.com/">, </a><a href="https://izabelpaguiar.com/about/">src1</a>, <a href="https://www.linkedin.com/in/jacqueline-feuerborn-87b7b3106/">src3</a></font></td>
</tr>
</tbody>
</table>
<p>
Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the <a href="https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1036&amp;context=codee">paper</a>, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (<a href="https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model">SIR</a>) model—to discuss gossip. Their work was done <em>before</em> the present pandemic, in 2017–2019.  It is also described in a nice <a href="https://sciencebuffs.org/2018/05/14/to-gossip-is-human-to-math-divine/">profile</a> of Aguiar. Their analogy is expressed by a drawing in their paper: </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg"><img alt="" class="aligncenter wp-image-17218" height="125" src="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg?w=400&amp;h=125" width="400"/></a></p>
<p/><p><br/>
Not just for today, but for the summer at least, Ken and I want to share some gossip, share some problems, and ask our readers a question.</p>
<p>
The question first. Ken and I wonder if GLL should start a virtual theory “lunch” meeting, that would meet periodically via Zoom. It would be like meeting for a theory lunch in the old days—just not all in the same room. Some topic might be agreed on, perhaps a short presentation, and always a chance to swap some gossip. Plus maybe ask the group for advice on a problem.</p>
<p>
I do miss the old meetings: </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/meet.png"><img alt="" class="aligncenter size-medium wp-image-17219" height="224" src="https://rjlipton.files.wordpress.com/2020/06/meet.png?w=300&amp;h=224" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">AcademicKeys #78 <a href="https://www.academickeys.com/all/cartoon.php?dothis=display&amp;cartoon[IDX]=78">source</a></font>
</td>
</tr>
</tbody></table>
<p>
What do you think? Should we have such meetings?</p>
<p>
</p><p/><h2> Some Gossip </h2><p/>
<p/><p>
The study of gossip feeds into other issues of the spread of information and misinformation during an election year. Ken’s Buffalo colleague Kenny Joseph has <a href="https://kennyjoseph.github.io/">research</a> on the spread of fake news and Twitter sentiment using mathematical tools adjacent to those of the trio above. Ken and I still intend to say more about epidemiology models ourselves when we get time. But no, here by “gossip” we just mean actual pieces of gossip—just as at a conference or other kind of in-person meeting.</p>
<p>
Here are two examples of the kind of gossip we might exchange. </p>
<p>
Anna Gilbert is moving from Michigan math to Yale math and statistics. She will be the John C. Malone Professor of Mathematics, Professor of Statistics &amp; Data Science. Pretty impressive. She was at Michigan math for <img alt="{2^{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{4}}"/> years. She told me that she could not wait for the next power of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, and thus had to try a new place, with new challenges. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png"><img alt="" class="aligncenter wp-image-17233" height="163" src="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png?w=127&amp;h=163" width="127"/></a></p>
<p>
Rich DeMillo is a long time friend who is at Georgia Institute of Technology and is not moving. He continues working on making voting fair, secure, and efficient. He is referenced in a recent article on voting issues in Georgia. See <a href="https://www.voanews.com/usa/us-politics/activists-cite-tabulation-flaw-georgia-mail-ballots">here</a> for details. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg"><img alt="" class="aligncenter wp-image-17234" height="138" src="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg?w=149&amp;h=138" width="149"/></a></p>
<p>
Note: we have in mind pleasant and factual gossip. The most useful kind is about probable directions and emphases to make projects attractive to pursue. This leads into our other component.</p>
<p>
</p><p/><h2> Possible Problems To Present </h2><p/>
<p/><p>
Here are a problem from each of us as examples of what could be discussed in these meetings and why that might give advantage over just hunting the literature. Both are about factoring—always factoring…</p>
<p>
</p><p/><h3> Factoring: Ken </h3><p/>
<p/><p>
I, Ken, would like to know about field tests of approximative methods in quantum computing, specifically of shortcuts to Shor’s Algorithm. The approximations I have in mind are rougher than those I find in the literature and need not be physically natural.</p>
<p>
To explain, the way Shor’s algorithm is proven correct in Shor’s paper and all textbooks we know—including ours—uses an exact analysis involving the quantum Fourier transform, in which exponentially fine phase angles appear in terms. Approximation can be argued in several ways. Circuits of Hadamard, CNOT, and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>-gates, in which no phase angle finer than <img alt="{\pi/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi/4}"/> appears, can approximate arbitrary quantum circuits to exponential precision with polynomial overhead. With just Hadamard and Toffoli gates, hence <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> as the only phases, one can approximate the data returned by measurements in the algorithm, though without approximating the algorithm’s result vectors in complex Hilbert space. There are other ways to approximate those vectors while eliding the finer phase components. We would like to see more attention to the concrete overheads of all these methods.</p>
<p>
What I would really like to discuss, however, is efforts toward more-brusque approximations that could yield new classical attempts on factoring. For a broad example, note that not only does <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}}"/> reduce to <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> but also individual steps in Shor’s algorithm can be broken down as reductions to counting. Now suppose we apply approximate counting heuristics to those steps. The stock answer for why this doesn’t work to approximate quantum measurement properties <em>globally</em> is that those probabilities have the form </p>
<p align="center"><img alt="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p+%3D+%5Cfrac%7Bf_1%28x%29+-+f_2%28x%29%7D%7BD%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} "/></p>
<p>where <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1}"/> and <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> are <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> functions and <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is something like <img alt="{2^{n/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/2}}"/>. Note the knowledge beforehand that <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is between <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The point is that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is exponential yet smaller than the additive approximations possible in polynomial time for <img alt="{f_1(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1(x)}"/> and <img alt="{f_2(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x)}"/> individually, so the approximation gives no help to the difference. </p>
<p>
However, this does not prevent using approximations of magnitudes that are not differences at intermediate steps. For a vein of more particular examples, I raise the translation from quantum gates to Boolean formulas in my 2018 <a href="https://link.springer.com/chapter/10.1007/978-3-662-56499-8_4">paper</a> with Amlan Chakrabarti and my recent PhD graduate Chaowen Guan. This translation can encode the state <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/> at any intermediate stage of an execution of Shor’s algorithm by a Boolean formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The size of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> stays linear in the size of the quantum circuit being simulated—the exponential explosion happens only when we try to count solutions to <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> encodes all the information in <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>, including the implicit presence of fine phase angles. Now suppose we alter <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> to a <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/> whose corresponding <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> is a simplified approximation of <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>. The kicker is that <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> might not need to be a legal quantum state. The transformations in our paper for later stages of the circuit will still apply building on <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/>. </p>
<p>
Is there any chance of this working? Heuristic approaches applying SAT to factoring have been tried and found to be <a href="https://toughsat.appspot.com/">tough</a>. The nice site <a href="http://beyondnp.org/">BeyondNP</a> includes <a href="http://beyondnp.org/pages/solvers/model-counters-exact/">links</a> to #SAT counters such as <a href="https://sites.google.com/site/marcthurley/sharpsat">sharpSAT</a> and <a href="https://www.cs.rochester.edu/u/kautz/Cachet/index.htm">Cachet</a>. Thus we are not asking anything outlandish. Leveraging Shor’s algorithm might be a new approach. Has anyone tried it? That’s the kind of question I would visit a conference to ask, where wider arity might work better than asking people individually. Thus also for raising it in a meeting.</p>
<p>
</p><p/><h3> Factoring: Dick </h3><p/>
<p/><p>
I have recently been thinking about the power of weak sub-theories of Peano Arithmetic. There are many proofs known that there are an infinite number of prime numbers. The usual proofs use this:</p>
<blockquote><p><b> </b> <em> For all <img alt="{x&gt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%3E1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x&gt;1}"/> there is some prime <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p}"/> that divides <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/>. </em>
</p></blockquote>
<p>Given this it is not hard to prove, in many ways, that there are an infinite number of primes. Euclid’s original proof uses it in the step: Let <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divide <img alt="{p_{1}\cdots p_{n} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%5Ccdots+p_%7Bn%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{1}\cdots p_{n} + 1}"/>. The idea is suppose some weak theory can prove the above. This means that it can prove: 	</p>
<p align="center"><img alt="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%3E1+%5C+%5Cexists+y+%5C+y%7Cx+%5Ctext%7B+and+%7D+%5Cmathsf%7Bprime%7D%28y%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). "/></p>
<p>	 I believe that this shows that if the theory is weak enough that this implies that factoring is in polynomial time. Is this known? Is it true? </p>
<p>
Once again, we can hunt for literature on this. We can ask individual people, such as Avi Wigderson and various co-authors of his. But our hunch is that this topic was explored in the 1990s without a definitive resolution. It could be more effective to get up to speed on it and share ideas in a meeting.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Should we start a virtual theory lunch? Would you attend?</p>
<p>
<b>Added 6/21:</b> Getting back to gossip, we wonder if the all-to-all nature of a Zoom meeting, versus few-to-few in a conference hallway, would filter out the badder kinds of gossip.</p></font></font></div>
    </content>
    <updated>2020-06-21T15:17:56Z</updated>
    <published>2020-06-21T15:17:56Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Factoring"/>
    <category term="Gossip"/>
    <category term="infection models"/>
    <category term="Izabel Aguiar"/>
    <category term="Jacqueline Feuerborn"/>
    <category term="Jessica Deters"/>
    <category term="Logic"/>
    <category term="meetings"/>
    <category term="quantum"/>
    <category term="Shor's algorithm"/>
    <category term="videoconferencing"/>
    <category term="witness functions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-22T04:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10715</id>
    <link href="http://arxiv.org/abs/2006.10715" rel="alternate" type="text/html"/>
    <title>List-Decodable Mean Estimation via Iterative Multi-Fitering</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, Daniel Kongsgaard <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10715">PDF</a><br/><b>Abstract: </b>We study the problem of {\em list-decodable mean estimation} for bounded
covariance distributions. Specifically, we are given a set $T$ of points in
$\mathbb{R}^d$ with the promise that an unknown $\alpha$-fraction of points in
$T$, where $0&lt; \alpha &lt; 1/2$, are drawn from an unknown mean and bounded
covariance distribution $D$, and no assumptions are made on the remaining
points. The goal is to output a small list of hypothesis vectors such that at
least one of them is close to the mean of $D$. We give the first practically
viable estimator for this problem. In more detail, our algorithm is sample and
computationally efficient, and achieves information-theoretically near-optimal
error. While the only prior algorithm for this setting inherently relied on the
ellipsoid method, our algorithm is iterative and only uses spectral techniques.
Our main technical innovation is the design of a soft outlier removal procedure
for high-dimensional heavy-tailed datasets with a majority of outliers.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10698</id>
    <link href="http://arxiv.org/abs/2006.10698" rel="alternate" type="text/html"/>
    <title>Resource Pools and the CAP Theorem</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lewis=Pye:Andrew.html">Andrew Lewis-Pye</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10698">PDF</a><br/><b>Abstract: </b>Blockchain protocols differ in fundamental ways, including the mechanics of
selecting users to produce blocks (e.g., proof-of-work vs. proof-of-stake) and
the method to establish consensus (e.g., longest chain rules vs. BFT-inspired
protocols). These fundamental differences have hindered "apples-to-apples"
comparisons between different categories of blockchain protocols and, in turn,
the development of theory to formally discuss their relative merits.
</p>
<p>This paper presents a parsimonious abstraction sufficient for capturing and
comparing properties of many well-known permissionless blockchain protocols,
simultaneously capturing essential properties of both proof-of-work and
proof-of-stake protocols, and of both longest-chain-type and BFT-type
protocols. Our framework blackboxes the precise mechanics of the user selection
process, allowing us to isolate the properties of the selection process which
are significant for protocol design.
</p>
<p>We illustrate our framework's utility with two results. First, we prove an
analog of the CAP theorem from distributed computing for our framework in a
partially synchronous setting. This theorem shows that a fundamental dichotomy
holds between protocols (such as Bitcoin) that are adaptive, in the sense that
they can function given unpredictable levels of participation, and protocols
(such as Algorand) that have certain finality properties. Second, we formalize
the idea that proof-of-work (PoW) protocols and non-PoW protocols can be
distinguished by the forms of permission that users are given to carry out
updates to the state.
</p></div>
    </summary>
    <updated>2020-06-21T23:30:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10692</id>
    <link href="http://arxiv.org/abs/2006.10692" rel="alternate" type="text/html"/>
    <title>A Competitive B-Matching Algorithm for Reconfigurable Datacenter Networks</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bienkowski:Marcin.html">Marcin Bienkowski</a>, David Fuchssteiner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcinkowski:Jan.html">Jan Marcinkowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Stefan.html">Stefan Schmid</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10692">PDF</a><br/><b>Abstract: </b>This paper initiates the study of online algorithms for the maintaining a
maximum weight b-matching problem, a generalization of maximum weight matching
where each node has at most b &gt; 0 adjacent matching edges. The problem is
motivated by emerging optical technologies which allow to enhance datacenter
networks with reconfigurable matchings, providing direct connectivity between
frequently communicating racks. These additional links may improve network
performance, by leveraging spatial and temporal structure in the workload. We
show that the underlying algorithmic problem features an intriguing connection
to online paging,but introduces a novel challenge. Our main contribution is an
online algorithm which is O (b)-competitive; we also prove that this is
asymptotically optimal. We complement our theoretical results with extensive
trace-driven simulations, based on real-world datacenter workloads as well as
synthetic traffic traces.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10689</id>
    <link href="http://arxiv.org/abs/2006.10689" rel="alternate" type="text/html"/>
    <title>Free Energy Wells and Overlap Gap Property in Sparse PCA</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arous:G=eacute=rard_Ben.html">Gérard Ben Arous</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadik:Ilias.html">Ilias Zadik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10689">PDF</a><br/><b>Abstract: </b>We study a variant of the sparse PCA (principal component analysis) problem
in the "hard" regime, where the inference task is possible yet no
polynomial-time algorithm is known to exist. Prior work, based on the
low-degree likelihood ratio, has conjectured a precise expression for the best
possible (sub-exponential) runtime throughout the hard regime. Following
instead a statistical physics inspired point of view, we show bounds on the
depth of free energy wells for various Gibbs measures naturally associated to
the problem. These free energy wells imply hitting time lower bounds that
corroborate the low-degree conjecture: we show that a class of natural MCMC
(Markov chain Monte Carlo) methods (with worst-case initialization) cannot
solve sparse PCA with less than the conjectured runtime. These lower bounds
apply to a wide range of values for two tuning parameters: temperature and
sparsity misparametrization. Finally, we prove that the Overlap Gap Property
(OGP), a structural property that implies failure of certain local search
algorithms, holds in a significant part of the hard regime.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10592</id>
    <link href="http://arxiv.org/abs/2006.10592" rel="alternate" type="text/html"/>
    <title>On the complexity of detecting hazards</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Komarath:Balagopal.html">Balagopal Komarath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Nitin.html">Nitin Saurabh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10592">PDF</a><br/><b>Abstract: </b>Detecting and eliminating logic hazards in Boolean circuits is a fundamental
problem in logic circuit design. We show that there is no $O(3^{(1-\epsilon)n}
\text{poly}(s))$ time algorithm, for any $\epsilon &gt; 0$, that detects logic
hazards in Boolean circuits of size $s$ on $n$ variables under the assumption
that the strong exponential time hypothesis is true. This lower bound holds
even when the input circuits are restricted to be formulas of depth four. We
also present a polynomial time algorithm for detecting $1$-hazards in DNF (or,
$0$-hazards in CNF) formulas. Since $0$-hazards in DNF (or, $1$-hazards in CNF)
formulas are easy to eliminate, this algorithm can be used to detect whether a
given DNF or CNF formula has a hazard in practice.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10456</id>
    <link href="http://arxiv.org/abs/2006.10456" rel="alternate" type="text/html"/>
    <title>Palette Sparsification Beyond $(\Delta+1)$ Vertex Coloring</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alon:Noga.html">Noga Alon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Assadi:Sepehr.html">Sepehr Assadi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10456">PDF</a><br/><b>Abstract: </b>A recent palette sparsification theorem of Assadi, Chen, and Khanna [SODA'19]
states that in every $n$-vertex graph $G$ with maximum degree $\Delta$,
sampling $O(\log{n})$ colors per each vertex independently from $\Delta+1$
colors almost certainly allows for proper coloring of $G$ from the sampled
colors. Besides being a combinatorial statement of its own independent
interest, this theorem was shown to have various applications to design of
algorithms for $(\Delta+1)$ coloring in different models of computation on
massive graphs such as streaming or sublinear-time algorithms.
</p>
<p>In this paper, we further study palette sparsification problems:
</p>
<p>* We prove that for $(1+\varepsilon) \Delta$ coloring, sampling only
$O_{\varepsilon}(\sqrt{\log{n}})$ colors per vertex is sufficient and necessary
to obtain a proper coloring from the sampled colors.
</p>
<p>* A natural family of graphs with chromatic number much smaller than
$(\Delta+1)$ are triangle-free graphs which are $O(\frac{\Delta}{\ln{\Delta}})$
colorable. We prove that sampling $O(\Delta^{\gamma} + \sqrt{\log{n}})$ colors
per vertex is sufficient and necessary to obtain a proper
$O_{\gamma}(\frac{\Delta}{\ln{\Delta}})$ coloring of triangle-free graphs.
</p>
<p>* We show that sampling $O_{\varepsilon}(\log{n})$ colors per vertex is
sufficient for proper coloring of any graph with high probability whenever each
vertex is sampling from a list of $(1+\varepsilon) \cdot deg(v)$ arbitrary
colors, or even only $deg(v)+1$ colors when the lists are the sets
$\{1,\ldots,deg(v)+1\}$.
</p>
<p>Similar to previous work, our new palette sparsification results naturally
lead to a host of new and/or improved algorithms for vertex coloring in
different models including streaming and sublinear-time algorithms.
</p></div>
    </summary>
    <updated>2020-06-21T23:32:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10444</id>
    <link href="http://arxiv.org/abs/2006.10444" rel="alternate" type="text/html"/>
    <title>Parameterized Inapproximability of Independent Set in $H$-Free Graphs</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pavel Dvořák, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rai:Ashutosh.html">Ashutosh Rai</a>, Paweł Rzążewski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10444">PDF</a><br/><b>Abstract: </b>We study the Independent Set (IS) problem in $H$-free graphs, i.e., graphs
excluding some fixed graph $H$ as an induced subgraph. We prove several
inapproximability results both for polynomial-time and parameterized
algorithms.
</p>
<p>Halld\'orsson [SODA 1995] showed that for every $\delta&gt;0$ IS has a
polynomial-time $(\frac{d-1}{2}+\delta)$-approximation in $K_{1,d}$-free
graphs. We extend this result by showing that $K_{a,b}$-free graphs admit a
polynomial-time $O(\alpha(G)^{1-1/a})$-approximation, where $\alpha(G)$ is the
size of a maximum independent set in $G$. Furthermore, we complement the result
of Halld\'orsson by showing that for some $\gamma=\Theta(d/\log d),$ there is
no polynomial-time $\gamma$-approximation for these graphs, unless NP = ZPP.
</p>
<p>Bonnet et al. [IPEC 2018] showed that IS parameterized by the size $k$ of the
independent set is W[1]-hard on graphs which do not contain (1) a cycle of
constant length at least $4$, (2) the star $K_{1,4}$, and (3) any tree with two
vertices of degree at least $3$ at constant distance.
</p>
<p>We strengthen this result by proving three inapproximability results under
different complexity assumptions for almost the same class of graphs (we weaken
condition (2) that $G$ does not contain $K_{1,5}$). First, under the ETH, there
is no $f(k)\cdot n^{o(k/\log k)}$ algorithm for any computable function $f$.
Then, under the deterministic Gap-ETH, there is a constant $\delta&gt;0$ such that
no $\delta$-approximation can be computed in $f(k) \cdot n^{O(1)}$ time. Also,
under the stronger randomized Gap-ETH there is no such approximation algorithm
with runtime $f(k)\cdot n^{o(k)}$.
</p>
<p>Finally, we consider the parameterization by the excluded graph $H$, and show
that under the ETH, IS has no $n^{o(\alpha(H))}$ algorithm in $H$-free graphs
and under Gap-ETH there is no $d/k^{o(1)}$-approximation for $K_{1,d}$-free
graphs with runtime $f(d,k) n^{O(1)}$.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10365</id>
    <link href="http://arxiv.org/abs/2006.10365" rel="alternate" type="text/html"/>
    <title>Efficient Planar Two-Center Algorithms</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jongmin Choi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahn:Hee=Kap.html">Hee-Kap Ahn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10365">PDF</a><br/><b>Abstract: </b>We consider the planar Euclidean two-center problem in which given $n$ points
in the plane find two congruent disks of the smallest radius covering the
points. We present a deterministic $O(n \log n)$-time algorithm for the case
that the centers of the two optimal disks are close together, that is, the
overlap of the two optimal disks is a constant fraction of the disk area. This
improves the previous best $O(n\log n\log\log n)$ bound by Wang for the case.
We also present a deterministic $O(n\log n)$-time algorithm for the case that
the input points are in convex position.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10364</id>
    <link href="http://arxiv.org/abs/2006.10364" rel="alternate" type="text/html"/>
    <title>On the Parameterized Approximability of Contraction to Classes of Chordal Graphs</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Spoorthy Gunda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Pallavi.html">Pallavi Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10364">PDF</a><br/><b>Abstract: </b>A graph operation that {\em contracts edges} is one of the fundamental
operations in the theory of graph minors. Parameterized Complexity of editing
to a family of graphs by contracting $k$ edges has recently gained substantial
scientific attention, and several new results have been obtained. Some
important families of graphs, namely the subfamilies of chordal graphs, in the
context of edge contractions, have proven to be significantly difficult than
one might expect. In this paper, we study the \textsc{$\cal F$-Contraction}
problem, where $\cal F$ is a subfamily of chordal graphs, in the realm of
parameterized approximation. Formally, given a graph $G$ and an integer $k$,
\textsc{ $\cal F$-Contraction} asks whether there exists $X \subseteq E(G)$
such that $G/X \in \cal F$ and $|X| \leq k$. Here, $G/X$ is the graph obtained
from $G$ by contracting edges in $X$. We obtain the following results for the
\textsc{ $\cal F$-Contraction} problem. $(1)$ We show that \textsc{Clique
Contraction} admits a polynomial-size approximate kernelization scheme
(\textsf{PSAKS}). $(2)$ We give a $(2+\epsilon)$-approximate polynomial kernel
for \textsc{Split Contraction} (which also implies a factor
$(2+\epsilon)$-\FPT-approximation algorithm for \textsc{ Split Contraction}).
Furthermore, we show that, assuming \textsf{ Gap-ETH}, there is no
$\left(\frac{5}{4}-\delta \right)$-\FPT-approximation algorithm for
\textsc{Split Contraction}. Here, $\epsilon, \delta&gt;0$ are fixed constants.
$(3)$ \textsc{Chordal Contraction} is known to be \WTH. We complement this
result by observing that the existing \textsf{W[2]-hardness} reduction can be
adapted to show that, assuming \FPT $\neq$ \textsf{W[1]}, there is no
$F(k)$-\FPT-approximation algorithm for \textsc{Chordal Contraction}. Here,
$F(k)$ is an arbitrary function depending on $k$ alone.
</p></div>
    </summary>
    <updated>2020-06-21T23:21:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10361</id>
    <link href="http://arxiv.org/abs/2006.10361" rel="alternate" type="text/html"/>
    <title>A 3/2--approximation for big two-bar charts packing</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Adil Erzin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nazarenko:Stepan.html">Stepan Nazarenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melidi:Gregory.html">Gregory Melidi</a>, Roman Plotnikov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10361">PDF</a><br/><b>Abstract: </b>We consider a Two-Bar Charts Packing Problem (2-BCPP), in which it is
necessary to pack two-bar charts (2-BCs) in a unit-height strip of minimum
length. The problem is a generalization of the Bin Packing Problem (BPP).
Earlier, we proposed an $O(n^2)$-time algorithm that constructs the packing
which length at most $2\cdot OPT+1$, where $OPT$ is the minimum length of the
packing of $n$ 2-BCs. In this paper, we propose an $O(n^4)$-time
3/2-approximate algorithm when each BC has at least one bar greater than 1/2.
</p></div>
    </summary>
    <updated>2020-06-21T23:24:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10302</id>
    <link href="http://arxiv.org/abs/2006.10302" rel="alternate" type="text/html"/>
    <title>Approximate bi-criteria search by efficient representation of subsets of the Pareto-optimal frontier</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salzman:Oren.html">Oren Salzman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10302">PDF</a><br/><b>Abstract: </b>We consider the bi-criteria shortest-path problem where we want to compute
shortest paths on a graph that simultaneously balance two cost functions. While
this problem has numerous applications, there is usually no path minimizing
both cost functions simultaneously. Thus, we typically consider the set of
paths where no path is strictly better then the others in both cost functions,
a set called the Pareto-optimal frontier. Unfortunately, the size of this set
may be exponential in the number of graph vertices and the general problem is
NP-hard. While existing schemes to approximate this set exist, they may be
slower than exact approaches when applied to relatively small instances and
running them on graphs with even a moderate number of nodes is often
impractical. The crux of the problem lies in how to efficiently approximate the
Pareto-optimal frontier. Our key insight is that the Pareto-optimal frontier
can be approximated using pairs of paths. This simple observation allows us to
run a best-first-search while efficiently and effectively pruning away
intermediate solutions in order to obtain an approximation of the Pareto
frontier for any given approximation factor. We compared our approach with an
adaptation of BOA*, the state-of-the-art algorithm for computing exact
solutions to the bi-criteria shortest-path problem. Our experiments show that
as the problem becomes harder, the speedup obtained becomes more pronounced.
Specifically, on large roadmaps, we obtain an average speedup of more than
$\times 8.5$ and a maximal speedup of over $\times 148$.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10286</id>
    <link href="http://arxiv.org/abs/2006.10286" rel="alternate" type="text/html"/>
    <title>Cyclic space-filling curves and their clustering property</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Igor V. Netay <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10286">PDF</a><br/><b>Abstract: </b>In this paper we introduce an algorithm of construction of cyclic
space-filling curves. One particular construction provides a family of
space-filling curves in all dimensions (H-curves). They are compared here with
the Hilbert curve in the sense of clustering properties, and it turns out that
the constructed curve is very close and sometimes a bit better than the Hilbert
curve. At the same time, its construction is more simple and evaluation is
significantly faster.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10268</id>
    <link href="http://arxiv.org/abs/2006.10268" rel="alternate" type="text/html"/>
    <title>A Fast Binary Splitting Approach to Non-Adaptive Group Testing</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Price:Eric.html">Eric Price</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scarlett:Jonathan.html">Jonathan Scarlett</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10268">PDF</a><br/><b>Abstract: </b>In this paper, we consider the problem of noiseless non-adaptive group
testing under the for-each recovery guarantee, also known as probabilistic
group testing. In the case of $n$ items and $k$ defectives, we provide an
algorithm attaining high-probability recovery with $O(k \log n)$ scaling in
both the number of tests and runtime, improving on the best known $O(k^2 \log k
\cdot \log n)$ runtime previously available for any algorithm that only uses
$O(k \log n)$ tests. Our algorithm bears resemblance to Hwang's adaptive
generalized binary splitting algorithm (Hwang, 1972); we recursively work with
groups of items of geometrically vanishing sizes, while maintaining a list of
"possibly defective" groups and circumventing the need for adaptivity. While
the most basic form of our algorithm requires $\Omega(n)$ storage, we also
provide a low-storage variant based on hashing, with similar recovery
guarantees.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10207</id>
    <link href="http://arxiv.org/abs/2006.10207" rel="alternate" type="text/html"/>
    <title>Political Advertising Dataset: the use case of the Polish 2020 Presidential Elections</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Łukasz Augustyniak, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajda:Krzysztof.html">Krzysztof Rajda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kajdanowicz:Tomasz.html">Tomasz Kajdanowicz</a>, Michał Bernaczyk <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10207">PDF</a><br/><b>Abstract: </b>Political campaigns are full of political ads posted by candidates on social
media. Political advertisements constitute a basic form of campaigning,
subjected to various social requirements. We present the first publicly open
dataset for detecting specific text chunks and categories of political
advertising in the Polish language. It contains 1,705 human-annotated tweets
tagged with nine categories, which constitute campaigning under Polish
electoral law. We achieved a 0.65 inter-annotator agreement (Cohen's kappa
score). An additional annotator resolved the mismatches between the first two
annotators improving the consistency and complexity of the annotation process.
We used the newly created dataset to train a well established neural tagger
(achieving a 70% percent points F1 score). We also present a possible direction
of use cases for such datasets and models with an initial analysis of the
Polish 2020 Presidential Elections on Twitter.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10129</id>
    <link href="http://arxiv.org/abs/2006.10129" rel="alternate" type="text/html"/>
    <title>Smoothed Analysis of Online and Differentially Private Learning</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haghtalab:Nika.html">Nika Haghtalab</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shetty:Abhishek.html">Abhishek Shetty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10129">PDF</a><br/><b>Abstract: </b>Practical and pervasive needs for robustness and privacy in algorithms have
inspired the design of online adversarial and differentially private learning
algorithms. The primary quantity that characterizes learnability in these
settings is the Littlestone dimension of the class of hypotheses [Ben-David et
al., 2009, Alon et al., 2019]. This characterization is often interpreted as an
impossibility result because classes such as linear thresholds and neural
networks have infinite Littlestone dimension. In this paper, we apply the
framework of smoothed analysis [Spielman and Teng, 2004], in which
adversarially chosen inputs are perturbed slightly by nature. We show that
fundamentally stronger regret and error guarantees are possible with smoothed
adversaries than with worst-case adversaries. In particular, we obtain regret
and privacy error bounds that depend only on the VC dimension and the
bracketing number of a hypothesis class, and on the magnitudes of the
perturbations.
</p></div>
    </summary>
    <updated>2020-06-21T23:28:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10085</id>
    <link href="http://arxiv.org/abs/2006.10085" rel="alternate" type="text/html"/>
    <title>Fair k-Means Clustering</title>
    <feedworld_mtime>1592697600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samadi:Samira.html">Samira Samadi</a>, Santosh Vempala <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10085">PDF</a><br/><b>Abstract: </b>We show that the popular $k$-means clustering algorithm (Lloyd's heuristic),
used for a variety of scientific data, can result in outcomes that are
unfavorable to subgroups of data (e.g., demographic groups). Such biased
clusterings can have deleterious implications for human-centric applications
such as resource allocation. We present a fair $k$-means objective and
algorithm to choose cluster centers that provide equitable costs for different
groups. The algorithm, Fair-Lloyd, is a modification of Lloyd's heuristic for
$k$-means, inheriting its simplicity, efficiency, and stability. In comparison
with standard Lloyd's, we find that on benchmark data sets, Fair-Lloyd exhibits
unbiased performance by ensuring that all groups have balanced costs in the
output $k$-clustering, while incurring a negligible increase in running time,
thus making it a viable fair option wherever $k$-means is currently used.
</p></div>
    </summary>
    <updated>2020-06-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4867</id>
    <link href="https://www.scottaaronson.com/blog/?p=4867" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4867#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4867" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum Computing Since Democritus: New Foreword!</title>
    <summary xml:lang="en-US">Time for a non-depressing post. Quantum Computing Since Democritus, which is already available in English and Russian, is about to be published in both Chinese and Japanese. (So if you read this blog, but have avoided tackling QCSD because your Chinese or Japanese is better than your English, today’s your day!) To go along with […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Time for a non-depressing post.  <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a>, which is already available in English and Russian, is about to be published in both Chinese and Japanese.  (So if you read this blog, but have avoided tackling QCSD because your Chinese or Japanese is better than your English, today’s your day!)  To go along with the new editions, Cambridge University Press asked me to write a new foreword, reflecting on what happened in the seven years since the book was published.  The editor, Paul Dobson, kindly gave me permission to share the new foreword on my blog.  So without further ado…</p>



<p/><hr/><p/>



<p><em>Quantum Computing Since Democritus</em> began its life as a course that I taught at the University of Waterloo in 2006.  Seven years later, it became the book that you now hold.  Its preface ended with the following words:</p>



<blockquote class="wp-block-quote"><p>Here’s hoping that, in 2020, this book will be as badly in need of revision as the 2006 lecture notes were in 2013.</p></blockquote>



<p>As I write this, in June 2020, a lot has happened that I would never have predicted in 2013.  Donald Trump is the President of the United States, and is up for reelection shortly.  This is not a political book, so let me resist the urge to comment further.  Meanwhile, the coronavirus pandemic is ravaging the world, killing hundreds of thousands of people, crashing economies, and shutting down schools and universities (including mine).  And in the past few weeks, protests against racism and police brutality started in America and then spread to the world, despite the danger of protesting during a pandemic.</p>



<p>Leaving aside the state of the world, my own life is also very different than it was seven years ago.  Along with my family, I’ve moved from MIT to the University of Texas in Austin.  My daughter, who was born at almost exactly the same time as <em>Quantum Computing Since Democritus</em>, is now a first-grader, and is joined by a 3-year-old son.  When my daughter’s school shut down due to the coronavirus, I began home-schooling her in math, computer science, and physics—in some of the exact same topics covered in this book.  I’m now engaged in an experiment to see what portion of this material can be made accessible to a 7-year-old.</p>



<p>But what about the material itself?  How has it held up over seven years?  Both the bad news and the (for you) good news, I suppose, is that it’s <em>not</em> particularly out of date.  The intellectual underpinnings of quantum computing and its surrounding disciplines remain largely as they were.  Still, let me discuss what <em>has</em> changed.</p>



<p>Between 2013 and 2020, the field of quantum computing made a striking transition, from a mostly academic pursuit to a major technological arms race.  The Chinese government, the US government, and the European Union have all pledged billions of dollars for quantum computing research.  Google, Microsoft, IBM, Amazon, Alibaba, Intel, and Honeywell also now all have well-funded groups tasked with building quantum computers, or providing quantum-computing-related software and services, or even just doing classical computing that’s “quantum-inspired.”  These giants are joined by dozens of startups focused entirely on quantum computing.</p>



<p>The new efforts vary greatly in caliber; some efforts seem rooted in visions of what quantum computers will be able to help with, and how soon, that I find to be wildly overoptimistic or even irresponsible.  But perhaps it’s always this way when a new technology moves from an intellectual aspiration to a commercial prospect.  Having joined the field around 1999, before there were <em>any</em> commercial efforts in quantum computing, I’ve found the change disorienting.</p>



<p>But while some of the new excitement is based on pure hype—on marketers now mixing some “quantum” into their word-salad of “blockchain,” “deep learning,” etc., with no particular understanding of any of the ingredients—there really have been some scientific advances in quantum computing since 2013, a fire underneath the smoke.</p>



<p>Surely the crowning achievement of quantum computing during this period was the achievement of “quantum supremacy,” which a team at Google announced in the fall of 2019.  For the first time, a programmable quantum computer was used to outperform any classical computer on earth, running any currently known algorithm.  Google’s device, called “Sycamore,” with 53 superconducting qubits cooled to a hundredth of a degree above absolute zero, solved a well-defined albeit probably useless sampling problem in about 3 minutes.  To compare, current state-of-the-art simulations on classical computers need a few days, even with hundreds of thousands of parallel processors.  Ah, but will a better classical simulation be possible?  That’s an open question in quantum complexity!  The discussion of that question draws on theoretical work that various colleagues and I did over the past decade.  That work in turn draws on my so-called <strong>PostBQP</strong>=<strong>PP</strong> theorem from 2004, explained in this book.</p>



<p>In the past seven years, there were also several breakthroughs in quantum computing theory—some of which resolved open problems mentioned in this book. </p>



<p>In 2018, Ran Raz and Avishay Tal gave an oracle relative to which <strong>BQP</strong> (Bounded-Error Quantum Polynomial-Time) is not contained in <strong>PH</strong> (the Polynomial Hierarchy).  This solved one of the main open questions, since 1993, about where <strong>BQP</strong> fits in with classical complexity classes, at least in the black-box setting.  (What does that mean?  Read the book!)  Raz and Tal’s proof used a candidate problem that I had defined in 2009 and called “Forrelation.”</p>



<p>Also in 2018, Urmila Mahadev gave a protocol, based on cryptography, by which a polynomial-time quantum computer (i.e., a <strong>BQP</strong> machine) could always prove the results of its computation to a classical polynomial-time skeptic, purely by exchanging classical messages with the skeptic.  Following Urmila’s achievement, I was delighted to give her a $25 prize for solving the problem that I’d announced on my blog back in 2007.</p>



<p>Perhaps most spectacularly of all, in 2020, Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen proved that <strong>MIP*</strong>=<strong>RE</strong>.  Here <strong>MIP*</strong> means the class of problems solvable using multi-prover interactive proof systems with quantumly entangled provers (and classical polynomial-time verifiers), while <strong>RE</strong> means Recursively Enumerable: a class that includes not only all the computable problems, but even the infamous halting problem (!).  To say it more simply, <em>entangled provers can convince a polynomial-time verifier that an arbitrary Turing machine halts</em>.  Besides its intrinsic interest, a byproduct of this breakthrough was to answer a decades-old question in pure math, the so-called Connes Embedding Conjecture (by <em>refuting</em> the conjecture).  To my knowledge, the new result represents the first time that quantum computing has reached “all the way up the ladder of hardness” to touch uncomputable problems.  It’s also the first time that non-relativizing techniques, like the ones central to the study of interactive proofs, were ever used in computability theory.</p>



<p>In a different direction, the last seven years have witnessed an astonishing convergence between quantum information and quantum gravity—something that was just starting when <em>Quantum Computing Since Democritus</em> appeared in 2013, and that I mentioned as an exciting new direction.  Since then, the so-called “It from Qubit” collaboration has brought together quantum computing theorists with string theorists and former string theorists—experts in things like the black hole information problem—to develop a shared language.  One striking proposal that’s emerged from this is a fundamental role for <em>quantum circuit complexity</em>—that is, the smallest number of 1- and 2-qubit gates needed to prepare a given n-qubit state from the all-0 state—in the so-called AdS/CFT (Anti de Sitter / Conformal Field Theory) correspondence.  AdS/CFT is a duality between physical theories involving different numbers of spatial dimensions; for more than twenty years, it’s been a central testbed for ideas about quantum gravity.  But the duality is extremely nonlocal: a “simple” quantity in the AdS theory, like the volume of a wormhole, can correspond to an incredibly “complicated” quantity in the dual CFT.  The new proposal is that the CFT quantity might be not just complicated, but literally circuit complexity itself.  Fanciful as that sounds, the truth is that no one has come up with any other proposal that passes the same sanity checks.  A related new insight is that the nonlocal mapping between the AdS and CFT theories is not merely analogous to, but literally an example of, a quantum error-correcting code: the same mathematical objects that will be needed to build scalable quantum computers.</p>



<p>When <em>Quantum Computing Since Democritus</em> was first published, some people thought it went too far in elevating computer science, and computational complexity in particular, to fundamental roles in understanding the physical world.  But even I wasn’t audacious enough to posit connections like the ones above, which are now more-or-less mainstream in quantum gravity research.</p>



<p>I’m proud that I wrote <em>Quantum Computing Since Democritus</em>, but as the years go by, I find that I have no particular desire to revise it, or even reread it.  It seems far better for the book to stand as a record of what I knew and believed and cared about at a certain moment in time.</p>



<p>The intellectual quest that’s defined my life—the quest to wrap together computation, physics, math, and philosophy into some sort of coherent picture of the world—might never end.  But it does need to start somewhere.  I’m honored that you chose <em>Quantum Computing Since Democritus</em> as a place to start or continue your own quest.  I hope you enjoy it.</p>



<p>Scott Aaronson<br/>Austin, Texas<br/>June 2020</p></div>
    </content>
    <updated>2020-06-20T23:48:04Z</updated>
    <published>2020-06-20T23:48:04Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum Computing Since Democritus"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-21T03:45:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7753</id>
    <link href="https://windowsontheory.org/2020/06/19/stoc-2020-information-guest-post-by-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 information (guest post by Madhur Tulsiani)</title>
    <summary>Dear fellow theorists, As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, please do so soon (students: $25, regular: $50). This will help us ensure we have capacity for various online events.  Upon registration, you should receive a confirmation […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx" rel="noreferrer noopener" target="_blank">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a>stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html" rel="noreferrer noopener" target="_blank">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li>Slack: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom sessions are available via information in the registration confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town/" rel="noreferrer noopener" target="_blank">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p>



<p>TheoryFest organization team</p>



<p>(<a>stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-19T22:05:41Z</updated>
    <published>2020-06-19T22:05:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-06-22T04:20:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=180</id>
    <link href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/" rel="alternate" type="text/html"/>
    <title>STOC 2020 Goes Virtual!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with TCS+, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some unusual technical challenges), but I think we have something which … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/">Continue reading<span class="screen-reader-text"> "STOC 2020 Goes Virtual!"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with <a href="https://sites.google.com/site/plustcs/">TCS+</a>, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some <a href="https://twitter.com/thegautamkamath/status/1273055827092549634">unusual technical challenges</a>), but I think we have something which I hope will be engaging and generally a lot of fun. In addition to the typical academic component, we also have a social component planned as well. We learnt from the work of others, including the <a href="https://www.acm.org/virtual-conferences">ACM virtual conferences guide</a>, <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, and <a href="https://www.daniellitt.com/blog/2020/4/20/wagon-lessons-learned">WAGON</a>. I may make some version of our logistics docs available to others after the conference, so others can learn from our experience as well. Anyway, read on for an announcement from me and the other General Chairs, Konstantin Makarychev, Yury Makarychev, and Madhur Tulsiani. See also the <a href="http://acm-stoc.org/stoc2020/">main STOC page</a> for a more complete list of credits.</p>



<hr class="wp-block-separator"/>



<p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a href="mailto:stoc2020@ttic.edu">stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li><strong>Slack</strong>: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom session via information in the confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p></div>
    </content>
    <updated>2020-06-19T20:20:16Z</updated>
    <published>2020-06-19T20:20:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-06-22T04:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc, PhD student at Ben-Gurion University (apply by November 20, 2020)</title>
    <summary>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel. Website: https://www.cs.bgu.ac.il/~klim/Links/Call Email: klim@bgu.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~klim/Links/Call">https://www.cs.bgu.ac.il/~klim/Links/Call</a><br/>
Email: klim@bgu.ac.il</p></div>
    </content>
    <updated>2020-06-19T13:47:44Z</updated>
    <published>2020-06-19T13:47:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-22T04:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4859</id>
    <link href="https://www.scottaaronson.com/blog/?p=4859" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4859#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4859" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Justice has no faction</title>
    <summary xml:lang="en-US">(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 holding led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-group"><div class="wp-block-group__inner-container"/></div>



<p>(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 <a href="https://www.supremecourt.gov/opinions/19pdf/18-587_5ifl.pdf">holding</a> led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in many cases, the only homes they remember, for no particular reason other than to slake the resentment of Trump’s base. Better still was the majority’s argument: that when, by law, a federal agency has to supply a <em>reason</em> for a policy change (in this case, ending DACA), its reason can’t just be blatantly invented <em>post facto</em>.</p>



<p>To connect to my <a href="https://www.scottaaronson.com/blog/?p=4845">last post</a>: I hope this gives some evidence that, if Trump refuses to accept an electoral loss in November, and if it ends up in the Supreme Court as Bush v. Gore did, then Roberts might once again break from the Court’s other four rightists, in favor of the continued survival of the Republic.</p>



<p>(2) Along with Steven Pinker, Scott Alexander, Sam Altman, Jonathan Haidt, Robert Solovay, and others who might be known to this blog’s readership, I decided after reflection to sign a <a href="https://sites.google.com/view/petition-letter-stephen-hsu/home?authuser=0">petition</a> in support of Steve Hsu, a theoretical physicist turned genomics researcher, and the Senior Vice President for Research and Innovation at Michigan State University.</p>



<figure class="wp-block-image"><img alt="Information Processing: Hail to the Chief" src="https://1.bp.blogspot.com/-dVAprDWO_YI/UzGkunExlkI/AAAAAAAAEq4/MuApiqQsX_I/s1600/photo+(4).JPG"/>Hsu is the one on the right.</figure>



<p>Hsu now faces possible firing, because of a social media campaign apparently started by an MSU grad student and SneerClub poster named Kevin Bird.  What are the <a href="https://twitter.com/GradEmpUnion/status/1270829003130261504">charges</a>?  Hsu appeared in 2017 on an alt-right podcast (albeit, one that Noam Chomsky has also appeared on).  On Hsu’s own podcast, he <a href="https://manifoldlearning.com/episode-010-transcript/">interviewed Ron Unz</a>, who despite Jewish birth has become a <a href="https://www.unz.com/runz/american-pravda-holocaust-denial/">nutcase Holocaust denier</a>—yet somehow that topic never came up on the podcast.  Hsu said that, as a scientist, he doesn’t know whether group differences in average IQ have a genetic component, but our commitment to anti-racism should never hinge on questions of biology (a view also espoused by Peter Singer, perhaps the leading liberal moral philosopher of our time).  Hsu has championed genomics research that, in addition to medical uses, <em>might someday</em> help enable embryo screening for traits like IQ.  Finally, Hsu supports the continued use of standardized tests in university admissions (yes, that’s one of the listed charges).</p>



<p>Crucially, <strong>it doesn’t matter</strong> for present purposes if you disagree with many of Hsu’s views. The question is more like: <em>is agreement with Steven Pinker, Jonathan Haidt, and other mild-mannered, Obama-supporting thinkers featured in your local airport bookstore now a firing offense in academia?  And will those who affirm that it is, claim in the next breath to be oppressed, marginalized, the Rebel Alliance?</em></p>



<p>To be fair to the cancelers, I think they have two reasonable arguments in their favor.</p>



<p>The first that they’re “merely” asking for Hsu to step down as vice president, not for him to lose his tenured professorship in physics.  Only <em>professors</em>, say the activists, enjoy academic freedom; <em>administrators</em> need to uphold the values and public image of their university, as Larry Summers learned fifteen years ago.  (And besides, we might add, what intellectual iconoclast in their right mind would ever <em>become</em> a university VP, or want to stay one??)  I’d actually be fine with this if I had any confidence that it was going to end here.  But I don’t.  Given the now-enshrined standards—e.g., that professors hold positions of power, and that the powerful can oppress the powerless, or even do violence to them, just by expressing or entertaining thoughts outside an ever-shrinking range—why should Hsu trust any assurances that he’ll be left alone, if he <em>does</em> go back to being a physics professor?  If the SneerClubbers can cancel him, then how long until they cancel Pinker, or Haidt, or me?  (I <em>hope</em> the SneerClubbers enthusiastically embrace those ideas!  If they do, then no one ever again gets to call me paranoid about Red Guards behind every bush.)</p>



<p>The second reasonable argument is that, as far as I can tell, Hsu really did grant undeserved legitimacy to a Holocaust denier, via a friendly interview about other topics on his podcast.  I think it would help if, without ceding a word that he doesn’t believe, Hsu were now to denounce racism, Holocaust denial, and specifically Ron Unz’s flirtation with Holocaust denial in the strongest possible terms, and explain why he didn’t bring the topic up with his guest (e.g., did he not know Unz’s views?).</p></div>
    </content>
    <updated>2020-06-18T21:35:08Z</updated>
    <published>2020-06-18T21:35:08Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-21T03:45:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-785371757594389601</id>
    <link href="http://processalgebra.blogspot.com/feeds/785371757594389601/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=785371757594389601" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/an-interview-with-hans-huttel-concur.html" rel="alternate" type="text/html"/>
    <title>An interview with Hans Hüttel, CONCUR Test-of-Time Award recipient</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">This post is devoted to the fourth, and last, interview with the <a href="https://concur2020.forsyte.at/test-of-time/index.html">colleagues</a> who were selected for the first edition of the CONCUR  Test-of-Time Award. (See <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html">here</a> for the interview with <a href="http://www.cs.unibo.it/~sangio/">Davide Sangiorgi</a>,  <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-nancy-lynch-and.html">here</a> for the interview with <a href="https://people.csail.mit.edu/lynch/">Nancy Lynch</a> and <a href="http://profs.sci.univr.it/~segala/">Roberto Segala</a>, and <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-rob-van-glabbeek.html">here</a> for the interview with </span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><a href="http://theory.stanford.edu/~rvg/">Rob van Glabbeek</a></span></span></span></span></span></span>.) In keeping with my previous interviews, I asked  <a href="http://people.cs.aau.dk/~hans/index-eng.html">Hans  Hüttel</a> (Aalborg University, Denmak) a few questions via email and you can find his answers below. </span></span></span></span></span></span><br/><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Hans receives the award for his paper</span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"> "Bisimulation Equivalence is Decidable for all Context-Free Processes", which he wrote  with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling. </span></span></span></span></span></span></span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren moved to industry after finishing his PhD. Colin is now retired.  </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br/><br/><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You receive one of the two CONCUR ToT Awards for the period 1990-1993 for the paper</span></span></span><span><span style="font-size: x-small;">  </span></span><span><span style="font-size: x-small;"><span lang="en-US">"<a href="https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-218/">Bisimulation Equivalence is Decidable for all Context-Free Processes</a>" you published with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling at CONCUR 1992. Could you tell us briefly what the context for that work was and how it came about? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I was working on my PhD which was on the topic of decidability of behavioural equivalences for process calculi that allow processes to have infinite state spaces. Baeten, Bergstra and Klop had proved that strong bisimilarity is in fact decidable for the BPA calculus even though the class of trace languages for BPA is exactly the class of context-free languages. The result only held for normed BPA processes, that is, processes that could always terminate. Colin was my supervisor in Edinburgh, and he suggested that I try to find a simpler proof of that result (much can be said about the original proof, but simple it was not!). This turned out to be really interesting; I met Didier Caucal from IRISA who had found a nice, much shorter proof that relied on finite characterizations and I was able to use his notion of self-bisimilarity to prove that a tableau system for bisimilarity was sound and complete wrt. bisimilary. Jan Friso Groote, who was a PhD student at the CWI at the time, and myself proved that all other known equivalences are undecidable for normed BPA (and therefore </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>a fortiori</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">also for full, unnormed BPA). But one problem that Colin and I were never able to solve was if the decidability result also held for the full BPA calculus.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Søren arrived in Edinburgh in 1990 and we shared a flat there, in St Leonards Bank just across from Holyrood Park. We hung out with the same people in the LFCS, many of whom were clever Italians such as Davide Sangiorgi and clever quasi-Italians such as Marcelo Fiore. It is no surprise that Søren and I often discussed our work or that he, given that Colin was also his supervisor, moved on to study decidability problems as well, the only difference being that Søren was mostly interested in the BPP calculus that has parallel composition instead of sequential composition.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">When I left Edinburgh at the end of August of 1991, Colin and I had managed to make some progress on the decidability problem for unnormed BPA. We realised that a finite characterization of the maximal bisimulation </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>á la</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">Caucal was the way ahead but the actual characterization escaped us. When I returned for my viva in December, Søren had found an important lemma on finite characterizations and everything fell into place. The decidability result relied on proving that bisimilarity is semi-decidable using the finite characterization; non-bisimilarity was already known to be semi-decidable. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: Both S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and you wrote the award-winning paper as PhD students in Edinburgh. Could you tell us about the research environment in Edinburgh at that time, and the influence it had on you then and in the rest of your career? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: The LFCS in Edinburgh was a great place to be at the time. Robin Milner was still around and busy working on the pi-calculus together with Davide Sangiorgi, who was his student at the time. Watching them at the blackboard was interesting, even though the rest of us often could not follow their discussions! Gordon Plotkin was there (and still is, fortunately). Rod Burstall was still active, and so was Mike Fourman. Plus many, many others. There was always someone to talk to, and it was perfectly legitimate to have an interest in basic research. Unlike the other professors, Colin had no background in maths – he was originally a philosopher! – and maybe that was why he was trying to avoid heavy mathematical lingo, trying to be simple and precise in his writing at the same time. I learned a lot from him, also in that respect.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">After Søren returned to Denmark, he left academia and got a job in the private sector. He still lives near Aarhus. Sadly we lost touch with each other, in all likelihood because our lives turned out so different. We got back in touch recently, when we were told about the reward and we look forward to finally meeting each other again. Colin retired recently, and I really hope to see him again, when I am able to travel to Scotland again some day.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: How much of your later work has built on your award-winning paper? What follow-up results of yours are you most proud of and why?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I worked on decidability issues for another few years after that but there was no-one to talk to in Aalborg, or rather, there was no-one there that shared my interest in the area at the time. What is more, the open problems that remained were major challenges. Some were only solved much later (such as the decidability of bisimilarity for pushdown automata, a result due to Sénizergues, the proof later greatly simplified by Colin) or remain open (such as the decidability of weak bisimilarity for BPA). Eventually I drifted down the slippery slope and became interested in other, related topics, and focused somewhat more directly on program properties. The follow-up result that most directly relates to my paper with Søren and Colin is the result from 1994 that bisimilarity is also the only equivalence that is decidable for BPP. This is a result that I am also quite proud of. It grew out of discussions with Javier Esparza and Yoram Hirshfeld, when I was back in Edinburgh for a while in 1993. Ironically, there was a subtle flaw in the proof that Naoki Kobayashi discovered many years later. Naoki and one of his student found out how to repair the proof, and the three of us co-authored the journal version that came out many years later. The reason why Naoki became interested in BPP was that he was trying to use the calculus as a behavioural type system for a pi-calculus. As it happened, this was also the route that I had taken.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Those of my later results that I am most proud of have to do with this area: My work on type systems for psi-calculus (CONCUR 2011 and later) and a session type system for bounded name use in the pi-calculus (Acta Informatica 2019). The latter paper also has a CONCUR connection; it grew out of attending a talk by Roland Meyer at CONCUR 2013 and wondering why they were not trying to characterize notions of name-boundedness in the pi-calculus by means of a type system. It turned out that Meyer et al. were not familiar with type systems at all. It took me an awful long time to work out a type-based characterization (using session types), as you can probably tell.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">As you can tell, I have not worked on bisimulation for quite some time. Not that there is anything wrong with bisimulation, of course, but if one wants results that are applicable for automated reasoning about program behaviour, decidability is important. One can then either choose to go for a less expressive model of computation (which is what researchers in the model checking community do) or keep the model of computation and go for sound, but incomplete characterizations of program properties (which is what researchers interested in type systems and related static analysis methods do). I ended up in the latter camp.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: To your mind, what are the most interesting or unexpected uses in the literature of the notions and techniques you developed in "Bisimulation Equivalence is Decidable for all Context-Free Processes"? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: BPA, BPP and similar process calculi can be used as the basis of behavioural type systems, and I am thrilled that my old research interests and my current research interests are so directly related. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">In 2018 I discovered that Vasco Vasconcelos and Peter Thiemann had devised a session type system for a functional programming language in which session types were not regular expressions (which is essentially what they are in the original work by Honda, Kubo and Vasconcelos) but BPA processes. Vasco and Peter knew that type equivalence should be decidable but they were not so familiar with our results from the early 1990s. At POPL 2019 I attended a talk by Andreia Mordido, one of Vasco’s collaborators, and she mentioned our paper from CONCUR 1992! Later that day, I ended up talking to Andreia and Vasco about my work on BPA from all those years ago.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: The last forty years have seen a huge amount of work on process algebra and process calculi. However, the emphasis on that field of research within concurrency theory seems to have diminished over the last few years, even in Europe. What advice would you give to a young researcher interested in working on process calculi today? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: That they should still work on process calculi! There remains a lot of interesting work to be done. One reason why research topics drift in and out of focus is simply that researchers lose interest; it is hardly ever the case that a topic runs out of interesting research questions. Another reason is rather grim: Basic research is nowhere near as well-respected as it used to be. If you look at the funding schemes that we have today, only the very successful few can get funding for basic research; I am not among them and it does get frustrating quite often. Most topics these days deal with applied research. There is nothing wrong with applied research per se; some of what I do is on that side of things, but there has to be more to research than that. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: What are the research topics that currently excite you the most?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I have slowly become more and more interested in programming language theory, and some of my current collaborators have taken a similar route, beginning in concurrency theory, drifting into the world of behavioural type systems and finally wanting to apply all of their skills to actual programming languages. Right now Mario Bravetti, Adrian Francalanza, António Ravara and myself are involved in working on a behavioural type system related to the Mungo tool for a subset of Java. I am fortunately enough to have had three exceptionally clever and productive MSc students involved as well, and this has been extremely helpful. Mungo is in many ways the work of Simon Gay and Ornela Dardha at Glasgow University, and they, too, began their careers working on process calculi.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You have a keen interest in teaching at university level. Is there anything you think we should do better in conveying the beauty and usefulness of theoretical computer science in general, and concurrency theory in particular, to our students today? Do you have any thoughts you'd like to share with us on how to combine digital resources and in-person meetings in the teaching of subjects in the theory of computing?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: Personally I think there is a tendency to present any academic topic – and in particular topics in the mathematical sciences, broadly speaking – in such a way that the definitions and theorems appear as if they fell from the heavens, fully formed. As any researcher will know, that is certainly </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>not </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">how they came about. In this way, we focus a lot on what Imre Lakatos and Karl Popper called the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of justification. </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">A well-honed presentation of a theory may appear to be beautiful, but in my opinion the actual beauty is the one that one experiences when one has finally understood the theory and understands why the definitions and theorem turned out the way they did – that is, one must understand the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of discovery.</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">I think problem-based learning (which is something that we talk about a lot at Aalborg University and at Roskilde University) is the key here, because it puts the focus on student-centered active learning.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">I have lectured a lot over the years but since 2013 I have drifted away from traditional lectures towards flipped teaching in which I use pre-recorded podcasts (of my own making) that students can watch whenever they want; I then use the plenary sessions for activities that focus on active learning. I by far prefer having a dialogue with students that focuses on the problems that they encounter to the monologue style of a lecture. All my teaching activities are now flipped and I am happy to say that some of my colleagues are now thinking along similar lines. It is always good to have someone to talk to. </span></span></span></span></span></span><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK"> </span></span></span></span></span></span></div></div>
    </content>
    <updated>2020-06-18T21:29:00Z</updated>
    <published>2020-06-18T21:29:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-21T21:12:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5834988441622500007</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5834988441622500007/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html" rel="alternate" type="text/html"/>
    <title>On Chain Letters and Pandemics</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><i>Guest post by Varsha Dani.</i></div><div><br/></div><div>My 11-year-old child received a letter in the mail. "Send a book to the first person named," it said, "then move everyone's name up the list, add your own name and send copies of the letter to six friends. In a few weeks you will receive 36 books from all over the world!". Wow. When I first encountered chain letters in the mid eighties, it was postcards, but even then it hadn't taken me in. Since then I hadn't seen one of these in a long time, but I guess with a lot of people suddenly at home for extended periods, people crave both entertainment and a connection to others. </div><div><br/></div><div>What's wrong with chain letters? Well quite apart from the fact that they are illegal, even a child can comprehend that the number of books (or postcards or other gifts) received must equal the number sent, and that for every participant who does get a rich reward, there will be many who get nothing. </div><div><br/></div><div>But there is another kind of chain communication going around. It is an email, asking the recipient to send a poem or meditation to somebody, and later they will receive many communications of the same sort. How endearing. Poetry. Sweetness and Light. No get-rich-quick pyramid schemes here. What's wrong with that? </div><div><br/></div><div>Of course, it depends on what one means by "wrong". Maybe you like exchanging poetry with strangers. Maybe you don't find it onerous or wish that your spam filter would weed it out. But let's leave aside those issues and look at the math alone. You send the email to two friends, each of whom forwards it to two of their friends and so on. So the number of people the email reaches ostensibly doubles every step. Exponential growth. But in fact that is not what the graph of human connections looks like. Instead, what happens is that the sets of friends overlap, so that after a while the growth stops being exponential and tapers down. </div><div><br/></div><div>Where else have we seen something like that? Oh, right. The pandemic. The virus jumps from infected people to the people they meet, and from them to the people they meet and so on. Initially, that's exponential growth fof new cases, but after a while  it tapers off, forms a peak and then starts to decrease. Why? Because eventually there is overlap in the sets of people that each infected person is "trying" (unintentionally) to infect, and a newly infected person who got the virus from one or many previously infected people is still just one newly infected person.  </div><div><br/></div><div>So the chain letter spreads just like a virus. Indeed if one were to, somewhat fancifully, think of the chain letter as an independent entity whose goal is to self-replicate, then it looks even more like a virus, and, like a virus, it can only achieve its self-replication goal through the help of a host. But here's a way in which it is not like a virus. Once one has got the virus and recovered, one (hopefully) does not get it again. Not so the chain letter, of which one may get many copies over time! So maybe you will get some gifts or poetry, but you will likely also get more requests for them!</div><div><br/></div><div>So what's wrong with the poetry chain email? It depends on your perspective.  To those of you who are wistfully waiting for that Poem from a Stranger, I dedicate the following to you.</div><div><br/></div><hr/><div><br/></div><div><i>An open letter to my 2<sup>n</sup> dearest friends:</i></div><div><br/></div><div>A letter came for me today</div><div>It promised wondrous ends</div><div>If only I would forward it </div><div>To just two other friends.</div><div><br/></div><div>If they in turn should send it on</div><div>to two more that they know,</div><div>the goodwill that we're sending out</div><div>would grow and grow and grow.</div><div><br/></div><div>Is this as pleasant as it seems?</div><div>Alas, dear friends, it's not.</div><div>This exponential growth can lead</div><div>To quite a sticky spot.</div><div><br/></div><div>Friends of friends of friends of mine</div><div>May very well be linked</div><div>The further that the letters go.</div><div>These folks are not distinct!</div><div><br/></div><div>Ensuring there's no overlap</div><div>Is a logistic* pain.</div><div>As you will see, when you receive</div><div>That letter yet again. </div><div><br/></div><div>So while you're stuck at home this year</div><div>And pacing in your room.</div><div>Pick up the phone and make a call</div><div>Or see your friends on Zoom.</div><div><br/></div><div>Your real thoughts would make me smile.</div><div>Chain letters are a con.</div><div>Do everyone a favor and</div><div>Don't send that letter on!</div><div><br/></div><div>--------------</div><div>* Pun intended. <a href="https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic">https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic</a></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-06-18T13:57:00Z</updated>
    <published>2020-06-18T13:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-21T08:03:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/background/</id>
    <link href="https://gradientscience.org/background/" rel="alternate" type="text/html"/>
    <title>Noise or Signal&amp;#58; The Role of Backgrounds in Image Classification</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="http://arxiv.org/abs/2006.09994" style="float: left;">
<i class="fas fa-file-pdf"/>
    Read the paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/backgrounds_challenge" style="float: right;">
<i class="fab fa-github"/>
   Download the datasets
</a></p>

<p><em>We discuss our recent <a href="https://arxiv.org/abs/2006.09994">paper</a> 
on identifying the role of backgrounds in image classification. Along with our
results, we’re releasing our code and datasets <a href="https://github.com/MadryLab/backgrounds_challenge">as a benchmark</a>.</em></p>

<p>As we discussed in our <a href="https://gradientscience.org/benchmarks">last post</a>, quantitative
benchmarks are key drivers of progress across many computer vision tasks. 
On tasks like image classification, state of the art is often determined by models’
accuracies on standard datasets, such as CIFAR-10 and ImageNet. 
Still, model accuracy isn’t all that matters, as evidenced by investigations into
robustness (e.g., <a href="https://gradientscience.org/intro_adversarial">[1]</a>), 
reliability (e.g., <a href="https://arxiv.org/abs/1903.12261">[2]</a>), 
and out-of-distribution performance (e.g., <a href="https://arxiv.org/abs/1706.02690">[3]</a>). 
These properties are governed not only by models’ predictions on test data, but
also by the specific set of correlations models use, and by how these
correlations are combined to make predictions. 
For example, previous work has shown that model predictions can behave
unexpectedly due to reliance on correlations that we humans 
don’t rely on (e.g. <a href="https://arxiv.org/abs/1711.11561">[4]</a>,
<a href="https://arxiv.org/abs/1807.04200">[5]</a>,
<a href="https://arxiv.org/abs/1905.02175">[6]</a>, 
<a href="https://arxiv.org/abs/1811.00401">[7]</a>); or due to overusing even
human-recognizable correlations such as texture (e.g., 
<a href="https://arxiv.org/abs/1811.12231">[8]</a>,
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6306249/">[9]</a>) or color 
(e.g., <a href="https://journals.sagepub.com/doi/10.1068/p3376">[10]</a>). 
So it follows that if we want to understand these more complex properties of
machine learning models, we must first be able to characterize the correlations
that these models leverage.</p>

<p>Needless to say, a full characterization of the features and signals exploited
by deep neural networks is far beyond the scope of any single paper. In our
<a href="https://arxiv.org/abs/2006.09994">latest paper</a>, 
we thus take a deep dive into one specific kind of signal: <em>image backgrounds</em>.</p>

<p>Backgrounds are an established source of correlation between images and
their labels in object detection: ML models may use backgrounds in
classification (cf.
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">[11]</a>,
<a href="https://arxiv.org/abs/1602.04938">[12]</a>, 
<a href="https://arxiv.org/abs/1611.06596">[13]</a>,
<a href="https://arxiv.org/abs/1911.08731">[14]</a>), and even human
vision can make use of image context (cf.
<a href="http://people.csail.mit.edu/torralba/IJCVobj.pdf">[15]</a> and references). 
We thus want to understand better how current
state-of-the-art image classifiers rely on image backgrounds. 
Specifically, we investigate the extent of this reliance, its implications, and how models’ use of
backgrounds has evolved over time.</p>

<h2 id="a-new-dataset-or-seven">A new dataset (or seven)</h2>

<p>Our main tool for understanding how models use background signals is a set of
synthetic datasets that we refer to as ImageNet-9 (IN9). These datasets aim
to disentangle images’ foreground and background signals and thus enable us
to study their relative effects.</p>

<p>To generate ImageNet-9, we start by organizing a subset of ImageNet into nine
coarse-grained classes based on common ancestry in the <a href="https://wordnet.princeton.edu">WordNet hierarchy</a>: the
resulting “super-classes” are dog, bird, vehicle, reptile, carnivore, insect, 
instrument, primate, and fish. We call the 9-class dataset of unmodified images
Original.
We then use a combination of the bounding boxes
provided by ImageNet and the computer vision library <a href="https://opencv.org">OpenCV</a> to separate the
foreground and background in each imagewe deleted any images where this
process was unsuccessful (e.g., if there is no bounding box provided by ImageNet, or the bounding box takes up the entirety of the image).</p>

<p>Once we’ve separated the foreground and background signals, we introduce
 <em>seven</em> new datasets, falling into three categories:</p>

<ul>
  <li>Background-only datasets
    <ul>
      <li><strong>Only-BG-B</strong>: Black out the bounding boxes given by ImageNet annotations,
leaving only the background.</li>
      <li><strong>Only-BG-T</strong>: Take Only-BG-B and replace the blacked-out region with a
tiled version of the rest of the image (the background).</li>
      <li><strong>No-FG</strong>: Use OpenCV to extract the exact shape of the foreground, and
replace it with black.</li>
    </ul>
  </li>
  <li>Foreground-only datasets
    <ul>
      <li><strong>Only-FG</strong>: The exact complement of No-FG—rather than removing
the foreground, remove everything else.</li>
    </ul>
  </li>
  <li>Mixed datasets
    <ul>
      <li><strong>Mixed-Rand</strong>: For each image, overlay the foreground (extracted using
OpenCV) onto the background from a different random image (again,
extracted using OpenCV).</li>
      <li><strong>Mixed-Next</strong>: Assign each class a number from 1 to 9. For each image of
class $y$, add the background from a random image of class $y+1$ (or $1$, if
$y=9$).</li>
      <li><strong>Mixed-Same</strong>: For each image, add the background from a random image of
the same class.</li>
    </ul>
  </li>
</ul>

<div class="widget" style="display: flex;">
    <div class="choices_one" id="left_in9">
	<span class="widgetheading">Choose an Image</span>
    </div>
    <div class="selected_one" id="in9_selected"/>
</div>
<div style="clear: both;"/>
<div class="footnote">
        8 versions of the same image, with each version capturing a different
        combination of foreground and background signals.
</div>

<h2 id="putting-imagenet-9-to-work">Putting ImageNet-9 to work</h2>

<p>It turns out that these proposed ImageNet-9 datasets allow us to ask (and
answer) a variety of questions about the role of background signals in image
classification.</p>

<h3 id="1-is-background-signal-enough-for-classification">1. Is background signal enough for classification?</h3>

<p>Before we look at the behaviour of standard ML models, we first double-check
that background signals are exploitable in the first place—i.e., that models
can learn reasonably accurate classifiers for natural images while being trained
on backgrounds alone. 
We are not the first ones to consider this question (e.g.,
<a href="https://arxiv.org/abs/1611.06596">[13]</a>) but it serves as a useful sanity 
check and gives us a baseline to compare the rest of our experiments to.</p>

<p>We train models on the Only-BG-T, Only-BG-B, and No-FG datasets; the models
generalize reasonably well to both their corresponding test sets <em>and</em> the Original
test set (each model gets around 40-50% accuracy: a random classifier would get
11%). Thus, image backgroundsInterestingly, the No-FG model doesn't do
significantly better than the others, despite having access to the shape of the
foregrounds in the training set. <em>do</em> contain signal that
models can use to classify images.</p>

<p><img alt="The results of training models on background-only datasets and testing on the original." src="https://gradientscience.org/images/background/bg_only_train.png" style="width: 70%;"/></p>

<h3 id="2-do-models-actually-use-background-signals">2. Do models actually use background signals?</h3>

<p>So, backgrounds are indeed a useable signal for deep learning classifiers.
That’s not necessarily bad, or even different to humans: if you see an
occluded picture with an underwater background, you’d (hopefully) say that the
pictured object is more likely to be a fish than a dog.
On the other hand, humans are still able to call a dog a dog when it’s
underwater, i.e., a misleading/irrelevant background usually does not preclude us from
making the correct predictions. Is the same true for models?</p>

<p>To answer this question, we study model accuracies on the Mixed-Rand dataset,
where image backgrounds are randomized and thus provide no information 
about the correct label. 
Specifically, we compare model performance on Mixed-Rand and Mixed-Same: the
latter maintains the foreground-background correlation (since the background is
from the correct class), while controlling for artifactsSee
Appendix D of our paper for more details! from image
splicing process.</p>

<p>We denote the accuracy gap between Mixed-Same and Mixed-Rand as the BG-Gap,
i.e., the drop in model accuracy due to changing the class signal from the
background. The table below summarizes our observations: the BG-Gap is
13-22% and 6-14% for models trained on IN-9 and ImageNet, respectively,
suggesting that backgrounds often mislead state-of-the-art models even
when the correct foreground is present. (As we discuss in Appendix B of <a href="https://arxiv.org/abs/2006.09994">our
paper</a>, ImageNet-trained models do seem to be
more robust in this sense, but the reason for this robustness is hard to pin down.)</p>

<p><img alt="Evaluating pretrained models on Imagenet, Mixed-Rand, and Mixed-Same to compute the BG-Gap." src="https://gradientscience.org/images/background/table.png" style="width: 100%;"/></p>

<h3 id="3-ok-but-how-bad-can-it-get">3. Ok, but how bad can it get?</h3>

<p>The BG-Gap introduced in the previous experiment measures, in some sense,
models’ average robustness to misleading backgrounds. What does the worst case
look like? To diagnose just how large of an issue background over-reliance
can be, we search for the worst extracted background corresponding for each
extracted foreground. It turns out that a ResNet-50 model can be fooled on
87.5% of foregrounds by overlaying them on a corresponding “adversarial background.”</p>

<p>In fact, there also turn out to exist backgrounds that consistently affect the
prediction of the classifier <em>regardless</em> of what foreground is overlaid onto
them. The backgrounds below (extracted from insect images) fool our model into
predicting “insect” on up to 52\% of non-insect foregrounds:
<img alt="Adversarial Backgrounds" src="https://gradientscience.org/images/background/insect_result.png" style="width: 100%;"/></p>
<div class="footnote">
        The 5 most fooling backgrounds from the insect class, as well as the percent of non-insect foregrounds that they individually fool.
</div>

<p>Further, we can make the classifier predict “insect” on over 2/3 of the
foregrounds in the ImageNet-9 dataset, just by combining the foregrounds with
different insect backgrounds.</p>

<h3 id="4-what-is-the-effect-of-the-training-dataset">4. What is the effect of the training dataset?</h3>

<p>So far, all of the models that we’ve looked at have been trained on natural
data, i.e., either on the Original dataset from IN9, or on ImageNet itself.
We now want to test whether the previously-observed dependence on backgrounds
can be reduced (or removed altogether) by appropriately altering the training data.</p>

<p>To this end, we train models on Mixed-Rand, where background signals have been
decorrelated from class labels. 
We find these models perform only slightly better than
random on datasets with no foregrounds (e.g., a ResNet-50 trained on Mixed-Rand
achieves 15% accuracy on Only-BG-T and Only-BG-B).
They also perform better in the presence of misleading backgrounds:
training on Mixed-Rand improves accuracy on Mixed-Rand by 17%, and improves
accuracy on Mixed-NextRecall that Mixed-Next
images have foregrounds from class $y$ mixed with backgrounds from class $y+1$,
labeled as class $y$. by 22%. The model trained on
Mixed-Rand also has very little variation in accuracy across all five test sets
that contain the correct foreground (providing more evidence for its invariance
to other factors).</p>

<p><img alt="Training on Mixed-Rand and evaluating on other datasets" src="https://gradientscience.org/images/background/mixed_rand_results.png" style="width: 100%;"/></p>

<p>Qualitatively, the Mixed-Rand model also appears to place more relative
importance on foreground pixels than its original counterpart, as demonstrated
by the saliency maps below:</p>

<p><img alt="Saliency maps for models trained on original versus on Mixed-Rand" src="https://gradientscience.org/images/background/saliency_other.png" style="width: 100%;"/></p>

<h3 id="5-are-we-really-making-progress">5. Are we really making progress?</h3>

<p>We’ve now shown that models can exploit backgrounds, do exploit backgrounds, and
may actually do so to a fault. Considering that the development of these models
is driven by standard computer vision benchmarks, our results beg the question: to
what extent have improvements on ImageNet come with (or resulted from)
improvements in leveraging background correlations? And relatedly, how has
model robustness
to misleading background signals evolved over time?</p>

<p>As a first step towards answering these questions, we study the progress made by
ImageNet models on our proposed synthetic datasets. Below, we plot accuracy on
these datasets against ImageNet accuracy for a variety of different
network architectures:</p>

<p><img alt="ImageNet accuracy plotted against accuracy on synthetic datasets" src="https://gradientscience.org/images/background/in_vs_bg.png" style="width: 100%;"/></p>

<p>The plot indicates that accuracy increases on ImageNet generally correspond to
accuracy increases on all of the synthetic datasets that we consider. 
This includes the datasets that only contain background signals (Only-BG-T
in the graph above), which means that models <em>do</em> improve at extracting correlations
from image backgrounds. The fact that better models are also better at
classifying background-only images suggests that the use of background
signals might be inherent to the current training paradigm, and may
not disappearThough again, this might not be a bad
thing! on its own (i.e., without explicit regularization
or training).</p>

<p>Still, models’ <em>relative</em> improvement in accuracy across dataset variants is
promising—accuracy on background-only datasets is improving slower than
accuracy on datasets where the background is misleading, such as Mixed-Rand or
Mixed-Next. Another promising sign is that the
performance gap between the Mixed-Rand and Mixed-Same dataset (which we
previously referred to as the BG-Gap) trends towards closing, indicating that
models are not only better at using foreground features, but also more
robust to misleading background features.</p>

<p>Overall, our analysis reveals that better models in terms of ImageNet accuracy
are (a) increasingly capable of exploiting background correlations, but at the
same time (b) becoming more robust to changes in background, suggesting that
over-reliance on background features may not be necessary to maximize the
benchmark accuracy.</p>

<h3 id="conclusions">Conclusions</h3>

<p>In this post, we saw how computer vision models tend to over-rely on image
backgrounds in image classification. On one hand, our findings provide more
evidence that our models are not fully aligned with the human vision system. On the
other hand, we have shown that advances in computer vision models, such as new
architectures and training methods, have led to models that tend to use the
foreground more effectively and are more robust to misleading backgrounds.
We hope that the datasets and findings in this work provide a way to monitor
progress towards reliable, human-aligned machine learning.</p>

<p>For more detailed information about the <a href="https://github.com/MadryLab/backgrounds_challenge">datasets</a> we created, full
experimental results, and additional analysis, see <a href="https://gradientscience.org/background.pdf">our paper</a>!</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <published>2020-06-18T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2020-06-21T23:50:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-6952358197668395658</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/6952358197668395658/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=6952358197668395658" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/algorithms-with-predictions-survey-and.html" rel="alternate" type="text/html"/>
    <title>Algorithms with Predictions:  Survey and Workshop</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There's a whole new, interesting theory trend  -- Algorithms with Predictions.  The idea, spurred by advances in machine learning, is that you assume you have predictor that tells you something about your input.  For example, in caching, you might have a prediction of when the item you are currently accessing will be next accessed.  Of course, machine learning predictions aren't perfect.  Still, you'd like to use this prediction to improve your caching algorithm, but from the theory side, we'd like provable statements.  For example, you could say, if my prediction is THIS good (e.g., the error is bounded under some metric), then my caching performance will correspondingly be at least THIS good (e.g., performance bounded in some way).<br/><br/>If you haven't seen the burgeoning spread of this line of work and are interested, you're in luck.  First, Sergei Vassilvitskii and I have written a <a href="https://arxiv.org/abs/2006.09123">brief survey that's now on the arxiv</a>.  We had written it for a collection Tim Roughgarden is organizing on Beyond Worst-Case Analysis (that we thought we be out by now, and should be out from the publisher soon-ish), but we've gone ahead and put a version on the arxiv to make it available.  The area is moving fast, so there are already many new results --  we hope to update the "survey" with new material as the area grows.<br/><br/>Second, one of the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">STOC'20 Workshops will be on Algorithms with Predictions</a>.  It will be on Friday from 1-4pm, with speakers Tim Roughgarden, Edith Cohen,  Ravi Kumar, and me.  I'll be talking about some of my recent work  (in submission) on queues with predictions, and partitioned learned Bloom filters.  (Arxiv papers are <a href="https://arxiv.org/abs/1902.00732">here</a>, <a href="https://arxiv.org/abs/1905.12155">here</a>, and <a href="https://arxiv.org/abs/2006.03176">here</a>, but maybe you want to see the talk first.)  I'll also do a blog post on partitioned learned Bloom filters in the near future.</div>
    </content>
    <updated>2020-06-17T17:52:00Z</updated>
    <published>2020-06-17T17:52:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-19T03:55:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2271116647104476479</id>
    <link href="http://processalgebra.blogspot.com/feeds/2271116647104476479/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2271116647104476479" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/logic-mentoring-workshop-2020.html" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_k"><a href="https://www2.csc.liv.ac.uk/~lehtinen/">Karoliina Lehtinen</a> asked me to encourage young researchers of all ages to attend this year's edition of the Logic Mentoring Workshop. (See <a href="https://lmw.mpi-sws.org/">here</a> for information.) The <a href="https://lmw.mpi-sws.org/speakers.html">set of speakers</a> is top class, registration is  free and I am sure that attending the event would be beneficial  to  many. Spread the news!<br/><br/>FWIW, I gave a talk at the <a href="https://lics.siglog.org/lics17/lmw.html">2017 edition</a> of the event and thoroughly enjoyed it. Even though the event is targeted at students, from senior undergraduates to graduates, I feel that I always learn something new from attending this kind of workshops/talks. </div></div>
    </content>
    <updated>2020-06-17T16:10:00Z</updated>
    <published>2020-06-17T16:10:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-21T21:12:58Z</updated>
    </source>
  </entry>
</feed>
