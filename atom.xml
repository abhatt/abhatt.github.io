<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-08-22T19:21:56Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07880</id>
    <link href="http://arxiv.org/abs/1908.07880" rel="alternate" type="text/html"/>
    <title>Universal Reconfiguration of Facet-Connected Modular Robots by Pivots: The $O(1)$ Musketeers</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akitaya:Hugo_A=.html">Hugo A. Akitaya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arkin:Esther_M=.html">Esther M. Arkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Damian:Mirela.html">Mirela Damian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, Vida Dujmović, Robin Flatland, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Palop:Bel=eacute=n.html">Belén Palop</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renssen:Andr=eacute=_van.html">André van Renssen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sacrist=aacute=n:Vera.html">Vera Sacristán</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07880">PDF</a><br/><b>Abstract: </b>We present the first universal reconfiguration algorithm for transforming a
modular robot between any two facet-connected square-grid configurations using
pivot moves. More precisely, we show that five extra "helper" modules
("musketeers") suffice to reconfigure the remaining $n$ modules between any two
given configurations. Our algorithm uses $O(n^2)$ pivot moves, which is
worst-case optimal. Previous reconfiguration algorithms either require less
restrictive "sliding" moves, do not preserve facet-connectivity, or for the
setting we consider, could only handle a small subset of configurations defined
by a local forbidden pattern. Configurations with the forbidden pattern do have
disconnected reconfiguration graphs (discrete configuration spaces), and indeed
we show that they can have an exponential number of connected components. But
forbidding the local pattern throughout the configuration is far from
necessary, as we show that just a constant number of added modules (placed to
be freely reconfigurable) suffice for universal reconfigurability. We also
classify three different models of natural pivot moves that preserve
facet-connectivity, and show separations between these models.
</p></div>
    </summary>
    <updated>2019-08-22T02:02:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07841</id>
    <link href="http://arxiv.org/abs/1908.07841" rel="alternate" type="text/html"/>
    <title>Ranking Viscous Finger Simulations to an Acquired Ground Truth with Topology-aware Matchings</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soler:Maxime.html">Maxime Soler</a>, Martin Petitfrere, Gilles Darche, Melanie Plainchault, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conche:Bruno.html">Bruno Conche</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierny:Julien.html">Julien Tierny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07841">PDF</a><br/><b>Abstract: </b>This application paper presents a novel framework based on topological data
analysis for the automatic evaluation and ranking of viscous finger simulation
runs in an ensemble with respect to a reference acquisition. Individual fingers
in a given time-step are associated with critical point pairs in the distance
field to the injection point, forming persistence diagrams. Different metrics,
based on optimal transport, for comparing time-varying persistence diagrams in
this specific applicative case are introduced. We evaluate the relevance of the
rankings obtained with these metrics, both qualitatively thanks to a
lightweight web visual interface, and quantitatively by studying the deviation
from a reference ranking suggested by experts. Extensive experiments show the
quantitative superiority of our approach compared to traditional alternatives.
Our web interface allows experts to conveniently explore the produced rankings.
We show a complete viscous fingering case study demonstrating the utility of
our approach in the context of porous media fluid flow, where our framework can
be used to automatically discard physically-irrelevant simulation runs from the
ensemble and rank the most plausible ones. We document an in-situ
implementation to lighten I/O and performance constraints arising in the
context of parametric studies.
</p></div>
    </summary>
    <updated>2019-08-22T02:22:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07792</id>
    <link href="http://arxiv.org/abs/1908.07792" rel="alternate" type="text/html"/>
    <title>A Quality Metric for Visualization of Clusters in Graphs</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meidiana:Amyra.html">Amyra Meidiana</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Seok=Hee.html">Seok-Hee Hong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eades:Peter.html">Peter Eades</a>, Daniel Keim <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07792">PDF</a><br/><b>Abstract: </b>Traditionally, graph quality metrics focus on readability, but recent studies
show the need for metrics which are more specific to the discovery of patterns
in graphs. Cluster analysis is a popular task within graph analysis, yet there
is no metric yet explicitly quantifying how well a drawing of a graph
represents its cluster structure. We define a clustering quality metric
measuring how well a node-link drawing of a graph represents the clusters
contained in the graph. Experiments with deforming graph drawings verify that
our metric effectively captures variations in the visual cluster quality of
graph drawings. We then use our metric to examine how well different graph
drawing algorithms visualize cluster structures in various graphs; the results
con-firm that some algorithms which have been specifically designed to show
cluster structures perform better than other algorithms.
</p></div>
    </summary>
    <updated>2019-08-22T01:20:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07668</id>
    <link href="http://arxiv.org/abs/1908.07668" rel="alternate" type="text/html"/>
    <title>Existence and hardness of conveyor belts</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Molly Baird, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Billey:Sara_C=.html">Sara C. Billey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Martin_L=.html">Martin L. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, Sándor Fekete, Graham Gordon, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Griffin:Sean.html">Sean Griffin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Joseph_S=_B=.html">Joseph S. B. Mitchell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swanson:Joshua_P=.html">Joshua P. Swanson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07668">PDF</a><br/><b>Abstract: </b>An open problem of Manuel Abellanas asks whether every set of disjoint closed
unit disks in the plane can be connected by a conveyor belt, which means a
tight simple closed curve that touches the boundary of each disk, possibly
multiple times. We prove three main results. First, for unit disks whose
centers are both $x$-monotone and $y$-monotone, or whose centers have
$x$-coordinates that differ by at least two units, a conveyor belt always
exists and can be found efficiently. Second, it is NP-complete to determine
whether disks of varying radii have a conveyor belt, and it remains NP-complete
when we constrain the belt to touch disks exactly once. Third, any disjoint set
of $n$ disks of arbitrary radii can be augmented by $O(n)$ "guide" disks so
that the augmented system has a conveyor belt touching each disk exactly once,
answering a conjecture of Demaine, Demaine, and Palop.
</p></div>
    </summary>
    <updated>2019-08-22T01:23:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07647</id>
    <link href="http://arxiv.org/abs/1908.07647" rel="alternate" type="text/html"/>
    <title>Line and Plane Cover Numbers Revisited</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Therese Biedl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Felsner:Stefan.html">Stefan Felsner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meijer:Henk.html">Henk Meijer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07647">PDF</a><br/><b>Abstract: </b>A measure for the visual complexity of a straight-line crossing-free drawing
of a graph is the minimum number of lines needed to cover all vertices. For a
given graph $G$, the minimum such number (over all drawings in dimension $d \in
\{2,3\}$) is called the \emph{$d$-dimensional weak line cover number} and
denoted by $\pi^1_d(G)$. In 3D, the minimum number of \emph{planes} needed to
cover all vertices of~$G$ is denoted by $\pi^2_3(G)$. When edges are also
required to be covered, the corresponding numbers $\rho^1_d(G)$ and
$\rho^2_3(G)$ are called the \emph{(strong) line cover number} and the
\emph{(strong) plane cover number}.
</p>
<p>Computing any of these cover numbers -- except $\pi^1_2(G)$ -- is known to be
NP-hard. The complexity of computing $\pi^1_2(G)$ was posed as an open problem
by Chaplick et al. [WADS 2017]. We show that it is NP-hard to decide, for a
given planar graph~$G$, whether $\pi^1_2(G)=2$. We further show that the
universal stacked triangulation of depth~$d$, $G_d$, has $\pi^1_2(G_d)=d+1$.
Concerning~3D, we show that any $n$-vertex graph~$G$ with $\rho^2_3(G)=2$ has
at most $5n-19$ edges, which is tight.
</p></div>
    </summary>
    <updated>2019-08-22T01:59:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07584</id>
    <link href="http://arxiv.org/abs/1908.07584" rel="alternate" type="text/html"/>
    <title>Optimization Bounds from the Branching Dual</title>
    <feedworld_mtime>1566432000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>J. G. Benade, J. N. Hooker <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07584">PDF</a><br/><b>Abstract: </b>We present a general method for obtaining strong bounds for discrete
optimization problems that is based on a concept of branching duality. It can
be applied when no useful integer programming model is available, and we
illustrate this with the minimum bandwidth problem. The method strengthens a
known bound for a given problem by formulating a dual problem whose feasible
solutions are partial branching trees. It solves the dual problem with a
"worst-bound" local search heuristic that explores neighboring partial trees.
After proving some optimality properties of the heuristic, we show that it
substantially improves known combinatorial bounds for the minimum bandwidth
problem with a modest amount of computation. It also obtains significantly
tighter bounds than depth-first and breadth-first branching, demonstrating that
the dual perspective can lead to better branching strategies when the object is
to find valid bounds.
</p></div>
    </summary>
    <updated>2019-08-22T01:23:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3404</id>
    <link href="https://agtb.wordpress.com/2019/08/21/papafest-schedule-announced/" rel="alternate" type="text/html"/>
    <title>PapaFest schedule announced</title>
    <summary>The schedule for PapaFest (celebrating Christos Papadimitriou) has been posted at http://papafest.cs.columbia.edu/ When/where: September 6-8, 2019, at Columbia University in Davis Auditorium. (Register at the URL above, for free.) Confirmed speakers: Sanjeev Arora, Michael Collins, Michael Jordan, Anna Karlin, Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The schedule for PapaFest (celebrating Christos Papadimitriou) has been posted at <a href="http://papafest.cs.columbia.edu/">http://papafest.cs.columbia.edu/</a></p>
<p>When/where: September 6-8, 2019, at Columbia University in Davis Auditorium. (Register at the URL above, for free.)</p>
<p>Confirmed speakers: Sanjeev Arora, Michael Collins, Michael Jordan, Anna Karlin, Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>There will also be two panels led by Richard Karp and Jitendra Malik, and a rock concert by Errors in Bars on Saturday night!</p></div>
    </content>
    <updated>2019-08-21T15:12:07Z</updated>
    <published>2019-08-21T15:12:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-08-22T19:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/21/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/21/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-31-2019/" rel="alternate" type="text/html"/>
    <title>Assistant professor (tenure-track) and professor positions in computer science at Institute of Science and Technology Austria (apply by October 31, 2019)</title>
    <summary>We invite applications in all areas of computer science for several open positions. Female researchers are strongly encouraged to apply. Website: https://ist.ac.at/en/jobs/faculty/ Email: professors@ist.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications in all areas of computer science for several open positions. Female researchers are strongly encouraged to apply.</p>
<p>Website: <a href="https://ist.ac.at/en/jobs/faculty/">https://ist.ac.at/en/jobs/faculty/</a><br/>
Email: <a href="mailto:professors@ist.ac.at" rel="noopener" target="_blank"> professors@ist.ac.at</a></p></div>
    </content>
    <updated>2019-08-21T11:55:31Z</updated>
    <published>2019-08-21T11:55:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-22T19:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17855</id>
    <link href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/" rel="alternate" type="text/html"/>
    <title>The Argument against Quantum Computers – a CERN Colloquium and a New Paper</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me announce my CERN colloquium this Thursday, August 22, 2019, 16:30-17:30 entitled “The argument against quantum computers.” If you are at CERN or the neighborhood, please please come to the lecture. (Tea and coffee will be served at 16:00. … <a href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me announce <a href="https://indico.cern.ch/event/839574/?fbclid=IwAR0JHF8kcQ_tQKJrbJcNYTu9lQvMjOEvcSk6Jsh_Tq4uH4EbjeaDz7qv30k">my CERN colloquium</a> this Thursday, August 22, 2019, 16:30-17:30 entitled “The argument against quantum computers.” If you are at CERN or the neighborhood, please please come to the lecture. (Tea and coffee will be served at 16:00. ) If you are further away, there is a <a href="https://webcast.web.cern.ch/event/i839574">live broadcast</a>.</p>
<p>A few weeks ago I uploaded to the arXive a new paper with the same title “<a href="https://arxiv.org/abs/1908.02499">The argument against quantum computers</a>“. The paper will appear in the volume: Quantum, Probability, Logic: Itamar Pitowsky’s Work and Influence, Springer, Nature (2019), edited by Meir Hemmo and Orly Shenker. A short abstract for the lecture and the paper is:</p>
<blockquote><p><em><strong><span style="color: #008080;">We give a computational complexity argument against the feasibility of quantum computers. We identify a very low complexity class of probability distributions described by noisy intermediate-scale quantum computers, and explain why it will allow neither good-quality quantum error-correction nor a demonstration of “quantum supremacy.”  Some general principles governing the behavior of noisy quantum systems are derived.</span></strong></em></p></blockquote>
<p>The new paper and lecture have the same title as my 2018 <a href="https://www.quantamagazine.org/gil-kalais-argument-against-quantum-computers-20180207/">interview</a> with Katia Moskvitch at Quanta Magazine (see also <a href="https://gilkalai.wordpress.com/2018/02/08/my-argument-against-quantum-computers-an-interview-with-katia-moskvitch-on-quanta-magazine/">this post</a>).  Note that Christopher Monroe has recently <a href="https://www.quantamagazine.org/gil-kalais-argument-against-quantum-computers-20180207/#comment-4559220424">contributed a very interesting comment</a> to the Quanta article. My paper is dedicated to the memory of Itamar Pitowsky, and for more on Itamar see the post <a href="https://gilkalai.wordpress.com/2010/02/15/itamar-pitowski-probability-in-physics-where-does-it-come-from/" rel="bookmark">Itamar Pitowsky: Probability in Physics, Where does it Come From?</a> See also this <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">previous post</a> for two other quantum events in Jerusalem: a seminar in the first semester and a winter school on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/sasb.png"><img alt="" class="alignnone size-full wp-image-17856" height="481" src="https://gilkalai.files.wordpress.com/2019/08/sasb.png?w=640&amp;h=481" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">A slide from a lecture by Scott Aaronson where he explains why soap bubble computers cannot solve the NP-complete Steiner-tree problem. Noisy intermediate scale quantum (NISQ) circuits are <em>computationally </em>much more primitive than Scott’s soap bubble computers and this will prevent them from achieving neither “quantum supremacy” nor good quality quantum error correcting codes.  </span></strong><span style="color: #ff0000;">(<a href="https://www.scottaaronson.com/blog/?p=4199">source</a> for the picture)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/entn.png"><img alt="" class="alignnone size-full wp-image-17860" height="360" src="https://gilkalai.files.wordpress.com/2019/08/entn.png?w=640&amp;h=360" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Low-entropy quantum states give probability distributions described by low degree polynomials, and very low-entropy quantum states give chaotic behavior. Higher entropy enables classical information. </span></strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/cern.png"><img alt="" class="alignnone size-full wp-image-17862" height="371" src="https://gilkalai.files.wordpress.com/2019/08/cern.png?w=640&amp;h=371" width="640"/></a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-08-21T01:26:28Z</updated>
    <published>2019-08-21T01:26:28Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Physics"/>
    <category term="Quantum"/>
    <category term="CERN"/>
    <category term="Quantum computers"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-22T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07452</id>
    <link href="http://arxiv.org/abs/1908.07452" rel="alternate" type="text/html"/>
    <title>Continuous Toolpath Planning in Additive Manufacturing</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Prashant.html">Prashant Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnamoorthy:Bala.html">Bala Krishnamoorthy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07452">PDF</a><br/><b>Abstract: </b>We develop a framework that creates a new polygonal mesh representation of
the 3D domain of a layer-by-layer 3D printing job on which we identify single,
continuous tool paths covering each connected piece of the domain in every
layer. We present a tool path algorithm that traverses each such continuous
tool path with no crossovers. The key construction at the heart of our
framework is a novel Euler transformation that we introduced recently in a
separate manuscript. Our Euler transformation converts a 2-dimensional cell
complex K into a new 2-complex K^ such that every vertex in the 1-skeleton G^
of K^ has degree 4. Hence G^ is Eulerian, and an Eulerian tour can be followed
to print all edges in a continuous fashion without stops. We start with a mesh
K of the union of polygons obtained by projecting all layers to the plane.
First we compute its Euler transformation K^. In the slicing step, we clip K^
at each layer i using its polygon to obtain K^_i. We then patch K^_i by adding
edges such that any odd-degree nodes created by slicing are transformed to have
even degrees again. We print extra support edges in place of any segments left
out to ensure there are no edges without support in the next layer above. These
support edges maintain the Euler nature of K^_i. Finally, we describe a
tree-based search algorithm that builds the continuous tool path by traversing
"concentric" cycles in the Euler complex. Our algorithm produces a tool path
that avoids material collisions and crossovers, and can be printed in a
continuous fashion irrespective of complex geometry or topology of the domain
(e.g., holes).
</p></div>
    </summary>
    <updated>2019-08-21T23:27:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07447</id>
    <link href="http://arxiv.org/abs/1908.07447" rel="alternate" type="text/html"/>
    <title>Finding Hamiltonian and Longest (s, t)-paths of C-shaped Supergrid Graphs in Linear Time</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hung:Ruo=Wei.html">Ruo-Wei Hung</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keshavarz=Kohjerdi:Fatemeh.html">Fatemeh Keshavarz-Kohjerdi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07447">PDF</a><br/><b>Abstract: </b>A supergrid graph is a finite vertex-induced subgraph of the infinite graph
whose vertex set consists of all points of the plane with integer coordinates
and in which two vertices are adjacent if the difference of their x or y
coordinates is not larger than 1. The Hamiltonian path (cycle) problem is to
determine whether a graph contains a simple path (cycle) in which each vertex
of the graph appears exactly once. This problem is NP-complete for general
graphs and it is also NP-complete for general supergrid graphs. Despite the
many applications of the problem, it is still open for many classes, including
solid supergrid graphs and supergrid graphs with some holes. A graph is called
Hamiltonian connected if it contains a Hamiltonian path between any two
distinct vertices. In this paper, first we will study the Hamiltonian cycle
property of C-shaped supergrid graphs, which are a special case of rectangular
supergrid graphs with a rectangular hole. Next, we will show that C-shaped
supergrid graphs are Hamiltonian connected except few conditions. Finally, we
will compute a longest path between two distinct vertices in these graphs. The
Hamiltonian connectivity of C-shaped supergrid graphs can be applied to compute
the optimal stitching trace of computer embroidery machines, and construct the
minimum printing trace of 3D printers with a C-like component being printed.
</p></div>
    </summary>
    <updated>2019-08-21T23:22:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07363</id>
    <link href="http://arxiv.org/abs/1908.07363" rel="alternate" type="text/html"/>
    <title>Node Overlap Removal Algorithms: A Comparative Study</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Fati Chen, Laurent Piccinini, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Poncelet:Pascal.html">Pascal Poncelet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sallaberry:Arnaud.html">Arnaud Sallaberry</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07363">PDF</a><br/><b>Abstract: </b>Many algorithms have been designed to remove node overlapping, and many
quality criteria and associated metrics have been proposed to evaluate those
algorithms. Unfortunately, a complete comparison of the algorithms based on
some metrics that evaluate the quality has never been provided and it is thus
difficult for a visualization designer to select the algorithm that best suits
his needs. In this paper, we review 21 metrics available in the literature,
classify them according to the quality criteria they try to capture, and select
a representative one for each class. Based on the selected metrics, we compare
8 node overlap removal algorithms. Our experiment involves 854 synthetic and
real-world graphs.
</p></div>
    </summary>
    <updated>2019-08-21T23:32:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07342</id>
    <link href="http://arxiv.org/abs/1908.07342" rel="alternate" type="text/html"/>
    <title>New efficient flat-back 3D gadgets in origami extrusions compatible with the conventional pyramid-supported 3D gadgets</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doi:Mamoru.html">Mamoru Doi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07342">PDF</a><br/><b>Abstract: </b>An origami extrusion is a folding of a 3D object in the middle of a flat
piece of paper, using 3D gadgets which create faces with solid angles. Our main
concern is to make origami extrusions of polyhedrons using 3D gadgets with
simple outgoing pleats, where a simple pleat is a pair of a mountain fold and a
valley fold which are parallel to each other. In this paper we present a new
type of 3D gadgets with simple outgoing pleats in origami extrusions and their
construction. Our 3D gadgets are downward compatible with the conventional
pyramid-supported gadgets developed by Calros Natan as a generalization of the
cube gadget, in the sense that in most cases we can replace the conventional
gadgets with the new ones with the same outgoing pleats while the converse is
not always possible. We can also change angles of the outgoing pleats under
certain conditions. Unlike the conventional pyramid-supported 3D gadgets, the
new ones have flat back sides above the ambient paper, and thus we can make
flat-foldable origami extrusions. Furthermore, since our new 3D gadgets are
less interfering with adjacent gadgets than the conventional ones, we can use
wider pleats at one time to make the extrusion higher. For example, we prove
that the maximal height of the prism of any convex polygon (resp. any triangle)
that can be extruded with our new gadgets is more than 4/3 times (resp.
$\sqrt{2}$ times) of that with the conventional ones. We also present explicit
constructions of division/repetition and negative versions of the new 3D
gadgets.
</p></div>
    </summary>
    <updated>2019-08-21T23:34:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07318</id>
    <link href="http://arxiv.org/abs/1908.07318" rel="alternate" type="text/html"/>
    <title>An algorithm for destroying claws and diamonds</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07318">PDF</a><br/><b>Abstract: </b>In the {Claw,Diamond}-Free Edge Deletion problem the input is a graph $G$ and
an integer $k$, and the goal is to decide whether there is a set of edges of
size at most $k$ such that removing the edges of the set from $G$ results a
graph that does not contain an induced claw or diamond. In this paper we give
an algorithm for this problem whose running time is $O^*(3.562^k)$.
</p></div>
    </summary>
    <updated>2019-08-21T23:27:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07315</id>
    <link href="http://arxiv.org/abs/1908.07315" rel="alternate" type="text/html"/>
    <title>Evacuation of equilateral triangles by mobile agents of limited communication range</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Iman Bagheri, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Lata.html">Lata Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Opatrny:Jaroslav.html">Jaroslav Opatrny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07315">PDF</a><br/><b>Abstract: </b>We consider the problem of evacuating $k \geq 2$ mobile agents from a
unit-sided equilateral triangle through an exit located at an unknown location
on the perimeter of the triangle. The agents are initially located at the
centroid of the triangle and they can communicate with other agents at distance
at most $r$ with $0\leq r \leq 1$. An agent can move at speed at most one, and
finds the exit only when it reaches the point where the exit is located. The
agents can collaborate in the search for the exit. The goal of the {\em
evacuation problem} is to minimize the evacuation time, defined as the
worst-case time for {\em all} the agents to reach the exit. We propose and
analyze several algorithms for the problem of evacuation by $k \geq 2$ agents;
our results indicate that the best strategy to be used varies depending on the
values of $r$ and $k$. For two agents, we give three algorithms, each of which
achieves the best performance for different sub-ranges of $r$ in the range $0
\leq r \leq 1$. Finally, we show that for any $r$, evacuation of $k=6
+2\lceil(\frac{1}{r}-1)\rceil$ agents can be done in time $1+\sqrt{3}/3$, which
is optimal in terms of time, and asymptotically optimal in terms of the number
of agents.
</p></div>
    </summary>
    <updated>2019-08-21T23:25:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07282</id>
    <link href="http://arxiv.org/abs/1908.07282" rel="alternate" type="text/html"/>
    <title>Verification of Flat FIFO Systems</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Finkel:Alain.html">Alain Finkel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Praveen:M=.html">M. Praveen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07282">PDF</a><br/><b>Abstract: </b>The decidability and complexity of reachability problems and model-checking
for flat counter systems have been explored in detail. However, only few
results are known for flat FIFO systems, only in some particular cases (a
single loop or a single bounded expression). We prove, by establishing
reductions between properties, and by reducing SAT to a subset of these
properties that many verification problems like reachability, non-termination,
unboundedness are Np-complete for flat FIFO systems, generalizing similar
existing results for flat counter systems. We construct a trace-flattable
counter system that is bisimilar to a given flat FIFO system, which allows to
model-check the original flat FIFO system. Our results lay the theoretical
foundations and open the way to build a verification tool for (general) FIFO
systems based on analysis of flat subsystems. 2012 ACM Subject Classification
Theory of computation $\rightarrow$ Parallel computing models 1 Introduction
FIFO systems Asynchronous distributed processes communicating through First In
First Out (FIFO) channels are used since the seventies as models for protocols
[40], distributed and concurrent programming and more recently for web service
choreography interface [14]. Since FIFO systems simulate counter machines, most
reachability properties are undecidable for FIFO systems: for example, the
basic task of checking if the number of messages buffered in a channel can grow
unboundedly is undecidable [13]. There aren't many interesting and useful FIFO
subclasses with a decidable reachability problem. Considering FIFO systems with
a unique FIFO channel is not a useful restriction since they may simulate
Turing machines [13]. A few examples of decidable subclasses are half-duplex
systems [15] (but they are restricted to two machines since the natural
extension to three machines leads to undecidability), existentially bounded
deadlock free FIFO systems [31] (but it is undecidable to check if a system is
existentially bounded, even for deadlock free FIFO systems), synchronisable
FIFO systems (the property of synchronisability is undecidable [28] and
moreover, it is not clear which properties of synchronisable systems are
decidable), flat FIFO systems [8, 9] and lossy FIFO systems [2] (but one loses
the perfect FIFO mechanism).
</p></div>
    </summary>
    <updated>2019-08-21T23:21:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07239</id>
    <link href="http://arxiv.org/abs/1908.07239" rel="alternate" type="text/html"/>
    <title>Two-variable logic revisited</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yanger Ma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Tony.html">Tony Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07239">PDF</a><br/><b>Abstract: </b>In this paper we present another proof for the well-known small model
property of two-variable logic. As far as we know, existing proofs of this
property rely heavily on model theoretic concepts. In contrast, ours is
combinatorial in nature and uses only a very simple counting argument, which we
find intuitive and elegant. We also consider matching lower bounds.
</p></div>
    </summary>
    <updated>2019-08-21T23:22:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07215</id>
    <link href="http://arxiv.org/abs/1908.07215" rel="alternate" type="text/html"/>
    <title>Decoding Downset codes over a finite grid</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srinivasan:Srikanth.html">Srikanth Srinivasan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tripathi:Utkarsh.html">Utkarsh Tripathi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkitesh:S=.html">S. Venkitesh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07215">PDF</a><br/><b>Abstract: </b>In a recent paper, Kim and Kopparty (Theory of Computing, 2017) gave a
deterministic algorithm for the unique decoding problem for polynomials of
bounded total degree over a general grid. We show that their algorithm can be
adapted to solve the unique decoding problem for the general family of Downset
codes. Here, a downset code is specified by a family D of monomials closed
under taking factors: the corresponding code is the space of evaluations of all
polynomials that can be written as linear combinations of monomials from D.
</p></div>
    </summary>
    <updated>2019-08-21T23:21:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07154</id>
    <link href="http://arxiv.org/abs/1908.07154" rel="alternate" type="text/html"/>
    <title>Discrete and Fast Fourier Transform Made Clear</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zeman:Peter.html">Peter Zeman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07154">PDF</a><br/><b>Abstract: </b>Fast Fourier transform was included in the Top 10 Algorithms of 20th Century
by Computing in Science &amp; Engineering. In this paper, we provide a new simple
derivation of both the discrete Fourier transform and fast Fourier transform by
means of elementary linear algebra. We start the exposition by introducing the
convolution product of vectors, represented by a circulant matrix, and derive
the discrete Fourier transform as the change of basis matrix that diagonalizes
the circulant matrix. We also generalize our approach to derive the Fourier
transform on any finite abelian group, where the case of Fourier transform on
the Boolean cube is especially important for many applications in theoretical
computer science.
</p></div>
    </summary>
    <updated>2019-08-21T23:27:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07153</id>
    <link href="http://arxiv.org/abs/1908.07153" rel="alternate" type="text/html"/>
    <title>Studying Wythoff and Zometool Constructions using Maple</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Benoit Charbonneau, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Whitehead:Spencer.html">Spencer Whitehead</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07153">PDF</a><br/><b>Abstract: </b>We describe a Maple package that serves at least four purposes. First, one
can use it to compute whether or not a given polyhedral structure is Zometool
constructible. Second, one can use it to manipulate Zometool objects, for
example to determine how to best build a given structure. Third, the package
allows for an easy computation of the polytopes obtained by the kaleiodoscopic
construction called the Wythoff construction. This feature provides a source of
multiple examples. Fourth, the package allows the projection on Coxeter planes
</p></div>
    </summary>
    <updated>2019-08-21T23:27:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07152</id>
    <link href="http://arxiv.org/abs/1908.07152" rel="alternate" type="text/html"/>
    <title>Unfolding Polyhedra</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Joseph O'Rourke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07152">PDF</a><br/><b>Abstract: </b>Starting with the unsolved "D\"urer's problem" of edge-unfolding a convex
polyhedron to a net, we specialize and generalize (a) the types of cuts
permitted, and (b) the polyhedra shapes, to highlight both advances established
and which problems remain open.
</p></div>
    </summary>
    <updated>2019-08-21T23:27:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07097</id>
    <link href="http://arxiv.org/abs/1908.07097" rel="alternate" type="text/html"/>
    <title>An Omega(n^2) Lower Bound for Random Universal Sets for Planar Graphs</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexander Choi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chrobak:Marek.html">Marek Chrobak</a>, Kevin Costello <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07097">PDF</a><br/><b>Abstract: </b>A set $U\subseteq \reals^2$ is $n$-universal if all $n$-vertex planar graphs
have a planar straight-line embedding into $U$. We prove that if $Q \subseteq
\reals^2$ consists of points chosen randomly and uniformly from the unit square
then $Q$ must have cardinality $\Omega(n^2)$ in order to be $n$-universal with
high probability. This shows that the probabilistic method, at least in its
basic form, cannot be used to establish an $o(n^2)$ upper bound on universal
sets.
</p></div>
    </summary>
    <updated>2019-08-21T23:30:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.07076</id>
    <link href="http://arxiv.org/abs/1908.07076" rel="alternate" type="text/html"/>
    <title>Improved Job sequencing Bounds from Decision Diagrams</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>J. N. Hooker <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.07076">PDF</a><br/><b>Abstract: </b>We introduce a general method for relaxing decision diagrams that allows one
to bound job sequencing problems by solving a Lagrangian dual problem on a
relaxed diagram. We also provide guidelines for identifying problems for which
this approach can result in useful bounds. These same guidelines can be applied
to bounding deterministic dynamic programming problems in general, since
decision diagrams rely on DP formulations. Computational tests show that
\mbox{Lagrangian} relaxation on a decision diagram can yield very tight bounds
for certain classes of hard job sequencing problems. For example, it proves for
the first time that the best known solutions for Biskup-Feldman instances are
within a small fraction of 1% of the optimal value, and sometimes optimal.
</p></div>
    </summary>
    <updated>2019-08-21T23:23:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.06964</id>
    <link href="http://arxiv.org/abs/1908.06964" rel="alternate" type="text/html"/>
    <title>PPT: New Low Complexity Deterministic Primality Tests Leveraging Explicit and Implicit Non-Residues. A Set of Three Companion Manuscripts</title>
    <feedworld_mtime>1566345600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phatak:Dhananjay.html">Dhananjay Phatak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherman:Alan_T=.html">Alan T. Sherman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Houston:Steven_D=.html">Steven D. Houston</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henry:Andrew.html">Andrew Henry</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.06964">PDF</a><br/><b>Abstract: </b>In this set of three companion manuscripts/articles, we unveil our new
results on primality testing and reveal new primality testing algorithms
enabled by those results. The results have been classified (and referred to) as
lemmas/corollaries/claims whenever we have complete analytic proof(s);
otherwise the results are introduced as conjectures.
</p>
<p>In Part/Article 1, we start with the Baseline Primality Conjecture~(PBPC)
which enables deterministic primality detection with a low complexity = O((log
N)^2) ; when an explicit value of a Quadratic Non Residue (QNR) modulo-N is
available (which happens to be the case for an overwhelming majority = 11/12 =
91.67% of all odd integers). We then demonstrate Primality Lemma PL-1, which
reveals close connections between the state-of-the-art Miller-Rabin method and
the renowned Euler-Criterion. This Lemma, together with the Baseline Primality
Conjecture enables a synergistic fusion of Miller-Rabin iterations and our
method(s), resulting in hybrid algorithms that are substantially better than
their components. Next, we illustrate how the requirement of an explicit value
of a QNR can be circumvented by using relations of the form: Polynomial(x) mod
N = 0 ; whose solutions implicitly specify Non Residues modulo-N. We then
develop a method to derive low-degree canonical polynomials that together
guarantee implicit Non Residues modulo-N ; which along with the Generalized
Primality Conjectures enable algorithms that achieve a worst case deterministic
polynomial complexity = O( (log N)^3 polylog(log N)) ; unconditionally ; for
any/all values of N.
</p>
<p>In Part/Article 2 , we present substantial experimental data that corroborate
all the conjectures. No counter example has been found.
</p>
<p>Finally in Part/Article 3, we present analytic proof(s) of the Baseline
Primality Conjecture that we have been able to complete for some special cases.
</p></div>
    </summary>
    <updated>2019-08-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16180</id>
    <link href="https://rjlipton.wordpress.com/2019/08/20/our-trip-to-monte-carlo/" rel="alternate" type="text/html"/>
    <title>Our Trip To Monte Carlo</title>
    <summary>Why does randomness help? Kathryn Farley is my dear wife. She and I are currently on a cruise through the Mediterranean. Our trip started in Barcelona and is stopping daily at various cities as we journey to Rome. “Tough duty,” but we are trying to enjoy it. Today I wish to talk about our visit […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Why does randomness help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/08/kathrynmontecarlo2.png"><img alt="" class="alignright wp-image-16183" height="180" src="https://rjlipton.files.wordpress.com/2019/08/kathrynmontecarlo2.png?w=141&amp;h=180" width="141"/></a></p>
<p>
Kathryn Farley is my dear wife. She and I are currently on a cruise through the Mediterranean. Our trip started in Barcelona and is stopping daily at various cities as we journey to Rome. “Tough duty,” but we are trying to enjoy it. </p>
<p>
Today I wish to talk about our visit to Monte Carlo. </p>
<p>
Our ship, the <a href="https://en.wikipedia.org/wiki/MV_Seabourn_Encore">Encore</a>, just docked there Sunday. The day was warm and clear, and we spent some time exploring the city. We did manage to avoid losing any money at the famous casino. Our secret was simple: do not play, do not gamble, do not lose.</p>
<p>
Over lunch I started to explain to Kathryn why Monte Carlo is an important city for complexity theorists. I felt a bit like we were at a theory shrine.</p>
<p>
</p><p/><h2> Why Randomness Helps </h2><p/>
<p/><p>
Indeed. I realized that it is not so simple to explain why randomness helps. Kathryn has a Ph.D in theatre. She is smart, is a member of Mensa, but is not a complexity theorist. How do I explain that randomness is powerful? Indeed.</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2019/08/randkinmontecarlo2.png"><img alt="" class="aligncenter size-medium wp-image-16186" height="251" src="https://rjlipton.files.wordpress.com/2019/08/randkinmontecarlo2.png?w=300&amp;h=251" width="300"/></a></p>
<p/><p><br/>
I started to explain, but my examples were lame. I think she got the main idea, but I also think that I did not do a great job. Russell Impagliazzo has a nice <a href="https://simons.berkeley.edu/sites/default/files/docs/6119/doesrandomnesshelp.pdf">explanation</a> on the role of randomness—I wish Russell had been there to help explain randomness to Kathryn. </p>
<p>
After lunch I started to think more about the role of randomness. I looked at our friends over at Wikipedia and discovered they had a pretty good <a href="https://en.wikipedia.org/wiki/Applications_of_randomness">page</a>. Some reasons are:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Games</i></p>
<p>
Randomness was first investigated in the context of gambling. Dice, playing cards, roulette wheels, all have been studied by those interested in gambling. Clearly, betting on the roll of dice, deal of cards, or spin of the wheel, only makes sense when these actions are unpredictable. Random. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Political</i></p>
<p>
Randomness is often used to create “fairness”. For example, in the US and UK, juror selection is done by a lottery. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Science</i></p>
<p>
Monte Carlo methods in physics and computer science require random numbers.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Cryptography</i></p>
<p>
Random keys for encryption algorithms should be unpredictable. Random. Otherwise, they can be guessed by others. The password “password” is usually not allowed.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Arts</i></p>
<p>
Kathryn is interested in the arts: in plays and in painting and other fine arts. Some theories of art claim that all art is random. One thinks of artists like Jackson Pollock with his famous drip paintings. He was a major player in the abstract expressionist movement.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/08/jpollock.png"><img alt="" class="aligncenter size-full wp-image-16188" src="https://rjlipton.files.wordpress.com/2019/08/jpollock.png?w=600"/></a></p>
<p/><h2> Pseudo or True? </h2><p/>
<p/><p>
Ken has been paying intensive devotions at the same shrine. As he wrote in the previous <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">post</a>, he has been conducting millions of randomized tests of his new chess model. </p>
<p>
Why random? What he needs to do is show that his model will not tend to “cry wolf” by giving a too-high <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-score to a set of games in a tournament by an honest player. He wants to show that his model is equally tempered no matter the rating of the player. So he runs trials at different rating levels ranging from Elo 1000 for novice players to Elo 2800 which is championship level. To show that the <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-scores given by his model conform to a normal bell curve, he needs to do 10,000s or 100,000s of tests at each level. </p>
<p>
The problem is there just don’t exist enough games. Most large tournaments give only the games played on their “top boards” which use special auto-recording equipment, and the losers on those boards in one round may play on lower boards in the next round. Thus out of about 60,000 player-tournament pairs Ken can track each year, most are only partial samples. So what Ken does is generate “synthetic players” by randomly taking subsets of (say) 9 games—from his data set of 1,000 or so games for each level—and randomly choosing white or black for each game. This is a common <a href="https://en.wikipedia.org/wiki/Resampling_(statistics)#Subsampling">resampling</a> technique, and it uses Monte Carlo.</p>
<p>
Ken uses pseudo-random generators (PRGs). He starts a C++ library PRG on a seed <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> based on the current time. The fact that the choices are deterministic once <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> is given might allow him to reproduce an entire run exactly (after a model tweak) by preserving the <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> it used. This is a paradox: we might want our “random” bits to be deterministic. Monte Carlo with predestined loaded dice.</p>
<p>
From time to time on this blog we have mused about what a world <a href="https://rjlipton.wordpress.com/2013/08/23/a-world-without-randomness/">without</a> randomness or with <a href="https://rjlipton.wordpress.com/2018/04/01/the-entropy-of-baseball/">reduced</a> entropy would be like. We were struck a few weeks ago when the noted physics blogger Sabine Hossenfelder wrote about “<a href="http://backreaction.blogspot.com/2019/07/the-forgotten-solution-superdeterminism.html">superdeterminism</a>.” That post provoked a few hundred comments in her blog, as did her <a href="http://backreaction.blogspot.com/2019/08/the-problem-with-quantum-measurements.html">post</a> last week on the quantum measurement problem—including long exchanges with Peter Shor. Ken and I don’t know which side to take, but I can say that the side of a ship is a great place to think about possible real effects of these differences.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What is your take on randomness? Do you employ it? How “true” do you need it to be? </p>
<p/></font></font></div>
    </content>
    <updated>2019-08-20T16:24:54Z</updated>
    <published>2019-08-20T16:24:54Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="art"/>
    <category term="cruise"/>
    <category term="Kathryn Farley"/>
    <category term="Monte Carlo"/>
    <category term="Peter Shor"/>
    <category term="Physics"/>
    <category term="quantum"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <category term="Sabine Hossenfelder"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-22T19:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/20/algorithms-postdoc-at-university-of-california-berkeley-apply-by-october-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/20/algorithms-postdoc-at-university-of-california-berkeley-apply-by-october-1-2019/" rel="alternate" type="text/html"/>
    <title>Algorithms Postdoc at University of California Berkeley (apply by October 1, 2019)</title>
    <summary>Multiple Postdoctoral positions available to work on Fine-grained Complexity, Approximation Algorithms and Additive Combinatorics. Please email directly to Barna with resume and contact information of three references. The start date is flexible. Website: https://barnasaha.net/ Email: barnas@berkeley.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple Postdoctoral positions available to work on Fine-grained Complexity, Approximation Algorithms and Additive Combinatorics. Please email directly to Barna with resume and contact information of three references. The start date is flexible.</p>
<p>Website: <a href="https://barnasaha.net/">https://barnasaha.net/</a><br/>
Email: barnas@berkeley.edu</p></div>
    </content>
    <updated>2019-08-20T04:00:50Z</updated>
    <published>2019-08-20T04:00:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-22T19:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17848</id>
    <link href="https://gilkalai.wordpress.com/2019/08/19/equiangular-lines-with-a-fixed-angle-and-other-breakthroughs-from-yufei-zhaos-blog/" rel="alternate" type="text/html"/>
    <title>Equiangular lines with a fixed angle and other breakthroughs from Yufei Zhao’s blog</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today I would like to report about some breakthroughs in the area of combinatorics, and about blog posts in Yufei Zhao’s blog that describe these remarkable results (better than I can). Many of the coauthors in these breakthroughs are undergraduate … <a href="https://gilkalai.wordpress.com/2019/08/19/equiangular-lines-with-a-fixed-angle-and-other-breakthroughs-from-yufei-zhaos-blog/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today I would like to report about some breakthroughs in the area of combinatorics, and about blog posts in <a href="https://yufeizhao.wordpress.com/">Yufei Zhao’s blog</a> that describe these remarkable results (better than I can). <span style="color: #993366;"><strong>Many of the coauthors in these breakthroughs are undergraduate students</strong>.</span></p>
<h2><a href="https://arxiv.org/abs/1907.12466">Equiangular lines with a fixed angle</a></h2>
<h3>by Zilin Jiang, Jonathan Tidor, Yuan Yao, Shengtong Zhang and Yufei Zhao.</h3>
<p><a href="https://arxiv.org/abs/1907.12466">Paper </a>; <a href="https://yufeizhao.wordpress.com/2019/07/29/equiangular-lines-with-a-fixed-angle/">blog post</a> (end of July, 2019)</p>
<p>A collection of equiangular lines is a collection of lines so that the angles between every pair of lines in the same?</p>
<p>Here are two classical questions:</p>
<ol>
<li>What is the maximum number of equiangular lines in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>?</li>
<li>Given an angle <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> what is the maximum number of equiangular lines in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>? so that the angle between every two lines is <img alt="\alpha?" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%3F&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha?"/></li>
</ol>
<p>In 2000 Dom de Caen found for the first time an equiangular set of lines in <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> space of size <img alt="cd^2" class="latex" src="https://s0.wp.com/latex.php?latex=cd%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="cd^2"/>. (The crucial observation that one of the graphs in the Cameron–Seidel association scheme has a certain eigenvalue of large multiplicity.  Prior to this construction, the largest sets had sizes of order <img alt="d^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d^{3/2}"/>.  In de Caen’s example the lines have angles approaching 90 degrees, and question 2 for a fixed value of <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> led to very different bounds. (For another result by Dom, see <a href="https://gilkalai.wordpress.com/2011/06/15/the-combinatorics-of-cocycles-and-borsuks-problem/">this post</a>.)</p>
<p>There were some important progress on this problem by Igor Balla, Felix Dräxler, Peter Keevash, and Benny Sudakov, as featured in this  <a href="https://www.quantamagazine.org/a-new-path-to-equal-angle-lines-20170411/">Quanta Magazine article</a> written by Kevin Hartnett. Zilin, Jonathan, Yuan, Shengtong, and Yufei  finished off the problem in a clean and crisp manner, in a 10-page paper with a self-contained proof. On the way they proved the following very interesting theorem.</p>
<p><strong>Theorem:</strong> A bounded degree graph must have sublinear second eigenvalue multiplicity.</p>
<h2><a href="https://arxiv.org/abs/1906.10482">Impartial digraphs</a></h2>
<h3>by Yufei Zhao and Yunkun Zhou.</h3>
<p><a href="https://arxiv.org/abs/1906.10482">Paper</a>, <a href="https://yufeizhao.wordpress.com/2019/06/27/impartial-digraphs/">blog post</a> (end of June 2019)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/yzb.png"><img alt="" class="alignnone size-full wp-image-17875" height="386" src="https://gilkalai.files.wordpress.com/2019/08/yzb.png?w=640&amp;h=386" width="640"/></a></p>
<p><strong>Abstract</strong>: We prove a conjecture of Fox, Huang, and Lee that characterizes directed graphs <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that have constant density in all tournaments: they are disjoint unions of trees that are each constructed in a certain recursive way.</p>
<p>“Constant density in all tournaments” means that for some <img alt="n_0" class="latex" src="https://s0.wp.com/latex.php?latex=n_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_0"/> (and hence for all <img alt="n \ge n_0" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cge+n_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \ge n_0"/>, every tournament with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices has the same number of copies of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>. (On the nose!)</p>
<p>This result is related to the famous Sidorenko’s conjecture. Let me copy its description from the paper:</p>
<p>For undirected graphs, conjectures of Sidorenko and Erdős–Simonovits (commonly referred to as Sidorenko’s conjecture) say that for every bipartite graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, the <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>-density in a graph of fixed density is minimized asymptotically by a random graph. Lately the conjecture has been proved for many families of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> though the conjecture remains open in general. In particular, the case <img alt="H = K_{5,5}\backslash C_{10}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+K_%7B5%2C5%7D%5Cbackslash+C_%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = K_{5,5}\backslash C_{10}"/> is open.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/yz.jpg"><img alt="" class="alignnone size-full wp-image-17879" height="427" src="https://gilkalai.files.wordpress.com/2019/08/yz.jpg?w=640&amp;h=427" width="640"/></a></h2>
<p><span style="color: #ff0000;"><strong>Yufei Zhao</strong></span></p>
<h2>More</h2>
<p>Let me describe briefly three additional posts on Yufei’s blog with two results from 2018 and one result from 2014.</p>
<h3>Ashwin Sah, Mehtaab Sawhney, David Stoner, and Yufei Zhao  <a href="https://arxiv.org/abs/1809.09462">A reverse Sidorenko inequality</a>; (<a href="https://yufeizhao.wordpress.com/2018/09/25/a-reverse-sidorenko-inequality/">blog post</a>) ; <a href="https://arxiv.org/abs/1805.04021">The number of independent sets in an irregular graph</a>; <a href="https://yufeizhao.wordpress.com/2018/05/12/the-number-of-independent-sets-in-an-irregular-graph/">blog post</a>.</h3>
<p>These are two remarkable papers by the same team of researchers. The paper  on the number of independent sets in a regular graph settled a famous 2001 conjecture by Jeff Kahn. An earlier breakthrough on the problem was made by Zhao in 2009 when he was an undergraduate student.</p>
<h3><a href="http://research.microsoft.com/en-us/um/people/eyal/">Eyal Lubetzky</a> and Yufei Zhao,  <em><a href="http://arxiv.org/abs/1402.6011">On the variational problem for upper tails of triangle counts in sparse random graphs</a></em>. <a href="https://yufeizhao.wordpress.com/2014/02/25/upper-tail/">Blog post</a>.</h3>
<p>Recently  I wrote a post <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="bookmark">Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</a> describing a major breakthrough on the infamous upper tail problem. Over the years I heard a lot of lectures and private explanation on upper tails and the remarkable related mathematics. I remember lectures by Kim and Vu from the early 2000’s and by Varadhan from ICM 2010 describing (among other things) the fundamental paper by  <a href="http://www.ams.org/mathscinet-getitem?mr=2825532">Chatterjee and Varadhan</a>,  and later works by  <a href="http://www.ams.org/mathscinet-getitem?mr=2925307">DeMarco and Kahn, </a> and by  <a href="http://arxiv.org/abs/1401.3495">Chatterjee and Dembo</a>  and Lubetzky and Zhao and others. But when I wrote the post I realized my knowledge is too sparse for giving a thorough description, and I decided not to wait and write a short post. This post by Yufei describes some of the history very nicely as well as the major papers by Eyal and Yufei from 2012 and 2014.</p></div>
    </content>
    <updated>2019-08-19T18:33:52Z</updated>
    <published>2019-08-19T18:33:52Z</published>
    <category term="Combinatorics"/>
    <category term="Ashwin Sah"/>
    <category term="David Stoner"/>
    <category term="Eyal Lubetzky"/>
    <category term="Jonathan Tidor"/>
    <category term="Mehtaab Sawhney"/>
    <category term="Shengtong Zhang"/>
    <category term="Yuan Yao"/>
    <category term="Yufei Zhao"/>
    <category term="Yunkun Zhou"/>
    <category term="Zilin Jiang"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-22T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/107</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/107" rel="alternate" type="text/html"/>
    <title>TR19-107 |  The Power of a Single Qubit: Two-way Quantum/Classical Finite Automata and the Word Problem for Linear Groups | 

	Zachary Remscrim</title>
    <summary>The two-way quantum/classical finite automaton (2QCFA), defined by Ambainis and Watrous, is a model of quantum computation whose quantum part is extremely limited; however, as they showed, 2QCFA are surprisingly powerful: a 2QCFA, with a single qubit, can recognize, with one-sided bounded-error, the language $L_{eq}=\{a^m b^m |m \in \mathbb{N}\}$ in expected polynomial time and the language $L_{pal}=\{w \in \{a,b\}^*|w \text{ is a palindrome}\}$ in expected exponential time.  

We further demonstrate the power of 2QCFA by showing that they can recognize the word problems of a broad class of groups. In particular, we first restrict our attention to 2QCFA that: $(1)$ have a single qubit, $(2)$ recognize their language with one-sided bounded-error, and $(3)$ have transition amplitudes which are algebraic numbers. We show that such 2QCFA can recognize the word problem of any finitely-generated virtually abelian group in expected polynomial time, as well as the word problem of a large class of linear groups in expected exponential time. This latter class includes all groups whose word problem is a context-free language as well as all groups whose word problem is known to be the intersection of finitely many context-free languages. As a corollary, we obtain a direct improvement on the original Ambainis and Watrous result by showing that $L_{eq}$ can be recognized by a 2QCFA with better parameters. 

We also consider those word problems which a 2QCFA can recognize with one-sided unbounded-error, and show that this class includes the word problem of more exotic groups such as the free product of any finite collection of finitely-generated free abelian groups. As a corollary of this result, we demonstrate that a new class of group word problems are co-stochastic languages. Lastly, we exhibit analogous results for 2QCFA with any finite number of qubits or with more general transition amplitudes, as well as results for other classic QFA models.</summary>
    <updated>2019-08-18T13:27:03Z</updated>
    <published>2019-08-18T13:27:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/106</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/106" rel="alternate" type="text/html"/>
    <title>TR19-106 |  Semialgebraic Proofs and Efficient Algorithm Design | 

	Noah Fleming, 

	Pravesh Kothari, 

	Toniann Pitassi</title>
    <summary>Over the last twenty years, an exciting interplay has emerged between proof systems and algorithms. Some natural families of algorithms can be viewed as a generic translation from a proof that a solution exists into an algorithm for finding the solution itself. This connection has perhaps been the most consequential in the context of semi-algebraic proof systems and basic primitives in algorithm design such as linear and semidefinite programming. The proof system perspective, in this context, has provided fundamentally new tools for both algorithm design and analysis. These news tools have helped in both designing better algorithms for well-studied problems and proving tight lower bounds on such techniques.

This monograph is aimed at expositing this interplay between proof systems and efficient algorithm design and surveying the state-of-the-art for two of the most important semi-algebraic proof systems: Sherali-Adams and Sum-of-Squares.

We rigorously develop and survey the state-of-the-art for Sherali-Adams and Sum-of-Squares both as proof systems, as well as a general family of optimization algorithms, stressing that  these perspectives are formal duals to one-another. Our treatment relies on interpreting the outputs of the Sum-of-Squares and Sherali-Adams algorithms as generalized expectation functions -- a viewpoint that has been essential in obtaining both algorithmic results and lower bounds. The emphasis is on illustrating the main ideas by presenting a small fraction of representative results with detailed intuition and commentary. The monograph is self-contained and includes a review of the necessary mathematical background including basic theory of linear and semi-definite programming.</summary>
    <updated>2019-08-18T06:14:17Z</updated>
    <published>2019-08-18T06:14:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5432</id>
    <link href="https://adamsheffer.wordpress.com/2019/08/18/abstraction-is-hard/" rel="alternate" type="text/html"/>
    <title>Abstraction is Hard</title>
    <summary>A few weeks ago I read Malcolm Gladwell’s book The Tipping Point. The book doesn’t really deal with mathematics, but it does contain one math-related anecdote. This anecdote demonstrates an interesting principle of learning mathematics, so I wanted to share it. Problem 1. We have a deck of cards, such that each card contains a […]</summary>
    <updated>2019-08-18T02:03:50Z</updated>
    <published>2019-08-18T02:03:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-08-22T19:21:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/17/footprints-in-snow</id>
    <link href="https://11011110.github.io/blog/2019/08/17/footprints-in-snow.html" rel="alternate" type="text/html"/>
    <title>Footprints in the snow</title>
    <summary>Given an abstract optimization problem with multiple solutions, how much partial information about a solution do you have to know in order to uniquely identify that solution? That has been the topic of some of my earlier research, on how many creases of an origami folding pattern you have to force to be mountain or valley folds in order to cause the remaining folds to go the way you want. And it’s the topic of my new preprint “Tracking paths in planar graphs” (arXiv:1908.05445, with Mike Goodrich, James Liu, and Pedro Matias).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Given an abstract optimization problem with multiple solutions, how much partial information about a solution do you have to know in order to uniquely identify that solution? That has been the topic of some of my earlier research, on <a href="https://11011110.github.io/blog/2014/10/08/forced-creases-in.html">how many creases of an origami folding pattern you have to force to be mountain or valley folds in order to cause the remaining folds to go the way you want</a>. And it’s the topic of my new preprint “Tracking paths in planar graphs” (<a href="https://arxiv.org/abs/1908.05445">arXiv:1908.05445</a>, with Mike Goodrich, James Liu, and Pedro Matias).</p>

<p>There’s an old story about how to design the footpaths on a college campus: wait for it to snow, see where the heaviest sets of footprints cross the snow from building to building, and then once the snow melts place paths in those same places. But what if you live somewhere like Irvine where it never snows? Or what if you want to perform some other type of data analysis on a data set of the paths that people take? For instance, in order to design improvements to the road networks used by commuter traffic, it would be helpful to figure out where all the traffic actually goes each day. How can you collect that data?</p>

<p>Our paper takes the point of view that you can attach sensors to the network that record the times and identities of people passing by them, but that these sensors are expensive. The goal is (for a given network with designated start and destination vertices  and ) to place as few of these sensors as possible at graph vertices, in such a way that every simple -path is uniquely identified by the sequence of sensors that it passes through.</p>

<p>The problem turns out to be -complete, even on planar networks. But there’s a simple approximation ratio based on the idea that the optimal number of sensors is always going to be proportional to the number of faces in the network. Each face (in the sequence of biconnected components between  and ) has to have at least one sensor, to distinguish paths that go one way around the face from paths that go the other way around. It turns out that placing one sensor at a vertex shared by many faces doesn’t work — those faces still need a proportional number of additional sensors. And our approximation algorithm ensures that the number of sensors is at most proportional to the number of faces.</p>

<p>We also use <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a> to prove that the exact solution is fixed-parameter tractable in the clique-width of the graph. Like most or all uses of Courcelle’s theorem, the resulting algorithm is impractical, so it would be of interest to find a more direct algorithm, perhaps for a weaker parameter.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102634545213040458">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-17T14:42:00Z</updated>
    <published>2019-08-17T14:42:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-17T21:55:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/105</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/105" rel="alternate" type="text/html"/>
    <title>TR19-105 |  A note on the relation between XOR and Selective XOR Lemmas | 

	Ragesh Jaiswal</title>
    <summary>Given an unpredictable Boolean function $f: \{0, 1\}^n \rightarrow \{0, 1\}$, the standard Yao's XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in [k]}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$, whereas the Selective XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in S}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$ and $S \subseteq \{1, ..., k\}$. We give a reduction from the Selective XOR lemma to the standard XOR lemma. Our reduction gives better quantitative bounds for certain choice of parameters and does not require the assumption of being able to sample $(x, f(x))$ pairs.</summary>
    <updated>2019-08-16T08:16:51Z</updated>
    <published>2019-08-16T08:16:51Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16160</id>
    <link href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/" rel="alternate" type="text/html"/>
    <title>Predicting Chess and Horses</title>
    <summary>Using predictivity both to sharpen and cross-check models Cropped from article source Patrice Miller and Jeff Seder look under the hide of horses. Their company EQB does predictive modeling for horse racing based on biometric data. They are famous for having advised the owner of American Pharoah not to sell because the horse had a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Using predictivity both to sharpen and cross-check models</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/patti-miller-and-jeff-seder-of-eqb-agents-consulting-2/" rel="attachment wp-att-16163"><img alt="" class="aligncenter wp-image-16163" height="204" src="https://rjlipton.files.wordpress.com/2019/08/patti-miller-and-jeff-seder-of-eqb-agents-consulting-1.jpg?w=212&amp;h=204" width="212"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from article <a href="https://www.inverse.com/article/31250-jeff-seder-kentucky-derby-horse-genetics-big-data">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Patrice Miller and Jeff Seder look under the hide of horses. Their company <a href="https://www.eqb.com/">EQB</a> does predictive modeling for horse racing based on biometric data. They are famous for having <a href="https://www.nytimes.com/2015/06/05/sports/american-pharoah-cant-erase-all-of-ahmed-zayats-missteps.html">advised</a> the owner of American Pharoah not to sell because the horse had a powerful heart. In 2015, American Pharoah became the first Triple Crown winner since the also-hearty Secretariat in 1978.</p>
<p>
Today I am happy to announce an extended version of my predictive model for chess and discuss how it gains accuracy by looking under the hood of chess positions.<br/>
<span id="more-16160"/></p>
<p>
I had thought to credit Charles Babbage and Ada Lovelace for being the first to envision computational predictive modeling, but the evidence connected to her design of betting schemes for horse racing is scant and <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/babbage/bio.htm">secondhand</a> <a href="https://blog.stephenwolfram.com/2015/12/untangling-the-tale-of-ada-lovelace/">accounts</a> <a href="https://books.google.com/books?id=RUDdYIL5TG0C&amp;pg=PR21&amp;lpg=PR21&amp;dq=charles+babbage+horse+races&amp;source=bl&amp;ots=VxqMznLIj0&amp;sig=ACfU3U0d6jICkDy2sSZ0MVlPyLQT_rGj6g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj5iNLB_ITkAhUB2VkKHYMyAoA4ChDoATAEegQICRAB#v=onepage&amp;q=charles babbage horse races&amp;f=false">differ</a>. It is known that Babbage compiled voluminous data on the medical fitness and diet of animals, including heart function by taking their pulse. We have discussed their computing work <a href="https://rjlipton.wordpress.com/2010/03/23/its-ada-lovelace-day/">here</a> and <a href="https://rjlipton.wordpress.com/2015/02/17/ada-the-amplifier/">here</a>. </p>
<p>
I will use horse racing as a device for explaining the main new ingredient of my model. It sharpens the prediction of moves—and the results of cheating tests—by using deeper information to “beat the bookie” as Lovelace tried to do. I have described the basic form of my model—and previous efforts to extend it—in <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">previous</a> <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">posts</a> <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">on</a> <a href="https://rjlipton.wordpress.com/2012/03/30/when-is-a-law-natural/">this</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">blog</a>. Last month, besides being involved in <a href="https://www.spiegel.de/sport/sonst/schach-wie-der-weltverband-betrueger-erwischt-a-1277439.html">several</a> <a href="https://www.foxnews.com/world/chess-grandmaster-caught-using-phone-inside-bathroom-during-a-tournament">media</a> <a href="https://www.chess.com/news/view/igors-rausis-58-under-investigation-of-cheating">stories</a> involving a grandmaster caught in the act of cheating in France, I was invited to discuss this work by Ben Johnson for his “Perpetual Chess” <a href="https://www.perpetualchesspod.com/new-blog/2019/7/23/episode-136-im-kenneth-regan">podcast</a>.</p>
<p>
</p><p/><h2> Betting the Favorite </h2><p/>
<p/><p>
My chess model does the same thing to a chess position—given information about the skill set of the player deciding on a move—that a bookie does to a horse race. It sets odds on each legal move <img alt="{m_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_i}"/> to “win” by being played in the game. The probabilities <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> need to be accurate for the same reason bookmakers need their “initial betting lines” to be close to how bets will ultimately balance, so they can preserve their <a href="https://en.wikipedia.org/wiki/Vigorish">margin</a>. A horse with highest <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/>—perhaps a tie—is the bookie’s <em>favorite</em>. The favorite might be “odds-on,” meaning <img alt="{p_i \gg 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i \gg 0.5}"/>, or might be a “narrow favorite” among several horses with near-equal chances.</p>
<p>
Suppose you don’t care how much money you might win but just want to maximize your chance of being right—of winning something. Unless you have reason to doubt the bookie, you should bet on the favorite. That is what my basic chess model does. Whichever move is given the highest value by the computer at the end of its search is declared the favorite, regardless of the player’s <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a> or other skill factors. </p>
<p>
That the best move—we’ll label it <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/>—should <em>always</em> be most likely even for the weakest players runs counter to sense. Aren’t weaker players weaker because they prefer weaker moves? When the right move is obvious, say a forced recapture or a checkmate in one, of course we expect any player to find it. But when <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/> is subtle, what then? </p>
<p/><p><br/>
My basic model still makes it the favorite. This doesn’t mean its probability <img alt="{p_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1}"/> is greater than half. My model might make <img alt="{p_1 \gg 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1 \gg 0.5}"/> for world champion level players but only, say, <img alt="{p_1 = 0.25}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1+%3D+0.25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1 = 0.25}"/> for beginning players. Thus it will still say the beginner is 75% likely to play an inferior move. What my base model shies away from is saying any other particular move—any other horse—is more likely to win than <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/>. As the rating gets lower it bunches up the probabilities so that while <img alt="{p_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1}"/> is lower, no other probability passes it.</p>
<p>
This is borne out in practice. The lowest Elo rating used by the World Chess Federation (FIDE) is 1000. Let’s take ratings between that and 1200 (which used to be the lowest rating) as denoting the novice class. Consider only those positions that have many reasonable choices—say at least ten moves valued within 0.25 (figuratively, a quarter of a pawn) of optimal. My main training set has 6.082 such positions in games between evenly-matched players of this level. Here are the frequencies of their playing the best through the tenth-best move in such <em>many-choice positions</em>:</p>
<p align="center">
</p><table align="center">
<tbody><tr>
<td align="right"> Rank </td>
<td align="right"> Pct.</td>
<td/>
<td/>
</tr>
<tr>
<td align="right"> 1 </td>
<td align="right"> 17.76%</td>
</tr>
<tr>
<td align="right"> 2 </td>
<td align="right"> 13.22%</td>
</tr>
<tr>
<td align="right"> 3 </td>
<td align="right"> 9.95%</td>
</tr>
<tr>
<td align="right"> 4 </td>
<td align="right"> 7.66%</td>
</tr>
<tr>
<td align="right"> 5 </td>
<td align="right"> 6.25%</td>
</tr>
<tr>
<td align="right"> 6 </td>
<td align="right"> 5.18%</td>
</tr>
<tr>
<td align="right"> 7 </td>
<td align="right"> 4.41%</td>
</tr>
<tr>
<td align="right"> 8 </td>
<td align="right"> 4.55%</td>
</tr>
<tr>
<td align="right"> 9 </td>
<td align="right"> 3.50%</td>
</tr>
<tr>
<td align="right"> 10 </td>
<td align="right"> 3.03%</td>
</tr>
<tr>
<td align="right"> 11+ </td>
<td align="right"> 24.49%</td>
</tr>
<tr>
<td align="right"> </td>
</tr>
</tbody></table>
<p>
Both my basic model and the new one, when fitted over the entire training set for this class but then restricted to the many-choices subset, give projections close to these actual values. The basic model, always betting the favorite, is right on under 18% of its projections. Can we do better? That is, can we “beat the bookie” at chess? </p>
<p>
</p><p/><h2> Predicting Inferior Moves </h2><p/>
<p/><p>
It is almost four years since the idea for improving predictions was <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">described</a> on this blog. In place of “weaker players prefer weaker moves,” it advanced a hypothesis that we can state as follows:</p>
<blockquote><p><b> </b> <em> Weaker players are more likely to be diverted by shiny objects. </em>
</p></blockquote>
<p/><p>
Most in particular, they will fall for moves that look attractive early on, but which are revealed (by the computer) to be inferior after deeper consideration. The computer programs output values for each depth of search, and when these moves’ values are graphed against the depth, they start high but “swing down” at higher depths. Weaker players are more likely to be satisfied by the early flash and not think deeper. The old <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">post</a> has a great example of such a move from the pivotal game in the 2008 world championship match, where Viswanathan Anand set a deep trap that caught the previous world champion, Vladimir Kramnik. </p>
<p>
The flip side are moves that look poor at low depths but whose high value emerges at high depths. My basic model, which uses only the final values of moves, gives too high a projection on these cases, and too low a likelihood of falling into traps. I have figured that these two kinds of ‘misses’ offset over a few dozen positions. Moreover, in both kinds of misses, the player is given express benefit of doubt by the projections. It is edgier, after all, to project that a player is more likely to fall into a trap than to find the safest and best move.</p>
<p>
The effect of lower-depth values is still too powerful to ignore in identifiable cases. Including them, however, makes the whole model edgier, as I have <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">described</a> here <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">before</a>. Simply put, the lower-depth values are subject to more noise, from which we are trying to extract greater information. It has been like trying to catch lightning—or <a href="https://www.pppl.gov/news/2019/08/improving-magnetic-bottle-controls-fusion-power-earth">fusion</a>—in a bottle.</p>
<p>
</p><p/><h2> Modest But Effective Success </h2><p/>
<p/><p>
My new model implements the “swing” feature without adding any more free parameters for fitting. It has new parameters but those are set “by hand” after an initial fitting of the free parameters under the “sliding-scale” regime I <a href="https://rjlipton.wordpress.com/2018/09/07/sliding-scale-problems/">described</a> last September, which is followed by a second round of re-fitting. It required heavy clamps on the weighting of lower-depth values and more-intense conditioning of inputs overall. It required a solution to the “firewall at zero” <a href="https://rjlipton.wordpress.com/2016/01/21/a-chess-firewall-at-zero/">phenomenon</a> that was the exact opposite of what I’d envisioned.</p>
<p>
After all this, here is what it delivers in the above case—and quite generally:</p>
<blockquote><p><b> </b> <em> It improves the prediction success rate—for the weakest players in the most difficult kind of positions to forecast—from 17.76% to <b>20.04%</b>. </em>
</p></blockquote>
<p/><p>
For the elite class—2600 to 2800—in the same kind of many-choice positions, the new model does even better. Much more data on elite players is available, so I have 49,793 such positions faced by them: </p>
<blockquote><p><b> </b> <em> Whereas elite players found the best move in 30.85% of these difficult positions, my new model finds <b>their</b> move in <b>34.64%</b> of them. </em>
</p></blockquote>
<p/><p>
Over all positions, the average <em>prediction gain</em> ranges from about 1 percentage point for the lowest players to over 2% for masters. These gains may not sound like much, but for cheating tests they give prime value. The reasons are twofold:</p>
<ul>
<li>
The gained predictions are all <em>against</em> their finding the computer’s move, so the act of finding the best move is more exposed. <p/>
</li><li>
The standard deviation is typically 3–5 percentage points depending on the volume of moves. Thus the prediction gain can enhance the measured <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> by upwards of 0.5 or more.
</li></ul>
<p>
Initial applications in recent cases seem to prove this out more often than not. Of course, the larger purpose is to have a better model of human chess play overall.</p>
<p>
</p><p/><h2> Cross-Checks and Caveats </h2><p/>
<p/><p>
In recent years, several new dimensions of quality and safety with predictive models have emerged. They supplement the two classic ones:</p>
<ul>
<li>
<em>Avoiding false positives.</em> In particular, over a natural population (such as the mass of honest players), the rate of outlier scores generated by the model must stay within the bounds of natural frequency for the population. Call this “natural safety.” <p/>
</li><li>
<em>Avoiding false negatives</em>. The model should provide enough <a href="https://en.wikipedia.org/wiki/Power_(statistics)">statistical power</a> to flag unnatural outliers without becoming unsafe.
</li></ul>
<p>
I vetted my model’s natural safety by processing tens of millions of generated z-scores under resampling after my final design tweaks earlier this month. This was over a link between departmental machines and UB’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>) where my data is generated. The previous discussion has all been about greater power. The first new factor updates the idea of <a href="https://en.wikipedia.org/wiki/Calibration_(statistics)#In_prediction_and_forecasting">calibration</a>:</p>
<ul>
<li>
<em>Non-bias and fairness.</em> More general than the societal context, which we discussed <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">here</a>, this means avoiding bias along functional lines that the model is not intended to distinguish.
</li></ul>
<p>
I have a suite of cross-checking measures besides those tests that are expressly fitted to be unbiased estimators. They include checking how my model performs on various different types of positions, such as those with many choices as above, or the opposite: those having one standout move. For example, the model’s best-move projection in the many-choice positions by elite players, using the general settings for 2700 rating, is 31.07%. That’s within 0.28%. Another check is figuratively how much “probability money” my model wagered to get its 34.64% hit rate. The sum of <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> it projected on its own most-likely moves, in the 68.4% of the many-choice positions where it agreed with the computer’s favorite plus 31.6% where it did not, was 35.00%. If I fit all 282,060 positions by these players, rather than use “2700,” and then re-select the subset, the model comes within <b>0.01%</b> on the first-move projection and <b>0.11%</b> on its own betting forecasts. I will say more about the cross-checks, use of <a href="https://en.wikipedia.org/wiki/Brier_score">prediction</a>–<a href="https://en.wikipedia.org/wiki/Score_(statistics)">scoring</a> <a href="https://en.wikipedia.org/wiki/Scoring_rule">metrics</a>, and conformance to normal distribution at a later time. The relevant point is to ask:</p>
<blockquote><p><b> </b> <em> How well does your model perform on pertinent tests besides those it was expressly trained for? </em>
</p></blockquote>
<p/><p>
Beyond fairness, good <em>wide-range</em> calibration alleviates dangers of “mission creep.” </p>
<p>
The second newer factor is:</p>
<ul>
<li>
<em><a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adversarial</a> performance.</em> This is apart from “natural safety.” Simply put: how resistant is the model to being deceived? Can it be gamed?
</li></ul>
<p>
My impressions over the long haul of this work is that the new model’s more-powerful heart inevitably brings greater “springiness.” By dint of its being more sensitive to moves whose high value emerges only after deep search, it is possible to create shorter sequences of such moves that make it jump to conclusions. The z-score vetting turned up a few games that were agreed drawn after some “book” moves—openings known by heart to many professional players—whose entirety the model would flag, except for the standard procedure of identifying and removing book moves from cheating tests. These outliers came from over a hundred thousand games between evenly-matched players, so they still conformed to the natural rate, but one can be concerned about the “unnatural rate.” On the flip side, I believe my more-intensive conditioning of values has made the model more robust against being gamed by cheaters playing a few inferior moves to cover their tracks. </p>
<p>
In general, and especially with nonlinear models, the caveat is that amplifying statistical power brings greater susceptibility to adversarial conditions. Trying to “beat the bookie” requires more model introspection. My model retains its <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainability</a> and ability to provide audits for its determinations. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What lessons from similar situations with other predictive models can be identified and brought to bear on this one?</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-16T00:52:25Z</updated>
    <published>2019-08-16T00:52:25Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Ada Lovelace"/>
    <category term="algorithmic fairness"/>
    <category term="Charles Babbage"/>
    <category term="cheating"/>
    <category term="horse racing"/>
    <category term="Jeff Seder"/>
    <category term="model safety"/>
    <category term="Patrice Miller"/>
    <category term="predictive modeling"/>
    <category term="predictivity"/>
    <category term="statistical power"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-22T19:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/08/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Tricolor pyramids (). In this logic puzzle by @jsiehler, you have to 3-color hexagonal tiles avoiding 2-colored upright triangles. What interests me is not that, but the following: it’s the time-space diagram of a 3-state cellular automaton (with time flowing upward and each cell taking the color that makes the triangle below it work). But turned it’s still the time-space diagram of the same automaton! I haven’t seen this sort of CA symmetry before.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/pyramids-start.html">Tricolor pyramids</a> (<a href="https://mathstodon.xyz/@11011110/102546072670351246"/>). In this logic puzzle by @jsiehler, you have to 3-color hexagonal tiles avoiding 2-colored upright triangles. What interests me is not that, but the following: it’s the time-space diagram of a 3-state cellular automaton (with time flowing upward and each cell taking the color that makes the triangle below it work). But turned  it’s still the time-space diagram of the same automaton! I haven’t seen this sort of CA symmetry before.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/08/02/publicsphere-v-elsevier.html">Elsevier sends copyright threat to site for linking to Sci-Hub</a> (<a href="https://mathstodon.xyz/@11011110/102551592262978036"/>). Apparently if you tell people they can find free copies of paywalled journal papers on pirate web site sci-hub, and link directly to sci-hub to make it even easier to find free copies of paywalled journal papers, you get a nasty letter from the corporate leeches who made it necessary to set up a pirate web site for free copies of paywalled journal papers . But if you <a href="https://en.wikipedia.org/wiki/Sci-Hub">go to Wikipedia</a> you can find the link in the infobox. And it turns out that <a href="https://eve.gd/2019/08/03/elsevier-threatens-others-for-linking-to-sci-hub-but-does-it-itself/">Elsevier journals themselves contain plenty of links to sci-hub</a> (<a href="https://boingboing.net/2019/08/03/zero">via</a>). Sci-hub sci-hub sci-hub.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@Breakfastisready/102554576764536048">@Breakfastisready recommends the new graphic novel “Prime Suspects”</a>, by Andrew and Jennifer Granville with illustrations by Robert J. Lewis: “It’s all about analytic number theory in metaphors.”</p>
  </li>
  <li>
    <p><a href="https://mati.naukas.com/">Mati y sus mateaventuras</a> (<a href="https://mathstodon.xyz/@11011110/102559401183096120"/>), blog of popularized mathematics stories by mathematician Clara Grima and illustrator Raquel Gu (in Spanish). The latest one (from a year ago; it hasn’t updated much recently) is <a href="https://en.wikipedia.org/wiki/Wythoff%27s_game">on Wythoff’s game</a>.</p>
  </li>
  <li>
    <p><a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Manu suggests reducing our impact on the planet by making conferences virtual</a> (<a href="https://mathstodon.xyz/@11011110/102568139862446088"/>). Or we could, you know, publish our papers in journals instead of conferences, like everyone else, and not need to go to quite so many conferences.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html">Why modern integer factoring algorithms have the time bounds they do, and what would be needed to improve them</a> (<a href="https://mathstodon.xyz/@11011110/102577633871564197"/>).</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/08/08/california-scientists-pull-support-elsevier-journals">The University of California’s fight with Elsevier spills over to editorships</a> (<a href="https://mathstodon.xyz/@11011110/102584940498877427"/>). 30 UC editors of Elsevier journals “will no longer provide editorial services” to Elsevier unless/until a satisfactory deal with Elsevier is reached.</p>
  </li>
  <li>
    <p><a href="https://senate.universityofcalifornia.edu/_files/reports/rm-jn-racialization-academic-espionage-concerns.pdf">A letter from the University of California Academic Council</a> (<a href="https://mathstodon.xyz/@11011110/102601263075559877"/>) expressing their alarm at “the increasingly racialized ways in which international scholars and students—especially those from China, Iran, and Russia—are being targeted in national conversations about academic espionage” and their support for the open exchange of research.</p>
  </li>
  <li>
    <p><a href="https://blogs.scientificamerican.com/roots-of-unity/the-longest-matrilineal-chain-in-math/">The longest matrilineal chain in math</a> (<a href="https://mathstodon.xyz/@11011110/102604836636431847"/>). Evelyn Lamb finds “five advisor-advisee chains of length four containing only women” in the Mathematics Genealogy Project, all starting with Olga Ladyzhenskaya and her student Nina Ivochkina. But her searches were haphazard so there may be longer ones still to find.</p>
  </li>
  <li>
    <p><a href="https://mathenchant.wordpress.com/2018/08/16/knots-and-narnias/">Knots and Narnias</a> (<a href="https://mathstodon.xyz/@11011110/102613921012752632"/>). Riffing on a video of a Bill Thurston lecture, Jim Propp explains that when a portal to another dimension has a knotted boundary, it can actually be a portal to several other dimensions.</p>
  </li>
  <li>
    <p><a href="https://gi.de/meldung/konrad-zuse-medaille-dorothea-wagner-erhaelt-hoechste-informatik-auszeichnung/">Dorothea Wagner wins the 2019 Konrad Zuse Medal</a> (<a href="https://mathstodon.xyz/@11011110/102616186862477955"/>). This is the highest award of the German Computer Science Society, and the first time since its establishment in 1987 that the winner is a woman. Dorothea’s research includes graph drawing, route planning, optimization, and social network analysis; see <a href="https://en.wikipedia.org/wiki/Dorothea_Wagner">her Wikipedia article</a> for more.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/new-proof-settles-how-to-approximate-numbers-like-pi-20190814/">Duffin–Schaeffer conjecture solved</a> (<a href="https://mathstodon.xyz/@11011110/102623251151301461"/>, <a href="https://arxiv.org/abs/1907.04593">original paper</a>). This is about finding rational approximations to irrational numbers, like . Given a criterion for how good an approximation you want, depending only on the denominator (for instance, allowing only prime denominators and seeking an approximation accurate to  for denominator ) the new theorem tells you when almost all irrationals have a good-enough approximation.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-08-15T16:07:00Z</updated>
    <published>2019-08-15T16:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-17T21:55:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16151</id>
    <link href="https://rjlipton.wordpress.com/2019/08/11/leaps-and-bounds-practice-meets-theory/" rel="alternate" type="text/html"/>
    <title>Leaps and Bounds: Practice Meets Theory</title>
    <summary>Solving the runtime selection problem Composite from src1, src2 Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s workshop at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.” Today I will discuss their talks, which I enjoyed greatly at the workshop. The workshop’s general theme was the use of machine-learning techniques […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Solving the runtime selection problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png"><img alt="" class="alignright wp-image-16153" height="129" src="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png?w=180&amp;h=129" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite from <a href="https://www.microsoft.com/en-us/research/people/brlucier/">src1</a>, <a href="https://www.microsoft.com/en-us/research/video/sparse-stochastic-bandits/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s <a href="http://www.cs.cmu.edu/~ckingsf/AutoAlg2019/">workshop</a> at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.”</p>
<p>
Today I will discuss their talks, which I enjoyed greatly at the workshop.<br/>
<span id="more-16151"/></p>
<p>
The workshop’s general theme was the use of machine-learning techniques to improve the tuning of algorithms. Indeed, the goal is to have the algorithm tune itself by selecting strategies from a collection of possible ones. Besides better performance with less human work, this promises better logical reliability than with hand-tuning programs and debugging. </p>
<p>
A common component of this work used in both talks is an interesting oracle model. Since oracles are familiar to many of us theorists this will give us an avenue into the talks and the <a href="https://pdfs.semanticscholar.org/0dce/10ed863423e2e9b1b77a0becfc23111578be.pdf">two</a> recent <a href="https://arxiv.org/pdf/1807.00755.pdf">papers</a> they were based on.</p>
<p>
</p><p/><h2> Runtime Oracles </h2><p/>
<p/><p>
The oracle has a nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> of shape <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/>. Think of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> as the <i>runtime</i> of the <img alt="{i^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i^{th}}"/> program on the <img alt="{j^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j^{th}}"/> input. You know <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, but must ask the oracle for information about <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/>. You may ask the oracle a question <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/>:</p>
<blockquote><p><b> </b> <em> <i>Is the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> less than or equal to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>?</i> </em>
</p></blockquote>
<p/><p>
Here <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is a time bound. Further they assume that the oracle charges you 	</p>
<p align="center"><img alt="\displaystyle  \min(R(i,j),t). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin%28R%28i%2Cj%29%2Ct%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min(R(i,j),t). "/></p>
<p>Thus an algorithm is charged in total 	</p>
<p align="center"><img alt="\displaystyle  \sum_{t} \min(R(i,j),t), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%7D+%5Cmin%28R%28i%2Cj%29%2Ct%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{t} \min(R(i,j),t), "/></p>
<p>where the sum is over all questions <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/> you asked. 	 The rationale is that the oracle can run a program <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> on a task <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and stop after at most <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> steps. Thus returning the minimum is realistic. Since their research is motivated by practical problems, this is a useful model for studying questions about program performance. </p>
<p>
In passing I believe the reason this oracle model is new is that theorists do not often think about running arbitrary programs. Well those in recursion type did, but those designing classic algorithms do not. </p>
<p>
</p><p/><h2> A Selection Problem </h2><p/>
<p/><p>
This model to used to study a selection problem. Assume <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is as above. The task is to find the row with the smallest row sum <img alt="{s_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_{i}}"/>: </p>
<p align="center"><img alt="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%3D+%5Csum_%7Bj%3D1%7D%5E%7BM%7D+R%28i%2Cj%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). "/></p>
<p>That is to find the program that takes the least total time on the inputs—hence the least average time.</p>
<p>
The trouble is that in the worst case this can require examining all the entries. So they introduce approximations to make the problem doable, but still useful in practice:</p>
<ol>
<li>
The rows need only be a <img alt="{(1+\epsilon)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2B%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1+\epsilon)}"/> approximation to the smallest row. <p/>
</li><li>
The entries can be assumed to be truncated by a value <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tau}"/>. That is you can assume that 	<p/>
<p align="center"><img alt="\displaystyle  R(i,j) \le \tau. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28i%2Cj%29+%5Cle+%5Ctau.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  R(i,j) \le \tau. "/></p>
</li><li>
The governing algorithm can be randomized and need only meet the performance goal with high probability.
</li></ol>
<p>
Now we can state the problem formally. It is parameterized by <img alt="{(\epsilon, \tau)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C+%5Ctau%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon, \tau)}"/>:</p>
<blockquote><p><b> </b> <em> <b>Runtime Selection Problem (RSP)</b>: Given a matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R}"/> with all entries bounded by <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\tau}"/>, find a row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/> so that 	</em></p><em>
<p align="center"><img alt="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%5Cle+%281+%2B+%5Cepsilon%29s_%7Bk%7D%2C+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, "/></p>
</em><p><em>for all <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, while minimizing the oracle charges for all questions “is <img alt="{R(i,j) \leq t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cleq+t%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j) \leq t}"/>?” that are asked. </em>
</p></blockquote>
<p>The talks gave a variety of randomized algorithms that solve such problems for various parameter assumptions. </p>
<p>
</p><p/><h2> Fast and Slow </h2><p/>
<p/><p>
See their papers for details on the results. The algorithms they have are interesting not only from a theory viewpoint but also in practice. Indeed, they not only prove theorems but also give experimental timings.</p>
<p>
In order to establish some intuition, let’s look at the following simple case. Assume that all entries <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> are either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or some <img alt="{\alpha \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \gg 1}"/>. This is the “fast-or-slow” running time stipulation. As theorists we often are drawn to binary values, so this might be a good case to look at initially.</p>
<p>
The first observation is that we will always ask questions of the form 	</p>
<p align="center"><img alt="\displaystyle  (i, j, 1.0001). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28i%2C+j%2C+1.0001%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (i, j, 1.0001). "/></p>
<p>This gives us the value of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> for almost unit cost: if it is the <img alt="{R(i,j) \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j) \gg 1}"/> case then we are only charged <img alt="{1.0001}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1.0001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1.0001}"/>. Thus, we have reduced the original problem to a classic oracle problem. There is no complicated oracle cost measure: the cost is just the number of entries we read. Well okay the cost is slightly higher, but we can make it as close as we wish.</p>
<p>
The selection problem then comes down to this: </p>
<ul>
<li>
We have a <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/> nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> whose entries are all either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. <p/>
</li><li>
We must find a row sum that is within a factor of <img alt="{1+\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1+\epsilon}"/> of the smallest.
</li></ul>
<p>
I believe that the analysis of this problem should be generally known. In any event it seems clear that randomly sampling each row is a good start.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Are there other natural problems where the runtime cost oracle is useful?</p>
<p>[Edited typo]</p></font></font></div>
    </content>
    <updated>2019-08-12T02:34:46Z</updated>
    <published>2019-08-12T02:34:46Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="fast"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="Algorithms"/>
    <category term="Brendan Lucier"/>
    <category term="complexity"/>
    <category term="Csaba Szepesvari"/>
    <category term="machine learning"/>
    <category term="oracles"/>
    <category term="practice"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-22T19:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/104</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/104" rel="alternate" type="text/html"/>
    <title>TR19-104 |  Reconstruction of Depth-$4$ Multilinear Circuits | 

	Vishwas Bhargava, 

	Shubhangi Saraf, 

	Ilya Volkovich</title>
    <summary>We present a deterministic algorithm for reconstructing multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits, i.e. multilinear depth-$4$ circuits with fan-in $k$ at the top $+$ gate. For any fixed $k$, given black-box access to a polynomial $f \in \mathbb{F}[x_{1},x_{2},\ldots ,x_{n}]$ computable by a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size $s$, the algorithm runs in time quasi-poly($n,s,{|\mathbb{F}|}$) and outputs a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size quasi-poly($n,s$) that computes $f$. 

Our result solves an open problem posed in \cite{GKL12} (STOC, 2012). Indeed, prior to our work, efficient reconstruction algorithms for multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits were known only for the case of $k=2$ \cite{GKL12, Volkovich17}.</summary>
    <updated>2019-08-11T04:14:43Z</updated>
    <published>2019-08-11T04:14:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/103</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/103" rel="alternate" type="text/html"/>
    <title>TR19-103 |  Query-to-Communication Lifting Using Low-Discrepancy Gadgets | 

	Or Meir, 

	Sajin Koroth, 

	Arkadev Chattopadhyay, 

	Toniann Pitassi, 

	Yuval Filmus</title>
    <summary>Lifting theorems are theorems that relate the query complexity of a function $f:\left\{ 0,1 \right\}^n\to \left\{ 0,1 \right\}$ to the communication complexity of the composed function $f\circ g^n$, for some “gadget” $g:\left\{ 0,1 \right\}^b\times \left\{ 0,1 \right\}^b\to \left\{ 0,1 \right\}$. Such theorems allow transferring lower bounds from query complexity to the communication complexity, and have seen numerous applications in the recent years. In addition, such theorems can be viewed as a strong generalization of a direct-sum theorem for the gadget $g$.

We prove a new lifting theorem that works for all gadgets $g$ that have logarithmic length and exponentially-small discrepancy, for both deterministic and randomized communication complexity. Thus, we significantly increase the range of gadgets for which such lifting theorems hold.

Our result has two main motivations: First, allowing a larger variety of gadgets may support more applications. In particular, our work is the first to prove a randomized lifting theorem for logarithmic-size gadgets, thus improving some applications of the theorem. Second, our result can be seen as a strong generalization of a direct-sum theorem for functions with low discrepancy.</summary>
    <updated>2019-08-11T04:04:36Z</updated>
    <published>2019-08-11T04:04:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://blog.ilyaraz.org/rss/12</id>
    <link href="https://blog.ilyaraz.org/?go=all/cuckoo-hashing-for-sketching-sets/" rel="alternate" type="text/html"/>
    <title>Cuckoo hashing for sketching sets</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>Below I show a neat application of <a href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hashing</a>, which is one of my favorite (cluster of) algorithms. Amazingly, we use it to obtain a purely information-theoretic (rather than algorithmic) statement.</p>
<p>Suppose we have a finite universe $U$ of size $n$ and a $k$-element subset of it $S \subseteq U$ with $k \ll n$. How many bits do we need to encode it? The obvious answer is $\log_2 \binom{n}{k} = \Theta(k \cdot \log(n / k))$.<br/>
Can we, however, improve this bound if we allow some approximation?</p>
<p>Even if $n = 2k$, it is not difficult to show the lower bound of $k \cdot \log_2(1 / \delta)$ bits if we allow to be wrong when answering queries “does $x$ belong to $S$?” with probability at most $\delta$ (hint: $\varepsilon$-nets). Can we match this lower bound?</p>
<p>One approach that does not quite work is to hash each element of $S$ to an $l$-bit string using a sufficiently good hash function $h \colon U \to \{0, 1\}^l$, and, when checking if $x$ lies in $S$, compute $h(x)$ and check if this value is among the hashes of $S$. To see why it does not work, let us analyze it: if $x \notin S$, then the probability that $h(x)$ coincides with at least one hash of an element of $S$ is around $k \cdot 2^{-l}$. To make the latter less than $\delta$, we need to take $l = \log_2(k / \delta)$ yielding the overall bound of $k \cdot \log_2(k / \delta)$ falling short of the desired size.</p>
<p>To get the optimal size, we need to avoid using the union bound in the above argument. In order to accomplish this, let us use perfect hashing on top of the above hashing scheme! It is convenient to use a particular approach to perfect hashing called <a href="https://en.wikipedia.org/wiki/Cuckoo_hashing">Cuckoo hashing</a>. In short, there is a way to generate two simple hash functions $h_1, h_2 \in U \to [m]$ for $m = O(k)$ and place the elements of our set $S$ into $m$ bins without collisions so that for every $x \in S$, the element $x$ is placed either in $h_1(x)$ or in $h_2(x)$. Now, to encode our set $S$, we build a Cuckoo hash table for it, and then for each of the $m$ bins, we either store one bit indicating that it’s empty, or store an $l$-bit hash of an element that is placed into it. Now we can set $l = \log_2(2 / \delta)$, since we compare the hash of a query to merely two hashes, instead of $k$. This gives the overall size $m + k \cdot \log_2 (2 / \delta) = k \cdot (\log_2(1 / \delta) + O(1))$, which is optimal up to a low-order term. Of course, the encoding should include $h_1$, $h_2$ and $h$, but it turns out they can be taken to be sufficiently simple so that their size does not really matter.</p>
<p>Two remarks are in order. First, in this context people usually bring up <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a>. However, they require space, which is $1.44$ times bigger, and, arguably, they are more mysterious (if technically simple). Second, one may naturally wonder why anyone would care about distinguishing bounds like $k \cdot \log_2 (1 / \delta)$ and $k \cdot \log_2(k / \delta)$. In my opinion, there are two answers to this. First, it is just a cool application of perfect hashing (an obligatory link to <a href="https://www.smbc-comics.com/comic/2010-12-09">one of my favorite comic strips</a>). Second, compressing sets is actually important in practice and constant factors do matter, for instance when we are aiming to transfer the set over the network.</p>
<p><b>Update</b> <a href="https://cs.au.dk/~larsen/">Kasper Green Larsen</a> observed that we can combine the naive and not-quite-working solutions to obtain the optimal bound. Namely, by hashing everything to $\log_2(k / \delta)$ bits, we effectively reduce the universe size to $n’ = k / \delta$. Then, the naive encoding takes $\log_2 \binom{n’}{k} \approx H(\delta) \cdot n’ = H(\delta) \cdot k / \delta \approx<br/>
k \cdot \log_2 (1 / \delta)$ bits.</p></div>
    </summary>
    <updated>2019-08-11T01:21:23Z</updated>
    <published>2019-08-11T01:21:23Z</published>
    <source>
      <id>https://blog.ilyaraz.org/</id>
      <author>
        <name>Ilya Razenshteyn</name>
      </author>
      <link href="https://blog.ilyaraz.org/" rel="alternate" type="text/html"/>
      <link href="https://blog.ilyaraz.org/rss/" rel="self" type="application/rss+xml"/>
      <title>Lullaby of Cape Cod</title>
      <updated>2019-08-21T23:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/102</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/102" rel="alternate" type="text/html"/>
    <title>TR19-102 |  Testing Isomorphism in the Bounded-Degree Graph Model | 

	Oded Goldreich</title>
    <summary>We consider two versions of the problem of testing graph isomorphism in the bounded-degree graph model: A version in which one graph is fixed, and a version in which the input consists of two graphs.
We essentially determine the query complexity of these testing problems in the special case of $n$-vertex graphs with connected components of size at most $\poly(\log n)$. 
This is done by showing that these problems are computationally equivalent (up to polylogarithmic factors) to corresponding problems regarding isomorphism between sequences (over a large alphabet). 
Ignoring the dependence on the proximity parameter, our main results are: 
\begin{enumerate}
\item 
The query complexity of testing isomorphism to a fixed object (i.e., an $n$-vertex graph or an $n$-long sequence) is ${\widetilde{\Theta}(n^{1/2})$. 
\item 
The query complexity of testing isomorphism between two input objects is ${\widetilde{\Theta}}(n^{2/3})$. 
\end{enumerate}
Testing isomorphism between two sequences is shown to be related to testing that two distributions are equivalent, and this relation yields reductions in three of the four relevant cases. 
Failing to reduce the problem of testing the equivalence of two distribution to the problem of testing isomorphism between two sequences, we adapt the proof of the lower bound on the complexity of the first problem to the second problem.
This adaptation constitutes the main technical contribution of the current work. 

Determining the complexity of testing graph isomorphism (in the bounded-degree graph model), in the general case (i.e., for arbitrary bounded-degree graphs), is left open.</summary>
    <updated>2019-08-10T16:22:55Z</updated>
    <published>2019-08-10T16:22:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-22T19:20:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/10/report-from-cccg</id>
    <link href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html" rel="alternate" type="text/html"/>
    <title>Report from CCCG</title>
    <summary>After WADS, I stayed in Edmonton for CCCG. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">WADS</a>, I stayed in Edmonton for <a href="https://sites.ualberta.ca/~cccg2019/">CCCG</a>. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</p>

<p>Like WADS, CCCG had three invited speakers. In past years, two were named the Paul Erdős Memorial Lecture and the Ferran Hurtado Memorial Lecture. This year, sadly, the third one has also been named, as the Godfried Toussaint Memorial Lecture.</p>

<ul>
  <li>
    <p>The Erdős Lecture was by Vida Dujmović, who spoke on her breakthrough work with several other Barbados workshop participants showing that <a href="https://arxiv.org/abs/1904.04791">every planar graph is a subgraph of a strong product of a path graph and a bounded-pathwidth graph</a>, from which it follows that these graphs have bounded <a href="https://en.wikipedia.org/wiki/Queue_number">queue number</a>, that they can be embedded into 3d grids of linear volume, and many other nice properties. The timing of the lecture invitation to Vida was good, as the breakthrough happened after she had already agreed to speak!</p>
  </li>
  <li>
    <p>The Toussaint Lecture was by Joseph O’Rourke. Joe spoke on <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting the boundary of a polyhedron into a surface that can unfold into a simple polygon in the plane. One of the points of his talk was to rationalize some of the terminology in this area. The standard version of the problem asks for (in his new terminology) an <em>edge-unfolding</em>, a set of cuts along edges of the polyhedron, forming a spanning tree for its vertices, such that the resulting cut surface unfolds to a flat polygon. But one can also ask for an anycut-unfolding, using cuts that do not have to follow the edges. Or one can ask for an edge-unzipping or anycut-unzipping, in which the cuts must form a single (Hamiltonian) path through the vertices of the polyhedron. In this terminology <a href="http://www.openproblemgarden.org/op/d_urers_conjecture">Dürer’s conjecture</a> becomes the statement that every convex polyhedron has an edge-unfolding, and the example I recently posted of a <a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">zipless polycube</a> shows that not every polycube has an edge-unzipping. Another well-known open question in this area asks whether every polycube whose boundary forms a topological sphere has an edge-unfolding. Joe conjectured that with high probability the convex hull of many random points on a sphere does not have an anycut-unzipping.</p>
  </li>
  <li>
    <p>Mark de Berg presented the Hurtado Lecture. His topic involved subexponential algorithms for disk intersection graphs and <a href="https://en.wikipedia.org/wiki/Unit_disk_graph">unit disk graphs</a>. At STOC 2018 he had a paper on <a href="https://arxiv.org/abs/1803.10633">finding the maximum independent set in disk graphs</a> in time , matching the time for planar graphs. In planar graphs, you can use the <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">planar separator theorem</a>: for each of the  independent subsets of the separator, recurse on both sides. This turns out to work in disk graphs by replacing the usual size bound on the separator (it should have  vertices) with a decomposition into a union of cliques  with . The separators can be found analogously to classical circle-packing methods for planar separators. Each clique can contribute one vertex to any independent set from which it follows that the separator again has  independent subsets. The same idea works for other problems like dominating sets in unit disk graphs (where the unit assumption is used to get a bounded contribution from each clique), and generalizes to fat objects in higher dimensions. The time bound is optimal assuming the <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">exponential time hypothesis</a>. And in FOCS 2018 de Berg obtained similar <a href="https://arxiv.org/abs/1807.06933">ETH-tight time bounds for the Euclidean traveling salesperson problem</a> by using separators of point sets with the property that few points are very close to the separator boundary.</p>
  </li>
</ul>

<p>I can’t find links for all the contributed papers, but you can find them in the <a href="https://sites.ualberta.ca/~cccg2019/cccg2019_proceedings.pdf">complete proceedings</a>. Among them:</p>

<ul>
  <li>
    <p>In “Three-Coloring Three-Dimensional Uniform Hypergraphs”, Biniaz, Bose, Cardinal, and Payne prove that, for  points in the plane and a fixed triangle shape, one can -color the points so that every scaled and translated copy of the triangle containing six or more points has more than one color. It was already known that if you change “six or more” to “two or more” you need four colors, and if you change it to “nine or more” you need only two colors.</p>
  </li>
  <li>
    <p>Audrey St. John’s talk on “Redundant Persistent Acyclic Formations for Vision-Based Control of Distributed Multi-Agent Formations” (with Burns, Klemperer, and Solyst) was beset by technical difficulties, but from it I learned that there is a theory of directed bar-and-joint frameworks, analogous to undirected rigidity theory, called “persistence theory”, and that the <a href="https://11011110.github.io/blog/2013/12/07/kinematic-chains-and.html">pebble game</a> for testing rigidity of an undirected framework produces an orientation of the network that is persistent. She used the analogy of a flock of geese, walking in formation: each goose pays attention only to the other geese in front, but the whole formation can keep its shape as the leading goose moves arbitrarily. Her goal is to get robots to do the same thing.</p>
  </li>
  <li>
    <p>In “Chirotopes of Random Points in Space are Realizable on a Small Integer Grid”, Cardinal, Fabila-Monroy and Hidalgo-Toscano prove that, with high probability, random point sets in  can be rounded to a grid of polynomial size without changing their order type.</p>
  </li>
  <li>
    <p>We had enough folding and unfolding papers to spill out over more than one section. Among them, I particularly liked “Efficient Segment Folding is Hard” by Klute, Parada, Horiyama, Korman, Uehara and Yamanaka. The question they asked is: given disjoint line segments on a piece of paper, when can you make a sequence of simple folds (that is, for a given fold line, folding all the layers of the paper that are crossed by the line), with each fold on a line through one of the segments that misses all the other segments? It turns out to be -complete. If you do allow fold lines to pass through other segments, folding sequences can be infinite, and it’s unknown whether every set of segments has a finite sequence.</p>
  </li>
  <li>
    <p>Pilar Cano spoke on generating triangulations of point sets in an affine-invariant way (“Affine invariant triangulations” with Bose and Silveira). The main trick is to use covariance to choose a canonical affine transformation for the points, after which you can use Delaunay, minimum weight, or your favorite other triangulation algorithm. But there are necessarily some general position assumptions (as there already are for using Delaunay triangulation without the affine invariance): for points in a parallelogram, there is no affine-invariant way of choosing which diagonal to use.</p>
  </li>
</ul>

<p>The excursion was to the <a href="https://royalalbertamuseum.ca/">Royal Alberta Museum</a>, where I skipped the special exhibit on Vikings (having gone to museum exhibits on them in Copenhagen a year earlier) and instead learned much about Great Plains geology and the historical mistreatment of the <a href="https://en.wikipedia.org/wiki/M%C3%A9tis">Métis</a>, local people descending both from First Nations and Europeans. (The First Nations themselves were of course also badly mistreated, but I had more of an idea of that already.)</p>

<p>From the business meeting, we heard that the acceptance ratio was a little higher than last year, but still approximately . Two papers were withdrawn because the authors had visa issues, double the number from last year, and several others were presented by non-authors after their authors were unable to attend. One possible improvement would be to move the submission and acceptance dates earlier to provide authors more time to obtain visas. The main topic of discussion was the conference’s status as a conference: should papers at CCCG continue to count as publications (in which case why are they still limited to only six pages) or should they be considered as preliminary announcements of papers that can still be sent to other more prestigious symposia? One possible compromise involves giving authors a choice: either publish your paper in the proceedings or give up the proceedings slot but still present your work in some other way (possibly as a poster, as GD does).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102595225020207137">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-10T15:34:00Z</updated>
    <published>2019-08-10T15:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-17T21:55:27Z</updated>
    </source>
  </entry>
</feed>
