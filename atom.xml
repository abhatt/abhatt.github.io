<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-18T12:21:42Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05911</id>
    <link href="http://arxiv.org/abs/1902.05911" rel="alternate" type="text/html"/>
    <title>Persistent Homology of Geospatial Data: A Case Study with Voting</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Michelle Feng, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porter:Mason_A=.html">Mason A. Porter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05911">PDF</a><br/><b>Abstract: </b>A crucial step in the analysis of persistent homology is transformation of
data into a simplicial complex. Modern packages for persistent homology often
construct Vietoris--Rips or other distance-based simplicial complexes on point
clouds because they are relatively easy to compute. We investigate alternative
methods of constructing these complexes and the effects of making associated
choices during simplicial-complex construction on the output of
persistent-homology algorithms. We present two new methods for constructing
simplicial complexes from two-dimensional geospatial data (such as maps). We
apply these methods to a California precinct-level voting data set,
demonstrating that our new constructions can capture geometric characteristics
that are missed by distance-based constructions. Our new constructions can thus
yield more interpretable persistence modules and barcodes for geospatial data.
In particular, they are able to distinguish short-persistence features that
occur only for a narrow range of distance scales (e.g., voting behaviors in
densely populated cities) from short-persistence noise by incorporating
information about other spatial relationships between precincts.
</p></div>
    </summary>
    <updated>2019-02-18T02:23:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05877</id>
    <link href="http://arxiv.org/abs/1902.05877" rel="alternate" type="text/html"/>
    <title>A 2/3-Approximation Algorithm for Vertex-weighted Matching</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Al=Herz:Ahmed.html">Ahmed Al-Herz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pothen:Alex.html">Alex Pothen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05877">PDF</a><br/><b>Abstract: </b>We consider the maximum vertex-weighted matching problem (MVM) for
non-bipartite graphs. In earlier work we have described a 2/3-approximation
algorithm for the MVM on bipartite graphs (Dobrian, Halappanavar, Pothen and
Al-Herz, SIAM J. Scientific Computing, 2019). Here we show that a
2/3-approximation algorithm for MVM on non-bipartite graphs can be obtained by
restricting the length of augmenting paths to at most three. The algorithm has
time complexity $O(m \log \Delta + n \log n)$, where $n$ is the number of
vertices, $m$ is the number of edges, and $\Delta$ is the maximum degree of a
vertex.
</p>
<p>The approximation ratio of the algorithm is obtained by considering failed
vertices, i.e., vertices that the approximation algorithm fails to match but
the exact algorithm does. We show that there are two distinct heavier matched
vertices that we can charge each failed vertex to. Our proof techniques
characterize the structure of augmenting paths in a novel way.
</p>
<p>We have implemented the 2/3-approximation algorithm and show that it runs in
under a minute on graphs with tens of millions of vertices and hundreds of
millions of edges. We compare its performance with five other algorithms: an
exact algorithm for MVM, an exact algorithm for the maximum edge-weighted
matching (MEM) problem, as well as three approximation algorithms. In our test
set of nineteen problems, there are graphs on which the exact algorithms fail
to terminate in 100 hours. The new 2/3-approximation algorithm for MVM
outperforms the other approximation algorithms by either being faster (often by
orders of magnitude) or obtaining better weights.
</p></div>
    </summary>
    <updated>2019-02-18T02:22:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05876</id>
    <link href="http://arxiv.org/abs/1902.05876" rel="alternate" type="text/html"/>
    <title>The Optimal Approximation Factor in Density Estimation</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Olivier.html">Olivier Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel.html">Daniel Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moran:Shay.html">Shay Moran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05876">PDF</a><br/><b>Abstract: </b>Consider the following problem: given two arbitrary densities $q_1,q_2$ and a
sample-access to an unknown target density $p$, find which of the $q_i$'s is
closer to $p$ in total variation.
</p>
<p>A remarkable result due to Yatracos shows that this problem is tractable in
the following sense: there exists an algorithm that uses $O(\epsilon^{-2})$
samples from $p$ and outputs~$q_i$ such that with high probability, $TV(q_i,p)
\leq 3\cdot\mathsf{opt} + \epsilon$, where $\mathsf{opt}=
\min\{TV(q_1,p),TV(q_2,p)\}$. Moreover, this result extends to any finite class
of densities $\mathcal{Q}$: there exists an algorithm that outputs the best
density in $\mathcal{Q}$ up to a multiplicative approximation factor of 3.
</p>
<p>We complement and extend this result by showing that: (i) the factor 3 can
not be improved if one restricts the algorithm to output a density from
$\mathcal{Q}$, and (ii) if one allows the algorithm to output arbitrary
densities (e.g.\ a mixture of densities from $\mathcal{Q}$), then the
approximation factor can be reduced to 2, which is optimal. In particular this
demonstrates an advantage of improper learning over proper in this setup.
</p>
<p>We develop two approaches to achieve the optimal approximation factor of 2:
an adaptive one and a static one. Both approaches are based on a geometric
point of view of the problem and rely on estimating surrogate metrics to the
total variation. Our sample complexity bounds exploit techniques from {\it
Adaptive Data Analysis}.
</p></div>
    </summary>
    <updated>2019-02-18T02:20:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05678</id>
    <link href="http://arxiv.org/abs/1902.05678" rel="alternate" type="text/html"/>
    <title>Strategy-Proof Approximation Algorithms for the Stable Marriage Problem with Ties and Incomplete Lists</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamada:Koki.html">Koki Hamada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyazaki:Shuichi.html">Shuichi Miyazaki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yanagisawa:Hiroki.html">Hiroki Yanagisawa</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05678">PDF</a><br/><b>Abstract: </b>In the stable marriage problem (SM), a mechanism that always outputs a stable
matching is called a stable mechanism. One of the well-known stable mechanisms
is the man-oriented Gale-Shapley algorithm (MGS). MGS has a good property that
it is strategy-proof to the men's side, i.e., no man can obtain a better
outcome by falsifying a preference list. We call such a mechanism a
man-strategy-proof mechanism. Unfortunately, MGS is not a woman-strategy-proof
mechanism. Roth has shown that there is no stable mechanism that is
simultaneously man-strategy-proof and woman-strategy-proof, which is known as
Roth's impossibility theorem.
</p>
<p>In this paper, we extend these results to the stable marriage problem with
ties and incomplete lists (SMTI). Since SMTI is an extension of SM, Roth's
impossibility theorem takes over to SMTI. Therefore, we focus on the
one-sided-strategy-proofness. In SMTI, one instance can have stable matchings
of different sizes, and it is natural to consider the problem of finding a
largest stable matching, known as MAX SMTI. Thus we incorporate the notion of
approximation ratio used in the theory of approximation algorithms. We say that
a stable-mechanism is $c$-approximate-stable mechanism if it always returns a
stable matching of size at least $1/c$ of a largest one. We also consider a
restricted variant of MAX SMTI, which we call MAX SMTI-1TM, where only men's
lists can contain ties.
</p>
<p>Our results are summarized as follows: (i) MAX SMTI admits both a
man-strategy-proof 2-approximate-stable mechanism and a woman-strategy-proof
2-approximate-stable mechanism. (ii) MAX SMTI-1TM admits a woman-strategy-proof
2-approximate-stable mechanism. (iii) MAX SMTI-1TM admits a man-strategy-proof
1.5-approximate-stable mechanism. All these results are tight in terms of
approximation ratios. Also, all these strategy-proofness results apply for
strategy-proofness against coalitions.
</p></div>
    </summary>
    <updated>2019-02-18T02:23:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05659</id>
    <link href="http://arxiv.org/abs/1902.05659" rel="alternate" type="text/html"/>
    <title>Massively Parallel Benders Decomposition for Correlation Clustering</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keuper:Margret.html">Margret Keuper</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Maneesh.html">Maneesh Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yarkony:Julian.html">Julian Yarkony</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05659">PDF</a><br/><b>Abstract: </b>We tackle the problem of graph partitioning for image segmentation using
correlation clustering (CC), which we treat as an integer linear program (ILP).
We reformulate optimization in the ILP so as to admit efficient optimization
via Benders decomposition, a classic technique from operations research. Our
Benders decomposition formulation has many subproblems, each associated with a
node in the CC instance's graph, which are solved in parallel. Each Benders
subproblem enforces the cycle inequalities corresponding to the negative weight
edges attached to its corresponding node in the CC instance. We generate
Magnanti-Wong Benders rows in addition to standard Benders rows, to accelerate
optimization. Our Benders decomposition approach provides a promising new
avenue to accelerate optimization for CC, and allows for massive
parallelization.
</p></div>
    </summary>
    <updated>2019-02-18T02:22:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05638</id>
    <link href="http://arxiv.org/abs/1902.05638" rel="alternate" type="text/html"/>
    <title>Finding Nearest Neighbors in graphs locally</title>
    <feedworld_mtime>1550448000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mishra:Abhinav.html">Abhinav Mishra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05638">PDF</a><br/><b>Abstract: </b>Many distributed learning techniques have been motivated by the increasing
size of datasets and their inability to fit into main memory on a single
machine. We propose an algorithm that finds the nearest neighbor in a graph
locally without the need of visiting the whole graph. Our algorithm is
distributed which further encourage scalability. We prove the convergence of
the algorithm
</p></div>
    </summary>
    <updated>2019-02-18T02:22:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05529</id>
    <link href="http://arxiv.org/abs/1902.05529" rel="alternate" type="text/html"/>
    <title>Parameterized Fine-Grained Reductions</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Elli Anastasiadi, Antonis Antonopoulos, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagourtzis:Aris.html">Aris Pagourtzis</a>, Stavros Petsalakis <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05529">PDF</a><br/><b>Abstract: </b>During recent years the field of fine-grained complexity has bloomed to
produce a plethora of results, with both applied and theoretical impact on the
computer science community. The cornerstone of the framework is the notion of
fine-grained reductions, which correlate the exact complexities of problems
such that improvements in their running times or hardness results are carried
over. We provide a parameterized viewpoint of these reductions (PFGR) in order
to further analyze the structure of improvable problems and set the foundations
of a unified methodology for extending algorithmic results. In this context, we
define a class of problems (FPI) that admit fixed-parameter improvements on
their running time. As an application of this framework we present a truly
sub-quadratic fixed-parameter algorithm for the orthogonal vectors problem.
Finally, we provide a circuit characterization for FPI to further solidify the
notion of improvement.
</p></div>
    </summary>
    <updated>2019-02-17T23:21:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05487</id>
    <link href="http://arxiv.org/abs/1902.05487" rel="alternate" type="text/html"/>
    <title>Complexity-Theoretic Aspects of Expanding Cellular Automata</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Modanese:Augusto.html">Augusto Modanese</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05487">PDF</a><br/><b>Abstract: </b>The expanding cellular automata (XCA) variant of cellular automata is
investigated and characterized from a complexity-theoretical standpoint. The
respective polynomial-time complexity class is shown to coincide with
${\le_{tt}^p}(\textbf{NP})$, that is, the class of decision problems
polynomial-time truth-table reducible to problems in $\textbf{NP}$. Corollaries
on select XCA variants are proven: XCAs with multiple accept and reject states
are shown to be polynomial-time equivalent to the original XCA model.
Meanwhile, XCAs with diverse acceptance behavior are classified in terms of
${\le_{tt}^p}(\textbf{NP})$ and the Turing machine polynomial-time class
$\textbf{P}$.
</p></div>
    </summary>
    <updated>2019-02-17T23:22:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05479</id>
    <link href="http://arxiv.org/abs/1902.05479" rel="alternate" type="text/html"/>
    <title>Which is the least complex explanation? Abduction and complexity</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soler=Toscano:Fernando.html">Fernando Soler-Toscano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05479">PDF</a><br/><b>Abstract: </b>It may happen that for a certain abductive problem there are several possible
explanations, not all of them mutually compatible. What explanation is selected
and which criteria are used to select it? This is the well-known problem of the
selection of abductive hypotheses. Are there criteria that can help us to
select the simplest explanation in a broad spectrum of abductive problems? To
give an (affirmative) answer to this question we will move to a field in
theoretical computer science: Algorithmic Information Theory (AIT). The
algorithmic complexity measure K(s) can be used to determine which is the best
theory within those explaining a set of observations. We introduce an
application of K(s) to the selection of the best abductive explanation, in the
context of dynamic epistemic logic (DEL).
</p></div>
    </summary>
    <updated>2019-02-17T23:21:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05432</id>
    <link href="http://arxiv.org/abs/1902.05432" rel="alternate" type="text/html"/>
    <title>Search and Rescue in the Face of Uncertain Threats</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lidbetter:Thomas.html">Thomas Lidbetter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05432">PDF</a><br/><b>Abstract: </b>We consider a search problem in which one or more targets must be rescued by
a search party, or Searcher. The targets may be survivors of some natural
disaster, or prisoners held by an adversary. The targets are hidden among a
finite set of locations, but when a location is searched, there is a known
probability that the search will come to an end, perhaps because the Searcher
becomes trapped herself, or is captured by the adversary. If this happens
before all the targets have been recovered, then the rescue attempt is deemed a
failure. The objective is to find the search that maximizes the probability of
recovering all the targets. We present and solve a game theoretic model for
this problem, by placing it in a more general framework that encompasses
another game previously introduced by the author. We also consider an extension
to the game in which the targets are hidden on the vertices of a graph. In the
case that there is only one target, we give a solution of the game played on a
tree.
</p></div>
    </summary>
    <updated>2019-02-17T23:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05224</id>
    <link href="http://arxiv.org/abs/1902.05224" rel="alternate" type="text/html"/>
    <title>Conversion from RLBWT to LZ77</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishimoto:Takaaki.html">Takaaki Nishimoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tabei:Yasuo.html">Yasuo Tabei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05224">PDF</a><br/><b>Abstract: </b>Converting a compressed format of a string into another compressed format
without an explicit decompression is one of the central research topics in
string processing. We discuss the problem of converting the run-length
Burrows-Wheeler Transform (RLBWT) of a string to Lempel-Ziv 77 (LZ77) phrases
of the reversed string. The first results with Policriti and Prezza's
conversion algorithm [Algorithmica 2018] were $O(n \log r)$ time and $O(r)$
working space for length of the string $n$, number of runs $r$ in the RLBWT,
and number of LZ77 phrases $z$. Recent results with Kempa's conversion
algorithm [SODA 2019] are $O(n / \log n + r \log^{9} n + z \log^{9} n)$ time
and $O(n / \log_{\sigma} n + r \log^{8} n)$ working space for the alphabet size
$\sigma$ of the RLBWT. In this paper, we present a new conversion algorithm by
improving Policriti and Prezza's conversion algorithm where dynamic data
structures for general purpose are used. We argue that these dynamic data
structures can be replaced and present new data structures for faster
conversion. The time and working space of our conversion algorithm with new
data structures are $O(n \min \{ \log \log n, \sqrt{\frac{\log r}{\log\log r}}
\})$ and $O(r)$, respectively.
</p></div>
    </summary>
    <updated>2019-02-17T23:22:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05166</id>
    <link href="http://arxiv.org/abs/1902.05166" rel="alternate" type="text/html"/>
    <title>Space-Efficient Data Structures for Lattices</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munro:J=_Ian.html">J. Ian Munro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandlund:Bryce.html">Bryce Sandlund</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinnamon:Corwin.html">Corwin Sinnamon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05166">PDF</a><br/><b>Abstract: </b>A lattice is a partially-ordered set in which every pair of elements has a
unique meet (greatest lower bound) and join (least upper bound). We present new
data structures for lattices that are simple, efficient, and nearly optimal in
terms of space complexity.
</p>
<p>Our first data structure can answer partial order queries in constant time
and find the meet or join of two elements in $O(n^{3/4})$ time, where $n$ is
the number of elements in the lattice. It occupies $O(n^{3/2}\log n)$ bits of
space, which is only a $\Theta(\log n)$ factor from the $\Theta(n^{3/2})$-bit
lower bound for storing lattices. The preprocessing time is $O(n^2)$.
</p>
<p>This structure admits a simple space-time tradeoff so that, for any $c \in
[\frac{1}{2}, 1]$, the data structure supports meet and join queries in
$O(n^{1-c/2})$ time, occupies $O(n^{1+c}\log n)$ bits of space, and can be
constructed in $O(n^2 + n^{1+3c/2})$ time.
</p>
<p>Our second data structure uses $O(n^{3/2}\log n)$ bits of space and supports
meet and join in $O(d \frac{\log n}{\log d})$ time, where $d$ is the maximum
degree of any element in the transitive reduction graph of the lattice. This
structure is much faster for lattices with low-degree elements.
</p>
<p>This paper also identifies an error in a long-standing solution to the
problem of representing lattices. We discuss the issue with this previous work.
</p></div>
    </summary>
    <updated>2019-02-17T23:23:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05134</id>
    <link href="http://arxiv.org/abs/1902.05134" rel="alternate" type="text/html"/>
    <title>Efficient Continuous Multi-Query Processing over Graph Streams</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zervakis:Lefteris.html">Lefteris Zervakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Setty:Vinay.html">Vinay Setty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tryfonopoulos:Christos.html">Christos Tryfonopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hose:Katja.html">Katja Hose</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05134">PDF</a><br/><b>Abstract: </b>Graphs are ubiquitous and ever-present data structures that have a wide range
of applications involving social networks, knowledge bases and biological
interactions. The evolution of a graph in such scenarios can yield important
insights about the nature and activities of the underlying network, which can
then be utilized for applications such as news dissemination, network
monitoring, and content curation. Capturing the continuous evolution of a graph
can be achieved by long-standing sub-graph queries. Although, for many
applications this can only be achieved by a set of queries, state-of-the-art
approaches focus on a single query scenario. In this paper, we therefore
introduce the notion of continuous multi-query processing over graph streams
and discuss its application to a number of use cases. To this end, we designed
and developed a novel algorithmic solution for efficient multi-query evaluation
against a stream of graph updates and experimentally demonstrated its
applicability. Our results against two baseline approaches using real-world, as
well as synthetic datasets, confirm a two orders of magnitude improvement of
the proposed solution.
</p></div>
    </summary>
    <updated>2019-02-17T23:22:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05101</id>
    <link href="http://arxiv.org/abs/1902.05101" rel="alternate" type="text/html"/>
    <title>Reconstructing Trees from Traces</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Sami.html">Sami Davies</a>, Miklos Z. Racz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rashtchian:Cyrus.html">Cyrus Rashtchian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05101">PDF</a><br/><b>Abstract: </b>We study the problem of learning a node-labeled tree given independent traces
from an appropriately defined deletion channel. This problem, tree trace
reconstruction, generalizes string trace reconstruction, which corresponds to
the tree being a path. For many classes of trees, including complete trees and
spiders, we provide algorithms that reconstruct the labels using only a
polynomial number of traces. This exhibits a stark contrast to known results on
string trace reconstruction, which require exponentially many traces, and where
a central open problem is to determine whether a polynomial number of traces
suffice. Our techniques combine novel combinatorial and complex analytic
methods.
</p></div>
    </summary>
    <updated>2019-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.05070</id>
    <link href="http://arxiv.org/abs/1902.05070" rel="alternate" type="text/html"/>
    <title>Optimization problems with low SWaP tactical Computing</title>
    <feedworld_mtime>1550361600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Im:Mee_Seong.html">Mee Seong Im</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dasari:Venkat_R=.html">Venkat R. Dasari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beshaj:Lubjana.html">Lubjana Beshaj</a>, Dale Shires <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.05070">PDF</a><br/><b>Abstract: </b>In a resource-constrained, contested environment, computing resources need to
be aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware
computational efficiency depends upon optimization of computational resources
and intelligent time versus efficiency tradeoffs in decision making. In this
paper we address the complexity of various optimization strategies related to
low SWaP computing. Due to these restrictions, only a small subset of less
complicated and fast computable algorithms can be used for tactical, adaptive
computing.
</p></div>
    </summary>
    <updated>2019-02-17T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16238</id>
    <link href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/" rel="alternate" type="text/html"/>
    <title>Attila Por’s Universality Result for Tverberg Partitions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In this post  I want to tell you about three papers and three theorems. I am thankful to Moshe White and Imre Barany for helpful discussions. a) Universality of vector sequences and universality of Tverberg partitions, by Attila Por; Theorem (Por’s … <a href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2/>
<p>In this post  I want to tell you about three papers and three theorems. I am thankful to Moshe White and Imre Barany for helpful discussions.</p>
<p><strong><a href="https://arxiv.org/abs/1805.07197">a) Universality of vector sequences and universality of Tverberg partitions,</a> by Attila Por;</strong></p>
<p><strong>Theorem (Por’s universality result, 2018):</strong> Every long enough sequence of points in general position in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>  contains a subsequence of length <em><span class="MathJax" id="MathJax-Element-16-Frame"><span class="math" id="MathJax-Span-98"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100">n</span></span></span></span></em> whose Tverberg partitions are exactly the so called rainbow partitions.</p>
<p class="title mathjax"><strong><a href="https://arxiv.org/abs/1611.01078">b) Classifying unavoidable Tverberg partitions</a>, by <a href="http://www.borisbukh.org/">Boris Bukh</a>, <a href="http://www.math.cmu.edu/~ploh/">Po-Shen Loh</a>, <a href="http://www.gabrielnivasch.org/">Gabriel Nivasch</a></strong></p>
<p><strong>Theorem (Bukh, Loh, and Nivasch, 2017):</strong> Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> be a tree-like <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>-uniform simple hypergraph with <img alt="d+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+1"/> edges and <img alt="n=(d+1)(r-1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D%28d%2B1%29%28r-1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=(d+1)(r-1)+1"/> edges. It is possible to associate to the vertices of each such hypergraph H a set X of n points in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> so that the Tverberg’s partitions of X correspond precisely to rainbow coloring of the hypergraph H. Moreover, the number of rainbow coloring is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/>. (Here, we consider two coloring as the same if they differ by a permutation of the colors.)</p>
<p><strong><a href="https://arxiv.org/abs/1508.07262">c) On Tverberg partitions</a>, by Moshe White</strong></p>
<p><strong>Theorem (White, 2015):</strong> For any partition <img alt="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_r%3A+1+%5Cle+a_i%5Cle+d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, there exists a set <img alt="X \subset \mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csubset+%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \subset \mathbb R^d"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>  points, such that every Tverberg partition of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/>  induces the same partition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> given by the parts <img alt="a_1,\dots,a_r" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2C%5Cdots%2Ca_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,\dots,a_r"/>. Moreover, the number of Tverberg’s partitions of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/></p>
<p>See the original abstracts for the papers at the end of the post.</p>
<h2>Radon’s and Tverberg’s theorems and Sierksma’s conjecture</h2>
<p>Recall the beautiful theorem of Tverberg: (We devoted two posts (<a href="https://gilkalai.wordpress.com/2008/11/24/sarkarias-proof-of-tverbergs-theorem-1/" rel="noopener noreferrer" target="_blank" title="Tverberg 1">I</a>, <a href="https://gilkalai.wordpress.com/2008/11/26/sarkarias-proof-of-tverbergs-theorem-2/" rel="noopener noreferrer" target="_blank" title="Tverberg 2">II</a>) to its background and proof.)</p>
<p><strong>Tverberg Theorem (1965): </strong>Let <img alt="x_1,x_2,\dots, x_m" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2Cx_2%2C%5Cdots%2C+x_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,x_2,\dots, x_m"/> be points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/>, <img alt="m \ge (r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=m+%5Cge+%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m \ge (r-1)(d+1)+1"/>. Then there is a partition <img alt="S_1,S_2,\dots, S_r" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2CS_2%2C%5Cdots%2C+S_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_1,S_2,\dots, S_r"/> of <img alt="\{1,2,\dots,m\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cm%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{1,2,\dots,m\}"/> such that <img alt="\cap _{j=1}^rconv (x_i: i \in S_j) \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccap+_%7Bj%3D1%7D%5Erconv+%28x_i%3A+i+%5Cin+S_j%29+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cap _{j=1}^rconv (x_i: i \in S_j) \ne \emptyset"/>.</p>
<p>The (much easier) case <img alt="r=2" class="latex" src="https://s0.wp.com/latex.php?latex=r%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r=2"/> of Tverberg’s theorem is <strong>Radon’s theorem</strong>.</p>
<p>We devoted a post to <a href="https://gilkalai.wordpress.com/2008/12/23/seven-problems-around-tverbergs-theorem/">seven open problems related to Tverberg’s theorem</a>, and one of them was:</p>
<p><strong>Sierksma Conjecture:</strong> The number of Tverberg’s <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>-partitions of a set of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> is at least <img alt="((r-1)!)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28%28r-1%29%21%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="((r-1)!)^d"/>.</p>
<p>Gerard Sierksma’s construction with <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/> Tverberg’s partition is obtained by taking <img alt="(r-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)"/> copies of each vertex of a simplex containing the origin in its interior, and adding the origin itself. A configuration of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> with precisely <img alt="((r-1)!)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28%28r-1%29%21%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="((r-1)!)^d"/> Tverberg partitions to <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> parts is called a <strong>Sierksma Configuration</strong>.</p>
<h2>White’s Theorem</h2>
<p>In 2015 Moshe White proved the following theorem which was an open problem for many years. White’s construction was surprisingly simple.</p>
<p><strong>Theorem 1 (White, 2015):</strong>  For any partition <img alt="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_r%3A+1+%5Cle+a_i%5Cle+d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, there exists a set <img alt="X \subset \mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csubset+%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \subset \mathbb R^d"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>  points, such that every Tverberg partition of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/>  induces the same partition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> given by the parts <img alt="a_1,\dots,a_r" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2C%5Cdots%2Ca_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,\dots,a_r"/>. Moreover, the number of Tverberg’s partitions of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/></p>
<h2>Bukh, Loh, and Nivasch’s  examples via staircase convexity.</h2>
<h2><a href="https://gilkalai.files.wordpress.com/2019/02/cascade-tverberg.png"><img alt="" class="alignnone size-full wp-image-16844" height="463" src="https://gilkalai.files.wordpress.com/2019/02/cascade-tverberg.png?w=640&amp;h=463" width="640"/></a></h2>
<p><strong><span style="color: #ff0000;">Five tree-like simple hypergraphs that correspond to configurations of 11 points in 4-dimensional space.</span></strong></p>
<p>Start with a tree-like hypergraph H of d+1 blocks of size r like the five examples in the Figure above. The intersection of every two blocks has at most one element. The union of all blocks has n=(d+1)(r-1)+1 elements.</p>
<p>A <strong>rainbow coloring</strong> of a r-uniform hypergraph H is a coloring of the vertices of H with r colors so that the vertices of every edge is colored by all r colors.</p>
<p><strong>Theorem 2 (Bukh, Loh, and Nivasch):</strong> It is possible to associate to the vertices of each such hypergraph H a set X of n points in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> so that the Tverberg’s partitions of X correspond precisely to rainbow coloring of the hypergraph H. Moreover, the number of rainbow coloring is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/>. (Here, we consider two coloring as the same if they differ by a permutation of the colors.)</p>
<p>For a starlike hypergraph where all blocks have a vertex in common we get the original Sierksma’s example. (Example (d) above.) White’s examples are obtained by considering such hypergraphs where there exists an edge <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> such that all edges have non empty intersection with <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. (Examples (c), (d), and (e) above).</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png"><img alt="" class="alignnone size-full wp-image-16899" height="463" src="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=640&amp;h=463" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Rainbow colorings of our five examples </span></strong></p>
<h2>Tverberg’s partitions for stretched points on the moment curve</h2>
<p>It is natural to consider $n$ points on the moment curve <img alt="x(t)=(t,t^2,\dots, t^d)" class="latex" src="https://s0.wp.com/latex.php?latex=x%28t%29%3D%28t%2Ct%5E2%2C%5Cdots%2C+t%5Ed%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(t)=(t,t^2,\dots, t^d)"/>. It turns out that the set of Tverberg’s partitions for points on the moment curve depend on the precise location of the points. By stretched points on the moment curve I mean that  you take the points <img alt="x(t_1), x(t_2), \dots x(t_n)" class="latex" src="https://s0.wp.com/latex.php?latex=x%28t_1%29%2C+x%28t_2%29%2C+%5Cdots+x%28t_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(t_1), x(t_2), \dots x(t_n)"/> where <img alt="t_1 &lt;&lt; t_2 &lt;&lt; \dots t_n" class="latex" src="https://s0.wp.com/latex.php?latex=t_1+%3C%3C+t_2+%3C%3C+%5Cdots+t_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_1 &lt;&lt; t_2 &lt;&lt; \dots t_n"/>, namely $t_2$ is much much larget than <img alt="t_1" class="latex" src="https://s0.wp.com/latex.php?latex=t_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_1"/> and <img alt="t_3" class="latex" src="https://s0.wp.com/latex.php?latex=t_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_3"/> is much much much much larger than <img alt="t_2" class="latex" src="https://s0.wp.com/latex.php?latex=t_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_2"/>, etc. etc. In this case, the configuration correspond to a <strong>path</strong> <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>: you let the vertices be <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{1,2,\dots,n\}"/> and the edges are sets of the form <img alt="\{(k-1)(r-1)+1, (k-1)(r-1)+2,\dots , k(r-1)+1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28k-1%29%28r-1%29%2B1%2C+%28k-1%29%28r-1%29%2B2%2C%5Cdots+%2C+k%28r-1%29%2B1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(k-1)(r-1)+1, (k-1)(r-1)+2,\dots , k(r-1)+1\}"/>. A stretched configuration of points on the moment curve has the property that every subset is also a stretched configuration of points on the moment curve.</p>
<p>The importance of Tverberg’s partitions for stretched points on the moment curve was realized by Barany and Por, by Bukh, Loh, and Nivasch, and by Perles and Sidron (See their paper <a href="https://link.springer.com/article/10.1007/s00454-016-9813-3">Tverberg Partitions of Points on the Moment Curve</a>), and perhaps by others.</p>
<h2>Por’s universality result</h2>
<p>Por’s universality theorem asserts that in terms of Tverberg partitions every large enough configuration of points in general position in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> contains a configuration whose Tverberg partitions are those of a stretched configuration of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points on the moment curve! Por’s  universality result was conjectured independently by Bukh, Loh, and Nivasch, (and they gave some partial results) and by Por himself.</p>
<p><strong>Theorem 3 (Por’s universality result, 2018):</strong> Every long enough sequence of points in $latex \mathbb <span class="MathJax" id="MathJax-Element-15-Frame"><span class="math" id="MathJax-Span-91"><span class="mrow" id="MathJax-Span-92"><span class="msubsup" id="MathJax-Span-93"><span class="texatom" id="MathJax-Span-94"><span class="mrow" id="MathJax-Span-95"><span class="mi" id="MathJax-Span-96">R^</span></span></span><span class="mi" id="MathJax-Span-97">d$</span></span></span></span></span> in general position contains a subsequence  of length <em><span class="MathJax" id="MathJax-Element-16-Frame"><span class="math" id="MathJax-Span-98"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100">n</span></span></span></span></em> whose Tverberg partitions are exactly the so called rainbow partitions.</p>
<p><span style="color: #000000;">Por actually proved an apparently stronger statement: We can find a subsequence <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> so the conclusion holds not only for <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> but also for every subsequence <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> of <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. </span></p>
<h2>Staircase Convexity</h2>
<p>The work of Bukh, Loh, and Nivasch relied on an important method of “staircase convexity”. An earlier 2001 application of the method (where it was introduced) was for lower bounds on weak epsilon nets by Bukh, Matousek, and Nivasch (Here are links to the paper, and to <a href="http://www.borisbukh.org/geomselthms_talk.pdf">slides from a talk by Boris Bukh</a>. See also <a href="https://terrytao.wordpress.com/2007/04/22/gil-kalai-the-weak-epsilon-net-problem/">this post</a> and <a href="https://gilkalai.wordpress.com/2018/04/05/nathan-rubin-improved-the-bound-for-planar-weak-%CE%B5-nets-and-other-news-from-ein-gedi/">this one</a> of the weak epsilon net problem.) Roughly the idea is this: consider a stretched grid where the sequence of coordinates are very very fast growing. When you choose configuration of points in such a grid questions regarding their convex hulls translate to purely combinatorial problems.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/staircase-convexity.png"><img alt="" class="alignnone size-full wp-image-16867" src="https://gilkalai.files.wordpress.com/2019/02/staircase-convexity.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Stairconvex sets explained by Boris Bukh</strong></span></p>
<h2>Erdos Szekeres in the plane and higher dimensions</h2>
<h3>The planar case</h3>
<p>Let <em><span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">E</span><span class="mi" id="MathJax-Span-4">S</span><span class="mo" id="MathJax-Span-5">(</span><span class="mi" id="MathJax-Span-6">n</span><span class="mo" id="MathJax-Span-7">)</span></span></span></span></em> be the smallest integer such that any set of <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10">E</span><span class="mi" id="MathJax-Span-11">S</span><span class="mo" id="MathJax-Span-12">(</span><span class="mi" id="MathJax-Span-13">n</span><span class="mo" id="MathJax-Span-14">)</span></span></span></span></em> points in the plane in general position contains <em><span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-15"><span class="mrow" id="MathJax-Span-16"><span class="mi" id="MathJax-Span-17">n</span></span></span></span></em> points in convex position. In their <a href="http://archive.numdam.org/ARCHIVE/CM/CM_1935__2_/CM_1935__2__463_0/CM_1935__2__463_0.pdf">seminal 1935 paper</a>, Erdős and Szekeres showed that <em>ES(n)</em> is finite.</p>
<p>The finiteness of ES(n) can be states as follows: Given a sequence of N points in general position in the plane <img alt="x_1,x_2, \dots , x_N" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2Cx_2%2C+%5Cdots+%2C+x_N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,x_2, \dots , x_N"/>  there is a subsequence <img alt="1_i,x_2, \dots , x_n" class="latex" src="https://s0.wp.com/latex.php?latex=1_i%2Cx_2%2C+%5Cdots+%2C+x_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_i,x_2, \dots , x_n"/> such that the line segments <img alt="[x_i,x_k]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bx_i%2Cx_k%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[x_i,x_k]"/> and <img alt="[x_j,x_\ell ]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bx_j%2Cx_%5Cell+%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[x_j,x_\ell ]"/> intersect. With this statement, the Erdős and Szekeres’ theorem can be seen as identifying a universal set of points in term of its <em>Radon partitions </em>(or equivalently in term of its <em>order type</em>).</p>
<h3>In high dimensions</h3>
<p>In higher dimension we can define <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/> and replace “in convex position” by “in cyclic position”. The finiteness of <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/> (with terrible bounds) follows easily from various Ramsey results. In a series of papers very good lower and upper bounds where obtained:  <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Barany%2C+I">Imre Barany</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Matousek%2C+J">Jiri Matousek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Por%2C+A">Attila Por</a>: <a href="https://arxiv.org/abs/1309.1147">Curves in R^d intersecting every hyperplane at most d+1 times</a>;  <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eli%C3%A1%C5%A1%2C+M">Marek Eliáš</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Matou%C5%A1ek%2C+J">Jiří Matoušek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rold%C3%A1n-Pensado%2C+E">Edgardo Roldán-Pensado</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Safernov%C3%A1%2C+Z">Zuzana Safernová</a>:<a href="https://arxiv.org/abs/1307.5157"> Lower bounds on geometric Ramsey functions</a>; Marek Elias, Jiri Matousek: <a href="https://arxiv.org/abs/1111.3824">Higher-order Erdos–Szekeres theorems </a><a href="https://arxiv.org/abs/1111.3824">.</a></p>
<h3>Por’s result</h3>
<p>Por’s result can be seen as a far-reaching strengthening of the finiteness of <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/>.</p>
<h2>Further Discussion:</h2>
<h3>High order order types?</h3>
<p>Can you base a higher-order notion of “order types” on Tverberg partitions?</p>
<p>The <strong>order type</strong> of a sequence of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points affinely spanning <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/>, is the described by the vector of signs (0, 1 or -1) of volume of simplices described by subsequences of length <img alt="d+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+1"/>. Equivalently the order type can be described by the minimal Radon partitions of the points.</p>
<ol>
<li>We can first ask if we can base a notion of higher order types on Tverberg’s partitions to <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> parts where <img alt="r&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=r%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r&gt;2"/>.</li>
<li>Next we can ask for an associated notion of “highr order oriented matroids.” (Oriented matroids in the usual sense are abstract order types which coincide with Euclidean order types for every subsequence of <img alt="d+3" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+3"/> points.)</li>
<li>A natural question regarding these “higher order types is: If a sequence of points in strong general position is Tverberg-equivalent to stretched points on the moment curve, does it apply to all of its subsequences?</li>
</ol>
<p>Another way to consider “higher” order types is to enlarge the family by to start with a family of points add to it all Radon points of minimal Radon’s partition and consider the order type of the new configuration. (This operation can be repeated <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> times.) See <a href="https://link.springer.com/article/10.1007/BF00147418">this paper of Michael Kallay on points sets which contains their Radon points</a>.</p>
<h3>Staircase convexity order types</h3>
<p>Understanding order types of configuration of points on stretched grids of Bukh et al. is a very interesting problem. It is interesting to understand such configurations that are not in general position as well. (In particular, which matroids are supported on the stretched grid?) Of course, the method may well have many more application.</p>
<h3>Fantastically strong forms of Sierksma’s conjecture</h3>
<p>Is the following true: For every sequence <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> of <img alt="n=(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> there is a Sierksma’s configuration <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of $n$ points so that every Tverberg’s partition of  <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is a Tverberg’s partition of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>?</p>
<p>An even stronger version is:</p>
<p>Does every sequence <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> there is a tree-like simple hypergraphs so that all the rainbow coloring of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> correspond to Tverberg partitions of the sequence? If true this will be a fantastically strong version of Sierksma’s conjecture.</p>
<h3>Is the Erdős-Szekeres’ conjecture outrageous?</h3>
<p>Erdős and Szekeres proved in 1935 that <img alt="ES(n)\le {{2n-4}\choose{n-2}}+1=4^{n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29%5Cle+%7B%7B2n-4%7D%5Cchoose%7Bn-2%7D%7D%2B1%3D4%5E%7Bn-o%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n)\le {{2n-4}\choose{n-2}}+1=4^{n-o(n)}"/>, and in 1960, they showed that <img alt="ES(n) \ge 2^{n-2}+1" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29+%5Cge+2%5E%7Bn-2%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n) \ge 2^{n-2}+1"/>, and conjectured this to be optimal. Despite the efforts of many researchers, until recently no improvement in the order of magnitude has ever been made on the upper bound over  81 years. A  recent breakthrough result by Andrew Suk (Here are links<a href="http://arxiv.org/abs/1604.08657"> to the paper</a>, and to<a href="https://gilkalai.wordpress.com/2016/05/04/the-erdos-szekeres-polygon-problem-solved-asymptotically-by-andrew-suk/"> our post discussing the result</a>) asserts that <img alt="ES(n)=2^{n+o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29%3D2%5E%7Bn%2Bo%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n)=2^{n+o(n)}"/>. <a href="https://mathoverflow.net/questions/259844/the-most-outrageous-or-ridiculous-conjectures-in-mathematics">Sometime ago I asked over MO a question on outrageous mathematical conjectures</a> and perhaps the conjecture that  <img alt="ES(n) = 2^{n-2}+1" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29+%3D+2%5E%7Bn-2%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n) = 2^{n-2}+1"/> on the nose is an example.</p>
<h2>Original Abstracts</h2>
<p><span id="more-16238"/></p>
<p><strong><a href="https://arxiv.org/abs/1805.07197">Universality of vector sequences and universality of Tverberg partitions,</a> by Attila Por;</strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/abstract-por.png"><img alt="" class="alignnone size-full wp-image-16870" src="https://gilkalai.files.wordpress.com/2019/02/abstract-por.png?w=640"/></a></p>
<p class="title mathjax"><strong><a href="https://arxiv.org/abs/1611.01078">Classifying unavoidable Tverberg partitions</a>, by Boris Bukh, Po-Shen Loh, Gabriel Nivasch</strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/bln-abstract.png"><img alt="" class="alignnone size-full wp-image-16871" src="https://gilkalai.files.wordpress.com/2019/02/bln-abstract.png?w=640"/></a></p>
<p><strong><a href="https://arxiv.org/abs/1508.07262">On Tverberg partitions</a>, by Moshe White</strong></p>
<p> </p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/02/white-abstract.png"><img alt="" class="alignnone size-full wp-image-16872" src="https://gilkalai.files.wordpress.com/2019/02/white-abstract.png?w=640"/></a></h2></div>
    </content>
    <updated>2019-02-16T16:06:16Z</updated>
    <published>2019-02-16T16:06:16Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Attila Por"/>
    <category term="Boris Bukh"/>
    <category term="Gabriel Nivasch"/>
    <category term="Moshe White"/>
    <category term="Po-Shen Loh"/>
    <category term="Sierksma's conjecture"/>
    <category term="Staircase convexity"/>
    <category term="Tverberg's theorem"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-18T12:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/02/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Beware the Ides of February.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Beware the Ides of February.</p>

<ul>
  <li>
    <p>Holes and their reflections (<a href="https://mathstodon.xyz/@11011110/101517910934422997"/>). (The reflections are in the curved surface of an espresso portafilter.)</p>

    <p style="text-align: center;"><img alt="Holes and their reflections" src="https://www.ics.uci.edu/~eppstein/pix/reflected-holes/reflected-holes-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings">The 2019 Bridges mathematical art gallery is online!</a> (<a href="https://mathstodon.xyz/@11011110/101526999074315478"/>). <a href="https://twitter.com/bit_player/status/1086463227154915329">Brian Hayes lists</a> his favorites as being the <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/unsolvedmre">warped notepaper of Matt Enlow</a> and the <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/burkholderd">Penrose quilt of Douglas G. Burkholder</a>.</p>
  </li>
  <li>
    <p>Some of my own favorites from this year’s Bridges mathematical art gallery (<a href="https://mathstodon.xyz/@11011110/101530712079779913"/>): <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/fieldingbrown">Fielding Brown’s 3d Lissajous wood ribbon sculpture</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/ddavis">Diana Davis’s periodic pentagonal billiards patterns</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/stephen-kenney">Stephen Kenney’s illustration of triangle geometry</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/espaley">Elizabeth Paley’s stoneware Klein bottle</a>, and <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/anduriel-s-widmark">Anduriel Widmark’s knotted glasswork</a>.</p>
  </li>
  <li>
    <p><a href="https://www.radionz.co.nz/national/programmes/ourchangingworld/audio/2018667030/mathematician-wins-top-science-award">Rod Downey, a New Zealand-based theoretical computer scientist who co-founded the theory of parameterized complexity, has won the Rutherford Medal, New Zealand’s highest science award</a> (<a href="https://mathstodon.xyz/@11011110/101537786624226744"/>). Somehow I missed this when it came around last October.</p>
  </li>
  <li>
    <p><a href="http://ad-publications.informatik.uni-freiburg.de/ESA_experiment_Bast_2018.pdf">Hannah Bast’s slides on the European Symposium on Algorithms 2018 Track B experiment</a> (<a href="https://mathstodon.xyz/@11011110/101543698645665393"/>).  (two independent program committees decided on the same set of papers and then the conference accepted the union of their acceptances). Some conclusions: the initial scoring is remarkably consistent, and per-paper discussions to reconcile differences of scoring are useful, but the final decision on which “gray zone” papers to keep is random and could be replaced by a simple threshold.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/the-sum-product-problem-shows-how-addition-and-multiplication-constrain-each-other-20190206/"><em>Quanta</em> writes up recent progress</a> on the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szemer%C3%A9di_theorem">Erdős–Szemerédi sum-product problem</a>, that any set of numbers must either have many distinct pairwise sums or many distinct products (<a href="https://mathstodon.xyz/@11011110/101549376500085965"/>). Progress: “many” increased from  to .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/02/07/the-case-of-the-reviewer-who-said-cite-me-or-i-wont-recommend-acceptance-of-your-work/">How to handle journal referees who ask authors to add unjustified citations to their own papers?</a> (<a href="https://mathstodon.xyz/@11011110/101552010373686789"/>).  Is their misbehavior protected by the anonymity of peer review or can they be publicly named and shamed?</p>
  </li>
  <li>
    <p>The Cal Poly ag students have started selling these blood oranges at the local farmer’s market, as they do every year around this time, only $1 for five. In the summer they sell sweet corn on the cob. (<a href="https://mathstodon.xyz/@11011110/101557509103586528"/>).</p>

    <p style="text-align: center;"><img alt="Blood oranges" src="https://www.ics.uci.edu/~eppstein/pix/bloodoranges/bloodoranges-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/ancient-turing-pattern-builds-feathers-hair-and-now-shark-skin-20190102/">Turing patterns in shark skin</a> (<a href="https://mathstodon.xyz/@11011110/101570379158959818"/>, <a href="http://doi.org/10.1126/sciadv.aau5484">original paper</a>). Researchers at the University of Florida led by Gareth Fraser and his student Rory Cooper used reaction-diffusion patterns (also named <a href="https://en.wikipedia.org/wiki/Turing_pattern">Turing patterns</a> after Turing’s early work) to model the distribution of scales on sharks, and performed knockdown experiments to validate their model in vivo.</p>
  </li>
  <li>
    <p>Did you know that two different graphs with 81 vertices and 20 edges/vertex are famous enough to have Wikipedia articles? (<a href="https://mathstodon.xyz/@11011110/101578088028534617"/>).  The strongly regular <a href="https://en.wikipedia.org/wiki/Brouwer%E2%80%93Haemers_graph">Brouwer–Haemers graph</a> connects elements of GF(81) that differ by a fourth power. The <a href="https://en.wikipedia.org/wiki/Sudoku_graph">Sudoku graph</a> connects cells of a Sudoku grid that should be unequal. Sudoku puzzles are instances of precoloring extension on this graph. Unfortunately the natural graphs on the 81 cards of Set have degree ≠ 20…</p>
  </li>
  <li>
    <p><a href="http://joshmillard.com/sgmenger/">Josh “cortex” Millard describes how he made a stained glass Menger sponge</a> (<a href="https://mastodon.social/@joshmillard/101580889806746340"/>).</p>
  </li>
  <li>
    <p>Jacob Siehler labels cubic graphs with binary strings of length 5 so that all labels appear once and each vertex is the xor of its neighbors (<a href="https://mathstodon.xyz/@jsiehler/101586101859381152"/>). He can do three vertex-transitive 32-vertex graphs: the Dyck graph, an expansion of the vertices of  into four cycles, and another one I don’t know.</p>
  </li>
  <li>
    <p>Four of <a href="https://oeis.org/A248380/a248380.pdf">Conway’s five $1000-prize problems</a> remain unsolved (<a href="https://mathstodon.xyz/@11011110/101592412607547272"/>): the dead fly problem on spacing of <a href="https://en.wikipedia.org/wiki/Danzer_set">point sets that touch all large convex sets</a>, <a href="https://en.wikipedia.org/wiki/Conway%27s_99-graph_problem">existence of a 99-vertex graph</a> with each edge in a unique triangle and each non-edge the diagonal of a unique quadrilateral, the <a href="https://en.wikipedia.org/wiki/Thrackle">thrackle conjecture</a>, on graphs drawn so all edges cross once, and who wins <a href="https://en.wikipedia.org/wiki/Sylver_coinage">Sylver coinage</a> after move 16?</p>
  </li>
  <li>
    <p><a href="http://eecs.oregonstate.edu/socg19/accepted.html">The list of accepted papers</a> from this year’s Symposium on Computational Geometry just came out (<a href="https://mathstodon.xyz/@11011110/101600288486356446"/>).</p>
  </li>
</ul></div>
    </content>
    <updated>2019-02-15T10:45:00Z</updated>
    <published>2019-02-15T10:45:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-16T06:47:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16854</id>
    <link href="https://gilkalai.wordpress.com/2019/02/15/henry-cohn-abhinav-kumar-stephen-d-miller-danylo-radchenko-and-maryna-viazovska-universal-optimality-of-the-e8-and-leech-lattices-and-interpolation-formulas/" rel="alternate" type="text/html"/>
    <title>Henry Cohn, Abhinav Kumar, Stephen D. Miller, Danylo Radchenko, and Maryna Viazovska: Universal optimality of the E8 and Leech lattices and interpolation formulas</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Henry Cohn A follow up paper on the tight bounds for sphere packings in eight and 24 dimensions. (Thanks, again, Steve, for letting me know.) For the 2016 breakthroughs see this post, this post of John Baez, this article by Erica Klarreich on … <a href="https://gilkalai.wordpress.com/2019/02/15/henry-cohn-abhinav-kumar-stephen-d-miller-danylo-radchenko-and-maryna-viazovska-universal-optimality-of-the-e8-and-leech-lattices-and-interpolation-formulas/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/hlc.jpg"><img alt="" class="alignnone size-full wp-image-16863" height="641" src="https://gilkalai.files.wordpress.com/2019/02/hlc.jpg?w=640&amp;h=641" width="640"/></a></p>
<p><span style="color: #ff0000;"><strong>Henry Cohn</strong></span></p>
<p>A follow up paper on the tight bounds for sphere packings in eight and 24 dimensions. (Thanks, again, Steve, for letting me know.)</p>
<p>For the 2016 breakthroughs see <a href="https://gilkalai.wordpress.com/2016/03/23/a-breakthrough-by-maryna-viazovska-lead-to-the-long-awaited-solutions-for-the-densest-packing-problem-in-dimensions-8-and-24/">this post</a>,<a href="https://golem.ph.utexas.edu/category/2016/03/e8_is_the_best.html"> this post of John Baez</a>, this <a href="https://www.quantamagazine.org/20160330-sphere-packing-solved-in-higher-dimensions/">article by Erica Klarreich on Quanta Magazine, </a>and a Notices AMS article by  Henry Cohn   <a href="http://www.ams.org/publications/journals/notices/201702/rnoti-p102.pdf" rel="nofollow">A conceptual breakthrough in sphere packing</a>. See also, Henry Cohn’s 2010 paper <a href="https://arxiv.org/abs/1003.3053">Order and disorder in energy minimization</a>, and <a href="https://www.youtube.com/watch?v=8y-uqcyRZ1M">Maryna Viazovska’s ICM 2018 videotaped lecture.</a></p>
<h3>Henry Cohn, Abhinav Kumar, Stephen D. Miller, Danylo Radchenko, and Maryna Viazovska: <a href="https://arxiv.org/abs/1902.05438">Universal optimality of the E8 and Leech lattices and interpolation formulas</a></h3>
<p><strong>Abstract: </strong>We prove that the <img alt="E_8" class="latex" src="https://s0.wp.com/latex.php?latex=E_8&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_8"/> root lattice and the Leech lattice are universally optimal among point configurations in Euclidean spaces of dimensions 8 and 24, respectively. In other words, they minimize energy for every potential function that is a completely monotonic function of squared distance (for example, inverse power laws or Gaussians), which is a strong form of robustness not previously known for any configuration in more than one dimension. This theorem implies their recently shown optimality as sphere packings, and broadly generalizes it to allow for long-range interactions.</p>
<p>The proof uses sharp linear programming bounds for energy. To construct the optimal auxiliary functions used to attain these bounds, we prove a new interpolation theorem, which is of independent interest. It reconstructs a radial Schwartz function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> from the values and radial derivatives of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and its Fourier transform <img alt="\hat f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat+f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat f"/> at the radii √2π for integers <em>n ≥ 1</em> in <img alt="R^8" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E8&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^8"/> and <em>n ≥ 2</em> in <img alt="R^{24}" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E%7B24%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^{24}"/>. To prove this theorem, we construct an interpolation basis using integral transforms of quasimodular forms, generalizing Viazovska’s work on sphere packing and placing it in the context of a more conceptual theory.</p></div>
    </content>
    <updated>2019-02-15T07:17:39Z</updated>
    <published>2019-02-15T07:17:39Z</published>
    <category term="Algebra and Number Theory"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Abhinav Kumar"/>
    <category term="Danylo Radchenko"/>
    <category term="Henry Cohn"/>
    <category term="Maryna Viazovska"/>
    <category term="Sphere packing"/>
    <category term="sphere packing in 24 dimensions"/>
    <category term="sphere packing in eight dimensions"/>
    <category term="Stephen D. Miller"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-18T12:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=336</id>
    <link href="https://tcsplus.wordpress.com/2019/02/14/tcs-talk-wednesday-february-20th-sepehr-assadi-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 20th, Sepehr Assadi, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Sepehr Assadi from Princeton University will speak about “A Simple Sublinear-Time Algorithm for Counting Arbitrary Subgraphs via Edge Sampling” (abstract below). Please make sure you reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 20th at<br/>
1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European<br/>
Time, 18:00 UTC). <strong>Sepehr Assadi</strong> from Princeton University will speak about “<em>A Simple Sublinear-Time Algorithm for Counting Arbitrary Subgraphs via Edge Sampling</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In the subgraph counting problem, we are given a (large) graph <img alt="G(V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=G%28V%2C+E%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="G(V, E)"/> and a (small) graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> (e.g., a triangle), and the goal is to estimate the number of occurrences of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. Our focus in this talk is on designing sublinear-time algorithms for approximately computing number of occurrences of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/> in the setting where the algorithm is given query access to <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. This problem has been studied in several recent work which primarily focused on specific families of graphs H such as triangles, cliques, and stars. However, not much is known about approximate counting of arbitrary graphs <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in the literature. This is in sharp contrast to the closely related subgraph enumeration problem in which the goal is to list all copies of the subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. The AGM bound shows that the maximum number of occurrences of any arbitrary subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/> with <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=fff&amp;fg=444444&amp;s=0" title="m"/> edges is <img alt="O(m^{p(H)})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E%7Bp%28H%29%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(m^{p(H)})"/>, where <img alt="p(H)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28H%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="p(H)"/> is the fractional edge cover number of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>, and enumeration algorithms with matching runtime are known for every <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>.</p>
<p>In this talk, we bridge this gap between the subgraph counting and subgraph enumeration problems and present a simple sublinear-time algorithm that estimates the number of occurrences of any arbitrary graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>, denoted by <img alt="\#H" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%23H&amp;bg=fff&amp;fg=444444&amp;s=0" title="\#H"/>, to within a <img alt="(1 \pm \varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281+%5Cpm+%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(1 \pm \varepsilon)"/>-approximation factor with high probability in <img alt="O(m^{p(H)} /\#H)\cdot \text{poly}(\log n,1/\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E%7Bp%28H%29%7D+%2F%5C%23H%29%5Ccdot+%5Ctext%7Bpoly%7D%28%5Clog+n%2C1%2F%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(m^{p(H)} /\#H)\cdot \text{poly}(\log n,1/\varepsilon)"/> time. Our algorithm is allowed the standard set of queries for general graphs, namely degree queries, pair queries and neighbor queries, plus an additional edge-sample query that returns an edge chosen uniformly at random. The performance of our algorithm matches those of Eden et al. [FOCS 2015, STOC 2018] for counting triangles and cliques and extend them to all choices of subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> under the additional assumption of edge-sample queries. Our results are also applicable to the more general problem of database join size estimation problem and for this slightly more general problem achieve optimal bounds for every choice of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>.</p>
<p>Joint work with Michael Kapralov and Sanjeev Khanna.</p></blockquote></div>
    </content>
    <updated>2019-02-15T00:03:08Z</updated>
    <published>2019-02-15T00:03:08Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-02-18T12:21:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5151224614999297675</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5151224614999297675/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html" rel="alternate" type="text/html"/>
    <title>The iPhonification of Everything</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">So you've got an iPhone XS in Space Grey. Congrats, so do 20 million other people. Maybe you have different cases but otherwise the hardware in all these phones are virtually identical. Yet you can tell with a glance that this is your phone. You can personalize apps and other elements of the home screen. It's your calendar and email and music.<br/>
<br/>
What? You've dropped your phone over Niagara falls. Luckily you've backed up your data. So you go back to Apple and buy another Space Grey iPhone XS and restore your data. Physically it's a completely different phone but for all practical purposes it's though you still had the original phone. Your phone is not defined by the device but the data that resides on it.<br/>
<br/>
It's not just phones. I can log into Google on anyone's Chrome browser and it will feel like my machine.<br/>
<br/>
Now we've all heard about a future world where nobody owns cars and we get driven around in self-driving Ubers, Lyfts and Waymos. One argument against this world is that people feel connected to their cars and unwilling to commute in some generic vehicle. But one can also imagine the car knows who you are, knows how you like your music, your lighting, how you adjust your seats even how your car drives. It becomes your car. Maybe even has electronic bumper stickers that change to support your political party.<br/>
<br/>
You can imagine the same for hotel rooms, your office, maybe even your apartment. It won't replicate your dog (or will it?) but as we get define more by our data than our things, do our things matter at all?</div>
    </content>
    <updated>2019-02-14T12:52:00Z</updated>
    <published>2019-02-14T12:52:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-18T10:38:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4121</id>
    <link href="https://www.scottaaronson.com/blog/?p=4121" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4121#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4121" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Four updates</title>
    <summary xml:lang="en-US">A few weeks ago, I was at QIP’2019 in Boulder, CO. This week I was at SQuInT’2019 in Albuquerque, NM. There were lots of amazing talks—feel free to ask in the comments section. There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled Quantum Computing: Capabilities and Limits. I didn’t […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few weeks ago, I was at <a href="http://jila.colorado.edu/qip2019/">QIP’2019</a> in Boulder, CO.  This week I was at <a href="http://physics.unm.edu/SQuInT/2019/index.php">SQuInT’2019</a> in Albuquerque, NM.  There were lots of amazing talks—feel free to ask in the comments section.</p>



<p>There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled <a href="https://gigaom.com/2019/01/17/quantum-computing-capabilities-and-limits-an-interview-with-scott-aaronson/">Quantum Computing: Capabilities and Limits</a>.  I didn’t proofread the transcript and it has some errors in it, but hopefully the meaning comes through.  In other interview news, if you were interested in my podcast with Adam Ford in Melbourne but don’t like YouTube, Adam has helpfully prepared transcripts of the two longest segments: <a href="http://www.scifuture.org/the-ghost-in-the-quantum-turing-machine-scott-aaronson/">The Ghost in the Quantum Turing Machine</a> and <a href="http://www.scifuture.org/the-winding-road-to-quantum-supremacy-scott-aaronson/">The Winding Road to Quantum Supremacy</a>.</p>



<p>The <em>New York Times</em> ran an article entitled <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">The Hard Part of Computer Science? Getting Into Class</a>, about the surge in computer science majors all over the US, and the shortage of professors to teach them.  The article’s go-to example of a university where this is happening is UT Austin, and there’s extensive commentary from my department chair, Don Fussell.</p>



<p>The <a href="http://acm-stoc.org/stoc2019/STOC%202019%20accepted%20papers.html">STOC’2019 accepted papers list</a> is finally out.  Lots of cool stuff!</p></div>
    </content>
    <updated>2019-02-13T04:43:23Z</updated>
    <published>2019-02-13T04:43:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-13T04:44:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5768393804446188224</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5768393804446188224/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html" rel="alternate" type="text/html"/>
    <title>I think ze was confused  -- in favor of genderless pronouns</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You've probably heard the following:<br/>
<br/>
<br/>
               At first I didn't want to get an X but now that I have it, I can't imagine life without one.<br/>
<br/>
X could be telegraph, radio, TV, color TV, VCR, CD player, streaming, Netflix, Amazon prime, an uber account, Washer and Dryer, Car Phones (remember those), Cell Phones. If you go back in history  wrist watches or sun dials (or wrist-sun-dials!).<br/>
<br/>
This has happened to me recently though not with an object. I read an article someplace saying that ze can be used instead of he or she. It was referring to nonbinaries (using `they' never quite sounded right) but actually it would be great if this was a general genderless pronoun. I am not making a political statement here (although I doubt I have any readers who are against genderless pronouns).<br/>
<br/>
Once I came across the term ze I found places to use it and now I can't imagine not using it.<br/>
<br/>
In a recent article I wrote I needed to say that someone was probably confused, but I did not know their gender. I used<br/>
<br/>
                                                         Ze was probably confused<br/>
<br/>
which is much better than<br/>
<br/>
                                                         S/he was probably confused<br/>
<br/>
                                                         He or she was probably confused<br/>
<br/>
                                                         The student was probably confused<br/>
<br/>
                                                         They were probably confused.<br/>
<br/>
Note that the first two leave out nonbinaries.<br/>
<br/>
0) In the article I put in a footnote saying what ze meant. In the future I may not have to.<br/>
<br/>
1) Will ze catch on? This blog post is an attempt to hasten the practice.<br/>
<br/>
2) Is there a term for his/her that is non-gendered? If not then maybe zer.<br/>
<br/>
3) Will there be political pushback on this usage? If its phrased as a way to include nonbinaries than unfortunately yes. If its phrased as above as when you don't know the gender, what do you do, then no.<br/>
<br/>
4) Is <i> nonbinary </i>the correct term? If not then please politely correct me in the comments.<br/>
<br/>
5) Has Ms replaced Miss and Mrs?<br/>
<br/>
I have used the term ze several times since then- often when I get email from a student such that I can't tell from the first name what their gender is, and I need to forward the email, such as<br/>
<br/>
                   Ze wants to take honors discrete math but does not have the prerequisite, but<br/>
                   since ze placed in the top five in the math olympiad, we'll let zer take it.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-11T19:43:00Z</updated>
    <published>2019-02-11T19:43:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-18T10:38:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/</id>
    <link href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/" rel="alternate" type="text/html"/>
    <title>Parameterized Approximation Algorithms Workshop (PAAW) 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 8, 2019 Patras, Greece https://sites.google.com/site/aefeldmann/parameterized-approximation-algorithms-workshop-paaw-2019 Submission deadline: April 26, 2019 Registration deadline: April 30, 2019 The 2019 edition of the Parameterized Approximation Algorithms Workshop (PAAW) will take place as a satellite workshop of ICALP 2019 in Patras, Greece, on Monday July 8th 2019. — Topics of interest — – Parameterized approximation algorithms – Lossy … <a class="more-link" href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/">Continue reading <span class="screen-reader-text">Parameterized Approximation Algorithms Workshop (PAAW) 2019</span></a></div>
    </summary>
    <updated>2019-02-11T15:31:13Z</updated>
    <published>2019-02-11T15:31:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-18T12:21:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2137</id>
    <link href="http://bit-player.org/2019/divisive-factorials" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Divisive factorials!</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">The other day I was derailed by this tweet from Fermat’s Library: The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready … <a href="http://bit-player.org/2019/divisive-factorials">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other day I was derailed by this tweet from Fermat’s Library:</p>
<p><img alt="Inverse factorial tweet" border="0" class="aligncenter" height="385" src="http://bit-player.org/wp-content/uploads/2019/02/inverse-factorial-tweet.png" width="592"/></p>
<p class="undent">The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready sort of way. Since the multiplicative version of \(n!\) goes to infinity as \(n\) increases, the “divisive” version should go to zero. And \(\frac{n^2}{n!}\) does exactly that; the polynomial function \(n^2\) grows slower than the exponential function \(n!\) for large enough \(n\):</p>
<p>\[\frac{1}{1}, \frac{4}{2}, \frac{9}{6}, \frac{16}{24}, \frac{25}{120}, \frac{36}{720}, \frac{49}{5040}, \frac{64}{40320}, \frac{81}{362880}, \frac{100}{3628800}.\]</p>
<p class="undent">But why does the quotient take the particular form \(\frac{n^2}{n!}\)? Where does the \(n^2\) come from?</p>
<p>To answer that question, I had to revisit the long-ago trauma of learning to divide fractions, but I pushed through the pain. Proceeding from left to right through the formula in the tweet, we first get \(\frac{n}{n-1}\). Then, dividing that quantity by \(n-2\) yields</p>
<p>\[\cfrac{\frac{n}{n-1}}{n-2} = \frac{n}{(n-1)(n-2)}.\]</p>
<p class="undent">Continuing in the same way, we ultimately arrive at:</p>
<p>\[n \mathbin{/} (n-1) \mathbin{/} (n-2) \mathbin{/} (n-3) \mathbin{/} \cdots \mathbin{/} 1 = \frac{n}{(n-1) (n-2) (n-3) \cdots 1} = \frac{n}{(n-1)!}\]</p>
<p class="undent">To recover the tweet’s stated result of \(\frac{n^2}{n!}\), just multiply numerator and denominator by \(n\). (To my taste, however, \(\frac{n}{(n-1)!}\) is the more perspicuous expression.)</p>
<hr/>
<p>I am a card-carrying factorial fanboy. You can keep your fancy Fibonaccis; <em>this</em> is my favorite function. Every time I try out a new programming language, my first exercise is to write a few routines for calculating factorials. Over the years I have pondered several variations on the theme, such as replacing \(\times\) with \(+\) in the definition (which produces triangular numbers). But I don’t think I’ve ever before considered substituting \(\mathbin{/}\) for \(\times\). It’s messy. Because multiplication is commutative and associative, you can define \(n!\) simply as the product of all the integers from \(1\) through \(n\), without worrying about the order of the operations. With division, order can’t be ignored. In general, \(x \mathbin{/} y \ne y \mathbin{/}x\), and \((x \mathbin{/} y) \mathbin{/} z \ne x \mathbin{/} (y \mathbin{/} z)\).</p>
<p>The Fermat’s Library tweet puts the factors in descending order: \(n, n-1, n-2, \ldots, 1\). The most obvious alternative is the ascending sequence \(1, 2, 3, \ldots, n\). What happens if we define the divisive factorial as \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\)? Another visit to the schoolroom algorithm for dividing fractions yields this simple answer:</p>
<p>\[1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n = \frac{1}{2 \times 3 \times 4 \times \cdots \times n} = \frac{1}{n!}.\]</p>
<p class="undent">In other words, when we repeatedly divide while counting up from \(1\) to \(n\), the final quotient is the reciprocal of \(n!\).  (I wish I could put an exclamation point at the end of that sentence!) If you’re looking for a canonical answer to the question, “What do you get if you divide instead of multiplying in \(n!\)?” I would argue that \(\frac{1}{n!}\) is a better candidate than \(\frac{n}{(n - 1)!}\). Why not embrace the symmetry between \(n!\) and its inverse?</p>
<p>Of course there are many other ways to arrange the <em>n</em> integers in the set \(\{1 \ldots n\}\). How many ways? As it happens, \(n!\) of them! Thus it would seem there are \(n!\) distinct ways to define the divisive \(n!\) function. However, looking at the answers for the two permutations discussed above suggests there’s a simpler pattern at work. Whatever element of the sequence happens to come first winds up in the numerator of a big fraction, and the denominator is the product of all the other elements. As a result, there are really only \(n\) different outcomes—assuming we stick to performing the division operations from left to right. For any integer \(k\) between \(1\) and \(n\), putting \(k\) at the head of the queue creates a divisive \(n!\) equal to \(k\) divided by all the other factors. We can write this out as:</p>
<p>\[\cfrac{k}{\frac{n!}{k}}, \text{ which can be rearranged as } \frac{k^2}{n!}.\]</p>
<p class="undent">And thus we also solve the minor mystery of how \(\frac{n}{(n-1)!}\) became \(\frac{n^2}{n!}\) in the tweet.</p>
<p>It’s worth noting that all of these functions converge to zero as \(n\) goes to infinity. Asymptotically speaking, \(\frac{1^2}{n!}, \frac{2^2}{n!}, \ldots, \frac{n^2}{n!}\) are all alike.</p>
<hr/>
<p>Ta dah! Mission accomplished. Problem solved. Done and dusted. Now we know everything there is to know about divisive factorials, right?</p>
<p>Well, maybe there’s one more question. What does the computer say? If you take your favorite factorial algorithm, and do as the tweet suggests, replacing any appearance of the \(\times\) (or <code>*</code>) operator with <code>/</code>, what happens? Which of the \(n\) variants of divisive \(n!\) does the program produce?</p>
<p>Here’s <em>my</em> favorite algorithm for computing factorials, in the form of a <a href="https://julialang.org/">Julia</a> program:</p>
<pre class="language-julia"><code>function mul!(n)
    if n == 1
        return 1
    else
        return n * mul!(n - 1)
    end
end
</code></pre>
<p>This is the algorithm that has introduced generations of nerds to the concept of recursion. In narrative form it says: If \(n\) is \(1\), then \(mul!(n)\) is \(1\). Otherwise, evaluate the function \(mul!(n-1)\), then multiply the result by \(n\). You might ask what happens if \(n\) is zero or negative. You might ask, but please don’t. For present purposes, \(n \in \mathbb{N}\).Starting with any positive \(n\), the sequence of recursive calls must eventually bottom out with \(n = 1\).</p>
<p>The function can be written more tersely using Julia’s one-liner style of definition:.</p>
<pre class="language-julia"><code>mul!(n)  =  n == 1 ? 1 : n * mul!(n - 1)</code></pre>
<p>The right side of the assignment statement is a conditional expression, or ternary operator, which has the form <code>a ? b : c</code>. Here <code>a</code> is a boolean test clause, which must return a value of either <code>true</code> or <code>false</code>. If <code>a</code> is <code>true</code>, clause <code>b</code> is evaluated, and the result becomes the value of the entire expression. Otherwise clause <code>c</code> is evaluated.</p>
<p>Just to be sure I’ve got this right, here are the first 10 factorials, as calculated by this program:</p>
<pre class="language-julia"><code>[mul!(n) for n in 1:10]
10-element Array{Int64,1}:
       1
       2
       6
      24
     120
     720
    5040
   40320
  362880
 3628800</code></pre>
<p class="indent">Now let’s edit that definition and convert the single occurence of <code>*</code> to a <code>/</code>, leaving everything else (except the name of the function) unchanged.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n / div!(n - 1)</code></pre>
<p>And here’s what comes back when we run the program for values of \(n\) from \(1\) through \(20\):</p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]
20-element Array{Real,1}:
 1                 
 2.0               
 1.5               
 2.6666666666666665
 1.875             
 3.2               
 2.1875            
 3.657142857142857 
 2.4609375         
 4.063492063492063 
 2.70703125        
 4.432900432900433 
 2.9326171875      
 4.773892773892774 
 3.14208984375     
 5.092152292152292 
 3.338470458984375 
 5.391690662278897 
 3.523941040039063 
 5.675463855030418 </code></pre>
<p>Huh? That sure doesn’t look like it’s converging to zero—not as \(\frac{1}{n!}\) or as \(\frac{n}{n - 1}\). As a matter of fact, it doesn’t look like it’s going to converge at all. The graph below suggests the sequence is made up of two alternating components, both of which appear to be slowly growing toward infinity as well as diverging from one another.</p>
<p><img alt="Div" border="0" class="aligncenter" height="" src="http://bit-player.org/wp-content/uploads/2019/02/div.svg" width=""/></p>
<p class="indent">In trying to make sense of what we’re seeing here, it helps to change the output type of the <code>div!</code> function. Instead of applying the division operator <code>/</code>, which returns the quotient as a floating-point number, we can substitute the  <code>//</code> operator, which returns an exact rational quotient, reduced to lowest terms.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n // div!(n - 1)</code></pre>
<p class="undent">Here’s the sequence of values for <code>n in 1:20</code>:</p>
<pre class="language-julia"><code>20-element Array{Real,1}:
       1      
      2//1    
      3//2    
      8//3    
     15//8    
     16//5    
     35//16   
    128//35   
    315//128  
    256//63   
    693//256  
   1024//231  
   3003//1024 
   2048//429  
   6435//2048 
  32768//6435 
 109395//32768
  65536//12155
 230945//65536
 262144//46189 </code></pre>
<p>The list is full of curious patterns. It’s a double helix, with even numbers and odd numbers zigzagging in complementary strands. The even numbers are not just even; they are all powers of \(2\). Also, they appear in pairs—first in the numerator, then in the denominator—and their sequence is nondecreasing. But there are gaps; not all powers of \(2\) are present. The odd strand looks even more complicated, with various small prime factors flitting in and out of the numbers. (The primes <em>have</em> to be small—smaller than \(n\), anyway.)</p>
<p>This outcome took me by surprise. I had really expected to see a much tamer sequence, like those I worked out with pencil and paper. All those jagged, jitterbuggy ups and downs made no sense. Nor did the overall trend of unbounded growth in the ratio. How could you keep dividing and dividing, and wind up with bigger and bigger numbers?</p>
<p>At this point you may want to pause before reading on, and try to work out your own theory of where these zigzag numbers are coming from. If you need a hint, you can get a strong one—almost a spoiler—by looking up the sequence of numerators or the sequence of denominators in the <a href="http://oeis.org">Online Encyclopedia of Integer Sequences</a>.</p>
<hr/>
<p>Here’s another hint. A small edit to the <code>div!</code> program completely transforms the output. Just flip the final clause, changing <code>n // div!(n - 1)</code> into <code>div!(n - 1) // n</code>. </p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : div!(n - 1) // n</code></pre>
<p class="undent">Now the results look like this:</p>
<pre class="language-julia"><code>10-element Array{Real,1}:
  1                    
 1//2                  
 1//6                  
 1//24                 
 1//120                
 1//720                
 1//5040               
 1//40320              
 1//362880             
 1//3628800</code></pre>
<p>This is the inverse factorial function we’ve already seen, the series of quotients generated when you march left to right through an ascending sequence of divisors \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\). </p>
<p>It’s no surprise that flipping the final clause in the procedure alters the outcome. After all, we know that division is not commutative or associative. What’s not so easy to see is why the sequence of quotients generated by the original program takes that weird zigzag form. What mechanism is giving rise to those paired powers of 2 and the alternation of odd and even?</p>
<p>I have found that it’s easier to explain what’s going on in the zigzag sequence when I describe an iterative version of the procedure, rather than the recursive one. (This is an embarrassing admission for someone who has argued that recursive definitions are easier to reason about, but there you have it.) Here’s the program:</p>
<pre class="language-julia"><code>function div!_iter(n)
    q = 1
    for i in 1:n
        q = i // q
    end
    return q
end</code></pre>
<p>I submit that this looping procedure is operationally identical to the recursive function, in the sense that if <code>div!(n)</code> and <code>div!_iter(n)</code> both return a result for some positive integer <code>n</code>, it will always be the same result. Here’s my evidence: </p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]    [div!_iter(n) for n in 1:20]
            1                         1//1    
           2//1                       2//1    
           3//2                       3//2    
           8//3                       8//3    
          15//8                      15//8    
          16//5                      16//5    
          35//16                     35//16   
         128//35                    128//35   
         315//128                   315//128  
         256//63                    256//63   
         693//256                   693//256  
        1024//231                  1024//231  
        3003//1024                 3003//1024 
        2048//429                  2048//429  
        6435//2048                 6435//2048 
       32768//6435                32768//6435 
      109395//32768              109395//32768
       65536//12155               65536//12155
      230945//65536              230945//65536
      262144//46189              262144//46189</code></pre>
<p>To understand the process that gives rise to these numbers, consider the successive values of the variables \(i\) and \(q\) each time the loop is executed. Initially, \(i\) and \(q\) are both set to \(1\); hence, after the first passage through the loop, the statement <code>q = i // q</code> gives \(q\) the value \(\frac{1}{1}\). Next time around, \(i = 2\) and \(q = \frac{1}{1}\), so \(q\)’s new value is \(\frac{2}{1}\). On the third iteration, \(i = 3\) and \(q = \frac{2}{1}\), yielding \(\frac{i}{q} \rightarrow \frac{3}{2}\). If this is still confusing, try thinking of \(\frac{i}{q}\) as \(i \times \frac{1}{q}\). The crucial observation is that on every passage through the loop, \(q\) is inverted, becoming \(\frac{1}{q}\).</p>
<p>If you unwind these operations, and look at the multiplications and divisions that go into each element of the series, a pattern emerges:</p>
<p>\[\frac{1}{1}, \quad \frac{2}{1}, \quad \frac{1 \cdot 3}{2}, \quad \frac{2 \cdot 4}{1 \cdot 3}, \quad \frac{1 \cdot 3 \cdot 5}{2 \cdot 4} \quad \frac{2 \cdot 4 \cdot 6}{1 \cdot 3 \cdot 5}\]</p>
<p class="undent">The general form is:</p>
<p>\[\frac{1 \cdot 3 \cdot 5 \cdot \cdots \cdot n}{2 \cdot 4 \cdot \cdots \cdot (n-1)} \quad (\text{odd } n) \qquad  \frac{2 \cdot 4 \cdot 6 \cdot \cdots \cdot n}{1 \cdot 3 \cdot 5 \cdot \cdots \cdot (n-1)} \quad (\text{even } n).<br/>
\]</p>
<hr/>
<p>The functions \(1 \cdot 3 \cdot 5 \cdot \cdots \cdot n\) for odd \(n\) and \(2 \cdot 4 \cdot 6 \cdot \cdots \cdot n\) for even \(n\) have a name! They are known as double factorials, with the notation \(n!!\). Terrible terminology, no? Better to have named them “semi-factorials.” And if I didn’t know better, I would read \(n!!\) as “the factorial of the factorial.” The double factorial of <em>n</em> is defined as the product of <em>n</em> and all smaller positive integers of the same parity. Thus our peculiar sequence of zigzag quotients is simply \(\frac{n!!}{(n-1)!!}\).</p>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.4169/math.mag.85.3.177">2012 article</a> by Henry W. Gould and Jocelyn Quaintance (behind a paywall, regrettably) surveys the applications of double factorials. They turn up more often than you might guess. In the middle of the 17th century John Wallis came up with this identity:</p>
<p>\[\frac{\pi}{2} = \frac{2 \cdot 2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdots}{1 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdots} = \lim_{n \rightarrow \infty} \frac{((2n)!!)^2}{(2n + 1)!!(2n - 1)!!}\]</p>
<p class="undent">An even weirder series, involving the cube of a quotient of double factorials, sums to \(\frac{2}{\pi}\). That one was discovered by (who else?) Srinivasa Ramanujan.</p>
<p>Gould and Quaintance also discuss the double factorial counterpart of binomial coefficients. The standard binomial coefficient is defined as:</p>
<p>\[\binom{n}{k} = \frac{n!}{k! (n-k)!}.\]</p>
<p class="undent">The double version is:</p>
<p>\[\left(\!\binom{n}{k}\!\right) = \frac{n!!}{k!! (n-k)!!}.\]</p>
<p class="undent">Note that our zigzag numbers fit this description and therefore qualify as double factorial binomial coefficients. Specifically, they are the numbers:</p>
<p>\[\left(\!\binom{n}{1}\!\right) = \left(\!\binom{n}{n - 1}\!\right) = \frac{n!!}{1!! (n-1)!!}.\]</p>
<p class="undent">The regular binomial \(\binom{n}{1}\) is not very interesting; it is simply equal to \(n\). But the doubled version \(\left(\!\binom{n}{1}\!\right)\), as we’ve seen, dances a livelier jig. And, unlike the single binomial, it is not always an integer. (The only integer values are \(1\) and \(2\).)</p>
<p>Seeing the zigzag numbers as ratios of double factorials explains quite a few of their properties, starting with the alternation of evens and odds. We can also see why all the even numbers in the sequence are powers of 2. Consider the case of \(n = 6\). The numerator of this fraction is \(2 \cdot 4 \cdot 6 = 48\), which acquires a factor of \(3\) from the \(6\). But the denominator is \(1 \cdot 3 \cdot 5 = 15\). The \(3\)s above and below cancel, leaving \(\frac{16}{5}\). Such cancelations will happen in every case. Whenever an odd factor \(m\) enters the even sequence, it must do so in the form \(2 \cdot m\), but at that point \(m\) itself must already be present in the odd sequence.</p>
<hr/>
<p>Is the sequence of zigzag numbers a reasonable answer to the question, “What happens when you divide instead of multiply in \(n!\)?” Or is the computer program that generates them just a buggy algorithm? My personal judgment is that \(\frac{1}{n!}\) is a more intuitive answer, but \(\frac{n!!}{(n - 1)!!}\) is more interesting.</p>
<p>Furthermore, the mere existence of the zigzag sequence broadens our horizons. As noted above, if you insist that the division algorithm must always chug along the list of \(n\) factors in order, at each stop dividing the number on the left by the number on the right, then there are only \(n\) possible outcomes, and they all look much alike. But the zigzag solution suggests wilder possibilities. We can formulate the task as follows. Take the set of factors \(\{1 \dots n\}\), select a subset, and invert all the elements of that subset; now multiply all the factors, both the inverted and the upright ones. If the inverted subset is empty, the result is the ordinary factorial \(n!\). If <em>all</em> of the factors are inverted, we get the inverse \(\frac{1}{n!}\). And if every second factor is inverted, starting with \(n - 1\), the result is an element of the zigzag sequence.</p>
<p>These are only a few among the many possible choices; in total there are \(2^n\) subsets of \(n\) items. For example, you might invert every number that is prime or a power of a prime \((2, 3, 4, 5, 7, 8, 9, 11, \dots)\). For small \(n\), the result jumps around but remains consistently less than \(1\):</p>
<p><img alt="Prime powers" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/prime-powers.svg" width=""/></p>
<p class="undent">If I were to continue this plot to larger \(n\), however, it would take off for the stratosphere. Prime powers get sparse farther out on the number line.</p>
<hr/>
<p>Here’s a question. We’ve seen factorial variants that go to zero as \(n\) goes to infinity, such as \(1/n!\). We’ve seen other variants grow without bound as \(n\) increases, including \(n!\) itself, and the zigzag numbers. Are there any versions of the factorial process that converge to a finite bound other than zero?</p>
<p>My first thought was this algorithm:</p>
<pre class="language-julia"><code>function greedy_balance(n)
    q = 1
    while n &gt; 0
        q = q &gt; 1 ? q /= n : q *= n
        n -= 1
    end
    return q
end</code></pre>
<p class="undent">We loop through the integers from \(n\) down to \(1\), calculating the running product/quotient \(q\) as we go. At each step, if the current value of \(q\) is greater than \(1\), we divide by the next factor; otherwise, we multiply. This scheme implements a kind of feedback control or target-seeking behavior. If \(q\) gets too large, we reduce it; too small and we increase it. I conjectured that as \(n\) goes to infinity, \(q\) would settle into an ever-narrower range of values near \(1\).</p>
<p>Running the experiment gave me another surprise:</p>
<p><img alt="Greedy balance linear" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance_linear.svg" width=""/></p>
<p class="undent">That sawtooth wave is not quite what I expected. One minor peculiarity is that the curve is not symmetric around \(1\); the excursions above have higher amplitude than those below. But this distortion is more visual than mathematical. Because \(q\) is a ratio, the distance from \(1\) to \(10\) is the same as the distance from \(1\) to \(\frac{1}{10}\), but it doesn’t look that way on a linear scale. The remedy is to plot the log of the ratio:</p>
<p><img alt="Greedy balance" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance.svg" width=""/></p>
<p>Now the graph is symmetric, or at least approximately so, centered on \(0\), which is the logarithm of \(1\). But a larger mystery remains. The sawtooth waveform is very regular, with a period of \(4\), and it shows no obvious signs of shrinking toward the expected limiting value of \(\log q = 0\). Numerical evidence suggests that as \(n\) goes to infinity the peaks of this curve converge on a value just above \(q = \frac{5}{3}\), and the troughs approach a value just below \(q = \frac{3}{5}\). (The corresponding base-\(10\) logarithms are roughly \(\pm0.222\). I have not worked out why this should be so. Perhaps someone will explain it to me.</p>
<p>The failure of this greedy algorithm doesn’t mean we can’t find a divisive factorial that converges to \(q = 1\). If we work with the logarithms of the factors, this procedure becomes an instance of a well-known compu­tational problem called the number partitioning problem. You are given a set of real numbers and asked to divide it into two sets whose sums are equal, or as close to equal as possible. It’s a certifiably hard problem, but it has also been called (<a href="http://bit-player.org/bph-publications/AmSci-2002-03-Hayes-NPP.pdf">PDF</a>) “the easiest hard problem.”For any given \(n\), we might find that inverting some other subset of the factors gives a better approximation to \(n! = 1\). For small \(n\), we can solve the problem by brute force: Just look at all \(2^n\) subsets and pick the best one.</p>
<p>I have computed the optimal partitionings up to \(n = 30\), where there are a billion possibilities to choose from.</p>
<p><img alt="Optimum balance graph" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/optimum_balance_graph.svg" width=""/></p>
<p class="undent">The graph is clearly flatlining. You could use the same method to force convergence to any other value between \(0\) and \(n!\).</p>
<p>And thus we have yet another answer to the question in the tweet that launched this adventure. What happens when you divide instead of multiply in n!? Anything you want.</p></div>
    </content>
    <updated>2019-02-10T08:48:33Z</updated>
    <published>2019-02-10T08:48:33Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2019-02-10T20:48:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra</id>
    <link href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html" rel="alternate" type="text/html"/>
    <title>Big convex polyhedra in grids</title>
    <summary>I recently wrote here about big convex polygons in grids, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl">2</a></sup> <sup id="fnref:bd"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img alt="Truncated rhombicuboctahedron" src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png"/></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? An easy construction for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh">6</a></sup>
It is never worse to use the convex hull of the ball than the points on a sphere,
and a celebrated paper by Elkin from 2011 (in the appendix of the published version) gives another proof of the  bound for convex hulls of balls (for ) in which the constant factor of the  is universal, not depending on . So when  is singly exponential in ,  becomes constant and the convex hull technique produces  vertices, improving Behrend’s construction for progression-free sets by the same  factor.<sup id="fnref:elk"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk">7</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. The paragraph describing Elkin’s results was updated from an earlier more tentative version in the original post. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-09T15:07:00Z</updated>
    <published>2019-02-09T15:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-16T06:47:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1087</id>
    <link href="https://ptreview.sublinear.info/?p=1087" rel="alternate" type="text/html"/>
    <title>News for January 2019</title>
    <summary>Minimax Testing of Identity to a Reference Ergodic Markov Chain, by Geoffrey Wolfer and Aryeh Kontorovich (arXiv). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by Daskalakis, Dikkala, and Gravin: we wish to test whether a Markov chain is equal to some reference chain, or far from […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>
    </content>
    <updated>2019-02-08T18:30:54Z</updated>
    <published>2019-02-08T18:30:54Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-02-17T23:27:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3379</id>
    <link href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/" rel="alternate" type="text/html"/>
    <title>ACM SIGecom Elections</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The following message just went out to ACM SIGecom members: ———- Forwarded message ——— From: Monique Chang &lt;chang@hq.acm.org&gt; Date: Mon, Feb 4, 2019 at 2:20 PM Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement To: &lt;SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org&gt; Dear ACM SIGecom Member, The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election. Chair … … <a href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br/>
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br/>
Date: Mon, Feb 4, 2019 at 2:20 PM<br/>
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br/>
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br/>
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>
    </content>
    <updated>2019-02-08T02:44:19Z</updated>
    <published>2019-02-08T02:44:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-02-18T12:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-18T12:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-18T12:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-18T10:38:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-18T12:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15634</id>
    <link href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/" rel="alternate" type="text/html"/>
    <title>An Old But Cool Result</title>
    <summary>Solving a type of Fermat Equation Leo Moser was a mathematician who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge numbers. Today I want to talk about one of his results with a very short proof. No, it is not about […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><p>
<font color="#0044cc"><br/>
<em>Solving a type of Fermat Equation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/unknown-117/" rel="attachment wp-att-15639"><img alt="" class="alignright size-full wp-image-15639" src="https://rjlipton.files.wordpress.com/2019/02/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"/></td>
</tr>
</tbody>
</table>
<p>
Leo Moser was a <a href="https://en.wikipedia.org/wiki/Leo_Moser">mathematician</a> who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge <a href="https://en.wikipedia.org/wiki/Steinhaus-Moser_notation">numbers</a>.</p>
<p>
Today I want to talk about one of his results with a very short proof.</p>
<p>
No, it is not about worms. That is a <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">question</a> in discrete geometry that is still open I believe: “What is the region of smallest area which can accommodate every planar arc of length one?” The region must be able to hold the arc inside but the curve can be moved and rotated to allow it to fit. A disk of diameter <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> works and has area about <img alt="{ 0.78}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.78%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.78}"/>. It is possible to do much better and get around <img alt="{ 0.27}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+0.27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ 0.27}"/>. </p>
<p><a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/worm3/" rel="attachment wp-att-15636"><img alt="" class="aligncenter size-medium wp-image-15636" height="143" src="https://rjlipton.files.wordpress.com/2019/02/worm3.png?w=300&amp;h=143" width="300"/></a></p>
<p>See this <a href="https://www.nada.kth.se/~johanh/snakes.pdf">paper</a> for some additional details.</p>
<p>
No, it is not about a conjecture of Paul Erdős See <a href="https://arxiv.org/pdf/1011.2956.pdf">this</a> for a great paper on this result: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that 	</em></p><em>
<p align="center"><img alt="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%5E%7Bk%7D+%2B+2%5E%7Bk%7D+%2B+%5Ccdots+%2B+%28m-1%29%5E%7Bk%7D+%3D+m%5E%7Bk%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. "/></p>
<p>Then any <img alt="{(m,k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28m%2Ck%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{(m,k)}"/> solution in integers with <img alt="{k \ge 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cge+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k \ge 2}"/> must have 	</p>
<p align="center"><img alt="\displaystyle  m &gt; 10^{10^{6}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m+%3E+10%5E%7B10%5E%7B6%7D%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  m &gt; 10^{10^{6}}. "/></p>
</em><p><em/>
</p></blockquote>
<p>Erdős conjectured there are no solutions at all. It is easy to check that for <img alt="{k=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1}"/> the unique solution is a bit smaller: 	</p>
<p align="center"><img alt="\displaystyle  1 + 2 = 3." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%2B+2+%3D+3.&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 + 2 = 3."/></p>
<p>
</p><p/><h2> The Result </h2><p/>
<p/><p>
Yes, it is about the solution to a natural family of Diophantine equations. This result of Moser comes from an old paper of his. The result can be found on the wonderful blog called <a href="https://www.cut-the-knot.org/arithmetic/algebra/TwoParameterFermat.shtml">cut-the-knot</a> written by Alexander Bogomolny.</p>
<p>
The question considered by Moser is simple to state: </p>
<blockquote><p><b> </b> <em> Consider the equation over the integers <img alt="{x^{a} + y^{b} = z^{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} = z^{c}}"/> where <img alt="{a, b, c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2C+b%2C+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a, b, c}"/> are fixed values that are relatively prime. Show that there are infinitely many integer solutions. </em>
</p></blockquote>
<p/><p>
The surprise, to me, is that this equation always has integer solutions. I thought about it for a bit and had no idea how to even start.</p>
<p>
The solution is as follows. The initial insight is that the restriction on the exponents implies that there are integers <img alt="{m, n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m, n}"/> so that <img alt="{abm + 1 = cn}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Babm+%2B+1+%3D+cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{abm + 1 = cn}"/>. </p>
<p>
Wait a minute. We must be careful by what we mean by “the values of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> are relatively prime.” We need more than the greatest common divisor (GCD) of <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c}"/> is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We need that <img alt="{ab}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bab%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ab}"/> and <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> are relatively prime. Note that <img alt="{6,10,15}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2C10%2C15%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6,10,15}"/> have GCD equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> but no matter which of the triple is “<img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/>” we cannot find the needed <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/>: 	</p>
<p align="center"><img alt="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%286%5Ccdot+10%2C15%29+%3E+1%2C+%2810%5Ccdot+15%2C+6%29%3E1%2C+%2815%2C6+%5Ccdot+10%29+%3E+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. "/></p>
<p>I thank Subrahmanyam Kalyanasundaram for catching this.</p>
<p>
The next idea is not to look for a single set of solutions but rather to find a parametrized solution. That is try to find expressions for <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/> that depend on some variables <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> so that for all <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> the equation is satisfied. </p>
<p>
Then set 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. "/></p>
<p>Note as <img alt="{u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v}"/> vary over integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> vary over integers too. The claim is that this is a parameterization of the equation. Let’s see why. We need to figure out what <img alt="{x^{a} + y^{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b}}"/> is equal to. It looks a bit nasty but it is not. Let <img alt="{W = u^{abm} + v^{abm}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BW+%3D+u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{W = u^{abm} + v^{abm}}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  x = u^{bm}W^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7DW%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = u^{bm}W^{bm}. "/></p>
<p align="center"><img alt="\displaystyle  y = v^{am}W^{am}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7DW%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y = v^{am}W^{am}. "/></p>
<p>So <img alt="{x^{a} + y^{b} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{a} + y^{b} }"/> is 	</p>
<p align="center"><img alt="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u%5E%7Babm%7D+W%5E%7Babm%7D+%2B+v%5E%7Babm%7DW%5E%7Babm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. "/></p>
<p>Which magically is 	</p>
<p align="center"><img alt="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++W%5E%7Babm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29+%3D+W%5E%7Babm%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. "/></p>
<p>Thus setting 	</p>
<p align="center"><img alt="\displaystyle  z = W^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z+%3D+W%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  z = W^{n} "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+W%5E%7Babm%2B1%7D+%3D+W%5E%7Bcn%7D+%3D+%28W%5E%7Bn%7D%29%5E%7Bc%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. "/></p>
<p>Very neat. By the way we do need to note that as <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> run through integers the values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> and <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> vary enough to get an infinite number of solutions. A simple growth argument shows that this is true.</p>
<p>
The key trick was to <b>not</b> use a standard idea and apply the binomial theorem and expand 	</p>
<p align="center"><img alt="\displaystyle  (u^{abm} + v^{abm})^{bm}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (u^{abm} + v^{abm})^{bm}. "/></p>
<p>My algebra DNA suggests that expanding such an expression is often a good idea. Here it would lead to a mess. This is a case where using the binomial expansion does not work.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I really like Moser’s clever solution to the diophantine equation 	</p>
<p align="center"><img alt="\displaystyle  x^{a} + y^{b} = z^{c}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{a} + y^{b} = z^{c}. "/></p>
<p>Note that it must fail when <img alt="{a=b=c=p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=p}"/> for <img alt="{p&gt;2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;2}"/> by the famous solution to the original Fermat equation. </p></font></font></div>
    </content>
    <updated>2019-02-06T12:57:11Z</updated>
    <published>2019-02-06T12:57:11Z</published>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="Fermat"/>
    <category term="worm problem"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-18T12:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1062</id>
    <link href="http://corner.mimuw.edu.pl/?p=1062" rel="alternate" type="text/html"/>
    <title>HALG 2019 - Call For Submissions of Short Contributed Presentations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a … <a href="http://corner.mimuw.edu.pl/?p=1062">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a different venue or journal (or to be submitted there) is welcome.</p>
<p>If you would like to present your results at HALG 2019, please submit their details the abstract of the talk or the contribution of the poster via EasyChair: <a href="https://easychair.org/conferences/?conf=halg2019" rel="noopener noreferrer" target="_blank">https://easychair.org/conferences/?conf=halg2019</a></p>
<p>The abstract should include (when relevant) information where the results have been published/accepted (e.g., conference), and where they are publicly available (e.g., arXiv). All submissions will be reviewed by the program committee, giving priority to new work not formally published yet, and to papers published in 2018 or later.</p>
<p>Submissions deadline: March 15th, 2019.<br/>
Late submissions will be accepted subject to space constraints.</p></div>
    </content>
    <updated>2019-02-06T11:41:10Z</updated>
    <published>2019-02-06T11:41:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-02-17T23:26:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=92</id>
    <link href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/" rel="alternate" type="text/html"/>
    <title>Extremal Combinatorics V: POSETS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the remaining post V on partially ordered sets of my series on extremal combinatorics (I,II,III,IV,VI).  We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting … <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img alt="C \subset P" class="latex" src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C \subset P"/> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and an antichain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> set can be covered by <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains.</p>
<p>(By the immediate lemma, at least <img alt="a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P)"/> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordered sets can be covered by <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains.</p>
<p>(By the immediate lemma, at least <img alt="c(P)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c(P)"/> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img alt="A_1=MIN(P)" class="latex" src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_1=MIN(P)"/> of minimal elements of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is an antichain. Let <img alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))"/>. We need two easy observations. First, <img alt="A_k is an antichain" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k is an antichain"/> and second: If <img alt="A_k \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k \ne \emptyset"/> then there is a chain with one element from <img alt="A_i: 1 \le i\le k" class="latex" src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i: 1 \le i\le k"/>. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth’s theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> or <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/>. In this case you consider a chain with one element in <img alt="MAX(P)" class="latex" src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MAX(P)"/> and one element in <img alt="MIN (P)" class="latex" src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="MIN (P)"/> and delete these elements from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For the resulting post <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/>, <img alt="a(Q)=a(P)-1" class="latex" src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(Q)=a(P)-1"/> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of maximum size <img alt="t=a(P)" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a(P)"/> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{a_1,a_2,\dots,a_t\}"/>. Let <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are larger or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, and let <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> be the set of elements in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which are smaller or equal some element in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>
<p>Now,</p>
<ol>
<li><img alt="P^+ \cup P^-=P" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cup P^-=P"/>. Otherwise we could add an element to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to form a larger antichain.</li>
<li><img alt="P^+ \cap P^- = A" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+ \cap P^- = A"/>. Otherwise, there will be two elements of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img alt="P^+" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^+"/> can be covered by <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^+, C_2^+, \dots, C_t^+"/> and <img alt="P^-" class="latex" src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P^-"/> can be covered by <img alt="a(P" class="latex" src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P"/>$ chains <img alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1^-, C_2^-, \dots, C_t^-"/>. Bu re-indexing we can assume that both <img alt="C_i^+" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^+"/> and <img alt="C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i^-"/> contains <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>. It follows that <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img alt="C_i=:C_i^+ \cup C_i^-" class="latex" src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i=:C_i^+ \cup C_i^-"/> is a chain. The <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> chains <img alt="C_1, C_2, \dots, C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1, C_2, \dots, C_t"/> cover <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img alt="a(P) c(P) \ge |P|." class="latex" src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a(P) c(P) \ge |P|."/></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img alt="n=ab+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=ab+1"/> then every sequence <img alt="a_1,a_2,\dots ,a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_n"/> of different real numbers contains a monotone increasing sequence of length <img alt="a+1" class="latex" src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a+1"/> or a monotone decreasing sequence of length <img alt="b+1" class="latex" src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b+1"/>.</p>
<p>There are simple proofs. For example, associate to every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> a pair <img alt="(I_k,D_k)" class="latex" src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(I_k,D_k)"/> of integers where  <img alt="I_k" class="latex" src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_k"/> is the maximum length of the increasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/> and <img alt="D_k" class="latex" src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_k"/> is the maximum length of the deccreasing subsequence starting with <img alt="a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k"/>. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual imply easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img alt="i &lt; k" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; k"/> if both <img alt="i&lt;k" class="latex" src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i&lt;k"/> and <img alt="a_i &lt; a_k" class="latex" src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i &lt; a_k"/>.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements set is <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/>. By Dilworth’s theorem it follows that we can cover all sets by <img alt="{{n} \choose {[n/2]}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{{n} \choose {[n/2]}}"/> chains (and, of course when we exhibit such a covering it reproves Sperner’s theorem). A symmetric saturated chain decomposition is a partition of <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/> (=all subsets of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/>) to saturated chains where each chain has, for some <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> for each chain <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/> create a new chain <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> by adding the element <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> to every set. And then move the top set in <img alt="C'_i" class="latex" src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'_i"/> to <img alt="C_i" class="latex" src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_i"/>.  <strong>Walla!</strong></p>
<p>This is the beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img alt="P(n)" class="latex" src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P(n)"/>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img alt="" class="alignnone size-full wp-image-16834" height="489" src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img alt="a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_k(P)"/> be the maximum size of the union <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> antichains in a poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>. For every chain For every chain <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> we have <img alt="|C \cap X| \le \min\{|C|,k\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|C \cap X| \le \min\{|C|,k\}"/>. Therefore for a partition of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> to chains <img alt="C_1,C_2,\dots,C_t" class="latex" src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1,C_2,\dots,C_t"/> we   have <img alt="\sum\min\{|C_i|,k\ge |X|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\ge |X|"/>. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there is always  a decomposition into chains with <img alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum\min\{|C_i|,k\}=a_k(P)"/>.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that shows that these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img alt="" class="alignnone size-full wp-image-16832" height="239" src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  are some beautiful and important theorems on posets. An order ideas <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of a post is a set of elements so that if <img alt="x in I" class="latex" src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x in I"/> and <img alt="y &lt; x" class="latex" src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y &lt; x"/> then <img alt="y \in I" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in I"/>.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> there is an element which is contained in more than δ and less than 1-δ order ideas of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> which is not a chain there are two incomparable elements <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> such that the number of linear extensions of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> for which <img alt="x&lt;y" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x&lt;y"/> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem and gives a weaker constant <img alt="1/2e" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2e"/> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> the maximum antichain is of size <img alt="o(|L|)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(|L|)"/>. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img alt="\{x,y\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{x,y\}"/> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> is a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-05T11:18:54Z</updated>
    <published>2019-02-05T11:18:54Z</published>
    <category term="Combinatorics"/>
    <category term="Claude Berge"/>
    <category term="Curtis Greene"/>
    <category term="Daniel Kleitman"/>
    <category term="Dilworth's theorem"/>
    <category term="Extremal combinatorics"/>
    <category term="Jeff Kahn"/>
    <category term="Laci Lovasz"/>
    <category term="Mike Saks"/>
    <category term="Nati Linial"/>
    <category term="Posets"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-18T12:20:50Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8542550481798271953</id>
    <link href="http://processalgebra.blogspot.com/feeds/8542550481798271953/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8542550481798271953" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8542550481798271953" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/two-awards-at-hicss19-for-csgssi.html" rel="alternate" type="text/html"/>
    <title>Two awards at HICSS’19 for CS@GSSI student Roberto Verdecchia</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><div><a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, a third-year Ph.D. student of the Gran Sasso Science Institute (GSSI) and the Vrije Universiteit Amsterdam (VU) has received two distinct prizes at the 52nd Hawaii International Conference on System Sciences (HICSS’19;<span> </span><a href="http://hicss.hawaii.edu/" style="color: #1155cc;" target="_blank">http://hicss.hawaii.edu/</a>) for his research paper “<a href="https://robertoverdecchia.github.io/papers/HICSS_2019.pdf" style="color: #1155cc;" target="_blank">DecidArch: Playing Cards as Software Architects</a>”, which is <span style="font-family: Helvetica; font-size: 12px;">co-authored with</span><i style="font-family: Helvetica; font-size: 12px;"> </i>Patricia Lago, Jia F. Cai (both at VU Amsterdam), Remco C. de Boer (ArchiXL) and Philippe Kruchten (University of British Columbia). Out of over 780 papers presented at HICCS within 11 different research tracks, the study was presented with the “Best Paper award” of the Software Education and Training track. Additionally, the article was also selected as one of the five “ISSIP-IBM-CBA Student Paper Award for Best Industry Studies Paper” of HICCS’19.</div><div><br/>The study presents a novel educational game conceived to train students and practitioners in concepts related to software architecture and decision making. The game is currently used as an interactive session of the course “Software Architecture”, taught at the Vrije Universiteit Amsterdam.<br/><br/>The two prizes were adjudicated independently by two distinct committees.</div><div> </div><div>Congratulations to Roberto!</div><div><br/></div><div>Let me close by adding that I expect that Roberto will deliver his PhD thesis in the autumn 2019 and will soon be on the job market. If you have a postdoc or tenure-track  position in SE, keep him mind. </div></div></div>
    </content>
    <updated>2019-02-05T08:58:00Z</updated>
    <published>2019-02-05T08:58:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-18T11:29:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4206</id>
    <link href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！ Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="8cxnLMGdi" class="alignnone size-full wp-image-4207" src="https://lucatrevisan.files.wordpress.com/2019/02/8cxnlmgdi.png?w=584"/></p>
<p>新年快乐！</p></div>
    </content>
    <updated>2019-02-05T06:45:35Z</updated>
    <published>2019-02-05T06:45:35Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-02-18T12:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4122</id>
    <link href="https://www.scottaaronson.com/blog/?p=4122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sabineblogging</title>
    <summary xml:lang="en-US">I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including Sabine Hossenfelder’s New York Times column arguing that we shouldn’t.  (See also the responses by Jeremy Bernstein and Lisa Randall, and the discussion on Peter Woit’s blog, and Daniel Harlow’s Facebook thread, and this Vox […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including <a href="https://www.nytimes.com/2019/01/23/opinion/particle-physics-large-hadron-collider.html">Sabine Hossenfelder’s <em>New York Times</em> column</a> arguing that we shouldn’t.  (See also the <a href="https://www.nytimes.com/2019/02/01/opinion/letters/physics-research-collider-cern.html">responses</a> by Jeremy Bernstein and Lisa Randall, and the <a href="http://www.math.columbia.edu/~woit/wordpress/?p=10768">discussion on Peter Woit’s blog</a>, and <a href="https://www.facebook.com/daniel.harlow.31/posts/10104284984149212">Daniel Harlow’s Facebook thread</a>, and <a href="https://www.vox.com/future-perfect/2019/1/22/18192281/cern-large-hadron-collider-future-circular-collider-physics">this <em>Vox</em> piece</a> by Kelsey Piper.)  Let me blog about this as a way of cracking my knuckles or tuning my violin, just getting back into blog-shape after a long hiatus for travel and family and the beginning of the semester.</p>
<p>Regardless of whether this opinion is widely shared among my colleagues, I like Sabine.  I’ve often found her <a href="http://backreaction.blogspot.com/">blogging</a> funny and insightful, and I wish more non-Lubos physicists would articulate their thoughts for the public the way she does, rather than just standing on the sidelines and criticizing the ones who do. I find it unfortunate that some of the replies to Sabine’s arguments dwelled on her competence and “standing” in physics (even if we set aside—as we should—Lubos’s misogynistic rants, whose predictability could be used to calibrate atomic clocks). It’s like this: if high-energy physics <em>had</em> reached a pathological state of building bigger and bigger colliders for no good reason, then we’d <em>expect</em> that it would take a semi-outsider to say so in public, so then it wouldn’t be a further surprise to find precisely such a person doing it.</p>
<p>Not for the first time, though, I find myself coming down on the opposite side as Sabine. Basically, <em>if</em> civilization could get its act together and find the money, I think it would be pretty awesome to build a new collider to push forward the energy frontier in our understanding of the universe.<br/><!--StartFragment--></p>


<p>Note that I’m not making the much stronger claim that this is the <em>best possible</em> use of $20 billion for science.  Plausibly a thousand $20-million projects could be found that would advance our understanding of reality by more than a new collider would.  But it’s also important to realize that that’s not the question at stake here.  When, for example, the US Congress cancelled the <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Supercollider</a> midway through construction—partly, it’s believed, on the basis of opposition from eminent physicists in other subfields, who argued that they could do equally important science for much cheaper—none of the SSC budget, as in 0% of it, ever <em>did</em> end up redirected to those other subfields.  In practice, then, the question of “whether a new collider is worth it” is probably best considered in absolute terms, rather than relative to other science projects.</p>



<p>What I found most puzzling, in Sabine’s writings on this subject, was the leap in logic from</p>



<ol><li>many theorists expected that superpartners, or other new particles besides the Higgs boson, had a good chance of being discovered at the LHC, based on statistical arguments about “natural” parameter values, and</li><li>the basic soundness of naturalness arguments was always open to doubt, and indeed the LHC results to date offer zero support for them, and</li><li>many of the same theorists now want an even bigger collider, and continue to expect new particles to be found, and haven’t sufficiently reckoned with their previous failed predictions, to …</li><li><strong>therefore</strong> we shouldn’t build the bigger collider.</li></ol>



<p>How do we get from 1-3 to 4: is the idea that we should <em>punish</em> the errant theorists, by withholding an experiment that they want, in order to deter future wrong predictions?  After step 3, it seems to me that Sabine could equally well have gone to: and therefore it’s all the more important that we <em>do</em> build a new collider, in order to establish all the more conclusively that there’s just an energy desert up there—and that I, Sabine, was right to emphasize that possibility, and those other theorists were wrong to downplay it!</p>



<p>Like, I gather that there are independently motivated scenarios where there <em>would</em> be only the Higgs at the LHC scale, and then new stuff at the next energy scale beyond it.  And as an unqualified outsider who enjoys talking to friends in particle physics and binge-reading about it, I’d find it hard to assign the totality of those scenarios less than ~20% credence or more than ~80%—certainly if the actual experts don’t either.</p>



<p>And crucially, it’s not as if <em>raising the collision energy</em> is just one arbitrary direction in which to look for new fundamental physics, among a hundred a-priori equally promising directions.  Basically, there’s raising the collision energy and then there’s everything else.  By raising the energy, you’re not testing one specific idea for physics beyond Standard Model, but a hundred or a thousand ideas in one swoop.</p>



<p>The situation reminds me a little of the quantum computing skeptics who say: scalable QC can never work, in practice and probably even in principle; the mainstream physics community only <em>thinks</em> it can work because of groupthink and hype; therefore, we shouldn’t waste more funds trying to make it work.  With the sole, very interesting exception of Gil Kalai, none of the skeptics ever seem to draw what strikes me as an equally logical conclusion: whoa, let’s go <em>full speed ahead</em> with trying to build a scalable QC, because there’s an epochal revolution in physics to be had here—once the experimenters finally see that I was right and the mainstream was wrong, and they start to unravel the reasons why!</p>



<p>Of course, $20 billion is a significant chunk of change, by the standards of science even if not by the standards of random government wastages (like our recent $11 billion shutdown).  And ultimately, decisions do need to be made about which experiments are most interesting to pursue with limited resources.  And if a future circular collider <em>were</em> built, and if it indeed just found a desert, I think the balance would tilt pretty strongly toward Sabine’s position—that is, toward declining to build an even bigger and more expensive collider after that.  If the Patriots drearily won every Superbowl 13-3, year after year after year, eventually no one would watch anymore and the Superbowl would get cancelled (well, maybe that will happen for other reasons…).</p>



<p>But it’s worth remembering that—correct me if I’m wrong—so far there have been <em>no</em> cases in the history of particle physics of massively expanding the energy frontier and finding absolutely nothing new there (i.e., nothing that at least conveyed multiple bits of information, as the Higgs mass did).  And while my opinion should count for less than a neutrino mass, just thinking it over a-priori, I keep coming back to the question: before we close the energy frontier for good, shouldn’t there have been at least <em>one</em> unmitigated null result, rather than zero?</p></div>
    </content>
    <updated>2019-02-04T12:30:47Z</updated>
    <published>2019-02-04T12:30:47Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-13T04:44:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9219479121065296157</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9219479121065296157/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9219479121065296157" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html" rel="alternate" type="text/html"/>
    <title>Don't know Football but still want bet on the Superb Owl?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
(Superb Owl is not a typo. I've heard (and it could be wrong) that the  NFL guards their copyright so you can't even say `Buy Beer here for the YOU KNOW WHATl' but instead `Buy Beer here for the big game''. Stephen Colbert a long time ago go around this by calling the game Superb Owl.)</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
If I knew more about football  I might place a bet related to the Superb Owl. What kind of bets can I place?</div>
<div>
<br/></div>
<div>
1) Bet the point spread: Last time I looked the Patriots were a 2.5 point favorite. So either bet that Patriots will win by more than  2.5 or the Rams will lose by less than 2.5 or just win.</div>
<div>
<br/></div>
<div>
2) Over-Under: bet that either the total score will be over 56.5 or under it.</div>
<div>
<br/></div>
<div>
 There are prop-bets-- bets that are ABOUT the game but not related to the final score.</div>
<div>
<br/></div>
<div>
I've seen the following</div>
<div>
<br/></div>
<div>
1) Tom Brady will retire after the game. I wonder if Tom Brady (or a friend of his) could bet on this one knowing some inside information. Not i any state in America, but off-shore...</div>
<div>
<br/></div>
<div>
2) Jamie White will score the first touchdown.</div>
<div>
<br/></div>
<div>
3) Will Gladys Knight's   National Anthem go longer than 1 minute, 50 seconds (it was 1:47 seconds a few days ago but it shifted to 1:50).</div>
<div>
<br/></div>
<div>
Amazingly, this last one is what Josh Hermsmeyer (on Nate Silver's Webpage)  chose to focus on: <a href="https://fivethirtyeight.com/features/the-super-bowls-best-matchup-is-gladys-knight-vs-the-clock/">here</a>. Note that:</div>
<div>
<br/></div>
<div>
1) The people who picked 1 minute 50 seconds as the over-under probably didn't do much research. They might have set it to get the same number of people on both sides, which may explain the shift; however, I can't imagine this bet got that much action. Then again, I'm not that imaginative.</div>
<div>
<br/></div>
<div>
2) Josh DID. He did an  analysis of what is likely (he thinks it will go longer)</div>
<div>
<br/></div>
<div>
3) So- can Josh bet on this an clean up? Can you bet on this and clean up?</div>
<div>
<br/></div>
<div>
4) There is an issue: Some kinds of bets are legal in some places (betting who will WIN or beat a point-spread is legal in Las Vegas-- the Supreme court struck down a federal anti-betting rule). Some prop bets are legal. The Gladys Knight one is not.  Why not? Someone could have inside information! Gladys Knight would!</div>
<div>
<br/></div>
<div>
So you CAN bet  Rams+2.5 beats the Patriots LEGALLY</div>
<div>
<br/></div>
<div>
but to bet Gladys Knight's National Anthem will take more than 1 minute 50 seconds you might need to use  BITCOIN, and go to some offshore account. Too much sugar for a <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshi</a>.</div>
<div>
<br/></div>
<div>
5) There is another issue- there is no such thing as a sure thing (I blogged on that <a href="https://blog.computationalcomplexity.org/2008/02/there-is-no-such-thing-as-sure-thing.html">here</a>). People who bet on sports for a living (I know one such person and will blog about that later) play THE LONG GAME. So to say</div>
<div>
<br/></div>
<div>
          <i> I will withdraw X dollars (for large X)  from my investments and bet it on </i></div>
<div>
<i>          Gladys Knight's</i><i>  Star Spangled Banner to go more than 1 minute 50 seconds</i></div>
<div>
<i>          because its a sure thing</i></div>
<div>
<br/></div>
<div>
Would be... a very bad idea.<br/>
<br/>
The above was all written the day before Superb Owl. Now its the next day and Gladys Knight has sung the National Anthem. So who won the Gladys Knight Bowl? The answer is not as straightforward as it could be, see <a href="https://www.usatoday.com/story/sports/nfl/super-bowl/2019/02/03/super-bowl-2019-gladys-knight-causes-prop-bet-controversy-anthem/2764778002/">here</a>.</div>
<div>
<br/></div></div>
    </content>
    <updated>2019-02-04T02:36:00Z</updated>
    <published>2019-02-04T02:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-18T10:38:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/014" rel="alternate" type="text/html"/>
    <title>TR19-014 |  A New Proof of Nonsignalling Multiprover Parallel Repetition Theorem | 

	Himanshu Tyagi, 

	Shun Watanabe</title>
    <summary>We present an information theoretic proof of the nonsignalling multiprover parallel repetition theorem, a recent extension of its two-prover variant that underlies many hardness of approximation results. The original proofs used de Finetti type decomposition for strategies. We present a new proof that is based on a technique we introduced recently for proving strong converse results in multiuser information theory and entails a change of measure after replacing hard information constraints with soft ones.</summary>
    <updated>2019-02-03T12:39:00Z</updated>
    <published>2019-02-03T12:39:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-18T12:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15616</id>
    <link href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/" rel="alternate" type="text/html"/>
    <title>A Strange Horizon</title>
    <summary>Data science of many things including citations Amazon India source Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company Statistical Horizons. They provides short courses and seminars for statistical training. Today we have a short seminar on statistics and horizons of effectiveness. Our […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Data science of many things including citations</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/allisonamazon/" rel="attachment wp-att-15619"><img alt="" class="alignright wp-image-15619" height="200" src="https://rjlipton.files.wordpress.com/2019/02/allisonamazon.jpg?w=133&amp;h=200" width="133"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon India <a href="https://www.amazon.in/l/B001H6KWN6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company <a href="https://statisticalhorizons.com/">Statistical Horizons</a>. They provides short courses and seminars for statistical training. </p>
<p>
Today we have a short seminar on statistics and horizons of effectiveness. <span id="more-15616"/></p>
<p>
Our first topic is about citations. Did we say citations? What are we in research more interested in than citations? Allison co-wrote a paper on a <a href="https://en.wikipedia.org/wiki/Lotka's_law">“law”</a> claimed by Alfred Lotka about how the number of citations behaves. Full details in a moment, but two upshots are: </p>
<ul>
<li>
Over half of the papers are contributed by a few highly prolific authors. <p/>
</li><li>
One-shot authors are roughly <img alt="{61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{61\%}"/> of the population but account for only a tiny proportion of the literature.
</li></ul>
<p>
</p><p/><h2> Allison’s Paper </h2><p/>
<p>Allison co-wrote his <a href="https://statisticalhorizons.com/wp-content/uploads/AllisonEtAl.SSS76.pdf">paper</a>, “Lotka’s Law: A Problem in Its Interpretation and Application,” with Derek de Solla Price, Belver Griffith, Michael Moravcsik, and John Stewart in 1976. Lotka’s law, which is related to George Zipf’s famous <a href="https://en.wikipedia.org/wiki/Zipf's_law">law</a>, alleges that over any time period in any scientific or literary field, the number <img alt="{a(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n)}"/> of authors with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> contributions obeys </p>
<p align="center"><img alt="\displaystyle  a(n) = \frac{C}{n^2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%28n%29+%3D+%5Cfrac%7BC%7D%7Bn%5E2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a(n) = \frac{C}{n^2}, "/></p>
<p>where <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is independent of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. This suggests a maximum of <img alt="{n_{max} = \sqrt{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D+%3D+%5Csqrt%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max} = \sqrt{C}}"/> on the range of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, since higher <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> give <img alt="{a(n) &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(n) &lt; 1}"/>, but there is also a probabilistic interpretation: The law says that the total number of papers at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <img alt="{C/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C/n}"/>, and that gives a positive constant expectation even when <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> varies as <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Both cases yield that out of the total number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of papers, which has <img alt="{T = \Theta(C\log(C))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5CTheta%28C%5Clog%28C%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \Theta(C\log(C))}"/>, over half of them are contributed by a vanishing percentage of highly prolific authors. Meanwhile, one-shot authors are roughly <img alt="{6/\pi^2 \approx 61\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2F%5Cpi%5E2+%5Capprox+61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6/\pi^2 \approx 61\%}"/> of the population but account for only a <img alt="{1/\log(T)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/\log(T)}"/> proportion of the literature.</p>
<p>
However, the paper also remarks on a third case, namely making <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> a fixed constant—since human time is finite in any field. This puts a sharper <em>horizon</em> on Lotka’s Law and changes the inferences made as the horizon is approached. The paper shows how the <img alt="{n_{max}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_{max}}"/> factor intrudes on other inferences they would like to draw, even between the former two cases. And never mind <a href="http://www.revistadestatistica.ro/index.php/the-power-of-lotkas-law-through-the-eyes-of-r/">more</a>–<a href="https://rjlipton.wordpress.com/feed/www.fosareh.net/fa/files/pdf/Osareh-mostafavi-collnet[1].doc">recent</a> <a href="http://www.collnet.de/Berlin-2008/LarsenWIS2008llc.pdf">evidence</a> of <a href="http://www.librarywaves.com/index.php/lw/article/download/51/45/">breakdowns</a> in Lotka’s law. </p>
<p>
</p><p/><h2> Horizons </h2><p/>
<p/><p>
We have mentioned de Solla Price <a href="https://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/">before</a> in regard to his founding <a href="https://en.wikipedia.org/wiki/Scientometrics">scientometrics</a>. In practice this is mainly concerned with citation analysis and other productivity metrics, but its widely-quoted definition, “the science of measuring and analyzing science,” strikes us as broader. We feel there should be a component for measuring limitations of the effectiveness of the science one is practicing.</p>
<p>
Now of course in statistics there are longstanding measures of statistical <a href="https://en.wikipedia.org/wiki/Power_(statistics)">power</a> and experiment acuity and of <em>noise</em> in general. Nevertheless, the cascading “(non-)reproducibility crisis” argues that more needs to be addressed. The development of software tools to counter “<a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>” exemplifies a new layer of scientific modeling to do so—which could be called introspective modeling. </p>
<p>
I will exemplify with two “horizons” that are apparent in my own statistical chess research. One involves estimating the Elo rating of “perfect play.” The other involves the level of skill at which my data may cease to be effective. The former has captured popular imagination—it was among the first questions posed to me by Judit Polgar in a broadcast during the 2016 world championship match—but the latter is my concern in practice. We will see that these may be the same horizon, approached either by looking down from the stars or up from the road. </p>
<p>
I am not the first to do this kind of work or face the issue of its resolving power. Matej Guid, Artiz Perez, and Ivan Bratko made it the sole topic of a 2008 followup <a href="https://pdfs.semanticscholar.org/fcdc/9fb1e88c40de12ad9481f0d580f803bc1582.pdf">paper</a> to their 2006 <a href="https://en.chessbase.com/news/2006/world_champions2006.pdf">study</a> of all games in world championship matches. But their indicators strike me as weak. Most simply, they do not try to estimate where their horizon <em>is</em>, just argue that their results are not wholly beyond it. We will try to do more—but speculatively. The first step is rock-solid—it is a big surprise I found last month.</p>
<p>
</p><p/><h2> More Data, More Resolution </h2><p/>
<p/><p>
I use strong chess programs to take two main kinds of data. My full model uses programs in an analysis mode that evaluates all available moves to the same degree of thoroughness and takes roughly 4–6 hours per game. My quicker “screening” tests use programs in their normal playing mode, which gives full shrift only to what’s considered the best move, but shaves the time down to 10–15 minutes. For my AAAI 2011 <a href="https://cse.buffalo.edu/~regan/papers/pdf/ReHa11c.pdf">paper</a> with Guy Haworth, I used over 400,000 positions from 5,700 games at rating levels from Elo 1600 to 2700 only, all run on my office and home PCs. Below Elo 2000 the available data was so scant that noise is evident in the paper’s table.</p>
<p>
Since then, many more games by lower-rated players are being archived—much thanks to the greater availability of chessboards that automatically record moves in the standard <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">PGN</a> format, and to an upswell in tournaments, for youth in particular. Last year, thanks to the great free bandwidth granted by my university’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>), I took data in the quicker mode from over 10,600,000 moves from just over 400,000 game-sides (counting White and Black separately) in every tournament compiled by <a href="https://en.chessbase.com/">ChessBase</a> as well as some posted only by The Week in Chess (<a href="http://theweekinchess.com/">TWIC</a>) or provided directly by the World Chess Federation (FIDE). My two main test quantities are:</p>
<ul>
<li>
The percentage of the computer’s best move being the one the player chose (“MM%”). <p/>
</li><li>
The average error judged by the computer per move, scaling down large differences (“ASD”).
</li></ul>
<p>
My 2011 paper found strong linear relations of these quantities to the players’ rating, and great ASD fits on a 3-million-move data set are shown graphically in this <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a>. With MM% and my new 2018 data, here is what I see when I limit to the 1600–2700 range, grouping in “buckets” of 25 Elo points. All screenshots are taken with Andrew Que’s Polynomial Regression <a href="http://polynomialregression.drque.net/online.php">applet</a>. They all show data taken with Stockfish 9 run to search depth at least 20 and breadth at least 200 million nodes; the similar data for the chess program Komodo 11.3 gives similar results.</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfitpart/" rel="attachment wp-att-15620"><img alt="" class="aligncenter wp-image-15620" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfitpart.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Even with vastly more data, there still does not appear any reason to reject the simple hypothesis that the relation to rating is linear. Not only is <img alt="{R^2 &gt; 0.99}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E2+%3E+0.99%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R^2 &gt; 0.99}"/>, the quality of fit is terrific. The noise under Elo 2000 is minimal.</p>
<p>
But now I have over 14,000 moves in individual buckets clear down to the FIDE minimum 1000 rating; only the 2750 bucket with 11,923 moves and the 2800-level bucket with 6,340 (from just a handful of the world’s elite players) lag behind. When those buckets are added, here is what we see:</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfita/" rel="attachment wp-att-15622"><img alt="" class="aligncenter wp-image-15622" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
The linear hypothesis is notably less tenable. Instead, a quadratic polynomial fits supremely well:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfita/" rel="attachment wp-att-15623"><img alt="" class="aligncenter wp-image-15623" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfita.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Thus it seems I must admit a <em>nonlinearity</em> into my chess model. This may not be just about slightly improving my model’s application to players at the ends of the rating spectrum. Philosophically, nonlinearity can be a game-changer: the way Newtonian physics is fine for flying jets all around the globe but finding your neighbor’s house via <a href="http://physicscentral.com/explore/writers/will.cfm">GPS</a> absolutely requires Einstein. </p>
<p>
</p><p/><h2> The Horizon Issue </h2><p/>
<p/><p>
Let us flip the axes so that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is MM% and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is rating. Then the intercept of <img alt="{X = 100\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+100%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 100\%}"/> would give the rating of perfect agreement with the computer. Well, here is what we see:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfitflipext/" rel="attachment wp-att-15624"><img alt="" class="aligncenter wp-image-15624" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfitflipext.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Having the rating of perfect agreement be about 1950—which is a amateur A-level in the US—is ludicrous. The greater import is how the increase stops at Elo 3000 with matching just under 75%. The serious implication I draw is that this helps locate the horizon of effectiveness of the data and my methods based on it. Meanwhile, I’ve had the sense from applications that my full model based on smaller higher-quality data is coherent up to about 3100 but cannot tell differences above that. </p>
<p>
Indeed, there is a corroborating indicator of this horizon: The top chess programs, or even different (major) versions of the same program, don’t even match <em>each other</em> over 75% with regularity. Moreover, the <em>same program</em> will fairly often change to a different move when left running for more time or to a greater search depth. If it didn’t change, it wouldn’t improve. Thus my tests, which have no foreknowledge of how long a program used to cheat was running and on how powerful hardware, cannot expect to register positives at a higher rate. The natural agreement rates for human players range from about 35% for novices to upwards of 60% for world champions. </p>
<p>
</p><p/><h2> The Average-Error Case </h2><p/>
<p/><p>
The fit to average scaled error-per-move (ASD) shows the other side of the horizon issue. The ASD measure is more tightly correlated to rating—as the graphs in the above-mentioned <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a> suffice to indicate. Here is the corresponding graph on the new data, again with flipped axes:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearasdfit/" rel="attachment wp-att-15625"><img alt="" class="aligncenter wp-image-15625" height="285" src="https://rjlipton.files.wordpress.com/2019/02/linearasdfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Only under 1250 Elo does perfect linearity seem to be countermanded. The issue, however, is at the other end. Committing asymptotically zero error seems to be a more acute indicator of perfection than 100% agreement with a strong program. However, the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept there is given as a rating under 3300, whereas computer programs have been reliably <a href="http://www.computerchess.org.uk/ccrl/404/">rated</a> above 3400, and very recently over 3500. Thus we’d appear to have computers rated higher than perfection.</p>
<p>
One can move from the above indication of my setup losing mojo before 3000 to allege that it is insufficient for fair judgment of human players above 2500, say, so that the intercept is not valid. My counter-argument is that the same intercept is also a robust extrapolation from the range 1500 to 2500 where the linear fit is nearly perfect and the computer’s sufficiency for authoritative judgment of the players is beyond doubt. </p>
<p>
Nevertheless, the above “game-changer” for the move-matching percentage suggests the same for ASD. A quadratic fit to ASD produces the following results:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticasdfitnw/" rel="attachment wp-att-15626"><img alt="" class="aligncenter wp-image-15626" height="285" src="https://rjlipton.files.wordpress.com/2019/02/quadraticasdfitnw.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Now the <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>-intercept at <img alt="{X = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = 0}"/> is within error bars of 3500, in agreement with the 3475 figure currently used in my full model and less starkly under the measured ratings.</p>
<p>
</p><p/><h2> One More Riff </h2><p/>
<p/><p>
Let us think of move-matching for a given rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> as a flip of a biased coin with heads probability <img alt="{p = p_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = p_R}"/>. If we plot <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> not against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> but against <img alt="{p\cdot p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5Ccdot+p%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p\cdot p(1-p)}"/>, we recover a nearly perfect linear fit (the plot shows <img alt="{4p^2 (1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4p%5E2+%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4p^2 (1-p)}"/>):</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/ppqfit/" rel="attachment wp-att-15627"><img alt="" class="aligncenter wp-image-15627" height="285" src="https://rjlipton.files.wordpress.com/2019/02/ppqfit.png?w=450&amp;h=285" width="450"/></a></p>
<p>
Well, <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> is the variance of one coin flip. Why should multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by this variance recover a linear fit in the <em>mean</em>? Only multiplying <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> by the square root of <img alt="{p(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(1-p)}"/> still leaves a significantly non-linear plot. </p>
<p>
Recovering <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from <img alt="{p^2(1-p)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^2(1-p)}"/> needs solving a cubic equation. The maximum value is at <img alt="{p = \frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p = \frac{2}{3}}"/> and is <img alt="{\frac{4}{27}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B4%7D%7B27%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{4}{27}.}"/> Multiplying by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> as in the plot makes <img alt="{\frac{16}{27} \approx 0.592593}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B16%7D%7B27%7D+%5Capprox+0.592593%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{16}{27} \approx 0.592593}"/> the maximum solvable value. This regression line associates this to a rating of only 2860. This suggests a tangibly lower horizon. It also seems contradicted by the fact of Magnus Carlsen maintaining a rating over 2860 from January 2013 through June 2015, yet his engine agreement did not approach 66.7%.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We’ve connected the horizon of perfect play to whether the fundamental relationship of rating to agreement with strong computer programs is linear, quadratic, or indirectly cubic. Which relationship is true? What further tests may best ascertain the range of effectiveness of inferences from these data?</p>
<p/></font></font></div>
    </content>
    <updated>2019-02-03T06:37:57Z</updated>
    <published>2019-02-03T06:37:57Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="Teaching"/>
    <category term="Alfred Lotka"/>
    <category term="Derek de Solla Price"/>
    <category term="horizons"/>
    <category term="linear regression"/>
    <category term="nonlinearity"/>
    <category term="Paul Allison"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-18T12:20:55Z</updated>
    </source>
  </entry>
</feed>
