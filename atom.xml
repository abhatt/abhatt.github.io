<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-01-11T12:22:04Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42187</id>
    <link href="https://cstheory.stackexchange.com/questions/42187/np-hard-problems-on-the-class-of-caterpillars" rel="alternate" type="text/html"/>
    <title>NP-hard problems on the class of caterpillars</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My question is <strong>whether there exist an NP-hard problem that has only a caterpillar as input</strong>.</p>

<p>By saying <em>only caterpillar as input</em>, I wanted to emphasize that no function (eg: weights on vertices or edges) or specially chosen vertex (or edge) or anything like that is part of the input.</p>

<p>Instance: a caterpillar <span class="math-container">$T$</span><br/>
Question: __________</p>

<p>There are two similar question in the site: <a href="https://cstheory.stackexchange.com/q/1215/47855">NP-hard problems on trees</a>, <a href="https://cstheory.stackexchange.com/q/20861/47855">NP-hard problems on paths</a>. Note that all answers for the latter problem needs more than one path in input and/or additional structures (edges weights, for instance). In fact, so are most (but not all) answers of the former problem (on trees) as well.</p>

<p>I feel that it is implausible to have an NP-hard problem that take only a path as input. But, it is possible to have an NP-complete problem that take only a caterpillar as input (isn't it?).</p>

<p>Thank you</p></div>
    </summary>
    <updated>2019-01-11T09:59:33Z</updated>
    <published>2019-01-11T09:59:33Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-hardness"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-complete"/>
    <author>
      <name>Cyriac Antony</name>
      <uri>https://cstheory.stackexchange.com/users/47855</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42186</id>
    <link href="https://cstheory.stackexchange.com/questions/42186/star-seperators-to-explain-computational-complexity-of-algorithms-on-a-class-of" rel="alternate" type="text/html"/>
    <title>Star seperators to explain computational complexity of algorithms on a class of graphs?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A lot of NP-hard optimization problems on graphs which are perfect become solvable in polynomial time. Unfortunately, the class of graphs that arise in my problem are not perfect. The graphs can be easily shown to be imperfect yet the mathematical programming implementation of several supposedly np-hard problems return optimal solutions in near instant time for problems with very large size (millions of nodes, millions of edges). Does there exist some explanation in terms of graph decomposition to explain this?</p>

<p>Tarjan in his paper "decomposition by clique separators", various methodologies in using clique separators for combinatorial optimization problems. This is done using the divide and conquer paradigm. Clique separator decomposition seems to allow easy calculation of conventionally hard problems for certain graph classes which yield a clique separation tree with atoms of basic structure. Another decomposition, the tree decomposition where we map a graph to a tree that follows a set of 3 properties, is one for which certain NP-hard optimization problems become more easily solvable (in the complexity sense) and basically linear time for a bounded width on the bags of the decomposition tree. </p>

<p>The class of graphs for which I am working with do not yield clique separators nor do they seem to have an easy tree representation.  I wanted to ask if there existed some methodology (in terms of decomposition maybe?) to explain the behaviour that I have encountered in the same vein of those above. For graphs that possess some other type of special structure to those previously mentioned. For context, I am neither a graph theorist or computer scientist so have very little competence in this stuff, I am actually an engineer working on a complex design problem which can, in a sense, be reduced down to maximum independent set on the class of graphs explained below:</p>

<p>The most I have been able to achieve is that if we let <span class="math-container">$G = (V,E)$</span> be a graph of the class, there always exists a partition with a star cut-set/separator which lets call <span class="math-container">$S$</span> whose deletion <span class="math-container">$G/S$</span> results in 2 disconnected sub-components <span class="math-container">$A$</span> and <span class="math-container">$B$</span> where <span class="math-container">$A$</span> is a clique and <span class="math-container">$B$</span> <span class="math-container">$U$</span> <span class="math-container">$S$</span> is either connected and possesses a star separator or is a clique. Basically, the graphs can always be represented in a way by a binary decomposition tree where the leaf atoms/nodes are all cliques and the articulation vertices are star separators. <span class="math-container">$K$</span> is a clique</p>

<p><a href="https://i.stack.imgur.com/zn6Se.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/zn6Se.png"/></a></p></div>
    </summary>
    <updated>2019-01-11T05:46:44Z</updated>
    <published>2019-01-11T05:46:44Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="graph-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="co.combinatorics"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="independent-set"/>
    <author>
      <name>Student</name>
      <uri>https://cstheory.stackexchange.com/users/51578</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3373</id>
    <link href="https://agtb.wordpress.com/2019/01/11/sigecom-dissertation-award-call/" rel="alternate" type="text/html"/>
    <title>SIGecom Dissertation Award call</title>
    <summary>Please consider nominating graduating Ph.D. students for the SIGecom Dissertation Award.  If you are a graduating student, consider asking your adviser or other senior mentor to nominate you. Nominations are due on February 28, 2019.  This award is given to a student who defended a thesis in 2018.  It is a prestigious award and is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Please consider nominating graduating Ph.D. students for the SIGecom Dissertation Award.  If you are a graduating student, consider asking your adviser or other senior mentor to nominate you.</div>
<div/>
<div>Nominations are due on February 28, 2019.  This award is given to a student who defended a thesis in 2018.  It is a prestigious award and is accompanied by a $1500 prize.  In the past, the grand prize has been awarded to:</div>
<div/>
<div>2017: Aviad Rubinstein, “Hardness of Approximation Between P and NP”</div>
<div>2016: Peng Shi, “Prediction and Optimization in School Choice”</div>
<div>2015: Inbal Talgam-Cohen, “Robust Market Design: Information and Computation “</div>
<div>2014: S. Matthew Weinberg, “Algorithms for Strategic Agents”</div>
<div>2013: Balasubramanian Sivan, “Prior Robust Optimization”</div>
<div/>
<div>And the award has had seven runner-ups: Rachel Cummings, Christos Tzamos, Bo Waggoner, James Wright, Xi (Alice) Gao, Yang Cai, and Sigal Oren.  You can find detailed information about the nomination process at: <a href="http://www.sigecom.org/awardd.html" rel="noopener" target="_blank">http://www.sigecom.org/awardd.html</a>. We look forward to reading your nominations!</div>
<div/>
<div>Your Award Committee,</div>
<div/>
<div>Renato Paes Leme</div>
<div>Aaron Roth (Chair)</div>
<div>Inbal Talgam-Cohen</div></div>
    </content>
    <updated>2019-01-11T03:27:39Z</updated>
    <published>2019-01-11T03:27:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-01-11T12:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.03319</id>
    <link href="http://arxiv.org/abs/1901.03319" rel="alternate" type="text/html"/>
    <title>Skeletonisation Algorithms for Unorganised Point Clouds with Theoretical Guarantees</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurlin:Vitaliy.html">Vitaliy Kurlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smith:Philip.html">Philip Smith</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.03319">PDF</a><br/><b>Abstract: </b>Real datasets often come in the form of an unorganised cloud of points. An
overall shape of such data is hard to visualise when data points are given by
coordinates in a high-dimensional Euclidean space. More general data can be
represented by an abstract graph with weights or distances on links between
data points. The skeletonisation problem for a point cloud is to find a graph
or a skeleton that correctly represents the shape of a cloud. This paper
compares three algorithms that solve the data skeletonisation problem for a
general cloud with topological and geometric guarantees. First, the Mapper
algorithm outputs a network of interlinked clusters. Second, the $\alpha$-Reeb
algorithm discretises the classical Reeb graph and can be applied to discrete
clouds at different scales $\alpha$. The third algorithm HoPeS produces a
Homologically Persistent Skeleton without any extra parameters. HoPeS
represents the 1-dimensional shape of a cloud at any scale by the Optimality
Theorem. The Reconstruction Theorem gives conditions on a noisy sample of a
graph when HoPeS provides a reconstructed graph with a correct homotopy type
and within a small offset of the sample. The experiments on synthetic and real
data show that HoPeS outperforms the other algorithms on several topological
and geometric measures.
</p></div>
    </summary>
    <updated>2019-01-11T02:32:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.03270</id>
    <link href="http://arxiv.org/abs/1901.03270" rel="alternate" type="text/html"/>
    <title>Scheduling in distributed systems: A cloud computing perspective</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bittencourt:Luiz_F=.html">Luiz F. Bittencourt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldman:Alfredo.html">Alfredo Goldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Madeira:Edmundo_R=_M=.html">Edmundo R. M. Madeira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fonseca:Nelson_L=_S=_da.html">Nelson L. S. da Fonseca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sakellariou:Rizos.html">Rizos Sakellariou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.03270">PDF</a><br/><b>Abstract: </b>Scheduling is essentially a decision-making process that enables resource
sharing among a number of activities by determining their execution order on
the set of available resources. The emergence of distributed systems brought
new challenges on scheduling in computer systems, including clusters, grids,
and more recently clouds. On the other hand, the plethora of research makes it
hard for both newcomers researchers to understand the relationship among
different scheduling problems and strategies proposed in the literature, which
hampers the identification of new and relevant research avenues. In this paper
we introduce a classification of the scheduling problem in distributed systems
by presenting a taxonomy that incorporates recent developments, especially
those in cloud computing. We review the scheduling literature to corroborate
the taxonomy and analyze the interest in different branches of the proposed
taxonomy. Finally, we identify relevant future directions in scheduling for
distributed systems.
</p></div>
    </summary>
    <updated>2019-01-11T02:24:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.03254</id>
    <link href="http://arxiv.org/abs/1901.03254" rel="alternate" type="text/html"/>
    <title>Quantum-inspired classical sublinear-time algorithm for solving low-rank semidefinite programming via sampling approaches</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chia:Nai=Hui.html">Nai-Hui Chia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Tongyang.html">Tongyang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Han=Hsuan.html">Han-Hsuan Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chunhao.html">Chunhao Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.03254">PDF</a><br/><b>Abstract: </b>Semidefinite programming (SDP) is a central topic in mathematical
optimization with extensive studies on its efficient solvers. Recently, quantum
algorithms with superpolynomial speedups for solving SDPs have been proposed
assuming access to its constraint matrices in quantum superposition. Mutually
inspired by both classical and quantum SDP solvers, in this paper we present a
sublinear classical algorithm for solving low-rank SDPs which is asymptotically
as good as existing quantum algorithms. Specifically, given an SDP with $m$
constraint matrices, each of dimension $n$ and rank $\mathrm{poly}(\log n)$,
our algorithm gives a succinct description and any entry of the solution matrix
in time $O(m\cdot\mathrm{poly}(\log n,1/\varepsilon))$ given access to a
sample-based low-overhead data structure of the constraint matrices, where
$\varepsilon$ is the precision of the solution. In addition, we apply our
algorithm to a quantum state learning task as an application.
</p>
<p>Technically, our approach aligns with both the SDP solvers based on the
matrix multiplicative weight (MMW) framework and the recent studies of
quantum-inspired machine learning algorithms. The cost of solving SDPs by MMW
mainly comes from the exponentiation of Hermitian matrices, and we propose two
new technical ingredients (compared to previous sample-based algorithms) for
this task that may be of independent interest:
</p>
<p>$\bullet$ Weighted sampling: assuming sampling access to each individual
constraint matrix $A_{1},\ldots,A_{\tau}$, we propose a procedure that gives a
good approximation of $A=A_{1}+\cdots+A_{\tau}$.
</p>
<p>$\bullet$ Symmetric approximation: we propose a sampling procedure that gives
low-rank spectral decomposition of a Hermitian matrix $A$. This improves upon
previous sampling procedures that only give low-rank singular value
decompositions, losing the signs of eigenvalues.
</p></div>
    </summary>
    <updated>2019-01-11T02:21:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.03155</id>
    <link href="http://arxiv.org/abs/1901.03155" rel="alternate" type="text/html"/>
    <title>Entropy Bounds for Grammar-Based Tree Compressors</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hucke:Danny.html">Danny Hucke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lohrey:Markus.html">Markus Lohrey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Benkner:Louisa_Seelbach.html">Louisa Seelbach Benkner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.03155">PDF</a><br/><b>Abstract: </b>The definition of $k^{th}$-order empirical entropy of strings is extended to
node labelled binary trees. A suitable binary encoding of tree straight-line
programs (that have been used for grammar-based tree compression before) is
shown to yield binary tree encodings of size bounded by the $k^{th}$-order
empirical entropy plus some lower order terms. This generalizes recent results
for grammar-based string compression to grammar-based tree compression.
</p></div>
    </summary>
    <updated>2019-01-11T02:22:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.03048</id>
    <link href="http://arxiv.org/abs/1901.03048" rel="alternate" type="text/html"/>
    <title>Understanding the Topology and the Geometry of the Persistence Diagram Space via Optimal Partial Transport</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Divol:Vincent.html">Vincent Divol</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lacombe:Th=eacute=o.html">Théo Lacombe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.03048">PDF</a><br/><b>Abstract: </b>We consider a generalization of persistence diagrams, namely Radon measures
supported on the upper half plane for which we define natural extensions of
Wasserstein and bottleneck distances between persistence diagrams. Such
measures naturally appear in topological data analysis when considering
continuous representations of persistence diagrams (e.g. persistence surfaces)
but also as limits for laws of large numbers on persistence diagrams or as
expectations of probability distributions on the persistence diagrams space.
Introducing a formalism originating from the theory of optimal partial
transport, we build a convenient framework to prove topological properties of
this new space, which will also hold for the closed subspace of persistence
diagrams. New results include a characterization of convergence with respect to
Wasserstein metrics, and the existence of barycenters (Fr{\'e}chet means) for
any distribution of diagrams. We also showcase the strength of this framework
by providing several statistical results made meaningful thanks to this new
formalism.
</p></div>
    </summary>
    <updated>2019-01-11T02:33:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02993</id>
    <link href="http://arxiv.org/abs/1901.02993" rel="alternate" type="text/html"/>
    <title>Secure and Computationally-Efficient Cryptographic Primitive based on Cellular Automation</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vuckovac:Rade.html">Rade Vuckovac</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02993">PDF</a><br/><b>Abstract: </b>Mageto, a random number generator based on one-dimensional cellular automaton
(CA) is presented. Three procedures of secure implementation using Mageto is
proposed and discussed. Implementations are very efficient in a wide range of
hardware and software scenarios. It includes the advanced application of the
Internet of Things (IoT) and cyber-physical systems which are both needed for
computationally-efficient cryptographic primitives. Furthermore, the proposed
primitive is inherently resistant against the Side Channel Attack (SCA), where
many currently available ciphers, such as AES, require additional hardware or
software effort to prevent SCA line of attack.
</p></div>
    </summary>
    <updated>2019-01-11T02:21:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1702.06844</id>
    <link href="http://arxiv.org/abs/1702.06844" rel="alternate" type="text/html"/>
    <title>Parameterized Shifted Combinatorial Optimization</title>
    <feedworld_mtime>1547164800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gajarsk=yacute=:Jakub.html">Jakub Gajarský</a>, Petr Hliněný, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kouteck=yacute=:Martin.html">Martin Koutecký</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1702.06844">PDF</a><br/><b>Abstract: </b>Shifted combinatorial optimization is a new nonlinear optimization framework
which is a broad extension of standard combinatorial optimization, involving
the choice of several feasible solutions at a time. This framework captures
well studied and diverse problems ranging from so-called vulnerability problems
to sharing and partitioning problems. In particular, every standard
combinatorial optimization problem has its shifted counterpart, which is
typically much harder. Already with explicitly given input set the shifted
problem may be NP-hard. In this article we initiate a study of the
parameterized complexity of this framework. First we show that shifting over an
explicitly given set with its cardinality as the parameter may be in XP, FPT or
P, depending on the objective function. Second, we study the shifted problem
over sets definable in MSO logic (which includes, e.g., the well known MSO
partitioning problems). Our main results here are that shifted combinatorial
optimization over MSO definable sets is in XP with respect to the MSO formula
and the treewidth (or more generally clique-width) of the input graph, and is
W[1]-hard even under further severe restrictions.
</p></div>
    </summary>
    <updated>2019-01-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-2366077530752985091</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/2366077530752985091/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=2366077530752985091" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2366077530752985091" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2366077530752985091" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/01/dear-all-please-consider-nominating.html" rel="alternate" type="text/html"/>
    <title>2019 SIGecom Dissertation Award: Call for Nominations</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="MsoNormal" style="margin: 0px;">Dear all,<br/><br/>Please consider nominating graduating Ph.D. students for the SIGecom Dissertation Award.  If you are a graduating student, consider asking your adviser or other senior mentor to nominate you.<br/><br/>Nominations are due on February 28, 2019.  This award is given to a student who defended a thesis in 2018.  It is a prestigious award and is accompanied by a $1500 prize.  In the past, the grand prize has been awarded to:<br/><br/>2017: Aviad Rubinstein, "Hardness of Approximation Between P and NP"<br/>2016: Peng Shi, "Prediction and Optimization in School Choice"<br/>2015: Inbal Talgam-Cohen, "Robust Market Design: Information and Computation "<br/>2014: S. Matthew Weinberg, "Algorithms for Strategic Agents"<br/>2013: Balasubramanian Sivan, "Prior Robust Optimization"<br/><br/><br/>And the award has had seven runner-ups: Rachel Cummings, Christos Tzamos, Bo Waggoner, James Wright, Xi (Alice) Gao, Yang Cai, and Sigal Oren.  You can find detailed information about the nomination process at: <a href="http://www.sigecom.org/awardd.html">http://www.sigecom.org/awardd.html</a>. We look forward to reading your nominations!<br/><br/><br/>Your Award Committee,<br/><b><br/></b><b>Renato Paes Leme</b><br/><b>Aaron Roth</b> (Chair)<br/><b>Inbal Talgam-Cohen</b></div><div class="m_-6389343170732676329gmail-adL" style="background-color: white; color: #222222; font-size: small;"><span class="m_-6389343170732676329gmail-im" style="color: #500050;"/><br/><div style="font-family: arial, helvetica, sans-serif;"/></div></div>
    </content>
    <updated>2019-01-10T20:26:00Z</updated>
    <published>2019-01-10T20:26:00Z</published>
    <author>
      <name>Aaron Roth</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/111805394598997130229</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron Roth</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-01-10T20:27:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42185</id>
    <link href="https://cstheory.stackexchange.com/questions/42185/is-there-a-p-complete-language-x-such-that-succinct-x-is-in-p" rel="alternate" type="text/html"/>
    <title>Is there a P-complete language X such that succinct-X is in P?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I came across a paper called "A Note on Succinct Representation of Graphs".  It seems that in the discussion section they claim that for any problem <span class="math-container">$X$</span> that is <span class="math-container">$\mathrm{P}$</span>-hard under projections, <span class="math-container">$\mbox{succinct-X}$</span> is <span class="math-container">$\mathrm{EXP}$</span>-hard.</p>

<p>This made me wonder if the theorem fails for more complicated kinds of reductions.  This led me to the following.</p>

<blockquote>
  <p><strong>My Question</strong></p>
  
  <p>Are there any problems <span class="math-container">$X$</span> such that <span class="math-container">$X$</span> is <span class="math-container">$\mathrm{P}$</span>-complete
  under logspace reductions and <span class="math-container">$\mbox{succinct-X}$</span> is in <span class="math-container">$\mathrm{P}$</span>?</p>
</blockquote>

<p><strong>Additional Questions:</strong></p>

<p>(1) If this is an open problem, then what are the implications if such an <span class="math-container">$X$</span> existed?</p>

<p>(2) If this is an open problem, is it still open is we weaken the requirement to <span class="math-container">$\mbox{succinct-X}$</span> in <span class="math-container">$PH$</span>?</p>

<p>(3) It seems that such an <span class="math-container">$X$</span> would also satisfy that <span class="math-container">$X$</span> is <span class="math-container">$\mathrm{P}$</span>-hard under logspace reductions, but not <span class="math-container">$\mathrm{P}$</span>-hard under projections.  Are such problems known to exist?</p>

<p>(4) I might be mistaken, but I think that I have a construction for such an <span class="math-container">$X$</span> assuming that <span class="math-container">$P = NP$</span>.  Would this be interesting?</p>

<p><strong>Note:</strong> I'm still learning about projections so please let me know if I made any mistakes.  Thank you!</p></div>
    </summary>
    <updated>2019-01-10T06:34:19Z</updated>
    <published>2019-01-10T06:34:19Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="complexity-classes"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reductions"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="succinct"/>
    <author>
      <name>Michael Wehar</name>
      <uri>https://cstheory.stackexchange.com/users/14207</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42184</id>
    <link href="https://cstheory.stackexchange.com/questions/42184/is-there-any-chance-these-results-are-correct" rel="alternate" type="text/html"/>
    <title>Is there any chance these results are correct? [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>P versus NP is considered as one of the most important open problems in computer science. This consists in knowing the answer of the following question: Is P equal to NP? A precise statement of the P versus NP problem was introduced independently by Stephen Cook and Leonid Levin. Since that date, all efforts to find a proof for this problem have failed. Given a positive integer x and a collection S of positive integers, MAXIMUM is the problem of deciding whether x is the maximum of S. We prove this problem is complete for P. Another major complexity classes are LOGSPACE, NLOGSPACE, coNP and EXP. Whether LOGSPACE = NLOGSPACE is a fundamental question that it is as important as it is unresolved. We show the problem MAXIMUM can be decided in logarithmic space. Consequently, we demonstrate the complexity class LOGSPACE is equal to P and thus, LOGSPACE is equal to NLOGSPACE. Furthermore, we define a problem called SUCCINCT-MAXIMUM. SUCCINCT-MAXIMUM contains the instances of MAXIMUM that can be represented by an exponentially more succinct way. We show this succinct version of MAXIMUM is in P under the assumption of P = NP. Since SUCCINCT-MAXIMUM is a succinct version of a P-complete problem under the complexity of properties of succinctly representable graphs, then this might be a good candidate to be in EXP-complete and therefore, this would imply the complexity class P is not equal to NP as a consequence of the Hierarchy Theorem.</p>

<p><a href="https://www.academia.edu/38094917/LOGSPACE_vs_P" rel="nofollow noreferrer">https://www.academia.edu/38094917/LOGSPACE_vs_P</a></p></div>
    </summary>
    <updated>2019-01-10T04:31:04Z</updated>
    <published>2019-01-10T04:31:04Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="cc.complexity-theory"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="complexity-classes"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="p-vs-np"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="open-problem"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="space-complexity"/>
    <author>
      <name>Frank Vega</name>
      <uri>https://cstheory.stackexchange.com/users/42178</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02871</id>
    <link href="http://arxiv.org/abs/1901.02871" rel="alternate" type="text/html"/>
    <title>The Lingering of Gradients: How to Reuse Gradients over Time</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allen=Zhu:Zeyuan.html">Zeyuan Allen-Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xinshang.html">Xinshang Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02871">PDF</a><br/><b>Abstract: </b>Classically, the time complexity of a first-order method is estimated by its
number of gradient computations. In this paper, we study a more refined
complexity by taking into account the "lingering" of gradients: once a gradient
is computed at $x_k$, the additional time to compute gradients at
$x_{k+1},x_{k+2},\dots$ may be reduced.
</p>
<p>We show how this improves the running time of gradient descent and SVRG. For
instance, if the "additional time" scales linearly with respect to the traveled
distance, then the "convergence rate" of gradient descent can be improved from
$1/T$ to $\exp(-T^{1/3})$. On the empirical side, we solve a hypothetical
revenue management problem on the Yahoo! Front Page Today Module application
with 4.6m users to $10^{-6}$ error (or $10^{-12}$ dual error) using 6 passes of
the dataset.
</p></div>
    </summary>
    <updated>2019-01-10T23:41:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02857</id>
    <link href="http://arxiv.org/abs/1901.02857" rel="alternate" type="text/html"/>
    <title>Fragile Complexity of Comparison-Based Algorithms</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshani:Peyman.html">Peyman Afshani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fagerberg:Rolf.html">Rolf Fagerberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hammer:David.html">David Hammer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Riko.html">Riko Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostitsyna:Irina.html">Irina Kostitsyna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyer:Ulrich.html">Ulrich Meyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sitchinava:Nodari.html">Nodari Sitchinava</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02857">PDF</a><br/><b>Abstract: </b>We initiate a study of algorithms with a focus on the computational
complexity of individual elements, and introduce the fragile complexity of
comparison-based algorithms as the maximal number of comparisons any individual
element takes part in. We give a number of upper and lower bounds on the
fragile complexity for fundamental problems, including Minimum, Selection,
Sorting and Heap Construction. The results include both deterministic and
randomized upper and lower bounds, and demonstrate a separation between the two
settings for a number of problems. The depth of a comparator network is a
straight-forward upper bound on the worst case fragile complexity of the
corresponding fragile algorithm. We prove that fragile complexity is a
different and strictly easier property than the depth of comparator networks,
in the sense that for some problems a fragile complexity equal to the best
network depth can be achieved with less total work and that with randomization,
even a lower fragile complexity is possible.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02823</id>
    <link href="http://arxiv.org/abs/1901.02823" rel="alternate" type="text/html"/>
    <title>An Elastic Energy Minimization Framework for Mean Contour Calculation</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jozsef Molnar, Michael Barbier, Winnok H. De Vos, Peter Horvath <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02823">PDF</a><br/><b>Abstract: </b>In this paper we propose a contour mean calculation and interpolation method
designed for averaging manual delineations of objects performed by experts and
interpolate 3D layer stack images. The proposed method retains all visible
information of the input contour set: the relative positions, orientations and
size, but allows invisible quantities - parameterization and the centroid - to
be changed. The chosen representation space - the position vector rescaled by
square root velocity - is a real valued vector space on which the imposed L2
metric is used to define the distance function. With respect to this
representation the re-parameterization group acts by isometries and the
distance has well defined meaning: the sum of the central second moments of the
coordinate functions. To identify the optimal re-parameterization system and
proper centroid we use double energy minimization realized in a variational
framework.
</p></div>
    </summary>
    <updated>2019-01-10T23:46:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02778</id>
    <link href="http://arxiv.org/abs/1901.02778" rel="alternate" type="text/html"/>
    <title>On NP-completeness of the cell formation problem</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mikhail V. Batsyn, Ekaterina K. Batsyna, Ilya S. Bychkov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02778">PDF</a><br/><b>Abstract: </b>In the current paper we provide a proof of NP-completeness for the CFP
problem with the fractional grouping efficacy objective. For this purpose we
first consider the CFP with the linear objective minimizing the total number of
exceptions and voids. Following the ideas of Pinheiro et al. (2016) we show
that it is equivalent to the Bicluster Graph Editing Problem (BGEP), which is
known to be NP-complete (Amit, 2004). Then we suggest a reduction of the CFP
problem with the linear objective function to the CFP with the grouping
efficacy objective.
</p></div>
    </summary>
    <updated>2019-01-10T23:30:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02771</id>
    <link href="http://arxiv.org/abs/1901.02771" rel="alternate" type="text/html"/>
    <title>Sweep Algorithms for the Capacitated Vehicle Routing Problem with Structured Time Window</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Christoph Hertrich, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hungerl=auml=nder:Philipp.html">Philipp Hungerländer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Truden:Christian.html">Christian Truden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02771">PDF</a><br/><b>Abstract: </b>The capacitated Vehicle Routing Problem with structured Time Windows
(cVRPsTW) is concerned with finding optimal tours for vehicles with given
capacity constraints to deliver goods to customers within assigned time
windows. In our problem variant these time windows have a special structure,
namely they are non-overlapping and each time window holds several customers.
This is a reasonable assumption for Attended Home Delivery services. Sweep
algorithms are known as simple, yet effective heuristics for the classical
capacitated Vehicle Routing Problem. We propose variants of the sweep algorithm
that are not only able to deal with time windows, but also exploit the
additional structure of the time windows in a cVRPsTW. Afterwards we suggest
local improvement heuristics to decrease our objective function even further. A
carefully constructed benchmark set that resembles real-world data is used to
prove the efficacy of our algorithms in a computational study.
</p></div>
    </summary>
    <updated>2019-01-10T23:45:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02560</id>
    <link href="http://arxiv.org/abs/1901.02560" rel="alternate" type="text/html"/>
    <title>Coercion-Resistant Voting in Linear Time via Fully Homomorphic Encryption: Towards a Quantum-Safe Scheme</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=oslash=nne:Peter_B=.html">Peter B. Rønne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Atashpendar:Arash.html">Arash Atashpendar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gj=oslash=steen:Kristian.html">Kristian Gjøsteen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ryan:Peter_Y=_A=.html">Peter Y. A. Ryan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02560">PDF</a><br/><b>Abstract: </b>We present an approach for performing the tallying work in the
coercion-resistant JCJ voting protocol, introduced by Juels, Catalano, and
Jakobsson, in linear time using fully homomorphic encryption (FHE). The
suggested enhancement also paves the path towards making JCJ quantum-resistant,
while leaving the underlying structure of JCJ intact. The exhaustive,
comparison-based approach of JCJ using plaintext equivalence tests leads to a
quadratic blow-up in the number of votes, which makes the tallying process
rather impractical in realistic settings with a large number of voters. We show
how the removal of invalid votes can be done in linear time via a solution
based on recent advances in various FHE primitives such as hashing,
zero-knowledge proofs of correct decryption, verifiable shuffles and threshold
FHE. We conclude by touching upon some of the advantages and challenges of such
an approach, followed by a discussion of further security and post-quantum
considerations.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02536</id>
    <link href="http://arxiv.org/abs/1901.02536" rel="alternate" type="text/html"/>
    <title>Fast generalized DFTs for all finite groups</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umans:Chris.html">Chris Umans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02536">PDF</a><br/><b>Abstract: </b>For any finite group $G$, we give an arithmetic algorithm to compute
generalized Discrete Fourier Transforms (DFTs) with respect to $G$, using
$O(|G|^{\omega/2 + \epsilon})$ operations, for any $\epsilon &gt; 0$. Here,
$\omega$ is the exponent of matrix multiplication.
</p></div>
    </summary>
    <updated>2019-01-10T23:41:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02510</id>
    <link href="http://arxiv.org/abs/1901.02510" rel="alternate" type="text/html"/>
    <title>New approach for a stable multi-criteria ridesharing system</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sawsen Ben Nasr <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02510">PDF</a><br/><b>Abstract: </b>The witnessed boom in mobility results in many problems such as urbanization,
costly construction of many highways and air pollution. In an attempt to
address these problems, in this master, we are interested in the implementation
of a ridesharing system. Ridesharing is recognized as a highly effective means
of transport to solve energy consumption, environmental pollution and traffic
congestion issues. Indeed, ridesharing can reduce the number of vehicles on the
roads to avoid traffic jams and thus it contributes to a reduction in
greenhouse gas emissions. Its main thrust resides in sharing transport
expenses, meeting different people and making traveling more enjoyable. In this
respect, we introduce in this dissertation an effective ridesharing system,
called the Stable Multi-Criteria Rideshare Matching (SMRM) system, that (i)
considers users' personal preferences when sharing a private space with others
and (ii) enables a stable matching between driver and passenger sets. The
performed experiments show that the introduced system outperforms its
competitors in terms of stability quality and cost.
</p>
<p>Keywords: Smart cities, Social sustainability, Ridesharing , Social
preferences , TOPSIS , Stable marriage .
</p></div>
    </summary>
    <updated>2019-01-10T23:41:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02508</id>
    <link href="http://arxiv.org/abs/1901.02508" rel="alternate" type="text/html"/>
    <title>An Application of Manifold Learning in Global Shape Descriptors</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bashiri:Fereshteh_S=.html">Fereshteh S. Bashiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rostami:Reihaneh.html">Reihaneh Rostami</a>, Peggy Peissig, Roshan M. D'Souza, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Zeyun.html">Zeyun Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02508">PDF</a><br/><b>Abstract: </b>With the rapid expansion of applied 3D computational vision, shape
descriptors have become increasingly important for a wide variety of
applications and objects from molecules to planets. Appropriate shape
descriptors are critical for accurate (and efficient) shape retrieval and 3D
model classification. Several spectral-based shape descriptors have been
introduced by solving various physical equations over a 3D surface model. In
this paper, for the first time, we incorporate a specific group of techniques
in statistics and machine learning, known as manifold learning, to develop a
global shape descriptor in the computer graphics domain. The proposed
descriptor utilizes the Laplacian Eigenmap technique in which the Laplacian
eigenvalue problem is discretized using an exponential weighting scheme. As a
result, our descriptor eliminates the limitations tied to the existing spectral
descriptors, namely dependency on triangular mesh representation and high
intra-class quality of 3D models. We also present a straightforward
normalization method to obtain a scale-invariant descriptor. The extensive
experiments performed in this study show that the present contribution provides
a highly discriminative and robust shape descriptor under the presence of a
high level of noise, random scale variations, and low sampling rate, in
addition to the known isometric-invariance property of the Laplace-Beltrami
operator. The proposed method significantly outperforms state-of-the-art
algorithms on several non-rigid shape retrieval benchmarks.
</p></div>
    </summary>
    <updated>2019-01-10T23:45:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.02491</id>
    <link href="http://arxiv.org/abs/1901.02491" rel="alternate" type="text/html"/>
    <title>Faster parameterized algorithm for pumpkin vertex deletion set</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02491">PDF</a><br/><b>Abstract: </b>A directed graph $G$ is called a pumpkin if $G$ is a union of induced paths
with a common start vertex $s$ and a common end vertex $t$, and the internal
vertices of every two paths are disjoint. We give an algorithm that given a
directed graph $G$ and an integer $k$, decides whether a pumpkin can be
obtained from $G$ by deleting at most $k$ vertices. The algorithm runs in
$O^*(2^k)$ time.
</p></div>
    </summary>
    <updated>2019-01-10T23:43:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.01861</id>
    <link href="http://arxiv.org/abs/1901.01861" rel="alternate" type="text/html"/>
    <title>On the Parameterized Complexity of $k$-Edge Colouring</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galby:Esther.html">Esther Galby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Paloma_T=.html">Paloma T. Lima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paulusma:Dani=euml=l.html">Daniël Paulusma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ries:Bernard.html">Bernard Ries</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.01861">PDF</a><br/><b>Abstract: </b>For every fixed integer $k \geq 1$, we prove that $k$-Edge Colouring is
fixed-parameter-tractable when parameterized by the number of vertices of
maximum degree.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1802.05859</id>
    <link href="http://arxiv.org/abs/1802.05859" rel="alternate" type="text/html"/>
    <title>A Parameterized Strongly Polynomial Algorithm for Block Structured Integer Programs</title>
    <feedworld_mtime>1547078400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kouteck=yacute=:Martin.html">Martin Koutecký</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1802.05859">PDF</a><br/><b>Abstract: </b>The theory of $n$-fold integer programming has been recently emerging as an
important tool in parameterized complexity. The input to an $n$-fold integer
program (IP) consists of parameter $A$, dimension $n$, and numerical data of
binary encoding length $L$. It was known for some time that such programs can
be solved in polynomial time using $O(n^{g(A)}L)$ arithmetic operations where
$g$ is an exponential function of the parameter. In 2013 it was shown that it
can be solved in fixed-parameter tractable (FPT) time using $O(f(A)n^3L)$
arithmetic operations for a single-exponential function $f$. This, and a faster
algorithm for a special case of combinatorial $n$-fold IP, have led to several
very recent breakthroughs in the parameterized complexity of scheduling,
stringology, and computational social choice. In 2015 it was shown that it can
be solved in strongly polynomial time using $O(n^{g(A)})$ arithmetic
operations.
</p>
<p>Here we establish a result which subsumes all three of the above results by
showing that $n$-fold IP can be solved in strongly polynomial FPT time using
$O(f(A)n^3)$ arithmetic operations. In fact, our results are much more general,
briefly outlined as follows.
</p>
<p>- There is a strongly polynomial algorithm for ILP whenever a so-called
Graver-best oracle is realizable for it.
</p>
<p>- Graver-best oracles for the large classes of multi-stage stochastic and
tree-fold ILPs can be realized in FPT time. Together with the previous oracle
algorithm, this newly shows two large classes of ILP to be strongly polynomial;
in contrast, only few classes of ILP were previously known to be strongly
polynomial.
</p>
<p>- We show that ILP is FPT parameterized by the largest coefficient
$\|A\|_\infty$ and the primal or dual treedepth of $A$, and that this
parameterization cannot be relaxed, signifying substantial progress in
understanding the parameterized complexity of ILP.
</p></div>
    </summary>
    <updated>2019-01-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-01-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-4590649641895956020</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/4590649641895956020/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=4590649641895956020" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4590649641895956020" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4590649641895956020" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2019/01/analco-sosa-soda-post.html" rel="alternate" type="text/html"/>
    <title>ANALCO, SOSA, SODA post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I spent the last few days at SODA-ANALCO-ALENEX-SOSA in San Diego.  (Nice location choice, I'd say!)  Here's some news.<br/><br/>This will be the last ANALCO (Analytic Algorithms and Combinatorics).  Apparently submissions have been decreasing, so they've decided it will halt and the work on these topics will go into SODA and other conferences.  I'm not sure how to think of it -- I think we as a community have far too many conferences/workshops generally, but I think the SODA model of having ANALCO and ALENEX (and now SOSA, I imagine) folded in cleanly into the main conference is an excellent model.  I also like the ANALCO topics.  But I can understand the time may have come to do something else.  Thanks to everyone who worked to organize ANALCO and keep it going these many years.<br/><br/>It looks like SOSA (Symposium on Simplicity in Algorithms) will be taking its place in the SODA lineup.  I co-chaired the symposium with Jeremy Fineman this year, the second for the symposium.  I was surprised by the high quality of the submissions, and was then further surprised by the strong turnout at SODA.  The room was quite full for the Tuesday afternoon sessions, and there were easily 75+ people at several of the talks.  I do think there's a need for SOSA -- no other workshop/conference hits the theme of simplicity in our area, and it's a really nice fit with the rest of SODA.  I'm hoping it will last, and in particular that they'll continue to have a good number of high quality submissions, but that depends on all of you.  Ideally, there will be a positive feedback loop here -- now that there's a good home for this type of work (besides notes on the arxiv), people will be more inclined to write up and submit things to SOSA.  For Tuesday's talks, I'll call out Josh Alman's great presentation on "An Illuminating Algorithm for the Light Bulb Problem" as my favorite for the day.<br/><br/>With ANALCO exiting, though, I think there's more room for additional satellite events at SODA, so hopefully some people will get creative.<br/><br/>If I had thought about it I should have live-blogged the business meeting.  I'd say as highlights, first, Sandy Irani presented the report of the ad hoc committee to combat harassment and discrimination in the theory of computing community.   (See <a href="https://www.ics.uci.edu/~irani/safetoc.html">here</a> for the report.)  There was an overwhelming vote to adopt their recommendations going forward.  It's good to see progress in addressing these community concerns.  Second, Shuchi Chawla will be the next PC chair, and she brought forward a plan to have SODA PC members be allowed to submit papers (with a higher bar) that was voted on favorably as well.<br/><br/>I suppose the last note is that Jon Kleinberg's invited talk was the conference highlight you expect a Jon Kleinberg talk to be, with interesting results and models related to fairness and implicit bias.<br/><br/>Thanks to SIAM and all the organizers for their hard work.</div>
    </content>
    <updated>2019-01-09T22:25:00Z</updated>
    <published>2019-01-09T22:25:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2019-01-09T22:25:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42183</id>
    <link href="https://cstheory.stackexchange.com/questions/42183/new-subset-sum-approach-results" rel="alternate" type="text/html"/>
    <title>new subset sum approach results</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have been working on a new approach for a subset sum exact solver, and the current state provides an algorithm operating on <span class="math-container">$O{n/2 \choose n/4}$</span>, demonstrating as well the hardest target value is not <span class="math-container">$\approx \frac{sum(S)}{2}$</span> but <span class="math-container">$\approx\frac{sum(S)}{4}$</span> for dense instances (<span class="math-container">$d \approx 1$</span>) in all cases.</p>

<p>I asked several people about their opinion and I got mixed feedback, some people though it was worth it to keep pushing the approach before publishing (to try to obtain an improved result, given this is likely possible, then publish), while other people encouraged me to publish right away given the improvement over the <span class="math-container">$O(2^{\frac{n}{2}})$</span> approach and the new characterization for the hardest target values not demonstrated before in the available literature, then continue working looking to improve these results.</p>

<p>What are your suggestions/opinions? </p></div>
    </summary>
    <updated>2019-01-09T21:51:34Z</updated>
    <published>2019-01-09T21:51:34Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="np-complete"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="subset-sum"/>
    <author>
      <name>John Seppard</name>
      <uri>https://cstheory.stackexchange.com/users/47335</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/</id>
    <link href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/" rel="alternate" type="text/html"/>
    <title>Mixed-Integer Nonlinear Optimization meets Data Science</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 25, 2018 – June 28, 2019 Ischia, Italy http://www.iasi.cnr.it/minoa/big-data-school/ CNR-IASI, as part of the MINOA project, announces the school for PhD students and post-docs on the theme Mixed Integer Non linear Optimization meets Data Science. The school will cover the following topics: Deep learning for AI Clustering for Big Data Machine Learning for Combinatorial … <a class="more-link" href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/">Continue reading <span class="screen-reader-text">Mixed-Integer Nonlinear Optimization meets Data Science</span></a></div>
    </summary>
    <updated>2019-01-09T20:51:39Z</updated>
    <published>2019-01-09T20:51:39Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-01-11T12:21:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5374</id>
    <link href="https://adamsheffer.wordpress.com/2019/01/09/the-baruch-distinguished-mathematics-lecture-series/" rel="alternate" type="text/html"/>
    <title>The Baruch Distinguished Mathematics Lecture Series</title>
    <summary>I am happy to announce the beginning of the Baruch Distinguished Mathematics Lecture Series. In this series we will bring established mathematicians to give talks to a general mathematical audience. Our first Distinguished Lecture, by Bjorn Poonen, will be “Undecidability in Number Theory”. Click here for the full details. The talk is open to everyone, […]</summary>
    <updated>2019-01-09T20:43:09Z</updated>
    <published>2019-01-09T20:43:09Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-01-11T12:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1350</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/" rel="alternate" type="text/html"/>
    <title>Nemirovski’s acceleration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I will describe here the very first (to my knowledge) acceleration algorithm for smooth convex optimization, which is due to Arkadi Nemirovski (dating back to the end of the 70’s). The algorithm relies on a -dimensional plane-search subroutine (which, in … <a href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I will describe here the very first (to my knowledge) acceleration algorithm for smooth convex optimization, which is due to <a class="liinternal" href="https://en.wikipedia.org/wiki/Arkadi_Nemirovski" rel="nofollow">Arkadi Nemirovski</a> (dating back to the end of the 70’s). The algorithm relies on a <img alt="2" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc2da46d9824359f6ac8d33c5fb882dd_l3.png?resize=8%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/>-dimensional plane-search subroutine (which, in theory, can be implemented in <img alt="\log(1/\epsilon)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-38bfa3c1131fbae41cb358b8b685dc56_l3.png?resize=61%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="61"/> calls to a first-order oracle). He later improved it to only require a <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>-dimensional line-search in 1981, but of course the breakthrough that everyone knows about came a year after with the famous 1982 paper by <a class="liinternal" href="https://en.wikipedia.org/wiki/Yurii_Nesterov" rel="nofollow">Nesterov</a> that gets rid of this extraneous logarithmic term altogether (and in addition is based on the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2018/11/21/a-short-proof-for-nesterovs-momentum/">deep insight</a> of modifying Polyak’s momentum).</p>
<p>Let <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> be a <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>-smooth function. Denote <img alt="x^{+} = x - \nabla f(x)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d69559ebcb4e4ecdf7454cab91bf526b_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="125"/>. Fix a sequence <img alt="(\lambda_t)_{t \in \N}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba9ca1ebe088d1befda0acb3c4644727_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/>, to be optimized later. We consider the “conjugate” point <img alt="\sum_{s =1}^t \lambda_s \nabla f(x_s)" class="ql-img-inline-formula " height="23" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d22daf1993fbb2397de0b21ab0ea87ee_l3.png?resize=119%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="119"/>. The algorithm simply returns the optimal combination of the conjugate point and the gradient descent point, that is:</p>
<p class="ql-center-displayed-equation" style="line-height: 54px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ x_{t+1} = \argmin_{x \in P_t} f(x) \, \text{where} \, P_t = \mathrm{span}\left(x_t^+, \sum_{s =1}^t \lambda_s \nabla f(x_s)\right) \,. \]" class="ql-img-displayed-equation " height="54" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-360399a70097a55997eaeacb3ec02615_l3.png?resize=424%2C54&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="424"/></p>
<p>Let us denote <img alt="g_s = \nabla f(x_s)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e614d7a76c02a9a308f9898af91df8ff_l3.png?resize=95%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="95"/> and <img alt="\delta_s = f(x_s) - f(x^*)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-629dcf91ea83c14ea854c74de1069acd_l3.png?resize=143%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="143"/> for shorthand. The key point is that <img alt="g_{t+1} \in P_t^{\perp}" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d21b904e2ccc5df54959aa117a37b98_l3.png?resize=77%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/>, and in particular <img alt="\|\sum_{s \leq t} \lambda_s g_s\|^2 = \sum_{s \leq t} \lambda_s^2 \|g_s\|^2" class="ql-img-inline-formula " height="22" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e57279bc2d0342e42087a51af61fb76_l3.png?resize=231%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="231"/>. Now recognize that <img alt="\|g_s\|^2" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b728147d95760e42ef7cdbb706a8cfd1_l3.png?resize=38%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="38"/> is a lower bound on the improvement <img alt="\delta_s - \delta_{s+1}" class="ql-img-inline-formula " height="17" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0808cda8024eb11ab7ce37176832a9fe_l3.png?resize=68%2C17&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="68"/> (here we use that <img alt="x_{s+1}" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b0878f455a78407f8618e726e941aea6_l3.png?resize=33%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="33"/> is better than <img alt="x_s^+" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5acc4c663fcf2f647eb177ebb24bc154_l3.png?resize=20%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/>). Thus we get:</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s^2 (\delta_s - \delta_{s+1}) \leq \sum_{s \leq t} \delta_s (\lambda_s^2 - \lambda_{s-1}^2) \,. \]" class="ql-img-displayed-equation " height="40" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a12bda17f9c1f0f0e13ef03c9a1c9d2c_l3.png?resize=404%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="404"/></p>
<p>In other words if the sequence <img alt="\lambda" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab48baf331239642a00255b86324280a_l3.png?resize=10%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> is chosen such that <img alt="\lambda_s = \lambda_s^2 - \lambda_{s-1}^2" class="ql-img-inline-formula " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2f241a8315da6dd3f7735135d1d2b7ae_l3.png?resize=114%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="114"/> then we get</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s \delta_s \,. \]" class="ql-img-displayed-equation " height="40" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8e959561f27eec9096b81bd7148a4a75_l3.png?resize=180%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="180"/></p>
<p>This is good because roughly the reverse inequality also holds true by convexity (and the fact that <img alt="x_s \in P_s" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-212cae06b1b9b8b6af498b589bb15865_l3.png?resize=56%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> so <img alt="g_s \cdot x_s = 0" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cf91835fdc91be361d1c7e89f867c5db_l3.png?resize=78%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="78"/>):</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{s \leq t} \lambda_s \delta_s \leq \sum_{s \leq t} \lambda_s g_s \cdot (x_s - x^*) \leq \|x^*\| \cdot \| \sum_{s \leq t} \lambda_s g_s\| \,. \]" class="ql-img-displayed-equation " height="40" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d1ee450c97dfc04bca3a123fb68daa8_l3.png?resize=391%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="391"/></p>
<p>So finally we get <img alt="\sum_{s \leq t} \lambda_s \delta_s \leq \|x^*\|^2" class="ql-img-inline-formula " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d58dea2404181d7f1751fcf8e68ad024_l3.png?resize=143%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="143"/>, and it just remains to realize that <img alt="\lambda_s" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f100f89f751713a1814b3938a510009b_l3.png?resize=16%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="16"/> is of order <img alt="s" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/> so that <img alt="\delta_t \leq \|x^*\|^2 / t^2" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ff4a3e78d1ced5a05f33eb077194504_l3.png?resize=103%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/>.</p></div>
    </content>
    <updated>2019-01-09T18:51:19Z</updated>
    <published>2019-01-09T18:51:19Z</published>
    <category term="Optimization"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-01-10T23:47:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42180</id>
    <link href="https://cstheory.stackexchange.com/questions/42180/coordinate-descent-in-integer-programing-when-does-it-work" rel="alternate" type="text/html"/>
    <title>Coordinate descent in integer programing: when does it work?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Denote <span class="math-container">$N_i=\{0,1,\dots,\bar{n}_i\}$</span> and define <span class="math-container">$N=N_1\times \dots \times N_I$</span>. I want to minimize a function <span class="math-container">$f:N\rightarrow \mathbb{R}$</span>. It is very easy to minimize <span class="math-container">$f$</span> coordinate by coordinate so one natural algorithm is to iterate on a mapping <span class="math-container">$T$</span> for which the <span class="math-container">$i$</span>th element is defined as
<span class="math-container">$$(Tn)_i=\arg\min_{\tilde{n}_i\in N_i} f\left( \left\{ n_1,\dots,\tilde{n}_i,\dots,n_I\right\}\right)$$</span>
until we have convergence. This is essentially a <a href="https://en.wikipedia.org/wiki/Coordinate_descent" rel="nofollow noreferrer">coordinate descent</a> algorithm but in a discrete space.</p>

<p>My question is: under what conditions does this approach yield the true global minimum of <span class="math-container">$f$</span>? For instance, is <span class="math-container">$f$</span> strictly convex a sufficient condition for this procedure to work? Also, if anybody has a reference on the topic that would be highly appreciated.</p></div>
    </summary>
    <updated>2019-01-09T18:38:14Z</updated>
    <published>2019-01-09T18:38:14Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="reference-request"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="integer-programming"/>
    <author>
      <name>user_lambda</name>
      <uri>https://cstheory.stackexchange.com/users/51700</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=606</id>
    <link href="https://emanueleviola.wordpress.com/2019/01/09/my-last-3-5-years/" rel="alternate" type="text/html"/>
    <title>My last 3.5 years</title>
    <summary>I haven’t breathed (freely) since 3.5 years ago.  Precisely since the day before I left my Cambridge flat, when the Pods guy told me he couldn’t park. I had to vacate within 24 hours, had no place to put all the stuff I had never used since moving there in 2008, and also happened to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">I haven’t breathed (freely) since 3.5 years ago.  Precisely since the day before I left my Cambridge flat, when the Pods guy told me he couldn’t park. I had to vacate within 24 hours, had no place to put all the stuff I had never used since moving there in 2008, and also happened to have a 3-hour CPR course planned long ago, starting in minutes.  I took that life-saving course on the edge of the seat, each 5-minute break dashing out to call movers who might have had an unlikely last minute cancellation in the busiest day of the year (August 31).</p>
<p style="text-align: justify;">Oh the times I wished that the fireproof storage where the things eventually went burned down to the ground.  Instead I was going to have to move my never used belongings a million times up and down stairs.</p>
<p style="text-align: justify;">Anyway, after Cambridge I went to the <a href="https://emanueleviola.wordpress.com/2015/11/16/from-the-simons-institute/">Simons institute</a>. Even with all the help from the staff, finding housing was atrocious, and I had to change it during the semester. I didn’t have a place to come back, and from Berkeley I eventually found a short-term rental in Needham, MA.  The idea was to buy a house in that short term.  This proved <a href="https://emanueleviola.wordpress.com/2015/12/15/how-to-buy-a-house/">impossible</a>.  So we had to find another rental.  In the process, I was discriminated against three times.  One time the landlord rejected in writing my application claiming that they did not want to rent to families. The other two times the landlord simply rejected my application, and then lowered the price. I thought these moves made them dumb, but maybe they are actually much smarter than me, because after toying with the idea I did not, in fact, sue.</p>
<p style="text-align: justify;">Eventually we found another longer-term rental.  From there, with more excruciating difficulties I <a href="https://emanueleviola.wordpress.com/2017/12/19/how-to-buy-a-house-ii/">wrote about earlier</a>, I bought a house, which however required 1 year of renovations (not exactly cosmetic — more about this later).  These were completed just in time to store my useless stuff there: I left for another semester at the Simons institute.</p>
<p style="text-align: justify;">My second visit to the institute was also great.  In fact I enjoyed it even more than the semester on fine-grained: I was there for the program on lower bounds, which are exactly the problems I went into computer science to study. I had the best time, and lots of research exchanges.</p>
<p style="text-align: justify;">But again, the housing situation in Berkeley was desperate.  Twice I lost a house for 1 hour. Meaning, the landlord called to make the deal, I couldn’t pick up the phone, and when I called back 1 hour later the place was gone.  I still think it would be better if the institute bought a block of houses, and also provided computers.  Even better if they make it easier to print, rather than having to stand in a corner or go through a complicated set up.</p>
<p style="text-align: justify;">Another interesting pattern is that during my first visit there was a heat wave and the AC broke, and it was hot.  This time there was a rather serious wildfire, causing very unhealthy conditions in the bay area, and at times they couldn’t run the heating systems to avoid sucking in the smoke, and it was cold.</p>
<p style="text-align: justify;">Berkeley isn’t Princeton, but it’s hard for me not to compare the logistics of my visits to Simons and the IAS in Princeton.  In the latter I was put in a house steps from the Institute, with minimal effort and at a fraction of the price.  In my office there was already a working computer, connected to a printer.</p>
<p>Here’s the meaning of cloud computing, remote desktop, telnet, etc in 2019, here’s the progress, the sustainability, the sharing economy: everybody brings their own laptop.</p>
<p style="text-align: justify;">Back from Simons, I can’t help but be surprised that I still have an office.  In fact this happens every time I go up the stairs, turn the corner and see my name on the tag, and it says “Professor”. Really? Under <em>my name</em>? I have a startle each time.  I know this feeling is irrational, but is there.  Coming back from California, the feeling is intense.</p>
<p style="text-align: justify;">Back to business, I am now teaching algorithms.  I am running an online section, for which I am making videos on my <a href="https://www.youtube.com/channel/UChbOQ1Q8Fv44LbrQMvTPoEQ">youtube channel</a>. It’s the future.</p></div>
    </content>
    <updated>2019-01-09T16:36:12Z</updated>
    <published>2019-01-09T16:36:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2019-01-11T12:21:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42178</id>
    <link href="https://cstheory.stackexchange.com/questions/42178/approximate-multi-covering-with-randomized-rounding" rel="alternate" type="text/html"/>
    <title>Approximate Multi Covering with Randomized Rounding</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the set multicover problem we are given a set <span class="math-container">$N$</span> of <span class="math-container">$n$</span> elements and a set <span class="math-container">$S$</span> of <span class="math-container">$m$</span> subsets of <span class="math-container">$N$</span>. Additionally, each element has a coverage requirement (the number of times it has to be covered) and each set has a weight. The question is to cover <span class="math-container">$N$</span> with the minimum weight subsets from <span class="math-container">$S$</span>. I'm aware of the approximation algorithm for this problem using (Rajagopalan &amp; Vazirani) .</p>

<p>But I am interested in finding an algorithm for this problem that uses the randomized rounding and study its approximation factor.</p>

<p>Thanks in advance!</p></div>
    </summary>
    <updated>2019-01-09T16:01:30Z</updated>
    <published>2019-01-09T16:01:30Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="randomized-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="set-cover"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="covering-problems"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="iterated-rounding"/>
    <author>
      <name>user2404626</name>
      <uri>https://cstheory.stackexchange.com/users/51697</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42177</id>
    <link href="https://cstheory.stackexchange.com/questions/42177/maximum-minimum-satisfiability" rel="alternate" type="text/html"/>
    <title>Maximum-minimum satisfiability</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <a href="https://en.wikipedia.org/wiki/Maximum_satisfiability_problem" rel="nofollow noreferrer">MAX-SAT</a>, given a formula, we want to maximize the number of satisfied clauses: given a formula <span class="math-container">$\phi = c_1 \cap \cdots \cap c_n$</span>, where each <span class="math-container">$c_i$</span> is a disjunction, we want to find the largest <span class="math-container">$k\in\{1,\ldots,n\}$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$c_{i1},\ldots,c_{ik}$</span> are true.</p>

<p>In <strong>MAX-MIN-SAT</strong>, given two different formulas, we want to maximize the minimum number of satisfied clauses in both.
I.e., given <span class="math-container">$\phi_a = a_1 \cap \cdots \cap a_n$</span> and <span class="math-container">$\phi_b = b_1 \cap \cdots \cap b_n$</span>,  where each <span class="math-container">$a_i$</span> and each <span class="math-container">$b_i$</span> is a disjunction, find the largest <span class="math-container">$k$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$a_{i1},\ldots,a_{ik}$</span> and some <span class="math-container">$k$</span> clauses <span class="math-container">$b_{j1},\ldots,b_{jk}$</span> are true.</p>

<p>To illustrate the difference between the problems, suppose we have two assignments: one assignment satisfies 10 clauses in <span class="math-container">$\phi_a$</span> and 1 clause in <span class="math-container">$\phi_b$</span>, while another assignment satisfies 5 clauses in <span class="math-container">$\phi_a$</span> and 4 clauses in <span class="math-container">$\phi_b$</span>. Then, MAX-SAT (on <span class="math-container">$\phi_a \cap \phi_b$</span>) would prefer the first assignment since it satisfies <span class="math-container">$11&gt;9$</span> clauses overall, while MAX-MIN-SAT would prefer the second assignment since it satisfies at least <span class="math-container">$4&gt;1$</span> clauses in both formulas.</p>

<p>This problem is obviously NP-hard, so I am looking for reasonable approximations.</p>

<p>As a first approximation, suppose each formula is a conjunction of <span class="math-container">$n$</span> clauses, and each clause is a disjunction of <span class="math-container">$l$</span> variables. Suppose we set each variable randomly. Then, each clause is unsatisfied with probability <span class="math-container">$2^{-l}$</span>. So the expected number of unsatisfied clauses in each formula is <span class="math-container">$2^{-l}n$</span>. So the expected number of unsatisfied clauses in both formulas is <span class="math-container">$2^{1-l}n$</span>. So there exists an assignment in which the total number of unsatisfied clauses is at most <span class="math-container">$2^{1-l}n$</span>. In that assignment, in each formula, at least  <span class="math-container">$(1-2^{1-l})n$</span> clauses are satisfied. 
So we have a constant-factor <span class="math-container">$(1-2^{1-l})$</span> approximation to MAX MIN SAT. </p>

<p>Is there a better approximation? </p>

<p><sub><a href="https://cs.stackexchange.com/q/100375/1342">Posted some weeks ago in cs.SE,</a> with no replies</sub></p></div>
    </summary>
    <updated>2019-01-09T15:31:20Z</updated>
    <published>2019-01-09T15:31:20Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="sat"/>
    <author>
      <name>Erel Segal-Halevi</name>
      <uri>https://cstheory.stackexchange.com/users/9453</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2727898493587029341</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2727898493587029341/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2727898493587029341" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2727898493587029341" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html" rel="alternate" type="text/html"/>
    <title>Search versus Decision</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Shockingly I've never done a post on search versus decision, one of the more interesting dualities in complexity. In short: Decision: Is there a needle in the haystack? Search: Find the needle.<br/>
<br/>
In Satisfiability, or any other NP-complete problem, the two problems are essentially equivalent. If you can decided SAT you can find a solution (good homework problem) or even the best solution. Often people mix up the two, where people say finding the shortest Traveling Salesman Tour is NP-complete, <a href="https://blog.computationalcomplexity.org/2014/01/is-traveling-salesman-np-complete.html">usually</a> without getting into too much trouble.<br/>
<br/>
Decision is always at least as easy as search: If you have a solution you know there is one. What about the other direction? We can't actually prove search is hard without separating P and NP, but we have our conjectures.<br/>
<br/>
Sometimes both are easy. We can easily find the maximum weighted matching.<br/>
<br/>
Sometimes decision is easy and search is supposedly hard: Composite Numbers. The search version is factoring.<br/>
<br/>
Sometimes decision is trivial (i.e. they always exist) and search is still hard. Nash Equilibria. <a href="https://blog.computationalcomplexity.org/2006/05/dispersing-ramsey-graphs.html">Ramsey Graphs</a>.<br/>
<br/>
Often we ask whether search reduces to decision? If you have some oracle (magic black box) that answered decision questions, can you solve the search problem efficiently? SAT has this property, as does Matching (for trivial reasons). Nash Equilibrium and Composite Numbers likely don't.<br/>
<br/>
Graph Isomorphism does, i.e., given an oracle for graph isomorphism you can find the isomorphism (another good homework problem).<br/>
<br/>
There's also an interesting non-adaptive version. Given a SAT formula can you find an assignment with questions to a SAT oracle that all have to be asked at the same time?<br/>
<br/>
Here we get a probable yes. If the formula has one solution you can find it by asking for each bit of the solution. <a href="https://blog.computationalcomplexity.org/2006/09/favorite-theorems-unique-witnesses.html">Randomly you can reduce SAT to several formulas</a>, one of which is likely to have a single assignment that is also an assignment of the original formula. With standard hardness assumptions <a href="https://blog.computationalcomplexity.org/2006/07/full-derandomization.html">you can eliminate the randomness</a>.<br/>
<br/>
Is the same true for graph isomorphism? I think that's still open.</div>
    </content>
    <updated>2019-01-09T13:10:00Z</updated>
    <published>2019-01-09T13:10:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-01-11T09:08:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/</id>
    <link href="https://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Saint Louis University (apply by January 21, 2019)</title>
    <summary>I have a openings for 2 postdocs, both starting in 2019: One is flexible in focus, fitting under the broad categories of computational topology/geometry and algorithms. The other is for a shape simplification project, jointly supervised by Dr. David Letscher, focusing on designing and implementing algorithms that use persistent homology as well as other tools […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have a openings for 2 postdocs, both starting in 2019: One is flexible in focus, fitting under the broad categories of computational topology/geometry and algorithms. The other is for a shape simplification project, jointly supervised by Dr. David Letscher, focusing on designing and implementing algorithms that use persistent homology as well as other tools from computational topology.</p>
<p>Website: <a href="http://cs.slu.edu/~chambers/">http://cs.slu.edu/~chambers/</a><br/>
Email: erin.chambers@slu.edu</p></div>
    </content>
    <updated>2019-01-08T18:05:57Z</updated>
    <published>2019-01-08T18:05:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-01-11T12:20:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42176</id>
    <link href="https://cstheory.stackexchange.com/questions/42176/minimal-dfa-corresponding-to-complement-of-a-language" rel="alternate" type="text/html"/>
    <title>minimal DFA corresponding to complement of a language [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>is it necessary that number of states in minimal DFA for a language corresponding to L' is equal to the number of states in minimal DFA of the language corresponding to L. </p>

<p>here L' is the complement of the language L.</p>

<p>for example,
number of states in the minimal DFA for the language</p>

<p>L={set of all string containing 01 and 011 as the substring over the alphabet {0,1}}</p>

<p>is 4. </p>

<p>if i'm making the DFA for the complement of this language, i'm getting 3. 
but is it true that it should be 4?</p>

<p>please help!! which one is correct-- 3 or 4?</p></div>
    </summary>
    <updated>2019-01-08T14:41:22Z</updated>
    <published>2019-01-08T14:41:22Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="automata-theory"/>
    <author>
      <name>aambazinga</name>
      <uri>https://cstheory.stackexchange.com/users/51682</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42171</id>
    <link href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation" rel="alternate" type="text/html"/>
    <title>Minimum relevant variables in linear system - additive approximation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the problem <a href="https://en.wikipedia.org/wiki/Minimum_relevant_variables_in_linear_system" rel="nofollow noreferrer">Minimum Relevant Variables in Linear System</a> (Min-RVLS), the input is a linear system, e.g.:</p>

<p><span class="math-container">$$ A x = b $$</span></p>

<p>and the goal is to find a solution <span class="math-container">$x$</span> with as few nonzero variables as possible. </p>

<p>The problem is known to be NP-hard and hard to approximate to within a constant multiplicative factor (see the wikipedia page for details). </p>

<p>My question is: is anything known about <em>additive</em> approximations? In particular: what is the complexity of finding a solution that has at most <span class="math-container">$\text{OPT}+d$</span> nonzero variables, where <span class="math-container">$\text{OPT}$</span> is the smallest number of nonzero variables in a solution, and <span class="math-container">$d$</span> is some constant?</p></div>
    </summary>
    <updated>2019-01-07T16:08:53Z</updated>
    <published>2019-01-07T16:08:53Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-algorithms"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="optimization"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="linear-programming"/>
    <category scheme="https://cstheory.stackexchange.com/tags" term="approximation-hardness"/>
    <author>
      <name>Erel Segal-Halevi</name>
      <uri>https://cstheory.stackexchange.com/users/9453</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://cstheory.stackexchange.com/q/42169</id>
    <link href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition" rel="alternate" type="text/html"/>
    <title>Optimal algorithm to compare lines of different files without repetition [on hold]</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have 1600 ASCII files with 1000 lines in each file. Each line has only one entry and is a floating point number e.g. 1.67923.
Let's denote the line1 of file1 with <code>L(1,1)</code>, line2 of file1 with <code>L(1,2)</code> and so forth to ...<code>L(1,1000)</code>. Similarly, line1 of file2 will be <code>L(2,1)</code> and the last line of file1600 will thus be <code>L(1600,1000)</code>.
My task is to come up with a memory efficient algorithm to compare all lines between each file and the lines within each file. Since, I have 1600 files and 1000 lines in each file, it will take approx. <code>10^12</code> calculations. These first comparisons will look like this:</p>

<pre><code>1. {L(1,1)-L(1,2)}, {L(1,1)-L(1,3)},....,{L(1,1)-L(1,1000)}
2. {L(1,1)-L(2,1)}, {L(1,1)-L(2,2)},....,{L(1,1)-L(2,1000)}
3. {L(1,1)-L(3,1)}, {L(1,1)-L(3,2)},....,{L(1,1)-L(3,1000)}
.
.
. 
</code></pre>

<p>Please note that I don't want repetitions i.e <code>{L(1,1)-L(2,1)} = {L(2,1)-L(1,1)}</code>.
I need to code this problem in Fortran but any help on a general scheme as to how the problem needs to be approached will be useful.
Thank you in advance!  </p></div>
    </summary>
    <updated>2019-01-07T15:12:49Z</updated>
    <published>2019-01-07T15:12:49Z</published>
    <category scheme="https://cstheory.stackexchange.com/tags" term="ds.algorithms"/>
    <author>
      <name>Abedin Y. Abedin</name>
      <uri>https://cstheory.stackexchange.com/users/51670</uri>
    </author>
    <source>
      <id>https://cstheory.stackexchange.com/feeds/</id>
      <link href="https://cstheory.stackexchange.com/feeds/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory.stackexchange.com/questions" rel="alternate" type="text/html"/>
      <link href="http://www.creativecommons.org/licenses/by-sa/3.0/rdf" rel="license"/>
      <subtitle>most recent 30 from cstheory.stackexchange.com</subtitle>
      <title>Recent Questions - Theoretical Computer Science Stack Exchange</title>
      <updated>2019-01-11T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1259</id>
    <link href="https://thmatters.wordpress.com/2019/01/07/catcs-mailing-list-and-sign-up-link/" rel="alternate" type="text/html"/>
    <title>CATCS mailing list and sign-up link</title>
    <summary>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at this link. You do not have […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at <a href="https://groups.google.com/forum/#!forum/catcs-news">this link</a>. You do not have to be a member of SIGACT to sign up.<span style="color: #000000; font-family: Arial, sans-serif;"><br/>
</span></p>
<div/></div>
    </content>
    <updated>2019-01-07T08:42:09Z</updated>
    <published>2019-01-07T08:42:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-01-11T12:21:07Z</updated>
    </source>
  </entry>
</feed>
