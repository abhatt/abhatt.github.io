<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-02-20T00:06:28Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07727</id>
    <link href="http://arxiv.org/abs/2002.07727" rel="alternate" type="text/html"/>
    <title>Faster Algorithms for Orienteering and $k$-TSP</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gottlieb:Lee=Ad.html">Lee-Ad Gottlieb</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rika:Havana.html">Havana Rika</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07727">PDF</a><br/><b>Abstract: </b>We consider the rooted orienteering problem in Euclidean space: Given $n$
points $P$ in $\mathbb R^d$, a root point $s\in P$ and a budget $\mathcal B&gt;0$,
find a path that starts from $s$, has total length at most $\mathcal B$, and
visits as many points of $P$ as possible. This problem is known to be NP-hard,
hence we study $(1-\delta)$-approximation algorithms. The previous
Polynomial-Time Approximation Scheme (PTAS) for this problem, due to Chen and
Har-Peled (2008), runs in time $n^{O(d\sqrt{d}/\delta)}(\log
n)^{(d/\delta)^{O(d)}}$, and improving on this time bound was left as an open
problem. Our main contribution is a PTAS with a significantly improved time
complexity of $n^{O(1/\delta)}(\log n)^{(d/\delta)^{O(d)}}$.
</p>
<p>A known technique for approximating the orienteering problem is to reduce it
to solving $1/\delta$ correlated instances of rooted $k$-TSP (a $k$-TSP tour is
one that visits at least $k$ points). However, the $k$-TSP tours in this
reduction must achieve a certain excess guarantee (namely, their length can
surpass the optimum length only in proportion to a parameter of the optimum
called excess) that is stronger than the usual $(1+\delta)$-approximation. Our
main technical contribution is to improve the running time of these $k$-TSP
variants, particularly in its dependence on the dimension $d$. Indeed, our
running time is polynomial even for a moderately large dimension, roughly up to
$d=O(\log\log n)$ instead of $d=O(1)$.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07723</id>
    <link href="http://arxiv.org/abs/2002.07723" rel="alternate" type="text/html"/>
    <title>Discrete Line Fields on Surfaces</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novello:Tiago.html">Tiago Novello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paix=atilde=o:Jo=atilde=o.html">João Paixão</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomei:Carlos.html">Carlos Tomei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lewiner:Thomas.html">Thomas Lewiner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07723">PDF</a><br/><b>Abstract: </b>Vector fields and line fields, their counterparts without orientations on
tangent lines, are familiar objects in the theory of dynamical systems. Among
the techniques used in their study, the Morse--Smale decomposition of a
(generic) field plays a fundamental role, relating the geometric structure of
phase space to a combinatorial object consisting of critical points and
separatrices. Such concepts led Forman to a satisfactory theory of discrete
vector fields, in close analogy to the continuous case. In this paper, we
introduce discrete line fields. Again, our definition is rich enough to provide
the counterparts of the basic results in the theory of continuous line fields:
a Euler-Poincar\'e formula, a Morse--Smale decomposition and a topologically
consistent cancellation of critical elements, which allows for topological
simplification of the original discrete line field.
</p></div>
    </summary>
    <updated>2020-02-20T00:03:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07627</id>
    <link href="http://arxiv.org/abs/2002.07627" rel="alternate" type="text/html"/>
    <title>Topology Optimization with Accessibility Constraint for Multi-Axis Machining</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mirzendehdel:Amir_M=.html">Amir M. Mirzendehdel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behandish:Morad.html">Morad Behandish</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelaturi:Saigopal.html">Saigopal Nelaturi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07627">PDF</a><br/><b>Abstract: </b>In this paper, we present a topology optimization (TO) framework to enable
automated design of mechanical components while ensuring the result can be
manufactured using multi-axis machining. Although TO improves the part's
performance, the as-designed model is often geometrically too complex to be
machined and the as-manufactured model can significantly vary due to machining
constraints that are not accounted for during TO. In other words, many of the
optimized design features cannot be accessed by a machine tool without
colliding with the part (or fixtures). The subsequent post-processing to make
the part machinable with the given setup requires trial-and-error without
guarantees on preserving the optimized performance. Our proposed approach is
based on the well-established accessibility analysis formulation using
convolutions in configuration space that is extensively used in spatial
planning and robotics. We define an 'inaccessibility measure field' (IMF) over
the design domain to identify non-manufacturable features and quantify their
contribution to non-manufacturability. The IMF is used to penalize the
sensitivity field of performance objectives and constraints to prevent
formation of inaccessible regions. Unlike existing discrete formulations, our
IMF provides a continuous spatial field that is desirable for TO convergence.
Our approach applies to arbitrary geometric complexity of the part, tools, and
fixtures, and is highly parallelizable on multi-core architecture. We
demonstrate the effectiveness of our framework on benchmark and realistic
examples in 2D and 3D. We also show that it is possible to directly construct
manufacturing plans for the optimized designs based on the accessibility
information.
</p></div>
    </summary>
    <updated>2020-02-20T00:03:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07611</id>
    <link href="http://arxiv.org/abs/2002.07611" rel="alternate" type="text/html"/>
    <title>Independent Sets of Dynamic Rectangles: Algorithms and Experiments</title>
    <feedworld_mtime>1582156800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Guangping.html">Guangping Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07611">PDF</a><br/><b>Abstract: </b>We study the maximal independent set (MIS) and maximum independent set
(MAX-IS) problems on dynamic sets of $O(n)$ axis-parallel rectangles, which can
be modeled as dynamic rectangle intersection graphs. We consider the fully
dynamic vertex update (insertion/deletion) model for two types of rectangles:
(i) uniform height and width and (ii) uniform height and arbitrary width. These
types of dynamic vertex update problems arise, e.g., in interactive map
labeling. We present the first deterministic algorithm for maintaining a MIS
(and thus a 4-approximate MAX-IS) of a dynamic set of uniform rectangles with
amortized sub-logarithmic update time. This breaks the natural barrier of
$O(\Delta)$ update time (where $\Delta$ is the maximum degree in the graph) for
vertex updates presented by Assadi et al. (STOC 2018). We continue by
investigating MAX-IS and provide a series of deterministic dynamic
approximation schemes. For uniform rectangles, we first give an algorithm that
maintains a $4$-approximate MAX-IS with $O(1)$ update time. In a subsequent
algorithm, we establish the trade-off between approximation quality
$2(1+\frac{1}{k})$ and update time $O(k^2\log n)$ for $k\in \mathbb{N}$. We
conclude with an algorithm that maintains a $2$-approximate MAX-IS for dynamic
sets of uniform height and arbitrary width rectangles with $O(\omega \log n)$
update time, where $\omega$ is the largest number of maximal cliques stabbed by
any axis-parallel line. We have implemented our algorithms and report the
results of an experimental comparison exploring the trade-off between solution
size and update time for synthetic and real-world map labeling data sets.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/019" rel="alternate" type="text/html"/>
    <title>TR20-019 |  A note on the explicit constructions of tree codes over polylogarithmic-sized alphabet | 

	Siddharth Bhandari, 

	Prahladh Harsha</title>
    <summary>Recently, Cohen, Haeupler and Schulman gave an explicit construction of binary tree codes over polylogarithmic-sized output alphabet based on Pudl\'{a}k's construction of maximum-distance-separable (MDS)  tree codes using totally-non-singular triangular matrices. In this short note, we give a unified and simpler presentation of Pudl\'{a}k and Cohen-Haeupler-Schulman's constructions.</summary>
    <updated>2020-02-19T15:04:50Z</updated>
    <published>2020-02-19T15:04:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-20T00:04:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/</id>
    <link href="https://cstheory-jobs.org/2020/02/19/associate-professor-professor-of-computer-science-at-university-of-oxford-apply-by-april-24-2020/" rel="alternate" type="text/html"/>
    <title>Associate Professor/Professor of Computer Science at University of Oxford (apply by April 24, 2020)</title>
    <summary>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science and St Catherine’s College are recruiting an Associate Professor of Computer Science in the Department of Computer Science, to start before 31 July 2020 if possible and by no later than 1 October 2020. The successful candidate will also be appointed as Fellow and Tutor in Computer Science at St Catherine’s College. (see link for details)</p>
<p>Website: <a href="http://www.cs.ox.ac.uk/news/1782-full.html">http://www.cs.ox.ac.uk/news/1782-full.html</a><br/>
Email: agalanis@cs.ox.ac.uk</p></div>
    </content>
    <updated>2020-02-19T13:29:42Z</updated>
    <published>2020-02-19T13:29:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-02-20T00:04:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07800</id>
    <link href="http://arxiv.org/abs/2002.07800" rel="alternate" type="text/html"/>
    <title>Dynamic Graph Algorithms with Batch Updates in the Massively Parallel Computation Model</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nowicki:Krzysztof.html">Krzysztof Nowicki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onak:Krzysztof.html">Krzysztof Onak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07800">PDF</a><br/><b>Abstract: </b>We study dynamic graph algorithms in the Massively Parallel Computation model
(MPC), inspired by practical data processing systems. Our goal is to provide
algorithms that can efficiently handle large batches of edge insertions and
deletions.
</p>
<p>We show algorithms that require fewer rounds to update a solution to problems
such as Minimum Spanning Forest and Maximal Matching than would be required by
their static counterparts to compute it from scratch. They work in the most
restrictive memory regime, in which local memory per machine is strongly
sublinear in the number of graph vertices. Improving on the size of the batch
they can handle would improve on the round complexity of known static
algorithms on sparse graphs.
</p>
<p>More precisely, we provide $O(1)$ round algorithms that can process a batch
of updated of size $O(S)$ for the Minimum Spanning Forest problem and a batch
of updates of size $O(S^{1-\varepsilon})$ for the Maximal Matching problem,
where $S$ is the limit on the local memory of a single machine.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07799</id>
    <link href="http://arxiv.org/abs/2002.07799" rel="alternate" type="text/html"/>
    <title>Polynomial Time Algorithms for Tracking Path Problems</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choudhary:Pratibha.html">Pratibha Choudhary</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07799">PDF</a><br/><b>Abstract: </b>Given a graph $G$, and terminal vertices $s$ and $t$, the TRACKING PATHS
problem asks to compute a minimum number of vertices to be marked as trackers,
such that the sequence of trackers encountered in each s-t path is unique.
TRACKING PATHS is NP-hard in both directed and undirected graphs in general. In
this paper we give a collection of polynomial time algorithms for some
restricted versions of TRACKING PATHS. We prove that TRACKING PATHS is
polynomial time solvable for chordal graphs and tournament graphs. We prove
that TRACKING PATHS is NP-hard in graphs with bounded maximum degree
$\delta\geq 6$, and give a $2(\delta+1)$-approximate algorithm for the same. We
also analyze the version of tracking s-t paths where paths are tracked using
edges instead of vertices, and we give a polynomial time algorithm for the
same. Finally, we show how to reconstruct an s-t path, given a sequence of
trackers and a tracking set for the graph in consideration.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07797</id>
    <link href="http://arxiv.org/abs/2002.07797" rel="alternate" type="text/html"/>
    <title>Probabilistically Faulty Searching on a Half-Line</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonato:Anthony.html">Anthony Bonato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Georgiou:Konstantinos.html">Konstantinos Georgiou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/MacRury:Calum.html">Calum MacRury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pralat:Pawel.html">Pawel Pralat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07797">PDF</a><br/><b>Abstract: </b>We study $p$-Faulty Search, a variant of the classic cow-path optimization
problem, where a unit speed robot searches the half-line (or $1$-ray) for a
hidden item. The searcher is probabilistically faulty, and detection of the
item with each visitation is an independent Bernoulli trial whose probability
of success $p$ is known. The objective is to minimize the worst case expected
detection time, relative to the distance of the hidden item to the origin. A
variation of the same problem was first proposed by Gal in 1980. Then in 2003,
Alpern and Gal [The Theory of Search Games and Rendezvous] proposed a so-called
monotone solution for searching the line ($2$-rays); that is, a trajectory in
which the newly searched space increases monotonically in each ray and in each
iteration. Moreover, they conjectured that an optimal trajectory for the
$2$-rays problem must be monotone. We disprove this conjecture when the search
domain is the half-line ($1$-ray). We provide a lower bound for all monotone
algorithms, which we also match with an upper bound. Our main contribution is
the design and analysis of a sequence of refined search strategies, outside the
family of monotone algorithms, which we call $t$-sub-monotone algorithms. Such
algorithms induce performance that is strictly decreasing with $t$, and for all
$p \in (0,1)$. The value of $t$ quantifies, in a certain sense, how much our
algorithms deviate from being monotone, demonstrating that monotone algorithms
are sub-optimal when searching the half-line.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07784</id>
    <link href="http://arxiv.org/abs/2002.07784" rel="alternate" type="text/html"/>
    <title>k-means++: few more steps yield constant approximation</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choo:Davin.html">Davin Choo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grunau:Christoph.html">Christoph Grunau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Portmann:Julian.html">Julian Portmann</a>, Václav Rozhoň <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07784">PDF</a><br/><b>Abstract: </b>The k-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is a
state-of-the-art algorithm for solving the k-means clustering problem and is
known to give an O(log k)-approximation in expectation. Recently, Lattanzi and
Sohler (ICML 2019) proposed augmenting k-means++ with O(k log log k) local
search steps to yield a constant approximation (in expectation) to the k-means
clustering problem. In this paper, we improve their analysis to show that, for
any arbitrarily small constant $\eps &gt; 0$, with only $\eps k$ additional local
search steps, one can achieve a constant approximation guarantee (with high
probability in k), resolving an open problem in their paper.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07782</id>
    <link href="http://arxiv.org/abs/2002.07782" rel="alternate" type="text/html"/>
    <title>A note on maximizing the difference between a monotone submodular function and a linear function</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ene:Alina.html">Alina Ene</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07782">PDF</a><br/><b>Abstract: </b>Motivated by team formation applications, we study discrete optimization
problems of the form $\max_{S\in\mathcal{S}}\left(f(S)-w(S)\right)$, where
$f:2^{V}\to\mathbb{R_{+}}$ is a non-negative monotone submodular function,
$w:2^{V}\to\mathbb{R}_{+}$ is a non-negative linear function, and
$\mathcal{S}\subseteq2^{V}$. We give very simple and efficient algorithms for
classical constraints, such as cardinality and matroid, that work in a variety
of models, including the offline, online, and streaming. Our algorithms use a
very simple scaling approach: we pick an absolute constant $c\geq1$ and
optimize the function $f(S)-c\cdot w(S)$ using a black-box application of
standard algorithms, such as the classical Greedy algorithm and the
single-threshold Greedy algorithm. These algorithms are based on recent works
that use (time varying) scaling combined with classical algorithms such as the
discrete and continuous Greedy algorithms (Feldman, WADS'19; Harshaw \emph{et
al.}, ICML'19).
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07761</id>
    <link href="http://arxiv.org/abs/2002.07761" rel="alternate" type="text/html"/>
    <title>Fixed-Parameter Tractability of the Weighted Edge Clique Partition Problem</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Issac:Davis.html">Davis Issac</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rai:Ashutosh.html">Ashutosh Rai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07761">PDF</a><br/><b>Abstract: </b>We develop an FPT algorithm and a kernel for the Weighted Edge Clique
Partition (WECP) problem, where a graph with $n$ vertices and integer edge
weights is given together with an integer $k$, and the aim is to find $k$
cliques, such that every edge appears in exactly as many cliques as its weight.
The problem has been previously only studied in the unweighted version called
Edge Clique Partition (ECP), where the edges need to be partitioned into $k$
cliques. It was shown that ECP admits a kernel with $k^2$ vertices [Mujuni and
Rosamond, 2008], but this kernel does not extend to WECP. The previously
fastest algorithm known for ECP had a runtime of $2^{O(k^2)}n^{O(1)}$ [Issac,
2019]. For WECP we develop a bi-kernel with $4^k$ vertices, and an algorithm
with runtime $2^{O(k^{3/2}w^{1/2}\log(k/w))}n^{O(1)}$, where $w$ is the maximum
edge weight. The latter in particular improves the runtime for ECP
to~$2^{O(k^{3/2}\log k)}n^{O(1)}$. We also show that our algorithm necessarily
needs a runtime of $2^{\Theta(k^{3/2}\log k)}n^{O(1)}$ to solve ECP.
</p></div>
    </summary>
    <updated>2020-02-19T23:55:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07746</id>
    <link href="http://arxiv.org/abs/2002.07746" rel="alternate" type="text/html"/>
    <title>Fuzzy Simultaneous Congruences</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deppert:Max_A=.html">Max A. Deppert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klein:Kim=Manuel.html">Kim-Manuel Klein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07746">PDF</a><br/><b>Abstract: </b>We introduce a very natural generalization of the well-known problem of
simultaneous congruences. Instead of searching for a positive integer $s$ that
is specified by $n$ fixed remainders modulo integer divisors $a_1,\dots,a_n$ we
consider remainder intervals $R_1,\dots,R_n$ such that $s$ is feasible if and
only if $s$ is congruent to $r_i$ modulo $a_i$ for some remainder $r_i$ in
interval $R_i$ for all $i$.
</p>
<p>This problem is a special case of a 2-stage integer program with only two
variables per constraint which is is closely related to directed Diophantine
approximation as well as the mixing set problem. We give a hardness result
showing that the problem is NP-hard in general.
</p>
<p>Motivated by the study of the mixing set problem and a recent result in the
field of real-time systems we investigate the case of harmonic divisors, i.e.
$a_{i+1}/a_i$ is an integer for all $i&lt;n$. We present an algorithm to decide
the feasibility of an instance in time $\mathcal{O}(n^2)$ and we show that even
the smallest feasible solution can be computed in strongly polynomial time
$\mathcal{O}(n^3)$.
</p></div>
    </summary>
    <updated>2020-02-19T23:52:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07745</id>
    <link href="http://arxiv.org/abs/2002.07745" rel="alternate" type="text/html"/>
    <title>N-fold integer programming via LP rounding</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jana Cslovjecsek, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eisenbrand:Friedrich.html">Friedrich Eisenbrand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weismantel:Robert.html">Robert Weismantel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07745">PDF</a><br/><b>Abstract: </b>We consider N-fold integer programming problems. After a decade of continuous
progress, the currently fastest algorithm for N-fold integer programming by
Jansen et al. (2019) has a running time of $(rs\Delta)^{O(r^2s + s^2)} {\phi}^2
\cdot nt \log^{O(1)}(nt)$. Here ${\phi}$ is the largest binary encoding length
of a number in the input. This algorithm, like its predecessors are based on
the augmentation framework, a tailored integer programming variant of local
search. In this paper we propose a different approach that is not based on
augmentation. Our algorithm relies on a stronger LP-relaxation of the N-fold
integer program instead. This relaxation can be solved in polynomial time with
parameter dependence $(s{\Delta})^{O(s^2)}$ by resorting to standard techniques
from convex optimization. We show that, for any given optimal vertex solution
$x^*$ of this relaxation, there exists an optimal integer solution $z^*$ that
is within short $\ell_1$-distance, namely $\|x^* - z^*\|_{1} \leq
(rs\Delta)^{O(rs)}$. With dynamic programming one can then find an optimal
integer solution of the N-fold IP in time $(rs\Delta)^{O(r^2s + s^2)} \,nt $.
This, together with an off-the-shelf-method from convex optimization, results
in the currently fastest algorithm for N-fold integer programming.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07741</id>
    <link href="http://arxiv.org/abs/2002.07741" rel="alternate" type="text/html"/>
    <title>Default Ambiguity: Finding the Best Solution to the Clearing Problem</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papp:P=aacute=l_Andr=aacute=s.html">Pál András Papp</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wattenhofer:Roger.html">Roger Wattenhofer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07741">PDF</a><br/><b>Abstract: </b>We study financial networks with debt contracts and credit default swaps
between specific pairs of banks. Given such a financial system, we want to
decide which of the banks are in default, and how much of their liabilities
these defaulting banks can pay. There can easily be multiple different
solutions to this problem, leading to a situation of default ambiguity and a
range of possible solutions to implement for a financial authority.
</p>
<p>In this paper, we study the general properties of the solution space of such
financial systems, and analyze a wide range of reasonable objective functions
for selecting from the set of solutions. Examples of such objective functions
include minimizing the number of defaulting banks, minimizing the amount of
unpaid debt, maximizing the number of satisfied banks, maximizing the equity of
a specific bank, finding the most balanced distribution of equity, and many
others. We show that for all of these objective functions, it is not only
NP-hard to find the optimal solution, but it is also NP-hard to approximate
this optimum: for each objective function, we show an inapproximability either
to an $n^{1/2-\epsilon}$ or to an $n^{1/4-\epsilon}$ factor for any
$\epsilon&gt;0$, with $n$ denoting the number of banks in the system. Thus even if
an authority has clear criteria to select a solution in case of default
ambiguity, it is computationally intractable to find a solution that is
reasonably good in terms of this criteria. We also show that our hardness
results hold in a wide range of different model variants.
</p></div>
    </summary>
    <updated>2020-02-19T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07698</id>
    <link href="http://arxiv.org/abs/2002.07698" rel="alternate" type="text/html"/>
    <title>Dynamics of Cycles in Polyhedra I: The Isolation Lemma</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kessler:Jan.html">Jan Kessler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Jens_M=.html">Jens M. Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07698">PDF</a><br/><b>Abstract: </b>A cycle $C$ of a graph $G$ is \emph{isolating} if every component of $G-V(C)$
is a single vertex. We show that isolating cycles in polyhedral graphs can be
extended to larger ones: every isolating cycle $C$ of length $8 \leq |E(C)| &lt;
\frac{2}{3}(|V(G)|+3)$ implies an isolating cycle $C'$ of larger length that
contains $V(C)$. By ``hopping'' iteratively to such larger cycles, we obtain a
powerful and very general inductive motor for proving and computing long cycles
(we will give an algorithm with running time $O(n^2)$). This provides a method
to prove lower bounds on Tutte cycles, as $C'$ will be a Tutte cycle of $G$ if
$C$ is. We also prove that $E(C') \leq E(C)+3$ if $G$ does not contain faces of
size five, which gives a new tool for proving results about cycle spectra and
evidence that these face sizes obstruct long cycles. As a sample application,
we test our motor on a conjecture on essentially 4-connected graphs. A planar
graph is \emph{essentially $4$-connected} if it is 3-connected and every of its
3-separators is the neighborhood of a single vertex. Essentially $4$-connected
graphs have been thoroughly investigated throughout literature as the subject
of Hamiltonicity studies. Jackson and Wormald proved that every essentially
4-connected planar graph $G$ on $n$ vertices contains a cycle of length at
least $\frac{2}{5}(n+2)$, and this result has recently been improved multiple
times, culminating in the lower bound $\frac{5}{8}(n+2)$. However, the best
known upper bound is given by an infinite family of such graphs in which every
graph $G$ on $n$ vertices has no cycle longer than $\frac{2}{3}(n+4)$; this
upper bound is still unmatched. Using isolating cycles, we improve the lower
bound to match the upper (up to a summand $+1$). This settles the long-standing
open problem of determining the circumference of essentially 4-connected planar
graphs.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07695</id>
    <link href="http://arxiv.org/abs/2002.07695" rel="alternate" type="text/html"/>
    <title>Computing the k Densest Subgraphs of a Graph</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dondi:Riccardo.html">Riccardo Dondi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07695">PDF</a><br/><b>Abstract: </b>Computing cohesive subgraphs is a central problem in graph theory. While many
formulations of cohesive subgraphs lead to NP-hard problems, finding a densest
subgraph can be done in polynomial time. As such, the densest subgraph model
has emerged as the most popular notion of cohesiveness. Recently, the data
mining community has started looking into the problem of computing k densest
subgraphs in a given graph, rather than one, with various restrictions on the
possible overlap between the subgraphs. However, there seems to be very little
known on this important and natural generalization from a theoretical
perspective. In this paper we hope to remedy this situation by analyzing three
natural variants of the k densest subgraphs problem. Each variant differs
depending on the amount of overlap that is allowed between the subgraphs. In
one extreme, when no overlap is allowed, we prove that the problem is NP-hard
for k &gt;= 3, but polynomial-time solvable for k &lt;= 2. On the other extreme, when
overlap is allowed without any restrictions and the solution subgraphs only
have to be distinct, we show that the problem is fixed-parameter tractable with
respect to k, and admits a PTAS for constant k. Finally, when a limited of
overlap is allowed between the subgraphs, we prove that the problem is NP-hard
for k = 2.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07682</id>
    <link href="http://arxiv.org/abs/2002.07682" rel="alternate" type="text/html"/>
    <title>How to Solve Fair $k$-Center in Massive Data Models</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiplunkar:Ashish.html">Ashish Chiplunkar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kale:Sagar.html">Sagar Kale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramamoorthy:Sivaramakrishnan_Natarajan.html">Sivaramakrishnan Natarajan Ramamoorthy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07682">PDF</a><br/><b>Abstract: </b>Fueled by massive data, important decision making is being automated with the
help of algorithms, therefore, fairness in algorithms has become an especially
important research topic. In this work, we design new streaming and distributed
algorithms for the fair $k$-center problem that models fair data summarization.
The streaming and distributed models of computation have an attractive feature
of being able to handle massive data sets that do not fit into main memory. Our
main contributions are: (a) the first distributed algorithm; which has provably
constant approximation ratio and is extremely parallelizable, and (b) a
two-pass streaming algorithm with a provable approximation guarantee matching
the best known algorithm (which is not a streaming algorithm). Our algorithms
have the advantages of being easy to implement in practice, being fast with
linear running times, having very small working memory and communication, and
outperforming existing algorithms on several real and synthetic data sets. To
complement our distributed algorithm, we also give a hardness result for
natural distributed algorithms, which holds for even the special case of
$k$-center.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07674</id>
    <link href="http://arxiv.org/abs/2002.07674" rel="alternate" type="text/html"/>
    <title>How incomputable is Kolmogorov complexity?</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Paul Vitanyi, CWI, University of Amsterdam <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07674">PDF</a><br/><b>Abstract: </b>Kolmogorov complexity is the length of the ultimately compressed version of a
file (that is, anything which can be put in a computer). Formally, it is the
length of a shortest program from which the file can be reconstructed. We
discuss the incomputabilty of Kolmogorov complexity, which formal loopholes
this leaves us, recent approaches to compute or approximate Kolmogorov
complexity, which approaches fail and which approaches are viable.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07659</id>
    <link href="http://arxiv.org/abs/2002.07659" rel="alternate" type="text/html"/>
    <title>Distributed graph problems through an automata-theoretic lens</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Studen=yacute=:Jan.html">Jan Studený</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07659">PDF</a><br/><b>Abstract: </b>We study the following algorithm synthesis question: given the description of
a locally checkable graph problem $\Pi$ for paths or cycles, determine in which
instances $\Pi$ is solvable, determine what is the distributed round complexity
of solving $\Pi$ in the usual $\mathsf{LOCAL}$ model of distributed computing,
and construct an asymptotically optimal distributed algorithm for solving
$\Pi$.
</p>
<p>To answer such questions, we represent $\Pi$ as a nondeterministic finite
automaton $\mathcal{M}$ over a unary alphabet. We classify the states of
$\mathcal{M}$ into repeatable states, flexible states, mirror-flexible states,
loops, and mirror-flexible loops; all of these can be decided in polynomial
time. We show that these five classes of states completely answer all questions
related to the solvability and distributed computational complexity of $\Pi$ on
cycles.
</p>
<p>On paths, there is one case in which the question of solvability coincides
with the classical universality problem for unary regular languages, and hence
determining if a given problem $\Pi$ is always solvable is
co-$\mathsf{NP}$-complete. However, we show that all other questions, including
the question of determining the distributed round complexity of $\Pi$ and
finding an asymptotically optimal algorithm for solving $\Pi$, can be answered
in polynomial time.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07649</id>
    <link href="http://arxiv.org/abs/2002.07649" rel="alternate" type="text/html"/>
    <title>Distributed Maximum Matching Verification in CONGEST</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahmadi:Mohamad.html">Mohamad Ahmadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07649">PDF</a><br/><b>Abstract: </b>We study the maximum cardinality matching problem in a standard distributed
setting, where the nodes $V$ of a given $n$-node network graph $G=(V,E)$
communicate over the edges $E$ in synchronous rounds. More specifically, we
consider the distributed CONGEST model, where in each round, each node of $G$
can send an $O(\log n)$-bit message to each of its neighbors. We show that for
every graph $G$ and a matching $M$ of $G$, there is a randomized CONGEST
algorithm to verify $M$ being a maximum matching of $G$ in time $O(|M|)$ and
disprove it in time $O(D + \ell)$, where $D$ is the diameter of $G$ and $\ell$
is the length of a shortest augmenting path. We hope that our algorithm
constitutes a significant step towards developing a CONGEST algorithm to
compute a maximum matching in time $\tilde{O}(s^*)$, where $s^*$ is the size of
a maximum matching.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07648</id>
    <link href="http://arxiv.org/abs/2002.07648" rel="alternate" type="text/html"/>
    <title>Compact Merkle Multiproofs</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramabaja:Lum.html">Lum Ramabaja</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Avdullahu:Arber.html">Arber Avdullahu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07648">PDF</a><br/><b>Abstract: </b>The compact Merkle multiproof is a new and significantly more
memory-efficient way to generate and verify sparse Merkle multiproofs. A
standard sparse Merkle multiproof requires to store an index for every non-leaf
hash in the multiproof. The compact Merkle multiproof on the other hand
requires only $k$ leaf indices, where $k$ is the number of elements used for
creating a multiproof. This significantly reduces the size of multirpoofs,
especially for larger Merke trees.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07612</id>
    <link href="http://arxiv.org/abs/2002.07612" rel="alternate" type="text/html"/>
    <title>Building large k-cores from sparse graphs</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sagunov:Danil.html">Danil Sagunov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simonov:Kirill.html">Kirill Simonov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07612">PDF</a><br/><b>Abstract: </b>A popular model to measure network stability is the $k$-core, that is the
maximal induced subgraph in which every vertex has degree at least $k$. For
example, $k$-cores are commonly used to model the unraveling phenomena in
social networks. In this model, users having less than $k$ connections within
the network leave it, so the remaining users form exactly the $k$-core. In this
paper we study the question whether it is possible to make the network more
robust by spending only a limited amount of resources on new connections. A
mathematical model for the $k$-core construction problem is the following Edge
$k$-Core optimization problem. We are given a graph $G$ and integers $k$, $b$
and $p$. The task is to ensure that the $k$-core of $G$ has at least $p$
vertices by adding at most $b$ edges.
</p>
<p>The previous studies on Edge $k$-Core demonstrate that the problem is
computationally challenging. In particular, it is NP-hard when $k=3$, W[1]-hard
being parameterized by $k+b+p$ (Chitnis and Talmon, 2018), and APX-hard (Zhou
et al, 2019). Nevertheless, we show that there are efficient algorithms with
provable guarantee when the $k$-core has to be constructed from a sparse graph
with some additional structural properties. Our results are 1) When the input
graph is a forest, Edge $k$-Core is solvable in polynomial time; 2) Edge
$k$-Core is fixed-parameter tractable (FPT) being parameterized by the minimum
size of a vertex cover in the input graph. On the other hand, with such
parameterization, the problem does not admit a polynomial kernel subject to a
widely-believed assumption from complexity theory; 3) Edge $k$-Core is FPT
parameterized by $\mathrm{tw}+k$. This improves upon the result of Chitnis and
Talmon by not requiring $b$ to be small. Each of our algorithms is built upon a
new graph-theoretical result interesting in its own.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07607</id>
    <link href="http://arxiv.org/abs/2002.07607" rel="alternate" type="text/html"/>
    <title>Manipulating Districts to Win Elections: Fine-Grained Complexity</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panolan:Fahad.html">Fahad Panolan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simonov:Kirill.html">Kirill Simonov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07607">PDF</a><br/><b>Abstract: </b>Gerrymandering is a practice of manipulating district boundaries and
locations in order to achieve a political advantage for a particular party.
Lewenberg, Lev, and Rosenschein [AAMAS 2017] initiated the algorithmic study of
a geographically-based manipulation problem, where voters must vote at the
ballot box closest to them. In this variant of gerrymandering, for a given set
of possible locations of ballot boxes and known political preferences of $n$
voters, the task is to identify locations for $k$ boxes out of $m$ possible
locations to guarantee victory of a certain party in at least $l$ districts.
Here integers $k$ and $l$ are some selected parameter.
</p>
<p>It is known that the problem is NP-complete already for 4 political parties
and prior to our work only heuristic algorithms for this problem were
developed. We initiate the rigorous study of the gerrymandering problem from
the perspectives of parameterized and fine-grained complexity and provide
asymptotically matching lower and upper bounds on its computational complexity.
We prove that the problem is W[1]-hard parameterized by $k+n$ and that it does
not admit an $f(n,k)\cdot m^{o(\sqrt{k})}$ algorithm for any function $f$ of
$k$ and $n$ only, unless Exponential Time Hypothesis (ETH) fails. Our lower
bounds hold already for $2$ parties. On the other hand, we give an algorithm
that solves the problem for a constant number of parties in time
$(m+n)^{O(\sqrt{k})}$.
</p></div>
    </summary>
    <updated>2020-02-19T23:55:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07569</id>
    <link href="http://arxiv.org/abs/2002.07569" rel="alternate" type="text/html"/>
    <title>Multistage s-t Path: Confronting Similarity with Dissimilarity</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fluschnik:Till.html">Till Fluschnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, Carsten Schubert, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zschoche:Philipp.html">Philipp Zschoche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07569">PDF</a><br/><b>Abstract: </b>Addressing a quest by Gupta et al. [ICALP'14], we provide a first,
comprehensive study of finding a short s-t path in the multistage graph model,
referred to as the Multistage s-t Path problem. Herein, given a sequence of
graphs over the same vertex set but changing edge sets, the task is to find
short s-t paths in each graph ("snapshot") such that in the resulting path
sequence the consecutive s-t paths are "similar". We measure similarity by the
size of the symmetric difference of either the vertex set (vertex-similarity)
or the edge set (edge-similarity) of any two consecutive paths. We prove that
the two variants of Multistage s-t Path are already NP-hard for an input
sequence of only two graphs. Motivated by this fact and natural applications of
this scenario e.g. in traffic route planning, we perform a parameterized
complexity analysis. Among other results, we prove parameterized hardness
(W[1]-hardness) regarding the size of the path sequence (solution size) for
both variants, vertex- and edge-similarity. As a novel conceptual contribution,
we then modify the multistage model by asking for dissimilar consecutive paths.
As one of the main results, we prove that dissimilarity allows for
fixed-parameter tractability for the parameter solution size, thereby
contrasting our W[1]-hardness proof of the corresponding similarity case.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07553</id>
    <link href="http://arxiv.org/abs/2002.07553" rel="alternate" type="text/html"/>
    <title>Connecting MapReduce Computations to Realistic Machine Models</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sanders:Peter.html">Peter Sanders</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07553">PDF</a><br/><b>Abstract: </b>We explain how the popular, highly abstract MapReduce model of parallel
computation (MRC) can be rooted in reality by explaining how it can be
simulated on realistic distributed-memory parallel machine models like BSP. We
first refine the model (MRC$^+$) to include parameters for total work $w$,
bottleneck work $\hat{w}$, data volume $m$, and maximum object sizes $\hat{m}$.
We then show matching upper and lower bounds for executing a MapReduce
calculation on the distributed-memory machine -- $\Theta(w/p+\hat{w}+\log p)$
work and $\Theta(m/p+\hat{m}+\log p)$ bottleneck communication volume using $p$
processors.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07466</id>
    <link href="http://arxiv.org/abs/2002.07466" rel="alternate" type="text/html"/>
    <title>Existence and Complexity of Approximate Equilibria in Weighted Congestion Games</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Christodoulou:George.html">George Christodoulou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gairing:Martin.html">Martin Gairing</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giannakopoulos:Yiannis.html">Yiannis Giannakopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Po=ccedil=as:Diogo.html">Diogo Poças</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waldmann:Clara.html">Clara Waldmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07466">PDF</a><br/><b>Abstract: </b>We study the existence of approximate pure Nash equilibria ($\alpha$-PNE) in
weighted atomic congestion games with polynomial cost functions of maximum
degree $d$. Previously it was known that $d$-approximate equilibria always
exist, while nonexistence was established only for small constants, namely for
$1.153$-PNE. We improve significantly upon this gap, proving that such games in
general do not have $\tilde{\Theta}(\sqrt{d})$-approximate PNE, which provides
the first super-constant lower bound.
</p>
<p>Furthermore, we provide a black-box gap-introducing method of combining such
nonexistence results with a specific circuit gadget, in order to derive
NP-completeness of the decision version of the problem. In particular,
deploying this technique we are able to show that deciding whether a weighted
congestion game has an $\tilde{O}(\sqrt{d})$-PNE is NP-complete. Previous
hardness results were known only for the special case of exact equilibria and
arbitrary cost functions.
</p>
<p>The circuit gadget is of independent interest and it allows us to also prove
hardness for a variety of problems related to the complexity of PNE in
congestion games. For example, we demonstrate that the question of existence of
$\alpha$-PNE in which a certain set of players plays a specific strategy
profile is NP-hard for any $\alpha &lt; 3^{d/2}$, even for unweighted congestion
games.
</p>
<p>Finally, we study the existence of approximate equilibria in weighted
congestion games with general (nondecreasing) costs, as a function of the
number of players $n$. We show that $n$-PNE always exist, matched by an almost
tight nonexistence bound of $\tilde\Theta(n)$ which we can again transform into
an NP-completeness proof for the decision problem.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07463</id>
    <link href="http://arxiv.org/abs/2002.07463" rel="alternate" type="text/html"/>
    <title>Coreset-based Strategies for Robust Center-type Problems</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pietracaprina:Andrea.html">Andrea Pietracaprina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pucci:Geppino.html">Geppino Pucci</a>, Federico Soldà <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07463">PDF</a><br/><b>Abstract: </b>Given a dataset $V$ of points from some metric space, the popular $k$-center
problem requires to identify a subset of $k$ points (centers) in $V$ minimizing
the maximum distance of any point of $V$ from its closest center. The
\emph{robust} formulation of the problem features a further parameter $z$ and
allows up to $z$ points of $V$ (outliers) to be disregarded when computing the
maximum distance from the centers. In this paper, we focus on two important
constrained variants of the robust $k$-center problem, namely, the Robust
Matroid Center (RMC) problem, where the set of returned centers are constrained
to be an independent set of a matroid of rank $k$ built on $V$, and the Robust
Knapsack Center (RKC) problem, where each element $i\in V$ is given a positive
weight $w_i&lt;1$ and the aggregate weight of the returned centers must be at most
1. We devise coreset-based strategies for the two problems which yield
efficient sequential, MapReduce, and Streaming algorithms. More specifically,
for any fixed $\epsilon&gt;0$, the algorithms return solutions featuring a
$(3+\epsilon)$-approximation ratio, which is a mere additive term $\epsilon$
away from the 3-approximations achievable by the best known polynomial-time
sequential algorithms for the two problems. Moreover, the algorithms
obliviously adapt to the intrinsic complexity of the dataset, captured by its
doubling dimension $D$. For wide ranges of the parameters $k,z,\epsilon, D$, we
obtain a sequential algorithm with running time linear in $|V|$, and
MapReduce/Streaming algorithms with few rounds/passes and substantially
sublinear local/working memory.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07448</id>
    <link href="http://arxiv.org/abs/2002.07448" rel="alternate" type="text/html"/>
    <title>Generating random bigraphs with preferential attachment</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grzelak:Dominik.html">Dominik Grzelak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Priwitzer:Barbara.html">Barbara Priwitzer</a>, Uwe Aßmann Software Technology Group at Technische Universität Dresden, Centre for Tactile Internet with Human-in-the-Loop at Technische Universität Dresden, Fakultät Technik at Hochschule Reutlingen) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07448">PDF</a><br/><b>Abstract: </b>The bigraph theory is a relatively young, yet formally rigorous, mathematical
framework encompassing Robin Milner's previous work on process calculi, on the
one hand, and provides a generic meta-model for complex systems such as
multi-agent systems, on the other. A bigraph $F = \langle F^P, F^L\rangle$ is a
superposition of two independent graph structures comprising a place graph
$F^P$ (i.e., a forest) and a link graph $F^L$ (i.e., a hypergraph), sharing the
same node set, to express locality and communication of processes independently
from each other.
</p>
<p>In this paper, we take some preparatory steps towards an algorithm for
generating random bigraphs with preferential attachment feature w.r.t. $F^P$
and assortative (disassortative) linkage pattern w.r.t. $F^L$. We employ
parameters allowing one to fine-tune the characteristics of the generated
bigraph structures. To study the pattern formation properties of our
algorithmic model, we analyze several metrics from graph theory based on
artificially created bigraphs under different configurations.
</p>
<p>Bigraphs provide a quite useful and expressive semantic for process calculi
for mobile and global ubiquitous computing. So far, this subject has not
received attention in the bigraph-related scientific literature. However,
artificial models may be particularly useful for simulation and evaluation of
real-world applications in ubiquitous systems necessitating random structures.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07444</id>
    <link href="http://arxiv.org/abs/2002.07444" rel="alternate" type="text/html"/>
    <title>Multiparty Karchmer-Wigderson Games and Threshold Circuits</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozachinskiy:Alexander.html">Alexander Kozachinskiy</a>, Vladimir Podolskii <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07444">PDF</a><br/><b>Abstract: </b>We suggest a generalization of Karchmer-Wigderson communication games to the
multiparty setting. Our generalization turns out to be tightly connected to
circuits consisting of threshold gates. This allows us to obtain new explicit
constructions of such circuits for several functions. In particular, we provide
an explicit (polynomial-time computable) log-depth monotone formula for
Majority function, consisting only of 3-bit majority gates and variables. This
resolves a conjecture of Cohen et al. (CRYPTO 2013).
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07415</id>
    <link href="http://arxiv.org/abs/2002.07415" rel="alternate" type="text/html"/>
    <title>On the Fine-Grained Complexity of Parity Problems</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abboud:Amir.html">Amir Abboud</a>, Shon Feller, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weimann:Oren.html">Oren Weimann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07415">PDF</a><br/><b>Abstract: </b>We consider the parity variants of basic problems studied in fine-grained
complexity. We show that finding the exact solution is just as hard as finding
its parity (i.e. if the solution is even or odd) for a large number of
classical problems, including All-Pairs Shortest Paths (APSP), Diameter,
Radius, Median, Second Shortest Path, Maximum Consecutive Subsums, Min-Plus
Convolution, and $0/1$-Knapsack.
</p>
<p>A direct reduction from a problem to its parity version is often difficult to
design. Instead, we revisit the existing hardness reductions and tailor them in
a problem-specific way to the parity version. Nearly all reductions from APSP
in the literature proceed via the (subcubic-equivalent but simpler) Negative
Weight Triangle (NWT) problem. Our new modified reductions also start from NWT
or a non-standard parity variant of it. We are not able to establish a
subcubic-equivalence with the more natural parity counting variant of NWT,
where we ask if the number of negative triangles is even or odd. Perhaps
surprisingly, we justify this by designing a reduction from the
seemingly-harder Zero Weight Triangle problem, showing that parity is
(conditionally) strictly harder than decision for NWT.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07363</id>
    <link href="http://arxiv.org/abs/2002.07363" rel="alternate" type="text/html"/>
    <title>The Complexity of Interactively Learning a Stable Matching by Trial and Error</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emamjomeh=Zadeh:Ehsan.html">Ehsan Emamjomeh-Zadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gonczarowski:Yannai_A=.html">Yannai A. Gonczarowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kempe:David.html">David Kempe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07363">PDF</a><br/><b>Abstract: </b>In a stable matching setting, we consider a query model that allows for an
interactive learning algorithm to make precisely one type of query: proposing a
matching, the response to which is either that the proposed matching is stable,
or a blocking pair (chosen adversarially) indicating that this matching is
unstable. For one-to-one matching markets, our main result is an essentially
tight upper bound of $O(n^2\log n)$ on the deterministic query complexity of
interactively learning a stable matching in this coarse query model, along with
an efficient randomized algorithm that achieves this query complexity with high
probability. For many-to-many matching markets in which participants have
responsive preferences, we first give an interactive learning algorithm whose
query complexity and running time are polynomial in the size of the market if
the maximum quota of each agent is bounded; our main result for many-to-many
markets is that the deterministic query complexity can be made polynomial (more
specifically, $O(n^3 \log n)$) in the size of the market even for arbitrary
(e.g., linear in the market size) quotas.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07342</id>
    <link href="http://arxiv.org/abs/2002.07342" rel="alternate" type="text/html"/>
    <title>An Upper Bound for Sorting $R_n$ with LRE</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sai Satwik Kuppili, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chitturi:Bhadrachalam.html">Bhadrachalam Chitturi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07342">PDF</a><br/><b>Abstract: </b>A permutation $\pi$ over alphabet $\Sigma = {1,2,3,\ldots,n}$, is a sequence
where every element $x$ in $\Sigma$ occurs exactly once. $S_n$ is the symmetric
group consisting of all permutations of length $n$ defined over $\Sigma$. $I_n$
= $(1, 2, 3,\ldots, n)$ and $R_n =(n, n-1, n-2,\ldots, 2, 1)$ are identity
(i.e. sorted) and reverse permutations respectively. An operation, that we call
as an $LRE$ operation, has been defined in OEIS with identity A186752. This
operation is constituted by three generators: left-rotation, right-rotation and
transposition(1,2). We call transposition(1,2) that swaps the two leftmost
elements as $Exchange$. The minimum number of moves required to transform $R_n$
into $I_n$ with $LRE$ operation are known for $n \leq 11$ as listed in OEIS
with sequence number A186752. For this problem no upper bound is known. OEIS
sequence A186783 gives the conjectured diameter of the symmetric group $S_n$
when generated by $LRE$ operations \cite{oeis}. The contributions of this
article are: (a) The first non-trivial upper bound for the number of moves
required to sort $R_n$ with $LRE$; (b) a tighter upper bound for the number of
moves required to sort $R_n$ with $LRE$; and (c) the minimum number of moves
required to sort $R_{10}$ and $R_{11}$ have been computed. Here we are
computing an upper bound of the diameter of Cayley graph generated by $LRE$
operation. Cayley graphs are employed in computer interconnection networks to
model efficient parallel architectures. The diameter of the network corresponds
to the maximum delay in the network.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07336</id>
    <link href="http://arxiv.org/abs/2002.07336" rel="alternate" type="text/html"/>
    <title>Noisy source location on a line</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lecomte:Victor.html">Victor Lecomte</a>, Gergely Ódor, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thiran:Patrick.html">Patrick Thiran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07336">PDF</a><br/><b>Abstract: </b>We study the problem of locating the source of an epidemic diffusion process
from a sparse set of sensors, under noise. In a graph $G=(V,E)$, an unknown
source node $v^* \in V$ is drawn uniformly at random, and unknown edge weights
$w(e)$ for $e\in E$, representing the propagation delays along the edges, are
drawn independently from a Gaussian distribution of mean $1$ and variance
$\sigma^2$. An algorithm then attempts to locate $v^*$ by picking sensor (also
called query) nodes $s \in V$ and being told the length of the shortest path
between $s$ and $v^*$ in graph $G$ weighted by $w$. We consider two settings:
static, in which all query nodes must be decided in advance, and sequential, in
which each query can depend on the results of the previous ones.
</p>
<p>We characterize the query complexity when $G$ is an $n$-node path. In the
static setting, $\Theta(n\sigma^2)$ queries are needed for $\sigma^2 \leq 1$,
and $\Theta(n)$ for $\sigma^2 \geq 1$. In the sequential setting, somewhat
surprisingly, only $\Theta(\log\log_{1/\sigma}n)$ are needed when $\sigma^2
\leq 1/2$, and $\Theta(\log \log n)+O_\sigma(1)$ when $\sigma^2 \geq 1/2$. This
is the first mathematical study of source location under non-trivial amounts of
noise.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07287</id>
    <link href="http://arxiv.org/abs/2002.07287" rel="alternate" type="text/html"/>
    <title>Sorting and Ranking of Self-Delimiting Numbers with Applications to Tree Isomorphism</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kammer:Frank.html">Frank Kammer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sajenko:Andrej.html">Andrej Sajenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07287">PDF</a><br/><b>Abstract: </b>Assume that an $N$-bit sequence $S$ of $k$ self-delimiting numbers is given
as input. We present space-efficient algorithms for sorting, dense ranking and
(competitive) ranking $S$ on the word RAM model with word size $\Omega(\log
N)$. Our algorithms run in $O(k + \frac{N}{\log N})$ time and use $O(N)$ bits.
The sorting algorithm returns the given numbers in sorted order stored within a
bit-vector of $N$ bits whereas our ranking algorithms construct data structures
that allows us subsequently to return the (dense) rank of each number $x$ in
$S$ in constant time if the position of $x$ in $S$ is given together with $x$.
As an application of our algorithms we give an algorithm for tree isomorphism
that runs in $O(n)$ time and uses $O(n)$ bits on $n$-node trees.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07249</id>
    <link href="http://arxiv.org/abs/2002.07249" rel="alternate" type="text/html"/>
    <title>Integrating products of quadratic forms</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexander Barvinok <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07249">PDF</a><br/><b>Abstract: </b>We prove that if $q_1, \ldots, q_m: {\Bbb R}^n \longrightarrow {\Bbb R}$ are
quadratic forms in variables $x_1, \ldots, x_n$ such that each $q_k$ depends on
at most $r$ variables and each $q_k$ has common variables with at most $r$
other forms, then the average value of the product $\left(1+ q_1\right) \cdots
\left(1+q_m\right)$ with respect to the standard Gaussian measure in ${\Bbb
R}^n$ can be approximated within relative error $\epsilon &gt;0$ in
quasi-polynomial $n^{O(1)} m^{O(\ln m -\ln \epsilon)}$ time, provided $|q_k(x)|
\leq \gamma \|x\|^2 /r$ for some absolute constant $\gamma &gt; 0$ and $k=1,
\ldots, m$. When $q_k$ are interpreted as pairwise squared distances for
configurations of points in Euclidean space, the average can be interpreted as
the partition function of systems of particles with mollified logarithmic
potentials. We sketch a possible application to testing the feasibility of
systems of real quadratic equations.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07235</id>
    <link href="http://arxiv.org/abs/2002.07235" rel="alternate" type="text/html"/>
    <title>Time-Space Tradeoffs for Distinguishing Distributions and Applications to Security of Goldreich's PRG</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Sumegha.html">Sumegha Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Pravesh_K=.html">Pravesh K. Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Ran.html">Ran Raz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07235">PDF</a><br/><b>Abstract: </b>In this work, we establish lower-bounds against memory bounded algorithms for
distinguishing between natural pairs of related distributions from samples that
arrive in a streaming setting.
</p>
<p>In our first result, we show that any algorithm that distinguishes between
uniform distribution on $\{0,1\}^n$ and uniform distribution on an
$n/2$-dimensional linear subspace of $\{0,1\}^n$ with non-negligible advantage
needs $2^{\Omega(n)}$ samples or $\Omega(n^2)$ memory.
</p>
<p>Our second result applies to distinguishing outputs of Goldreich's local
pseudorandom generator from the uniform distribution on the output domain.
Specifically, Goldreich's pseudorandom generator $G$ fixes a predicate
$P:\{0,1\}^k \rightarrow \{0,1\}$ and a collection of subsets $S_1, S_2,
\ldots, S_m \subseteq [n]$ of size $k$. For any seed $x \in \{0,1\}^n$, it
outputs $P(x_{S_1}), P(x_{S_2}), \ldots, P(x_{S_m})$ where $x_{S_i}$ is the
projection of $x$ to the coordinates in $S_i$. We prove that whenever $P$ is
$t$-resilient (all non-zero Fourier coefficients of $(-1)^P$ are of degree $t$
or higher), then no algorithm, with $&lt;n^\epsilon$ memory, can distinguish the
output of $G$ from the uniform distribution on $\{0,1\}^m$ with a large inverse
polynomial advantage, for stretch $m \le
\left(\frac{n}{t}\right)^{\frac{(1-\epsilon)}{36}\cdot t}$ (barring some
restrictions on $k$). The lower bound holds in the streaming model where at
each time step $i$, $S_i\subseteq [n]$ is a randomly chosen (ordered) subset of
size $k$ and the distinguisher sees either $P(x_{S_i})$ or a uniformly random
bit along with $S_i$.
</p>
<p>Our proof builds on the recently developed machinery for proving time-space
trade-offs (Raz 2016 and follow-ups) for search/learning problems.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07211</id>
    <link href="http://arxiv.org/abs/2002.07211" rel="alternate" type="text/html"/>
    <title>Spectrum preserving short cycle removal on regular graphs</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paredes:Pedro.html">Pedro Paredes</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07211">PDF</a><br/><b>Abstract: </b>We describe a new method to remove short cycles on regular graphs while
maintaining spectral bounds (the nontrivial eigenvalues of the adjacency
matrix), as long as the graphs have certain combinatorial properties. These
combinatorial properties are related to the number and distance between short
cycles and are known to happen with high probability in uniformly random
regular graphs.
</p>
<p>Using this method we can show two results involving high girth spectral
expander graphs. First, we show that given $d \geq 3$ and $n$, there exists an
explicit distribution of $d$-regular $\Theta(n)$-vertex graphs where with high
probability its samples have girth $\Omega(\log_{d - 1} n)$ and are
$\epsilon$-near-Ramanujan; i.e., its eigenvalues are bounded in magnitude by
$2\sqrt{d - 1} + \epsilon$ (excluding the single trivial eigenvalue of $d$).
Then, for every constant $d \geq 3$ and $\epsilon &gt; 0$, we give a deterministic
poly$(n)$-time algorithm that outputs a $d$-regular graph on
$\Theta(n)$-vertices that is $\epsilon$-near-Ramanujan and has girth
$\Omega(\sqrt{\log n})$, based on the work of <a href="http://export.arxiv.org/abs/1909.06988">arXiv:1909.06988</a> .
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07208</id>
    <link href="http://arxiv.org/abs/2002.07208" rel="alternate" type="text/html"/>
    <title>Optimal Error Pseudodistributions for Read-Once Branching Programs</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chattopadhyay:Eshan.html">Eshan Chattopadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liao:Jyun=Jie.html">Jyun-Jie Liao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07208">PDF</a><br/><b>Abstract: </b>In 1992, Nisan (Combinatorica'92) constructed a pseudorandom generator for
length $n$, width $w$ read-once branching program with error $\varepsilon$ and
seed length $O(\log n\cdot \log(nw)+\log n\cdot\log(1/\varepsilon))$. A central
question in complexity theory is to reduce the seed length to $O(\log
(nw/\varepsilon))$, which will imply $\mathbf{BPL}=\mathbf{L}$. However, there
has been no improvement on Nisan's construction for the case $n=w$, which is
most relevant to space-bounded derandomization.
</p>
<p>Recently, in a beautiful work, Braverman, Cohen and Garg (STOC'18) introduced
the notion of a pseudorandom pseudo-distribution (PRPD) and gave an explicit
construction of a PRPD with seed length $\tilde{O}(\log n\cdot
\log(nw)+\log(1/\varepsilon))$. A PRPD is a relaxation of a pseudorandom
generator, which suffices for derandomizing $\mathbf{BPL}$ and also implies a
hitting set. Unfortunately, their construction is quite involved and
complicated. Hoza and Williams (FOCS'18) later constructed a much simpler
hitting set generator with seed length $O(\log n\cdot
\log(nw)+\log(1/\varepsilon))$, but their techniques are restricted to hitting
sets.
</p>
<p>In this work, we construct a PRPD with seed length $$O(\log n\cdot \log
(nw)\cdot \log\log(nw)+\log(1/\varepsilon)).$$ This improves upon the
construction in [BCG18] by a $O(\log\log(1/\varepsilon))$ factor, and is
optimal in the small error regime. In addition, we believe our construction and
analysis to be simpler than the work of Braverman, Cohen and Garg.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.07207</id>
    <link href="http://arxiv.org/abs/2002.07207" rel="alternate" type="text/html"/>
    <title>Semi-dynamic Algorithms for Strongly Chordal Graphs</title>
    <feedworld_mtime>1582070400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahman:Md=_Zamilur.html">Md. Zamilur Rahman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Asish.html">Asish Mukhopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.07207">PDF</a><br/><b>Abstract: </b>There is an extensive literature on dynamic algorithms for a large number of
graph theoretic problems, particularly for all varieties of shortest path
problems. Germane to this paper are a number fully dynamic algorithms that are
known for chordal graphs. However, to the best of our knowledge no study has
been done for the problem of dynamic algorithms for strongly chordal graphs. To
address this gap, in this paper, we propose a semi-dynamic algorithm for
edge-deletions and a semi-dynamic algorithm for edge-insertions in a strongly
chordal graph, $G = (V, E)$, on $n$ vertices and $m$ edges. The query
complexity of an edge-deletion is $O(d_u^2d_v^2 (n + m))$, where $d_u$ and
$d_v$ are the degrees of the vertices $u$ and $v$ of the candidate edge $\{u,
v\}$, while the query-complexity of an edge-insertion is $O(n^2)$.
</p></div>
    </summary>
    <updated>2020-02-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-19T01:30:00Z</updated>
    </source>
  </entry>
</feed>
