<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-03-11T15:22:01Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/11/postdoc-at-technion-israel-institute-of-technology-apply-by-april-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion Israel Institute of Technology (apply by April 30, 2019)</title>
    <summary>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory. Website: https://nailon.net.technion.ac.il/openings/ Email: nailon@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>For an exciting project funded by the European Commission for Research (ERC), I currently have several openings for post-docs working in the intersection of theoretical computer science and learning theory.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/openings/">https://nailon.net.technion.ac.il/openings/</a><br/>
Email: nailon@cs.technion.ac.il</p></div>
    </content>
    <updated>2019-03-11T15:10:35Z</updated>
    <published>2019-03-11T15:10:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-11T15:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5378</id>
    <link href="https://adamsheffer.wordpress.com/2019/03/11/incidences-open-problem-part-1/" rel="alternate" type="text/html"/>
    <title>Incidences: Open Problem (part 1)</title>
    <summary>The past decade brought us several breakthroughs in the study of geometric incidences. Most importantly, Guth and Katz introduced polynomial partitioning, and this has become the main technique for studying incidences. The recent breakthroughs sometimes leads to a wrong impression about the state of this field. Actually, most of the main incidence problems are still […]</summary>
    <updated>2019-03-11T01:06:19Z</updated>
    <published>2019-03-11T01:06:19Z</published>
    <category term="Incidences"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-03-11T15:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03605</id>
    <link href="http://arxiv.org/abs/1903.03605" rel="alternate" type="text/html"/>
    <title>Understanding Sparse JL for Feature Hashing</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jagadeesan:Meena.html">Meena Jagadeesan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03605">PDF</a><br/><b>Abstract: </b>Feature hashing and more general projection schemes are commonly used in
machine learning to reduce the dimensionality of feature vectors. The goal is
to efficiently project a high-dimensional feature vector living in
$\mathbb{R}^n$ into a lower-dimensional space $\mathbb{R}^m$, while
approximately preserving Euclidean norm. These schemes can be constructed using
sparse random projections, for example using a sparse Johnson-Lindenstrauss
(JL) transform. In practice, feature vectors often have a low
$\ell_\infty$-to-$\ell_2$ norm ratio, and for this restricted set of vectors,
many sparse JL-based schemes can achieve the norm-preserving objective with
smaller dimension $m$ than is necessary for the scheme on the full space
$\mathbb{R}^n$. A line of work introduced by Weinberger et. al (ICML '09)
analyzes the sparse JL transform with one nonzero entry per column, which is a
standard feature hashing scheme. Recently, Freksen, Kamma, and Larsen (NIPS
'18) closed this line of work by proving an essentially tight tradeoff between
$\ell_\infty$-to-$\ell_2$ norm ratio, distortion, failure probability, and
dimension $m$ for this feature hashing scheme.
</p>
<p>We study more general projection schemes that are constructed using sparse JL
transforms permitted to have more than one (but still a small fraction of)
nonzero entries per column. Our main result is an essentially tight tradeoff
between $\ell_\infty$-to-$\ell_2$ norm ratio, distortion, failure probability,
and dimension $m$ for a general sparsity $s$, that generalizes the result of
Freksen et. al. We also connect our result to the sparse JL literature by
showing that it implies lower bounds on dimension-sparsity tradeoffs that
essentially match upper bounds by Cohen (SODA '16). Moreover, our proof
introduces a new perspective on bounding moments of certain random variables,
that could be useful in other settings in theoretical computer science.
</p></div>
    </summary>
    <updated>2019-03-11T01:46:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03560</id>
    <link href="http://arxiv.org/abs/1903.03560" rel="alternate" type="text/html"/>
    <title>Belga B-trees</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerman:Stefan.html">Stefan Langerman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03560">PDF</a><br/><b>Abstract: </b>We revisit self-adjusting external memory tree data structures, which combine
the optimal (and practical) worst-case I/O performances of B-trees, while
adapting to the online distribution of queries. Our approach is analogous to
undergoing efforts in the BST model, where Tango Trees (Demaine et al. 2007)
were shown to be $O(\log\log N)$-competitive with the runtime of the best
offline binary search tree on every sequence of searches. Here we formalize the
B-Tree model as a natural generalization of the BST model. We prove lower
bounds for the B-Tree model, and introduce a B-Tree model data structure, the
Belga B-tree, that executes any sequence of searches within a $O(\log \log N)$
factor of the best offline B-tree model algorithm, provided $B=\log^{O(1)}N$.
We also show how to transform any static BST into a static B-tree which is
faster by a $\Theta(\log B)$ factor; the transformation is randomized and we
show that randomization is necessary to obtain any significant speedup.
</p></div>
    </summary>
    <updated>2019-03-11T01:30:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03520</id>
    <link href="http://arxiv.org/abs/1903.03520" rel="alternate" type="text/html"/>
    <title>The One-Way Communication Complexity of Dynamic Time Warping Distance</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Lin_F=.html">Lin F. Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03520">PDF</a><br/><b>Abstract: </b>We resolve the randomized one-way communication complexity of Dynamic Time
Warping (DTW) distance. We show that there is an efficient one-way
communication protocol using $\widetilde{O}(n/\alpha)$ bits for the problem of
computing an $\alpha$-approximation for DTW between strings $x$ and $y$ of
length $n$, and we prove a lower bound of $\Omega(n / \alpha)$ bits for the
same problem. Our communication protocol works for strings over an arbitrary
metric of polynomial size and aspect ratio, and we optimize the logarithmic
factors depending on properties of the underlying metric, such as when the
points are low-dimensional integer vectors equipped with various metrics or
have bounded doubling dimension. We also consider linear sketches of DTW,
showing that such sketches must have size $\Omega(n)$.
</p></div>
    </summary>
    <updated>2019-03-11T01:20:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03487</id>
    <link href="http://arxiv.org/abs/1903.03487" rel="alternate" type="text/html"/>
    <title>Set CRDT com M\'ultiplas Pol\'iticas de Resolu\c{c}\~ao de Conflitos</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>André Rijo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferreira:Carla.html">Carla Ferreira</a>, Nuno Preguiça <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03487">PDF</a><br/><b>Abstract: </b>Um CRDT \'e um tipo de dados que pode ser replicado e modificado
concorrentemente sem coordena\c{c}\~ao, garantindo-se a converg\^encia das
r\'eplicas atrav\'es da resolu\c{c}\~ao autom\'atica de conflitos. Cada CRDT
implementa uma pol\'itica espec\'ifica para resolver conflitos. Por exemplo, um
conjunto CRDT add-wins d\'a prioridade ao "add" aquando da execu\c{c}\~ao
concorrente de um "add" e "rem" do mesmo elemento. Em algumas aplica\c{c}\~oes
pode ser necess\'ario usar diferentes pol\'iticas para diferentes
execu\c{c}\~oes de uma opera\c{c}\~ao -- por exemplo, uma aplica\c{c}\~ao que
utilize um conjunto CRDT add-wins pode querer que alguns "removes" ganhem sobre
"adds" concorrentes. Neste artigo \'e apresentado e avaliado o desenho dum
conjunto CRDT que implementa as sem\^anticas referidas.
</p>
<p>---
</p>
<p>Conflict-Free Replicated Data Types (CRDTs) allow objects to be replicated
and concurrently modified without coordination. CRDTs solve conflicts
automatically and provide eventual consistency. Typically each CRDT uses a
specific policy for solving conflicts. For example, in an add-wins set CRDT,
when an element is concurrently add and removed in different replicas, priority
is given to add, i.e., the element stays in the set. Unfortunately, this may be
inadequate for some applications - it may be desired to overrule the default
policy for some operation executions. For example, an application using an
add-wins set may want some removes to win over concurrent adds. This paper
present the design of a set CRDT that implements such semantics.
</p></div>
    </summary>
    <updated>2019-03-11T01:30:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03479</id>
    <link href="http://arxiv.org/abs/1903.03479" rel="alternate" type="text/html"/>
    <title>NEARBY Platform for Automatic Asteroids Detection and EURONEAR Surveys</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorgan:Dorian.html">Dorian Gorgan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaduvescu:Ovidiu.html">Ovidiu Vaduvescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefanut:Teodor.html">Teodor Stefanut</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bacu:Victor.html">Victor Bacu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sabou:Adrian.html">Adrian Sabou</a>, Denisa Copandean Balazs, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandra:Constantin.html">Constantin Nandra</a>, Costin Boldea, Afrodita Boldea, Marian Predatu, Viktoria Pinter, Adrian Stanica <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03479">PDF</a><br/><b>Abstract: </b>The survey of the nearby space and continuous monitoring of the Near Earth
Objects (NEOs) and especially Near Earth Asteroids (NEAs) are essential for the
future of our planet and should represent a priority for our solar system
research and nearby space exploration. More computing power and sophisticated
digital tracking algorithms are needed to cope with the larger astronomy
imaging cameras dedicated for survey telescopes. The paper presents the NEARBY
platform that aims to experiment new algorithms for automatic image reduction,
detection and validation of moving objects in astronomical surveys,
specifically NEAs. The NEARBY platform has been developed and experimented
through a collaborative research work between the Technical University of
Cluj-Napoca (UTCN) and the University of Craiova, Romania, using observing
infrastructure of the Instituto de Astrofisica de Canarias (IAC) and Isaac
Newton Group (ING), La Palma, Spain. The NEARBY platform has been developed and
deployed on the UTCN's cloud infrastructure and the acquired images are
processed remotely by the astronomers who transfer it from ING through the web
interface of the NEARBY platform. The paper analyzes and highlights the main
aspects of the NEARBY platform development, and the results and conclusions on
the EURONEAR surveys.
</p></div>
    </summary>
    <updated>2019-03-11T01:45:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03404</id>
    <link href="http://arxiv.org/abs/1903.03404" rel="alternate" type="text/html"/>
    <title>Accelerating Generalized Linear Models with MLWeaving: A One-Size-Fits-All System for Any-precision Learning</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Zeke.html">Zeke Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Kaan.html">Kaan Kara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hantian.html">Hantian Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alonso:Gustavo.html">Gustavo Alonso</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mutlu:Onur.html">Onur Mutlu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ce.html">Ce Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03404">PDF</a><br/><b>Abstract: </b>Learning from the data stored in a database is an important function
increasingly available in relational engines. Methods using lower precision
input data are of special interest given their overall higher efficiency but,
in databases, these methods have a hidden cost: the quantization of the real
value into a smaller number is an expensive step. To address the issue, in this
paper we present MLWeaving, a data structure and hardware acceleration
technique intended to speed up learning of generalized linear models in
databases. ML-Weaving provides a compact, in-memory representation enabling the
retrieval of data at any level of precision. MLWeaving also takes advantage of
the increasing availability of FPGA-based accelerators to provide a highly
efficient implementation of stochastic gradient descent. The solution adopted
in MLWeaving is more efficient than existing designs in terms of space (since
it can process any resolution on the same design) and resources (via the use of
bit-serial multipliers). MLWeaving also enables the runtime tuning of
precision, instead of a fixed precision level during the training. We
illustrate this using a simple, dynamic precision schedule. Experimental
results show MLWeaving achieves up to16 performance improvement over
low-precision CPU implementations of first-order methods.
</p></div>
    </summary>
    <updated>2019-03-11T01:24:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03211</id>
    <link href="http://arxiv.org/abs/1903.03211" rel="alternate" type="text/html"/>
    <title>The VC Dimension of Metric Balls under Fr\'echet and Hausdorff Distances</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Driemel:Anne.html">Anne Driemel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psarros:Ioannis.html">Ioannis Psarros</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03211">PDF</a><br/><b>Abstract: </b>The Vapnik-Chervonenkis dimension provides a notion of complexity for systems
of sets. If the VC dimension is small, then knowing this can drastically
simplify fundamental computational tasks such as classification, range
counting, and density estimation through the use of sampling bounds. We analyze
set systems where the ground set $X$ is a set of polygonal curves in
$\mathbb{R}^d$ and the sets $\mathcal{R}$ are metric balls defined by curve
similarity metrics, such as the Fr\'echet distance and the Hausdorff distance,
as well as their discrete counterparts. We derive upper and lower bounds on the
VC dimension that imply useful sampling bounds in the setting that the number
of curves is large, but the complexity of the individual curves is small. Our
upper bounds are either near-quadratic or near-linear in the complexity of the
curves that define the ranges and they are logarithmic in the complexity of the
curves that define the ground set.
</p></div>
    </summary>
    <updated>2019-03-11T01:47:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03147</id>
    <link href="http://arxiv.org/abs/1903.03147" rel="alternate" type="text/html"/>
    <title>External memory priority queues with decrease-key and applications to graph algorithms</title>
    <feedworld_mtime>1552262400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Riko.html">Riko Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsakalidis:Konstantinos.html">Konstantinos Tsakalidis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03147">PDF</a><br/><b>Abstract: </b>We present priority queues in the external memory model with block size $B$
and main memory size $M$ that support on $N$ elements, operation Update (a
combination of operations Insert and Decrease-Key) in
$O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ amortized I/Os,
operation Extract-Min in $O\left({\frac{M^{\varepsilon}}{B}\log_{\frac{M}{B}}
\frac{N}{B}}\right)$ amortized I/Os and operation Delete in
$O\left({\frac{M^{\varepsilon}}{B}\log^2_{\frac{M}{B}} \frac{N}{B}}\right)$
amortized I/Os, for any real $\varepsilon \in \left(0,1\right)$, using
$O\left({\frac{N}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ blocks. Previous
I/O-efficient priority queues either support these operations in
$O\left({\frac{1}{B}\log_2 \frac{N}{B}}\right)$ amortized I/Os [Kumar and
Schwabe, SPDP '96], or support only operations Insert, Delete and Extract-Min
in optimal $O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$
amortized I/Os, however without supporting Decrease-Key [Fadel et al., TCS
'99].
</p>
<p>We also present buffered repository trees that support on a multi-set of $N$
elements, operations Insert and Extract (on $K$ extracted elements) in
$O\left({\frac{1}{B}\log_{\frac{M}{B}} \frac{N}{B}}\right)$ and
$O\left({\log_{\frac{M}{B}} \frac{N}{B} + K/B}\right)$ amortized I/Os,
respectively, using $O\left({\frac{N}{B}}\right)$ blocks. This improves upon
the previous I/O-bounds that achieve a base-$2$ logarithm instead [Buchsbaum et
al., SODA '00].
</p>
<p>Our results imply improved $O\left({\frac{E}{B}\log_{\frac{M}{B}}
\frac{E}{B}}\right)$ I/Os for single-source shortest paths, depth-first search
and breadth-first search algorithms on massive directed graphs with an
edge-to-node ratio $\frac{E}{V}=\Omega({M^{\varepsilon}})$, which is equal to
the I/O-optimal bound for sorting $E$ values in external memory.
</p></div>
    </summary>
    <updated>2019-03-11T01:46:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5113460714750651988</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5113460714750651988/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5113460714750651988" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/richard-karp-his-influence-and-how-to.html" rel="alternate" type="text/html"/>
    <title>Richard Karp: His influence and how to honor him</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first saw the definition of NP-Complete I first thought<i> if there are NP-complete problems I suspect they are contrived. </i>When I saw the proof that  SAT is NP-complete I thought <i>okay, so there is one natural problem  NP-complete by a trick of encoding, but I suspect there aren't any more.</i>  I then read Karp's article that had 22 NP-complete problems. I thought <i>okay, there are 22, but I suspect there are no more. </i>No I didn't think that. But the point is that Cook and Karp together birthed modern complexity theory by introduction NP-completeness and showing that there are MANY natural problems that are NP-complete.<br/>
<br/>
How many people has Richard Karp inspired? I don't know but I suspect it's a  cardinal between countable and the reals so it may depend on your model of set theory. Later in this post I will present Samir Khuller's story of how Richard Karp inspired him.<br/>
<br/>
How to honor him?  The Simons inst. is currently welcoming contributions to the Richard M Karp Fund, which honors the scientific contributions of Founding Director Dick Karp. The fund will provide vital support for the mission and activities of the Simons institute. They have a deadline of Pi-Day. You can go <a href="https://simons.berkeley.edu/support/donate">here</a> to contribute and/or <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/goldwasserkarp.txt">here</a> for a letter from Shafi Goldwasser, Prabhakar Raghavan, and Umesh Vazirani about the fund.<br/>
<br/>
OKAY, Samir's story:<br/>
<br/>
<div>
<b>Mentoring and Influence via a Train Journey...</b></div>
<div>
<br/></div>
<div>
Almost to the day, 33 years ago I was running from my dorm room to catch an unreliable bus to the train station as I headed home for a mid-semester break.  On the way,I  stopped by the mailroom, and not knowing where to put the CACM that had just arrived,  stuffed it into the side of my bag and in the process, dropping my   notebook in the process. On the train, when I looked for my  notebook to go over  some material I realized it was missing! All I had was a CACM and a very long train ride. Skimming through the journal, I found Karp’s Turing Award article “Combinatorics, Complexity, and Randomness“. I  started reading this article, and was riveted! It was one of those life changing moments for me, when my immediate future became clear - I wanted to study Theoretical Computer Science and specifically the complexity of combinatorial problems. Without ever having met Dick Karp, he changed my life forever.</div>
<div>
<br/></div>
<div>
I met Dick long after he influenced me via his Turing Award Lecture and it was a real privilege to have had the opportunity to interview him via a fireside chat at Simons. See <a href="https://www.youtube.com/watch?v=g1DT_UeJwps">here</a>.</div>
<div>
<br/></div>
<div>
I am delighted about the fund Bill mentions above as the money that goes to it will help inspire others as Karp inspired me.</div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div>
<br/>
<br/></div>
    </content>
    <updated>2019-03-10T21:26:00Z</updated>
    <published>2019-03-10T21:26:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-11T10:16:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/10/postdoc-at-ist-austria-vienna-apply-by-april-15-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at IST Austria (Vienna) (apply by April 15, 2019)</title>
    <summary>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019. Website: http://people.csail.mit.edu/alistarh/ Email: d.alistarh@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Distributed Algorithms Group at IST Austria (near Vienna) is looking for strong postdoc candidates in CS Theory, with a focus on (distributed) optimization. The starting date is (roughly) in Fall 2019.</p>
<p>Website: <a href="http://people.csail.mit.edu/alistarh/">http://people.csail.mit.edu/alistarh/</a><br/>
Email: d.alistarh@gmail.com</p></div>
    </content>
    <updated>2019-03-10T20:48:31Z</updated>
    <published>2019-03-10T20:48:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-11T15:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15674</id>
    <link href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/" rel="alternate" type="text/html"/>
    <title>Problems With a Point</title>
    <summary>Bill and Clyde’s new book Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their book Problems With a Point. Today Dick and I congratulate them on the book and give a brief overview of it. The tandem of Bill and Clyde […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Bill and Clyde’s new book</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2019/03/10/problems-with-a-point/gasarchkruskal/" rel="attachment wp-att-15675"><img alt="" class="alignright wp-image-15675" height="114" src="https://rjlipton.files.wordpress.com/2019/03/gasarchkruskal.png?w=200&amp;h=114" width="200"/></a></p>
<p/><p>
Bill Gasarch and Clyde Kruskal are colleagues in Computer Science at the University of Maryland. They have just seen the publication of their <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261">book</a> <em>Problems With a Point</em>.</p>
<p>
Today Dick and I congratulate them on the book and give a brief overview of it.</p>
<p>
The tandem of Bill and Clyde were <a href="https://rjlipton.wordpress.com/2011/12/06/theorems-are-forever-a-great-one-from-1492/">featured</a> before on this blog in connection with a <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.138.6154">series</a> of <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/3apsurvey.pdf">papers</a> with James Glenn on sets of numbers that have no arithmetical progressions of length 3. </p>
<p>
Can a “series” have only two members? We could add a third <a href="https://link.springer.com/chapter/10.1007/11821069_13">paper</a> to the series, but it is by Glenn and Bill with Richard Beigel rather than Clyde and is on the different topic of multi-party communication complexity. But Clyde gets into the act since it is the topic of Chapter 19 of the book. That chapter analyzes a game form of problems that go back to a 1983 <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/multiparty-vdw.pdf">paper</a> by Dick with Ashok Chandra and Merrick Furst. Does this mean Dick should get some royalties? Note that this last link is to Bill’s website. And ‘vdw’ in this link seems to refer to van der Waerden’s <a href="https://en.wikipedia.org/wiki/Van_der_Waerden's_theorem">theorem</a>, which is a pillar of both Ramsey theory and number theory, which in turn receive much attention in the book.</p>
<p>
My last paragraph flits through divergent questions but they are representative of things that we working mathematical computing theorists think about every day—and of various kinds of content in the book. Of course, Bill partners on Lance Fortnow’s prominent <a href="https://blog.computationalcomplexity.org/">blog</a> and so has shared all kinds of these musings. The book, which incorporates numerous posts by Bill but is not a “blog book” <em>per-se</em>, furnishes contexts for them. Let’s look at the book.</p>
<p>
</p><p/><h2> The Book </h2><p/>
<p/><p>
The book has three main parts, titled:</p>
<ul>
<li>
Stories With a Point. <p/>
</li><li>
Problems With a Point. <p/>
</li><li>
Theorems With a Point.
</li></ul>
<p>
All the chapters except three are prefaced with a section titled “Point”—or “The Point” or “Points”—after one sentence on prior knowledge needed, which often reads, “None.”</p>
<p>
The first part begins with a chapter titled, “When Terms From Math are Used By Civilians,” one of several with social discussion. The second is about how human aspects of sports upset statistical regularities one might expect to see. For example, many more baseball hitters have had season batting averages of .300 than .299 or .301, evidently because .300 is a “goal number” everyone strives to meet. There are numerous things in the book I didn’t know. </p>
<p>
The next chapter largely reproduces this record-long <a href="https://blog.computationalcomplexity.org/2011/07/disproofing-myth-that-many-early.html">post</a> on the blog but adds much extra commentary. Then there are chapters on what makes a mathematical function worth defining, on how mathematical objects are named, on Bill’s visit to a “Gathering for [Martin] Gardner” <a href="http://www.gathering4gardner.org/">conference</a>, on coloring the plane, two on imagined applications of Ramsey Theory to medieval history, and one on the methodological and social impact of having theorems that represent barriers to ways of trying to prove other theorems. </p>
<p>
</p><p/><h2> Chapter Ten </h2><p/>
<p/><p>
This last chapter of Part I <a href="https://blog.computationalcomplexity.org/2010/04/lets-prove-something-instead-of-proving.html">draws</a> on <a href="https://blog.computationalcomplexity.org/2010/04/but-seriously-now-folks-what-do-you.html">several</a> of Bill’s <a href="https://blog.computationalcomplexity.org/2017/03/other-fields-of-math-dont-prove-barrier.html">posts</a>. It goes most to the heart of what we all in computational complexity grapple with daily and benefits from having more context: As we just mused in this blog’s 10-year anniversary <a href="https://rjlipton.wordpress.com/2019/02/18/have-ten-years-brought-us-closer/">post</a>, the major questions in complexity are not only as open as when we started, but as open as when the field started 50-plus years ago. There has barely been any discernible direct progress, and this is not only a concern for entering students but a retardant on everyone—about which we’ve given <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">exhortation</a>.</p>
<p>
There are instead <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">barrier</a> theorems saying <em>why</em> the main questions will not be resolvable by the very techniques that were used to build the field. Of three broad categories of barriers, “oracle results” de-fang all the methods typically taught in intro graduate complexity courses. Those methods meter computations at inputs and outputs but not how they “progress” inside toward a solution. Oracle languages supply blasts of external information that either make progress trivially quick or allow conditioning the terms of the complexity-class relation under analysis to information in the oracle that is tailored to obfuscate. Oracles of the former kind usually collapse complexity classes together, such as <img alt="{A =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A =}"/> any polynomial-space complete language making <img alt="{\mathsf{P}^A = \mathsf{NP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EA+%3D+%5Cmathsf%7BNP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^A = \mathsf{NP}^A}"/>, whereas oracles <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of the latter kind drive them apart (so <img alt="{\mathsf{P}^B \neq \mathsf{NP}^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EB+%5Cneq+%5Cmathsf%7BNP%7D%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^B \neq \mathsf{NP}^B}"/>) but often for reasons that frustrate as much as enlighten. When contemplating a new complexity class relation it is incumbent to frame a “relativized” version of it and see if some oracles can make it true and others false. Such oracle constructions were initially easy to come by—“fast food” for research—but their ultimate besideness-of-the-point is reflected in this early <a href="https://rjlipton.wordpress.com/2009/05/21/i-hate-oracle-results/">post</a> by Dick.</p>
<p>
Next after oracles is the “Natural Proofs” <a href="https://en.wikipedia.org/wiki/Natural_proof">barrier</a>, which basically cuts against all the techniques taught in advanced graduate complexity courses unless they can somehow be weirdly narrow or intensely complex in their conceptual framing. The attitude on those is captured by the title of another early <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">post</a> by Dick titled, “Who’s Afraid of Natural Proofs?” The third barrier is <a href="https://www.scottaaronson.com/papers/algstoc.pdf">algebrization</a>, which cuts <a href="https://en.wikipedia.org/wiki/P_versus_NP_problem#Results_about_difficulty_of_proof">against</a> efforts to escape from oracles. </p>
<p>
Amid all this environment of obstruction, what of consequence can we prove? Well, the chapter on this has by far the highest concentration of Bill’s trademark all-capital letters and exclamation points. The initial “Point” section is titled, “Rant.” (The chapter also includes a page on the attempts to prove Euclid’s parallel postulate, which might be called the original “problem with a point.”)</p>
<p>
</p><p/><h2> Part II </h2><p/>
<p/><p>
Much of Part II involves the kind of problems that were used or considered for high-school mathematics competitions. By definition those are not research problems but they often point toward frontiers by representing accessible cases of them. The appealing ones blend equal parts research relevance, amusement value, and reward of technical command. Often they require mathematical “street smarts” and a repertoire of useful tricks and proof patterns. Practicing researchers will find this aspect of the book most valuable. The problems are mainly on the number-theory side of recreational mathematics, plus geometric and coloring problems. Egyptian fractions, prime-factor puzzles, sums over digits, summation formulas, and of course Ramsey theory all make their appearance. Here is one problem I mention partly to correct a small content error, where the correction seems to make the problem more interesting. Say that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds if there are integers <img alt="{n_1,\dots,n_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn_1%2C%5Cdots%2Cn_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n_1,\dots,n_m}"/> such that </p>
<p align="center"><img alt="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n_1+%2B+%5Ccdots+%2B+n_m+%3D+n+%5Cqquad%5Ctext%7Band%7D%5Cqquad+%5Cfrac%7B1%7D%7Bn_1%7D+%2B+%5Ccdots+%2B+%5Cfrac%7B1%7D%7Bn_m%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n_1 + \cdots + n_m = n \qquad\text{and}\qquad \frac{1}{n_1} + \cdots + \frac{1}{n_m} = 1. "/></p>
<p>A general principle discovered by Joseph Sylvester gives cases such as <img alt="{C(1861,5)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%281861%2C5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(1861,5)}"/> being witnessed by </p>
<p align="center"><img alt="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1861+%3D+2+%2B+3+%2B+7+%2B+43+%2B+1806+%5Cqquad%5Ctext%7Band%7D%5Cqquad+1+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B3%7D+%2B+%5Cfrac%7B1%7D%7B7%7D+%2B+%5Cfrac%7B1%7D%7B43%7D+%2B+%5Cfrac%7B1%7D%7B1806%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1861 = 2 + 3 + 7 + 43 + 1806 \qquad\text{and}\qquad 1 = \frac{1}{2} + \frac{1}{3} + \frac{1}{7} + \frac{1}{43} + \frac{1}{1806}. "/></p>
<p>How can it and related ideas be extended to other cases? The particular problem is given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to find <img alt="{m_n =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n =}"/> the least <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> such that <img alt="{C(n,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28n%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(n,m)}"/> holds—and to find a witnessing sum. The error is an assertion that <img alt="{m_n \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n \leq n}"/> “by writing <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> as a sum of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>‘s,” but then the reciprocals add up to <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> not <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. So is there any bound on <img alt="{m_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_n}"/>? That is rather fun to think about. </p>
<p>
This problem’s chapter is made from a short <a href="https://blog.computationalcomplexity.org/2011/12/is-this-problem-too-hard-for-hs-math.html">post</a> with an enormous comments section.  There is also a chapter on the boundary between a fair problem and a “trick question” that much extends an April Fool’s post on the blog.</p>
<p>
</p><p/><h2> Part III </h2><p/>
<p/><p>
Part III continues the nature of the problem content with emphasis on the worths of proofs of theorems. One illustration involving perfect numbers and sums of cubes notes that the proof loses value because it also applies to certain non-perfect numbers. Two things <em>en-passant</em>: First, Lemma 21.1 in this chapter needs qualification that <img alt="{a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b}"/> are relatively prime and <img alt="{x+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x+1}"/> is prime. Second, this prompts me to note <a href="https://gilkalai.wordpress.com/2019/03/09/">via</a> Gil Kalai the discovery by Tim Browning that the number 33 is a sum of three cubes: </p>
<p><br/></p>
<p align="center"><img alt="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++33+%3D+8%2C%5C%21866%2C%5C%21128%2C%5C%21975%2C%5C%21287%2C%5C%21528%5E3+%2B+%28-8%2C%5C%21778%2C%5C%21405%2C%5C%21442%2C%5C%21862%2C%5C%21239%29%5E3+%2B+%28-2%2C%5C%21736%2C%5C%21111%2C%5C%21468%2C%5C%21807%2C%5C%21040%29%5E3.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  33 = 8,\!866,\!128,\!975,\!287,\!528^3 + (-8,\!778,\!405,\!442,\!862,\!239)^3 + (-2,\!736,\!111,\!468,\!807,\!040)^3. "/></p>
<p/><p><br/>
Gil points to a Quora <a href="https://affinemess.quora.com/HOLY-CRAP-33-IS-THE-SUM-OF-THREE-CUBES">post</a> by Alon Amit. There is only the bare equation on Browning’s <a href="http://pub.ist.ac.at/~tbrownin/">homepage</a>, and nothing about his methods or how much he used computer search is known. The theme of proofs by computer runs through several chapters of Bill and Clyde’s book. It is also <a href="https://www.scottaaronson.com/blog/?p=4133">current</a> on Scott Aaronson’s blog—we would be remiss if we did not mention Scott in this post—and more widely.</p>
<p>
The penultimate chapter covers the beautiful theory of rectangle-free colorings of grids. We mentioned Bill’s involvement with this Ramsey-style problem in a <a href="https://rjlipton.wordpress.com/2012/02/12/how-deep-is-your-coloring/">post</a> on what happened to be this blog’s third anniversary. We connected it to Kolmogorov complexity, which together with uncomputability is the subject of the last chapter. This and other chapters I’ve mentioned exemplify how the research ambit connects traditional mathematics with the terms and concerns of computing theory. How to work in this ambit may be the greatest value of the book for students. In all I found the book light, lighthearted, and enlightening.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The big open problem with the book is how it might help gear us up to tackle the big open problems.</p>
<p>
[sourced chapter near end of Part II to blog]</p></font></font></div>
    </content>
    <updated>2019-03-10T19:43:13Z</updated>
    <published>2019-03-10T19:43:13Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Bill Gasarch"/>
    <category term="book"/>
    <category term="Clyde Kruskal"/>
    <category term="Problems"/>
    <category term="review"/>
    <category term="teaching"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-03-11T15:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/038</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/038" rel="alternate" type="text/html"/>
    <title>TR19-038 |  Statistical Difference Beyond the Polarizing Regime | 

	Itay Berman, 

	Akshay Degwekar, 

	Ron D. Rothblum, 

	Prashant Nalini Vasudevan</title>
    <summary>The polarization lemma for statistical distance ($\mathrm{SD}$), due to Sahai and Vadhan (JACM, 2003), is an efficient transformation taking as input a pair of circuits $(C_0,C_1)$ and an integer $k$ and outputting a new pair of circuits $(D_0,D_1)$ such that if $\mathrm{SD}(C_0,C_1)\geq\alpha$ then $\mathrm{SD}(D_0,D_1) \geq 1-2^{-k}$ and if $\mathrm{SD}(C_0,C_1) \leq \beta$ then $\mathrm{SD}(D_0,D_1) \leq 2^{-k}$. The polarization lemma is known to hold for any constant values $\beta &lt; \alpha^2$, but extending the lemma to the regime in which $\alpha^2 \leq \beta &lt; \alpha$ has remained elusive. The focus of this work is in studying the latter regime of parameters. Our main results are:

1. Polarization lemmas for different notions of distance, such as Triangular Discrimination ($\mathrm{TD}$) and Jensen-Shannon Divergence ($\mathrm{JS}$), which enable polarization for some problems where the statistical distance satisfies $\alpha^2 &lt; \beta &lt; \alpha$. We also derive a polarization lemma for statistical distance with any inverse-polynomially small gap between $\alpha^2$ and $\beta$ (rather than a constant).

2. The average-case hardness of the statistical difference problem (i.e., determining whether the statistical distance between two given circuits is at least $\alpha$ or at most $\beta$), for any values of $\beta &lt; \alpha$, implies the existence of one-way functions. Such a result was previously only known for $\beta &lt; \alpha^2$.

3. A (direct) constant-round interactive proof for estimating the statistical distance between any two distributions (up to any inverse polynomial error) given circuits that generate them.</summary>
    <updated>2019-03-10T08:50:14Z</updated>
    <published>2019-03-10T08:50:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03101</id>
    <link href="http://arxiv.org/abs/1903.03101" rel="alternate" type="text/html"/>
    <title>Computing Exact Solutions of Consensus Halving and the Borsuk-Ulam Theorem</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deligkas:Argyrios.html">Argyrios Deligkas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fearnley:John.html">John Fearnley</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melissourgos:Themistoklis.html">Themistoklis Melissourgos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirakis:Paul_G=.html">Paul G. Spirakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03101">PDF</a><br/><b>Abstract: </b>We study the problem of finding an exact solution to the consensus halving
problem. While recent work has shown that the approximate version of this
problem is PPA-complete, we show that the exact version is much harder.
Specifically, finding a solution with $n$ cuts is FIXP-hard, and deciding
whether there exists a solution with fewer than $n$ cuts is ETR-complete. We
also give a QPTAS for the case where each agent's valuation is a polynomial.
</p>
<p>Along the way, we define a new complexity class BU, which captures all
problems that can be reduced to solving an instance of the Borsuk-Ulam problem
exactly. We show that FIXP $\subseteq$ BU $\subseteq$ TFETR and that LinearBU
$=$ PPA, where LinearBU is the subclass of BU in which the Borsuk-Ulam instance
is specified by a linear arithmetic circuit.
</p></div>
    </summary>
    <updated>2019-03-10T23:21:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03070</id>
    <link href="http://arxiv.org/abs/1903.03070" rel="alternate" type="text/html"/>
    <title>An algorithmic approach to the existence of ideal objects in commutative algebra</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Powell:Thomas.html">Thomas Powell</a>, Peter M Schuster, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiesnet:Franziskus.html">Franziskus Wiesnet</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03070">PDF</a><br/><b>Abstract: </b>The existence of ideal objects, such as maximal ideals in nonzero rings,
plays a crucial role in commutative algebra. These are typically justified
using Zorn's lemma, and thus pose a challenge from a computational point of
view. Giving a constructive meaning to ideal objects is a problem which dates
back to Hilbert's program, and today is still a central theme in the area of
dynamical algebra, which focuses on the elimination of ideal objects via
syntactic methods. In this paper, we take an alternative approach based on
Kreisel's no counterexample interpretation and sequential algorithms. We first
give a computational interpretation to an abstract maximality principle in the
countable setting via an intuitive, state based algorithm. We then carry out a
concrete case study, in which we give an algorithmic account of the result that
in any commutative ring, the intersection of all prime ideals is contained in
its nilradical.
</p></div>
    </summary>
    <updated>2019-03-10T23:37:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03014</id>
    <link href="http://arxiv.org/abs/1903.03014" rel="alternate" type="text/html"/>
    <title>An Experimental Study of Forbidden Patterns in Geometric Permutations by Combinatorial Lifting</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goaoc:Xavier.html">Xavier Goaoc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Holmsen:Andreas.html">Andreas Holmsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nicaud:Cyril.html">Cyril Nicaud</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03014">PDF</a><br/><b>Abstract: </b>We study the problem of deciding if a given triple of permutations can be
realized as geometric permutations of disjoint convex sets in $\mathbb{R}^3$.
We show that this question, which is equivalent to deciding the emptiness of
certain semi-algebraic sets bounded by cubic polynomials, can be "lifted" to a
purely combinatorial problem. We propose an effective algorithm for that
problem, and use it to gain new insights into the structure of geometric
permutations.
</p></div>
    </summary>
    <updated>2019-03-10T23:37:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.03003</id>
    <link href="http://arxiv.org/abs/1903.03003" rel="alternate" type="text/html"/>
    <title>Fast Exact Dynamic Time Warping on Run-Length Encoded Time Series</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Froese:Vincent.html">Vincent Froese</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Brijnesh.html">Brijnesh Jain</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.03003">PDF</a><br/><b>Abstract: </b>Dynamic Time Warping (DTW) is a well-known similarity measure for time
series. The standard dynamic programming approach to compute the dtw-distance
of two length-$n$ time series, however, requires $O(n^2)$ time, which is often
too slow in applications. Therefore, many heuristics have been proposed to
speed up the dtw computation. These are often based on approximating or
bounding the true dtw-distance or considering special inputs (e.g. binary or
piecewise constant time series). In this paper, we present a fast and exact
algorithm to compute the dtw-distance of two run-length encoded time series.
This might be used for fast and accurate indexing and classification of time
series in combination with preprocessing techniques such as piecewise aggregate
approximation (PAA).
</p></div>
    </summary>
    <updated>2019-03-10T23:29:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02999</id>
    <link href="http://arxiv.org/abs/1903.02999" rel="alternate" type="text/html"/>
    <title>Hierarchies in directed networks</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02999">PDF</a><br/><b>Abstract: </b>Interactions in many real-world phenomena can be explained by a strong
hierarchical structure. Typically, this structure or ranking is not known;
instead we only have observed outcomes of the interactions, and the goal is to
infer the hierarchy from these observations. Discovering a hierarchy in the
context of directed networks can be formulated as follows: given a graph,
partition vertices into levels such that, ideally, there are only edges from
upper levels to lower levels. The ideal case can only happen if the graph is
acyclic. Consequently, in practice we have to introduce a penalty function that
penalizes edges violating the hierarchy. A practical variant for such penalty
is agony, where each violating edge is penalized based on the severity of the
violation. Hierarchy minimizing agony can be discovered in $O(m^2)$ time, and
much faster in practice. In this paper we introduce several extensions to
agony. We extend the definition for weighted graphs and allow a cardinality
constraint that limits the number of levels. While, these are conceptually
trivial extensions, current algorithms cannot handle them, nor they can be
easily extended. We provide an exact algorithm of $O(m^2 \log n)$ time by
showing the connection of agony to the capacitated circulation problem. We also
show that this bound is in fact pessimistic and we can compute agony for large
datasets. In addition, we show that we can compute agony in polynomial time for
any convex penalty, and, to complete the picture, we show that minimizing
hierarchy with any concave penalty is an NP-hard problem.
</p></div>
    </summary>
    <updated>2019-03-10T23:36:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02904</id>
    <link href="http://arxiv.org/abs/1903.02904" rel="alternate" type="text/html"/>
    <title>Halin graphs are 3-vertex-colorable except even wheels</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>A. Kapanowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krawczyk:A=.html">A. Krawczyk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02904">PDF</a><br/><b>Abstract: </b>A Halin graph is a graph obtained by embedding a tree having no nodes of
degree two in the plane, and then adding a cycle to join the leaves of the tree
in such a way that the resulting graph is planar. According to the four color
theorem, Halin graphs are 4-vertex-colorable. On the other hand, they are not
2-vertex-colorable because they have triangles. We show that all Halin graphs
are 3-vertex-colorable except even wheels. We also show how to find the perfect
elimination ordering of a chordal completion for a given Halin graph. The
algorithms are implemented in Python using the graphtheory package. Generators
of random Halin graphs (general or cubic) are included. The source code is
available from the public GitHub repository.
</p></div>
    </summary>
    <updated>2019-03-10T23:37:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02840</id>
    <link href="http://arxiv.org/abs/1903.02840" rel="alternate" type="text/html"/>
    <title>Quantum hardness of learning shallow classical circuits</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arunachalam:Srinivasan.html">Srinivasan Arunachalam</a>, Alex B. Grilo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sundaram:Aarthi.html">Aarthi Sundaram</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02840">PDF</a><br/><b>Abstract: </b>In this paper we study the quantum learnability of constant-depth classical
circuits under the uniform distribution and in the distribution-independent
framework of PAC learning. In order to attain our results, we establish
connections between quantum learning and quantum-secure cryptosystems. We then
achieve the following results.
</p>
<p>1) Hardness of learning AC$^0$ and TC$^0$ under the uniform distribution. Our
first result concerns the concept class TC$^0$ (resp. AC$^0$), the class of
constant-depth and polynomial-sized circuits with unbounded fan-in majority
gates (resp. AND, OR, NOT gates). We show that if there exists no quantum
polynomial-time (resp. sub-exponential time) algorithm to solve the Learning
with Errors (LWE) problem, then there exists no polynomial-time quantum
learning algorithm for TC$^0$ (resp. AC$^0$) under the uniform distribution
(even with access to quantum membership queries). The main technique in this
result uses explicit pseudo-random generators that are believed to be
quantum-secure to construct concept classes that are hard to learn quantumly
under the uniform distribution.
</p>
<p>2) Hardness of learning TC$^0_2$ in the PAC setting. Our second result shows
that if there exists no quantum polynomial time algorithm for the LWE problem,
then there exists no polynomial time quantum PAC learning algorithm for the
class TC$^0_2$, i.e., depth-2 TC$^0$ circuits. The main technique in this
result is to establish a connection between the quantum security of public-key
cryptosystems and the learnability of a concept class that consists of
decryption functions of the cryptosystem.
</p>
<p>This gives a strong conditional negative answer to one of the "Ten Semi-Grand
Challenges for Quantum Computing Theory" raised by Aaronson [Aar05], who asked
if AC$^0$ and TC$^0$ can be PAC-learned in quantum polynomial time.
</p></div>
    </summary>
    <updated>2019-03-10T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02810</id>
    <link href="http://arxiv.org/abs/1903.02810" rel="alternate" type="text/html"/>
    <title>The robust bilevel continuous knapsack problem</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchheim:Christoph.html">Christoph Buchheim</a>, Dorothee Henke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02810">PDF</a><br/><b>Abstract: </b>We consider a bilevel continuous knapsack problem where the leader controls
the capacity of the knapsack and the follower's profits are uncertain. Adopting
the robust optimization approach and assuming that the follower's profits
belong to a given uncertainty set, our aim is to compute a worst case optimal
solution for the leader. We show that this problem can be solved in polynomial
time for both discrete and interval uncertainty. In the latter case, we make
use of an algorithm by Woeginger for a class of precedence constraint knapsack
problems.
</p></div>
    </summary>
    <updated>2019-03-10T23:37:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02758</id>
    <link href="http://arxiv.org/abs/1903.02758" rel="alternate" type="text/html"/>
    <title>A face cover perspective to $\ell_1$ embeddings of planar graphs</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Arnold.html">Arnold Filtser</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02758">PDF</a><br/><b>Abstract: </b>It was conjectured by Gupta et. al. [Combinatorica04] that every planar graph
can be embedded into $\ell_1$ with constant distortion. However, given an
$n$-vertex weighted planar graph, the best upper bound is only $O(\sqrt{\log
n})$ by Rao [SoCG99]. In this paper we study the terminated case, where there
is a set $K$ of terminals, and the goal is to embed only the terminals into
$\ell_1$ with low distortion. In a seminal paper, Okamura and Seymour
[J.Comb.Theory81] showed that if all the terminals lie on a single face, they
can be embedded isometrically into $\ell_1$. More generally, suppose that the
terminals could be covered by $\gamma$ faces. In a recent paper Krauthgamer,
Lee and Rika [SODA19] showed an upper bound of $O(\log \gamma)$ on the
distortion, improving previous results by Lee and Sidiropoulos [STOC09] and
Chekuri et. al. [J.Comb.Theory13]. Our contribution is a further improvement of
the upper bound to $O(\sqrt{\log\gamma})$. Note that since every planar graph
has at most $O(n)$ faces, any further improvement of this result, will imply an
improvement upon Rao's long standing upper bound.
</p>
<p>It is well known that the flow-cut gap equals to the distortion of the best
embedding into $\ell_1$. In particular, our result provide a polynomial time
$O(\sqrt{\log \gamma})$-approximation to the sparsest cut problem on planar
graph, for the case where all the demand pairs can be covered by $\gamma$
faces.
</p></div>
    </summary>
    <updated>2019-03-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02742</id>
    <link href="http://arxiv.org/abs/1903.02742" rel="alternate" type="text/html"/>
    <title>Stronger L2/L2 Compressed Sensing; Without Iterating</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakos:Vasileios.html">Vasileios Nakos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02742">PDF</a><br/><b>Abstract: </b>We consider the extensively studied problem of $\ell_2/\ell_2$ compressed
sensing. The main contribution of our work is an improvement over [Gilbert, Li,
Porat and Strauss, STOC 2010] with faster decoding time and significantly
smaller column sparsity, answering two open questions of the aforementioned
work.
</p>
<p>Previous work on sublinear-time compressed sensing employed an iterative
procedure, recovering the heavy coordinates in phases. We completely depart
from that framework, and give the first sublinear-time $\ell_2/\ell_2$ scheme
which achieves the optimal number of measurements without iterating; this new
approach is the key step to our progress. Towards that, we satisfy the
$\ell_2/\ell_2$ guarantee by exploiting the heaviness of coordinates in a way
that was not exploited in previous work. Via our techniques we obtain improved
results for various sparse recovery tasks, and indicate possible further
applications to problems in the field, to which the aforementioned iterative
procedure creates significant obstructions.
</p></div>
    </summary>
    <updated>2019-03-10T23:36:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02675</id>
    <link href="http://arxiv.org/abs/1903.02675" rel="alternate" type="text/html"/>
    <title>A Rank-1 Sketch for Matrix Multiplicative Weights</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carmon:Yair.html">Yair Carmon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duchi:John_C=.html">John C. Duchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Kevin.html">Kevin Tian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02675">PDF</a><br/><b>Abstract: </b>We show that a simple randomized sketch of the matrix multiplicative weight
(MMW) update enjoys the same regret bounds as MMW, up to a small constant
factor. Unlike MMW, where every step requires full matrix exponentiation, our
steps require only a single product of the form $e^A b$, which the Lanczos
method approximates efficiently. Our key technique is to view the sketch as a
randomized mirror projection, and perform mirror descent analysis on the
expected projection. Our sketch solves the online eigenvector problem,
improving the best known complexity bounds. We also apply this sketch to a
simple no-regret scheme for semidefinite programming in saddle-point form,
where it matches the best known guarantees.
</p></div>
    </summary>
    <updated>2019-03-10T23:35:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1903.02645</id>
    <link href="http://arxiv.org/abs/1903.02645" rel="alternate" type="text/html"/>
    <title>Encoding 3SUM</title>
    <feedworld_mtime>1552176000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cabello:Sergio.html">Sergio Cabello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardinal:Jean.html">Jean Cardinal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerman:Stefan.html">Stefan Langerman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Morin:Pat.html">Pat Morin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ooms:Aur=eacute=lien.html">Aurélien Ooms</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02645">PDF</a><br/><b>Abstract: </b>We consider the following problem: given three sets of real numbers, output a
word-RAM data structure from which we can efficiently recover the sign of the
sum of any triple of numbers, one in each set. This is similar to a previous
work by some of the authors to encode the order type of a finite set of points.
While this previous work showed that it was possible to achieve slightly
subquadratic space and logarithmic query time, we show here that for the
simpler 3SUM problem, one can achieve an encoding that takes
$\tilde{O}(N^{\frac 32})$ space for inputs sets of size $N$ and allows constant
time queries in the word-RAM.
</p></div>
    </summary>
    <updated>2019-03-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-03-08T00:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1494</id>
    <link href="https://theorydish.blog/2019/03/08/stoc-2019-workshop-and-tutorial-proposals/" rel="alternate" type="text/html"/>
    <title>STOC 2019 workshop and tutorial proposals</title>
    <summary>I want to draw your attention to the call for workshop and tutorial proposals for STOC 2019:http://acm-stoc.org/stoc2019/callforworkshops.html Important Dates Submission deadline:March 24, 2019Notification:April 5, 2019Workshop Day:Sunday June 23, 2019 STOC 2019 will hold a Workshop and Tutorial Day on Sunday June 23. We invite groups of interested researchers to submit workshop or tutorial proposals. The STOC 2019 Workshop and Tutorial Day provides an informal forum for researchers to discuss important research questions, directions, and challenges of the field. We also encourage workshops that focus on connections between theoretical computer science and other areas, topics that are not well represented at STOC, new directions, and open problems. The program may also include tutorials, each consisting of a few survey talks on a particular area. Format: We have room for three workshops/tutorials running in parallel for the course of the day with a break for lunch. In addition, workshops or tutorials may be full-day (6 hrs) or half-day (3 hrs). Proposal Submission Workshop and tutorial proposals should, ideally, fit one page. Please include a list of names and email addresses of the organizers, a brief description of the topic and the goals of the workshop or tutorial, the proposed workshop format (invited [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I want to draw your attention to the call for workshop and tutorial proposals for STOC 2019:<br/><a href="http://acm-stoc.org/stoc2019/callforworkshops.html">http://acm-stoc.org/stoc2019/callforworkshops.html</a></p>



<h4>Important Dates</h4>



<table class="wp-block-table"><tbody><tr><td>Submission deadline:</td><td><strong>March 24, 2019</strong></td></tr><tr><td>Notification:</td><td>April 5, 2019</td></tr><tr><td>Workshop Day:</td><td><strong>Sunday June 23, 2019</strong></td></tr></tbody></table>



<p><strong>STOC 2019 will hold a Workshop and Tutorial Day on Sunday June 23. We invite groups of interested researchers to submit workshop or tutorial proposals.</strong></p>



<p>The STOC 2019 Workshop and Tutorial Day provides an informal forum for researchers to discuss important research questions, directions, and challenges of the field. We also encourage workshops that focus on connections between theoretical computer science and other areas, topics that are not well represented at STOC, new directions, and open problems. The program may also include tutorials, each consisting of a few survey talks on a particular area.</p>



<p><strong>Format</strong>: We have room for three workshops/tutorials running in parallel for the course of the day with a break for lunch. In addition, workshops or tutorials may be full-day (6 hrs) or half-day (3 hrs). </p>



<h4>Proposal Submission</h4>



<p>Workshop and tutorial proposals should, ideally, fit one page. Please include a list of names and email addresses of the organizers, a brief description of the topic and the goals of the workshop or tutorial, the proposed workshop format (invited talks, contributed talks, contributed posters, panel, etc.), and proposed or tentatively confirmed speakers if known. Please also indicate the preferred length of time (3 hrs or 6 hrs) for your workshop/tutorial. If your proposal is accepted and you wish to solicit contributed talks (which we strongly encourage), we can link to your call-for-contributions from the STOC 2019 page. Feel free to contact the Chair of the Workshop and Tutorials Committee directly or at the email address below if you have any questions.</p>



<h4>Submission Deadline</h4>



<p>Proposals should be submitted by <strong>March 24, 2019</strong> via email to <a href="mailto:stoc2019events@gmail.com">stoc2019events@gmail.com</a>. Proposers will be notified by April 5, 2019 whether their proposals have been accepted.</p>



<p><strong>Workshop and Tutorials Committee:</strong> Moses Charikar (Chair)</p>



<p><br/></p>



<p/></div>
    </content>
    <updated>2019-03-08T16:25:56Z</updated>
    <published>2019-03-08T16:25:56Z</published>
    <category term="Uncategorized"/>
    <category term="STOC2019"/>
    <author>
      <name>Moses Charikar</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-03-11T15:21:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5011417931001574576</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5011417931001574576/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/qed.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5011417931001574576" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5011417931001574576" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/03/qed.html" rel="alternate" type="text/html"/>
    <title>QED</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Via <a href="https://www.scottaaronson.com/blog/?p=4133">Scott</a>, John Horgan wrote a <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">blog post</a> following on his 1993 Scientific American article <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">The Death of Proof</a>. The article talked about computer-generated proofs, experimental mathematics and even mentioned some of our work on <a href="https://doi.org/10.1145/103418.103428">transparent proofs</a> (basically time-efficient probabilistically checkable proofs). I got (sarcastically I think) accused of killing mathematics after that article but of course we had traditional proofs about probabilistically check proofs. Andrew Wiles got a sidebar titled "A Splendid Anachronism?" for merely solving the most famous open problem in all of mathematics. Somehow traditional mathematical proofs survived the article.<div>
<br/></div>
<div>
Meanwhile in CACM, Moshe Vardi writes <a href="https://cacm.acm.org/magazines/2019/3/234913-lost-in-math/fulltext">Lost in Math?</a> </div>
<blockquote class="tr_bq">
TCS is surely blessed with mathematical beauty. As a graduate student a long time ago, it was mathematical beauty that attracted me to TCS, and continued to lead my research for many years. I find computational complexity theory (or complexity theory, for short), with its theorems (for example, the time-hierarchy and space-hierarchy theorems) and its open questions (for example, P vs NP), to be hauntingly beautiful. Beauty, yes; but what about truth?</blockquote>
Here here on the beauty of complexity. So what about truth? I cover much of this in my <a href="https://cacm.acm.org/magazines/2009/9/38904-the-status-of-the-p-versus-np-problem/fulltext">P v NP survey</a>. In short the P v NP captures the most critical aspects of what is efficiently computable but it is not the endpoint. Nevertheless P v NP captures both truth and beauty and that's why the problem has so captivated and guided me throughout my research career.</div>
    </content>
    <updated>2019-03-08T15:05:00Z</updated>
    <published>2019-03-08T15:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-03-11T10:16:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=622</id>
    <link href="https://emanueleviola.wordpress.com/2019/03/07/a-dream-come-true-sort-of-e-ink-monitors/" rel="alternate" type="text/html"/>
    <title>A dream come true, sort of: E-ink monitors</title>
    <summary>Spending your life staring at a (traditional) computer screen may not be ideal for your eyes (and more); so since an early age I have been dreaming of a “purely mechanical” monitor that you could stare at more or less indefinitely, like at parchment. This dream is not becoming reality, sort of.  The Dasung E-ink […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;">Spending your life staring at a (traditional) computer screen may not be ideal for your eyes (and more); so since an early age I have been dreaming of a “purely mechanical” monitor that you could stare at more or less indefinitely, like at parchment.</p>
<p style="text-align: justify;">This dream is not becoming reality, sort of.  The <a href="https://www.amazon.com/Dasung-Ink-Paperlike-13-3-Monitor/dp/B07GWGFW1B/ref=asc_df_B07GWGFW1B/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=309743296044&amp;hvpos=1o1&amp;hvnetw=g&amp;hvrand=4273202700836301476&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9002067&amp;hvtargid=pla-571127059636&amp;psc=1">Dasung E-ink monitor </a>has no backlight and instead reportedly uses electric flows to move ink droplets.</p>
<p style="text-align: justify;">After some consideration, spending yet more hours reading reviews online and watching youtube videos about it sealed the deal.  I shelled out $1300 and bought the thing.</p>
<p style="text-align: justify;">I have had it for a few days now and I am sort of happy. I went from using a giant 30-inch monitor far away (my theory for avoiding eye strain) to using a ~13-inch monitor at pretty much the same distance as reading a book. I had to avoid sunlight, now I seek it (see the picture).</p>
<p style="text-align: justify;"><img alt="20190307_094550" class="alignnone size-full wp-image-624" src="https://emanueleviola.files.wordpress.com/2019/03/20190307_094550.jpg?w=640"/></p>
<p style="text-align: justify;">The monitor makes your computer look like Windows 3.1 on a monochrome screen from the 80’s. The refresh is slow, and there is a ghosting effect, meaning there are shadows of previous images — which you can clear out. Also, it’s 4:3 instead of 16:9, which is a pain because it means I have to change resolution when I am forced to use my other monitor (for example if I have to check colors — the screen is gray-scale, did I mention that?). It makes browsing the internet quite painful, which is a nice side effect.</p>
<p style="text-align: justify;">Contrary to advice, I am using it as my primary monitor. I am sort of happy with it and don’t regret buying it. I have started writing and reading papers with it and it’s working well enough.</p>
<p style="text-align: justify;">I think as soon as the technology improves the market for these things will be huge.  Already having a 17″ monitor in 16:9 ratio, ideally touch-screen, even if gray scale, would be a dream come true.</p></div>
    </content>
    <updated>2019-03-07T14:54:57Z</updated>
    <published>2019-03-07T14:54:57Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="review"/>
    <category term="tech"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2019-03-11T15:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4133</id>
    <link href="https://www.scottaaronson.com/blog/?p=4133" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4133#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4133" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Death of proof greatly exaggerated</title>
    <summary xml:lang="en-US">In 1993, the science writer John Horgan—who’s best known for his book The End of Science, and (of course) for interviewing me in 2016—wrote a now-(in)famous cover article for Scientific American entitled “The Death of Proof.” Mashing together a large number of (what I’d consider) basically separate trends and ideas, Horgan argued that math was […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 1993, the science writer <a href="https://en.wikipedia.org/wiki/John_Horgan_(journalist)">John Horgan</a>—who’s best known for his book <em><a href="https://www.amazon.com/End-Science-Knowledge-Twilight-Scientific/dp/0465065929">The End of Science</a></em>, and (of course) for <a href="https://blogs.scientificamerican.com/cross-check/scott-aaronson-answers-every-ridiculously-big-question-i-throw-at-him/">interviewing me in 2016</a>—wrote a now-(in)famous cover article for <em>Scientific American</em> entitled <a href="https://pdfs.semanticscholar.org/4e56/c6fea76922082400dfc6e13a3a169ae7b9a6.pdf">“The Death of Proof.”</a>  Mashing together a large number of (what I’d consider) basically separate trends and ideas, Horgan argued that math was undergoing a fundamental change, with traditional deductive proofs being replaced by a combination of non-rigorous numerical simulations, machine-generated proofs, probabilistic and probabilistically-checkable proofs, and proofs using graphics and video.  Horgan also suggested that Andrew Wiles’s then-brand-new <a href="https://en.wikipedia.org/wiki/Wiles%27s_proof_of_Fermat%27s_Last_Theorem">proof</a> of Fermat’s Last Theorem—which might have looked, at first glance, like a spectacular counterexample to the “death of proof” thesis—could be the “last gasp of a dying culture” and a “splendid anachronism.”  Apparently, “The Death of Proof” garnered one of the largest volumes of angry mail in <em>Scientific American</em>‘s history, with mathematician after mathematician arguing that Horgan had strung together half-digested quotes and vignettes to manufacture a non-story.</p>



<p>Now Horgan—who you could variously describe as a wonderful sport, or a ham, or a sucker for punishment—has written a <a href="https://blogs.scientificamerican.com/cross-check/the-horgan-surface-and-the-death-of-proof/">26-year retrospective</a> on his “death of proof” article.  The prompt for this was Horgan’s recent discovery that, back in the 90s, David Hoffman and Hermann Karcher, two mathematicians annoyed by the “death of proof” article, had named a nonexistent mathematical object after its author.  The so-called <em><a href="https://minimalsurfaces.blog/home/repository/non-existent-surfaces/the-horgan-surface/">Horgan surface</a></em> is a minimal surface that numerical computations strongly suggested should exist, but that can be rigorously proven not to exist after all.  “The term was intended as an insult, but I’m honored anyway,” Horgan writes.</p>



<p>As a followup to his blog post, Horgan then decided to solicit commentary from various people he knew, including yours truly, about “how proofs are faring in an era of increasing computerization.”  He wrote, “I’d love to get a paragraph or two from you.”  Alas, I didn’t have the time to do as requested, but only to write <i>eight</i> paragraphs.  So Horgan suggested that I make the result into a post on my own blog, which he’d then link to.  Without further ado, then:</p>



<hr/>



<p>John, I like you so I hate to say it, but the last quarter century has not been kind to your thesis about “the death of proof”!  Those mathematicians sending you the irate letters had a point: there’s been no fundamental change to mathematics that deserves such a dramatic title.  Proof-based math remains quite healthy, with (e.g.) a solution to the <a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture">Poincaré conjecture</a> since your article came out, as well as to the <a href="https://arxiv.org/abs/1509.05363">Erdős discrepancy problem</a>, the <a href="https://en.wikipedia.org/wiki/Kadison%E2%80%93Singer_problem">Kadison-Singer conjecture</a>, <a href="https://en.wikipedia.org/wiki/Catalan%27s_conjecture">Catalan’s conjecture</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.998&amp;rep=rep1&amp;type=pdf">bounded gaps in primes</a>, <a href="https://en.wikipedia.org/wiki/AKS_primality_test">testing primality in deterministic polynomial time</a>, etc. — just to pick a few examples from the tiny subset of areas that I know anything about.</p>



<p>There are evolutionary changes to mathematical practice, as there always have been.  Since 2009, the website <a href="https://mathoverflow.net/">MathOverflow</a> has let mathematicians query the global hive-mind about an obscure reference or a recalcitrant step in a proof, and get near-instant answers.  Meanwhile <a href="https://polymathprojects.org/">“polymath” projects</a> have, with moderate success, tried to harness blogs and other social media to make advances on long-standing open math problems using massive collaborations.</p>



<p>While humans remain in the driver’s seat, there are persistent efforts to increase the role of computers, with some notable successes.  These include Thomas Hales’s 1998 computer-assisted proof of the <a href="https://en.wikipedia.org/wiki/Kepler_conjecture">Kepler Conjecture</a> (about the densest possible way to pack oranges) — now fully machine-verified from start to finish, after <del>the </del><em><del>Annals of Mathematics</del></em><del> refused to publish a mixture of traditional mathematics and computer code</del> (seems this is not exactly what happened; see the comment section for more).  It also includes William McCune’s 1996 solution to the <a href="https://en.wikipedia.org/wiki/Robbins_algebra">Robbins Conjecture</a> in algebra (the computer-generated <a href="https://www.cs.unm.edu/~mccune/papers/robbins/eqp-theorem.proof.txt">proof</a> was only half a page, but involved substitutions so strange that for 60 years no human had found them); and at the “opposite extreme,” the 2016 solution to the <a href="https://en.wikipedia.org/wiki/Boolean_Pythagorean_triples_problem">Pythagorean triples problem</a> by Marijn Heule and collaborators, which weighed in at 200 terabytes (at that time, “the longest proof in the history of mathematics”).</p>



<p>It’s conceivable that someday, computers will replace humans at all aspects of mathematical research — but it’s also conceivable that, by the time they can do that, they’ll be able to replace humans at music and science journalism and everything else!</p>



<p><a href="http://www.scottaaronson.com/talks/proofs.ppt">New notions of proof</a> — including probabilistic, interactive, zero-knowledge, and even quantum proofs — have seen further development by theoretical computer scientists since 1993.  So far, though, these new types of proof remain either entirely theoretical (as with <a href="https://arxiv.org/abs/1610.01664">quantum proofs</a>), or else they’re used for cryptographic protocols but not for mathematical research.  (For example, zero-knowledge proofs now play a major role in certain cryptocurrencies, such as <a href="https://en.wikipedia.org/wiki/Zcash">Zcash</a>.)</p>



<p>In many areas of math (including my own, theoretical computer science), proofs have continued to get longer and harder for any one person to absorb.  This has led some to advocate a split approach, wherein human mathematicians would talk to each other only about the handwavy intuitions and high-level concepts, while the tedious verification of details would be left to computers.  So far, though, the huge investment of time needed to write proofs in machine-checkable format — for almost no return in new insight — has prevented this approach’s wide adoption.</p>



<p>Yes, there are non-rigorous approaches to math, which continue to be widely used in physics and engineering and other fields, as they always have been.  But none of these approaches have displaced proof as the gold standard whenever it’s available.  If I had to speculate about why, I’d say: if you use non-rigorous approaches, then even if it’s clear to you under what conditions your results can be trusted, it’s probably much less clear to others.  Also, even if only one segment of a research community cares about rigor, whatever earlier work that segment builds on will need to be rigorous as well — thereby exerting constant pressure in that direction.  Thus, the more collaborative a given research area becomes, the more important is rigor.</p>



<p>For my money, the elucidation of the foundations of mathematics a century ago, by Cantor, Frege, Peano, Hilbert, Russell, Zermelo, Gödel, Turing, and others, still stands as one of the greatest triumphs of human thought, up there with evolution or quantum mechanics or anything else.  It’s true that the ideal set by these luminaries remains mostly aspirational.  When mathematicians say that a theorem has been “proved,” they still mean, as they always have, something more like: “we’ve reached a social consensus that all the ideas are now in place for a strictly formal proof that could be verified by a machine … with the only task remaining being massive rote coding work that none of us has any intention of ever doing!”  It’s also true that mathematicians, being human, are subject to the full panoply of foibles you might expect: claiming to have proved things they haven’t, squabbling over who proved what, accusing others of lack of rigor while hypocritically taking liberties themselves.  But just like love and honesty remain fine ideals no matter how often they’re flouted, so too does mathematical rigor.</p>



<p><strong><font color="red">Update:</font></strong> <a href="https://blogs.scientificamerican.com/cross-check/okay-maybe-proofs-arent-dying-after-all/">Here’s Horgan’s new post</a> (entitled “Okay, Maybe Proofs Aren’t Dying After All”), which also includes a contribution from Peter Woit.<br/></p></div>
    </content>
    <updated>2019-03-07T10:11:41Z</updated>
    <published>2019-03-07T10:11:41Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-03-07T19:54:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/037</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/037" rel="alternate" type="text/html"/>
    <title>TR19-037 |  Closure of VP under taking factors: a short and simple proof | 

	Mrinal Kumar, 

	Chi-Ning  Chou, 

	Noam Solomon</title>
    <summary>In this note, we give a short, simple and almost completely self contained proof of a classical result of Kaltofen [Kal86, Kal87, Kal89] which shows that if an n variate degree $d$ polynomial f can be computed by an arithmetic circuit of size s, then each of its factors can be computed by an arithmetic circuit of size at most poly(s, n, d). 

However, unlike Kaltofen's argument, our proof  does not  directly give an efficient algorithm for computing the circuits for the factors of f.</summary>
    <updated>2019-03-06T05:52:21Z</updated>
    <published>2019-03-06T05:52:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/03/06/postdoc-at-center-for-quantum-technologies-nus-singapore-apply-by-april-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/03/06/postdoc-at-center-for-quantum-technologies-nus-singapore-apply-by-april-30-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at Center for Quantum Technologies, NUS, Singapore (apply by April 30, 2019)</title>
    <summary>We have a postdoctoral position in post-quantum cryptography broadly defined. In particular, anyone interested in algorithmic and/or complexity-theoretic aspects of problems relevant in lattice-based, code-based, multivariate cryptography is welcome to apply. The position comes with an internationally competitive salary and sufficient support for travel. Website: http://cs.quantumlah.org/index.php Email: divesh.aggarwal@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We have a postdoctoral position in post-quantum cryptography broadly defined. In particular, anyone interested in algorithmic and/or complexity-theoretic aspects of problems relevant in lattice-based, code-based, multivariate cryptography is welcome to apply.</p>
<p>The position comes with an internationally competitive salary and sufficient support for travel.</p>
<p>Website: <a href="http://cs.quantumlah.org/index.php">http://cs.quantumlah.org/index.php</a><br/>
Email: divesh.aggarwal@gmail.com</p></div>
    </content>
    <updated>2019-03-06T00:50:53Z</updated>
    <published>2019-03-06T00:50:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-03-11T15:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/03/04/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/</id>
    <link href="https://cstheory-events.org/2019/03/05/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/" rel="alternate" type="text/html"/>
    <title>Symposium on 50 Years of Complexity Theory: A Celebration of the Work of Stephen Cook</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 6-9, 2019 The Fields Institute, Toronto, Ontario, Canada http://www.fields.utoronto.ca/activities/18-19/NP50 This symposium celebrates 50 years of NP-Completeness and the outstanding achievements of Stephen Cook and his remarkable influence on the field of computing. The symposium begins Monday evening May 6, with a reception and a public lecture by Christos Papadimitriou. The scientific program continues Tuesday … <a class="more-link" href="https://cstheory-events.org/2019/03/05/symposium-on-50-years-of-complexity-theory-a-celebration-of-the-work-of-stephen-cook/">Continue reading <span class="screen-reader-text">Symposium on 50 Years of Complexity Theory: A Celebration of the Work of Stephen Cook</span></a></div>
    </summary>
    <updated>2019-03-05T19:05:21Z</updated>
    <published>2019-03-05T19:05:21Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-03-11T15:21:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2300296093606210929</id>
    <link href="http://processalgebra.blogspot.com/feeds/2300296093606210929/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2300296093606210929" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2300296093606210929" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2300296093606210929" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/03/sirocco-2019-second-call-for-papers.html" rel="alternate" type="text/html"/>
    <title>SIROCCO 2019 - Second Call for Papers</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Michele Flammini, PC co-chair of <a href="http://cs.gssi.it/sirocco2019" target="_blank">this year's SIROCCO conference</a>, asked me to post the second CFP for that event. Submit your paper and win a trip to the Abruzzo region this summer! (In case you need them, here are <a href="https://edition.cnn.com/travel/article/italy-abruzzo-best-things-to-do/index.html" target="_blank">ten reasons why you should</a>. In my biased opinion, there are many more.)</i><br/><br/><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO 2019 - Second Call for Papers</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">26th International Colloquium on Structural Information and Communication Complexity (SIROCCO 2019)</span></div><div><u><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"><a href="http://cs.gssi.it/sirocco2019" style="color: purple;" target="_blank">http://cs.gssi.it/sirocco2019</a></span></u><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"/></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">July 1-4, 2019, L’Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">OVERVIEW. SIROCCO is devoted to the study of the interplay between structural knowledge, communication, and computing in decentralized systems of multiple communicating entities. Special emphasis is given to innovative approaches leading to better understanding of the relationship between computing and communication. SIROCCO has a tradition of interesting and productive scientific meetings in a relaxed and pleasant atmosphere, attracting leading researchers in a variety of fields in which communication and knowledge play a significant role. This year, SIROCCO will be held in L’Aquila, a beautiful historical city in the mountain side, 100km away from Rome.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SCOPE. Original papers are solicited from all areas of study of local structural knowledge, global communication, and computational complexities. Among the typical areas are distributed computing, communication networks, game theory, parallel computing, social networks, mobile computing (including autonomous robots), peer to peer systems, communication complexity, fault tolerant graphs, and probability in networks. Keeping up with the tradition of SIROCCO, new areas are always welcome.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SUBMISSIONS. Papers are to be submitted electronically through EasyChair at the following link: <a href="https://easychair.org/conferences/?conf=sirocco2019" style="color: purple;" target="_blank">https://easychair.org/conferences/?conf=sirocco2019</a>.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Authors are invited to submit their work in one of the two acceptable formats: regular papers and brief announcements. First, abstracts should be registered and later the full papers are due. A regular submission must report on original research and must contain results that have not previously appeared, and have not been concurrently submitted to a journal or a conference with published proceedings. It must be no longer than 12 single-column pages on letter-size paper using at least 11-point font, including tables and references. Up to 4 additional pages of figures may be included with the submission. Additional details may be included in a clearly marked appendix, which will be read at the discretion of the program committee. Full Proofs omitted for lack of space should appear in an appendix.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">A submission for a brief announcement must be no longer than 3 single-column pages on letter-size paper using at least 11-point font. The title of a submission for a brief announcement must begin with “Brief announcement:”. Such submissions may describe work in progress or work presented elsewhere. A submission that is not selected for regular presentation may be invited for a brief announcement.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">PUBLICATION. Regular papers and brief announcements will be included in the conference proceedings that will be published by Springer. Regular papers receive up to 15 pages, brief announcements receive up to 2 LNCS-style pages.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">BEST STUDENT PAPER AWARD. A prize will be given to the best student regular paper. A paper is eligible if at least one author is a full-time student at the time of submission, and the contribution of the student is significant. This must be noted on the cover page. The program committee may decline to give the award or may split it.</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">INVITED SPEAKERS</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Susanne Albers, TU München, Germany</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Pierre Fraigniaud, CNRS and University Paris Diderot, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Stefano Leonardi, Sapienza University of Rome, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Merav Parter, Weizmann Institute of Science, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO 2019 will also feature a talk by Paola Flocchini, University of Ottawa, Canada – Recipient of the 2019 Prize for Innovation in Distributed Computing</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">KEY DATES (all in 2019)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Abstract registration: April 1</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Full paper submission: April 7</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">SIROCCO notification: May 17</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Proceedings version: TBD</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Early registration: June 1</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">PROGRAM COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Dan Alistarh, IST Austria, Austria</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">James Aspnes, Yale University, USA</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Alkida Balliu, Aalto University, Finland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Vittorio Bilò, University of Salento, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Lelia Blin, Sorbonne University, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ioannis Caragiannis, University of Patras, Greece</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Keren Censor-Hillel, Technion, Israel (co-chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Michele Flammini, GSSI &amp; University of L’Aquila, Italy (co-chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Luisa Gargano, University of Salerno, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Chryssis Georgiou, University of Cyprus, Cyprus</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Magnús Halldórsson, Reykjavik University, Iceland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Tomasz Jurdzinski, University of Wroclaw, Poland</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Fabian Kuhn, University of Freiburg, Germany</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Toshimitsu Masuzawa, Osaka University, Japan</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Alessia Milani, University of Bordeaux, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ivan Rapaport, Universidad de Chile, Chile</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Dror Rawitz, Bar-Ilan University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Mordechai Shalom, Tel-Hai College, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Jennifer Welch, Texas A&amp;M University, USA</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Prudence W.H. Wong, University of Liverpool, UK</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Yukiko Yamauchi, Kyushu University, Japan</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">        </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">ORGANIZING COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Guido Proietti, University of L'Aquila, Italy (chair)</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Gianlorenzo D’Angelo, GSSI, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Mattia D’Emidio, University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Michele Flammini, GSSI &amp; University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Luciano Gualà, University of Rome Tor Vergata, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Ludovico Iovino, GSSI, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Cosimo Vinci, University of L'Aquila, Italy</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;"> </span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">STEERING COMMITTEE</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Shantanu Das, Aix-Marseille University, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Rastislav Kralovic, Comenius University, Slovakia</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Zvi Lotker, Ben Gurion University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Boaz Patt-Shamir, Tel Aviv University, Israel</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Andrzej Pelc, University of Québec, Canada</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Nicola Santoro, Carleton University, Canada</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Sebastien Tixeuil, University Paris 6, France</span></div><div><span style="color: #1f497d; font-family: Calibri, sans-serif; font-size: 11pt;">Jukka Suomela, Aalto University, Finland</span></div></div>
    </content>
    <updated>2019-03-05T18:03:00Z</updated>
    <published>2019-03-05T18:03:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-03-05T18:03:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/036</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/036" rel="alternate" type="text/html"/>
    <title>TR19-036 |  On the complexity of computing a random Boolean function over the reals | 

	Pavel Hrubes</title>
    <summary>We say that a first-order formula $A(x_1,\dots,x_n)$ over $\mathbb{R}$ defines a Boolean function $f:\{0,1\}^n\rightarrow\{0,1\}$, if for every $x_1,\dots,x_n\in\{0,1\}$, $A(x_1,\dots,x_n)$ is true iff $f(x_1,\dots,x_n)=1$. We show that:

(i) every $f$ can be defined by a formula of size $O(n)$, 
(ii) if $A$ is required to have at most $k\geq 1$ quantifier alternations, there exists an $f$ which requires  a formula of size $2^{\Omega(n/k)}$. 
 
The latter result implies several previously known as well as some new lower bounds in computational complexity. We note that (i) holds over any field of characteristic zero, and (ii) holds for any real closed or algebraically closed field.</summary>
    <updated>2019-03-05T14:26:34Z</updated>
    <published>2019-03-05T14:26:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/035</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/035" rel="alternate" type="text/html"/>
    <title>TR19-035 |  PIT for depth-4 circuits and Sylvester-Gallai theorem for polynomials | 

	Alexey Milovanov</title>
    <summary>This text is a development of  a preprint of Ankit Gupta. 

We present an approach for devising a deterministic polynomial time whitekbox identity testing (PIT) algorithm for depth-$4$ circuits with bounded top fanin.
This approach is similar to Kayal-Saraf approach for depth-$3$ circuits. Kayal and Saraf  based their algorithm on Sylvester-Gallai-type theorem about linear polynomials. We show how it is possible to generalize this approach to depth-$4$ circuits. However we failed to implement this plan completely. We succeeded to construct a polynomial time deterministic algorithm for depth-$4$ circuits with bounded top fanin and its correctness requires a hypothesis. Also we present a  polynomial-time (unconditional) algorithm for some subclass of   depth-$4$ circuits with bounded top fanin.</summary>
    <updated>2019-03-05T14:25:03Z</updated>
    <published>2019-03-05T14:25:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/034</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/034" rel="alternate" type="text/html"/>
    <title>TR19-034 |  On $\epsilon$-sensitive monotone computations | 

	Pavel Hrubes</title>
    <summary>We show that strong-enough lower bounds on monotone arithmetic circuits or the non-negative rank of a matrix imply unconditional lower bounds in arithmetic or Boolean circuit complexity. First, we show that if a polynomial $f\in {\mathbb {R}}[x_1,\dots, x_n]$ of degree $d$ has an arithmetic circuit of size $s$ then $(x_1+\dots+x_n+1)^d+\epsilon f$ has a monotone arithmetic circuit of size $O(sd^2+n\log n)$, for some $\epsilon&gt;0$.  Second, if $f:\{0,1\}^n\rightarrow \{0,1\}$ is a Boolean function,  we associate with $f$ an explicit exponential-size matrix $M(f)$ such that the Boolean circuit size of $f$ is at least $\Omega(\min_{\epsilon &gt;0}(\hbox{rk}_+(M(f)-\epsilon J))- 2n)$, where $J$ is the all-ones matrix and $\hbox{rk}_+$ denotes the non-negative rank of a matrix. In fact, the quantity $\min_{\epsilon &gt;0}(\hbox{rk}_+(M(f)-\epsilon J))$ characterizes how hard is it to distinguish rejecting and accepting inputs of $f$ by means of a linear program. 
Finally, we introduce a proof system resembling the Boolean monotone calculus and show that similar $\epsilon$-sensitive lower bounds on monotone arithmetic circuits imply lower bounds on proof-size in the system.</summary>
    <updated>2019-03-05T13:06:08Z</updated>
    <published>2019-03-05T13:06:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/033</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/033" rel="alternate" type="text/html"/>
    <title>TR19-033 |  Counting basic-irreducible factors mod $p^k$ in deterministic poly-time and $p$-adic applications | 

	Ashish Dwivedi, 

	Rajat Mittal, 

	Nitin Saxena</title>
    <summary>Finding an irreducible factor, of a polynomial $f(x)$ modulo a prime $p$, is not known to be in deterministic polynomial time. Though there is such a classical algorithm that {\em counts} the number of irreducible factors of $f\bmod p$. We can ask the same question modulo prime-powers $p^k$. The irreducible factors of $f\bmod p^k$ blow up exponentially in number; making it hard to describe them. Can we count  those irreducible factors $\bmod~p^k$ that remain irreducible mod $p$? These are called {\em basic-irreducible}. A simple example is in $f=x^2+px \bmod p^2$; it has $p$ many basic-irreducible factors. Also note that, $x^2+p \bmod p^2$ is irreducible but not basic-irreducible!

We give an algorithm to count the number of basic-irreducible factors of $f\bmod p^k$ in deterministic poly($\deg(f),k\log p$)-time. This solves the open questions posed in (Cheng et al, ANTS'18 \&amp; Kopp et al, Math.Comp.'19). In particular, we are counting roots $\bmod\ p^k$; which gives the first deterministic poly-time algorithm to compute Igusa zeta function of $f$. Also, our algorithm efficiently partitions the set of all basic-irreducible factors (possibly exponential) into merely $\deg(f)$-many disjoint sets, using a compact tree data structure and {\em split} ideals.</summary>
    <updated>2019-03-05T08:51:33Z</updated>
    <published>2019-03-05T08:51:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/032</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/032" rel="alternate" type="text/html"/>
    <title>TR19-032 |  Strongly Exponential Separation Between Monotone VP and Monotone VNP | 

	Srikanth Srinivasan</title>
    <summary>We show that there is a sequence of explicit multilinear polynomials $P_n(x_1,\ldots,x_n)\in \mathbb{R}[x_1,\ldots,x_n]$ with non-negative coefficients that lies in monotone VNP such that any monotone algebraic circuit for $P_n$ must have size $\exp(\Omega(n)).$ This builds on (and strengthens) a result of Yehudayoff (2018) who showed a lower bound of $\exp(\tilde{\Omega}(\sqrt{n})).$</summary>
    <updated>2019-03-05T08:51:04Z</updated>
    <published>2019-03-05T08:51:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/031</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/031" rel="alternate" type="text/html"/>
    <title>TR19-031 |  Non-deterministic Quasi-Polynomial Time is Average-case Hard for ACC Circuits | 

	Lijie Chen</title>
    <summary>Following the seminal work of [Williams, J. ACM 2014], in a recent breakthrough, [Murray and Williams, STOC 2018] proved that NQP (non-deterministic quasi-polynomial time) does not have polynomial-size ACC^0 circuits.
	
We strengthen the above lower bound to an average case one, by proving that for all constants c, there is a language in NQP, which is not 1/2+1/log^c(n)-approximable by polynomial-size ACC^0 circuits. In fact, our lower bound holds for a larger circuit class: 2^(log^a n)-size ACC^0 circuits with a layer of threshold gates at the bottom, for all constants a. Our work also improves the average-case lower bound for NEXP against polynomial-size ACC circuits by [Chen, Oliveira, and Santhanam, LATIN 2018].
	
Our new lower bound builds on several interesting components, including: 
	
Barrington's theorem and the existence of an NC^1-complete language which is random self-reducible.
		
The sub-exponential witness-size lower bound for NE against ACC^0 and the conditional non-deterministic PRG construction in [Williams, SICOMP 2016].
		
An ``almost'' almost-everywhere MA average-case lower bound (which strengthens the corresponding worst-case lower bound in [Murray and Williams, STOC 2018]). 
		
A PSPACE-complete language which is same-length checkable, error-correctable and also has some other nice reducibility properties, which builds on [Trevisan and Vadhan, Computational Complexity 2007]. Moreover, all its reducibility properties have corresponding low-depth non-adaptive oracle circuits.

Like other lower bounds proved via the ``algorithmic approach'', the only property of ACC^0 of THR exploited by us is the existence of a non-trivial  SAT algorithm for ACC^0 of THR [Williams, STOC 2014]. Therefore, for any typical circuit class C, our results apply to them as well if the corresponding non-trivial SAT (in fact, GAP-UNSAT) algorithms are discovered.</summary>
    <updated>2019-03-04T23:07:29Z</updated>
    <published>2019-03-04T23:07:29Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-03-11T15:20:35Z</updated>
    </source>
  </entry>
</feed>
