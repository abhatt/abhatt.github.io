<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-08-08T20:22:33Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17394</id>
    <link href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/" rel="alternate" type="text/html"/>
    <title>Fran Allen: 1932-2020</title>
    <summary>We lost a great computer scientist. Frances Allen was one of the leaders who helped create the field of compilers research. Fran was an elite researcher at IBM, and won a Turing Award for this pioneering work. Allen also collected other awards. Perhaps the coolest award is one that Fran could never win: The Frances […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>We lost a great computer scientist.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p>
Frances Allen was one of the leaders who helped create the field of <a href="https://en.wikipedia.org/wiki/Compiler">compilers</a> research. Fran was an elite researcher at IBM, and won a Turing Award for this pioneering work. Allen also collected other awards. </p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/fran/" rel="attachment wp-att-17396"><img alt="" class="alignright size-medium wp-image-17396" height="180" src="https://rjlipton.files.wordpress.com/2020/08/fran.png?w=300&amp;h=180" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>Perhaps the coolest award is one that Fran could never win: The <a href="https://www.ieee.org/about/awards/medals/frances-e-allen-medal.html">Frances E. Allen</a> award created this year by the IEEE: </p>
<blockquote><p><b> </b> <em> <i>For innovative work in computing leading to lasting impact on other fields of engineering, technology, or science.</i> </em>
</p></blockquote>
<p/><p>
Today we will talk about Fran, who sadly just passed away.</p>
<p>
I consider Fran a friend, although we never worked together—our areas of interest were different. One fond memory of mine is being on panel a while ago with Fran. What a delightful presence.</p>
<p>
Fran always seemed to be smiling, always with that smile. The following images come in large part from interviews and lectures and award events-the fact that it is so easy to find them is a testament to her public engagement as well as scientific contributions.</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/collage/" rel="attachment wp-att-17398"><img alt="" class="aligncenter size-medium wp-image-17398" height="290" src="https://rjlipton.files.wordpress.com/2020/08/collage.png?w=300&amp;h=290" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p/><h2> Compliers were Key </h2><p/>
<p/><p>
There was a time when compliers were the most important program available on any new computer. Perhaps on any computer. Here is proof: </p>
<ol>
<li>
Computers are there to solve problems. <p/>
</li><li>
We must write programs to solve problems. <p/>
</li><li>
Details of the computer and instructions, are complicated, which make writing programs hard. <p/>
</li><li>
Thus, automating the writing of programs is important. <p/>
</li><li>
QED: we must have compliers.
</li></ol>
<p>
Okay this is not really a “proof”, but there is some truth to the argument. Fran was at IBM and worked on some of the early compliers, including FORTRAN and related languages. IBM wanted to sell computers, well actually in the early days rent them. One potential roadblock, IBM realized, was that new computers could be hard to program. Thus to ensure that companies rented new machines as fast as IBM could manufacture them was important. This created the need for compliers and even more for <i>optimizing compilers</i>.</p>
<p>
In order to ship more machines, the code that a complier created had to be efficient. Hence, a stress on Allen was to figure out how compliers could generate high quality code. This led Fran and others like John Cocke to discover many complier techniques that are still used today. A short list of the ideas is: </p>
<ul>
<li>
Branch prediction <p/>
</li><li>
Register allocation <p/>
</li><li>
Control flow graphs <p/>
</li><li>
Program dependence graphs <p/>
</li><li>
And many more.
</li></ul>
<p>
What is so important is that Allen’s work was not just applicable to this machine or that language. Rather the work was able to be used for almost any machine and for almost any language. This universal nature of the work on compliers reminds me of what we try to do in theory. Allen’s research was so important because it could be used for future hardware as well as future languages. </p>
<p>
</p><p/><h2> Register Allocation </h2><p/>
<p/><p>
Guy Steele interviewed Allen for the ACM <a href="https://cacm.acm.org/magazines/2011/1/103191-an-interview-with-frances-e-allen/fulltext">here</a>. During the interview Fran talked about register allocation:</p>
<blockquote><p><b> </b> <em> I have a story about register allocation. FORTRAN back in the 1950’s had the beginnings of a theory of register allocation, even though there were only three registers on the target machine. Quite a bit later, John Backus became interested in applying graph coloring to allocating registers; he worked for about 10 years on that problem and just couldn’t solve it. I considered it the biggest outstanding problem in optimizing compilers for a long time. Optimizing transformations would produce code with symbolic registers; the issue was then to map symbolic registers to real machine registers, of which there was a limited set. For high-performance computing, register allocation often conflicts with instruction scheduling. There wasn’t a good algorithm until the Chaitin algorithm. Chaitin was working on the PL compiler for the 801 system. Ashok Chandra, another student of Knuth’s, joined the department and told about how he had worked on the graph coloring problem, which Knuth had given out in class, and had solved it not by solving the coloring problem directly, but in terms of what is the minimal number of colors needed to color the graph. Greg immediately recognized that he could apply this solution to the register allocator issue. It was a wonderful kind of serendipity. </em>
</p></blockquote>
<p>
</p><p/><h2> Compliers Create Theory </h2><p/>
<p/><p>
The early goal of creating compliers lead directly to some wonderful theory problems. One whole area that dominated early theory research was language theory. In particular understanding questions that arise in defining programming languages. Syntax came first—later semantics was formalized.</p>
<p>
Noam Chomsky created context-free grammars to help understand natural languages in the 1950s. His ideas were used by John Backus, also a Turing award winner from IBM, to describe the then new programming language IAL. This is known today as ALGOL 58, which became ALGOL 60. Peter Naur on the ALGOL 60 committee called Backus’s notation for ALGOL’s syntax: Backus normal form, but is now called BNF-Backus-Naur form. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/bnf-2/" rel="attachment wp-att-17399"><img alt="" class="aligncenter size-medium wp-image-17399" height="39" src="https://rjlipton.files.wordpress.com/2020/08/bnf.png?w=300&amp;h=39" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Theorists worked on, I confess I did, many questions about such languages. Existence problems, decidability problems, efficient algorithms, and closure properties were just some of the examples. Not clear how much of this theory effected compiler design, but I would like to think that some was useful. Theorist should thank the complier researchers. I do. </p>
<p>
For instance the 1970 STOC <a href="https://dblp.org/db/conf/stoc/stoc70">program</a> had many papers on language related topics—here are some:</p>
<ul>
<li>
A Result on the Relationship between Simple Precedence Languages and Reducing Transition Languages. 		Gary Lindstrom <p/>
</li><li>
The Design of Parsers for Incremental Language Processors: 		Ronald Book, Sheila Greibach, Ben Wegbreit <p/>
</li><li>
Tape- and Time-Bounded Turing Acceptors and AFLs. 		David Lewis <p/>
</li><li>
Closure of Families of Languages under Substitution Operators. 		William Rounds <p/>
</li><li>
Tree-Oriented Proofs of Some Theorems on Context-Free and Indexed Languages. 		Barry Rosen <p/>
</li><li>
On Syntax-Directed Transduction and Tree Transducers. 		Alfred Aho, Jeffrey Ullman <p/>
</li><li>
The Analysis of Two-Dimensional Patterns using Picture Processing Grammars. 		Jean-Francois Perrot <p/>
</li><li>
On Some Families of Languages Related to the Dyck Language. 		Joseph Ullian <p/>
</li><li>
Three Theorems on Abstract Families of Languages. 	Joseph Ullian
</li></ul>
<p>
By the way Abstract Families of Languages or <a href="https://en.wikipedia.org/wiki/Abstract_family_of_languages">AFL</a>s was created by Seymour Ginsburg and Sheila Greibach in 1967 as a way to generalize context free languages. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Fran was asked by Steele in that <a href="https://cacm.acm.org/magazines/2011/1/103191-an-interview-with-frances-e-allen/fulltext">interview</a>: <i>Any advice for the future?</i></p>
<blockquote><p><b> </b> <em> Yes, I do have one thing. Students aren’t joining our field, computer science, and I don’t know why. It’s just such an amazing field, and it’s changed the world, and we’re just at the beginning of the change. We have to find a way to get our excitement out to be more publicly visible. It is exciting, in the 50 years that I’ve been involved, the change has been astounding. </em>
</p></blockquote>
<p/><p>
Thanks Fran. Much of that change is due to pioneers like you. Thanks for everything.</p>
<p/></font></font></div>
    </content>
    <updated>2020-08-08T14:40:43Z</updated>
    <published>2020-08-08T14:40:43Z</published>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="code"/>
    <category term="complier"/>
    <category term="optimization"/>
    <category term="register"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-08T20:20:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/07/report-from-cccg</id>
    <link href="https://11011110.github.io/blog/2020/08/07/report-from-cccg.html" rel="alternate" type="text/html"/>
    <title>Report from CCCG</title>
    <summary>I spent the last few days participating in the Canadian Conference in Computational Geometry, originally planned for Saskatoon but organized virtually instead.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I spent the last few days participating in the <a href="http://vga.usask.ca/cccg2020/">Canadian Conference in Computational Geometry</a>, originally planned for Saskatoon but organized virtually instead.</p>

<p>The way the conference was organized was that (after the usual submission reviewing process) the accepted authors provided both a proceedings paper and a 10-15 minute talk video to the conference organizers. Participants were required to register, but with no registration fee, and were provided with links to the papers and talks (which are all still live on the conference program). Then, during the conference itself, live online Zoom sessions ran for only 2-3 hours daily, scheduled for 10AM-1PM Saskatoon time: very convenient for anywhere in North America or Europe, not so much for the participants in Iran, India, China, Japan, and Korea (all of which did have participants). The sessions included a daily 1-hour live invited talk, and question-and-answer sessions for the contributed works, in which we were shown a one-minute teaser for each video and then invited to ask questions of authors, at least one of whom was required to be present.</p>

<p>I think it all worked very well; so well, in fact, that during the business meeting there were calls for having at least some of the content similarly online so that people could participate remotely again. The ability to ask and answer questions either by live video on Zoom or through Zoom chat was useful, and used. Attendance was far above previous levels: 162 registrants, and over 120 unique participants at the most heavily attended of the two daily parallel sessions, compared to roughly 60 attendees each at the last two physical conferences. Despite the free registration, the conference organization was not without cost: they spent roughly $1500 (Canadian) in video production costs and video conferencing fees, but this was more than made up for by institutional support for the conference, so they ended up running a surplus which may (if it can be kept) end up providing some float for future conference organizers.</p>

<p>There are two changes I would suggest for future events of this type:</p>

<ul>
  <li>
    <p>The contributed sessions were for a short enough time that holding them in parallel seemed unnecessary, and made it impossible to participate in all discussions. So this format may work better with less parallelism.</p>
  </li>
  <li>
    <p>The one-minute teaser videos were cut together by the conference organizers from the longer videos provided by the authors, but in some cases the pacing of the longer videos from which they were cut meant that these teaser videos could not clearly state the results of their papers. I think it would have been better to ask authors to provide these alongside the longer talk videos.</p>
  </li>
</ul>

<p>Some of the highlights of the event:</p>

<ul>
  <li>
    <p>Wednesday’s invited talk by Erik Demaine was a moving tribute to Godfried Toussaint and a survey of some of both Toussaint’s research, and Erik’s research on problems started by Toussaint, including <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Nagy_theorem">convexifying polygons by flips</a>, sona curves (<a href="https://arxiv.org/abs/2007.15784">the subject of one of my own contributions</a>), the <a href="https://en.wikipedia.org/wiki/The_Geometry_of_Musical_Rhythm">geometry of musical rhythms</a>, and perhaps most importantly “supercollaboration”, the model of shared research and shared authorship developed by Toussaint at the Barbados research workshops and also used by Erik within many of his MIT classes. <a href="https://www.youtube.com/watch?v=exzxGODi2YU">Erik’s talk was recorded and is now on YouTube</a>; I hope the same will be true of the other two invited talks.</p>
  </li>
  <li>
    <p>In Wednesday’s contributed session on unfolding (in which I had two papers) I particularly liked Satyan Devadoss’s talk, “Nets of higher-dimensional cubes”. The main result is that if you unfold a hypercube, then no path of facets of the unfolded shape can contain a u-turn: if the path takes a step in one any coordinate direction, it cannot step in the opposite direction. This implies that all dual spanning trees unfold flat without self-intersection. The same property was known for all the Platonic solids, and Satyan can prove it for regular simplices in any dimension, but that still leaves several regular polytopes for which it is still open whether all unfoldings work: the cross-polytopes in all dimensions, and the three exceptional regular polytopes in four dimensions.</p>
  </li>
  <li>
    <p>Thursday’s invited talk was by Jeff Erickson, “Chasing puppies”. It was an entertaining presentation of an elegant topological proof of the following result: if you and a puppy can both move around a simple closed curve in the plane, with the puppy always moving along the curve to a local minimum of distance to you, then you can always find a path to follow that will bring you and the puppy to the same point.</p>
  </li>
  <li>
    <p>There wasn’t an official prize for best contributed presentation, but in the data structures session on Thursday, several comments nominated <a href="https://medium.com/photos-we-love/the-trinity-of-incongruity-or-why-i-still-love-this-tuxedo-sewing-machine-ups-truck-photograph-39712dd32fcb">Don Sheehy</a> as the unofficial winner, for a video artfully mixing live action with computer animations. His paper, “One-hop greedy permutations” concerned heuristics for improving the <a href="https://en.wikipedia.org/wiki/Farthest-first_traversal">farthest-first traversal</a> of a set of points by looking near each point as the sequence is constructed for a better point to use instead.</p>
  </li>
  <li>
    <p>There was an official best student paper award, and it went to <a href="https://www.cs.umd.edu/people/afloresv">Alejandro Flores Velazco</a> for his paper “Social distancing is good for points too!” It concerns the problem of reducing the size of a data set while preserving the quality of nearest-neighbor classification using the reduced set. It proves that FCNN, which it calls the most popular heuristic for this problem, can produce significantly less-reduced outputs than some other proven heuristics, and shows how to modify FCNN to get a heuristic with guaranteed output quality.</p>
  </li>
  <li>
    <p>The third of the invited sessions was by Yusu Wang, newly moved from Ohio State to UC San Diego. She gave a nice introduction to combinatorial methods for reconstructing road networks (or other networks embedded into higher-dimensional geometry) from noisy samples of points on the network by combining discrete Morse theory to find the ridge lines of sample density with persistent homology to clean some of the noise from the data.</p>
  </li>
  <li>
    <p>The final technical component of the conference was an open problem session, also recorded and presumably to be uploaded at some point. Satyan posed his question on regular polytope unfolding there. Mike Paterson asked whether one can construct “Plato’s torus”, an embedded torus with six equilateral-triangle faces meeting at each vertex; <a href="https://11011110.github.io/blog/2009/02/03/flat-equilateral-tori.html">in a blog post I made on this problem in 2009 I traced its history to Nick Halloway in 1997</a> but Mike says he discussed it already with Christopher Zeeman in the 1970s. Another problem that caught my attention asked for an algorithmic version of the polyhedral <a href="https://en.wikipedia.org/wiki/Theorem_of_the_three_geodesics">theorem of the three geodesics</a>, the existence of a path across the surface of a convex polyhedron that stays straight across each edge or face of the polyhedron, and has at most \(\pi\) surface angle on each side of it when it passes through a vertex. Again there’s some history here: Joe O’Rourke says he once mentioned the problem to Gromov, who said it was easy but unfortunately didn’t elaborate.</p>
  </li>
</ul>

<p>CCCG 2021 is planned for Halifax, colocated with WADS. One somewhat controversial issue is that the current plan is to have both conferences overlap for two days, with one overlap-free day for each conference at each end of the overlap period. But if both conferences are double-session, this means that participants can only choose one of four overlapping talks. At this point everyone is still hoping that events allow for a physical conference by then but that remains to be seen.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104651090140382005">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-08-07T17:46:00Z</updated>
    <published>2020-08-07T17:46:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-08T01:30:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.02782</id>
    <link href="http://arxiv.org/abs/2008.02782" rel="alternate" type="text/html"/>
    <title>Singularly Optimal Randomized Leader Election</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a>, William K. Moses Jr., <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pandurangan:Gopal.html">Gopal Pandurangan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peleg:David.html">David Peleg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02782">PDF</a><br/><b>Abstract: </b>This paper concerns designing distributed algorithms that are singularly
optimal, i.e., algorithms that are simultaneously time and message optimal, for
the fundamental leader election problem in networks. Our main result is a
randomized distributed leader election algorithm for asynchronous complete
networks that is essentially (up to a polylogarithmic factor) singularly
optimal. Our algorithm uses $O(n)$ messages with high probability and runs in
$O(\log^2 n)$ time (with high probability) to elect a unique leader. The $O(n)$
message complexity should be contrasted with the $\Omega(n \log n)$ lower
bounds for the deterministic message complexity of leader election algorithms
(regardless of time), proven by Korach, Moran, and Zaks (TCS, 1989) for
asynchronous algorithms and by Afek and Gafni (SIAM J. Comput., 1991) for
synchronous networks. Hence, our result also separates the message complexities
of randomized and deterministic leader election. More importantly, our
(randomized) time complexity of $O(\log^2 n)$ for obtaining the optimal $O(n)$
message complexity is significantly smaller than the long-standing
$\tilde{\Theta}(n)$ time complexity obtained by Afek and Gafni and by Singh
(SIAM J. Comput., 1997) for message optimal (deterministic) election in
asynchronous networks.
</p>
<p>In synchronous complete networks, Afek and Gafni showed an essentially
singularly optimal deterministic algorithm with $O(\log n)$ time and $O(n \log
n)$ messages. Ramanathan et al. (Distrib. Comput. 2007) used randomization to
improve the message complexity, and showed a randomized algorithm with $O(n)$
messages and $O(\log n)$ time (with failure probability $O(1 /
\log^{\Omega(1)}n)$). Our second result is a tightly singularly optimal
randomized algorithm, with $O(1)$ time and $O(n)$ messages, for this setting,
whose time bound holds with certainty and message bound holds with high
probability.
</p></div>
    </summary>
    <updated>2020-08-07T23:22:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.02769</id>
    <link href="http://arxiv.org/abs/2008.02769" rel="alternate" type="text/html"/>
    <title>Fine-Grained Complexity of Regular Expression Pattern Matching and Membership</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schepper:Philipp.html">Philipp Schepper</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02769">PDF</a><br/><b>Abstract: </b>The currently fastest algorithm for regular expression pattern matching and
membership improves the classical O(nm) time algorithm by a factor of about
log^{3/2}n. Instead of focussing on general patterns we analyse homogeneous
patterns of bounded depth in this work. For them a classification splitting the
types in easy (strongly sub-quadratic) and hard (essentially quadratic time
under SETH) is known. We take a very fine-grained look at the hard pattern
types from this classification and show a dichotomy: few types allow
super-poly-logarithmic improvements while the algorithms for the other pattern
types can only be improved by a constant number of log-factors, assuming the
Formula-SAT Hypothesis.
</p></div>
    </summary>
    <updated>2020-08-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.02753</id>
    <link href="http://arxiv.org/abs/2008.02753" rel="alternate" type="text/html"/>
    <title>Competitive Allocation of a Mixed Manna</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaudhury:Bhaskar_Ray.html">Bhaskar Ray Chaudhury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Jugal.html">Jugal Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGlaughlin:Peter.html">Peter McGlaughlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mehta:Ruta.html">Ruta Mehta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02753">PDF</a><br/><b>Abstract: </b>We study the fair division problem of allocating a mixed manna under
additively separable piecewise linear concave (SPLC) utilities. A mixed manna
contains goods that everyone likes and bads that everyone dislikes, as well as
items that some like and others dislike. The seminal work of Bogomolnaia et al.
[Econometrica'17] argue why allocating a mixed manna is genuinely more
complicated than a good or a bad manna, and why competitive equilibrium is the
best mechanism. They also provide the existence of equilibrium and establish
its peculiar properties (e.g., non-convex and disconnected set of equilibria
even under linear utilities), but leave the problem of computing an equilibrium
open. This problem remained unresolved even for only bad manna under linear
utilities.
</p>
<p>Our main result is a simplex-like algorithm based on Lemke's scheme for
computing a competitive allocation of a mixed manna under SPLC utilities, a
strict generalization of linear. Experimental results on randomly generated
instances suggest that our algorithm will be fast in practice. The problem is
known to be PPAD-hard for the case of good manna, and we also show a similar
result for the case of bad manna. Given these PPAD-hardness results, designing
such an algorithm is the only non-brute-force (non-enumerative) option known,
e.g., the classic Lemke-Howson algorithm (1964) for computing a Nash
equilibrium in a 2-player game is still one of the most widely used algorithms
in practice.
</p>
<p>Our algorithm also yields several new structural properties as simple
corollaries. We obtain a (constructive) proof of existence for a far more
general setting, membership of the problem in PPAD, rational-valued solution,
and odd number of solutions property. The last property also settles the
conjecture of Bogomolnaia et al. in the affirmative.
</p></div>
    </summary>
    <updated>2020-08-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.02523</id>
    <link href="http://arxiv.org/abs/2008.02523" rel="alternate" type="text/html"/>
    <title>Some `converses' to intrinsic linking theorems</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karasev:R=.html">R. Karasev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skopenkov:A=.html">A. Skopenkov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02523">PDF</a><br/><b>Abstract: </b>A low-dimensional version of our main result is the following `converse' of
the Conway-Gordon-Sachs Theorem on intrinsic linking of the graph $K_6$ in
3-space:
</p>
<p>For any integer $z$ there are 6 points $1,2,3,4,5,6$ in 3-space, of which
every two $i,j$ are joint by a polygonal line $ij$, the interior of one
polygonal line is disjoint with any other polygonal line, the linking
coefficient of any pair disjoint 3-cycles except for $\{123,456\}$ is zero, and
for the exceptional pair $\{123,456\}$ is $2z+1$.
</p>
<p>We prove a higher-dimensional analogue, which is a `converse' of a lemma by
Segal-Spie\.z.
</p></div>
    </summary>
    <updated>2020-08-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.02398</id>
    <link href="http://arxiv.org/abs/2008.02398" rel="alternate" type="text/html"/>
    <title>An Evolver program for weighted Steiner trees</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Botelho:Henrique.html">Henrique Botelho</a>, Francisco Zampirolli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Batista:Val=eacute=rio_Ramos.html">Valério Ramos Batista</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02398">PDF</a><br/><b>Abstract: </b>We present an algorithm to find near-optimal weighted Steiner minimal trees
in the plane. The algorithm is implemented in Evolver programming language,
which already contains many built-in energy minimisation routines. Some are
invoked in the program, which enable it to consist of only 183 lines of source
code. Our algorithm reproduces the physical experiment of a soap film detaching
from connected pins towards a stable configuration. In the non-weighted case
comparisons with GeoSteiner are drawn for terminals that form a pattern.
</p></div>
    </summary>
    <updated>2020-08-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.04232</id>
    <link href="http://arxiv.org/abs/2002.04232" rel="alternate" type="text/html"/>
    <title>Learning and Sampling of Atomic Interventions from Observations</title>
    <feedworld_mtime>1596758400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharyya:Arnab.html">Arnab Bhattacharyya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gayen:Sutanu.html">Sutanu Gayen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kandasamy:Saravanan.html">Saravanan Kandasamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maran:Ashwin.html">Ashwin Maran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinodchandran:N=_V=.html">N. V. Vinodchandran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.04232">PDF</a><br/><b>Abstract: </b>We study the problem of efficiently estimating the effect of an intervention
on a single variable (atomic interventions) using observational samples in a
causal Bayesian network. Our goal is to give algorithms that are efficient in
both time and sample complexity in a non-parametric setting.
</p>
<p>Tian and Pearl (AAAI `02) have exactly characterized the class of causal
graphs for which causal effects of atomic interventions can be identified from
observational data. We make their result quantitative. Suppose P is a causal
model on a set $\vec{V}$ of n observable variables with respect to a given
causal graph G with observable distribution $P$. Let $P_x$ denote the
interventional distribution over the observables with respect to an
intervention of a designated variable X with x. Assuming that $G$ has bounded
in-degree, bounded c-components ($k$), and that the observational distribution
is identifiable and satisfies certain strong positivity condition, we give an
algorithm that takes $m=\tilde{O}(n\epsilon^{-2})$ samples from $P$ and $O(mn)$
time, and outputs with high probability a description of a distribution
$\hat{P}$ such that $d_{\mathrm{TV}}(P_x, \hat{P}) \leq \epsilon$, and:
</p>
<p>1. [Evaluation] the description can return in $O(n)$ time the probability
$\hat{P}(\vec{v})$ for any assignment $\vec{v}$ to $\vec{V}$
</p>
<p>2. [Generation] the description can return an iid sample from $\hat{P}$ in
$O(n)$ time.
</p>
<p>We also show lower bounds for the sample complexity showing that our sample
complexity has an optimal dependence on the parameters $n$ and $\epsilon$, as
well as if $k=1$ on the strong positivity parameter.
</p></div>
    </summary>
    <updated>2020-08-07T23:21:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4290135672537490640</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4290135672537490640/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/do-senators-have-advantage-for-being.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4290135672537490640" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4290135672537490640" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/08/do-senators-have-advantage-for-being.html" rel="alternate" type="text/html"/>
    <title>Do Senators have an Advantage for being Dem VP Nominee?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a non-partisan post. Even so:  I plan to vote for Joe Biden.<div><br/></div><div>(Lance says that whenever I write `this is a non-partisan post'  its partisan anyway.)</div><div><br/></div><div>I've had posts on predicting VPs before:</div><div><br/></div><div>In <a href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html">this post</a> I looked at a Nate Silver column a few months ago where they were trying to predict the democratic VP nomination <i>before the Prez nominee was know</i>n. Some of what they said seems relevant.</div><div><br/></div><div>In <a href="https://blog.computationalcomplexity.org/2008/09/i-would-be-on-intrade-that-intrade-will.html">this post</a> I PREDICTED that bets on INTRADE would not do well on picking VPs since VP picks are hard to predict and often are not from anyone's short list. I DID NOT PREDICT that INTRADE would go out of business.</div><div><br/></div><div>I came across a statistic recently that seems relevant and inspired this post. Actually this post asks IS this statistic relevant?</div><div><br/></div><div>From Prez candidate  Harry Truman to Prez candidate Hillary Clinton there have been 15 Dem VP nominees (not  counting incumbents) of which 13 have been Senators:</div><div><br/></div><div>Harry Truman(Prez)-Alben Barkely. Sen from Kentucky</div><div>Adelaide Stevenson(Gov-Illinois) -John Sparkman. Sen from Alabama</div><div>Adelaide Stevenson(Gov-Illinois)-Estes Kefauver, Sen from Tennessee </div><div>John F Kennedy(Sen-Mass)-Lyndon B Johnson, Sen from Texas</div><div>Lyndon B Johnson(Prez)-Hubert Humphrey,Sen from Minnesoda</div><div>Hubert Humphrey(VP)-Ed Muskie, Sen from Maine</div><div>George McGovern Sen-South Dakota)-Sgt Shriver Amb to France, Office of Econ Activity</div><div>Jimmy Carter(Gov Georgia)-Walter Mondale- Senator from Minnesota</div><div>Walter Mondale(Senator Minnesota)-Geraldine Ferraro Congressperson- NY</div><div>Mike Dukakis (Gov Mass), Lloyd Benson-Sen Texas</div><div>Bill Clinton(Gov Arkansas), Al Gore Sen from Tennesee</div><div>Al Gore (VP), Joe Lieberman Senator from Conn</div><div>John Kerry (Sen-Mass), John Edwards Sen from NC</div><div>Barack Obama (Sen-Illinois), Joe Biden Sen from Del</div><div>Hillary Clinton (Sen-NY), Tom Kaine- Sen Virginia</div><div><br/></div><div>Of the 15 Dem VP nominees, 13 are Senators</div><div><br/></div><div>Of the 13 Rep VP nominees, 4 are Senators  <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/rebvp.txt">see here</a></div><div><br/></div><div>My Speculations: </div><div><br/></div><div>1)  When a gov runs he wants someone with fed experience. That explains 5 of the cases above.</div><div><br/></div><div>2) Senators tend to be better known than other politicians, so perhaps being well known is what you need. Note on the Republican Side Paul Ryan was a House member but was well known.</div><div><br/></div><div>3) Why do the Reps and Dems differ on this? Is the sample size too small to make this question interesting? </div><div><br/></div><div>So here is the question: When trying to predict who the Dem VP will be (this year or any year) should being a Senator give someone a plus? A higher weight in a Neural Net? </div><div><br/></div><div>Kamela Harris is the favorite on the betting markets.  Is this because she is a Senator?</div><div><br/></div><div>She has a national profile and has already been vetted since she rana serious campaign  for Prez in the primaries. So I would say that THATS the reason (and other reasons), not that she is a Senator. But would she have been able to run a serious campaign  in the primaries if she wasn't already a Senator? I ask non rhetorically.</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-08-06T18:59:00Z</updated>
    <published>2020-08-06T18:59:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-08T16:35:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1380</id>
    <link href="https://ptreview.sublinear.info/?p=1380" rel="alternate" type="text/html"/>
    <title>Videos from the WoLA 2020 workshop</title>
    <summary>The 4th Workshop on Local Algorithms (WoLA 2020) recently concluded: aimed at “fostering dialogue and cross-pollination of ideas between the various communities” related to local algorithms, broadly construed, it featured invited and contributed talks on a variety of topics, many (if not most) very relevant to the sublinear algorithms and property testing community. Because of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 4th <a href="https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html">Workshop on Local Algorithms (WoLA 2020)</a> recently concluded: aimed at <em>“fostering dialogue and cross-pollination of ideas between the various communities</em>” related to local algorithms, broadly construed, it featured invited and contributed talks on a variety of topics, many (if not most) very relevant to the sublinear algorithms and property testing community.</p>



<p>Because of the online format of the workshop (imposed by the current circumstances), all talks were recorded and posted online. As such, all videos all available on the workshop’s <a href="https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html">website</a> and <a href="https://www.youtube.com/channel/UCMBSZ3q2FKJntpcK72h9eeA/videos">YouTube channel</a>: a good list of resources to peruse!</p></div>
    </content>
    <updated>2020-08-06T00:33:58Z</updated>
    <published>2020-08-06T00:33:58Z</published>
    <category term="Conference reports"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-08-07T23:38:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5510</id>
    <link href="https://adamsheffer.wordpress.com/2020/08/05/mind-benders-for-the-quarantined/" rel="alternate" type="text/html"/>
    <title>Mind-Benders for the Quarantined</title>
    <summary>Peter Winkler is a world expert on mathematical puzzles (he is also an excellent researcher and this year’s resident mathematician of the MoMath). I just learned about two things that he is currently up to. Winkler is running Mind-Benders for the Quarantined. After signing up to this free service, you receive a mathematical puzzle every […]</summary>
    <updated>2020-08-05T22:51:31Z</updated>
    <published>2020-08-05T22:51:31Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-08-08T20:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1091</id>
    <link href="http://corner.mimuw.edu.pl/?p=1091" rel="alternate" type="text/html"/>
    <title>Faster PageRank on MPC</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Years ago when I learned about Google PageRank algorithm, my first reaction was this is not the way it should be done! There should be some proof. This probably just shows that my CS education was too theoretical ;). Years … <a href="http://corner.mimuw.edu.pl/?p=1091">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Years ago when I learned about Google PageRank algorithm, my first reaction was this is not the way it should be done! There should be some proof. This probably just shows that my CS education was too theoretical ;). Years later I have learned that indeed there are some nice tools to argue about the running time of PageRank algorithm. And very recently we were able to give some new parallel (in MPC model) algorithms for computing vanilla PageRank. We improved the number of rounds needed from O(log n) to O(log^2 log n) time. You can hear Solbodan talking out it here:  <a href="https://www.youtube.com/watch?v=xoodhmjJ9Xs">https://www.youtube.com/watch?v=xoodhmjJ9Xs</a> .<br/> </p></div>
    </content>
    <updated>2020-08-05T18:55:13Z</updated>
    <published>2020-08-05T18:55:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2020-08-07T23:36:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/open-problem-all-pairs/</id>
    <link href="https://differentialprivacy.org/open-problem-all-pairs/" rel="alternate" type="text/html"/>
    <title>Open Problem: Private All-Pairs Distances</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Background:</strong> Suppose we are interested in computing the distance between two vertices in a graph. Under edge or node differential privacy, this problem is not promising because the removal of a single edge can make distances change from 1 to \(n − 1\) or can even disconnect the graph. However, a different setting that makes sense to consider is that of a weighted graph \((G, w)\) whose topology \(G = (V, E)\) is publicly known but edge weight function \(w : E \to \mathbb{R}^+\) must be kept private. (For instance, consider transit times on a road network. The topology of the road network may be publicly available as a map, but the edge weights corresponding to transit times may be based on private GPS locations of individual cars.)</p>

<p>Suppose that two weight functions \(w\) and \(w’\) of the same graph \(G\) are considered to be neighbors if they differ by at most 1 in \(\ell^1\) norm. Then the length of any fixed path is sensitivity-one, so the distance between any pair of vertices is also sensitivity-one and can be released privately via the Laplace mechanism. But what if we want to release all \(\Theta(n^2)\) distances between all pairs of vertices in \(G\)? We can do this with accuracy roughly \(O(n \log n )/\varepsilon\) by adding noise to each edge, or roughly \(O(n \sqrt{\log(1/\delta)}/\varepsilon)\) using composition theorems. Both of these are roughly \(n/\varepsilon\). But is this linear dependence on \(n\) inherent, or is it possible to release all-pairs distances with error sublinear in \(n\)?</p>

<p>This setting and question were considered in [<a href="https://arxiv.org/abs/1511.04631">S16</a>].</p>

<p><strong>Problem 1:</strong> Let \(G\) be an arbitrary public graph, and \(w : E \to \mathbb{R}^+\) be an edge weight function. Can we release approximate all-pairs distances in \((G, w)\) with accuracy sublinear in \(n\) while preserving the privacy of the edge weight function, where two weight functions \(w, w’\) are neighbors if \(\|w − w’\|_1 \le 1\)? Or can we show that any private algorithm must have error \(\Omega(n)\)? A weaker (but nontrivial) lower bound would also be nice.</p>

<p><strong>Reward:</strong> A bar of chocolate.</p>

<p><strong>Other related work:</strong> [<a href="https://arxiv.org/abs/1511.04631">S16</a>] provided algorithms with better error for two special cases, trees and graphs of a priori bounded weight. For trees, it is possible to release all-pairs distances with error roughly \(O(\log^{1.5} n)/\varepsilon\), while for arbitrary graphs with edge weights restricted to the interval \([0,M]\), it is possible to release all-pairs distances with error roughly \(O( \sqrt{nM\varepsilon^{-1}\log(1/\delta)})\)</p>

<p><em>Submitted by <a href="http://www.mit.edu/~asealfon/">Adam Sealfon</a> on April 9, 2019.</em></p></div>
    </summary>
    <updated>2020-08-05T18:00:00Z</updated>
    <published>2020-08-05T18:00:00Z</published>
    <author>
      <name>Audra McMillan</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-08-07T23:38:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=755</id>
    <link href="https://emanueleviola.wordpress.com/2020/08/05/previous-vs-concurrent-independent-work/" rel="alternate" type="text/html"/>
    <title>Previous vs. concurrent/independent work</title>
    <summary>Should Paper X cite Paper Y as previous or concurrent/independent work? This is sometimes tricky: maybe Paper Y circulated privately before Paper X, maybe the authors of Paper X knew about Paper Y maybe not — nobody can know for sure. One can say that the authors of Paper Y should have posted Paper Y […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Should Paper X cite Paper Y as previous or concurrent/independent work?  This is sometimes tricky: maybe Paper Y circulated privately before Paper X, maybe the authors of Paper X knew about Paper Y maybe not — nobody can know for sure.  One can say that the authors of Paper Y should have posted Paper Y online earlier to prevent this issue, but <a href="https://emanueleviola.wordpress.com/2014/07/02/only-papers-on-the-arxiv-can-be-submitted-for-publication/">that is not standard practice </a>and might lead to other problems, <a href="https://emanueleviola.wordpress.com/2016/08/10/paper-x-on-the-arxiv-keeps-getting-rejected/">including Paper Y never getting published!</a></p>



<p>I propose the following guiding principle:</p>



<p>“If a different accept/reject outcome would have forced paper X to cite paper Y as previous work, then paper X should cite paper Y as previous work.”<br/></p>



<p>The reasons behind my principle seem to me especially valid in the fast-moving theoretical computer science community, where papers are typically sent to conferences and thus seen by the entire program committee plus around 3 external referees, who are typically experts — only to be rejected.  Moreover, the progress is extremely fast, with the next conference cycle making obsolete a number of papers in just the previous cycle.</p></div>
    </content>
    <updated>2020-08-05T14:50:33Z</updated>
    <published>2020-08-05T14:50:33Z</published>
    <category term="Uncategorized"/>
    <category term="utopia-tcs"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-08-08T20:21:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/118</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/118" rel="alternate" type="text/html"/>
    <title>TR20-118 |  On Testing Asymmetry in the Bounded Degree Graph Model | 

	Oded Goldreich</title>
    <summary>We consider the problem of testing asymmetry in the bounded-degree graph model, where a graph is called asymmetric if the identity permutation is its only automorphism. Seeking to determine the query complexity of this testing problem, we provide partial results. Considering the special case of $n$-vertex graphs with connected components of size at most $s(n)=\Omega(\log n)$, we show that the query complexity of $\epsilon$-testing asymmetry (in this case) is at most $O({\sqrt n}\cdot s(n)/\epsilon)$, whereas the query complexity of $o(1/s(n))$-testing asymmetry (in this case) is at least $\Omega({\sqrt{n/s(n)}})$.

In addition, we show that testing asymmetry in the dense graph model is almost trivial.</summary>
    <updated>2020-08-04T21:41:44Z</updated>
    <published>2020-08-04T21:41:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2561</id>
    <link href="https://francisbach.com/integration-by-parts-abel-transformation/" rel="alternate" type="text/html"/>
    <title>The many faces of integration by parts – I : Abel transformation</title>
    <summary>Integration by parts is a highlight of any calculus class. It leads to multiple classical applications for integration of logarithms, exponentials, etc., and it is the source of an infinite number of exercises and applications to special functions. In this post, I will look at a classical discrete extension that is useful in machine learning...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Integration by parts is a highlight of any calculus class. It leads to multiple classical applications for integration of logarithms, exponentials, etc., and it is the source of an infinite number of exercises and applications to <a href="https://en.wikipedia.org/wiki/Special_functions">special functions</a>. In this post, I will look at a classical discrete extension that is useful in machine learning and optimization, namely <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a>, with applications to convergence proofs for the (stochastic) <a href="https://en.wikipedia.org/wiki/Subgradient_method">subgradient method</a>. Next month, extensions to higher dimensions will be considered, with applications to score functions [<a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">2</a>, <a href="https://www.jstor.org/stable/1914309">3</a>] and randomized smoothing [4, <a href="https://arxiv.org/pdf/2002.08676">5</a>].</p>



<h2>Abel transformation: from continuous to discrete</h2>



<p class="justify-text">The most classical version of integration by parts goes as follows. Given two continuously differentiable functions from \(\mathbb{R}\) to \(\mathbb{R}\), we have: $$ \int_a^b \!\!\!\!f(x)g'(x) dx = \Big[ f(x) g(x) \Big]_a^b \!-\! \int_a^b\!\!\! \!f'(x) g(x) dx =  f(b) g(b)\, – f(a)g(a)-\! \int_a^b\! \!\!\! f'(x) g(x) dx.$$ This is valid for less regular functions, but this is not the main concern here. The proof follows naturally from the derivative of a product, but there is a nice “proof without words” (see, e.g., [1, p. 42] or <a href="https://en.wikipedia.org/wiki/Integration_by_parts#Visualization">here</a>).</p>



<p class="justify-text">There is a discrete analogue referred to as <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a> or summation by parts, where derivatives are replaced by increments: given two real-valued sequences \((a_n)_{n \geq 0}\) and \((b_n)_{n \geq 0}\) (the second sequence could also be taken vector-valued), we can expand $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) =\sum_{k=1}^n a_k  b_k \ – \sum_{k=1}^n a_k  b_{k-1} = \sum_{k=1}^n a_k b_k \ – \sum_{k=0}^{n-1} a_{k+1} b_{k},$$ using a simple index increment in the second sum.  Rearranging terms, this leads to $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) = a_n b_n \ – a_0 b_0\  – \sum_{k=0}^{n-1} ( a_{k+1} – a_{k } ) b_k.$$ In other words, we can transfer the first-order difference from the sequence \((b_k)_{k \geq 0}\) to the sequence \((a_k)_{k \geq 0}\).  A few remarks:</p>



<ul class="justify-text"><li><strong>Warning</strong>! It is very easy/common to make mistakes with indices and signs.</li><li>I gave the direct proof but a proof through explicit integration by part is also possible, by introducing the piecewise-constant function \(f\) equal to \(a_k\) on \([k,k+1)\), and \(g\) continuous  piecewise affine equal to \(b_{k} + (t-k) ( b_{k+1}-b_{k})\) for \(t \in [k,k+1]\), and integrating between \(0+\) and \(n+\). </li></ul>



<p class="justify-text">There are classical applications for the convergence of series (see <a href="https://en.wikipedia.org/wiki/Summation_by_parts">here</a>), but in this post, I will show how it can lead to an elegant result for stochastic gradient descent for non-smooth functions and <em>decaying</em> step-sizes.</p>



<h2>Decaying step-sizes in stochastic gradient descent</h2>



<p class="justify-text">The Abel summation formula is quite useful when analyzing optimization algorithms, and we give a simple example below. We consider a sequence of random potentially <em>non-smooth</em> convex functions \((f_k)_{k \geq 0}\) which are independent and identically distributed functions from \(\mathbb{R}^d \) to \(\mathbb{R}\), with expectation \(F\). The goal is to find a minimizer \(x_\ast\) of \(F\) over a some convex bounded set \(\mathcal{C}\), only being given access to some stochastic gradients of \(f_k\) at well-chosen points. The most classical example is supervised machine learning, where \(f_k(\theta)\) is the loss of a random observation for the predictor parameterized by \(\theta\).  The difficulty here is the potential non-smoothness of the function \(f_k\) (e.g., for the <a href="https://en.wikipedia.org/wiki/Hinge_loss">hinge loss</a> and the <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine</a>).</p>



<p class="justify-text">We consider the projected stochastic subgradient descent method. The deterministic version of this method dates back to Naum Shor [6] in 1962 (see nice history <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/43_goffin-jean-louis.pdf">here</a>). The method goes as follows: starting from some \(\theta_0 \in \mathbb{R}^d\), we perform the iteration $$ \theta_{k} = \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) \big),$$ where \(\Pi_{ \mathcal{C}}: \mathbb{R}^d \to \mathbb{R}^d\) is the orthogonal projection onto the set \(\mathcal{C}\), and \(\nabla f_k(\theta_{k-1})\) is any subgradient of \(f_k\) at \(\theta_{k-1}\). </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4324" height="211" src="https://francisbach.com/wp-content/uploads/2020/07/gradient_contours_projection-1024x410.png" width="528"/>One step of projected (sub)gradient descent: from a vector \(\theta\), we go down the direction of a negative subgradient \(\nabla f(\theta)\) of the function \(f\) (here typically a random function) and an orthogonal projection is performed to obtain the new vector \(\theta_+\).</figure></div>



<p class="justify-text">We make the following standard assumptions: (a) the set \(\mathcal{C}\) is convex and compact with diameter \(\Delta\) (with respect to the \(\ell_2\)-norm), (b) the functions \(f_k\) are almost surely convex and \(B\)-Lipschitz-continuous (or equivalently with gradients bounded in \(\ell_2\)-norm by \(B\)). We denote by \(\theta_\ast\) a minimizer of \(f\) on \(\mathcal{C}\) (there can be multiple ones). </p>



<p class="justify-text">For non-smooth problems, choosing a constant step-size does not lead to an algorithm converging to a global minimizer: decaying step-sizes are then needed.</p>



<h2>Convergence proof through Lyapunov functions</h2>



<p class="justify-text">Since the functions \(f_k\) are non-smooth, we cannot use Taylor expansions, and we rely on a now classical proof technique dating back from the 1960’s (see, e.g., a <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">paper</a> by Boris Polyak [7] in Russian), that has led to several extensions in particular for online learning [<a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">8</a>]. The proof relies on the concept of “<a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov functions</a>“, often also referred to as “potential functions”. This is a non-negative function \(V(\theta_k)\) of the iterates \(\theta_k\), that is supposed to go down along iterations (at least in expectation). In optimization, standard Lyapunov functions are \(V(\theta)  = F(\theta)\, – F(\theta_\ast)\) or \(V(\theta) = \| \theta \ – \theta_\ast\|_2^2\). </p>



<p class="justify-text">For the subgradient method, we will not be able to show that the Lyapunov function is decreasing, but this will lead through a manipulation which is standard in linear dynamical system analysis to a convergence proof for the averaged iterate: that is, if \(V(\theta_k) \leqslant V(\theta_{k-1})\ – W(\theta_{k-1}) + \varepsilon_k\),  for a certain function \(W\) and extra positive terms \(\varepsilon_k\), then, using telescoping sums, $$ \frac{1}{n} \sum_{k=1}^n W(\theta_{k-1}) \leqslant \frac{1}{n} \big( V(\theta_0)\ – V(\theta_n) \big) + \frac{1}{n} \sum_{k=1}^n \varepsilon_k.$$ We can then either use <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a> to get a bound on \(W \big( \frac{1}{n} \sum_{k=1}^n \theta_{k-1} \big)\), or directly get a bound on \(\min_{k \in \{1,\dots,n\}} W(\theta_{k-1})\). The first solution gives a performance guarantee for a well-defined iterate, while the second solution only shows that among the first \(n-1\) iterates, one of them has a performance guarantee; in the stochastic set-up where latex \(W\) is an expectation, it is not easily possible to know which one, so we will consider only averaging below.</p>



<p class="justify-text"><strong>Standard inequality. </strong>We have, by contractivity of orthogonal projections: $$ \|\theta_k \ – \theta_\ast\|_2^2 =  \big\|  \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k   \nabla f_k(\theta_{k-1}) \big) – \Pi_{ \mathcal{C} } (\theta_\ast)  \big\|_2^2 \leqslant  \big\|   \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) -\   \theta_\ast  \big\|_2^2.$$ We can then expand the squared Euclidean norm to get: $$ \|\theta_k – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1} – \theta_\ast\|_2^2 \ – 2\gamma_k (\theta_{k-1} – \theta_\ast)^\top \nabla f_k (\theta_{k-1}) + \gamma_k^2 \|  \nabla f_k(\theta_{k-1})\|_2^2.$$ The last term is upper-bounded by \(\gamma_k^2 B^2\) because of the regularity assumption on \(f_k\). For the middle term, we use the convexity of \(f_k\), that is,  the function \(f_k\) is greater than its tangent at \(\theta_{k-1}\). See figure below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4331" height="220" src="https://francisbach.com/wp-content/uploads/2020/07/tangent_convex-1-1024x440.png" width="513"/>Convex function above its tangent at \(\theta_{k-1}\), leading to the desired inequality.</figure></div>



<p class="justify-text">We then obtain $$ f_k(\theta_\ast) \geqslant f_k(\theta_{k-1}) + \nabla f_k(\theta_{k-1})^\top ( \theta_{\ast} – \theta_{k-1}).$$</p>



<p class="justify-text">Putting everything together, this leads to $$ \|\theta_k \ – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1}\  – \theta_\ast\|_2^2 \ – 2\gamma_k  \big[ f_k(\theta_{k-1}) \ – f_k(\theta_\ast) \big] + \gamma_k^2 B^2.$$ At this point, except the last term, all terms are random. We can now take expectations, with a particular focus on the term \(\mathbb{E} \big[ f_k(\theta_{k-1}) \big]\), for which we can use the fact that the random function \(f_k\) is independent from the past, so that $$ \mathbb{E} \big[ f_k(\theta_{k-1}) \big] =  \mathbb{E} \Big[  \mathbb{E} \big[ f_k(\theta_{k-1}) \big| f_{1},\dots,f_{k-1}  \big] \Big] =\mathbb{E} \big[   F(\theta_{k-1})   \big] . $$ We thus get $$ \mathbb{E} \big[ \|\theta_k – \theta_\ast\|_2^2\big] \leqslant  \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big]  – 2\gamma_k \big( \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \big) + \gamma_k^2 B^2.$$ As above, we can now isolate the excess in function values as: $$ \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant \frac{1}{2 \gamma_k} \Big( \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma_k}{2} B^2.$$ At this point, the “optimization part” of the proof is done. Only algebraic manipulations are needed to obtain a convergence rate. This is where Abel transformation will come in.</p>



<h2>From fixed horizon to anytime algorithms</h2>



<p class="justify-text"><strong>The lazy way.</strong> At this point, many authors (including me sometimes) will take a constant step-size \(\gamma_k = \gamma\) so as to obtain a telescopic sum, leading to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{2n\gamma}     \Big( \mathbb{E} \big[ \|\theta_{0} \ – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{n}\  – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma}{2} B^2,$$ which is less than \(\displaystyle \frac{\Delta^2}{2n \gamma} + \frac{\gamma}{2} B^2\), and minimized for \(\displaystyle \gamma = \frac{ \Delta}{B \sqrt{n}}\), leading to a convergence rate less than \(\displaystyle \frac{ B \Delta}{\sqrt{n}}\). Using Jensen’s inequality, we then get for \(\bar{\theta}_n = \frac{1}{n} \sum_{k=1}^n \theta_{k-1}\): $$\mathbb{E} \big[ F(\bar{\theta}_{n}) \big] – F(\theta_\ast) \leqslant \frac{ B \Delta}{\sqrt{n}} .$$ This result leads to the desired rate but can be improved in at least one way: the step-size currently has to depend on the “horizon” \(n\) (which has to be known in advance), and the algorithm is not “anytime”, which is not desirable in practice (where one often launches an algorithm and stops it when it the performance gains have plateaued or when the user gets bored waiting).</p>



<p class="justify-text"><strong>Non-uniform averaging.</strong> Another way [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>] is to consider the non-uniform average $$ \eta_{k} =   \frac{\sum_{k=1}^n \gamma_{k} \theta_{k-1}}{\sum_{k=1}^n \gamma_{k}}, $$ for which telescoping sums apply as before, to get $$ \mathbb{E} \big[ F(\eta_k) \big] – F(\theta_\ast) \leqslant \frac{1}{2} \frac{\Delta^2 + B^2 \sum_{k=1}^n \gamma_k^2}{\sum_{k=1}^n \gamma_{k}}.$$  Then, by selecting a decaying step-size \(\displaystyle \gamma_k = \frac{ \Delta}{B \sqrt{k}}\), that depends on the iteration number, we get a rate proportional to \(\displaystyle \frac{ B \Delta}{\sqrt{n}} ( 1 + \log n)\). We now have an anytime algorithm, but we have lost a logarithmic term, which is not the end of the world, but still disappointing. In [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>], “tail-averaging” (only averaging iterates between a constant times \(n\) and \(n\)) is proposed, that removes the logarithmic term but requires to store iterates (moreover, the non-uniform averaging puts too much weight on the first iterates, slowing down convergence).</p>



<p class="justify-text"><strong>Using Abel transformation.</strong> If we start to sum inequalities from \(k=1\) to \(k=n\), we get, with \(\delta_k = \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big]\) (which is always between \(0\) and \(\Delta^2\)): $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant  \frac{1}{n} \sum_{k=1}^n \bigg( \frac{1}{2 \gamma_k} \Big( \delta_{k-1} –  \delta_k \Big)\bigg) +  \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ which can be transformed through Abel transformation into $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1}  {\delta_k} \bigg(\frac{1}{ 2\gamma_{k+1}}- \frac{1}{ 2\gamma_{k}} \bigg) + \frac{\delta_0}{2 \gamma_1}- \frac{\delta_t}{2 \gamma_t}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For decreasing step-size sequences, this leads to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1} {\Delta^2} \bigg(\frac{1}{ 2\gamma_{k+1}}- \frac{1}{ 2\gamma_{k}} \bigg) + \frac{\Delta^2}{2 \gamma_1}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ and thus $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{\Delta^2 }{2 n \gamma_n} + \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For \(\gamma_k = \frac{  \Delta}{B \sqrt{k}}\), this leads to an upper bound $$\frac{\Delta B }{2 \sqrt{n}} \big( 1+ \frac{1}{\sqrt{n}} \sum_{k=1}^n \frac{1}{\sqrt{k}}\big) \leqslant \frac{3 \Delta B }{2 \sqrt{n}},$$ which is up to a factor \(\frac{3}{2}\) exactly the same bound as with a constant step-size, but now with an anytime algorithm.</p>



<h2>Experiments</h2>



<p class="justify-text">To illustrate the behaviors above, let’s consider minimizing \(\mathbb{E}_x \| x – \theta \|_1\), with respect to \(\theta\), with \(f_k(\theta) = \| x_k- \theta\|_1\), where \(x_k\) is sampled independently from a given distribution (here independent log-normal distributions for each coordinate). The global optimum \(\theta_\ast\) is the per-coordinate median of the distribution of \(x\)’s.</p>



<p class="justify-text">When applying SGD, the chosen subgradient of \(f_k\) has components in \(\{-1,1\}\). Hence in the plots below in two dimensions, the iterates are always on a grid. With a constant step-size: if the \(\gamma\) is too large (right), there are large oscillations, while if \(\gamma\) is too small (left), optimization is too slow. Note that while the SGD iterate with a constant step-size is always oscillating, the averaged iterate converges to some point (which is not the global optimum, and is typically at distance \(O(\gamma)\) away from it [<a href="https://arxiv.org/pdf/1707.06386">11</a>]).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4339" height="230" src="https://francisbach.com/wp-content/uploads/2020/07/sgd-1.gif" width="545"/>Stochastic gradient descent (averaged or not), with constant step-size. Left: small step-size. Right: large step-size (8 times larger).</figure></div>



<p class="justify-text">With a decaying step-size (figure below), the initial conditions are forgotten reasonably fast and the iterates converge to the global optimum (and of course, we get an anytime algorithm!).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-4340" height="295" src="https://francisbach.com/wp-content/uploads/2020/07/sgd_decaying.gif" width="310"/>Stochastic gradient descent (averaged or not), with decreasing step-size.</figure></div>



<p>We can now compare in terms of function values, showing that a constant step-size only works well for a specific range of iteration numbers.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4335" height="276" src="https://francisbach.com/wp-content/uploads/2020/07/convergence_proofs.png" width="371"/>Comparison of expected performance for decaying and constant-step sizes. Several constant step-sizes are tested, with uniform spacings in log-scale (hence the the uniform spacings in performance for large \(n\)).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">Being able to deal with decaying step-sizes and anytime algorithms is arguably not a major improvement, but quite a satisfactory one, at least to me! Discrete integration by parts is the key enabler here.</p>



<p class="justify-text">There is another rewarding aspect which is totally unrelated to integration by parts: when applied to supervised machine learning, we just obtained from elementary principles (convexity) and few calculations a generalization bound <em>on unseen data</em>, which is as good as regular bounds from statistics [<a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">10</a>] that use much more complex tools such as <a href="https://en.wikipedia.org/wiki/Rademacher_complexity">Rademacher complexities</a> (but typically no convexity assumptions): here, statistics considered independently from optimization is not only slower (considering the empirical risk and minimizing it using the plain non-stochastic subgradient method would lead to an \(n\) times slower algorithm) but also more difficult to analyze! </p>



<h2>References</h2>



<p class="justify-text">[1] Roger B. Nelsen, <em>Proofs without Words: Exercises in Visual Thinking</em>, Mathematical Association of America, 1997.<br/>[2] Aapo Hyvärinen, <a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">Estimation of non-normalized statistical models by score matching</a>. <em>Journal of Machine Learning Research</em>, <em>6</em>(Apr), 695-709, 2005.<br/>[3] Thomas M. Stoker, <a href="https://www.jstor.org/stable/1914309">Consistent estimation of scaled coefficients</a>.  <em>Econometrica: Journal of the Econometric Society</em>, 54(6):1461-1481, 1986.<br/>[4] Tamir Hazan, George Papandreou, and Daniel Tarlow. <a href="https://mitpress.mit.edu/books/perturbations-optimization-and-statistics">Perturbation, Optimization, and Statistics</a>. MIT Press, 2016.<br/>[5] Quentin Berthet, Matthieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach, <a href="https://arxiv.org/pdf/2002.08676">Learning with differentiable perturbed optimizers</a>. Technical report arXiv 2002.08676, 2020.<br/>[6] Naum Z. Shor. An application of the method of gradient descent to the solution of the network transportation problem. <em>Notes of Scientific Seminar on Theory and Applications of Cybernetics and Operations Research</em>, <em>Ukrainian Academy of Sciences</em>, Kiev, 9–17, 1962.<br/>[7] Boris T. Polyak, <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">A general method for solving extremal problems</a>. <em>Doklady Akademii Nauk SSSR</em>, 174(1):33–36, 1967.<br/>[8] Martin Zinkevich. <a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">Online convex programming and generalized infinitesimal gradient ascent</a>. <em>Proceedings of the international conference on machine learning )(ICML)</em>, 2003.<br/>[9] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>.</em> <a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br/>[10] Stéphane Boucheron, Olivier Bousquet, Gabor Lugosi. <a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">Theory of classification: A survey of some recent advances</a>. <em>ESAIM: probability and statistics</em>, <em>9</em>, 323-375, 2005.<br/>[11] Aymeric Dieuleveut, Alain Durmus, and Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the gap between constant step size stochastic gradient descent and Markov chains</a>. Annals of Statistics, 48(3):1348-1382, 2020.</p></div>
    </content>
    <updated>2020-08-04T15:55:26Z</updated>
    <published>2020-08-04T15:55:26Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-08-08T20:22:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/117</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/117" rel="alternate" type="text/html"/>
    <title>TR20-117 |  New bounds on the half-duplex communication complexity | 

	Alexander Smal, 

	Yuriy Dementiev, 

	Artur Ignatiev, 

	Vyacheslav Sidelnik, 

	Mikhail Ushakov</title>
    <summary>In this work, we continue the research started in [HIMS18], where the authors suggested to study the half-duplex communication complexity. Unlike the classical model of communication complexity introduced by Yao, in the half-duplex model, Alice and Bob can speak or listen simultaneously, as if they were talking using a walkie-talkie. The motivation for such a communication model comes from the study of the KRW conjecture. Following the open questions formulated in [HIMS18], we prove lower bounds for the disjointness function in all variants of half-duplex models and an upper bound in the half-duplex model with zero, that separates disjointness from the inner product function in this setting. Next, we prove lower and upper bounds on the half-duplex complexity of the Karchmer-Wigderson games for the counting functions and for the recursive majority function, adapting the ideas used in the classical communication complexity. Finally, we define the non-deterministic half-duplex complexity and establish bounds connecting it with non-deterministic complexity in the classical model.</summary>
    <updated>2020-08-04T15:11:42Z</updated>
    <published>2020-08-04T15:11:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1371</id>
    <link href="https://ptreview.sublinear.info/?p=1371" rel="alternate" type="text/html"/>
    <title>News for July 2020</title>
    <summary>We hope you’re all staying safe and healthy! To bring you some news (and distraction?) during this… atypical summer,here are the recent papers on property testing and sublinear algorithms we saw appear this month. Graphs, probability distributions, functions… there is a something for everyone. On Testing Hamiltonicity in the Bounded Degree Graph Model, by Oded […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We hope you’re all staying safe and healthy! To bring you some news (and distraction?) during this… atypical summer,here are the recent papers on property testing and sublinear algorithms we saw appear this month. Graphs, probability distributions, functions… there is a something for everyone.</p>



<p><strong>On Testing Hamiltonicity in the Bounded Degree Graph Model,</strong> by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2020/109/">ECCC</a>). The title sort of gives it away: this relatively short paper shows that testing whether an unknown bounded-degree graph has a Hamiltonian path (or Hamiltonian cycle) in the bounded-degree model requires a number of queries linear in \(n\), the number of nodes. The results also hold for directed graphs (with respect to directed Hamiltonian path or cycle), and are shown via a local reduction to a promise problem of satisfiability of 3CNF formulae. Also included: a complete proof of the linear lower bound for another problem, Independent Set Size; and an open problem: <em>what is the query complexity of testing graph isomorphism in the bounded-degree model?</em></p>



<p><strong>Local Access to Sparse Connected Subgraphs Via Edge Sampling</strong>, by Rogers Epstein (<a href="https://arxiv.org/abs/2007.05523">arXiv</a>). Given access to a connected graph \(G=(V,E)\), can we efficiently provide access to some <em>sparse</em> connected subgraph \(G’=(V,E’)\subseteq G\) with \(|E’|\ll |E|\)? This question, well-studied in particular for the case where \(G\) had bounded degree and the goal is to achieve \(|E’|\leq (1-\varepsilon)|V|\), is the focus of this paper which provides a trade-off between the query complexity of the oracle and \(|E’|\). Specifically, for every parameter \(T\), one can give oracle access to \(G’\) with \(|E’|=O(|V|T)\), with a query complexity \(=\tilde{O}(|E|/T)\). </p>



<p>Switching gears, we move from graphs to probability distributions:</p>



<p><strong>Tolerant Distribution Testing in the Conditional Sampling Model</strong>, by Shyam Narayanan (<a href="https://arxiv.org/abs/2007.09895">arXiv</a>). In the conditional sampling model for distribution testing, which we have covered a few times on this blog, the algorithm at each step gets to specify a subset \(S\) of the domain, and observe a sample from the distribution <em>conditioned on \(S\).</em> As it turns out, this can speed things up a <strong>lot</strong>: as Canonne, Ron, and Servedio (2015) showed, even tolerant uniformity testing, which with i.i.d. samples requires a near-linear (in the domain size \(n\)) number of samples, can be done in a <em>constant</em> number of conditional queries. Well, sort of constant: no dependence on \(n\), but the dependence on the distance parameter \(\varepsilon\) was, in CRS15, quite bad: \(\tilde{O}(1/\varepsilon^{20})\).  This work gets rid of this badness, and shows the (nearly) optimal \(\tilde{O}(1/\varepsilon^{2})\) query complexity! Among other results, it also generalizes it to tolerant identity testing  (\(\tilde{O}(1/\varepsilon^{4})\)), for which previously no constant-query upper bound was known. Things have become <em>truly</em> sublinear.</p>



<p>I<strong>nteractive Inference under Information Constraints</strong>, by Jayadev Acharya, Clément Canonne, Yuhan Liu, Ziteng Sun, and Himanshu Tyagi (<a href="https://arxiv.org/abs/2007.10976">arXiv</a>). Say you want to do uniformity/identity testing (or learn, but let’s focus on testing) on a discrete distribution, but you can’t actually observe the i.i.d. samples: instead, you can only do some sort of limited, “local” measurement on each sample. How hard is the task, compared to what you’d do if you fully had the samples? This setting, which captures things like distributed testing with communication or local privacy constraints, erasure channels, etc., was well-understood from previous recent work in the <em>non-adaptive</em> setting. But what if the “measurements” could be made <em>adaptively</em>? This paper shows general lower bounds for identity testing and learning, as a function of the type of local measurement allowed: as a corollary, this gives tight bounds for communication constraints and local privacy, and shows the first separation between adaptive and non-adaptive uniformity testing, for a type of “leaky” membership query measurement.</p>



<p><strong>Efficient Parameter Estimation of</strong> <strong>Truncated Boolean Product Distributions</strong>, by Dimitris Fotakis, Alkis Kalavasis, and Christos Tzamos (<a href="https://arxiv.org/abs/2007.02392">arXiv</a>). Suppose there is a fixed and unknown subset \(S\) of the hypercube, a “truncation” set, which you can only accessible via membership query; and you receive i.i.d. samples from an unknown product distribution on the hypercube, <em>truncated</em> on that set \(S\) (for instance, because your polling strategy or experimental measurements have limitations). Can you still learn that distribution efficiently? Can you test it for various properties, as you typically really would like to? (or is it just me?) This paper identifies some natural sufficient condition on \(S\), which they call <em>fatness</em>, under which the answer is a resounding <em>yes</em>. Specifically, if \(S\) satisfies this condition, one can actually generate honest-to-goodness i.i.d. samples (non-truncated) from the true distribution, given truncated samples! </p>



<p>Leaving distribution testing, our last paper is on testing functions in the <em>distribution-free</em> model:</p>



<p><strong>Downsampling for Testing and Learning in Product Distributions,</strong> by Nathaniel Harms and Yuichi Yoshida (<a href="https://arxiv.org/abs/2007.07449">arXiv</a>). Suppose you want to test (or learn) a class of Boolean functions \(\mathcal{C}\) over some domain \(\Omega^n\), with respect to some (unknown) product distribution (i.e., in the distribution-free testing model, or PAC-learning model). This paper develops a general technique, downsampling, which allows one to reduce such distribution-free testing of \(\mathcal{C}\) under a product distribution to testing \(\mathcal{C}\) over \([r]^d\) under the <em>uniform</em> distribution, for a suitable parameter \(r=r(d,\varepsilon,\mathcal{C})\). This allows the authors, among many other things and learning results, to easily re-establish (and, in the second case, improve upon) recent results on testing of monotonicity over \([n]^d\) (uniform distribution) and over \(\mathbb{R}^d\) (distribution-free). </p></div>
    </content>
    <updated>2020-08-04T02:59:57Z</updated>
    <published>2020-08-04T02:59:57Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-08-07T23:38:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17379</id>
    <link href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/" rel="alternate" type="text/html"/>
    <title>Cleverer Automata Exist</title>
    <summary>A breakthrough on the separating words problem Zachary Chase is a graduate student of Ben Green at Oxford. Chase has already solved a number of interesting problems–check his site for more details. His advisor is famous for his brilliant work—especially in additive combinatorics. One example is his joint work with Terence Tao proving this amazing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A breakthrough on the separating words problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17371" rel="attachment wp-att-17371"><img alt="" class="alignright wp-image-17371" src="https://rjlipton.files.wordpress.com/2020/08/chase.png?w=125" width="125"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p/><p>
Zachary Chase is a graduate student of Ben Green at Oxford. Chase has already solved a number of interesting problems–check his <a href="http://people.maths.ox.ac.uk/~chase/">site</a> for more details. His advisor is famous for his brilliant work—especially in additive combinatorics. One example is his joint work with Terence Tao <a href="https://en.wikipedia.org/wiki/Green-Tao_theorem">proving</a> this amazing statement:</p>
<blockquote><p><b>Theorem 1</b> <em> The prime numbers contain arbitrarily long arithmetic progressions. </em>
</p></blockquote>
<p>
</p><p>
Today we wish to report Chase’s new <a href="https://arxiv.org/pdf/2007.12097.pdf">paper</a> on a problem we have twice discussed before. </p>
<p>
But first Ken wants to say something about Oxford where he got his degree long before Green arrived. </p>
<p>
</p><p/><h2> Oxford Making Waves </h2><p/>
<p/><p>
Green moved to Oxford in 2013. He holds a professorship associated to Magdalen College. I (Ken) did not know him when I started at Oxford in 1981. It would have been hard, as Green was only 4 years old at the time. But I did know the preteen Ruth Lawrence when she started there and even once played a departmental croquet match including her in which Bryan Birch made some epic long shots. Lawrence had <a href="https://en.wikipedia.org/wiki/Ruth_Lawrence">joined</a> St. Hugh’s College in 1983 at the age of twelve.</p>
<p>
Oxford has been Dick’s and my mind more in the past six years than before. Both of us were guests of Joël Ouaknine in 2012–2015 when he was there. Oxford has developed a front-line group in quantum computation, which fits as David Deutsch’s role as an originator began from there—note my story in the middle of this recent <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">post</a>.</p>
<p>
Recently Oxford has been in the <a href="https://www.statnews.com/2020/07/20/study-provides-first-glimpse-of-efficacy-of-oxford-astrazeneca-covid-19-vaccine/">news</a> for developing a promising Covid-19 vaccine. <a href="https://www.precisionvaccinations.com/vaccines/chadox1-mers-coronavirus-vaccine">ChAdOx1</a> heads Wikipedia’s <a href="https://en.wikipedia.org/wiki/COVID-19_vaccine#Vaccine_candidates">list</a> of candidate vaccines and has gone to final <a href="https://www.nationalgeographic.com/science/2020/07/oxford-vaccine-enters-final-phase-of-covid-19-trials-in-brazil-cvd/">trials</a>, though there is still a long evaluation process before approval for general use.</p>
<p>
Before that, a modeling <a href="https://nymag.com/intelligencer/2020/03/oxford-study-coronavirus-may-have-infected-half-of-u-k.html">study</a> from Oxford in March raised the question of whether many more people have had Covid-19 without symptoms or any knowledge. This kind of possibility has since been <a href="https://marginalrevolution.com/marginalrevolution/2020/06/karl-friston-on-immunological-dark-matter.html">likened</a> to a “dark matter” hypothesis, not just now regarding Covid-19 but a decade <a href="https://pubmed.ncbi.nlm.nih.gov/21839767/">ago</a> and before. </p>
<p>
A main <a href="https://theconversation.com/coronavirus-techniques-from-physics-promise-better-covid-19-models-can-they-deliver-139925">supporting</a> <a href="https://www.brunel.ac.uk/news-and-events/news/articles/Coronavirus-techniques-from-physics-promise-better-COVID-19-models-can-they-deliver">argument</a> is that a wide class of mathematical models can be fitted with higher relative likelihood if the hypothesis is true. I have wanted to take time to evaluate this argument amid the wider backdrop of <a href="https://rjlipton.wordpress.com/2018/05/19/lost-in-complexity/">controversy</a> over inference methods in physics, but online chess with unfortunately ramped-up frequency of cheating has filled up all disposable time and more.</p>
<p>
</p><p/><h2> The Problem </h2><p/>
<p/><p>
Back to Chase’s new results on the following problem: </p>
<blockquote><p><b> </b> <em> Given two distinct binary strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> there is always a finite state deterministic automaton (FSA) that accepts one and rejects the other. <i>How few states can such a machine have?</i> </em>
</p></blockquote>
<p/><p>
This is called the <em>separating words problem</em> (SWP). Here we consider it for binary strings only.</p>
<p>
John Robson proved <img alt="{O(n^{2/5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^{2/5})}"/> states are enough—we suppress any log factors. Some like to write this as <img alt="{\tilde{O}(n^{2/5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{2/5})}"/>. Chase <a href="https://arxiv.org/pdf/2007.12097.pdf">improves</a> this to <img alt="{\tilde{O}(n^{1/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{1/3})}"/>:</p>
<blockquote><p><b>Theorem 2</b> <em><a name="Chasethm"/> For any distinct <img alt="{x,y \in \{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y \in \{0,1\}^{n}}"/>, there is a finite state deterministic automaton with <img alt="{O(n^{1/3} \log^{7} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B1%2F3%7D+%5Clog%5E%7B7%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{1/3} \log^{7} n)}"/> states that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> but not <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/>. </em>
</p></blockquote>
<p/><p>
We previously discussed this twice at GLL. We discussed the background and early results <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">here</a>. The original problem is due to Pavel Goralcik and Vaclav Koubek. They proved an upper bound that was <img alt="{o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(n)}"/>. Then we went over Robson’s bound <a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/">here</a>. The best upper bound was Robson’s result until Chase came along.</p>
<p>
</p><p/><h2> The Approach </h2><p/>
<p/><p>
All the approaches to SWP seem to have a common thread. They find some family of “hash” functions <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> so that:</p>
<ol>
<li>
Any <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> in <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> can be computed by a FSA with few states. <p/>
</li><li>
For any <img alt="{x \neq y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cneq+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \neq y}"/> binary strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, there is an <img alt="{h \in H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh+%5Cin+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h \in H}"/> so that <img alt="{h(x) \neq h(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%5Cneq+h%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x) \neq h(y)}"/>.
</li></ol>
<p>
The challenge is to find clever families that can do do both. Be easy to compute and also be able to tell strings apart. Actually this is only a coarse outline—Chase’s situation is a bit more complicated. </p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
We have taken the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#Chasethm">2</a> verbatim from the paper. It has a common pecadillo of beginning a sentence for a specific <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> but writing <img alt="{O(\cdots n \cdots)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Ccdots+n+%5Ccdots%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\cdots n \cdots)}"/> later. However, this is how we think intuitively: in terms of how the pieces of the formula behave. Chase declares right away his intent to ignore the power of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. How he gets the power <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/> of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the real point. We can convey the intuition in brief.</p>
<p>
A length-<img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> binary string can be identified with its set <img alt="{A \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \subseteq [n]}"/> of positions where the string has a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Chase begins by showing how a power of <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is obtainable by considering sets of the form </p>
<p align="center"><img alt="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bi%2Cp%7D+%3D+%5C%7Bj+%3A+j+%5Cin+A+%5Cwedge+j+%5Cequiv+i+%5Cpmod%7Bp%7D%5C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, "/></p>
<p>where <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime and <img alt="{i &lt; p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i &lt; p}"/>. Suppose we know a bound <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> such that for all distinct <img alt="{A,B \subseteq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B \subseteq n}"/> (that is, all distinct binary strings of legnth <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) there is a prime <img alt="{p &lt; k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3C+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p &lt; k}"/> and <img alt="{i &lt; p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i &lt; p}"/> such that </p>
<p align="center"><img alt="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. "/></p>
<p>Then by the Chinese Remainder Theorem, there is a prime <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> of magnitude about <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> such that </p>
<p align="center"><img alt="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cnot%5Cequiv+%7CB_%7Bi%2Cp%7D%7C+%5Cpmod%7Bq%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. "/></p>
<p>Now we can make a finite automaton <img alt="{M_{A,B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_{A,B}}"/> with states <img alt="{(j,\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28j%2C%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(j,\ell)}"/> that always increments <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> modulo <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> and increments <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> modulo <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> each time it reads a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> when <img alt="{j \equiv i \pmod{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%5Cequiv+i+%5Cpmod%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j \equiv i \pmod{p}}"/>. Then <img alt="{M_{A,B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_{A,B}}"/> has order-of <img alt="{pq \approx k\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bpq+%5Capprox+k%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{pq \approx k\log n}"/> states. The finisher is that <img alt="{k = \tilde{O}(n^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = \tilde{O}(n^{1/2})}"/> suffices. Again we ignore the pecadillo but we add some redundant words to the statement in the paper between dashes:</p>
<blockquote><p><b>Lemma 3</b> <em> For any distinct <img alt="{A,B \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A,B \subseteq [n]}"/>—of size at most <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>—there is a prime <img alt="{p = \tilde{O}(n^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p = \tilde{O}(n^{1/2})}"/> such that for some <img alt="{i \in [p]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i \in [p]}"/>, <img alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|A_{i,p}| \neq |B_{i,p}|.}"/> </em>
</p></blockquote>
<p/><p>
The power <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> is of course weaker than Robson’s <img alt="{2/5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2/5}"/>, but this statement conceals two “<a href="https://rjlipton.wordpress.com/2011/08/05/give-me-a-lever/">levers</a>” that enable leap-frogging <img alt="{2/5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2/5}"/> to get <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/>. The first is that we don’t have to limit attention to sets <img alt="{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B}"/> that come from places where the corresponding strings <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/> have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Consider any string <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and take <img alt="{A_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_w}"/> to be the set of index positions <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> in which <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has the substring <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> beginning at place <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/>. Define <img alt="{B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_w}"/> likewise for <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>. Then we can try to prove results of the following form given <img alt="{m &lt; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m &lt; n}"/>:</p>
<blockquote><p><b>Proposition 4</b> <em> For all distinct <img alt="{x,y \in \{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y \in \{0,1\}^n}"/> there is <img alt="{w \in \{0,1\}^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw+%5Cin+%5C%7B0%2C1%5C%7D%5Em%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{w \in \{0,1\}^m}"/> such that <img alt="{A_w \neq B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_w \neq B_w}"/> and </em></p><em>
<p align="center"><img alt="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_w%7C%2C%7CB_w%7C+%3D+O%28%5Cfrac%7Bn%7D%7Bm%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
A finite automaton using this extension needs <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> states to store <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> in its finite control. The second lever is to try to prove results of this form, where now the words “of size at most <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>” are not redundant:</p>
<blockquote><p><b>Lemma 5 (?)</b> <em><a name="conjlemma"/> For any distinct <img alt="{A,B \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A,B \subseteq [n]}"/> of size at most <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{N}"/> there is a prime <img alt="{p = \tilde{O}(N^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p = \tilde{O}(N^{1/2})}"/> such that for some <img alt="{i \in [p]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i \in [p]}"/>, <img alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|A_{i,p}| \neq |B_{i,p}|.}"/>  </em>
</p></blockquote>
<p/><p>
Now we need to balance the levers using the proposition and the lemma together.  Since <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> will add order-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> states to the automaton, we balance it against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from the previous argument.  So take <img alt="{m = n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = n^{1/3}}"/>. Then <img alt="{N = \frac{n}{m} \approx n^{2/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+%5Cfrac%7Bn%7D%7Bm%7D+%5Capprox+n%5E%7B2%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = \frac{n}{m} \approx n^{2/3}}"/>. Lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a> then gives the bound </p>
<p align="center"><img alt="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) "/></p>
<p>on the magnitude of the needed primes <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. This yields the <img alt="{\tilde{O}(n^{1/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{1/3})}"/> breakthrough on SWP.</p>
<p/><p>
Here a famous New Yorker <a href="https://www.allposters.com/-sp/Oh-if-only-it-were-so-simple-New-Yorker-Cartoon-Posters_i9168200_.htm?UPI=PGQEG50&amp;PODConfigID=8419447&amp;sOrigID=169338">cartoon</a> with the caption “If only it were so simple” comes to mind.  But there is a catch. Chase is not quite able to prove lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a>. However, the <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> lever comes with extra flexibility that enables finding <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> that make <img alt="{A_w \neq B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_w \neq B_w}"/> and also give those sets an extra regularity property <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. Using <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, he is able to show the existence of good hash functions of a certain type. The modified lemma is enough to prove his new bound.  The proof still uses intricate analysis including integrals.</p>
<p>
This is classic high-power mathematics. When some idea is blocked, try to weaken the requirements. Sometimes it is possible to still proceed. It is a lesson that we sometimes forget, but a valuable one nevertheless.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We like the SWP and think Chase’s contribution is impressive. Note that it adds a third element <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> and <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> in the automaton.  Can the argument be pushed further by finding more levers to add more elements?  Is Lemma 5 true as stated, and with what (other) tradeoffs of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> between it and Proposition 4?</p>
<p>
We feel there could also be interesting applications for his theorem as it stands. Is the ability to tell two strings apart with a simple device—a FSA with not many states—useful? Could it solve some open problem? It does seem like a basic insight, yet we have no candidate application. Perhaps you have an idea. </p>
<p/><p><br/>
[added Q on Lemma 5 to “Open Problems”, “lower” bound –&gt; “upper” bound in third section.]</p></font></font></div>
    </content>
    <updated>2020-08-03T14:50:54Z</updated>
    <published>2020-08-03T14:50:54Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="trick"/>
    <category term="Ben Green"/>
    <category term="estimates"/>
    <category term="finite automata"/>
    <category term="hash functions"/>
    <category term="levers"/>
    <category term="log factors"/>
    <category term="Oxford"/>
    <category term="separating words problem"/>
    <category term="SWP"/>
    <category term="Zachary Chase"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-08T20:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsmath.wordpress.com/?p=2293</id>
    <link href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/" rel="alternate" type="text/html"/>
    <title>ITCS 2021 Call for Papers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The 12th Innovations in Theoretical Computer Science (ITCS) conference will be held online from January 6-8, 2021. The submission deadline is September 7, 2020. The program committee encourages you to send your papers our way! See the call for papers for information about submitting to the conference. ITCS seeks to promote research that carries a strong conceptual message (e.g., introducing … <a class="more-link" href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/">Continue reading <span class="screen-reader-text">ITCS 2021 Call for Papers</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <strong>12th Innovations in Theoretical Computer Science (ITCS)</strong> conference will be held <strong>online</strong> from <strong>January 6-8, 2021</strong>.   The <strong>submission deadline</strong> is <strong>September 7, 2020</strong>.</p>



<p>The <a href="http://itcs-conf.org/">program committee</a> encourages you to send your papers our way!  See the <a href="http://itcs-conf.org/">call for papers</a> for information about submitting to the conference.</p>



<p>ITCS seeks to promote research that carries a strong conceptual message (e.g., introducing a new concept, model or understanding, opening a new line of inquiry within traditional or interdisciplinary areas, introducing new mathematical techniques and methodologies, or new applications of known techniques). ITCS welcomes both conceptual and technical contributions whose contents will advance and inspire the greater theory community.</p>



<p/>



<h3>Important dates</h3>



<ul><li><strong>Submission deadline: </strong> September 7, 2020 (05:59PM PDT) </li><li><strong>Notification to authors:</strong> November 1, 2020</li><li><strong>Conference dates: </strong>January 6-8, 2021</li></ul>



<p/>



<p/></div>
    </content>
    <updated>2020-08-03T02:06:40Z</updated>
    <published>2020-08-03T02:06:40Z</published>
    <category term="Announcement"/>
    <category term="ITCS"/>
    <category term="theory conference"/>
    <author>
      <name>James</name>
    </author>
    <source>
      <id>https://tcsmath.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsmath.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsmath.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsmath.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsmath.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>some mathematics &amp; computation</subtitle>
      <title>tcs math</title>
      <updated>2020-08-08T20:20:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1233384953933252805</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1233384953933252805/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/the-gauss-story-is-false-yet-we-still.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1233384953933252805" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1233384953933252805" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/the-gauss-story-is-false-yet-we-still.html" rel="alternate" type="text/html"/>
    <title>The Gauss story is false yet we still tell it. Should we?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
When teaching discrete math a while back I told the following story which some had already heard in High School: <br/>
<i><br/></i>
<i>When Gauss was in 1st grade the class was being bad. So the teacher made them sit down and add up the numbers from 1 to 100. Gauss did it in 2 minutes by noting that if S was the answer then </i><br/>
<i><br/></i>
<i>2S = (100+1) +(99+2) + ... + (1 + 100) = 100*101</i><br/>
<i><br/></i>
<i>So S = 50*101.  Then he went to Google and typed in 50*101 for the answer.</i><br/>
<i><br/></i>
The class laughed because of course the last part about Google was false. But I then told them that the entire story was false and showed them the following slides:  <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/gaussstory.pdf">here</a>  Take a look at them (there are only 4 of them) before reading on.<div><br/></div><div>(ADDED LATER: here is an article by Brian Hayes that documents the history of the story.</div><div><br/></div><div><a href="http://bit-player.org/wp-content/extras/bph-publications/AmSci-2006-05-Hayes-Gauss.pdf" target="_blank">http://bit-player.org/wp-content/extras/bph-publications/AmSci-2006-05-Hayes-Gauss.pdf</a></div><div><br/></div><div>)<br/>
<br/>
<br/>
So I told them the Gauss Story was false (I am right about this) and then told them a lie- that the story's progression over time was orderly. I then told them that that was false (hmmm- actually I might not of, oh well).<br/>
<br/>
One of my students emailed me this semester<br/>
<br/>
<i>Dr Gasarch- one of my Math professors is telling the Gauss story as if its true! You should make a public service announcement and tell people its false!</i><div><i><br/></i></div><div>I do not think this is needed. I also don't know how one goes about making a public service announcement  I also  suspect the teacher knew it was false but told it anyway.<div>
<br/>
OKAY- what do you do if you have a nice story that has some good MATH in it but  its not true?<br/>
<br/><b>Options:</b></div><div><br/></div><div>Tell it and let the students think its true.</div><div><br/></div><div>Tell it and debunk it.</div><div><br/></div><div>Tell it and debunk it and tell another myth</div><div><br/></div><div>Tell it and debunk it and tell another myth and then debunk that</div><div><br/></div><div>Ask your readers what they would do. Which I do now: What do you do? <br/><br/></div></div></div></div>
    </content>
    <updated>2020-08-03T02:02:00Z</updated>
    <published>2020-08-03T02:02:00Z</published>
    <author>
      <name>Unknown</name>
      <email>noreply@blogger.com</email>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-08T16:35:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/02/sona-enumeration</id>
    <link href="https://11011110.github.io/blog/2020/08/02/sona-enumeration.html" rel="alternate" type="text/html"/>
    <title>Sona enumeration</title>
    <summary>The last of my CCCG 2020 papers is now on the arXiv: “New Results in Sona Drawing: Hardness and TSP Separation”, arXiv:2007.15784, with Chiu, Demaine, Diomidov, Hearn, Hesterberg, Korman, Parada, and Rudoy. (As you might infer from the long list of coauthors, it’s a Barbados workshop paper.) The paper studies a mathematical formalization of the lusona drawings of southwest Africa; in this formalization, a sona curve for a given set of points is a curve that can be drawn in a single motion, intersecting itself only at simple crossings, and surrounding each given point in a separate region of the plane, with no empty regions. The paper proves that it’s hard to find the shortest one, hard even to find whether one exists when restricted to grid edges, and gives tighter bounds for the widest possible ratio between sona curve length and TSP tour length; see the preprint or the video I already posted for more information.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The last of my CCCG 2020 papers is now on the arXiv: “New Results in Sona Drawing: Hardness and TSP Separation”, <a href="https://arxiv.org/abs/2007.15784">arXiv:2007.15784</a>, with Chiu, Demaine, Diomidov, Hearn, Hesterberg, Korman, Parada, and Rudoy. (As you might infer from the long list of coauthors, it’s a Barbados workshop paper.) The paper studies a mathematical formalization of the <a href="https://en.wikipedia.org/wiki/Lusona">lusona</a> drawings of southwest Africa; in this formalization, a sona curve for a given set of points is a curve that can be drawn in a single motion, intersecting itself only at simple crossings, and surrounding each given point in a separate region of the plane, with no empty regions. The paper proves that it’s hard to find the shortest one, hard even to find whether one exists when restricted to grid edges, and gives tighter bounds for the widest possible ratio between sona curve length and TSP tour length; see the preprint or <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">the video I already posted</a> for more information.</p>

<p>To save this post from being content-free, here’s a research question that we didn’t even state in the paper, let alone make any progress on solving: just how many of these curves can a given set of points have? A sona curve can be described as a 4-regular plane multigraph (satisfying certain extra conditions) together with an assignment of the given points to its bounded faces, so there are finitely many of these things up to some sort of topological equivalence. And because this is topological it shouldn’t matter where the points are placed in the plane: the number of curves should be a function only of the number of points. I tried hand-enumerating the curves for up to three points but it was already messy and I’m not certain I got them all. (In an earlier version of this post I definitely didn’t get them all — I had to update the figure below after finding more.) Here are the ones I found:</p>

<p style="text-align: center;"><img alt="Sona curves for up to three points" src="https://11011110.github.io/blog/assets/2020/sona-enum.svg"/></p>

<p>If this hand enumeration is correct, then the numbers of sona curves for \(n\) labeled points form an integer sequence beginning \(1, 3, 24,\dots\) and the numbers for unlabeled points form a sequence beginning \(1, 2, 5,\dots\) but I don’t really know anything more than that for this problem.</p>

<p>Another research direction I don’t know much about yet: given a topological equivalence class of sona drawings, how can we find a good layout for it as an explicit drawing? There’s lots of research on drawing plane graphs nicely but it’s not clear how much of it carries over to making nice sona curves.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104624173377453724">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-08-02T23:48:00Z</updated>
    <published>2020-08-02T23:48:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-08T01:30:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/116</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/116" rel="alternate" type="text/html"/>
    <title>TR20-116 |  Toward better depth lower bounds: the XOR-KRW conjecture | 

	Alexander Smal, 

	Ivan Mihajlin</title>
    <summary>In this paper, we propose a new conjecture, the XOR-KRW conjecture, which is a relaxation of the Karchmer-Raz-Wigderson conjecture [KRW95]. This relaxation is still strong enough to imply $\mathbf{P} \not\subseteq \mathbf{NC}^1$ if proven. We also present a weaker version of this conjecture that might be used for breaking $n^3$ lower bound for De~Morgan formulas. Our study of this conjecture allows us to partially answer an open question stated in [GMWW17] regarding the composition of the universal relation with a function. To be more precise, we prove that there exists a function $g$ such that the composition of the universal relation with $g$ is significantly harder than just a universal relation. The fact that we can only prove the existence of $g$ is an inherent feature of our approach.
    
The paper's main technical contribution is a method of converting lower bounds for multiplexer-type relations into lower bounds against functions. In order to do this, we develop techniques to lower bound communication complexity using reductions from non-deterministic communication complexity and non-classical models: half-duplex and partially half-duplex communication models.</summary>
    <updated>2020-08-02T06:10:06Z</updated>
    <published>2020-08-02T06:10:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19988</id>
    <link href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/" rel="alternate" type="text/html"/>
    <title>To Cheer you up in Difficult Times 8: Nathan Keller and Ohad Klein Proved Tomaszewski’s Conjecture on Randomly Signed Sums</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today we talk about the paper, Proof of Tomaszewski’s Conjecture on Randomly Signed Sums, by Nathan Keller and Ohad Klein. Consider a unit vector That is latex \sum_{i=1}^n a_i^2=1$. Consider all () signed sums where each is either 1 or … <a href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today we talk about the paper, <a href="https://arxiv.org/abs/2006.16834">Proof of Tomaszewski’s Conjecture on Randomly Signed Sums</a>, by Nathan Keller and Ohad Klein.</p>
<p>Consider a unit vector <img alt="a=(a_1,a_2,\dots, a_n)." class="latex" src="https://s0.wp.com/latex.php?latex=a%3D%28a_1%2Ca_2%2C%5Cdots%2C+a_n%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a=(a_1,a_2,\dots, a_n)."/> That is latex \sum_{i=1}^n a_i^2=1$. Consider all (<img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>) signed sums <img alt="\displaystyle \epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%2C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n, "/> where each <img alt="\epsilon_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon_k"/> is either 1 or -1.</p>
<p><strong>Theorem (Keller and Klein (2020) asked by Boguslav Tomaszewski (1986)): </strong>For at least <img alt="2^{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}"/> signed sums <img alt="\displaystyle |\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%7C+%5Cle+1+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle |\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ."/></p>
<p>Another way to state the theorem is that the probability of a signed sum to be in the interval [-1, 1] is at least 1/2.</p>
<p>To see that this is best possible consider the case that <img alt="n=2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=2"/> and let <img alt="a_1,a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2"/> be non zero. For the sum in question to exceed one we need both summands to have the same sign which happens half of the times. There is another example of importance, the vector <img alt="(\frac{1}{2}, \frac{1}{2}, \frac {1}{2}, \frac{1}{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cfrac%7B1%7D%7B2%7D%2C+%5Cfrac%7B1%7D%7B2%7D%2C+%5Cfrac+%7B1%7D%7B2%7D%2C+%5Cfrac%7B1%7D%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\frac{1}{2}, \frac{1}{2}, \frac {1}{2}, \frac{1}{2})"/>. Here 3/8 of the absolute values of signed sums (6 out of 16) are below 1 (in fact, equal to zero), 1/2 equal to 1 and 1/8 exceed 1. Holzman and Kleitman proved in 1992 that the fraction of absolute values of signed sums below 1 is always at least 3/8.</p>
<p>Congratulations to Nathan and Ohad. I will say a little more about the problem below but before that, a few more things.</p>
<h3>A few more things</h3>
<p>Luca Trevisan posted on his blog In Theory a post “Silver linings” about two cheerful pieces of news. The first one is “Karlin, Klein, and Oveis Gharan have just <a href="https://arxiv.org/abs/2007.01409">posted a paper</a> in which, at long last, they improve over the 1.5 approximation ratio for metric TSP which was achieved, in 1974, by Christofides.”</p>
<p>The second  one is about breaking the logarithmic barrier for Roth’s theorem that we wrote about here. This was also discussed by Bill <a>Gasarch </a>on Computational Complexity. In the comment section of my post there is an interesting discussion regarding timetable for future achievements and how surprising they would be.</p>
<p>The third is about Ron Graham, a friend and a mathematical giant who passed away a few days ago. Here is a <a href="https://www.facebook.com/fan.chung.9/posts/10220086655131549">moving post</a> by Fan Chung, <a href="http://www.math.ucsd.edu/~fan/ron/">a web page for Ron</a> set by Fan, and a <a href="https://rjlipton.wordpress.com/2020/07/10/ron-graham-1935-2020/">blog post by Dick and Ken on GLL</a>.</p>
<p>The fourth is that there is a nice collection of open problems on Boolean functions that is cited in the paper of Nathan and Ohad:  Y. Filmus, H. Hatami, S. Heilman, E. Mossel, R. O’Donnell, S. Sachdeva, A. Wan, and K. Wimmer, <a href="https://simons.berkeley.edu/sites/default/files/openprobsmerged.pdf">Real analysis in computer science: A collection of open problems</a>.</p>
<p>The fifth is that both our (HUJI) combinatorics seminar and basic notions seminar are running and are recorded. Here are the links. (Hmm, the links are not yet available, I will update.)</p>
<h2>Back to the result of Keller and Klein</h2>
<h3><a href="https://gilkalai.files.wordpress.com/2020/08/dkrh2.png"><img alt="" class="alignnone size-full wp-image-20034" height="365" src="https://gilkalai.files.wordpress.com/2020/08/dkrh2.png?w=640&amp;h=365" width="640"/></a></h3>
<p><span style="color: #ff0000;">Daniel Kleitman and Ron Holzman</span></p>
<h3>A quick orientation</h3>
<p>If the <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>s are all the same, or small, or random, then to compute the probability that the weighted sum is between -1 and 1, we can use some Gaussian approximation and then we will find ourselves in a clash of constants that goes our way. The probability will be close to a constant well above 1/2. So what we need to understand is the case where some <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>s are large.</p>
<h3>Early papers on the problem</h3>
<p>The problem first appeared in the American Math Monthly.  Richard Guy <a href="https://www.math.wisc.edu/~miller/res/fun-problem.pdf">collected several problems  and challenged the readers Any Answers Anent These Analytical Enigmas?</a> (I don’t know what the fate of the other questions is.)  Holzman and Kleitman <a href="https://holzman.technion.ac.il/files/2012/09/combsigns.pdf">proved in 1992</a> that the fraction of absolute values of signed sums below 1 is always at least 3/8, and this is tight. For many years, 3/8 was the record for the original problem, until  the 2017 paper by Ravi Boppana and Ron Holzman: <a href="https://arxiv.org/abs/1704.00350">Tomaszewski’s problem on randomly signed sums: Breaking the 3/8 barrier</a>, where a lower bound of 0.406, was proved. The current record 0f 0.46 was proved in the paper <a href="https://arxiv.org/abs/2005.05031">Improved Bound for Tomaszewski’s Problem</a> by Vojtěch Dvořák, Peter van Hintum, and Marius Tiba. The new definite result by Nathan and Ohad used some ideas of these early papers.</p>
<h3>What is the crux of matters</h3>
<p>Let me quote what the authors kindly wrote me:</p>
<blockquote><p><em>“The crux of the matter is how to deal with the case of very large coefficients (<img alt="a_1+a_2&gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ba_2%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1+a_2&gt;1"/>). We gave a short semi-inductive argument covering this case (this is Section 5 of the paper). The argument is only semi-inductive, as it requires the full assertion of Tomaszewski for any n'&lt;n, and gives only the case (<img alt="a_1+a_2&gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ba_2%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1+a_2&gt;1"/>) for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. But this means that if we can handle all other cases by other methods then we will be done.</em></p>
<p><em>The semi-inductive argument takes only 3 pages. Handling the other cases takes 72 more pages and requires several new tools, but is closer to things that were done in previous works. (Actually, after we found the 3-page argument, we were quite sure we will be able to finalize the proof; this indeed happened, but took a year).”</em></p></blockquote>
<p>Most of the paper deals with the case of small coefficients. This requires several ideas and new tools.</p>
<h3>Rademacher sums: Improved Berry-Esseen and local tail inequalities</h3>
<p>If all coefficients are “sufficiently small”, then we can<br/>
approximate X by a Gaussian and the inequality should follow. However, using the standard <a href="https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem">Berry-Esseen bound</a>, this holds only if all coefficients are less than 0.16.<br/>
Nathan and Ohad showed that for Rademacher sums, namely random variables of the form <img alt="X=\sum a_i x_i" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D%5Csum+a_i+x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=\sum a_i x_i"/>, as discussed in the conjecture, a stronger Berry-Esseen<br/>
bound can be obtained, and this bound shows immediately that Tomaszewski’s assertion holds whenever all coefficients are less than 0.31. The stronger bound stems<br/>
from a method of Prawitz, presented in the 1972 paper. H. Prawitz, <a href="https://www.tandfonline.com/doi/abs/10.1080/03461238.1972.10404645">Limits for a distribution, if the characteristic function is given in a finite domain</a>, which appeared in the Scandinavian <span style="color: #ff0000;">Actuarial</span> journal.</p>
<p>The second tool is local tail inequalities for Rademacher sums, of the form <img alt="\Pr[a&lt;X&lt;b] \leq \Pr[c&lt;X&lt;d]," class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Ba%3CX%3Cb%5D+%5Cleq+%5CPr%5Bc%3CX%3Cd%5D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[a&lt;X&lt;b] \leq \Pr[c&lt;X&lt;d],"/> where <em>a,b,c,d</em> satisfy certain conditions. Inequalities of this kind were obtained before by Devroye and Lugosi in the 2008 paper:  <a href="https://arxiv.org/abs/0712.1686">Local tail bounds for functions of independent random variables</a>.</p>
<p>These local tail inequalities already have some other applications, e.g., to analysis of Boolean functions. They were developed and applied in an earlier paper paper of Keller and Klein: <a href="https://arxiv.org/abs/1710.07429">Biased halfspaces, noise sensitivity, and relative Chernoff inequalities</a>. Let me mention my related MO question <a href="https://mathoverflow.net/questions/85835/a-variance-tail-description-for-continuous-probability-distributions">A variance tail description for continuous probability distributions.</a></p>
<h3>A couple more ingredients</h3>
<p><strong>A  stopping time argument.</strong> Variants of Tomaszewski’s problem appeared in various fields. The problem was stated independently in a 2002 paper by Ben-Tal, Nemirovski, Roos, <a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RQP_2002.pdf">Robust solutions of uncertain quadratic and conic-quadratic problems.</a>  A stopping time argument introduced there (for proving a lower bound of 1/3) played a crucial role in subsequent works and the critical semi-inductive argument by Nathan and Ohad.</p>
<p><strong>Refinements of the famous <a href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">Chebyshev’s inequality</a>.</strong>  (Did you know Chebyshev’s full name? Ans: Pafnuty Lvovich Chebyshev.)</p>
<dl>
<dd/>
</dl>
<h3>Questions and connections that come to mind</h3>
<p><strong>Q1:</strong> What can be said about families <img alt="\cal F" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cal F"/> of signs that can serve as those signs for which  <img alt="|\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ," class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%7C+%5Cle+1+%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ,"/> for some vector <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>.</p>
<p><strong>Q2:</strong> What can be said about the complex version or even more generally about high dimensions?</p>
<p><strong>Q3:</strong> Are there any relations to <a href="https://www.jstor.org/stable/1971442?seq=1">Littlewood-Offord type problems</a>?</p>
<p><strong>Q4:</strong> Is there any relation to the <a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-of-data-science-fall-2015/projects/MIT18_S096F15_Open0.1.pdf">Komlos Conjecture</a>?</p>
<p>See also <a href="https://mathoverflow.net/questions/53669/anti-concentration-of-bernoulli-sums/53683#53683">this MO question</a> by Luca Trevisan and <a href="https://mathoverflow.net/questions/366894/a-rademacher-root-7-anti-concentration-inequality">this one</a> by George Lowther.</p>
<h3><span style="color: #ff0000;"><strong>Is there a simpler proof?</strong></span></h3>
<p>We can ask about simpler or just different proofs for almost every result we discuss here. But here the statement is so simple…</p>
<div class="thumb tright">
<div class="thumbinner"/>
</div>
<div class="thumb tright">
<div class="thumbinner">
<div class="thumbcaption"/>
</div>
</div></div>
    </content>
    <updated>2020-08-01T18:32:23Z</updated>
    <published>2020-08-01T18:32:23Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Boguslav Tomaszewski"/>
    <category term="Nathan Keller"/>
    <category term="Ohad Klein"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-08T20:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/115</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/115" rel="alternate" type="text/html"/>
    <title>TR20-115 |  The Busy Beaver Frontier | 

	Scott Aaronson</title>
    <summary>The Busy Beaver function, with its incomprehensibly rapid growth, has captivated generations of computer scientists, mathematicians, and hobbyists. In this survey, I offer a personal view of the BB function 58 years after its introduction, emphasizing lesser-known insights, recent progress, and especially favorite open problems. Examples of such problems include: when does the BB function first exceed the Ackermann function? Is the value of BB(20) independent of set theory? Can we prove that BB(n+1)&gt;2^BB(n) for large enough n? Given BB(n), how many advice bits are needed to compute BB(n+1)? Do all Busy Beavers halt on all inputs, not just the 0 input? Is it decidable, given n, whether BB(n) is even or odd?</summary>
    <updated>2020-08-01T05:13:00Z</updated>
    <published>2020-08-01T05:13:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/31/linkage</id>
    <link href="https://11011110.github.io/blog/2020/07/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Gil Kalai on recent developments in Roth’s theorem (\(\mathbb{M}\), see also). Salem and Spencer and later Behrend proved in the 1940s that subsets of \([1,n]\) with no triple in arithmetic progression can have nearly linear size, and Klaus Roth proved in 1953 that they must be sublinear. The upper bounds have slowly come down, to \(n/\log^{1+c} n\) in this new result, but they’re still far from Behrend’s \(n/e^{O(\sqrt{\log n})}\) lower bound.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Gil Kalai on recent developments in Roth’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/104533566344469712">\(\mathbb{M}\)</a>, <a href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html">see also</a>). Salem and Spencer and later Behrend proved in the 1940s that <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">subsets of \([1,n]\) with no triple in arithmetic progression</a> can have nearly linear size, and Klaus Roth proved in 1953 that <a href="https://en.wikipedia.org/wiki/Roth%27s_theorem_on_arithmetic_progressions">they must be sublinear</a>. The upper bounds have slowly come down, to \(n/\log^{1+c} n\) in this new result, but they’re still far from Behrend’s \(n/e^{O(\sqrt{\log n})}\) lower bound.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2020/06/27/peter-sarnaks-hardy-lecture/">Peter Cameron describes Peter Sarnak’s Hardy Lecture</a> (<a href="https://mathstodon.xyz/@11011110/104539029304056696">\(\mathbb{M}\)</a>). It’s on the spectral theory of graphs. If you know about this you probably already know that regular graphs with a big gap between the largest eigenvalue (degree) and the second largest are very good expander graphs. It turns out that 3-regular graphs with gaps elsewhere in their spectrum are also important in the theories of waveguides and fullerenes, and some tight bounds on where those gaps can be are now known.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.07983">Optimal angle bounds for quadrilateral meshes</a> (<a href="https://mathstodon.xyz/@11011110/104544859698397049">\(\mathbb{M}\)</a>). Christopher J. Bishop meshes any simple polygon (why simple?) with max angle 120° and min angle max(60°, min of the polygon). Nice techniques involving conformal mapping, hyperbolic tessellation, and thick/thin decompositions of hyperbolic convex hulls of ideal sets. Also amusing to see him have to disambiguate my name from David B. A. Epstein’s within a single paragraph.</p>
  </li>
  <li>
    <p><a href="https://imgur.com/gallery/72lduu6">One-dimensional diagonal cellular automata generate Sierpinski carpets and intricate branching structures</a> (<a href="https://mathstodon.xyz/@11011110/104550317577491129">\(\mathbb{M}\)</a>, <a href="https://community.wolfram.com/groups/-/m/t/1890120">see also</a>). Via the June 27 update to <a href="http://www.mathpuzzle.com/">mathpuzzle.com</a> which also has plenty of other neat stuff involving tilings, drawings of symmetric graphs, graceful labeling, rectangle dissection into similar rectangles, etc.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/a/366118">Terry Tao on mathematical notation</a> (<a href="https://mathstodon.xyz/@JordiGH/104552943941946623">\(\mathbb{M}\)</a>), in response to a MathOverflow question about why there’s more than one way to write inner products.</p>
  </li>
  <li>
    <p><a href="http://matroidunion.org/?p=2693">Carmesin’s 3d version of Whitney’s planarity criterion</a> (<a href="https://mathstodon.xyz/@11011110/104567191288903767">\(\mathbb{M}\)</a>): a simply-connected 2-dimensional simplicial complex (meeting a technical condition, “locality”) can be topologically embedded into Euclidean space if and only if a certain ternary matroid on its faces has a graphic dual. The proof relies on Perelman’s proof of the Poincaré conjecture! Simply-connected complexes are pretty restrictive but they include e.g. the cone over a graph, which embeds if and only if the graph is planar.</p>
  </li>
  <li>
    <p><a href="https://cp4space.wordpress.com/2020/07/24/fast-growing-functions-revisited/">Fast-growing functions revisited</a> (<a href="https://mathstodon.xyz/@11011110/104573335749947907">\(\mathbb{M}\)</a>). News of recent developments relating the <a href="https://en.wikipedia.org/wiki/Busy_beaver">busy beaver function</a> with <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a>, and proofs of some older claims.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/s12109-020-09750-0">Wikipedia, the free online medical encyclopedia anyone can plagiarize: Time to address wiki‑plagiarism</a> (<a href="https://mathstodon.xyz/@11011110/104576022559029845">\(\mathbb{M}\)</a>, <a href="https://retractionwatch.com/2020/07/25/weekend-reads-image-duplication-software-debuts-papers-that-plagiarize-wikipedia-time-to-get-serious-about-research-fraud/">via</a>). In this editorial in <em>Publishing Research Quarterly</em>, Michaël R. Laurent identifies five PubMed-indexed papers that copied content from Wikipedia without crediting it (noting that this is much more prevalent in predatory book and journal publishing), and argues that doing this should be treated as a form of academic misconduct.</p>
  </li>
  <li>
    <p><a href="https://andrewducker.dreamwidth.org/3861716.html">Facebook temporarily blocks posts of links to dreamwidth</a> (<a href="https://mathstodon.xyz/@11011110/104581191674329045">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=23956640">via</a>). Maybe it was just a mistake? And I guess the decentralization of Mastodon would make doing this to Mastodon posts somewhat harder. But this continued walling-off of the open web is not a good thing.</p>
  </li>
  <li>
    <p><a href="https://nebusresearch.wordpress.com/2020/07/23/my-all-2020-mathematics-a-to-z-fibonacci/">How much we don’t know about Fibonacci</a> (<a href="https://mathstodon.xyz/@nebusj/104581720945583863">\(\mathbb{M}\)</a>). Entry F in Joseph Nebus’s 2020 mathematics A-to-Z.</p>
  </li>
  <li>
    <p><a href="https://cp4space.wordpress.com/2020/07/25/rational-dodecahedron-inscribed-in-unit-sphere/">Rational dodecahedron inscribed in unit sphere</a> (<a href="https://mathstodon.xyz/@11011110/104595876537307480">\(\mathbb{M}\)</a>). It’s easy to inscribe a dodecahedron in the unit sphere: just use a regular one of the appropriate size. And it’s <a href="https://johncarlosbaez.wordpress.com/2011/09/12/fools-gold/">not hard to construct a dodecahedron combinatorially equivalent to the regular dodecahedron but with integer coordinates</a>. Now Adam Goucher shows how to do both at once, in answer to <a href="https://mathoverflow.net/q/234212/440">an old MathOverflow question</a>.</p>
  </li>
  <li>
    <p><em><a href="https://doi.org/10.1007/978-1-4612-5759-2">Descartes on Polyhedra</a></em> (<a href="https://mathstodon.xyz/@11011110/104606789909959594">\(\mathbb{M}\)</a>, <a href="https://en.wikipedia.org/wiki/Descartes_on_Polyhedra">see also</a>). This book is mainly on whether Descartes (circa 1630) knew Euler’s formula \(E-V+F=2\) (before Euler in 1752, but after Maurolico in 1537). It also covers Descartes’ invention of polyhedral figurate numbers beyond the cubes and pyramidal ones known to the Greeks. Descartes’ manuscript has an interesting history: found after his death in a desk, sunk in the Seine, copied by Leibniz, both copies lost, and Leibniz’s copy finally rediscovered in 1860.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=yY9GAyJtuJ0">Spherical geometry is stranger than hyperbolic (in how it looks from an in-universe viewpoint)</a> (<a href="https://mathstodon.xyz/@11011110/104611506183926064">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24011727">via</a>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-07-31T21:03:00Z</updated>
    <published>2020-07-31T21:03:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-08T01:30:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings</id>
    <link href="https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings.html" rel="alternate" type="text/html"/>
    <title>Polyhedra with convex unfoldings</title>
    <summary>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (arXiv:2007.14525). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I already posted a video for the paper so see that for more information.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (<a href="https://arxiv.org/abs/2007.14525">arXiv:2007.14525</a>). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">already posted a video for the paper</a> so see that for more information.</p>

<p>Instead, I thought I’d go into a little more detail about a throwaway remark in the video and the paper (one that I already got an email query about). It says that <a href="https://en.wikipedia.org/wiki/Ideal_polyhedron">ideal hyperbolic polyhedra</a> can always be unfolded (into the hyperbolic plane). These polyhedra are the hyperbolic convex hulls of finitely many limit points of the hyperbolic space; their faces are ideal polygons, glued together along entire hyperbolic lines. More strongly, if you cut an ideal polyhedron along any spanning tree of its vertices and edges, the result always unfolds into a convex ideal hyperbolic polygon. Here, for instance, is a net for an ideal cube:</p>

<p style="text-align: center;"><img alt="Net for an ideal cube" src="https://11011110.github.io/blog/assets/2020/ideal-cube-net.svg"/></p>

<p>I don’t know of a previous reference for this result, and the paper and video state it without proof (because it’s an introductory remark and not the topic of the paper), but it’s easy to prove a stronger statement by induction: any collection of ideal hyperbolic polygons (like the faces of an ideal polyhedron), when connected edge-to-edge in a complex with the connectivity of a tree (like the faces of any convex polyhedron when you cut it along a spanning tree), unfolds to an ideal convex polygon. As a base case, when you have one polygon in your collection, it unfolds to itself. When you have more than one, find a leaf polygon of the tree structure, remove it, and unfold the rest into a convex ideal polygon. Now add back the leaf. It needs to be connected to the rest of the complex along a hyperbolic line, which (by the induction hypothesis that the rest unfolds convexly) has the rest of the complex on one side and an empty hyperbolic halfplane on the other side. Any convex ideal polygon can be placed within this halfplane so that the side on which it should be glued matches up with the boundary line of the halfplane, with enough freedom to match up the points along this line that should be matched up.</p>

<p>This caused me to wonder: which Euclidean convex polyhedra have the same property, that cutting them along any spanning tree leads to a convex unfolding? The answer is: not very many. By <a href="https://en.wikipedia.org/wiki/Descartes%27_theorem_on_total_angular_defect">Descartes’ theorem on total angular defect</a>, the angular defects at the vertices of a convex polyhedron add up to \(4\pi\). If a polyhedron is to have all spanning trees produce a (weakly) convex unfolding, then each vertex has to have angular defect at least \(\pi\), because otherwise cutting along a spanning tree that has a leaf at that vertex will make an unfolding that is non-convex at that vertex. And this is the only thing that can go wrong, because if all angular defects are at least \(\pi\) then the unfolding will be convex at each of its vertices and cannot self-overlap.</p>

<p>So to answer the question about Euclidean polyhedra with all unfoldings convex, we need only look for ways to partition the total angular defect of \(4\pi\) among some set of vertices so that each one gets at least \(\pi\). If we know the defects of all the vertices and the distances between vertices, then by <a href="https://en.wikipedia.org/wiki/Alexandrov%27s_uniqueness_theorem">Alexandrov’s uniqueness theorem</a> the shape of the polyhedron will be determined. Since we’re using Alexandrov, we should also consider a <a href="https://en.wikipedia.org/wiki/Dihedron">dihedron</a> (two mirror-image convex faces glued at their edges) to be a special case of a polyhedron. This leaves, as the only cases:</p>

<ul>
  <li>
    <p>A triangular dihedron based on a right or acute triangle.</p>
  </li>
  <li>
    <p>A rectangular dihedron.</p>
  </li>
  <li>
    <p>A tetrahedron with angular defect exactly \(\pi\) at each vertex.</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="Convex unfoldings of dihedra and a disphenoid" src="https://11011110.github.io/blog/assets/2020/convex-unfoldings.svg"/></p>

<p>The unfoldings of the dihedra have two copies of their face, mirrored across a joining edge. The tetrahedra with all-convex unfoldings are exactly the <a href="https://en.wikipedia.org/wiki/Disphenoid">disphenoids</a>, the tetrahedra whose four faces are congruent. They unfold either to a copy of the same face shape,
expanded by a factor of two in each dimension and creased into four copies along its <a href="https://en.wikipedia.org/wiki/Medial_triangle">medial triangle</a>, or a parallelogram, creased to form a strip of four congruent triangles. Their unfoldings were discussed by Jin Akiyama in his paper “Tile-makers and semi-tile-makers” (<em>American Mathematical Monthly</em> 2007, <a href="https://doi.org/10.1080/00029890.2007.11920450">doi:10.1080/00029890.2007.11920450</a>, <a href="https://www.jstor.org/stable/27642275">jstor:27642275</a>), as part of a broader investigation of polyhedra whose every unfolding tiles the plane.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104601177683049272">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-29T22:18:00Z</updated>
    <published>2020-07-29T22:18:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-08T01:30:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/" rel="alternate" type="text/html"/>
    <title>Junior Fellowship / Andvanced Fellowship at ETH Institute for Theoretical Studies in Zurich (apply by September 23, 2020)</title>
    <summary>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years. Website: https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html Email: nominations@eth-its.ethz.ch</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years.</p>
<p>Website: <a href="https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html">https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html</a><br/>
Email: nominations@eth-its.ethz.ch</p></div>
    </content>
    <updated>2020-07-29T14:52:31Z</updated>
    <published>2020-07-29T14:52:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-08T20:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/114</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/114" rel="alternate" type="text/html"/>
    <title>TR20-114 |  Disjointness through the Lens of Vapnik–Chervonenkis Dimension: Sparsity and Beyond | 

	Anup Bhattacharya, 

	Sourav Chakraborty, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</title>
    <summary>The disjointness problem - where Alice and Bob are given two subsets of $\{1, \dots, n\}$ and they have to check if their sets intersect - is a central problem in the world of communication complexity. While both deterministic and randomized communication complexities for this problem are known to be $\Theta(n)$, it is also known that if the sets are assumed to be drawn from some restricted set systems then the communication complexity can be much lower. In this work, we explore how communication complexity measures change with respect to the complexity of the underlying set system. The complexity measure for the set system that we use in this work is the Vapnik–Chervonenkis (VC) dimension. More precisely, on any set system with VC dimension bounded by $d$, we analyze how large can the deterministic and randomized communication complexities be, as a function of $d$ and $n$.  The $d$-sparse set disjointness problem, where the sets have size at most $d$, is one such set system with VC dimension $d$. The deterministic and the randomized communication complexities of the $d$-sparse set disjointness problem have been well studied and is known to be $\Theta \left( d \log \left({n}/{d}\right)\right)$ and $\Theta(d)$, respectively, in the multi-round communication setting. In this paper, we address the question of whether the randomized communication complexity is always upper bounded by a function of the VC dimension of the set system, and does there always exist a gap between the deterministic and randomized communication complexity for set systems with small VC dimension. 

In this paper, we construct two natural set systems of VC dimension $d$, motivated from geometry. Using these set systems we show that the deterministic and randomized communication complexity can be $\widetilde{\Theta}\left(d\log \left( n/d \right)\right)$ for set systems of VC dimension $d$ and this matches the deterministic upper bound for all set systems of VC dimension $d$. We also study the deterministic and randomized communication complexities of the set intersection problem when sets belong to a set system of bounded VC dimension. We show that there exists set systems of VC dimension $d$ such that both deterministic and randomized (one-way and multi-round) complexities for the set intersection problem can be as high as $\Theta\left( d\log \left( n/d \right) \right)$, and this is tight among all set systems of VC dimension $d$.</summary>
    <updated>2020-07-29T14:15:30Z</updated>
    <published>2020-07-29T14:15:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/113</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/113" rel="alternate" type="text/html"/>
    <title>TR20-113 |  Relaxed Locally Correctable Codes with Nearly-Linear Block Length and Constant Query Complexity | 

	Tom Gur, 

	Igor Shinkar, 

	Alessandro Chiesa</title>
    <summary>Locally correctable codes (LCCs) are error correcting codes C : \Sigma^k \to \Sigma^n which admit local algorithms that correct any individual symbol of a corrupted codeword via a minuscule number of queries. This notion is stronger than that of locally decodable codes (LDCs), where the goal is to only recover individual symbols of the message. One of the central problems in algorithmic coding theory is to construct O(1)-query LCCs and LDCs with minimal block length. Alas, state-of-the-art of such codes requires super-polynomial block length to admit O(1)-query algorithms for local correction and decoding, despite much attention during the last two decades.

This lack of progress prompted the study of relaxed LCCs and LDCs, which allow the correction algorithm to abort (but not err) on a small fraction of the locations. This relaxation turned out to allow constant-query correcting and decoding algorithms for codes with polynomial block length. Focusing on local correction, Gur, Ramnarayan, and Rothblum (ITCS~2018) showed that there exist O(1)-query relaxed LCCs that achieve nearly-quartic block length n = k^{4+\alpha}, for an arbitrarily small constant \alpha&gt;0.

We construct an O(1)-query relaxed LCC with nearly-linear block length n = k^{1+\alpha}, for an arbitrarily small constant \alpha&gt;0. This significantly narrows the gap between the lower bound which states that there are no O(1)-query relaxed LCCs with block length n = k^{1+o(1)}. In particular, our construction matches the parameters achieved by Ben-Sasson et al. (SIAM J. Comput. 2006), who constructed relaxed LDCs with the same parameters. This resolves an open problem raised by Gur, Ramnarayan, and Rothblum (ITCS 2018).</summary>
    <updated>2020-07-27T20:27:01Z</updated>
    <published>2020-07-27T20:27:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/112</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/112" rel="alternate" type="text/html"/>
    <title>TR20-112 |  Simulating DQBF Preprocessing Techniques with Resolution Asymmetric Tautologies | 

	Joshua Blinkhorn</title>
    <summary>Dependency quantified Boolean formulas (DQBF) describe an NEXPTIME-complete generalisation of QBF, which in turn generalises SAT. QRAT is a recently proposed proof system for quantified Boolean formulas (QBF), which simulates the full suite of QBF preprocessing techniques and thus forms a uniform proof checking format for solver verification.

In this work, we study QRAT in the more general DQBF context, obtaining a sound and complete refutational DQBF proof system that we call DQRAT. We show that DQRAT can simulate the full suite of dedicated DQBF preprocessing techniques, except those relying on defined variables, which we cover with the introduction of a new form of prefix modification. Our work enables generalisations of further QBF preprocessing techniques (e.g. blocked literal elimination) that were not previously considered for DQBF.</summary>
    <updated>2020-07-27T19:18:09Z</updated>
    <published>2020-07-27T19:18:09Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17349</id>
    <link href="https://rjlipton.wordpress.com/2020/07/27/a-brilliant-book-on-combinatorics/" rel="alternate" type="text/html"/>
    <title>A Brilliant Book on Combinatorics</title>
    <summary>And Razborov’s brilliant proof method Stasys Jukna is the author of the book Extremal Combinatorics With Applications in Computer Science. Today we talk about Jukna’s book on extremal combinatorics. The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And Razborov’s brilliant proof method</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/07/jukna1.png"><img alt="" class="alignright size-full wp-image-17351" src="https://rjlipton.files.wordpress.com/2020/07/jukna1.png?w=600"/></a></p>
<p>
Stasys Jukna is the author of the <a href="https://www.google.com/books/edition/Extremal_Combinatorics/NV3Y8vjWo8kC?hl=en&amp;gbpv=1">book</a> <em>Extremal Combinatorics With Applications in Computer Science</em>. </p>
<p>
Today we talk about Jukna’s book on extremal combinatorics.</p>
<p><span id="more-17349"/></p>
<p>
The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we might highlight one tiny part—the part on monotone circuit lower bounds. Here goes. All below is based directly on his discussion. Any errors or misguided comments are ours.</p>
<p>
</p><p/><h2> Monotone Boolean Functions </h2><p/>
<p/><p>
Fix an input size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and consider some property of subsets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Let <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> exactly when <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has the property. We can think of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as a Boolean function. You believe that this property is hard to compute—how do you go about proving that? </p>
<p>
In general we have no tools, but if the property is monotone, then there are some powerful methods. Recall <em>monotone</em> means that if <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> then any set <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> so that <img alt="{S \subset T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \subset T}"/> still has the property. For example, <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/> could be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> includes at least half of the elements of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. It cannot be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has an even number of elements. Another example is when <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is given in <em>disjunctive normal form</em> (DNF), </p>
<p align="center"><img alt="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+T_1+%5Cvee+T_2+%5Cvee+%5Ccdots+T_m%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, "/></p>
<p>where each <b>term</b> <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is a conjunction of variables. Each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> can be regarded as a subset of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \supseteq T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csupseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \supseteq T_k}"/> for some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. Every monotone function also has a <em>conjunctive normal form</em> (CNF) </p>
<p align="center"><img alt="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+C_f+%3D+C_1+%5Cwedge+C_2+%5Cwedge+%5Ccdots+%5Cwedge+C_%5Cell%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, "/></p>
<p>where each <b>clause</b> <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> is a disjunction of variables. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \cap C_k \neq \emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+C_k+%5Cneq+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \cap C_k \neq \emptyset}"/> for <em>all</em> <img alt="{k.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k.}"/> The problem is that the numbers <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> of terms and <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> of clauses involved may be huge. The clauses may have different sizes. Given a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, we write <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> for the conjunction of clauses of size exactly <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> and <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> for the rest. We similarly write <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> for DNFs <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>.</p>
<p>
The lower bound methods are on the size of a monotone circuit for <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/>. That is the circuit can only use gates <img alt="{AND}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAND%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AND}"/> and <img alt="{OR}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BOR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{OR}"/>, but no other types of gates, especially not <img alt="{NOT}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BNOT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{NOT}"/> gates. Of course, if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has no small monotone circuits, then it has no small DNF or CNF formulas either. </p>
<p>
The neat fact on which the lower-bound technique builds is that if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> <b>does</b> have small monotone circuits, then we can “wrap” it between a CNF and a DNF in various customizable ways:</p>
<blockquote><p><b>Theorem 1 (informal)</b> <em><a name="informal"/> For every <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> with small monotone circuits and <img alt="{r,s &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s &gt; 0}"/> we can find a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> and a DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of maximum term size <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r}"/> such that </em></p><em>
<p align="center"><img alt="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cleq+f+%5Cleq+D+%5Cqquad%5Ctext%7Band+also%7D%5Cqquad+D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. "/></p>
</em><p><em>Moreover, <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D^r}"/> are small. </em>
</p></blockquote>
<p/><p>
We have said “wrap” not “sandwich” because although <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the “upper slice,” the part of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> with smaller terms—but there could be many of them—wraps around to be under the corresponding part of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. This fact will enable us to throw away the smaller clauses and terms. How small is “small”? We will say later. We are trying to solve problems of exposition by keeping a high-level view at the start. </p>
<p>
</p><p/><h2> Exposition Problems </h2><p/>
<p/><p>
Tim Gowers has written an <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.8986&amp;rep=rep1&amp;type=pdf">article</a> about the lower method for monotone functions. The method is due to Alexander Razborov in his seminal 1985 <a href="http://people.cs.uchicago.edu/~razborov/files/clique.pdf">paper</a> and extended by Noga Alon and Ravi Boppana in their <a href="https://core.ac.uk/download/pdf/191378189.pdf">paper</a> right afterward, and by Benjamin Rossman in his 2009 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5526&amp;rep=rep1&amp;type=pdf">paper</a>, to name a few. </p>
<p>
Gowers says right away that the original papers on this method are clear and well written. But he believes that there is need for more exposition. The method is so important that it must be made easy for all to understand. He says his article is an attempt to solve an <i>open exposition problem</i>. The notion of an exposition problem is due to Timothy Chow who <a href="https://arxiv.org/pdf/0712.1320.pdf">wrote</a>:</p>
<blockquote><p><b> </b> <em> All mathematicians are familiar with the concept of an open research problem. I propose the less familiar concept of an open exposition problem. </em>
</p></blockquote>
<p/><p>
Chow raised this issue with respect to the forcing method in set theory due to Paul Cohen. A modest suggestion: Read Chow on forcing, a great exposition; read Gowers on the monotone lower bound method, another great one. Both are much better than anything we can do. But we will put our own spin on the lower bound method. And hope to add to the quest to solve the exposition problem. </p>
<p/><h2> The Method—High Level </h2><p/>
<p/><p>
Suppose that <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is a monotone boolean circuit that has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs and computes <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> at the last gate. The method is called the <i>approximation method</i> because the idea is that it builds two other boolean functions <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/>: for all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{\{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^{n}}"/>: </p>
<p align="center"><img alt="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Blower%7D%28x%29+%5Cle+f%28x%29+%5Cle+%5Cmathsf%7Bupper%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). "/></p>
<p>This follows a tradition in math that we often replace a complex function, <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>, with simpler upper and lower bounds. Standard stuff. </p>
<p>
Usually the point is that the approximators are not only easier to understand but also simpler in some objective sense. For example, Christophe Chesneau and Yogesh Bagul give a nice short <a href="https://hal.archives-ouvertes.fr/hal-01934571/document">compendium</a> of approximating formulas involving trigonometric functions by formulas without them, including that for all <img alt="{0&lt;x&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cx%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;x&lt;1}"/>, </p>
<p align="center"><img alt="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexp%28-bx%5E%7B2%7D%29+%3C+%5Csin%28x%29%2Fx+%3C+%5Cexp%28-x%5E%7B2%7D%2F6%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), "/></p>
<p>with <img alt="{b \approx 0.172604}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Capprox+0.172604%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \approx 0.172604}"/>. If you have to reason about the behavior of <img alt="{\sin(x)/x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csin%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sin(x)/x}"/>, it is nice to have these upper and lower bounds. Note that the upper bound kind-of wraps around because it is the same kind of function as the lower bound.</p>
<p>
What gives the monotone method a special twist is that <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/> are not necessarily simple in the sense of being small.  Rather, they <em>make simple errors</em>—ones that can be corrected with small effort. The correction process yields <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r.}"/>  Isolating what is small, however, requires us to trade an “AND” of two inequalities for an “OR” of two economical ones. We know that at least one of the latter inequalities must be true. We arrange that either one gives us the kind of lower bound we seek. </p>
<p>
</p><p/><h2> Some More Detail </h2><p/>
<p/><p>
Here is how the trade happens. From Theorem <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> we have: </p>
<p align="center"><img alt="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cwedge+C%5E%7B%3Cs%7D+%5Cleq+f+%5Cleq+D%5E%7B%3Cr%7D+%5Cvee+D%5Er%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, "/></p>
<p>where: <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> are small, and while <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> might be big, we have <img alt="{D^{&lt;r} \leq C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r} \leq C^{&lt;s}}"/>. The trick is to ask:</p>
<blockquote><p><b> </b> <em> Is <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> empty—that is, is it the trivial <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> function? </em>
</p></blockquote>
<p>
</p><ul>
<li>
If <em>yes</em>, then it goes away on the left-hand side. We get: <p/>
<p align="center"><img alt="\displaystyle  C^s \leq f. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cleq+f.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \leq f. "/></p>
<p>Since <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> is small, this is something we want. We got a small lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that holds for <b>all</b> arguments <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. </p>
</li><li>
If <em>no</em>, then it has a nontrivial clause corresponding to a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s-1}"/>. This is where the wraparound comes in. We have: <p/>
<p align="center"><img alt="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D+%5Cleq+E%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, "/></p>
<p>since we chose at least one clause. Substituting on the right-hand side thus gives us: </p>
<p align="center"><img alt="\displaystyle  f \leq E \vee D^r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cleq+E+%5Cvee+D%5Er.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \leq E \vee D^r. "/></p>
<p>Now <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> is small, since it is just one clause, and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> is small. We got a small upper bound rather than lower bound, but the fact that it has a restricted form and holds for <b>all</b> cases we can input to <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> will give us a lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>.
</p></li></ul>
<p>
Finally we are ready to state the theorem, which quantifies “small.” To follow Jukna, we now need to replace “<img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>” by “<img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r+1}"/>” and “<img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>” by “<img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.” But the essence is the same.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="tsimple"/> If <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has a monotone Boolean circuit of size <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>, then for any <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s}"/> such that <img alt="{1 \leq r,s \leq n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+r%2Cs+%5Cleq+n-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \leq r,s \leq n-1}"/>, we can build a conjunction <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of at most <img alt="{t \cdot r^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+r%5E%7Bs%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot r^{s+1}}"/> clauses of size exactly <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s+1}"/>, a disjunction <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of at most <img alt="{t \cdot s^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+s%5E%7Br%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot s^{r+1}}"/> terms of size exactly <img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r+1}"/>, and a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> such that either <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C \leq f}"/> or <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. </em>
</p></blockquote>
<p/><p>
Rather than re-prove this, we will continue the discussion with a concrete example. An exposition trick is: give examples before the general case and then abstract. Our example will involve graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>—so the variables have the form <img alt="{x_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j}}"/>, where <img alt="{x_{i,j} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 1}"/> means there is an edge between vertex <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and vertex <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/>, <img alt="{x_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 0}"/> otherwise. Putting <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> as the number of vertices, the number of possible edges is <img alt="{n = \binom{m}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%5Cbinom%7Bm%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = \binom{m}{2}}"/>. We think of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> as a set of edges, so <img alt="{G \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \subseteq [n]}"/>.</p>
<p>
</p><p/><h2> Checking for Triangles </h2><p/>
<p/><p>
Let <img alt="{f(G)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)=1}"/> hold precisely when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> has a triangle. This is clearly a monotone property. Our goal is to use the lower and upper bounds to prove that the monotone complexity of <img alt="{f(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)}"/> is almost of order <img alt="{m^{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m^{3}}"/>. A side note is that the general complexity is much less via <img alt="{m \times m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times m}"/> matrix products. </p>
<p>
The first beauty of using the method is that <em>you</em> get to choose the parameters <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> with a goal <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in mind. The <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> must be in <img alt="{[1,n-1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B1%2Cn-1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[1,n-1]}"/>. The value of <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> will be a lower bound on the size of any monotone boolean circuit for <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. The parameters <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r,s}"/> are bounds on the clause and term size of the DNF and the CNF. You can select them any way you wish. But of course choose them wisely.</p>
<p>
In this case we know that <img alt="{r=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r=1}"/> is a right choice. We will say what <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> is later but we will have <img alt="{s=(\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%3D%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s=(\log n)^{O(1)}}"/>. Once you pick them, the CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> and DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> (and small set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/>, a set of <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log n)}"/> edges in this case) are chosen for you. You have no control over the sets <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> that make up the terms of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> and the sets <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> that correspond to the clauses of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Well you do know something about them. Here is what you do know about how many sets there are and how big the sets are:</p>
<ol>
<li>
For <img alt="{k=1,\dots,t \cdot s^{r+1} = ts^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%2C%5Cdots%2Ct+%5Ccdot+s%5E%7Br%2B1%7D+%3D+ts%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1,\dots,t \cdot s^{r+1} = ts^2}"/>, each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is of size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. <p/>
</li><li>
For <img alt="{\ell=1,\dots, t \cdot r^{s+1} = t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%3D1%2C%5Cdots%2C+t+%5Ccdot+r%5E%7Bs%2B1%7D+%3D+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell=1,\dots, t \cdot r^{s+1} = t}"/>, each <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> is of size <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.
</li></ol>
<p>The goal in either case is to force <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> to be large. We’ve numbered the right-hand case first.</p>
<ol>
<li>
Case <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> that <b>do</b> have a triangle—and nothing else. Because <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> includes at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> edges, hence touches at most <img alt="{2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s}"/> vertices, and <img alt="{2s \ll m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s+%5Cll+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s \ll m}"/>, we can focus on triangles among the <img alt="{m' = m - 2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%27+%3D+m+-+2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m' = m - 2s}"/> untouched vertices. There are <img alt="{T = \binom{m'}{3} = \Theta(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5Cbinom%7Bm%27%7D%7B3%7D+%3D+%5CTheta%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \binom{m'}{3} = \Theta(m^3)}"/> such triangles, hence <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> to consider.<p/>
<p>
Since these graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> have no edges in <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> but make <img alt="{f(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 1}"/>, there must be some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> such that <img alt="{T_k(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k(G) = 1}"/>. Since <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, this means <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has two edges of the triangle. Now the point is:</p>
<blockquote><p><b> </b> <em> For each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/>, there is at most <b>one</b> triangle that <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/> can be two edges of. </em>
</p></blockquote>
<p/><p>
Hence there must be at least as many terms as possible triangles. This means: </p>
<p align="center"><img alt="\displaystyle  ts^2 \geq \binom{m'}{3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++ts%5E2+%5Cgeq+%5Cbinom%7Bm%27%7D%7B3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  ts^2 \geq \binom{m'}{3}. "/></p>
<p>Because <img alt="{s = (\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs+%3D+%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s = (\log n)^{O(1)}}"/>, we finally get <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/>, where the tilde means to ignore factors of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>.</p>
<p/></li><li>
Case <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> such that <img alt="{f(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 0}"/> but <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is chock full of as many edges as one can have without creating a triangle. Such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> include complete bipartite graphs. There are <img alt="{2^{m-1} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm-1%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m-1} - 1}"/> such graph inputs, as can be realized from how any binary string <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> except <img alt="{0^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^m}"/> and <img alt="{1^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1^m}"/> encodes such a graph—and only its bit-complement <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> encodes the same labeled graph.<p/>
<p>
In order to keep <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/> we need <img alt="{C(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(G) = 0}"/> for all such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>, so we need (at least) one clause <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> to <em>fail</em> on <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. This means that all vertices touched by the edges in <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> must be in the same partition. The more vertices touched, the fewer strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> have all <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s (or all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>s) in the corresponding positions, which means the fewer graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> “covered” by that clause. We want to know how many clauses we need to cover all these graphs, hence we try to minimize the number of vertices touched by each clause. That number is at least <img alt="{s' = \lceil \sqrt{2s}\rceil}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3D+%5Clceil+%5Csqrt%7B2s%7D%5Crceil%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' = \lceil \sqrt{2s}\rceil}"/>. The number of graphs we cover is at most <img alt="{2^{m - s'} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm+-+s%27%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m - s'} - 1}"/> (the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> excludes the empty graph). Thus the number <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> of clauses we need satisfies </p>
<p align="center"><img alt="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%5Cgeq+%5Cfrac%7B2%5E%7Bm-1%7D+-+1%7D%7B2%5E%7Bm+-+s%27%7D+-+1%7D+%5Cgeq+2%5E%7Bs%27+-+1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. "/></p>
<p>By taking <img alt="{s' &gt; 4.5\log^2 m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3E+4.5%5Clog%5E2+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' &gt; 4.5\log^2 m}"/> we can make <img alt="{t \geq m^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Cgeq+m%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t \geq m^3}"/> in this case. We can actually get bigger functions with bigger <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, but this balances against case 1 where <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/> was the best we could do, so that is our lower bound.
</p></li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in understanding the approximation method? Can you work out the concretely optimum choice of <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the triangle example?</p>
<p>
Would you prefer not changing <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a>? Then we would have worded the triangle example with “<img alt="{r = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 2}"/>” rather than “<img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/>.” The former is a little more suggestive of the idea of having two edges of a triangle. Doing so, however, could make notation in the proof of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a> somewhat messier. Another possibility was keeping Jukna’s usage throughout, so that the earlier version <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> of the theorem would say <img alt="{D^{\leq r} \leq C^{\leq s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%5Cleq+r%7D+%5Cleq+C%5E%7B%5Cleq+s%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{\leq r} \leq C^{\leq s}}"/> with <img alt="{C^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7Bs%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{s+1}}"/> and <img alt="{D^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7Br%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{r+1}}"/> being small. We try to solve “exposition problems” in every post but feel a dilemma here. Comments might help us on a followup post. </p>
<p/></font></font></div>
    </content>
    <updated>2020-07-27T06:39:13Z</updated>
    <published>2020-07-27T06:39:13Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="Alexander Razborov"/>
    <category term="approximation"/>
    <category term="Boolean functions"/>
    <category term="circuits"/>
    <category term="complexity"/>
    <category term="exposition problems"/>
    <category term="lower bounds"/>
    <category term="monotone"/>
    <category term="Stasys Jukna"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-08T20:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3389282706697250678</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3389282706697250678/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html" rel="alternate" type="text/html"/>
    <title>Do computers make us more safe or less safe?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Norbert Weiner wrote a paper <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/moral.pdf">Some Moral and Technical Consequences of Automation</a> in 1960. It warns of the dangers of computers in two ways:<br/>
<br/>
1) If a chess program is only trained against expert chess players then it might get confused if its opponent makes a bad move. This is not dangerous. But imagine a nuclear missle system that assumes the opponent is rational. If the opponent is not rational then it might launch and have an accidental nuclear war. So <i>there must be a human component </i>so that this won't happen.<br/>
<br/>
I offer a story and a counter narrative. In the 5th season, 23rd episode of the TV show Castle,<br/>
title <i>The Human Factor </i>a character had the following story to tell:<br/>
<i><br/>
The drone on its own was going to bomb a car. But the human noticed that there were red roses on the car, so it was a wedding couple, not a terrorist. If a human had not been involved the drone may have killed an innocent just married couple!</i><br/>
<br/>
This scene bothered me. It could EASILY be the other way around: the human wants to bomb and the drone (which has better vision) notices the roses. Or there may be many other ways that a computer could be BETTER than a human. I am not saying that a completely automated system is better, I am saying that its not obvious which way to go.  Both in some combination? What combination? Who has the final say? And in the drone scenario there may not be time for a human to consider the options.<br/>
<br/>
2) The Sorcerer's apprentice scenario. In The Sorcerer's Apprentice segment of the (original) movie Fantasia, Mickey mouse tells a broom to get him a glass of water. The broom keeps bringing him water and Mickey almost drowns. Computers may take orders to literally and not stop. I wonder if  automated stock-trading and automated auctions may have this problem. Is there a case known where this really did cause a problem?<div><br/></div><div>So what do you think?</div><div><br/></div><div>NOW- do computers (or, more generally technology) make us more safe or less safe?</div><div><br/></div><div>FUTURE- same question.</div></div>
    </content>
    <updated>2020-07-27T03:18:00Z</updated>
    <published>2020-07-27T03:18:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-08T16:35:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/07/27/discrete-fragility/</id>
    <link href="http://benjamin-recht.github.io/2020/07/27/discrete-fragility/" rel="alternate" type="text/html"/>
    <title>Digital Witnesses</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Doyle derived his LQG counterexample in the time before the ubiquity of numerical computing. This meant that numerical examples did not carry the rhetorical weight of algebraic closed form instances. The need for clean, persuasive formulae also meant that controllers were idealized in continuous time. Continuous-time optimal control often produced policies that couldn’t be implemented because of the limits of physical reality: no system can act instantaneously with arbitrary power. These issues of infeasibility were <a href="https://ieeexplore.ieee.org/document/1099822/">certainly noted in the literature</a> during the hey day of optimal control, but continuous time models still often made it difficult to pinpoint these issues.</p>

<p>Discrete-time models don’t share many of these issues. In discrete time, we explicitly encode the sequential, computational nature of decision and control. Discrete-time formulae are unfortunately less elegant than their continuous-time counterparts, but, as I hope to show here, they are often more revealing. Indeed, constructing examples where discrete-time optimal control leads to fragile solutions seems to be surprisingly easy.</p>

<p>Here, I’ll highlight a few examples where relatively innocuous problem formulations lead to very fragile control policies. The examples are weirdly simple and almost comical to a point. But anyone who has played with discrete-time optimal control may have stumbled into similar control policies and had to step back and think about why.</p>

<p>Let’s revisit the discrete-time LQR problem:</p>



<p>We again assume $x_t$ is observed perfectly without noise. While such perfect state information is not realistic, even ideal state feedback ends up being fragile in discrete time. $w_t$ is assumed to be stochastic, but I don’t think much changes if we move to a more adversarial setting. Here, we need the decision variable $u_t$ to be <em>causal</em>. It must be a function of only the values $x_s$ and $u_s$ with $s\leq t$. For stochastic disturbances, the optimal $u$ can always be found by dynamic programming.</p>

<p>Consider the following innocuous dynamics:</p>



<p>This system is a simple, two-state shift register. I’ll write the state out with indexed components $x=[x^{(1)},x^{(2)}]^\top$. New states enter through the control $B$ into the second state. The first state, $x^{(1)}$ is simply whatever was in the second register at the previous time step. The open loop dynamics of this system are as stable as you could imagine. Both eigenvalues of $A$ are zero.</p>

<p>Let’s say our control objective aims to try to keep the two states equal to each other. We can model this with the quadratic cost:</p>



<p>I assume $R=0$ here for simplicity, as the formulae are particularly nice for this case. But, as I will discuss in a moment, the situation is not improved simply by having $R$ be positive. For the disturbance, assume that $w_t$ is zero mean, has bounded second moment, $\Sigma_t = \mathbb{E}[w_t w_t^\top]$, and is uncorrelated with $x_t$ and $u_t$.</p>

<p>The cost is asking to minimize</p>



<p>When $w_t=0$, $x_t^{(1)}+x_t^{(2)} = x_{t-1}^{(2)}+u_{t-1}$, so it seems like our best bet is to just set $u_{t}=x_t^{(2)}$. This turns out to be the optimal action, and you can prove this directly using standard dynamic programming computations. What this means is that the closed loop dynamics of the system are</p>



<p>This closed-loop system is <em>marginally stable</em>, meaning that while signals don’t blow up, some states will persist forever and not converge to $0$. Indeed, the state-transition matrix here has eigenvalues $0$ and $1$. The $1$ corresponds the state where the two components are equal, and such a state can persist forever.</p>

<p>If we learned an incorrect model of the dynamics, how would that influence the closed loop behavior? The simplest scenario is that we identified $B$ from some preliminary experiments. We can immediately see that if the true $B_\star=\alpha B $, then the closed loop dynamics are</p>



<p>This system is unstable for any $\alpha&gt;1$. That is, the system is arbitrarily sensitive to misidentification of the dynamics. Note that this lack of robustness has nothing to do with the noise sequence. The structure of the cost is what drives the system to fragility.</p>

<p>If $R&gt;0$, you will get a slightly different policy. Again, using elementary dynamic programming shows that the optimal control is $u_t=\beta_t(R) x_t^{(2)}$ for some $\beta_t(R) \in (1/2,1)$. The closed loop system will be a bit more stable, but this comes at the price of reduced performance. And, at best, the gain margin of this system approaches $2$ as $R$ goes to infinity. You can also check that if you add $\epsilon$ times the identity to $Q$, you again get a control policy proportional to $x_t^{(2)}$.</p>

<p>This behavior can occur in even simpler systems. Consider the one-state linear system</p>



<p>The open loop system is again as stable as it gets. Now let’s aim to minimize $\Vert x-u \Vert$. It doesn’t matter what norm you choose here or whether you treat the noise as stochastic or worst case with respect to $w$, the optimal control is going to be $u_t = x_t/b$. Once again, the closed loop system has a pole at $1$ and is arbitrary fragile to misspecification of $b$.</p>

<p>I could continue to construct nasty examples, but I hope these examples are sufficiently illustrative. They are certainly contrived and pathological, and it’s not at all clear that they reflect any optimal control problem you might have been hoping to solve. However, both examples involve systems that are robust and stable in open loop. It’s only when we close the feedback loop that we end up in a dangerous situation. That simple optimal control problems give some profoundly fragile solutions should be a clear warning: <em>You can’t just optimize and hope to be robust.</em> You have to consider uncertainty as a first class citizen when designing feedback systems.</p>

<p>In some sense, the core contribution of robust control is in raising awareness of fundamental tradeoffs in the design of feedback systems. Optimal control promises that you can roughly identify a system, model uncertainty as noise, solve an optimization problem,  and then ship your policy. Hopefully, the examples in the last two posts have shown why this particular approach is fraught with danger.</p>

<p>If failure of a feedback system has any consequences, then a more holistic robust approach is <em>necessary</em>. We have to work with experts at different levels of the engineering pipeline, worry about unmodeled behaviors, and understand hard limits and practical tradeoffs. That is, engineering has to be more concerned with <em>design</em> than with <em>optimization.</em></p>

<p>There are all sorts of questions that a robust, systems level engineering effort might ask. Where should you put that extra sensor? Which parts of the system are likely to create issues? Is it possible to avoid performance disruptions when updating a single component in a legacy system? These questions are important in all aspects of system engineering, and developing accessible tools for addressing them in machine learning systems remains a daunting but essential challenge.</p>

<p>I am emphatically not saying that the design of feedback systems is hopeless. It’s easy to walk away with the impression “Ben’s examples are pathologies and unlike what I see in practice” or the pessimistic feeling of “shoot, all of this ML stuff is hopeless, I’m going to go work on something tractable like vaccine development.” I’m not saying that engineering robust machine learning systems is hopeless. I’m just saying that our community has to work better to incorporate multiple levels of uncertainty in its thinking. What are the fundamental tradeoffs between performance and robustness in machine learning? What do we even want to be robust to? In the next post I want to describe some of these robustness tradeoffs without using the language of optimization, probing if that provides some possible paths forward.</p></div>
    </summary>
    <updated>2020-07-27T00:00:00Z</updated>
    <published>2020-07-27T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-08-07T23:37:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/" rel="alternate" type="text/html"/>
    <title>Private Set Intersection #2</title>
    <summary>In the first post on Private Set Intersection, I presented the problem of Private Set Intersection, its applications and the simple protocol of [KMRS14], that allows Alice and Bob to learn the intersection of their sets with the aid of an untrusted third party Steve who is assumed to not...</summary>
    <updated>2020-07-26T23:00:00Z</updated>
    <published>2020-07-26T23:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-08-07T23:38:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/111</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/111" rel="alternate" type="text/html"/>
    <title>TR20-111 |  Lifting: As Easy As 1,2,3 | 

	Ian Mertz, 

	Toniann Pitassi</title>
    <summary>Query-to-communication lifting theorems translate lower bounds on query complexity to lower bounds for the corresponding communication model. In this paper, we give a simplified proof of deterministic lifting (in both the tree-like and dag-like settings). Whereas previous proofs used sophisticated Fourier analytic techniques, our proof uses elementary counting together with the sunflower lemma.</summary>
    <updated>2020-07-25T05:05:34Z</updated>
    <published>2020-07-25T05:05:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-08T20:20:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8081773524220393104</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8081773524220393104/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8081773524220393104" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8081773524220393104" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html" rel="alternate" type="text/html"/>
    <title>Virtual Complexity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The <a href="https://computationalcomplexity.org/Archive/2020/fullsite/">Complexity Complexity Conference</a>, the conference that shares its name and URL with this blog, originally scheduled for Saarbrücken will be held virtually next week. Registration is free for non-authors. <a href="https://www.youtube.com/channel/UCXgNLnzWOP4bM2-xfHDHUrw">Talks</a> are already posted. Looking forward to seeing you at the business meeting and the social.<br/>
<div>
<br/></div>
<div>
<div>
Award winners have already been announced: The Best Student Paper Award goes to Rahul Ilango for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12583/">Connecting Perebor Conjectures: Towards a Search to Decision Reduction for Minimizing Formulas</a> and the Best Paper Award goes to Daniel Dadush and Samarth Tiwari for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12586/">On the Complexity of Branching Proofs</a>.</div>
</div>
<div>
<br/></div>
<div>
Virtual conferences give an opportunity for far more people to attend since you don't have the expense and time needed to go to Germany. On the other hand it's hard to dedicate time for a conference when you aren't there. I missed STOC which would have been walking distance from where I live but I did attend parts of the <a href="http://ec20.sigecom.org/">Economics and Computation</a> conference which was supposed to be in Budapest. EC made great use of <a href="http://gather.town/">gather.town</a> where you can wander around virtual rooms bumping into and talking to people. I caught up with a few people there. Complexity plans to use gather for its social meeting next week. Looking forward to the virtual beer.</div></div>
    </content>
    <updated>2020-07-24T16:21:00Z</updated>
    <published>2020-07-24T16:21:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-08T16:35:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19859</id>
    <link href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/" rel="alternate" type="text/html"/>
    <title>Noam Lifshitz: A new hypercontractivity inequality — The proof!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a guest post kindly contributed by Noam Lifshitz. Here is a pdf version.  This post is a continuation of the post  To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new … <a href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is a guest post kindly contributed by Noam Lifshitz</em>. <em>Here is a <a href="https://gilkalai.files.wordpress.com/2020/07/proof-of-hypercontractivity.pdf">pdf version</a>.  This post is a continuation of the post  </em><a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="bookmark">To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</a>, <em>and it gives the proof of the new hypercontractive inequality. We plan a third post where various applications will be mentioned.</em></p>
<p>Before we get to the post I want to mention that there are a lot of activities on the web. I may devote a special post to links and discussion (and contributing links in the comment section is very welcome.) but meanwhile a few links:  1) <a href="https://simons.berkeley.edu/events/boolean">Advances in Boolean Function Analysis Lecture Series</a> (thanks to Avishay Tal and Prasad Raghavendra for letting me know); 2) <a href="https://math216.wordpress.com/agittoc-2020/">Online course in Foundations of Algebraic Geometry</a> Given by Ravi Vakil from Stanford. You can take the course at varying levels of involvement. (Thanks to Tami Ziegler for telling me) A very very interesting way of online teaching. 3) <a href="https://researchseminars.org/">A site with online mathematical lectures.</a></p>
<h2><img alt="Bonami" class="alignnone size-full wp-image-19984" height="480" src="https://gilkalai.files.wordpress.com/2020/07/bonami.jpg?w=640&amp;h=480" width="640"/></h2>
<p><span style="color: #ff0000;">Aline Bonami with Szilard Revesz and me (2006). Aline Bonami first proved the 2-point hypercontractive inequality which is very useful in the analysis of Boolean functions. (Leonard Gross proved it independently a few years later and William Beckner found important applications to harmonic analysis.)</span></p>
<h2>Proof of the new hypercontractivity inequality</h2>
<p>Our aim is to prove the hypercontractivity theorem for global functions. The proof here is taken from a joint paper with David Ellis and Guy Kindler that’ll soon be out on the Arxiv.</p>
<h3><strong>Theorem 1:</strong></h3>
<p><img alt="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, "/></p>
<p>Here we use the notations given in the <a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/">last blog post</a>. Let us first get a feel for our hypercontractivity theorem by proving the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case. Here the RHS is <img alt="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}"/></p>
<h3>1. Proof of the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case</h3>
<p>We will prove the following slightly stronger version of Theorem 1 for the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case.</p>
<p><strong>Proposition 2:</strong></p>
<p>Let <img alt="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5Crightarrow%5Cmathbb%7BC%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}"/> Let <img alt="{\rho\le\frac{1}{10}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}.}"/> Then<br/>
<img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. "/></p>
<p style="text-align: left;"><strong>Proof</strong>: Let us write <img alt="{L\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L\left[f\right]}"/> for <img alt="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B1%7D%5Cleft%5Bf%5Cright%5D%3Df-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}"/> Rearranging, we have<br/>
<img alt="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2BL%5Cleft%5Bf%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. "/><br/>
The noise operator in the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case is by definition equal to <img alt="{\rho Id+\left(1-\rho\right)\mathbb{E},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho+Id%2B%5Cleft%281-%5Crho%5Cright%29%5Cmathbb%7BE%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho Id+\left(1-\rho\right)\mathbb{E},}"/> where <img alt="{\mathbb{E}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{E}}"/> is the expectation over <img alt="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}"/> operator, and <img alt="{Id}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BId%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Id}"/> is the identity operator. Hence,<br/>
<img alt="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Crho+L%5Bf%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. "/></p>
<p>Now when expanding the 4-norm of the function <img alt="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}"/>, we obtain</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\left|\mathbb{E}\left[f\right]\right|^{4}"/><br/>
<img alt="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B6%5Crho%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CLf%5C%7C_%7B2%7D%5E%7B2%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+"/><br/>
<img alt="\displaystyle&#xA0; +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%2B4%5Crho%5E%7B3%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+"/><br/>
<img alt="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B+%5Crho%5E%7B4%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4},"/></p>
<p>where we used the fact that the expectation of <img alt="{L\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L\left[f\right]}"/> is 0. When looking at the right hand side of the global hypercontractivity theorem, we see most of the above terms except for the one involving the third norm of the Laplacian. Indeed we have</p>
<p style="text-align: center;"><img alt="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+RHS+%3D%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}"/><br/>
<img alt="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}"/><br/>
<img alt="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B2%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}"/><br/>
<img alt="\displaystyle +\|L\left[f\right]\|_{2}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +\|L\left[f\right]\|_{2}^{4}"/><br/>
<img alt="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%5C%7C%7D%7D_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}."/></p>
<p>Hence we see that the only term in the left hand side that doesn’t appear with a greater coefficient in the left hand side is the term <img alt="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}"/> and by AM-GM we have</p>
<p style="text-align: center;"><img alt="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}"/> <img alt="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B3%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]"/><br/>
<img alt="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cle%5Cmathbb%7BE%7D%5Cleft%5B%5Cfrac%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%2B%5Cleft%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%7D%7D%5Cright%7C%5E%7B4%7D%7D%7B2%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]"/><br/>
<img alt="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cfrac%7B1%7D%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%2B%5Cfrac%7B1%7D%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, "/></p>
<p>which allows us to upper bound the only term appearing in the left hand side but not in the right hand side by corresponding terms that do appear in the right hand side. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<h3>2. Tensorisation lemma</h3>
<p>Next we are going to prove a theorem that doesn’t seem to fit to our setting, but we’re going to fit it in by force. Let <img alt="{X,Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,Y}"/> be finite sets. Let us write <img alt="{\mathcal{F}\left(X\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\right)}"/> for the linear space of complex valued functions on <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. The space <img alt="{\mathcal{F}\left(X\times Y\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\times Y\right)}"/> can be identified with the space <img alt="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Cotimes%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}"/> where a pair of function <img alt="{f\otimes g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\otimes g}"/> is identified with the function<br/>
<img alt="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28x%2Cy%5Cright%29%5Cmapsto+f%5Cleft%28x%5Cright%29g%5Cleft%28y%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) "/><br/>
in <img alt="{\mathcal{F}\left(X\times Y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\times Y\right).}"/></p>
<p>Given two operators <img alt="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Cright%29%2CA_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}"/>, the operator <img alt="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Ctimes+X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Ctimes+Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}"/> is the unique operator sending <img alt="{f\otimes g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\otimes g}"/> to <img alt="{A_{1}f\otimes A_{2}g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7Df%5Cotimes+A_%7B2%7Dg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}f\otimes A_{2}g}"/>. We write <img alt="{A^{\otimes n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^{\otimes n}}"/> for <img alt="{A\otimes\cdots\otimes A.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes%5Ccdots%5Cotimes+A.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes\cdots\otimes A.}"/> The operator <img alt="{A_{1}\otimes A_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}}"/> can also be defined more explictly in terms of its values on functions. The operator <img alt="{A_{1}\otimes A_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}}"/> can be understood more explicitly by noting that it is the composition of the operators <img alt="{A_{1}\otimes I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes I}"/> and <img alt="{I\otimes A_{2}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%5Cotimes+A_%7B2%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I\otimes A_{2}.}"/> Now the operator <img alt="{A\otimes I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes I}"/> is given by <img alt="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+If%5Cleft%28x%2Cy%5Cright%29%3DAf_%7By%7D%5Cleft%28x%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}"/> where <img alt="{f_{y}\left(x\right)=f\left(x,y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%5Cleft%28x%5Cright%29%3Df%5Cleft%28x%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}\left(x\right)=f\left(x,y\right).}"/></p>
<p><strong>Lemma 3:</strong> Let <img alt="{X,Y,Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%2CZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,Y,Z}"/> be measure spaces with finite underlying sets. Let <img alt="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2CB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Z%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}"/> be operators satisfying</p>
<p style="text-align: center;"><img alt="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CAf%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} "/></p>
<p>for all functions <img alt="{f\in\mathcal{F}\left(X\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in\mathcal{F}\left(X\right).}"/><br/>
Then</p>
<p style="text-align: center;"><img alt="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CA%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} "/></p>
<p>for all <img alt="{f\in\mathcal{F}\left(X^{n}\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5E%7Bn%7D%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in\mathcal{F}\left(X^{n}\right).}"/></p>
<p>Here the spaces <img alt="{X^{n},Y^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%5E%7Bn%7D%2CY%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X^{n},Y^{n},}"/> and <img alt="{Z^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z^{n}}"/> are equipped with the product measure, where the measure of an atom is the product of the measures of its coordiates.</p>
<p><strong>Proof:</strong> For each <img alt="{y\in X,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%5Cin+X%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y\in X,}"/> let <img alt="{g_{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_{y}}"/> be given by <img alt="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%3A%3DA%5E%7B%5Cotimes%5Cleft%28n-1%5Cright%29%7Df%5Cleft%28%5Ccdot%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}"/> As mentioned <img alt="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7Df%5Cleft%28x%2Cy%5Cright%29%3DAg_%7By%7D%5Cleft%28x%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}"/> Hence by hypothesis, we have</p>
<p style="text-align: center;"><img alt="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathrm%7BA%7D%5E%7B%5Cotimes+n%7Df%5Cright%7C%5E%7B4%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]"/> <img alt="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CAg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}"/><br/>
<img alt="\displaystyle&#xA0; \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CBg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}"/><br/>
<img alt="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5C%7CA%5E%7B%5Cotimes+n-1%7D%5Cotimes+B%5C%7C_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}."/> We may now repeat the same process on each of the other coordinates to replace the <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>s by <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>s one by one. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<h3>3. The main idea: Fourifying the 2-norms.</h3>
<p>The strategy of our proof is to take the theorem</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, "/></p>
<p>which we established in the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case for <img alt="{\rho\le\frac{1}{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}}"/>, and to turn it into an essentially equivalent statement about 4-norms. We will then get a tensorised statement for general <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, which we will be able to convert back into our hypercontractivity theorem for global functions. Our idea is to encode our function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as a function <img alt="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5Ccolon%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}"/> satisfying</p>
<p style="text-align: center;"><img alt="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} "/></p>
<p>and</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%3D%5C%7Cf%5C%7C_%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. "/></p>
<p>The benefit of working with <img alt="{\mathrm{En}f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}f}"/> rather than <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is that in <img alt="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}"/> one may move between 4-norms and 2-norms by appealing to the hypercontractivity theorem there, which gives</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Ccirc%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D%5Cle%5C%7C%5Cmathrm%7BE%7Dnf%5C%7C_%7B2%7D%5Cle%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} "/></p>
<p>at the cost of some noise.</p>
<p>To define <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> we use Fourier analysis of Abelian groups. Let us briefly recall it. For simplicity let us assume that <img alt="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}"/> where <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is a prime. Let <img alt="{\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\omega}"/> be a <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>th root of unity. For any <img alt="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}"/> we have a character <img alt="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}"/> given by <img alt="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Cleft%28x%5Cright%29%3D%5Comega%5E%7B%5Cleft%5Clangle+%5Cgamma%2Cx%5Cright%5Crangle+%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}"/> The <img alt="{\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}}"/> are an orthonormal basis of <img alt="{\left(\mathbb{Z}/p\right)^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left(\mathbb{Z}/p\right)^{n}}"/> and we write <img alt="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3D%5Csum%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}"/>, where <img alt="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B%5Cgamma%7D%5Cright%5Crangle+.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}"/> Note that <img alt="{\chi_{0}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{0}}"/> is the constant function, and so we have</p>
<p style="text-align: center;"><img alt="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat%7Bf%7D%5Cleft%280%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B0%7D%5Cright%5Crangle+%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], "/></p>
<p>which gives</p>
<p style="text-align: center;"><img alt="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum%5Chat%7Bf%7D%5Cleft%28i%5Cright%29%5Cchi_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. "/></p>
<p>Our mission will first be to convert the <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>-norm of a function <img alt="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}"/> to the <img alt="{4-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4-}"/>norm of a different function.</p>
<p>We define an encoding operator <img alt="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}"/> by setting</p>
<p style="text-align: center;"><img alt="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%5Cmapsto%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum_%7Bi%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cp-1%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28i%5Cright%29x_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. "/></p>
<p>We have</p>
<p style="text-align: center;"><img alt="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7Cf%5C%7C_%7B2%7D%5E%7B2%7D%3D%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%5E%7B2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, "/></p>
<p>as the <img alt="{\chi_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{i}}"/> are orthonormal and so are the <img alt="{x_{i}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}.}"/> Moreover, <img alt="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D%3D%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}"/> by the Fourier formula for <img alt="{\mathrm{T}_{\rho}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}.}"/> Since <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>-norms are always smaller than 4-norms on probability spaces, we’ve got the following corollary of Proposition 2.</p>
<p><strong>Lemma 4.</strong> For all <img alt="{\rho\le\frac{1}{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}}"/> and all <img alt="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}"/> we have</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. "/></p>
<p>We now reach the final little trick. We define a measure space <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> whose underlying set is <img alt="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Csqcup%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7B%5Cleft%5C%7B+p-1%5Cright%5C%7D+%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}"/> and where the measure is given by <img alt="{\mu\left(i\right)=\frac{1}{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28i%5Cright%29%3D%5Cfrac%7B1%7D%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu\left(i\right)=\frac{1}{p}}"/> for <img alt="{i\in\mathbb{Z}/p\mathbb{Z}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5Cin%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i\in\mathbb{Z}/p\mathbb{Z}}"/> and <img alt="{\mu\left(x\right)=\frac{1}{2}^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28x%5Cright%29%3D%5Cfrac%7B1%7D%7B2%7D%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu\left(x\right)=\frac{1}{2}^{p-1}}"/> for <img alt="{x\in\left\{ -1,1\right\} ^{p-1}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left\{ -1,1\right\} ^{p-1}.}"/> We let <img alt="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}"/> be given by <img alt="{Bf=\mathrm{En}f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BBf%3D%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Bf=\mathrm{En}f}"/> on <img alt="{\left\{ -1,1\right\} ^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} ^{p-1}}"/> and letting it be <img alt="{f-\mathbb{E}\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f-\mathbb{E}\left[f\right]}"/> on <img alt="{\mathbb{Z}/p\mathbb{Z}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}.}"/> This way Lemma 4 takes the form <img alt="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}"/></p>
<h3>4. Tensorised operators</h3>
<p>The operator <img alt="{\mathrm{T}_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}}"/> on <img alt="{\mathbb{Z}/p\mathbb{Z}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}^{n}}"/> satisfies <img alt="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}"/> where the latter <img alt="{\mathrm{T}_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}}"/> refers to the noise operator on <img alt="{\mathbb{Z}/p.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p.}"/> The characters <img alt="{\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}}"/> satisfy <img alt="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%3D%5Cbigotimes%5Cchi_%7B%5Cgamma_%7Bi%7D%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}"/> and so we have the Fourier formula</p>
<p style="text-align: center;"><img alt="\displaystyle \mathrm{T}_{\rho}f&#xA0; =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%C2%A0+%3D%5Csum_%7B%5Cgamma%7D%5Crho%5E%7B%5C%23%5Cleft%5C%7B+i%3A%5Cgamma_%7Bi%7D%5Cne0%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \mathrm{T}_{\rho}f&#xA0; =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. "/></p>
<p>We also have</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Cbigotimes_%7Bi%5Cin+S%7D%5Cleft%28f%5Cmapsto+f-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%29%5Cotimes%5Cbigotimes_%7Bi%5Cnotin+S%7DId%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, "/></p>
<p>and so</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Csum_%7B%5Cgamma%3A%5Cgamma_%7Bi%7D%5Cne0%5Ctext%7B+for+all+%7Di%5Cin+S%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. "/></p>
<p>This will allow us to conclude that</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7DT_%7B%5Crho%7DL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. "/></p>
<p>We will also encounter the operator <img alt="{\mathrm{En}^{\otimes n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}^{\otimes n},}"/> which by abusing notation we also call <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> encodes</p>
<p style="text-align: center;"><img alt="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Csum_%7B%5Cgamma%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} "/></p>
<p>as the function <img alt="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7B%5Cgamma%7D%5Cwidehat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cprod_%7Bi%3D1%7D%5E%7Bn%7Dx_%7Bpi%2B%5Cgamma_%7Bi%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}"/> on <img alt="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}"/><br/>
Now finally we can get to the understanding of the operator <img alt="{B^{\otimes n}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%5E%7B%5Cotimes+n%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B^{\otimes n}.}"/> The space <img alt="{Y^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y^{n}}"/> is the disjoint union of <img alt="{2^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n}}"/> spaces of the form</p>
<p style="text-align: center;"><img alt="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. "/></p>
<p>By definition of the tensor product, for <img alt="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}"/> is the function</p>
<p style="text-align: center;"><img alt="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+B%5E%7Bn%7Df%5Cleft%28x%2Cy%5Cright%29%3D%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cleft%28y%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). "/></p>
<h3>5. Finishing the proof</h3>
<p><strong>Proof:</strong> Lemmas 3 and 4 yield:</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\|B^{\otimes n}f\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\|B^{\otimes n}f\|_{4}^{4}"/> <img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4},"/></p>
<p>for any <img alt="{\rho\le\frac{1}{10}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}.}"/> We now have</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B%5Crho%7D%7B%5Csqrt%7B3%7D%7D%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}"/> <img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%28%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%29%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Cleft%28%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4},"/><br/>
<img alt="\displaystyle&#xA0; \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}"/><br/>
<img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}."/></p>
<p>The first equality follows from the formula <img alt="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathrm%7BT%7D_%7B%5Crho%7DL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}"/> and the fact that <img alt="{\mathrm{T_{\rho}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT_%7B%5Crho%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T_{\rho}}}"/> commutes with the encoding. The inequality used hypercontractivity on the discrete cube. The last equality follows from the fact that the <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> operator preserves 2-norms. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-07-24T15:21:49Z</updated>
    <published>2020-07-24T15:21:49Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Guest blogger"/>
    <category term="Noam Lifshitz"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-08T20:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7779</id>
    <link href="https://windowsontheory.org/2020/07/24/ryan-odonnels-tcs-toolkit-and-other-resources/" rel="alternate" type="text/html"/>
    <title>Ryan O’Donnell’s “TCS Toolkit” and other resources</title>
    <summary>When I was in grad school a common advice for beginning grad students was to leaf through the (paper) STOC or FOCS proceedings to see papers that you are interested in. This is still a decent advice (and requires less physical strength these days 🙂 ) but papers are not always the best source for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>When I was in grad school a common advice for beginning grad students was to leaf through the (paper) STOC or FOCS proceedings to see papers that you are interested in. This is still a decent advice (and requires less physical strength these days <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> ) but papers are not always the best source for people starting out. More often than we’d like to, the author of the 10th paper on a topic writes it to the audience of people that read (in fact probably wrote) the previous 9 papers.</p>



<p>Talks often do a better job of giving an overview of the field, and one great resource is the <a href="https://simons.berkeley.edu/videos">videos</a> from the Simons Institute. If you want to get more in-depth information about a particular topic, it’s hard to beat the extended surveys in <a href="https://www.nowpublishers.com/TCS">Foundations and Trends in TCS</a>, as well as the related areas such as <a href="https://www.nowpublishers.com/MAL">Machine Learning</a> and <a href="https://www.nowpublishers.com/CIT">Information Theory</a>. </p>



<p>But if you are not yet sure what topic you’re interested in, or perhaps not even sure if you want to go to grad school, but you just know that you are interested in theory, there is now a new great resource. As I learned from <a href="https://twitter.com/BooleanAnalysis/status/1286658578049359873">Twitter</a>, Ryan O’Donnell has just finished his <a href="https://www.diderot.one/course/28/">TCS Toolkit course</a>. All 99(!) lectures are on <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube</a>.</p>



<p>The topics are the following (these links are to the handwritten notes, for the lecture videos see <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube channel</a>):</p>



<p><a href="https://www.diderot.one/course/28/chapters/1824/">1.   Course Overview, and How to TCS</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1881/">2.   Basic Asymptotics</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1889/">3.   Factorials and Binomial Coefficients</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1923/">4.   Central Limit Theorem</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1956/">5.   Chernoff Bounds</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1973/">6.   Computational Models</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1981/">7.   Fast Multiplication with the DFT</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1990/">8.   Analysis of Boolean Functions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2003/">9.   Quantum Computation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2037/">10.   Fields and Polynomials</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2038/">11.   Error-Correcting Codes</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2064/">12.   Derandomization</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2065/">13.   Spectral Graph Theory I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2094/">14.   Spectral Graph Theory II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2099/">15.   Spectral Graph Theory III</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2101/">15.1.   Cheeger’s Inequality (Spectral Graph Theory bonus)</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2112/">16.   Expander Graphs</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2149/">17.   Linear Programming I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2162/">18.   Linear Programming II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2173/">19.   The Ellipsoid Algorithm</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2190/">20.   CSPs and Approximation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2197/">21.   LP Hierarchies and Proof Systems</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2209/">22.   Treewidth</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2227/">23.   Communication Complexity</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2250/">24.   Information Theory</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2251/">25.   Cryptography</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2290/">26.   Hardness Assumptions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2291/">27.   The PCP Theorem</a></p>



<p>p.s. For giving a high level taste of theory to beginning undergraduates, a great resource is Aaronson’s <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing since Democritus</a> or <a href="https://www.math.ias.edu/avi/book">Wigderson’s Math and Computation</a> if they’re more math inclined. </p></div>
    </content>
    <updated>2020-07-24T14:34:02Z</updated>
    <published>2020-07-24T14:34:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-08-08T20:21:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4916</id>
    <link href="https://www.scottaaronson.com/blog/?p=4916" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4916#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4916" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Busy Beaver Frontier</title>
    <summary xml:lang="en-US">Update (July 27): I now have a substantially revised and expanded version (now revised and expanded even a second time), which incorporates (among other things) the extensive feedback that I got from this blog post. There are new philosophical remarks, some lovely new open problems, and an even-faster-growing (!) integer sequence. Check it out! A […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (July 27):</span></strong> I now have a <a href="https://www.scottaaronson.com/papers/bb.pdf">substantially revised and expanded version</a> (now revised and expanded even a second time), which incorporates (among other things) the extensive feedback that I got from this blog post.  There are new philosophical remarks, some lovely new open problems, and an <em>even-faster-growing</em> (!) integer sequence.  Check it out!</p>



<p/><hr/><p/>



<p>A life that was all covid, cancellations, and Trump, all desperate rearguard defense of the beleaguered ideals of the Enlightenment, would hardly be worth living.  So it was an exquisite delight, these past two weeks, to forget current events and write an <a href="https://www.scottaaronson.com/papers/bb.pdf">18-page survey article</a> about the <a href="https://en.wikipedia.org/wiki/Busy_beaver">Busy Beaver function</a>: the staggeringly quickly-growing function that probably encodes a huge portion of all interesting mathematical truth in its first hundred values, if only we could know those values or exploit them if we did.</p>



<p>Without further ado, here’s the title, abstract, and link:</p>



<blockquote class="wp-block-quote"><p><a href="https://www.scottaaronson.com/papers/bb.pdf"><strong>The Busy Beaver Frontier</strong></a><br/>by Scott Aaronson</p><p>The Busy Beaver function, with its incomprehensibly rapid growth, has captivated generations of computer scientists, mathematicians, and hobbyists.  In this survey, I offer a personal view of the BB function 58 years after its introduction, emphasizing lesser-known insights, recent progress, and especially favorite open problems.  Examples of such problems include: when does the BB function first exceed the Ackermann function?  Is the value of BB(20) independent of set theory?  Can we prove that BB(n+1)&gt;2<sup>BB(n)</sup> for large enough n?  Given BB(n), how many advice bits are needed to compute BB(n+1)?  Do all Busy Beavers halt on all inputs, not just the 0 input?  Is it decidable whether BB(n) is even or odd?</p></blockquote>



<p>The article is slated to appear soon in <em>SIGACT News</em>.  I’m grateful to Bill Gasarch for suggesting it—even with everything else going on, this was a commission I felt I couldn’t turn down!</p>



<p>Besides Bill, I’m grateful to the various Busy Beaver experts who answered my inquiries, to Marijn Heule and Andy Drucker for suggesting some of the open problems, to Marijn for creating a figure, and to Lily, my 7-year-old daughter, for raising the question about the first value of n at which the Busy Beaver function exceeds the Ackermann function.  (Yes, Lily’s covid homeschooling has included multiple lessons on very large positive integers.)</p>



<p>There are still a few days until I have to deliver the final version. So if you spot anything wrong or in need of improvement, don’t hesitate to leave a comment or send an email.  Thanks in advance!</p>



<p>Of course Busy Beaver has been an obsession that I’ve returned to many times in my life: for example, in that <a href="https://www.scottaaronson.com/writings/bignumbers.html">Who Can Name the Bigger Number?</a> essay that I wrote way back when I was 18, in <em><a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a></em>, in my <a href="https://www.scottaaronson.com/blog/?p=3445">public lecture at Festivaletteratura</a>, and in my <a href="https://www.scottaaronson.com/blog/?p=2725">2016 paper with Adam Yedidia</a> that showed that the values of all Busy Beaver numbers beyond the 7910<sup>th</sup> are independent of the axioms of set theory (Stefan O’Rear has since shown that independence starts at the 748<sup>th</sup> value or sooner).  This survey, however, represents the first time I’ve tried to take stock of BusyBeaverology <em>as a research topic</em>—collecting in one place all the lesser-known theorems and empirical observations and open problems that I found the most striking, in the hope of inspiring not just contemplation or wonderment but actual progress.</p>



<p>Within the last few months, the world of <em>deep mathematics that you can actually explain to a child</em> lost two of its greatest giants: <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Conway</a> (who died of covid, and who I <a href="https://www.scottaaronson.com/blog/?p=4732">eulogized here</a>) and <a href="https://en.wikipedia.org/wiki/Ronald_Graham">Ron Graham</a>.  One thing I found poignant, and that I didn’t know before I started writing, is that Conway and Graham <em>both</em> play significant roles in the story of the Busy Beaver function.  Conway, because most of the best known candidates for Busy Beaver Turing machines turn out, when you analyze them, to be testing variants of the notorious <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz Conjecture</a>—and Conway is the one who proved, in 1972, that the set of “Collatz-like questions” is Turing-undecidable.  And Graham because of <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a> from <a href="https://en.wikipedia.org/wiki/Ramsey_theory">Ramsey theory</a>—a candidate for the biggest number that’s ever played a role in mathematical research—and because of the <a href="https://googology.wikia.org/wiki/User_blog:Wythagoras/The_nineteenth_Busy_Beaver_number_is_greater_than_Graham%27s_Number!">discovery</a>, four years ago, that the 18<sup>th</sup> Busy Beaver number exceeds Graham’s number.</p>



<p>(“Just how big is Graham’s number?  So big that the <em>17<sup>th</sup> Busy Beaver number</em> is not yet known to exceed it!”)</p>



<p>Anyway, I tried to make the survey pretty accessible, while still providing enough technical content to sink one’s two overgrown front teeth into (don’t worry, there are no such puns in the piece itself).  I hope you like reading it at least 1/BB(10) as much as I liked writing it.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (July 24):</span></strong> Longtime commenter Joshua Zelinsky gently reminded me that one of the main questions discussed in the survey—namely, whether we can prove BB(n+1)&gt;2<sup>BB(n)</sup> for all large enough n—was <a href="https://www.scottaaronson.com/blog/?p=1385#comment-73298">first brought to my attention</a> by him, Joshua, in a 2013 Ask-Me-Anything session on this blog!  I apologize to Joshua for the major oversight, which has now been corrected.  On the positive side, we just got a powerful demonstration <em>both</em> of the intellectual benefits of blogging, and of the benefits of sharing paper drafts on one’s blog before sending them to the editor!</p></div>
    </content>
    <updated>2020-07-23T06:42:48Z</updated>
    <published>2020-07-23T06:42:48Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-31T21:10:53Z</updated>
    </source>
  </entry>
</feed>
