<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-21T00:22:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07036</id>
    <link href="http://arxiv.org/abs/2004.07036" rel="alternate" type="text/html"/>
    <title>Connecting the Dots: Discovering the "Shape" of Data</title>
    <feedworld_mtime>1587427200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Michelle.html">Michelle Feng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hickok:Abigail.html">Abigail Hickok</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kureh:Yacoub_H=.html">Yacoub H. Kureh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porter:Mason_A=.html">Mason A. Porter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Topaz:Chad_M=.html">Chad M. Topaz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07036">PDF</a><br/><b>Abstract: </b>Scientists use a mathematical subject called topology to study the shapes of
objects. An important part of topology is counting the numbers of pieces and
holes in objects, and people use this information to group objects into
different types. For example, a doughnut has the same number of holes and the
same number of pieces as a teacup with one handle, but it is different from a
ball. In studies that resemble activities like "connect the dots", scientists
use ideas from topology to study the shape of data. Data can take many possible
forms: a picture made of dots, a large collection of numbers from a scientific
experiment, or something else. The approach in these studies is called
\emph{topological data analysis}, and it has been used to study the branching
structures of veins in leaves, how people vote in elections, flight patterns in
models of bird flocking, and more. Scientists can take data on the way veins
branch on leaves and use topological data analysis to divide the leaves into
different groups and discover patterns that may otherwise be hard to find.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4768</id>
    <link href="https://www.scottaaronson.com/blog/?p=4768" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4768#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4768" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AirToAll: Another guest post by Steve Ebin</title>
    <summary xml:lang="en-US">Scott’s foreword: Today I’m honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a beautiful essay here a month ago (the one that I titled “First it came from Wuhan”), but also posted an extremely informative timeline of what he understood when about the severity of the covid crisis, from […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Scott’s foreword:</span></strong> Today I’m honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a <a href="https://www.scottaaronson.com/blog/?p=4675">beautiful essay</a> here a month ago (the one that I titled “First it came from Wuhan”), but also posted an extremely informative <a href="https://www.scottaaronson.com/blog/?p=4695#comment-1834991">timeline</a> of what he understood when about the severity of the covid crisis, from early January until March 31st.  By the latter date, Steve had quit his job, having made a hefty sum shorting airline stocks, and was devoting his full time to a new nonprofit to manufacture low-cost ventilators, called AirToCall.  A couple weeks ago, Steve was kind enough to include me in one of AirToAll’s regular Zoom meetings; I learned more about pistons than I had in my entire previous life (admittedly, still not much).  Which brings me to what Steve wants to talk about today: what he and others are doing and how <em>you</em> can help.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Without further ado, Steve’s guest post:</span></strong></p>



<p>In my <a href="https://www.scottaaronson.com/blog/?p=4675">last essay</a> on Coronavirus, I argued that Coronavirus will radically change society.  In this blog post, I’d like to propose a structure for how we can organize to fight the virus.  I will also make a call to action for readers of this blog to help a non-profit I co-founded, <a href="http://airtoall.org">AirToAll</a>, build safe, low-cost ventilators and other medical devices and distribute them across the world at scale.</p>



<p>There are four ways we can help fight coronavirus:</p>



<ol><li><strong>Reduce exposure to the virus. </strong>Examples: learn where the virus is through better testing; attempt to be where the virus isn’t through social distancing, quarantining, and other means.</li><li><strong>Reduce the chance of exposure leading to infection.</strong> Examples: Wash your hands; avoid touching your face; wear personal protective equipment.</li><li><strong>Reduce the chance of infection leading to serious illness. </strong>Examples: improve your aerobic and pulmonary health; make it more difficult for coronavirus’s spike protein to bind to ACE-2 receptors; scale antibody therapies; consume adequate vitamin D; get more sleep; develop a vaccine.</li><li><strong>Reduce the chance of serious illness leading to death. </strong>Examples: ramp up the production and distribution of certain drugs; develop better drugs; build more ventilators; help healthcare workers.</li></ol>



<p>Obviously, not every example I listed is practical, advisable, or will work, and some options, like producing a vaccine, may be better solutions than others. But we must pursue all approaches.</p>



<p>I’ve been devoting my own time to pursuing the fourth approach, reducing the chance that the illness will lead to death.  Specifically, along with Neil Thanedar, I co-founded AirToAll, a nonprofit that helps bring low-cost, reliable, and clinically tested ventilators to market.  I know lots of groups are working on this problem, so I thought I’d talk about it briefly.</p>



<p>First, like many groups, we’re designing our own ventilators.  Although designing ventilators and bringing them to market at scale poses unique challenges, particularly in an environment where supply chains are strained, this is <em>much </em>easier than it must have been to build iron lungs in the early part of the 20th century, when Zoom conferencing wasn’t yet invented.  When it comes to the ventilators we’re producing, we’re focused on safety and clinical validation rather than speed to market.  We are not the farthest along here, but we’ve made good progress.</p>



<p>Second, our nonprofit is helping other groups produce safe and reliable ventilators by doing direct consultations with them and also by producing <a href="https://591654b2-a393-4da6-9d87-f168fb514898.filesusr.com/ugd/9fa1d3_9f8fa025b877468e91b8ba575c054815.pdf">whitepapers</a> to help them think through the issues at hand (h/t to Harvey Hawes, Abdullah Saleh, and our friends at <a href="https://icchange.ca/">ICChange</a>).</p>



<p>Third, we’re working to increase the manufacturing capacity for currently approved ventilators.</p>



<p>The current shortage of ventilators is a symptom of a greater underlying problem: namely, the world is not good at recognizing healthcare crises early and responding to them quickly.  While our nonprofit helps bring more ventilators to market, we are also trying to solve this greater underlying problem.  I look at our work in ventilator-land as a first step towards our ultimate goal of making medical devices cheaper and more available through an open-source nonprofit model.</p>



<p>I am writing this post as a call to action to you, dear <em>Shtetl-Optimized</em> reader, to get involved.</p>



<p>You don’t have to be an engineer, pulmonologist, virologist, or epidemiologist to help us, although those skillsets are of course helpful and if you are we’d love to have you.  If you have experience in data science and modeling, supply chain and manufacturing, public health, finance, operations, community management, or anything else a rapidly scaling organization needs, you can help us too. </p>



<p>We are a group of 700+ volunteers and growing rapidly.  If you’d like to help, we’d love to have you.  If you might be interested in volunteering, click <a href="https://airtoall.org/community/">here</a>.  Donors click <a href="https://airtoall.org/donate/">here</a>.  Everyone else, please email me at <a href="mailto:steven@airtoall.org">steven@airtoall.org</a> and include a clear subject line so I can direct you to the right person.</p></div>
    </content>
    <updated>2020-04-20T22:41:43Z</updated>
    <published>2020-04-20T22:41:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-20T22:43:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/</id>
    <link href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Local Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 20-21, 2020 Virtual (8am — 12pm Pacific Time) https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html Submission deadline: May 15, 2020 Registration deadline: June 30, 2020 Due to the current situation with COVID-19, we have decided to hold a virtual and shorter version of WOLA this year. WOLA 2020 will run for two days between 8am – 12pm PT to maximize … <a class="more-link" href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/">Continue reading <span class="screen-reader-text">Workshop on Local Algorithms</span></a></div>
    </summary>
    <updated>2020-04-20T20:26:48Z</updated>
    <published>2020-04-20T20:26:48Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-04-21T00:21:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/053</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/053" rel="alternate" type="text/html"/>
    <title>TR20-053 |  Understanding the Relative Strength of QBF CDCL Solvers and QBF Resolution | 

	Benjamin Böhm, 

	Olaf Beyersdorff</title>
    <summary>QBF solvers implementing the QCDCL paradigm are powerful algorithms that
successfully tackle many computationally complex applications. However, our
theoretical understanding of the strength and limitations of these QCDCL
solvers is very limited.

In this paper we suggest to formally model QCDCL solvers as proof systems. We
define different policies that can be used for decision heuristics and unit
propagation and give rise to a number of sound and complete QBF proof systems
(and hence new QCDCL algorithms). With respect to the standard policies used
in practical QCDCL solving, we show that the corresponding QCDCL proof system
is incomparable (via exponential separations) to Q-resolution, the classical
QBF resolution system used in the literature. This is in stark contrast to the
propositional setting where CDCL and resolution are known to be p-equivalent.

This raises the question what formulas are hard for standard QCDCL, since
Q-resolution lower bounds do not necessarily apply to QCDCL as we show here.
In answer to this question we prove several lower bounds for QCDCL, including
exponential lower bounds for a large class of random QBFs.

We also introduce a strengthening of the decision heuristic used in classical
QCDCL, which does not necessarily decide variables in order of the prefix, but
still allows to learn asserting clauses. We show that with this decision
policy, QCDCL can be exponentially faster on some formulas.

We further exhibit a QCDCL proof system that is p-equivalent to Q-resolution.
In comparison to classical QCDCL, this new QCDCL version adapts both decision
and unit propagation policies.</summary>
    <updated>2020-04-20T19:05:12Z</updated>
    <published>2020-04-20T19:05:12Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-515246364372918249</id>
    <link href="https://blog.computationalcomplexity.org/feeds/515246364372918249/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/the-summer-virtual-conference-season.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/515246364372918249" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/515246364372918249" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/the-summer-virtual-conference-season.html" rel="alternate" type="text/html"/>
    <title>The Summer Virtual Conference Season</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Both <a href="http://acm-stoc.org/stoc2020/">STOC</a> and <a href="https://computationalcomplexity.org/">Complexity</a> have announced they will go virtual for the summer. <a href="https://icalp2020.saarland-informatics-campus.de/">ICALP</a> moved from Beijing to Stuttgart to online. I expect every major summer conference and workshop will be cancelled, postponed or virtualized.<br/>
<div>
<br/></div>
<div>
Most CS conferences serve as publication venues and can't be cancelled or postponed. So how do we virtualize a conference? The ACM has an evolving <a href="https://people.clarkson.edu/~jmatthew/acm/VirtualConferences_GuideToBestPractices_CURRENT.pdf">virtual conferences best practices guide</a>. Putting the talks and poster sessions online is not trivial, but relatively straightforward. Personally I go to conferences mostly not for the talks but for the interactions with other participants--the receptions, meal time and just hanging in the hallways. The ACM document describes some approaches like Dagstuhl-style randomized virtual dinner tables. The IEEE VR conference <a href="https://www.cccblog.org/2020/04/02/computing-researchers-respond-to-covid-19-running-a-virtual-conference/">tried virtual reality</a> through <a href="https://hubs.mozilla.com/#/">Mozilla hubs</a>. None of these can truly replicate the on-site experience.</div>
<div>
<br/></div>
<div>
Let me mention two other meetings the <a href="https://games2020.hu/">Game Theory Congress</a> held every four years due to be held in Budapest and the <a href="https://cra.org/conference-at-snowbird/">CRA Snowbird Conference</a>, a meeting of CS department chairs and computing leadership, held every other summer in Utah. Both meetings are not archival publications venues though have several talks and panels. But the main purpose of both is mostly to bring people together, game theorists and CS leaders. I hope they postpone rather than virtualize these meetings. Rather get together a year late than pretend to get together now.</div></div>
    </content>
    <updated>2020-04-20T13:57:00Z</updated>
    <published>2020-04-20T13:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-20T19:20:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08375</id>
    <link href="http://arxiv.org/abs/2004.08375" rel="alternate" type="text/html"/>
    <title>Low-stretch spanning trees of graphs with bounded width</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Borradaile:Glencora.html">Glencora Borradaile</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chambers:Erin_Wolf.html">Erin Wolf Chambers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maxwell:William.html">William Maxwell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayyeri:Amir.html">Amir Nayyeri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08375">PDF</a><br/><b>Abstract: </b>We study the problem of low-stretch spanning trees in graphs of bounded
width: bandwidth, cutwidth, and treewidth. We show that any simple connected
graph $G$ with a linear arrangement of bandwidth $b$ can be embedded into a
distribution $\mathcal T$ of spanning trees such that the expected stretch of
each edge of $G$ is $O(b^2)$. Our proof implies a linear time algorithm for
sampling from $\mathcal T$. Therefore, we have a linear time algorithm that
finds a spanning tree of $G$ with average stretch $O(b^2)$ with high
probability. We also describe a deterministic linear-time algorithm for
computing a spanning tree of $G$ with average stretch $O(b^3)$. For graphs of
cutwidth $c$, we construct a spanning tree with stretch $O(c^2)$ in linear
time. Finally, when $G$ has treewidth $k$ we provide a dynamic programming
algorithm computing a minimum stretch spanning tree of $G$ that runs in
polynomial time with respect to the number of vertices of $G$.
</p></div>
    </summary>
    <updated>2020-04-20T23:41:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08374</id>
    <link href="http://arxiv.org/abs/2004.08374" rel="alternate" type="text/html"/>
    <title>On Regularity of Max-CSPs and Min-CSPs</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stankovic:Aleksa.html">Aleksa Stankovic</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08374">PDF</a><br/><b>Abstract: </b>We study approximability of regular constraint satisfaction problems, i.e.,
CSPs where each variable in an instance has the same number of occurrences. In
particular, we show that for any CSP $\Lambda$, existence of an $\alpha$
approximation algorithm for unweighted regular Max-CSP $\Lambda$ implies
existence of an $\alpha-o(1)$ approximation algorithm for weighted Max-CSP
$\Lambda$ in which regularity of the instances is not imposed. We also give an
analogous result for Min-CSPs, and therefore show that up to arbitrarily small
error it is sufficient to conduct the study of approximability of CSPs only on
regular unweighted instances.
</p></div>
    </summary>
    <updated>2020-04-20T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08359</id>
    <link href="http://arxiv.org/abs/2004.08359" rel="alternate" type="text/html"/>
    <title>On homotopy continuation based singularity distance computations for 3-RPR manipulators</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Aditya Kapilavai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nawratil:Georg.html">Georg Nawratil</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08359">PDF</a><br/><b>Abstract: </b>It is known that parallel manipulators suffer from singular configurations.
Evaluating the distance between a given configuration to the closest singular
one is of interest for industrial applications (e.g.\ singularity-free path
planning). For parallel manipulators of Stewart-Gough type, geometric
meaningful distance measures are known, which are used for the computation of
the singularity distance as the global minimizer of an optimization problem. In
the case of hexapods and linear pentapods the critical points of the
corresponding polynomial Lagrange function cannot be found by the Grobner basis
method due to the degree and number of unknowns. But this polynomial system of
equations can be solved by software tools of numerical algebraic geometry
relying on homotopy continuation. To gain experiences for the treatment of the
mentioned spatial manipulators, this paper attempts to find minimal
multi-homogeneous Bezout numbers for the homotopy continuation based
singularity distance computation with respect to various algebraic motion
representations of planar Euclidean/equiform kinematics. The homogenous and
non-homogenous representations under study are compared and discussed based on
the 3-RPR manipulator.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08350</id>
    <link href="http://arxiv.org/abs/2004.08350" rel="alternate" type="text/html"/>
    <title>Faster Approximate Pattern Matching: A Unified Approach</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charalampopoulos:Panagiotis.html">Panagiotis Charalampopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellnitz:Philip.html">Philip Wellnitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08350">PDF</a><br/><b>Abstract: </b>Approximate pattern matching is a natural and well-studied problem on
strings: Given a text $T$, a pattern $P$, and a threshold $k$, find (the
starting positions of) all substrings of $T$ that are at distance at most $k$
from $P$. We consider the two most fundamental string metrics: the Hamming
distance and the edit distance. Under the Hamming distance, we search for
substrings of $T$ that have at most $k$ mismatches with $P$, while under the
edit distance, we search for substrings of $T$ that can be transformed to $P$
with at most $k$ edits.
</p>
<p>Exact occurrences of $P$ in $T$ have a very simple structure: If we assume
for simplicity that $|T| \le 3|P|/2$ and trim $T$ so that $P$ occurs both as a
prefix and as a suffix of $T$, then both $P$ and $T$ are periodic with a common
period. However, an analogous characterization for the structure of occurrences
with up to $k$ mismatches was proved only recently by Bringmann et al.
[SODA'19]: Either there are $O(k^2)$ $k$-mismatch occurrences of $P$ in $T$, or
both $P$ and $T$ are at Hamming distance $O(k)$ from strings with a common
period $O(m/k)$. We tighten this characterization by showing that there are
$O(k)$ $k$-mismatch occurrences in the case when the pattern is not
(approximately) periodic, and we lift it to the edit distance setting, where we
tightly bound the number of $k$-edit occurrences by $O(k^2)$ in the
non-periodic case. Our proofs are constructive and let us obtain a unified
framework for approximate pattern matching for both considered distances. We
showcase the generality of our framework with results for the fully-compressed
setting (where $T$ and $P$ are given as a straight-line program) and for the
dynamic setting (where we extend a data structure of Gawrychowski et al.
[SODA'18]).
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08338</id>
    <link href="http://arxiv.org/abs/2004.08338" rel="alternate" type="text/html"/>
    <title>The two player shortest path network interdiction problem</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Simon Busan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sch=auml=fer:Luca_E=.html">Luca E. Schäfer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruzika:Stefan.html">Stefan Ruzika</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08338">PDF</a><br/><b>Abstract: </b>In this article, we study a biobjective extension of the shortest path
network interdiction problem. Each arc in the network is associated with two
integer length values and two players compute their respective shortest paths
from source to sink independently from each other while an interdictor tries to
lengthen both shortest paths by removing arcs. We show that this problem is
intractable and that deciding whether a feasible interdiction strategy is
efficient, is NP- complete. We provide a solution procedure to solve the
problem on two-terminal series-parallel graphs in pseudopolynomial time. In
addition, we show that a variant of the problem with bottleneck objectives can
be solved in polynomial time on general directed graphs.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08324</id>
    <link href="http://arxiv.org/abs/2004.08324" rel="alternate" type="text/html"/>
    <title>Hitting forbidden induced subgraphs on bounded treewidth graphs</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sau:Ignasi.html">Ignasi Sau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souza:U=eacute=verton_S=.html">Uéverton S. Souza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08324">PDF</a><br/><b>Abstract: </b>For a fixed graph $H$, the $H$-IS-Deletion problem asks, given a graph $G$,
for the minimum size of a set $S \subseteq V(G)$ such that $G\setminus S$ does
not contain $H$ as an induced subgraph. Motivated by previous work about
hitting (topological) minors and subgraphs on bounded treewidth graphs, we are
interested in determining, for a fixed graph $H$, the smallest function
$f_H(t)$ such that $H$-IS-Deletion can be solved in time $f_H(t) \cdot
n^{O(1)}$ assuming the Exponential Time Hypothesis (ETH), where $t$ and $n$
denote the treewidth and the number of vertices of the input graph,
respectively.
</p>
<p>We show that $f_H(t) = 2^{O(t^{h-2})}$ for every graph $H$ on $h \geq 3$
vertices, and that $f_H(t) = 2^{O(t)}$ if $H$ is a clique or an independent
set. We present a number of lower bounds by generalizing a reduction of Cygan
et al. [MFCS 2014] for the subgraph version. In particular, we show that when
$H$ deviates slightly from a clique, the function $f_H(t)$ suffers a sharp
jump: if $H$ is obtained from a clique of size $h$ by removing one edge, then
$f_H(t) = 2^{\Theta(t^{h-2})}$. We also show that $f_H(t) = 2^{\Omega(t^{h})}$
when $H=K_{h,h}$, and this reduction answers an open question of Mi. Pilipczuk
[MFCS 2011] about the function $f_{C_4}(t)$ for the subgraph version.
</p>
<p>Motivated by Cygan et al. [MFCS 2014], we also consider the colorful variant
of the problem, where each vertex of $G$ is colored with some color from $V(H)$
and we require to hit only induced copies of $H$ with matching colors. In this
case, we determine, under the ETH, the function $f_H(t)$ for every connected
graph $H$ on $h$ vertices: if $h\leq 2$ the problem can be solved in polynomial
time; if $h\geq 3$, $f_H(t) = 2^{\Theta(t)}$ if $H$ is a clique, and $f_H(t) =
2^{\Theta(t^{h-2})}$ otherwise.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08255</id>
    <link href="http://arxiv.org/abs/2004.08255" rel="alternate" type="text/html"/>
    <title>A Survey of Approximate Quantile Computation on Large-scale Data (Technical Report)</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zhiwei.html">Zhiwei Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Aoqian.html">Aoqian Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08255">PDF</a><br/><b>Abstract: </b>As data volume grows extensively, data profiling helps to extract metadata of
large-scale data. However, one kind of metadata, order statistics, is difficult
to be computed because they are not mergeable or incremental. Thus, the
limitation of time and memory space does not support their computation on
large-scale data. In this paper, we focus on an order statistic, quantiles, and
present a comprehensive analysis of studies on approximate quantile
computation. Both deterministic algorithms and randomized algorithms that
compute approximate quantiles over streaming models or distributed models are
covered. Then, multiple techniques for improving the efficiency and performance
of approximate quantile algorithms in various scenarios, such as skewed data
and high-speed data streams, are presented. Finally, we conclude with coverage
of existing packages in different languages and with a brief discussion of the
future direction in this area.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08238</id>
    <link href="http://arxiv.org/abs/2004.08238" rel="alternate" type="text/html"/>
    <title>Novel Binary-Addition Tree Algorithm (BAT) for Binary-State Network Reliability Problem</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeh:Wei=Chang.html">Wei-Chang Yeh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08238">PDF</a><br/><b>Abstract: </b>Network structures and models have been widely adopted, e.g., for Internet of
Things, wireless sensor networks, smart grids, transportation networks,
communication networks, social networks, and computer grid systems. Network
reliability is an effective and popular technique to estimate the probability
that the network is still functioning. Networks composed of binary-state (e.g.,
working or failed) components (arcs and/or nodes) are called binary-state
networks. The binary-state network is the fundamental type of network; thus,
there is always a need for a more efficient algorithm to calculate the network
reliability. Thus, a novel binary-addition tree (BAT) algorithm that employs
binary addition for finding all the possible state vectors and the path-based
layered-search algorithm for filtering out all the connected vectors is
proposed for calculating the binary-state network reliability. According to the
time complexity and numerical examples, the efficiency of the proposed BAT is
higher than those of traditional algorithms for solving the binary-state
network reliability problem.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08160</id>
    <link href="http://arxiv.org/abs/2004.08160" rel="alternate" type="text/html"/>
    <title>Hilbert geometry of the Siegel disk: The Siegel-Klein disk model</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nielsen:Frank.html">Frank Nielsen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08160">PDF</a><br/><b>Abstract: </b>We introduce and study the Hilbert geometry induced by the Siegel disk, an
open bounded convex set of complex matrices. This Hilbert geometry naturally
yields a generalization of the Klein disk model of hyperbolic geometry, which
we term the Siegel-Klein model to differentiate it with the usual Siegel upper
plane and Siegel disk domains. In the Siegel-Klein disk, geodesics are by
construction always straight, allowing one to build efficient geometric
algorithms and data-structures from computational geometry. For example, we
show how to approximate the Smallest Enclosing Ball (SEB) of a set of complex
matrices in the Siegel domains: We compare two implementations of a
generalization of the iterative algorithm of [Badoiu and Clarkson, 2003] in the
Siegel-Poincar\'e disk and in the Siegel-Klein disk. We demonstrate that
geometric computing in the Siegel-Klein disk allows one (i) to bypass the
time-costly recentering operations to the origin (Siegel translations) required
at each iteration of the SEB algorithm in the Siegel-Poincar\'e disk model, and
(ii) to approximate numerically fast the Siegel distance with guaranteed lower
and upper bounds.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08039</id>
    <link href="http://arxiv.org/abs/2004.08039" rel="alternate" type="text/html"/>
    <title>Contention Resolution Without Collision Detection</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bender:Michael_A=.html">Michael A. Bender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pettie:Seth.html">Seth Pettie</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08039">PDF</a><br/><b>Abstract: </b>This paper focuses on the contention resolution problem on a shared
communication channel that does not support collision detection. A shared
communication channel is a multiple access channel, which consists of a
sequence of synchronized time slots. Players on the channel may attempt to
broadcast a packet (message) in any time slot. A player's broadcast succeeds if
no other player broadcasts during that slot. If two or more players broadcast
in the same time slot, then the broadcasts collide and both broadcasts fail.
The lack of collision detection means that a player monitoring the channel
cannot differentiate between the case of two or more players broadcasting in
the same slot (a collision) and zero players broadcasting. In the
contention-resolution problem, players arrive on the channel over time, and
each player has one packet to transmit. The goal is to coordinate the players
so that each player is able to successfully transmit its packet within
reasonable time. However, the players can only communicate via the shared
channel by choosing to either broadcast or not. A contention-resolution
protocol is measured in terms of its throughput (channel utilization). Previous
work on contention resolution that achieved constant throughput assumed that
either players could detect collisions, or the players' arrival pattern is
generated by a memoryless (non-adversarial) process.
</p>
<p>The foundational question answered by this paper is whether collision
detection is a luxury or necessity when the objective is to achieve constant
throughput. We show that even without collision detection, one can solve
contention resolution, achieving constant throughput, with high probability.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.08037</id>
    <link href="http://arxiv.org/abs/2004.08037" rel="alternate" type="text/html"/>
    <title>Automating Cutting Planes is NP-Hard}</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml==ouml=s:Mika.html">Mika Göös</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koroth:Sajin.html">Sajin Koroth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertz:Ian.html">Ian Mertz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pitassi:Toniann.html">Toniann Pitassi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.08037">PDF</a><br/><b>Abstract: </b>We show that Cutting Planes (CP) proofs are hard to find: Given an
unsatisfiable formula $F$,
</p>
<p>1) It is NP-hard to find a CP refutation of $F$ in time polynomial in the
length of the shortest such refutation; and
</p>
<p>2)unless Gap-Hitting-Set admits a nontrivial algorithm, one cannot find a
tree-like CP refutation of $F$ in time polynomial in the length of the shortest
such refutation.
</p>
<p>The first result extends the recent breakthrough of Atserias and M\"uller
(FOCS 2019) that established an analogous result for Resolution. Our proofs
rely on two new lifting theorems: (1) Dag-like lifting for gadgets with many
output bits. (2) Tree-like lifting that simulates an $r$-round protocol with
gadgets of query complexity $O(\log r)$ independent of input length.
</p></div>
    </summary>
    <updated>2020-04-20T23:21:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07996</id>
    <link href="http://arxiv.org/abs/2004.07996" rel="alternate" type="text/html"/>
    <title>Compatible Paths on Labelled Point Sets</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arseneva:Elena.html">Elena Arseneva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bahoo:Yeganeh.html">Yeganeh Bahoo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cano:Pilar.html">Pilar Cano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chanchary:Farah.html">Farah Chanchary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Kshitij.html">Kshitij Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lubiw:Anna.html">Anna Lubiw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mondal:Debajyoti.html">Debajyoti Mondal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheikhan:Khadijeh.html">Khadijeh Sheikhan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07996">PDF</a><br/><b>Abstract: </b>Let $P$ and $Q$ be finite point sets of the same cardinality in
$\mathbb{R}^2$, each labelled from $1$ to $n$. Two noncrossing geometric graphs
$G_P$ and $G_Q$ spanning $P$ and $Q$, respectively, are called compatible if
for every face $f$ in $G_P$, there exists a corresponding face in $G_Q$ with
the same clockwise ordering of the vertices on its boundary as in $f$. In
particular, $G_P$ and $G_Q$ must be straight-line embeddings of the same
connected $n$-vertex graph.
</p>
<p>Deciding whether two labelled point sets admit compatible geometric paths is
known to be NP-complete. We give polynomial-time algorithms to find compatible
paths or report that none exist in three scenarios: $O(n)$ time for points in
convex position; $O(n^2)$ time for two simple polygons, where the paths are
restricted to remain inside the closed polygons; and $O(n^2 \log n)$ time for
points in general position if the paths are restricted to be monotone.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07986</id>
    <link href="http://arxiv.org/abs/2004.07986" rel="alternate" type="text/html"/>
    <title>Average Case Column Subset Selection for Entrywise $\ell_1$-Norm Loss</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Peilin.html">Peilin Zhong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07986">PDF</a><br/><b>Abstract: </b>We study the column subset selection problem with respect to the entrywise
$\ell_1$-norm loss. It is known that in the worst case, to obtain a good
rank-$k$ approximation to a matrix, one needs an arbitrarily large
$n^{\Omega(1)}$ number of columns to obtain a $(1+\epsilon)$-approximation to
the best entrywise $\ell_1$-norm low rank approximation of an $n \times n$
matrix. Nevertheless, we show that under certain minimal and realistic
distributional settings, it is possible to obtain a
$(1+\epsilon)$-approximation with a nearly linear running time and
poly$(k/\epsilon)+O(k\log n)$ columns. Namely, we show that if the input matrix
$A$ has the form $A = B + E$, where $B$ is an arbitrary rank-$k$ matrix, and
$E$ is a matrix with i.i.d. entries drawn from any distribution $\mu$ for which
the $(1+\gamma)$-th moment exists, for an arbitrarily small constant $\gamma &gt;
0$, then it is possible to obtain a $(1+\epsilon)$-approximate column subset
selection to the entrywise $\ell_1$-norm in nearly linear time. Conversely we
show that if the first moment does not exist, then it is not possible to obtain
a $(1+\epsilon)$-approximate subset selection algorithm even if one chooses any
$n^{o(1)}$ columns. This is the first algorithm of any kind for achieving a
$(1+\epsilon)$-approximation for entrywise $\ell_1$-norm loss low rank
approximation.
</p></div>
    </summary>
    <updated>2020-04-20T23:31:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07946</id>
    <link href="http://arxiv.org/abs/2004.07946" rel="alternate" type="text/html"/>
    <title>Beyond Tree Embeddings -- a Deterministic Framework for Network Design with Deadlines or Delay</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Azar:Yossi.html">Yossi Azar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Touitou:Noam.html">Noam Touitou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07946">PDF</a><br/><b>Abstract: </b>We consider network design problems with deadline or delay. All previous
results for these models are based on randomized embedding of the graph into a
tree (HST) and then solving the problem on this tree. We show that this is not
necessary. In particular, we design a deterministic framework for these
problems which is not based on embedding. This enables us to provide
deterministic $\text{poly-log}(n)$-competitive algorithms for Steiner tree,
generalized Steiner tree, node weighted Steiner tree, (non-uniform) facility
location and directed Steiner tree with deadlines or with delay (where $n$ is
the number of nodes). Our deterministic algorithms also give improved
guarantees over some previous randomized results. In addition, we show a lower
bound of $\text{poly-log}(n)$ for some of these problems, which implies that
our framework is optimal up to the power of the poly-log. Our algorithms and
techniques differ significantly from those in all previous considerations of
these problems.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07886</id>
    <link href="http://arxiv.org/abs/2004.07886" rel="alternate" type="text/html"/>
    <title>Maximizing Determinants under Matroid Constraints</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Madan:Vivek.html">Vivek Madan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolov:Aleksandar.html">Aleksandar Nikolov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Mohit.html">Mohit Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tantipongpipat:Uthaipon.html">Uthaipon Tantipongpipat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07886">PDF</a><br/><b>Abstract: </b>Given vectors $v_1,\dots,v_n\in\mathbb{R}^d$ and a matroid $M=([n],I)$, we
study the problem of finding a basis $S$ of $M$ such that $\det(\sum_{i \in
S}v_i v_i^\top)$ is maximized. This problem appears in a diverse set of areas
such as experimental design, fair allocation of goods, network design, and
machine learning. The current best results include an $e^{2k}$-estimation for
any matroid of rank $k$ and a $(1+\epsilon)^d$-approximation for a uniform
matroid of rank $k\ge d+\frac d\epsilon$, where the rank $k\ge d$ denotes the
desired size of the optimal set. Our main result is a new approximation
algorithm with an approximation guarantee that depends only on the dimension
$d$ of the vectors and not on the size $k$ of the output set. In particular, we
show an $(O(d))^{d}$-estimation and an $(O(d))^{d^3}$-approximation for any
matroid, giving a significant improvement over prior work when $k\gg d$.
</p>
<p>Our result relies on the existence of an optimal solution to a convex
programming relaxation for the problem which has sparse support; in particular,
no more than $O(d^2)$ variables of the solution have fractional values. The
sparsity results rely on the interplay between the first-order optimality
conditions for the convex program and matroid theory. We believe that the
techniques introduced to show sparsity of optimal solutions to convex programs
will be of independent interest. We also give a randomized algorithm that
rounds a sparse fractional solution to a feasible integral solution to the
original problem. To show the approximation guarantee, we utilize recent works
on strongly log-concave polynomials and show new relationships between
different convex programs studied for the problem. Finally, we use the
estimation algorithm and sparsity results to give an efficient deterministic
approximation algorithm with an approximation guarantee that depends solely on
the dimension $d$.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07869</id>
    <link href="http://arxiv.org/abs/2004.07869" rel="alternate" type="text/html"/>
    <title>Entanglement is Necessary for Optimal Quantum Property Testing</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sebastien Bubeck, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Sitan.html">Sitan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07869">PDF</a><br/><b>Abstract: </b>There has been a surge of progress in recent years in developing algorithms
for testing and learning quantum states that achieve optimal copy complexity.
Unfortunately, they require the use of entangled measurements across many
copies of the underlying state and thus remain outside the realm of what is
currently experimentally feasible. A natural question is whether one can match
the copy complexity of such algorithms using only independent---but possibly
adaptively chosen---measurements on individual copies.
</p>
<p>We answer this in the negative for arguably the most basic quantum testing
problem: deciding whether a given $d$-dimensional quantum state is equal to or
$\epsilon$-far in trace distance from the maximally mixed state. While it is
known how to achieve optimal $O(d/\epsilon^2)$ copy complexity using entangled
measurements, we show that with independent measurements,
$\Omega(d^{4/3}/\epsilon^2)$ is necessary, even if the measurements are chosen
adaptively. This resolves a question of Wright. To obtain this lower bound, we
develop several new techniques, including a chain-rule style proof of
Paninski's lower bound for classical uniformity testing, which may be of
independent interest.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07839</id>
    <link href="http://arxiv.org/abs/2004.07839" rel="alternate" type="text/html"/>
    <title>Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mansour:Yishay.html">Yishay Mansour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stemmer:Uri.html">Uri Stemmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsfadia:Eliad.html">Eliad Tsfadia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07839">PDF</a><br/><b>Abstract: </b>We present a differentially private learner for halfspaces over a finite grid
$G$ in $\mathbb{R}^d$ with sample complexity $\approx d^{2.5}\cdot
2^{\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al.,
COLT 2019] by a $d^2$ factor. The building block for our learner is a new
differentially private algorithm for approximately solving the linear
feasibility problem: Given a feasible collection of $m$ linear constraints of
the form $Ax\geq b$, the task is to privately identify a solution $x$ that
satisfies most of the constraints. Our algorithm is iterative, where each
iteration determines the next coordinate of the constructed solution $x$.
</p></div>
    </summary>
    <updated>2020-04-20T23:20:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07823</id>
    <link href="http://arxiv.org/abs/2004.07823" rel="alternate" type="text/html"/>
    <title>Polynomial-delay Enumeration Algorithms in Set Systems</title>
    <feedworld_mtime>1587340800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haraguchi:Kazuya.html">Kazuya Haraguchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagamochi:Hiroshi.html">Hiroshi Nagamochi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07823">PDF</a><br/><b>Abstract: </b>We consider a set system $(V, {\mathcal C}\subseteq 2^V)$ on a finite set $V$
of elements, where we call a set $C\in {\mathcal C}$ a component. We assume
that two oracles $\mathrm{L}_1$ and $\mathrm{L}_2$ are available, where given
two subsets $X,Y\subseteq V$, $\mathrm{L}_1$ returns a maximal component $C\in
{\mathcal C}$ with $X\subseteq C\subseteq Y$; and given a set $Y\subseteq V$,
$\mathrm{L}_2$ returns all maximal components $C\in {\mathcal C}$ with
$C\subseteq Y$. Given a set $I$ of attributes and a function $\sigma:V\to 2^I$
in a transitive system, a component $C\in {\mathcal C}$ is called a solution if
the set of common attributes in $C$ is inclusively maximal; i.e.,
$\bigcap_{v\in C}\sigma(v)\supsetneq \bigcap_{v\in X}\sigma(v)$ for any
component $X\in{\mathcal C}$ with $C\subsetneq X$. We prove that there exists
an algorithm of enumerating all solutions (or all components) in delay bounded
by a polynomial with respect to the input size and the running times of the
oracles.
</p></div>
    </summary>
    <updated>2020-04-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4762</id>
    <link href="https://www.scottaaronson.com/blog/?p=4762" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4762#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4762" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Lockdown day 39</title>
    <summary xml:lang="en-US">This is really getting depressing. One of the only things that makes it bearable—even though in some sense it shouldn’t—is that most of humanity is in this together. For once, there’s no question of “why me?” Having watched the eighth and final episode of Devs, the thought occurred to me: if I’d had the opportunity […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>This is <em>really</em> getting depressing.  One of the only things that makes it bearable—even though in some sense it shouldn’t—is that most of humanity is in this together.  For once, there’s no question of “why me?”</li><li>Having watched the eighth and final episode of <em>Devs</em>, the thought occurred to me: if I’d had the opportunity to restart the world from 8 months ago, even inside a simulation, I’d seize the chance and never look back.</li><li>I think I finally figured out how to explain the issue with <em>Devs</em> to my literary sophisticate readers.  Namely: <em>Devs</em> consists, precisely, of the <strong>cultural appropriation </strong>of quantum computing.  Now, I never felt like cultural appropriation was the world’s worst problem—not even <em>before</em> a pandemic started overflowing the morgues—so I wouldn’t say I was <em>offended</em> by Alex Garland appropriating the images and buzzwords of my quantum computing tribe for a basically unrelated purpose, but it is what it is.  Again: <em>Devs</em> is the show for you, if you want a haunting, slow-paced, well-produced meditation about free will and determinism and predicting the future and parallel worlds and “what if the whole universe is a simulation?,” and the various ideas I would’ve had about such topics around the age of 11.  It’s just not a show about quantum computing.  I hope that makes it clear.</li><li>I read with interest <a href="https://project-evidence.github.io/">this anonymous but PGP-signed article</a>, laying out the case that it’s <em>plausible</em> that covid accidentally leaked from either the Wuhan Institute of Virology or the Wuhan CDC, rather than originating at the Huanan seafood market.  Or, as an intermediate hypothesis, that an infected animal from one of those labs ended up at the seafood market.  (Note that this is completely different from the hypothesis that covid was purposefully engineered—the authors of the article find that totally implausible, and I agree with them.)  Notably, the Wuhan labs are known to have experimented with bat coronaviruses very much like covid, and are known to have performed “gain-of-function” experiments on them, and were probably the central labs in China for such experiments.  And viruses are known to have leaked from other labs in China on other occasions, and the nature → seafood market route has unresolved issues, like where exactly the crossover from bats to pangolins (or some other intermediate species) is supposed to have happened, such that people would only start getting infected at the seafood market and not at its faraway suppliers, and … well, anyway, read the article and form your own judgment!</li><li>I find it interesting that three months ago, I would’ve hesitated even to share such a link, because my internal critic would’ve screamed “this looks too much like tinfoil-hat stuff—are you ready for all the people you respect sneering at you?”  But the me of three months ago is not the me of today.  I make no apologies for adapting my thoughts to the freak branch of the multiverse where I actually find myself.</li></ol>



<p/></div>
    </content>
    <updated>2020-04-19T22:51:16Z</updated>
    <published>2020-04-19T22:51:16Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-20T22:43:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/04/19/stretch-average-stretch</id>
    <link href="https://11011110.github.io/blog/2020/04/19/stretch-average-stretch.html" rel="alternate" type="text/html"/>
    <title>Stretch, average stretch, and expected stretch of spanning trees</title>
    <summary>The graph below is a series-parallel graph. It can be put together from four smaller series-parallel graphs, each constructed recursively in the same way, by performing a series composition of two pairs and then a parallel composition of the two results.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The graph below is a <a href="https://en.wikipedia.org/wiki/Series-parallel_graph">series-parallel graph</a>. It can be put together from four smaller series-parallel graphs, each constructed recursively in the same way, by performing a series composition of two pairs and then a parallel composition of the two results.</p>

<p style="text-align: center;"><img alt="Series-parallel graph for which all spanning trees have high stretch" src="https://11011110.github.io/blog/assets/2020/binserpar.svg"/></p>

<p>This family of graphs (although not the radial layout I’m using for it) comes from a paper “Cuts, trees and -embeddings of graphs”, by Anupam Gupta, Ilan Newman, Yuri Rabinovich, and Alistair Sinclair, <em>Combinatorica</em> 2004, <a href="https://doi.org/10.1007/s00493-004-0015-x">doi:10.1007/s00493-004-0015-x</a> (see Figure 3, p. 261). They used it to show a lower bound on the average stretch of any spanning tree for these graphs.</p>

<p>Here, given a graph , any edge  of , and any subgraph  of , the stretch of  with respect to  is how much farther you have to go in  to find a path connecting the endpoints of , relative to the unit distance between these endpoints in . For instance, in a cycle graph , every spanning tree is formed by deleting one edge from the cycle. The deleted edge has stretch  (you have to go the long way around to connect its endpoints), but all other edges have stretch , so the average stretch is . More strongly, if you choose the edge to delete randomly, the resulting distribution over spanning trees of  gives every edge expected stretch .</p>

<p>But for the series-parallel graphs of Gupta, Newman, Rabinovich, and Sinclair, such low stretch is not possible. If there are  vertices, then there are  edges. Each edge has stretch at least one.
There are  four-cycles, each of which has at least one missing edge,
with stretch at least three; added to the one unit of stretch that we’ve already counted, the extra stretch from these missing edges is at least .
Removing one edge from each four-cycle leaves  eight-cycles, each of which has at least one more missing edge. The edge that is removed in this way, and the other missing edge from the same four-cycle, have stretch at least seven, adding another ten units per eight-cycle, or  overall, to the total stretch. And so on; at each level of recursion the number of cycles goes down by a factor of four, but the number of edges that need to be cut to break each cycle doubles, as does their length. Therefore, the contribution per level of the recursive construction ends up being linear, and the total stretch is . Thus, as Gupta et al. show, the average stretch for their graphs is .</p>

<p>This result is the background to my newest preprint, “Low-stretch spanning trees of graphs with bounded width” (with Cora Borradaile, Erin Chambers, Will Maxwell, and Amir Nayyeri, <a href="https://arxiv.org/abs/2004.08375">arXiv:2004.08375</a>, to appear at SWAT). From the result of Gupta, we know that having bounded treewidth is not enough to ensure bounded average stretch, or bounded expected stretch. What is? We show that bounded bandwidth is enough to find a distribution over spanning trees with bounded expected stretch, and that bounded cutwidth is enough to find a single spanning tree with bounded average stretch.</p>

<p>This leaves open the question for pathwidth. It was known from another previous work, “Pathwidth, trees, and random embeddings” (James Lee and Tasos Sidiropoulos, <em>Combinatorica</em> 2013, <a href="https://doi.org/10.1007/s00493-013-2685-8">doi:10.1007/s00493-013-2685-8</a>) that graphs of bounded pathwidth can be mapped to a random distribution over trees with bounded expected stretch per edge, but the trees of this distribution are not spanning trees. Our new paper includes a conjecture that bounded-pathwidth graphs have distributions over spanning trees with constant average stretch, which if true would generalize our results for both bandwidth and cutwidth.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104028326751044483">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-04-19T18:10:00Z</updated>
    <published>2020-04-19T18:10:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-20T01:32:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=415</id>
    <link href="https://tcsplus.wordpress.com/2020/04/19/tcs-talk-wednesday-april-22-huacheng-yu-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 22 — Huacheng Yu, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Huacheng Yu from Princeton will speak about a “Nearly Optimal Static Las Vegas Succinct Dictionary” (abstract below). You can reserve a spot as an individual or a group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 22nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Huacheng Yu</strong> from Princeton will speak about a “<em>Nearly Optimal Static Las Vegas Succinct Dictionary</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk">the online form</a>. Due to security concerns, <strong>registration is required</strong> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Given a set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> (distinct) keys from key space <img alt="[U]" class="latex" src="https://s0.wp.com/latex.php?latex=%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="[U]"/>, each associated with a value from <img alt="\Sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Sigma"/>, the <em>static dictionary problem</em> asks to preprocess these (key, value) pairs into a data structure, supporting value-retrieval queries: for any given <img alt="x \in [U]" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5BU%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="x \in [U]"/>, valRet<img alt="(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(x)"/> must return the value associated with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>, or return “N/A” if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=fff&amp;fg=444444&amp;s=0" title="x"/> is not in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=fff&amp;fg=444444&amp;s=0" title="S"/>. The special case where <img alt="|\Sigma|=1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CSigma%7C%3D1&amp;bg=fff&amp;fg=444444&amp;s=0" title="|\Sigma|=1"/> is called the membership problem. The “textbook” solution is to use a hash table, which occupies linear space and answers each query in constant time. On the other hand, the minimum possible space to encode all (key, value) pairs is only <img alt="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D+%3A%3D+%5Clg+%5Cbinom%7BU%7D%7Bn%7D+%2B+n+%5Clg+%7C%5CSigma%7C&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT} := \lg \binom{U}{n} + n \lg |\Sigma|"/> bits, which could be much less.</p>
<p>In this talk, we will talk about a randomized dictionary data structure using <img alt="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2B%5Ctextrm%7Bpoly%7D%5Clg+n%2BO%28%5Clg%5Clg%5Ccdots%5Clg+U%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+\textrm{poly}\lg n+O(\lg\lg\cdots\lg U)"/> bits of space and expected constant query time, assuming the query algorithm have access to an external data-independent lookup table of size <img alt="n^{0.001}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B0.001%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="n^{0.001}"/>. Previously, even for membership queries and when <img alt="U\leq n^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Cleq+n%5E%7BO%281%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="U\leq n^{O(1)}"/>, the best known data structure with constant query time requires <img alt="\textrm{OPT}+n/\textrm{poly} \lg n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%2F%5Ctextrm%7Bpoly%7D+%5Clg+n&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n/\textrm{poly} \lg n"/> bits of space (due to Pagh [Pagh’01] and Pătraşcu [Pat’08]). It has <img alt="O(\lg n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clg+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(\lg n)"/> query time when the space is at most <img alt="\textrm{OPT}+n^{0.999}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BOPT%7D%2Bn%5E%7B0.999%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{OPT}+n^{0.999}"/>.</p></blockquote></div>
    </content>
    <updated>2020-04-19T18:01:40Z</updated>
    <published>2020-04-19T18:01:40Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-04-21T00:21:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19738</id>
    <link href="https://gilkalai.wordpress.com/2020/04/19/to-cheer-you-up-in-difficult-times-ii-mysterious-matching-news-by-gal-beniamini-naom-nisan-vijay-vazirani-and-thorben-trobst/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times II: Mysterious matching news by Gal Beniamini, Naom Nisan, Vijay Vazirani and Thorben Tröbst!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Matching is one of the richest gold mines for ideas and results in mathematics, computer science and other areas.  Today I want to briefly tell you about a curious, surprising, mysterious, and cheerful recent result by Gal Beniamini and Noam … <a href="https://gilkalai.wordpress.com/2020/04/19/to-cheer-you-up-in-difficult-times-ii-mysterious-matching-news-by-gal-beniamini-naom-nisan-vijay-vazirani-and-thorben-trobst/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Matching is one of the richest gold mines for ideas and results in mathematics, computer science and other areas.  Today I want to briefly tell you about a curious, surprising, mysterious, and <a href="https://arxiv.org/abs/2001.07642">cheerful recent result</a> by Gal Beniamini and Noam Nisan and a subsequent work of Vijay Vazirani. It is a result that will cheer up combinatorialists on both sides of the isle: graph theorists and researchers in extremal and probabilistic combinatorics as well as algebraic and enumerative combinatorialists.  (And it is related to query complexity, Eulerian lattices, Birkhoff’s polytope, a theorem of Lou Billera and Aravamuthan Sarangarajan, evasiveness, analysis of Boolean functions, and various other things.) At the end of the post I will remind you of a central problem in matching theory: to extend Lovasz’ randomized algorithm for matching to general graphs. (Perhaps methods from algebraic combinatorics can help.)</p>
<p>I will start with sad news. <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Horton Conway</a>, an amazing mathematical hero,  passed away a few days ago. There are very nice posts on Conway’s work <a href="https://www.scottaaronson.com/blog/?p=4732">by Scott Aaronson</a> (with many nice memories in the comment section), <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">by Terry Tao</a>, and by <a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">Dick Lipton and Ken Regan</a>. And<a href="https://xkcd.com/2293/"> a moving obituary on xkcd</a> with a touch of ingenuity of Conway’s style. (Here is also a question on MO on <a href="https://mathoverflow.net/questions/357197/conways-lesser-known-results">Conway’s less known results</a>, and two questions on the game of life (<a href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">I</a>, <a href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">II</a>).)</p>
<p>Another reading material to cheer you up is my paper: <a href="https://gilkalai.files.wordpress.com/2020/04/laws-blog.pdf">The argument against quantum computers, the quantum laws of nature, and Google’s supremacy claims.</a> It is for <em>Laws, Rigidity and Dynamics,</em> Proceedings of the <a href="https://gilkalai.wordpress.com/2018/06/10/conference-in-singapore-vietnam-appeasement-restorative-justice-laws-of-history-and-neutrinos/">ICA workshops</a> 2018 &amp; 2019 Singapore and Birmingham. <span style="color: #993366;">Remarks are most welcome.</span></p>
<p><strong>Update:</strong> starting today, <a href="https://sites.google.com/view/acow2020/home">the algebraic combinatorics online workshop.</a>  Here is the schedule <a href="https://drive.google.com/file/d/17us1_lpZk1XLdQ1IewxS9cp-fBPA6TKw/view">for the first week</a>, and <a href="https://drive.google.com/file/d/1wJlUyLkdQ1Uvz5OxZGCNuE2SWyRk5_te/view">for the second week</a>.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/mt.jpg"><img alt="" class="alignnone size-full wp-image-19748" src="https://gilkalai.files.wordpress.com/2020/04/mt.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;">Matching theory by Lovasz and Plummer is probably one of the best mathematics books ever written. </span></p>
<h2>Bipartite Perfect Matching as a Real Polynomial</h2>
<p><a href="https://arxiv.org/abs/2001.07642">Bipartite Perfect Matching as a Real Polynomial,</a> by Gal Beniamini and Noam Nisan</p>
<p><strong>Abstract:</strong> We obtain a description of the Bipartite Perfect Matching decision problem as a multilinear polynomial over the Reals. We show that it has full degree and <img alt="(1-o_n(1))\cdot 2^{n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%281-o_n%281%29%29%5Ccdot+2%5E%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1-o_n(1))\cdot 2^{n^2}"/>  monomials with non-zero coefficients. In contrast, we show that in the dual representation (switching the roles of 0 and 1) the number of monomials is only exponential in <img alt="\Theta(n \log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28n+%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta(n \log n)"/>  Our proof relies heavily on the fact that the lattice of graphs which are “matching-covered” is Eulerian.</p>
<p>And here is how the paper starts</p>
<p>Every Boolean function <img alt="f:\{0,1\}^n\to\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Cto%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:\{0,1\}^n\to\{0,1\}"/> can be represented in a unique way as a Real multilinear polynomial. This representation and related ones (e.g. using the {1,−1} basis rather than {0,1}– the “Fourier transform” over the hypercube, or approximation variants) have many applications for various complexity and algorithmic purposes. See, e.g., [O’D14] for a recent textbook. In this paper we derive the representation of the bipartite-perfect-matching decision problem as a Real polynomial.</p>
<p><strong>Deﬁnition.</strong> The Boolean function <img alt="BPM_n(x_{1,1},\dots,x_{n,n})" class="latex" src="https://s0.wp.com/latex.php?latex=BPM_n%28x_%7B1%2C1%7D%2C%5Cdots%2Cx_%7Bn%2Cn%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="BPM_n(x_{1,1},\dots,x_{n,n})"/> is deﬁned to be 1 if and only if the bipartite graph whose edges are<img alt="\{(i,j):x_{i,j}=1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28i%2Cj%29%3Ax_%7Bi%2Cj%7D%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(i,j):x_{i,j}=1\}"/> has a perfect matching, and 0 otherwise.</p>
<p>And here are the two main theorems regarding this polynomial and the polynomial for the dual representation:</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn2.png"><img alt="" class="alignnone size-full wp-image-19769" height="138" src="https://gilkalai.files.wordpress.com/2020/04/bn2.png?w=640&amp;h=138" width="640"/></a></p>
<p>(For the second theorem you need the notion of totally ordered bipartite graphs.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn3.png"><img alt="" class="alignnone size-full wp-image-19770" height="143" src="https://gilkalai.files.wordpress.com/2020/04/bn3.png?w=640&amp;h=143" width="640"/></a></p>
<p>And here is a nice picture!</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/bn4.png"><img alt="" class="alignnone size-full wp-image-19771" height="421" src="https://gilkalai.files.wordpress.com/2020/04/bn4.png?w=640&amp;h=421" width="640"/></a></p>
<p>A very interesting open problem is:</p>
<p><strong>Problem:</strong> Can the Beniamini-Nisan results be extended to general (non bipartite) graphs</p>
<p>This reminds me of an old great problem:</p>
<p><strong>Problem:</strong> Does Lovasz’ randomized algorithm for matching extend to the non-bipartite case?</p>
<p>For both problems maybe methods of algebraic combinatorics can be helpful.</p>
<h2>An Extension by Vijay Vazirani and Thorben Tröbst</h2>
<p class="title mathjax"><a href="https://arxiv.org/abs/2003.08917">A Real Polynomial for Bipartite Graph Minimum Weight Perfect Matchings,</a> Thorben Tröbst, Vijay V. Vazirani</p>
<p><strong>Abstract:</strong></p>
<p>In a recent paper, Beniamini and Nisan gave a closed-form formula for the unique multilinear polynomial for the Boolean function determining whether a given bipartite graph <img alt="G \subset K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Csubset+K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G \subset K_{n,n}"/> has a perfect matching, together with an efficient algorithm for computing the coefficients of the monomials of this polynomial. We give the following generalization: Given an arbitrary non-negative weight function <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-12"><span class="mrow" id="MathJax-Span-13"><span class="mi" id="MathJax-Span-14">w</span></span></span></span> on the edges of <img alt="K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{n,n}"/>, consider its set of minimum weight perfect matchings. We give the real multilinear polynomial for the Boolean function which determines if a graph <img alt="G \subset K_{n,n}" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Csubset+K_%7Bn%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G \subset K_{n,n}"/> contains one of these minimum weight perfect matchings.</p>
<h3>Three more remarks about VVV</h3>
<p>Three more VVV remarks: In the Tel Aviv theory fast three month ago (it seems like ages ago)  Vijay Vazirani gave a lecture about matching; Here is the link to <a href="https://youtu.be/DFGsIOVGOIs">VJ’s lecture</a>, and to <a href="https://www.youtube.com/playlist?list=PLGRBwz8taWHgpFOqbKQLvm-eAaZz33zM7">all plenary lectures</a>.  At the end, I asked him how he explains that matching theory is such a never exhausting gold mine and Vijay mentioned the fact that a polynomial time algorithm for the assignment problem (which is closely related to matching) was <a href="http://www.lix.polytechnique.fr/~ollivier/JACOBI/presentationlEngl.htm">already found by Jacobi in 1890</a>. (unfortunately VJ’s inspiring answer was not recorder). Few years ago Vijay<a href="https://arxiv.org/abs/1210.4594"> published a simplified proof</a> of a fantastic famous results he first proved with Silvio Micaly 34 years earlier; And here is a most amazing story: A few years ago I went to the beach in Tel Aviv and I discovered Vijay swimming just next to me.  We were quite happy to see each other and Vijay told me a few things about matching, economics and biology.  This sounds now like truly a surrealistic story, and perhaps we even shook hands.</p>
<h3/>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-04-19T08:47:01Z</updated>
    <published>2020-04-19T08:47:01Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Gal Beniamini"/>
    <category term="Naom Nisan"/>
    <category term="Thorben Tr&#xF6;bst"/>
    <category term="Vijay Vazirani"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-04-21T00:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16965</id>
    <link href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/" rel="alternate" type="text/html"/>
    <title>Proof and Cake Envy</title>
    <summary>Our proofs can be big too [Mackenzie and Aziz] Haris Aziz and Simon Mackenzie are computer scientists at UNSW and CMU respectively. Of course UNSW is the University of New South Wales and CMU is the Carnegie Mellon University. Today we will discuss cake cutting and more. Aziz and Mackenzie have solved an open problem […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Our proofs can be big too</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/screen-shot-2020-04-18-at-12-47-07-pm/" rel="attachment wp-att-16968"><img alt="" class="alignright size-medium wp-image-16968" height="163" src="https://rjlipton.files.wordpress.com/2020/04/screen-shot-2020-04-18-at-12.47.07-pm.png?w=300&amp;h=163" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[Mackenzie and Aziz]</font></td>
</tr>
</tbody>
</table>
<p>
Haris Aziz and Simon Mackenzie are computer scientists at UNSW and CMU respectively. Of course UNSW is the University of New South Wales and CMU is the Carnegie Mellon University. </p>
<p>
Today we will discuss cake cutting and more.</p>
<p>
Aziz and Mackenzie have solved an open problem concerning how to cut cakes. Their <a href="https://cacm.acm.org/magazines/2020/4/243651-a-bounded-and-envy-free-cake-cutting-algorithm/fulltext">paper</a> is in the April issue of the CACM: “A Bounded and Envy-Free Cake Cutting Algorithm.” </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/cake/" rel="attachment wp-att-16970"><img alt="" class="aligncenter size-full wp-image-16970" src="https://rjlipton.files.wordpress.com/2020/04/cake.jpg?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Why Cake Cutting? </h2><p/>
<p/><p>
Before we talk about cake cutting from a theory viewpoint let’s take a look at why it is interesting. The real answer probably is it is a beautiful math problem. It is easy to state without lots of background. It is simple like Fermat’s Last Theorem: 	</p>
<p align="center"><img alt="\displaystyle  x^{n} + y^{n} = z^{n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bn%7D+%2B+y%5E%7Bn%7D+%3D+z%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{n} + y^{n} = z^{n} "/></p>
<p>has no solutions over the integers with <img alt="{xyz \neq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bxyz+%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{xyz \neq 0}"/> and <img alt="n&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n&gt;2"/>. Cake cutting is hard. We like problems that strike back: problems that are not easy to solve. This is a strange view. In real life we might prefer problems that we can easily solve. But not in math. We like problems that are not trivial. The cake cutting problem is hard, so we like it. </p>
<p>
</p><p/><h2> Cutting Cakes </h2><p/>
<p/><p>
We are theorists so our cakes are one-dimensional line segments. The problem involves a finite set of agents, say Alice, Bob, and so on. They want to divide the cake, the line segment, into a finite number of pieces. The pieces are then allocated to the agents. The goal is to get a fair division of the cake. </p>
<p>
The notion of “fair” is what makes the problem interesting. Often agents will not have the same tastes: Some like icing more than others, some like the end pieces, while others do not. The fact that the agents assign different values to a piece of the cake is what makes the problem challenging. </p>
<p>
If there are two agents the problem has long been solved. Let Bob divide the cake into two pieces, so that he is happy to get either of these pieces. Then have Alice chose which piece she wants. It is easy to see that both Bob and Alice are happy. Both are <i>envy-free</i>: neither would exchange their piece for the others piece. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/two/" rel="attachment wp-att-16971"><img alt="" class="aligncenter size-medium wp-image-16971" height="144" src="https://rjlipton.files.wordpress.com/2020/04/two.png?w=300&amp;h=144" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
There is a large literature on the <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake-cutting</a> problem. Its creator, Hugo Steinhaus, noted:</p>
<blockquote><p><b> </b> <em> Interesting mathematical problems arise if we are to determine the minimal numbers of “cuts” necessary for fair division. </em>
</p></blockquote>
<p/><p>
We have taken the quote from an <a href="https://medium.com/cantors-paradise/envy-free-cake-cutting-procedures-de3cf13c5d3d">article</a> on <em>Medium</em> that neatly conveys details on various protocols. Some main results are: </p>
<ul>
<li>
The Selfridge-Conway discrete procedure produces an envy-free division for <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> people using at most <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/> cuts. <p/>
</li><li>
The Brams-Taylor-Zwicker moving knives procedure produces an envy-free division for <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> people using at most <img alt="{11}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{11}"/> cuts. <p/>
</li><li>
Three different procedures produce an envy-free division for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> people. Both algorithms require a finite but unbounded number of cuts. That is to say, the number of cuts may depend on details of their preference functions. <p/>
</li><li>
The procedure by Aziz and Mackenzie finds an envy-free division for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> people in a bounded number of cuts.
</li></ul>
<p>The last is the result in the CACM paper. Note, the number of cuts can be large: 	</p>
<p align="center"><img alt="\displaystyle  n^{n^{n^{n^{n^{n}}}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n%5E%7Bn%5E%7Bn%5E%7Bn%5E%7Bn%5E%7Bn%7D%7D%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n^{n^{n^{n^{n^{n}}}}}. "/></p>
<p>Even for <img alt="{n=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=2}"/> this is immense, galactic. This should be compared to the best lower bound that is order <img alt="{n^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{2}}"/>. This gap is even larger than the usual gaps we find in complexity theory. The P=NP question is only one exponential not five.</p>
<p>
This has started me thinking: what exactly is the relationship between this and <em>proof complexity</em>? The latter has well-established relationships to complexity-class questions. The link from proofs in various systems of <a href="https://en.wikipedia.org/wiki/Bounded_arithmetic">bounded arithmetic</a> goes through the heart of P=NP. See for instance these <a href="https://www.math.ucsd.edu/~sbuss/ResearchWeb/StPetersburg_BoundedArith_2016/talkAllSlides_Corrected.pdf">slides</a> by Sam Buss and <a href="https://www.math.ucsd.edu/~sbuss/ResearchWeb/Barbados95Notes/reporte.pdf">notes</a> that were scribed by Ken and others. What I am puzzled by is that in most cases the blowup is only one or two exponentials. The setting with cake-cutting is different, but how different? </p>
<p>
</p><p/><h2> Easy Cases </h2><p/>
<p/><p>
The Aziz and Mackenzie algorithm takes a long time. It is a nontrivial result, but not one that applies in any practical case. It always takes way too long. The cake will be stale by the time the agents have agreed on their pieces. </p>
<p>
This raises a question, that also applies to many computational problems. Is there a way cut a cake faster on some interesting examples? We can explain this by the analogy to sorting. The fastest sorting algorithms run in <img alt="{O(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n \log n)}"/> time where there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> objects. But what happens if the objects are already in sorted order? Or at least close to sorted order? The answer is it depends:</p>
<ol>
<li>
Some sorting algorithms always take the same time, independent of the input structure. <p/>
</li><li>
There are other sorting algorithms that can take advantage of the nature of the input.
</li></ol>
<p>
That is some sorting algorithms can run say in linear time if the input is almost sorted. For the cake cutting problem we ask:</p>
<blockquote><p><b> </b> <em> <i>Is there a way to cut cakes that is envy-free when the agents have some property <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{P}"/>?</i> </em>
</p></blockquote>
<p/><p>
We do not know the answer, but we think it is an interesting question. Here is an example. Suppose that the agents have the same measures. That is, they evaluate every piece of cake in the same way. </p>
<p>
If we <em>know</em> this—and if we continue our supposition above that Bob can cut with exact precision—then there is an easy answer: Have Bob do the cuts. Then all agents will be equally happy since they have the same measures. The question is, what if we do not know? I believe there should be some theorem like this:</p>
<blockquote><p><b>Theorem 1 (Conjecture)</b> <em> There is an envy-free algorithm that operates in <img alt="{O(n^{2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{2})}"/> time the algorithm so that either: </em></p><em>
<ol>
<li>
It yields an envy-free solution, or <p/>
</li><li>
It determines that some agents have different measures.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
In the second case the cake will be cut as before. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I originally planned on discussing size and complexity of proofs. This is driven by the complexity of the cake cutting algorithms. They tend to have lots of cases and are difficult to understand.<br/>
<a href="https://rjlipton.wordpress.com/2020/04/18/proof-and-cake-envy/over/" rel="attachment wp-att-16973"><img alt="" class="aligncenter size-full wp-image-16973" src="https://rjlipton.files.wordpress.com/2020/04/over.png?w=600"/></a><br/>
They are also difficult to find—this is why cake cutting questions have been resistance to progress. More on this in the future. </p>
<p>[Edit <img alt="n&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n&gt;2"/> in Fermat example]</p></font></font></div>
    </content>
    <updated>2020-04-18T16:59:55Z</updated>
    <published>2020-04-18T16:59:55Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Algorithms"/>
    <category term="cake-cutting"/>
    <category term="galactic algorithms"/>
    <category term="open problems"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-21T00:21:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/052</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/052" rel="alternate" type="text/html"/>
    <title>TR20-052 |  On One-way Functions and Kolmogorov Complexity | 

	Rafael Pass, 

	Yanyi Liu</title>
    <summary>We prove the equivalence of two fundamental problems in the theory of computation:

- Existence of one-way functions: the existence of one-way functions (which in turn are equivalent to pseudorandom generators, pseudorandom functions, private-key encryption schemes, digital signatures, commitment schemes, and more).
  
- Mild average-case hardness of $K^{poly}$-complexity: the existence of polynomials $t,p$ such that no PPT algorithm can determine the $t$-time bounded Kolmogorov Complexity, $K^t$, for more than a $1-\frac{1}{p(n)}$ fraction of $n$-bit strings.

In doing so, we present the first natural, and well-studied, computational problem characterizing ``non-trivial'' complexity-based Cryptography: ``Non-trivial'' complexity-based Cryptography is possible iff $K^{poly}$ is mildly hard-on average.</summary>
    <updated>2020-04-18T09:44:35Z</updated>
    <published>2020-04-18T09:44:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/051</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/051" rel="alternate" type="text/html"/>
    <title>TR20-051 |  Is it Easier to Prove Theorems that are Guaranteed to be True? | 

	Rafael Pass, 

	Muthuramakrishnan Venkitasubramaniam</title>
    <summary>Consider the following two fundamental open problems in complexity theory: (a) Does a hard-on-average language in $\NP$ imply the existence of one-way functions?, or (b) Does a hard-on-average language in NP imply a hard-on-average problem in TFNP (i.e., the class of total NP search problem)? Our main result is that the answer to (at least) one of these questions is yes.
 
Both one-way functions and problems in TFNP can be interpreted as promise-true distributional NP search problems---namely, distributional search problems where the sampler only samples true statements. As a direct corollary of the above result, we thus get that the existence of a hard-on-average distributional NP search problem implies a hard-on-average promise-true distributional NP search problem. In other words,” It is no easier to find witnesses (a.k.a. proofs) for efficiently-sampled statements (theorems) that are guaranteed to be true.”?

This result follows from a more general study of interactive puzzles---a generalization of average-case hardness in NP—and in particular, a novel round-collapse theorem for computationally-sound protocols, analogous to Babai-Moran's celebrated round-collapse theorem for information-theoretically sound protocols. As another consequence of this treatment, we show that the existence of O(1)-round public-coin non-trivial arguments (i.e., argument systems that are not proofs) imply the existence of a hard-on-average problem in NP/poly.</summary>
    <updated>2020-04-18T09:42:43Z</updated>
    <published>2020-04-18T09:42:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/050</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/050" rel="alternate" type="text/html"/>
    <title>TR20-050 |  Unexpected Hardness Results for Kolmogorov Complexity Under Uniform Reductions | 

	Shuichi Hirahara</title>
    <summary>Hardness of computing the Kolmogorov complexity of a given string is closely tied to a security proof of hitting set generators, and thus understanding hardness of Kolmogorov complexity is one of the central questions in complexity theory.  In this paper, we develop new proof techniques for showing hardness of computing Kolmogorov complexity under *surprisingly efficient reductions*, which were previously conjectured to be impossible.  It is known that the set $R_K$ of Kolmogorov-random strings is PSPACE-hard under polynomial-time Turing reductions, i.e., $PSPACE \subset P^{R_K}$, and that $NEXP \subset NP^{R_K}$, which was conjectured to be tight by Allender (CiE 2012).  We prove that $EXP^{NP} \subset P^{R_K}$, which simultaneously improves these hardness results and refutes the conjecture of Allender under the plausible assumption that $EXP^{NP} \neq NEXP$.  At the core of our results is a new security proof of a pseudorandom generator via a black-box uniform reduction, which overcomes an impossibility result of Gutfreund and Vadhan (RANDOM/APPROX 2008).

Our proof techniques have further consequences, including:

1.  Applying our proof techniques to the case of resource-bounded Kolmogorov complexity, we obtain NP-hardness of the problem $MINcKT^{SAT}$ of computing conditional polynomial-time-bounded SAT-oracle Kolmogorov complexity under polynomial-time deterministic reductions.  In contrast, the Minimum SAT-Oracle Circuit Size Problem, which is a version of sublinear-time-bounded Kolmogorov complexity, cannot be NP-hard under polynomial-time deterministic reductions without resolving $EXP \neq ZPP$.  Our hardness result is the first result that overcomes the non-NP-hardness results of MCSP.  We also prove DistNP-hardness of $MINKT^{SAT}$, which is a partial converse of the approach of Hirahara (FOCS 2018) for proving the equivalence between worst-case and average-case complexity of NP.

2.  We prove $S_2^p$-hardness of Kolmogorov complexity under quasi-polynomial-time *nonadaptive* reductions.  This is the first result that overcomes a P/poly barrier result of Allender, Buhrman, Friedman, and Loff (MFCS 2012).

We also establish a firm link between non-trivial satisfiability algorithms and immunity of random strings, and obtain the following unconditional lower bounds.

1.  It has been a long-standing open question whether the set of subexponential-time-bounded Kolmogorov-random strings is decidable in P.  We resolve this open question, by showing that the set of super-polynomial-time-bounded Kolmogorov-random strings is P-immune, which is a much stronger lower bound than an average-case lower bound.

2.  The set of Levin's Kolmogorov-random strings is (P-uniform ACC)-immune.</summary>
    <updated>2020-04-18T07:45:52Z</updated>
    <published>2020-04-18T07:45:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/049</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/049" rel="alternate" type="text/html"/>
    <title>TR20-049 |  Automating Cutting Planes is NP-Hard | 

	Mika Göös, 

	Sajin Koroth, 

	Ian Mertz, 

	Toniann Pitassi</title>
    <summary>We show that Cutting Planes (CP) proofs are hard to find: Given an unsatisfiable formula $F$,

(1) it is NP-hard to find a CP refutation of $F$ in time polynomial in the length of the shortest such refutation; and

(2) unless Gap-Hitting-Set admits a nontrivial algorithm, one cannot find a tree-like CP refutation of $F$ in time polynomial in the length of the shortest such refutation.

The first result extends the recent breakthrough of Atserias and Muller (FOCS 2019) that established an analogous result for Resolution. Our proofs rely on two new lifting theorems: (1) Dag-like lifting for gadgets with many output bits. (2) Tree-like lifting that simulates an $r$-round protocol with gadgets of query complexity $O(\log r)$ independent of input length.</summary>
    <updated>2020-04-16T22:12:13Z</updated>
    <published>2020-04-16T22:12:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/048</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/048" rel="alternate" type="text/html"/>
    <title>TR20-048 |  Improved lifting theorems via robust sunflowers | 

	Jiapeng Zhang, 

	Shachar Lovett, 

	Raghu Meka</title>
    <summary>Lifting theorems are a generic way to lift lower bounds in query complexity to lower bounds in communication complexity, with applications in diverse areas, such as combinatorial optimization, proof complexity, game theory. Lifting theorems rely on a gadget, where smaller gadgets give stronger lower bounds. However, existing proof techniques are known to require somewhat large gadgets.

We focus on one of the most widely used gadgets, the index gadget. For this gadget, existing lifting techniques are known to require at least a quadratic gadget size. We develop a new approach to prove lifting theorems for the indexing gadget, based on a novel connection to the recently developed robust sunflower lemmas. We show that this allows to reduce the gadget size to linear. We conjecture that it can be further improved to poly logarithmic, similar to the known bounds for the corresponding robust sunflower lemmas.</summary>
    <updated>2020-04-16T17:49:17Z</updated>
    <published>2020-04-16T17:49:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/047</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/047" rel="alternate" type="text/html"/>
    <title>TR20-047 |  Explicit Uniquely Decodable Codes for Space Bounded Channels That Achieve List-Decoding Capacity | 

	Jad Silbak, 

	Ronen Shaltiel</title>
    <summary>We consider codes for space bounded channels. This is a model for communication under noise that was introduced by Guruswami and Smith (J. ACM 2016) and lies between the Shannon (random) and Hamming (adversarial) models. In this model, a channel is a space bounded procedure that reads the codeword in one pass, and modifies at most a $p$ fraction of the bits of the codeword.

Explicit uniquely decodable codes for space bounded channels: Our main result is that for every $0 \le p \le \frac{1}{4}$, there exists a constant $\delta\ge 0$ and a \emph{uniquely decodable} code that is \emph{explicit} (meaning that encoding and decoding are in poly-time) and has rate $1-H(p)$ for channels with space $n^{\delta}$.

This improves upon previous explicit codes by Guruswami and Smith, and Kopparty, Shaltiel and Silbak (FOCS 2019). Specifically, we obtain the same space and rate as earlier works, even though prior work gave only list-decodable codes (rather than uniquely decodable codes).

Complete characterization of the capacity of space bounded channels: Together with a result by Guruswami and Smith showing the impossibility of unique decoding for $p \ge \frac{1}{4}$, our techniques also give a complete characterization of the capacity $R(p)$ of space $n^{1-o(1)}$ channels, specifically: $R(p)=1-H(p)$ for $0 \le p \le 1/4$ and $R(p)=0$ for $p \ge 1/4$.

In particular, $R(\cdot)$ is not continuous at $p=1/4$. This capacity is strictly larger than the capacity of Hamming channels for every $0 \le p \le \frac{1}{4}$, and matches the capacity of list decoding, and binary symmetric channels in this range.


Our results are incomparable to recent work on casual channels. Casual channels are stronger channels in which the channel reads the codeword in one pass, but there is no space restriction. The best known codes for casual channels, due to Chen, Jaggi and Langberg (STOC 2015), are shown to exist by the probabilistic method, and no explicit codes are known. Furthermore, our results imply that for $p\ge p_0 \approx 0.0804$, there is a separation between the capacities of space bounded channels and casual channels, and the capacity of the former is strictly larger than that of the latter.


Our approach builds on previous explicit list decodable codes for space bounded channels. We introduce and study a notion of ``\emph{evasivenss}'' of codes, which is concerned with whether a decoding algorithm rejects a word that is obtained when a channel induces few errors to a \emph{uniformly chosen} string. We use evasiveness (as well as several additional new ideas related to coding theory and pseudorandomness) to identify the ``correct'' message in the list. Loosely speaking, this is achieved by arguing that on ``incorrect messages'' the decoding algorithm cannot distinguish the codeword from a uniform string.</summary>
    <updated>2020-04-16T10:28:32Z</updated>
    <published>2020-04-16T10:28:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Mathematics as a team sport (). What a week-long research workshop at Oberwolfach (or Dagstuhl, or many similar retreats) can be like. The workshop in the link is on low-dimensional topology, but the story would be the same for many other subjects. In late March, instead of attending a Bellairs workshop, we all collaborated remotely. I think we got a fair amount of research accomplished, but I didn’t have the same sense of all being brought together to do that one thing.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematics-as-a-team-sport-20200331/">Mathematics as a team sport</a> (<a href="https://mathstodon.xyz/@11011110/103927542292984705"/>). What a week-long research workshop at Oberwolfach (or Dagstuhl, or many similar retreats) can be like. The workshop in the link is on low-dimensional topology, but the story would be the same for many other subjects. In late March, instead of attending a Bellairs workshop, we all collaborated remotely. I think we got a fair amount of research accomplished, but I didn’t have the same sense of all being brought together to do that one thing.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.11832">Semidefinite programming bounds for the average kissing number</a> (<a href="https://mathstodon.xyz/@11011110/103932970304148800"/>). Spheres kiss by touching with no overlap. The kissing number is how many unit spheres can touch a central one, and lattice kissing number is how many can touch in a lattice packing; both are 12 in 3d. Average kissing number is for finitely many non-unit spheres. It is ≥ lattice kissing number and ≤ 2x kissing number. One of my papers has a slightly better lower bound in 3d, and now we have better upper bounds in many dimensions.</p>
  </li>
  <li>
    <p><a href="https://mathsedideas.blogspot.com/p/resources.html#RAMs">320 Random Acts of Maths</a> (<a href="https://mathstodon.xyz/@antoinechambertloir/103920121638187355"/>). Pocket-sized problems, teasers, curios, provocations, inspirations, etc.</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/d41586-020-00998-2">Mochizuki will publish his purported proof of the abc conjecture in the journal of which he is editor in chief</a> (<a href="https://mathstodon.xyz/@11011110/103941722283312831"/>, <a href="https://retractionwatch.com/2020/04/04/weekend-reads-covid-19-and-peer-review-blaming-a-spell-checker-for-plagiarism-the-fastest-retracting-country/">via</a>). “The latest announcement seems unlikely to move many researchers over to Mochizuki’s camp.”</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Ring_lemma">The ring lemma</a> (<a href="https://mathstodon.xyz/@11011110/103950535538050348"/>). New Wikipedia article on the ratio between sizes of adjacent circles in a circle packing.</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/site/calculatinghistory/home/computing-linkages">Computing linkages</a> (<a href="https://mathstodon.xyz/@esoterica/103950724802083262"/>). Article by Andries de Man on computing devices built with hinged rods instead of electronics or gears.</p>
  </li>
  <li>
    <p><a href="https://bl.ocks.org/robinhouston/6096950">Doyle spiral explorer</a> (<a href="https://mathstodon.xyz/@11011110/103961199355813355"/>). If you slur “Doyle spiral” enough it kind of sounds like “Dora”. You can also <a href="https://observablehq.com/@mbostock/double-doyle-spiral">Möbius transform these things and get double spirals</a>.</p>
  </li>
  <li>
    <p>This photo (<a href="https://mathstodon.xyz/@11011110/103965972080045328"/>) is actually from a year ago but I neglected to upload it then and only rediscovered it recently while attempting to explain to an older relative, over the phone, how to attach images to text messages. It’s a shallow Showa bowl from Japan, bought when my wife and I visited Tokyo three years ago. We usually hold fruit in it; at the time I posted, it held three bananas and three lemons.</p>

    <p style="text-align: center;"><a href="https://www.ics.uci.edu/~eppstein/pix/radialbowl/index.html"><img alt="Showa bowl from above" src="https://www.ics.uci.edu/~eppstein/pix/radialbowl/RadialBowl-m.jpg" style="border-style: solid; border-color: black;"/></a></p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/C._Doris_Hellman">C. Doris Hellman, historian of astronomy</a> (<a href="https://mathstodon.xyz/@11011110/103970811680488005"/>), now a Good Article on Wikipedia. Through Hellman’s work on the Great Comet of 1577, historians came to see how Tycho Brahe’s observations of the comet moving unobstructed through translunar space <a href="https://en.wikipedia.org/wiki/Copernican_Revolution">became key evidence for heliocentrism and against the geocentric model of crystal spheres holding up the planets</a>. She also translated the definitive biography of Johannes Kepler from German into English.</p>
  </li>
  <li>
    <p>Found in Friedman’s <em>A History of Folding in Mathematics</em>, p. 71, a quote from Francesco Maurolico from <span style="white-space: nowrap;">1537 (<a href="https://mathstodon.xyz/@11011110/103978188972978011"/>):</span> “Item manifestum est in unoquoque regularium solidorum, numerum basium coniunctum cum numero cacuminum conflare numerum, qui binario excedit numerum laterum”. Except for the fact that he considers only Platonic solids, this is Euler’s formula  for convex polyhedra (in the equivalent form ), long before Euler (1752) and Descartes (1630).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Convex_hull">Convex hull</a> (<a href="https://mathstodon.xyz/@11011110/103981026707788374"/>), now a Good Article on Wikipedia.</p>
  </li>
  <li>
    <p>Appreciations of John Conway, following his death from the coronavirus (<a href="https://mathstodon.xyz/@11011110/103987909082094935"/>):</p>

    <ul>
      <li>
        <p><a href="https://cameroncounts.wordpress.com/2020/04/12/john-conway/">Peter Cameron</a></p>
      </li>
      <li>
        <p><a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">Terry Tao</a></p>
      </li>
      <li>
        <p><a href="https://www.scottaaronson.com/blog/?p=4732">Scott Aaronson</a></p>
      </li>
      <li>
        <p><a href="https://www.solipsys.co.uk/new/RememberingConway.html?td12mn">Colin Wright</a></p>
      </li>
      <li>
        <p><a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">Richard Lipton and Ken Regan</a></p>
      </li>
      <li>
        <p><a href="https://xkcd.com/2293/">xkcd</a></p>
      </li>
      <li>
        <p><em><a href="http://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">The Guardian</a></em></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="http://www.dam.brown.edu/people/mumford/blog/2015/WakeUp.html">Wake up!</a> (<a href="https://mathstodon.xyz/@11011110/103998469608885562"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/A_K_Peters">via</a>). A five-year-old blog post by David Mumford on the problems of corporate takeover of academic publishing, and the ensuing destruction of traditional author-editor relations.</p>
  </li>
  <li>
    <p><a href="http://utf8everywhere.org/">utf8 everywhere</a> (<a href="https://mathstodon.xyz/@11011110/104001143871939014"/>, <a href="https://news.ycombinator.com/item?id=22867503">via</a>). Mostly a manifesto about how we should be using utf8 instead of utf16 for unicode text files. But I think the sentiment that we should be treating utf8 as the default instead of ascii (which still is the actual default in many situations) is also valid.</p>
  </li>
  <li>
    <p>In <a href="https://11011110.github.io/blog/2020/03/29/backyard-sunlight.html">the previous batch of photos</a> the stripy shadows were artificial (caused by the slats of a trellis shading our patio) but this time they’re natural: they come from the fronds of one of the palm trees in our garden, shading the trunk of the tree (<a href="https://mathstodon.xyz/@11011110/104005420231873385"/>).</p>

    <p style="text-align: center;"><a href="https://www.ics.uci.edu/~eppstein/pix/palmshadow/index.html"><img alt="Palm tree casts shadows on itself" src="https://www.ics.uci.edu/~eppstein/pix/palmshadow/PalmShadow-m.jpg" style="border-style: solid; border-color: black;"/></a></p>
  </li>
</ul></div>
    </content>
    <updated>2020-04-15T21:54:00Z</updated>
    <published>2020-04-15T21:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-20T01:32:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/046</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/046" rel="alternate" type="text/html"/>
    <title>TR20-046 |  A Robust Version of Heged\H{u}s&amp;#39;s Lemma, with Applications | 

	Srikanth Srinivasan</title>
    <summary>Heged\H{u}s's lemma is the following combinatorial statement regarding polynomials over finite fields. Over a field $\mathbb{F}$ of characteristic $p &gt; 0$ and for $q$ a  power of $p$, the lemma says that any multilinear polynomial $P\in \mathbb{F}[x_1,\ldots,x_n]$ of degree less than $q$ that vanishes at all points in $\{0,1\}^n$ of Hamming weight $k\in [q,n-q]$ must also vanish at all points in $\{0,1\}^n$ of weight $k + q$. This lemma was used by Heged\H{u}s (2009) to give a solution to \emph{Galvin's problem}, an extremal problem about set systems; by Alon, Kumar and Volk (2018) to improve the best-known multilinear circuit lower bounds; and by Hrube\v{s}, Ramamoorthy, Rao and Yehudayoff (2019) to prove optimal lower bounds against depth-$2$ threshold circuits for computing some symmetric functions. 
		
		In this paper, we formulate a robust version of Heged\H{u}s's lemma. Informally, this version says that if a polynomial of degree $o(q)$ vanishes at most points of weight $k$, then it vanishes at many points of weight $k+q$. We prove this lemma and give the following three different applications.
		
		1. Degree lower bounds for the coin problem: The \emph{$\delta$-Coin Problem} is the problem of distinguishing between a coin that is heads with probability $((1/2) + \delta)$ and a coin that is heads with probability $1/2$. We show that over a field of positive (fixed) characteristic, any polynomial that solves the $\delta$-coin problem with error $\varepsilon$ must have degree $\Omega(\frac{1}{\delta}\log(1/\varepsilon)),$ which is tight up to constant factors.
		
		2. Probabilistic degree lower bounds: The \emph{Probabilistic degree} of a Boolean function is the minimum $d$ such that there is a random polynomial of degree $d$ that agrees with the function at each point with high probability. We give tight lower bounds on the probabilistic degree of \emph{every} symmetric Boolean function over positive (fixed) characteristic. As far as we know, this was not known even for some very simple functions such as unweighted Exact Threshold functions, and constant error.
		
		3. A robust version of the combinatorial result of Heged\H{u}s (2009) mentioned above.</summary>
    <updated>2020-04-15T16:25:07Z</updated>
    <published>2020-04-15T16:25:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-104815394733465706</id>
    <link href="https://blog.computationalcomplexity.org/feeds/104815394733465706/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/theoretical-computer-science-for-future.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/104815394733465706" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/104815394733465706" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/theoretical-computer-science-for-future.html" rel="alternate" type="text/html"/>
    <title>Theoretical Computer Science for the Future</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Guest post by the TCS4F initiative
(Antoine Amarilli, Thomas Colcombet, Hugo Férée, Thomas Schwentick) </i><div><br/></div><div><a href="https://tcs4f.org/">TCS4F</a> is an initiative by theoretical computer scientists who are
concerned about that other major crisis of our time: climate change. We
anticipate that the climate crisis will be a major challenge of the
decades to come, that it will require major changes at all levels of
society to mitigate the harm that it will cause, and that researchers in
theoretical computer science, like all other actors, must be part of the
solution and not part of the problem.</div>
<div><br/></div><div>Our initiative is to propose a <a href="https://tcs4f.org/">manifesto</a> to commit
to a reduction of greenhouse gas emissions: following <a href="https://www.ipcc.ch/2018/10/08/summary-for-policymakers-of-ipcc-special-report-on-global-warming-of-1-5c-approved-by-governments/">IPCC goals</a>, the
objective is to reduce by at least 50% before 2030 relative to pre-2020
levels. The manifesto is more than a simple expression of concern,
because it is a pledge with concrete objectives. However, it does not
prescribe specific measures, as we believe this discussion is not
settled yet and the right steps to take can vary depending on everyone's
practices. </div><div><br/>
The manifesto can be signed by individual researchers (like you, dear
reader!), by research groups, and by organizers of conferences and
workshops. Currently, over 50 researchers have signed it. The goal of
TCS4F is also to start organizing a community of concerned researchers,
across theoretical computer science, to think about the issue of climate
change and how to adjust what we do, in particular our travel habits. </div><div><br/>
We need your help to make this initiative a success and help theoretical
CS lead the way towards a sustainable, carbon-neutral future:</div><div><ul style="text-align: left;"><li>If you agree with our concerns and are ready to commit to reducing
 your carbon footprint, consider <a href="https://tcs4f.org/">signing the manifesto</a>. Signing is open to all researchers in
 theoretical CS in the broadest possible sense.</li><li>Advertise your support of the manifesto (e.g., by putting one of our
 badges on your webpage). Talk in your research teams and departments
 about the manifesto, and see if you can gather support for signing the
 manifesto collectively as a research group.</li><li>If you are involved in conferences and workshops, start a discussion
 about the carbon footprint of the event, and whether the event could
 commit to the manifesto's goal. Indeed, now that conferences across
 the globe are moving online because of the COVID-19 pandemic, it is a
 good time to discuss how conferences could evolve towards more
 sustainable models.</li><li>Spread the word about the issue of climate change and the TCS4F
 initiative, and encourage discussion of this important challenge in
 our communities. </li></ul></div><div>
As theoretical researchers, we are not used to discussing uncomfortable
non-scientific questions like the effects of our activities on the
world. However, we believe that the magnitude of the climate crisis
obliges us to act now as a community. We are confident that great
changes can be achieved if we do not limit our creativity to our
specific research areas and also use it to re-think our way to do
research.
<br/></div></div>
    </content>
    <updated>2020-04-15T13:42:00Z</updated>
    <published>2020-04-15T13:42:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-20T19:20:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/045</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/045" rel="alternate" type="text/html"/>
    <title>TR20-045 |  Learning sums of powers of low-degree polynomials in the non-degenerate case | 

	Ankit Garg, 

	Neeraj Kayal, 

	Chandan Saha</title>
    <summary>We develop algorithms for writing a polynomial as sums of powers of low degree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can be written as
$$f = c_1Q_1^{m} + \ldots + c_s Q_s^{m},$$
where each $c_i\in \mathbb{F}^{\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m = d$. In this paper, we give a $\text{poly}((ns)^t)$-time learning algorithm for finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy certain non-degeneracy conditions and $n$ is larger than $d^2$. The set of degenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a non-trivial variety and hence if the $Q_i$'s are chosen according to any reasonable (full-dimensional) distribution, then they are non-degenerate with high probability (if $s$ is not too large). This problem generalizes symmetric tensor decomposition, which corresponds to the $t = 1$ case and is widely studied, having many applications in machine learning. Our algorithm (for $t=2$) allows us to solve the moment problem for mixtures of zero-mean Gaussians in the non-degenerate case.

Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from a lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on how the spaces decompose. Such a scheme is present in a rudimentary form in an earlier work of Kayal and Saha. Here, we make it more general and detailed, and potentially applicable to learning other circuit models.

An exponential lower bound for the representation above (also known as homogeneous $\Sigma \wedge \Sigma \Pi^{[t]}$ circuits) is known using the shifted partials measure. However, the number of linear operators in shifted partials is exponential and also the non-degeneracy condition emerging out of this measure is unlikely to be satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit when the number of variables is large with respect to the degree. We bypass this hurdle by proving a lower bound (which is nearly as strong as the previous bound) using a novel variant of the partial derivatives measure, namely affine projections of partials (APP). The non-degeneracy conditions appearing from this new measure are satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit. The APP measure could be of independent interest for proving other lower bounds.</summary>
    <updated>2020-04-15T07:50:58Z</updated>
    <published>2020-04-15T07:50:58Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-21T00:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4740</id>
    <link href="https://www.scottaaronson.com/blog/?p=4740" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4740#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4740" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The quantum computer that knows all</title>
    <summary xml:lang="en-US">This is my first post in more than a month that’s totally unrelated to the covid crisis. Or rather, it’s related only insofar as it’s about a Hulu miniseries, the sort of thing that many of us have more occasion to watch while holed up at home. Three weeks ago, a journalist named Ben Lindbergh—who’d […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is my first post in more than a month that’s totally unrelated to the covid crisis.  Or rather, it’s related only insofar as it’s about a Hulu miniseries, the sort of thing that many of us have more occasion to watch while holed up at home.</p>



<p>Three weeks ago, a journalist named Ben Lindbergh—who’d previously asked me to <a href="https://www.scottaaronson.com/blog/?p=4184">comment on the scientific accuracy of <em>Avengers: Endgame</em></a>—asked me the same question about the miniseries <a href="https://en.wikipedia.org/wiki/Devs_(miniseries)">Devs</a>, which I hadn’t previously heard of.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">[Warning: Spoilers follow]</span></strong></p>



<p>‘Devs,’ I learned, is a spooky sci-fi action thriller about a secretive Silicon Valley company that builds a quantum computer that can perfectly reconstruct the past, down to what Jesus looked like on the cross, and can also (at least up to a point) predict the future.</p>



<p>And I was supposed, not only to endure such a show, but to comment on the <em>accuracy</em> of its invocations of quantum computing?  This didn’t sound promising.</p>



<p>But, y’know, I was at home quarantined.  So I agreed to watch the first episode.  Which quickly turned into the second, third, fourth, fifth, sixth, and seventh episodes (the eighth and final one isn’t out yet).</p>



<p>It turns out that ‘Devs’ isn’t too bad, <em>except</em> that it’s not particularly about quantum computers.  The latter is simply a buzzword chosen by the writers for a plot concept that would’ve been entirely familiar to the ancient Greeks, who called it the Delphic Oracle.  You know, the mysterious entity that prophesies your fate, so then you try to escape the prophecy, but your very evasive maneuvers make the prophecy come true?  Picture that, except with qubits—and for some reason, in a gleaming golden laboratory that has components that float in midair.</p>



<figure class="wp-block-image"><img alt="Devs Trailer Reveals New Look at FX-Hulu's Upcoming Limited Series" src="https://cdn1-www.comingsoon.net/assets/uploads/2020/01/Screen-Shot-2020-01-09-at-2.52.52-PM.png"/>If you’re never visited a real quantum computing lab: they’re messier and a lot less golden.</figure>



<p>At this point, I’ll just link you to Ben Lindbergh’s article about the show: <a href="https://www.theringer.com/tv/2020/4/10/21216149/devs-hulu-quantum-physics-philosophy-alex-garland">Making Sense of the Science and Philosophy of ‘Devs.’</a>  His long and excellent piece quotes me extensively enough that I see no need <em>also</em> to analyze the show in this blog post.  (It also quotes several academic philosophers.)</p>



<p>Instead, I’ll just share a few tidbits that Ben left out, but that might be amusing to quantum computing fans.</p>



<ul><li>The first episode opens with a conversation between two characters about how even “elliptical curve” cryptography is insecure against attack by quantum computers.  So I immediately knew <em>both</em> that the writers had one or more consultants who actually knew something about QC, and also that those consultants were not as heavily involved as they could’ve been.</li></ul>



<ul><li>Similarly: in a later scene, some employees at the secretive company hold what appears to be a reading group about Shor’s algorithm.  They talk about waves that interfere and cancel each other out, which is great, but beyond that their discussion sounded to me like nonsense.  In particular, their idea seemed to be that the waves would reinforce at the prime factors p and q themselves, rather than at inverse multiples of the period of a periodic function that only indirectly encodes the factoring problem.  (What do you say: should we let this one slide?)</li></ul>



<ul><li>“How many qubits does this thing have?” “A number that there would be no point in describing as a number.”  ROFL</li></ul>



<ul><li>In the show, a crucial break comes when the employees abandon a prediction algorithm based on the deBroglie-Bohm pilot wave interpretation, and substitute one based on Everett’s many-worlds interpretation.  Which I could actually <em>almost</em> believe, except that the many-worlds interpretation seems to contradict the entire premise of the rest of the show?</li></ul>



<ul><li>A new employee, after he sees the code of the superpowerful quantum computer for the first time, is so disoriented and overwhelmed that he runs and vomits into a toilet.  I, too, have had that reaction to the claims of certain quantum computing companies, although in some sense for the opposite reason.</li></ul>



<p>Anyway, none of the above addresses the show’s central conceit: namely, that the <a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">Laplace demon</a> can be made real, the past and future rendered fully knowable (with at most occasional breaks and exceptions) by a machine that’s feasible to build.  This conceit is fascinating to explore, but also <em>false</em>.</p>



<p>In the past, if you’d asked me to justify its falsity, I would’ve talked about chaos, and quantum mechanics, and the unknowability of the fine details of the universe’s state; I might’ve even pointed you to my <a href="https://arxiv.org/abs/1306.0159">Ghost in the Quantum Turing Machine</a> essay.  I also would’ve mentioned the severe conceptual difficulties in forcing Nature to find a fixed-point of a universe where you get to see your own future and act on that information (these difficulties are just a variant of the famous <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">Grandfather Paradox</a>).</p>



<p>But it occurs to me that, just as the coronavirus has now made plain the nature of exponential growth, even to the world’s least abstract-minded person, so too it’s made plain the universe’s unpredictability.  Let’s put it this way: do you find it plausible that the quantum computer from ‘Devs,’ had you booted it up six months ago, would’ve known the exact state of every nucleotide in every virus in every bat in Wuhan?  No?  Then it wouldn’t have known our future.</p>



<p>And I see now that I’ve violated my promise that this post would have nothing to do with covid.</p></div>
    </content>
    <updated>2020-04-15T00:24:30Z</updated>
    <published>2020-04-15T00:24:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-20T22:43:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16931</id>
    <link href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/" rel="alternate" type="text/html"/>
    <title>John Horton Conway 1937–2020</title>
    <summary>An appreciation Names for large numbers source John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope. Today Ken and I thought we would reflect on some of Conway’s many contributions and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>An appreciation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg"><img alt="" class="alignright wp-image-16933" height="240" src="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg?w=192&amp;h=240" width="192"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Names for large numbers <a href="https://sites.google.com/site/largenumbers/home/2-4/6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope.</p>
<p>
Today Ken and I thought we would reflect on some of Conway’s many contributions and emphasize three in which we see connections to computational complexity. </p>
<p>
Conway was a Fellow of the Royal Society, and was the first recipient of the London Mathematical Society’s Pólya Prize. His nomination to the Royal Society reads:</p>
<blockquote><p><b> </b> <em> A versatile mathematician who combines a deep combinatorial insight with algebraic virtuosity, particularly in the construction and manipulation of “off-beat” algebraic structures which illuminate a wide variety of problems in completely unexpected ways. He has made distinguished contributions to the theory of finite groups, to the theory of knots, to mathematical logic (both set theory and automata theory) and to the theory of games (as also to its practice). </em>
</p></blockquote>
<p>
</p><p/><h2> A Life Force </h2><p/>
<p/><p>
Conway may be most noted for his game of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Life</a>. This is a two-dimensional cellular automaton. Conway invented it in 1970, which he rounded up from 1969. The game—and Martin Gardner’s 1970 column on it in <em>Scientific American</em>—made him famous in the wider community. The website <a href="https://www.conwaylife.com/">conwaylife.com</a> and <a href="https://catagolue.appspot.com/home">several</a> <a href="https://tebs-game-of-life.com/">others</a> link to more information than we could digest in a lifetime.</p>
<p>
We want to emphasize instead how Conway was a special force in mathematics. He applied an almost elementary approach to deep hard problems of mathematics. This is a unique combination. There have been mathematicians who worked on deep problems and also on recreational math, but few who established integral flows across the boundary between them. Conway infused both with magic in a way conveyed by an iconic photograph of his Princeton office in 1993:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg"><img alt="" class="aligncenter wp-image-16934" height="270" src="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg?w=450&amp;h=270" width="450"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Guardian<i> via Dith Pran, <i>NY Times</i> <a href="https://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">source</a> </i></i></font>
</td>
</tr>
</tbody></table>
<p>
What Ken remembers is how accessible Conway was <em>outside</em> his office. “I know I met him at least once while I was an undergraduate at Princeton in 1979 or 1980, though this is overlaid by a memory of finding just him and a few others in the Fine Hall tea room when I was there for my tenth reunion in 1991. My most evocative memory is when Conway gave an evening talk to the undergraduate mathematics club at Oxford when I was there sometime after 1981. It was relatively sparsely attended, perhaps because it was literally a dark and stormy winter night. But after his lecture we all got to huddle around him for another hour in the tea room as he regaled us with stories and mathematical problems.” </p>
<p>
We also remember that Conway was one of Andrew Wiles’s main confidants during the months before Wiles announced his proof of Fermat’s Last Theorem in June 1993. Here is a <a href="https://www.pbs.org/wgbh/nova/transcripts/2414proof.html">transcript</a> of a PBS Nova documentary on the proof in which Conway appears prominently. Ken has picked out two of Conway’s other contributions that we feel may have untapped use for research in complexity theory.</p>
<p>
</p><p/><h2> Conway’s Numbers </h2><p/>
<p/><p>
One of this blog’s “invariants” is first-name last-name style, thus “Godfrey Hardy” not “G.H. Hardy.” But we make an exception in Conway’s case. Partly this owes to how his initials were amplified by Donald Knuth in his novella <em>Surreal Numbers</em>:</p>
<blockquote><p><b> </b> <em> In the beginning, everything was void, and J.H.W.H. Conway began to create numbers. </em>
</p></blockquote>
<p/><p>
Besides the void (that is, <img alt="{\emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset}"/>), the creation uses the idea of a <em>left set</em> <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and a <em>right set</em> <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>. Every number has the form <img alt="{\langle L~|~R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L~|~R \rangle}"/>. The initial number is </p>
<p align="center"><img alt="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. "/></p>
<p>
Once a number is generated, it can be in the <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> or <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> of other numbers. Thus, next come </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Clangle+0+%7E%7C%7E+%5Cemptyset+%5Crangle+%26%3D%26+1%5C%5C+%5Clangle+%5Cemptyset+%7E%7C%7E+0+%5Crangle+%26%3D%26+-1.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} "/></p>
<p>
You might think of <img alt="{\langle 0 ~|~ 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 0 ~|~ 0 \rangle}"/> next, but it violates the invariant </p>
<p align="center"><img alt="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+%5Cell+%5Cin+L%29%28%5Cforall+r+%5Cin+R%29%5Cneg+%28r+%5Cleq+%5Cell%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). "/></p>
<p>which defines an <img alt="{\langle L~|~R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L~|~R \rangle}"/> <em>form</em> to be a <em>number</em>. </p>
<p>
The relation <img alt="{\leq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\leq}"/> is inductively defined for <img alt="{a = \langle L_a ~|~ R_a \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+%5Clangle+L_a+%7E%7C%7E+R_a+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a = \langle L_a ~|~ R_a \rangle}"/> and <img alt="{b = \langle L_b ~|~ R_b \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%3D+%5Clangle+L_b+%7E%7C%7E+R_b+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b = \langle L_b ~|~ R_b \rangle}"/> by </p>
<p align="center"><img alt="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Cleq+b+%5Cquad%5Cequiv%5Cquad+%28%5Cforall+%5Cell_a+%5Cin+L_a%29%28%5Cforall+r_b+%5Cin+R_b%29%5Cneg%28b+%5Cleq+%5Cell_a+%5C%3B%5Clor%5C%3B+r_b+%5Cleq+a%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). "/></p>
<p>
That is, no member of the left-set of <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> “bumps” <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> (in the sense of rowing races) and <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> does not bump any member of the right-set of <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>.  Note that <img alt="{R_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R_a}"/> and <img alt="{L_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_b}"/> are not involved—they already behave correctly owing to the invariant. The numbers <img alt="{a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b}"/> are equal if <img alt="{a \leq b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cleq+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a \leq b}"/> and <img alt="{b \leq a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cleq+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \leq a}"/> both hold. The rule for addition is </p>
<p align="center"><img alt="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%2B+b+%3D+%5Clangle+%28L_a+%5Cboxplus+b%29+%5Ccup+%28a+%5Cboxplus+L_b%29+%7E%7C%7E+%28a+%5Cboxplus+R_b%29+%5Ccup+%28R_a+%5Cboxplus+b%29+%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, "/></p>
<p>
where <img alt="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_a+%5Cboxplus+b+%3D+%5C%7B%5Cell_a+%2B+b%3A+%5Cell_a+%5Cin+L_a%5C%7D+%3D+b+%5Cboxplus+L_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}"/> and so on. The logical rule <img alt="{\emptyset \boxplus a = \emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset+%5Cboxplus+a+%3D+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset \boxplus a = \emptyset}"/> for any <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> makes the definition of addition well-founded. This yields the numerical fact </p>
<p align="center"><img alt="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+0+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%7E%7C%7E+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%5Crangle+%3D+%5Clangle%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. "/></p>
<p>
It is immediate that <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/> is commutative. There is also a rule for multiplication but addition gives us enough to talk about here.</p>
<p>
</p><p/><h2> Redundancy and Simplicity </h2><p/>
<p/><p>
It is straightforward to compute that <img alt="{0 + 1 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%2B+1+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 + 1 = 1}"/> and <img alt="{-1 + 0 = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%2B+0+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 + 0 = -1}"/>. Now consider: </p>
<p align="center"><img alt="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-1+%2B+1+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+1%29+%5Ccup+%28-1+%5Cboxplus+%5C%7B0%5C%7D%29+%7E%7C%7E+%28-1+%5Cboxplus+%5Cemptyset+%29+%5Ccup+%28%5C%7B0%5C%7D+%5Cboxplus+1%29%5Crangle+%3D+%5Clangle+-1+%7E%7C%7E+1%5Crangle.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. "/></p>
<p>This is a legal number. You can check that the relations <img alt="{\langle -1 ~|~ 1\rangle \leq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle -1 ~|~ 1\rangle \leq 0}"/> and <img alt="{0 \leq \langle -1 ~|~ 1\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \leq \langle -1 ~|~ 1\rangle}"/> both hold. Thus—as a number rather than a “form”—the number <img alt="{\langle -1 ~|~ 1\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle -1 ~|~ 1\rangle}"/> equals <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. </p>
<p>
That seems to make sense since <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> is the average of <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, but now compute <img alt="{2 = 1 + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2+%3D+1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2 = 1 + 1}"/> as a formal Conway number and consider <img alt="{c = \langle -1 ~|~ 2\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Clangle+-1+%7E%7C%7E+2%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c = \langle -1 ~|~ 2\rangle}"/>. This also satisfies the relations <img alt="{c \leq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c \leq 0}"/> and <img alt="{0 \leq c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \leq c}"/>, so <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> must likewise equal <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Thus <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> is not some kind of numerical interpolation between <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>. The interpretation that grabbed my imagination as a teenager in 1976 is that:</p>
<blockquote><p><b> </b> <em> <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> equals the <b>simplest</b> number that is between <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R}"/>. </em>
</p></blockquote>
<p/><p>
This is especially evocative in cases like <img alt="{\langle 1 ~|~ \emptyset \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+1+%7E%7C%7E+%5Cemptyset+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 1 ~|~ \emptyset \rangle}"/>, which is what one gets by computing <img alt="{1 + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 + 1}"/>. In general, <img alt="{m+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m+1}"/> is the simplest number between <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{\emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset}"/>. Conway made this a theorem by giving each number a set-theoretic ordinal for its “time of generation” and proved that <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> always equals a (the) least-ordinal number <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> such that <img alt="{\ell \leq c \leq r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cleq+c+%5Cleq+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell \leq c \leq r}"/> for every <img alt="{\ell \in L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cin+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell \in L}"/> and <img alt="{r \in R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \in R}"/>. </p>
<p>
Conway’s rules allow <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> to be infinite sets—any sets of numbers built by the rules of set theory. Then not only do all real numbers emerge at ordinal times, so do infinitesimals and further richness of structure. We should remember that Conway began as a set theorist with a dissertation under Harold Davenport titled <em>Homogeneous ordered sets</em>. All Conway numbers with finite creation times are dyadic rational numbers, which may seem trivial from the standpoint of set theory, but those are akin to binary strings. </p>
<p>
What became magic was how Conway’s rules characterize <em>games</em>. Through games we can also interpret forms like <img alt="{\langle 0 ~|~ 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 0 ~|~ 0 \rangle}"/> that are not numbers. I did not know about complexity when I purchased Conway’s <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">book</a> <em>On Numbers and Games</em> around 1980, let alone the connections between games and complexity. The book has a lot of depth that might be useful to complexity theory. To quote Peter Sarnak, per this <a href="https://www.ias.edu/ideas/2015/roberts-john-horton-conway">article</a> by Conway’s biographer Siobhan Roberts on Conway’s meeting with Kurt Gödel:</p>
<blockquote><p><b> </b> <em> The surreal numbers will be applied. It’s just a question of how and when. </em>
</p></blockquote>
<p>
</p><p>
</p><p>
</p><p/><h2> Modular Programming </h2><p/>
<p/><p>
Most of us know that the conditional-jump instruction</p>
<p>
<font size="+1"><tt><b><br/>
if (x == 0) goto k<br/>
</b></tt></font></p>
<p/><p><br/>
where <tt><b>k</b></tt> is the label of another instruction, creates a universal programming language when added to the usual programming primitives of assignment, sequencing, and simple arithmetic. Conway was a maven of the “modular-jump”:</p>
<p>
<font size="+1"><tt><b><br/>
if (x == 0 mod m) goto k.<br/>
</b></tt></font></p>
<p/><p><br/>
In complexity theory we know that mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> gates having 0-1 inputs define the idea of <img alt="{\mathsf{ACC}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}}"/> circuits, with <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/> denoting problems solved by families of these circuits having fixed depth and polynomial size. If we don’t insist on fixed depth and unary inputs, we get modular programs. They are more complex than <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/> circuits, but we can learn from what can be done <em>concretely</em> with them.</p>
<p>
Conway created a particular form of modular programs in a language he called <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4808-8_2">FRACTRAN</a>. A program is just a list of positive fractions <img alt="{\frac{a_r}{b_r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Ba_r%7D%7Bb_r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{a_r}{b_r}}"/> in lowest terms. The input is an integer <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> held in a separate register. Each fraction represents the code line</p>
<p/><p align="center"><img alt="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7Bif+%7D+%28n%2Aa_r+%5Cequiv+0+%5Cpmod%7Bb_r%7D%29+%5C%7B+n+%3D+n%5Cfrac%7Ba_r%7D%7Bb_r%7D%3B+%5Ctext%7Bgoto+start%7D+%5C%7D%3B+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; "/></p>
<p>
In other words, each iteration takes the first fraction <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> such that <img alt="{nf}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{nf}"/> is an integer and updates <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to <img alt="{nf}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{nf}"/>; if there is no such fraction then the program exits and outputs <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.</p>
<p>
For example, the following FRACTRAN program given in Wikipedia’s <a href="https://en.wikipedia.org/wiki/FRACTRAN">article</a> implicitly computes integer division: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B91%7D%7B66%7D%2C%7E%5Cfrac%7B11%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B33%7D%2C%7E%5Cfrac%7B85%7D%7B11%7D%2C%7E%5Cfrac%7B57%7D%7B119%7D%2C%7E%5Cfrac%7B17%7D%7B19%7D%2C%7E%5Cfrac%7B11%7D%7B17%7D%2C%7E%5Cfrac%7B1%7D%7B3%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. "/></p>
<p>The notation is unary: The input <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has the form <img alt="{2^n 3^d 11}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En+3%5Ed+11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n 3^d 11}"/> and the ouput is <img alt="{5^q 7^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%5Eq+7%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5^q 7^r}"/> where <img alt="{n = qd + r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+qd+%2B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = qd + r}"/> with remainder <img alt="{r &lt; d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3C+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r &lt; d}"/>. This already hints the fact that FRACTRAN is a universal programming language. Powers of primes serve as memory registers. The following program computes the Hamming weight <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> of the binary expansion of a natural number <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> encoded as <img alt="{2^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^x}"/>, returning the value <img alt="{13^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B13%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{13^k}"/>: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B33%7D%7B20%7D%2C%7E%5Cfrac%7B5%7D%7B11%7D%2C%7E%5Cfrac%7B13%7D%7B10%7D%2C%7E%5Cfrac%7B1%7D%7B5%7D%2C%7E%5Cfrac%7B2%7D%7B3%7D%2C%7E%5Cfrac%7B10%7D%7B7%7D%2C%7E%5Cfrac%7B7%7D%7B2%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. "/></p>
<p>This might help bridge to our notions of <img alt="{\mathsf{ACC}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}}"/>. The Wikipedia article does a good job of de-mystifying the fractions in terms of their actions on the prime-power registers under the unary-style encoding. We wonder what happens when we try to work directly with binary encodings. </p>
<p>
</p><p/><h2> The Collatz Example </h2><p/>
<p/><p>
The famous “<img alt="{3n+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n+1}"/>” problem of Lothar Collatz is a case in point. It iterates the function </p>
<p align="center"><img alt="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T%28n%29+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B3n%2B1%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+odd%7D+%5C%5C+%5Cfrac%7Bn%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+even%7D+%5Cend%7Bcases%7D++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  "/></p>
<p>The following FRACTRAN program <a href="https://hal.inria.fr/hal-00958971/document">given</a> by Kenneth Monks iterates <img alt="{T(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(n)}"/> under the unary encoding <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/>: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B1%7D%7B11%7D%2C%7E%5Cfrac%7B136%7D%7B15%7D%2C%7E%5Cfrac%7B5%7D%7B17%7D%2C%7E%5Cfrac%7B4%7D%7B5%7D%2C%7E%5Cfrac%7B26%7D%7B21%7D%2C%7E%5Cfrac%7B7%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B7%7D%2C%7E%5Cfrac%7B33%7D%7B4%7D%2C%7E%5Cfrac%7B5%7D%7B2%7D%2C%7E%5Cfrac%7B7%7D%7B1%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. "/></p>
<p>Note that since the last fraction is an integer the program runs forever. If <img alt="{n = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 1}"/> so that the input is <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, it would go <img alt="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2+%5Crightarrow+5+%5Crightarrow+4+%5Crightarrow+33+%5Crightarrow+3+%5Crightarrow+21+%5Crightarrow+26+%5Crightarrow+14+%5Crightarrow+2+%5Ccdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}"/> and thus cycle, unless we stop it. The powers of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> that appear in its output give the desired sequence. </p>
<p>
More natural to us, however, is the following modular program—which can use binary or any notation:</p>
<p>
<font size="+1"><tt><b><br/>
start: if (n == 1) { halt; }<br/>
if (n == 0 mod 2) { goto div; }<br/>
n = 3*n + 1;<br/>
div: n = n/2;<br/>
goto start;<br/>
</b></tt></font></p>
<p/><p><br/>
One can generalize the Collatz problem to moduli <img alt="{m &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m &gt; 2}"/>. For each <img alt="{k &lt; m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3C+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k &lt; m}"/> we have a linear transformation <img alt="{n \mapsto c_k n + d_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cmapsto+c_k+n+%2B+d_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \mapsto c_k n + d_k}"/> that always gives an integer value when <img alt="{n \equiv k \pmod{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cequiv+k+%5Cpmod%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \equiv k \pmod{m}}"/>. We want to know about the orbits of numbers <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> under this iteration.</p>
<p>
In fact, this is exactly what FRACTRAN does. Take <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> to be the least common multiple of the denominators <img alt="{b_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_r}"/> in a FRACTRAN program <img alt="{[\frac{a_r}{b_r}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cfrac%7Ba_r%7D%7Bb_r%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\frac{a_r}{b_r}]}"/>. Then for each <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> we can list the remainders <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> that are multiples of <img alt="{b_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_r}"/> and we get <img alt="{c_k = \frac{a_r}{\gcd(k,m)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_k+%3D+%5Cfrac%7Ba_r%7D%7B%5Cgcd%28k%2Cm%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_k = \frac{a_r}{\gcd(k,m)}}"/>, with <img alt="{d_k = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_k = 0}"/>. The Turing-universality of FRACTRAN then proves a general theorem Conway stated in 1972:</p>
<blockquote><p><b>Theorem 1</b> <em> Generalized Collatz-type problems for moduli <img alt="{m &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2}"/> are undecidable. </em>
</p></blockquote>
<p/><p>
<a href="https://link.springer.com/chapter/10.1007/978-3-540-72504-6_49">Several</a> <a href="http://julienmalka.me/collatz.pdf">followup</a> <a href="https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Lagarias3-23.pdf">papers</a> have proved stronger and more particular forms of the undecidability. The paper by Monks linked above leverages the unary encoding to show that having <img alt="{d_k = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_k = 0}"/> is essentially without loss of generality for universality; it is titled “<img alt="{3x+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3x%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3x+1}"/> Minus the <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/>.” </p>
<p>
Having digested universality, it is natural to wonder about complexity. Can we use modular programming to achieve stronger connections between number theory and complexity classes—classes above the level of <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/>, say? One possible mode of connection is exemplified by this <a href="https://www.researchgate.net/publication/220994869_One_Binary_Horn_Clause_is_Enough">paper</a> from STACS 1994, which both Dick and I attended. We wonder whether the kind of connection noted by Terry Tao in his <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">tribute</a> to Conway can also smooth the way to understanding <img alt="{\mathsf{MIP^* = RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{MIP^* = RE}}"/>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Conway posed many open problems himself. Here is a <a href="https://oeis.org/A248380/a248380.pdf">list</a> of five for which he posted cash rewards in the manner of Paul Erdős. The fifth was recently solved. The fourth can be stated in one sentence:</p>
<blockquote><p><b> </b> <em> If a set of points in the plane intersects every convex region of area 1, then must it have pairs of points at arbitrarily small distances? </em>
</p></blockquote>
<p/><p>
Our condolences go out to his family and all who were enthralled by him in the mathematical world. We could talk endlessly about his impact on mathematics education—even about simple things like how to <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=3111964">prove</a> that <img alt="{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{2}}"/> is irrational—or try to tangle with his <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">applications</a> of the “Monster” group to modular forms, but those must be for another time. Also see Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=4732">tribute</a> and its comments section for many more stories and items.</p>
<p/><p><br/>
[some small word and format changes, added link to Scott and may add others as time allows]</p></font></font></div>
    </content>
    <updated>2020-04-14T20:06:27Z</updated>
    <published>2020-04-14T20:06:27Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Teaching"/>
    <category term="Collatz conjecture"/>
    <category term="complexity"/>
    <category term="FRACTRAN"/>
    <category term="in memoriam"/>
    <category term="John Conway"/>
    <category term="Life"/>
    <category term="Logic"/>
    <category term="memorial"/>
    <category term="modular arithmetic"/>
    <category term="Princeton"/>
    <category term="set theory"/>
    <category term="surreal numbers"/>
    <category term="Turing universality"/>
    <category term="undecidability"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-21T00:21:03Z</updated>
    </source>
  </entry>
</feed>
