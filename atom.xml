<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-09-17T11:21:51Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/124</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/124" rel="alternate" type="text/html"/>
    <title>TR19-124 |  Testing Odd Direct Sums Using High Dimensional Expanders | 

	Roy Gotlib, 

	Tali Kaufman</title>
    <summary>In this work, using methods from high dimensional expansion, we show that the property of $k$-direct-sum is testable for odd values of $k$ . Previous work of Kaufman and Lubotzky could inherently deal only with the case that $k$ is even, using a reduction to linearity testing.
Interestingly, our work is the first to combine the topological notion of high dimensional expansion (called co-systolic expansion) with the combinatorial/spectral notion of high dimensional expansion (called colorful expansion) to obtain the result.

The classical $k$-direct-sum problem applies to the complete complex; Namely it considers a function defined over all $k$-subsets of some $n$ sized universe. Our result here applies to any collection of $k$-subsets of an $n$-universe, assuming this collection of subsets forms a high dimensional expander.</summary>
    <updated>2019-09-17T00:04:22Z</updated>
    <published>2019-09-17T00:04:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-17T11:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/123</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/123" rel="alternate" type="text/html"/>
    <title>TR19-123 |  On the Hardness of Robust Classification | 

	Pascale Gourdeau, 

	Varun Kanade, 

	Marta Kwiatkowska, 

	James Worrell</title>
    <summary>It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show moreover that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\omega(\log n)$ input bits. However if the adversary is restricted to perturbing $O(\log n)$ bits, then the class of monotone conjunctions can be robustly learned with respect to a general class of distributions (that includes the uniform distribution). Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on another computational model (e.g. the statistical query model) nor on any hardness assumption other than the existence of a hard learning problem in the PAC framework.</summary>
    <updated>2019-09-17T00:00:40Z</updated>
    <published>2019-09-17T00:00:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-17T11:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07347</id>
    <link href="http://arxiv.org/abs/1909.07347" rel="alternate" type="text/html"/>
    <title>Extending simple drawings with one edge is hard</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arroyo:Alan.html">Alan Arroyo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seidel:Raimund.html">Raimund Seidel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vogtenhuber:Birgit.html">Birgit Vogtenhuber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiedera:Tilo.html">Tilo Wiedera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07347">PDF</a><br/><b>Abstract: </b>A simple drawing $D(G)$ of a graph $G = (V,E)$ is a drawing in which two
edges have at most one point in common that is either an endpoint or a proper
crossing. An edge $e$ from the complement of $ G $ can be inserted into $D(G)$
if there exists a simple drawing of $G' = (V, E\cup \{e\})$ containing $D(G)$
as a subdrawing. We show that it is NP-complete to decide whether a given edge
can be inserted into a simple drawing, by this solving an open question by
Arroyo, Derka, and Parada.
</p></div>
    </summary>
    <updated>2019-09-17T01:53:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07326</id>
    <link href="http://arxiv.org/abs/1909.07326" rel="alternate" type="text/html"/>
    <title>Multitype Integer Monoid Optimization and Applications</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Dušan Knop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kouteck=yacute=:Martin.html">Martin Koutecký</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07326">PDF</a><br/><b>Abstract: </b>Configuration integer programs (IP) have been key in the design of algorithms
for NP-hard high-multiplicity problems since the pioneering work of Gilmore and
Gomory [Oper. Res., 1961]. Configuration IPs have a variable for each possible
configuration, which describes a placement of items into a location, and whose
value corresponds to the number of locations with that placement. In high
multiplicity problems items come in types, and are represented succinctly by a
vector of multiplicities; solving the configuration IP then amounts to deciding
whether the input vector of multiplicities of items of each type can be
decomposed into a given number of configurations.
</p>
<p>We make this implicit notion explicit by observing that the set of all input
vectors decomposable into configurations forms a monoid, and solving the
configuration IP is the Monoid Decomposition problem. Motivated by
applications, we enrich this problem in two ways. First, sometimes each
configuration additionally has an objective value, yielding an optimization
problem of finding a "best" decomposition under the given objective. Second,
there are often different types of configurations for different types of
locations. The resulting problem is to optimize over decompositions of the
input multiplicity vector into configurations of several types, and we call it
Multitype Integer Monoid Optimization, or MIMO.
</p>
<p>We develop fast exact algorithms for various MIMO with few or many location
types and with various objectives. Our algorithms build on a novel proximity
theorem connecting the solutions of a certain configuration IP to those of its
continuous relaxation. We then cast several fundamental scheduling and bin
packing problems as MIMOs, and thereby obtain new or substantially faster
algorithms for them.
</p>
<p>We complement our positive algorithmic results by hardness results.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07313</id>
    <link href="http://arxiv.org/abs/1909.07313" rel="alternate" type="text/html"/>
    <title>Solving Strong-Substitutes Product-Mix Auctions</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Elizabeth Baldwin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Paul_W=.html">Paul W. Goldberg</a>, Paul Klemperer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lock:Edwin.html">Edwin Lock</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07313">PDF</a><br/><b>Abstract: </b>This paper develops algorithms to solve strong-substitutes product-mix
auctions. That is, it finds competitive equilibrium prices and quantities for
agents who use this auction's bidding language to truthfully express their
strong-substitutes preferences over an arbitrary number of goods, each of which
is available in multiple discrete units. (Strong substitutes preferences are
also known, in other literatures, as $M^\natural$-concave, matroidal and
well-layered maps, and valuated matroids). Our use of the bidding language, and
the information it provides, contrasts with existing algorithms that rely on
access to a valuation or demand oracle to find equilibrium.
</p>
<p>We compute market-clearing prices using algorithms that apply existing
submodular minimisation methods. Allocating the supply among the bidders at
these prices then requires solving a novel constrained matching problem. Our
algorithm iteratively simplifies the allocation problem, perturbing bids and
prices in a way that resolves tie-breaking choices created by bids that can be
accepted on more than one good. We provide practical running time bounds on
both price-finding and allocation, and illustrate experimentally that our
allocation mechanism is practical.
</p></div>
    </summary>
    <updated>2019-09-17T01:25:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07251</id>
    <link href="http://arxiv.org/abs/1909.07251" rel="alternate" type="text/html"/>
    <title>Note on distributed certification of minimum spanning trees</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feuilloley:Laurent.html">Laurent Feuilloley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07251">PDF</a><br/><b>Abstract: </b>A distributed proof (also known as local certification, or proof-labeling
scheme) is a mechanism to certify that the solution to a graph problem is
correct. It takes the form of an assignment of labels to the nodes, that can be
checked locally. There exists such a proof for the minimum spanning tree
problem, using $O(\log n \log W)$ bit labels (where $n$ is the number of nodes
in the graph, and $W$ is the largest weight of an edge). This is due to Korman
and Kutten who describe it in concise and formal manner in [Korman and Kutten
07]. In this note, we propose a more intuitive description of the result, as
well as a gentle introduction to the problem.
</p></div>
    </summary>
    <updated>2019-09-17T01:37:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07141</id>
    <link href="http://arxiv.org/abs/1909.07141" rel="alternate" type="text/html"/>
    <title>Disproportionate division</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Logan Crew, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Bhargav.html">Bhargav Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirkl:Sophie.html">Sophie Spirkl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07141">PDF</a><br/><b>Abstract: </b>We study the disproportionate version of the classical cake-cutting problem:
how efficiently can we divide a cake, here $[0,1]$, among $n$ agents with
different demands $\alpha_1, \alpha_2, \dots, \alpha_n$ summing to $1$? When
all the agents have equal demands of $\alpha_1 = \alpha_2 = \dots = \alpha_n =
1/n$, it is well-known that there exists a fair division with $n-1$ cuts, and
this is optimal. For arbitrary demands on the other hand, folklore arguments
from algebraic topology show that $O(n\log n)$ cuts suffice, and this has been
the state of the art for decades. Here, we improve the state of affairs in two
ways: we prove that disproportionate division may always be achieved with
$3n-4$ cuts, and give an effective combinatorial procedure to construct such a
division. We also offer a topological conjecture that implies that $2n-2$ cuts
suffice in general, which would be optimal.
</p></div>
    </summary>
    <updated>2019-09-17T01:45:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07093</id>
    <link href="http://arxiv.org/abs/1909.07093" rel="alternate" type="text/html"/>
    <title>How to Morph a Tree on a Small Grid</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barrera=Cruz:Fidel.html">Fidel Barrera-Cruz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Borrazzo:Manuel.html">Manuel Borrazzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Battista:Giuseppe_Di.html">Giuseppe Di Battista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frati:Fabrizio.html">Fabrizio Frati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patrignani:Maurizio.html">Maurizio Patrignani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roselli:Vincenzo.html">Vincenzo Roselli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07093">PDF</a><br/><b>Abstract: </b>In this paper we study planar morphs between straight-line planar grid
drawings of trees. A morph consists of a sequence of morphing steps, where in a
morphing step vertices move along straight-line trajectories at constant speed.
We show how to construct planar morphs that simultaneously achieve a reduced
number of morphing steps and a polynomially-bounded resolution. We assume that
both the initial and final drawings lie on the grid and we ensure that each
morphing step produces a grid drawing; further, we consider both upward
drawings of rooted trees and drawings of arbitrary trees.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07059</id>
    <link href="http://arxiv.org/abs/1909.07059" rel="alternate" type="text/html"/>
    <title>Improved Strong Spatial Mixing for Colorings on Trees</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efthymiou:Charilaos.html">Charilaos Efthymiou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hayes:Thomas_P=.html">Thomas P. Hayes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefankovic:Daniel.html">Daniel Stefankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07059">PDF</a><br/><b>Abstract: </b>Strong spatial mixing (SSM) is a form of correlation decay that has played an
essential role in the design of approximate counting algorithms for spin
systems. A notable example is the algorithm of Weitz (2006) for the hard-core
model on weighted independent sets. We study SSM for the $q$-colorings problem
on the infinite $(d+1)$-regular tree. Weak spatial mixing (WSM) captures
whether the influence of the leaves on the root vanishes as the height of the
tree grows. Jonasson (2002) established WSM when $q&gt;d+1$. In contrast, in SSM,
we first fix a coloring on a subset of internal vertices, and we again ask if
the influence of the leaves on the root is vanishing. It was known that SSM
holds on the $(d+1)$-regular tree when $q&gt;\alpha d$ where $\alpha\approx
1.763...$ is a constant that has arisen in a variety of results concerning
random colorings. Here we improve on this bound by showing SSM for $q&gt;1.59d$.
Our proof establishes an $L^2$ contraction for the BP operator. For the
contraction we bound the norm of the BP Jacobian by exploiting combinatorial
properties of the coloring of the tree.
</p></div>
    </summary>
    <updated>2019-09-17T01:35:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07013</id>
    <link href="http://arxiv.org/abs/1909.07013" rel="alternate" type="text/html"/>
    <title>Proceedings of the 27th International Symposium on Graph Drawing and Network Visualization (GD 2019)</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Archambault:Daniel.html">Daniel Archambault</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=oacute=th:Csaba_D=.html">Csaba D. Tóth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07013">PDF</a><br/><b>Abstract: </b>This is the arXiv index for the electronic proceedings of GD 2019, which
contains the peer-reviewed and revised accepted papers with an optional
appendix. Proceedings (without appendices) are also to be published by Springer
in the Lecture Notes in Computer Science series.
</p></div>
    </summary>
    <updated>2019-09-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06988</id>
    <link href="http://arxiv.org/abs/1909.06988" rel="alternate" type="text/html"/>
    <title>Explicit near-Ramanujan graphs of every degree</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Sidhanth.html">Sidhanth Mohanty</a>, Ryan O'Donnell, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paredes:Pedro.html">Pedro Paredes</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06988">PDF</a><br/><b>Abstract: </b>For every constant $d \geq 3$ and $\epsilon &gt; 0$, we give a deterministic
$\mathrm{poly}(n)$-time algorithm that outputs a $d$-regular graph on
$\Theta(n)$ vertices that is $\epsilon$-near-Ramanujan; i.e., its eigenvalues
are bounded in magnitude by $2\sqrt{d-1} + \epsilon$ (excluding the single
trivial eigenvalue of~$d$).
</p></div>
    </summary>
    <updated>2019-09-17T01:23:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06811</id>
    <link href="http://arxiv.org/abs/1909.06811" rel="alternate" type="text/html"/>
    <title>Noisy Beeping Networks</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yagel Ashkenazi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gelles:Ran.html">Ran Gelles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leshem:Amir.html">Amir Leshem</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06811">PDF</a><br/><b>Abstract: </b>We introduce noisy beeping networks, where nodes have limited communication
capabilities, namely, they can only emit energy or sense the channel for
energy. Furthermore, imperfections may cause devices to malfunction with some
fixed probability when sensing the channel, which amounts to deducing a noisy
received transmission. Such noisy networks have implications for
ultra-lightweight sensor networks and biological systems.
</p>
<p>We show how to compute tasks in a noise-resilient manner over noisy beeping
networks of arbitrary structure. In particular, we transform any algorithm that
assumes a noiseless beeping network (of size $n$) into a noise-resilient
version while incurring a multiplicative overhead of only $O(\log n)$ in its
round complexity, with high probability. We show that our coding is optimal for
some tasks, such as node-coloring of a clique.
</p>
<p>We further show how to simulate a large family of algorithms designed for
distributed networks in the CONGEST($B$) model over a noisy beeping network.
The simulation succeeds with high probability and incurs an asymptotic
multiplicative overhead of $O(B\cdot \Delta \cdot \min(n,\Delta^2))$ in the
round complexity, where $\Delta$ is the maximal degree of the network. The
overhead is tight for certain graphs, e.g., a clique. Further, this simulation
implies a constant overhead coding for constant-degree networks.
</p></div>
    </summary>
    <updated>2019-09-17T01:26:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06794</id>
    <link href="http://arxiv.org/abs/1909.06794" rel="alternate" type="text/html"/>
    <title>Run-Length Encoding in a Finite Universe</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larsson:N=_Jesper.html">N. Jesper Larsson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06794">PDF</a><br/><b>Abstract: </b>Text compression schemes and compact data structures usually combine
sophisticated probability models with basic coding methods whose average
codeword length closely match the entropy of known distributions. In the
frequent case where basic coding represents run-lengths of outcomes that have
probability $p$, i.e.\@ the geometric distribution $\Pr(i)=p^i(1-p)$, a
\emph{Golomb code} is an optimal instantaneous code, which has the additional
advantage that codewords can be computed using only an integer parameter
calculated from $p$, without need for a large or sophisticated data structure.
Golomb coding does not, however, gracefully handle the case where run-lengths
are bounded by a known integer~$n$. In this case, codewords allocated for the
case $i&gt;n$ are wasted. While negligible for large $n$, this makes Golomb coding
unattractive in situations where $n$ is recurrently small, e.g., when
representing many short lists of integers drawn from limited ranges, or when
the range of $n$ is narrowed down by a recursive algorithm. We address the
problem of choosing a code for this case, considering efficiency from both
information-theoretic and computational perspectives, and arrive at a simple
code that allows computing a codeword using only $O(1)$ simple computer
operations and $O(1)$ machine words. We demonstrate experimentally that the
resulting representation length is very close (equal in a majority of tested
cases) to the optimal Huffman code, to the extent that the expected difference
is practically negligible. We describe efficient branch-free implementation of
encoding and decoding.
</p></div>
    </summary>
    <updated>2019-09-17T01:40:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06747</id>
    <link href="http://arxiv.org/abs/1909.06747" rel="alternate" type="text/html"/>
    <title>Algorithms for Manipulating Sequential Allocation</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a>, Jiaxing Ling <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06747">PDF</a><br/><b>Abstract: </b>Sequential allocation is a simple and widely studied mechanism to allocate
indivisible items in turns to agents according to a pre-specified picking
sequence of agents. At each turn, the current agent in the picking sequence
picks its most preferred item among all items having not been allocated yet.
This problem is well-known to be not strategyproof, i.e., an agent may get more
utility by reporting an untruthful preference ranking of items. It arises the
problem: how to find the best response of an agent?
</p>
<p>It is known that this problem is polynomially solvable for only two agents
and NP-complete for arbitrary number of agents.
</p>
<p>The computational complexity of this problem with three agents was left as an
open problem. In this paper, we give a novel algorithm that solves the problem
in polynomial time for each fixed number of agents. We also show that an agent
can always get at least half of its optimal utility by simply using its
truthful preference as the response.
</p></div>
    </summary>
    <updated>2019-09-17T01:29:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06653</id>
    <link href="http://arxiv.org/abs/1909.06653" rel="alternate" type="text/html"/>
    <title>A Tree Structure For Dynamic Facility Location</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leniowski:Dariusz.html">Dariusz Leniowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06653">PDF</a><br/><b>Abstract: </b>We study the metric facility location problem with client insertions and
deletions. This setting differs from the classic dynamic facility location
problem, where the set of clients remains the same, but the metric space can
change over time. We show a deterministic algorithm that maintains a constant
factor approximation to the optimal solution in worst-case time $\tilde
O(2^{O(\kappa^2)})$ per client insertion or deletion in metric spaces while
answering queries about the cost in $O(1)$ time, where $\kappa$ denotes the
doubling dimension of the metric. For metric spaces with bounded doubling
dimension, the update time is polylogarithmic in the parameters of the problem.
</p></div>
    </summary>
    <updated>2019-09-17T01:23:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06535</id>
    <link href="http://arxiv.org/abs/1909.06535" rel="alternate" type="text/html"/>
    <title>Private and Atomic Exchange of Assets over Zero Knowledge Based Payment Ledger</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Zhimin.html">Zhimin Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Lei.html">Lei Xu</a>, Keshav Kasichainula, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lin.html">Lin Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carbunar:Bogdan.html">Bogdan Carbunar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Weidong.html">Weidong Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06535">PDF</a><br/><b>Abstract: </b>Bitcoin brings a new type of digital currency that does not rely on a central
system to maintain transactions. By benefiting from the concept of
decentralized ledger, users who do not know or trust each other can still
conduct transactions in a peer-to-peer manner. Inspired by Bitcoin, other
cryptocurrencies were invented in recent years such as Ethereum, Dash, Zcash,
Monero, Grin, etc. Some of these focus on enhancing privacy for instance crypto
note or systems that apply the similar concept of encrypted notes used for
transactions to enhance privacy (e.g., Zcash, Monero). However, there are few
mechanisms to support the exchange of privacy-enhanced notes or assets on the
chain, and at the same time preserving the privacy of the exchange operations.
Existing approaches for fair exchanges of assets with privacy mostly rely on
off-chain/side-chain, escrow or centralized services. Thus, we propose a
solution that supports oblivious and privacy-protected fair exchange of crypto
notes or privacy enhanced crypto assets. The technology is demonstrated by
extending zero-knowledge based crypto notes. To address "privacy" and
"multi-currency", we build a new zero-knowledge proving system and extend note
format with new property to represent various types of tokenized assets or
cryptocurrencies. By extending the payment protocol, exchange operations are
realized through privacy enhanced transactions (e.g., shielded transactions).
Based on the possible scenarios during the exchange operation, we add new
constraints and conditions to the zero-knowledge proving system used for
validating transactions publicly.
</p></div>
    </summary>
    <updated>2019-09-17T01:40:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06524</id>
    <link href="http://arxiv.org/abs/1909.06524" rel="alternate" type="text/html"/>
    <title>A Generalized Randomized Rank-Revealing Factorization</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ballard:Grey.html">Grey Ballard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demmel:James.html">James Demmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dumitriu:Ioana.html">Ioana Dumitriu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rusciano:Alexander.html">Alexander Rusciano</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06524">PDF</a><br/><b>Abstract: </b>We introduce a Generalized Randomized QR-decomposition that may be applied to
arbitrary products of matrices and their inverses, without needing to
explicitly compute the products or inverses. This factorization is a critical
part of a communication-optimal spectral divide-and-conquer algorithm for the
nonsymmetric eigenvalue problem. In this paper, we establish that this
randomized QR-factorization satisfies the strong rank-revealing properties. We
also formally prove its stability, making it suitable in applications. Finally,
we present numerical experiments which demonstrate that our theoretical bounds
capture the empirical behavior of the factorization.
</p></div>
    </summary>
    <updated>2019-09-17T01:27:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06485</id>
    <link href="http://arxiv.org/abs/1909.06485" rel="alternate" type="text/html"/>
    <title>Multi-Perspective, Simultaneous Embedding</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Md Iqbal Hossain, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huroyan:Vahan.html">Vahan Huroyan</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarrete:Raymundo.html">Raymundo Navarrete</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06485">PDF</a><br/><b>Abstract: </b>We describe a method for simultaneous visualization of multiple pairwise
distances in 3 dimensional (3D) space. Given the distance matrices that
correspond to 2 dimensional projections of a 3 dimensional object (dataset) the
goal is to recover the 3 dimensional object (dataset). We propose an approach
that uses 3D to place the points, along with projections (planes) that preserve
each of the given distance matrices. Our multi-perspective, simultaneous
embedding (MPSE) method is based on non-linear dimensionality reduction that
generalizes multidimensional scaling. We consider two versions of the problem:
in the first one we are given the input distance matrices and the projections
(e.g., if we have 3 different projections we can use the three orthogonal
directions of the unit cube). In the second version of the problem we also
compute the best projections as part of the optimization. We experimentally
evaluate MPSE using synthetic datasets that illustrate the quality of the
resulting solutions. Finally, we provide a functional prototype which
implements both settings.
</p></div>
    </summary>
    <updated>2019-09-17T01:38:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06463</id>
    <link href="http://arxiv.org/abs/1909.06463" rel="alternate" type="text/html"/>
    <title>Optimization on the Surface of the (Hyper)-Sphere</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raman:Parameswaran.html">Parameswaran Raman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Jiasen.html">Jiasen Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06463">PDF</a><br/><b>Abstract: </b>Thomson problem is a classical problem in physics to study how $n$ number of
charged particles distribute themselves on the surface of a sphere of $k$
dimensions. When $k=2$, i.e. a 2-sphere (a circle), the particles appear at
equally spaced points. Such a configuration can be computed analytically.
However, for higher dimensions such as $k \ge 3$, i.e. the case of 3-sphere
(standard sphere), there is not much that is understood analytically. Finding
global minimum of the problem under these settings is particularly tough since
the optimization problem becomes increasingly computationally intensive with
larger values of $k$ and $n$. In this work, we explore a wide variety of
numerical optimization methods to solve the Thomson problem. In our empirical
study, we find stochastic gradient based methods (SGD) to be a compelling
choice for this problem as it scales well with the number of points.
</p></div>
    </summary>
    <updated>2019-09-17T01:54:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06457</id>
    <link href="http://arxiv.org/abs/1909.06457" rel="alternate" type="text/html"/>
    <title>Linear Size Planar Manhattan Network for Convex Point Sets</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jana:Satyabrata.html">Satyabrata Jana</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maheshwari:Anil.html">Anil Maheshwari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roy:Sasanka.html">Sasanka Roy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06457">PDF</a><br/><b>Abstract: </b>Let $G = (V, E)$ be an edge-weighted geometric graph such that every edge is
horizontal or vertical. The weight of an edge $uv \in E$ is its length. Let $
W_G (u,v)$ denote the length of a shortest path between a pair of vertices $u$
and $v$ in $G$. The graph $G$ is said to be a Manhattan network for a given
point set $ P $ in the plane if $P \subseteq V$ and $\forall p,q \in P$, $ W_G
(p,q)=|pq|_1$. In addition to $ P$, graph $G$ may also include a set $T$ of
Steiner points in its vertex set $V$. In the Manhattan network problem, the
objective is to construct a Manhattan network of small size for a set of $ n $
points. This problem was first considered by Gudmundsson et
al.\cite{gudmundsson2007small}. They give a construction of a Manhattan network
of size $\Theta(n \log n)$ for general point set in the plane. We say a
Manhattan network is planar if it can be embedded in the plane without any edge
crossings. In this paper, we construct a linear size planar Manhattan network
for convex point set in linear time using $\mathcal{ O}(n)$ Steiner points. We
also show that, even for convex point set, the construction in Gudmundsson et
al. \cite{gudmundsson2007small} needs $\Omega (n \log n)$ Steiner points and
the network may not be planar.
</p></div>
    </summary>
    <updated>2019-09-17T01:51:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06444</id>
    <link href="http://arxiv.org/abs/1909.06444" rel="alternate" type="text/html"/>
    <title>Local Decode and Update for Big Data Compression</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vatedka:Shashank.html">Shashank Vatedka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tchamkerten:Aslan.html">Aslan Tchamkerten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06444">PDF</a><br/><b>Abstract: </b>This paper investigates data compression that simultaneously allows local
decoding and local update. The main result is a universal compression scheme
for memoryless sources with the following features. The rate can be made
arbitrarily close to the entropy of the underlying source, contiguous fragments
of the source can be recovered or updated by probing or modifying a number of
codeword bits that is on average linear in the size of the fragment, and the
overall encoding and decoding complexity is quasilinear in the blocklength of
the source. In particular, the local decoding or update of a single message
symbol can be performed by probing or modifying a constant number of codeword
bits. This latter part improves over previous best known results for which
local decodability or update efficiency grows logarithmically with blocklength.
</p></div>
    </summary>
    <updated>2019-09-17T01:35:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06437</id>
    <link href="http://arxiv.org/abs/1909.06437" rel="alternate" type="text/html"/>
    <title>The Computational Complexity of Finding Temporal Paths under Waiting Time Constraints</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casteigts:Arnaud.html">Arnaud Casteigts</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Himmel:Anne=Sophie.html">Anne-Sophie Himmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zschoche:Philipp.html">Philipp Zschoche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06437">PDF</a><br/><b>Abstract: </b>Computing a (shortest) path between two vertices in a graph is one of the
most fundamental primitive in graph algorithmics. In recent years, the study of
paths in temporal graphs, that is, graphs where the vertex set remains static
but the edge set may change over time, gained more and more attention. In a
nutshell, temporal paths have to respect time, that is, they may only move
forward in time. More formally, the time edges used by a temporal path either
need to have increasing or non-decreasing time stamps. In is well known that
computing temporal paths is polynomial-time solvable. We study a natural
variant, where temporal paths may only dwell a certain given amount of time
steps in any vertex, which we call restless temporal paths. This small
modification creates a significant change in the computational complexity of
the task of finding temporal paths. We show that finding restless temporal
paths is NP-complete and give a thorough analysis of the (parameterized)
computational complexity of this problem. In particular, we show that problem
remains computationally hard on temporal graphs with three layers and is
W[1]-hard when parameterized by the feedback vertex number of the underlying
graph. On the positive side, we give an efficient (FPT) algorithm to find short
restless temporal paths that has an asymptotically optimal running time
assuming the Exponential Time Hypothesis.
</p></div>
    </summary>
    <updated>2019-09-17T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06435</id>
    <link href="http://arxiv.org/abs/1909.06435" rel="alternate" type="text/html"/>
    <title>A Random Network Model for the Analysis of Blockchain Designs with Communication Delay</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pinz=oacute=n:Carlos.html">Carlos Pinzón</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rocha:Camilo.html">Camilo Rocha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Finke:Jorge.html">Jorge Finke</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06435">PDF</a><br/><b>Abstract: </b>This paper proposes a random network model for blockchains, a distributed
hierarchical data structure of blocks that has found several applications in
various industries. The model is parametric on two probability distribution
functions governing block production and communication delay, which are key to
capture the complexity of the mechanism used to synchronize the many
distributed local copies of a blockchain. The proposed model is equipped with
simulation algorithms for both bounded and unbounded number of distributed
copies of the blockchain. They are used to study fast blockchain systems, i.e.,
blockchains in which the average time of block production can match the average
time of message broadcasting used for blockchain synchronization. In
particular, the model and the algorithms are useful to understand efficiency
criteria associated with fast blockchains for identifying, e.g., when
increasing the block production will have negative impact on the stability of
the distributed data structure given the network's broadcast delay.
</p></div>
    </summary>
    <updated>2019-09-17T01:38:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06430</id>
    <link href="http://arxiv.org/abs/1909.06430" rel="alternate" type="text/html"/>
    <title>LDPC Codes Achieve List Decoding Capacity</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mosheiff:Jonathan.html">Jonathan Mosheiff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Resch:Nicolas.html">Nicolas Resch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ron=Zewi:Noga.html">Noga Ron-Zewi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silas:Shashwat.html">Shashwat Silas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wootters:Mary.html">Mary Wootters</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06430">PDF</a><br/><b>Abstract: </b>We show that Gallager's ensemble of Low-Density Parity Check (LDPC) codes
achieve list-decoding capacity. These are the first graph-based codes shown to
have this property. Previously, the only codes known to achieve list-decoding
capacity were completely random codes, random linear codes, and codes
constructed by algebraic (rather than combinatorial) techniques. This result
opens up a potential avenue towards truly linear-time list-decodable codes
which achieve list-decoding capacity.
</p>
<p>Our result on list decoding follows from a much more general result: any
local property satisfied with high probability by a random linear code is also
satisfied with high probability by a random LDPC code from Gallager's
distribution. Local properties are properties characterized by the exclusion of
small sets of codewords, and include list-decoding, list-recovery and
average-radius list-decoding. Along the way, we give a characterization of sets
of codewords that are likely to appear in a random linear code, which may be of
independent interest.
</p></div>
    </summary>
    <updated>2019-09-17T01:22:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06413</id>
    <link href="http://arxiv.org/abs/1909.06413" rel="alternate" type="text/html"/>
    <title>Dynamic Graph Algorithms and Graph Sparsification: New Techniques and Connections</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06413">PDF</a><br/><b>Abstract: </b>Graphs naturally appear in several real-world contexts including social
networks, the web network, and telecommunication networks. While the analysis
and the understanding of graph structures have been a central area of study in
algorithm design, the rapid increase of data sets over the last decades has
posed new challenges for designing efficient algorithms that process
large-scale graphs. These challenges arise from two usual assumptions in
classical algorithm design, namely that graphs are static and that they fit
into a single machine. However, in many application domains, graphs are subject
to frequent changes over time, and their massive size makes them infeasible to
be stored in the memory of a single machine.
</p>
<p>Driven by the need to devise new tools for overcoming such challenges, this
thesis focuses on two areas of modern algorithm design that directly deal with
processing massive graphs, namely dynamic graph algorithms and graph
sparsification. We develop new algorithmic techniques from both dynamic and
sparsification perspective for a multitude of graph-based optimization problems
which lie at the core of Spectral Graph Theory, Graph Partitioning, and Metric
Embeddings. Our algorithms are faster than any previous one and design smaller
sparsifiers with better (approximation) quality. More importantly, this work
introduces novel reduction techniques that show unexpected connections between
seemingly different areas such as dynamic graph algorithms and graph
sparsification.
</p></div>
    </summary>
    <updated>2019-09-17T01:38:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06363</id>
    <link href="http://arxiv.org/abs/1909.06363" rel="alternate" type="text/html"/>
    <title>Sample Complexity of Probabilistic Roadmaps via $\epsilon$-nets</title>
    <feedworld_mtime>1568678400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsao:Matthew.html">Matthew Tsao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solovey:Kiril.html">Kiril Solovey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavone:Marco.html">Marco Pavone</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06363">PDF</a><br/><b>Abstract: </b>We study fundamental theoretical aspects of probabilistic roadmaps (PRM) in
the finite time (non-asymptotic) regime. In particular, we investigate how
completeness and optimality guarantees of the approach are influenced by the
underlying deterministic sampling distribution ${\X}$ and connection radius
${r&gt;0}$. We develop the notion of ${(\delta,\epsilon)}$-completeness of the
parameters ${\X, r}$, which indicates that for every motion-planning problem of
clearance at least ${\delta&gt;0}$, PRM using ${\X, r}$ returns a solution no
longer than ${1+\epsilon}$ times the shortest ${\delta}$-clear path. Leveraging
the concept of ${\epsilon}$-nets, we characterize in terms of lower and upper
bounds the number of samples needed to guarantee
${(\delta,\epsilon)}$-completeness. This is in contrast with previous work
which mostly considered the asymptotic regime in which the number of samples
tends to infinity. In practice, we propose a sampling distribution inspired by
${\epsilon}$-nets that achieves nearly the same coverage as grids while using
significantly fewer samples.
</p></div>
    </summary>
    <updated>2019-09-17T01:37:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/122</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/122" rel="alternate" type="text/html"/>
    <title>TR19-122 |  LDPC Codes Achieve List-Decoding Capacity | 

	Jonathan Mosheiff, 

	Nicolas Resch, 

	Noga Ron-Zewi, 

	Shashwat Silas, 

	Mary Wootters</title>
    <summary>We show that Gallager's ensemble of Low-Density Parity Check (LDPC) codes achieve list-decoding capacity. These are the first graph-based codes shown to have this property. Previously, the only codes known to achieve list-decoding capacity were completely random codes, random linear codes, and codes constructed by algebraic (rather than combinatorial) techniques. This result opens up a potential avenue towards truly linear-time list-decodable codes which achieve list-decoding capacity.

Our result on list decoding follows from a much more general result: any local property satisfied with high probability by a random linear code is also satisfied with high probability by a random LDPC code from Gallager's distribution. Local properties are properties characterized by the exclusion of small sets of codewords, and include list-decoding, list-recovery and average-radius list-decoding. Along the way, we give a characterization of sets of codewords that are likely to appear in a random linear code, which may be of independent interest.</summary>
    <updated>2019-09-16T23:58:26Z</updated>
    <published>2019-09-16T23:58:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-17T11:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/121</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/121" rel="alternate" type="text/html"/>
    <title>TR19-121 |  Vanishing-Error Approximate Degree and QMA Complexity | 

	Justin Thaler, 

	Alexander A. Sherstov</title>
    <summary>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)| \leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate degree of the element distinctness function, the surjectivity function, and the permutation testing problem, showing they are $\Theta(n^{2/3} \log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and  $\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these bounds were known only for constant $\epsilon.$ 

We also derive a connection between vanishing-error approximate degree and quantum Merlin--Arthur (QMA) query complexity. We use this connection to show that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson (Quantum Information &amp; Computation, 2012), and comes somewhat close to matching a known upper bound of $O(n^{1/3})$.</summary>
    <updated>2019-09-16T23:55:59Z</updated>
    <published>2019-09-16T23:55:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-17T11:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16239</id>
    <link href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/" rel="alternate" type="text/html"/>
    <title>Separating Words: Decoding a Paper</title>
    <summary>A clever trick on combining automata John Robson has worked on various problems including what is still the best result on separating words—the topic we discussed the other day. Ken first knew him for his proof than checkers is -complete and similar hardness results for chess and Go. Today I want to talk about his […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A clever trick on combining automata</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/unknown-128/" rel="attachment wp-att-16242"><img alt="" class="alignright  wp-image-16242" src="https://rjlipton.files.wordpress.com/2019/09/unknown-2.jpeg?w=190" width="190"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
John Robson has worked on various problems including what is still the best result on separating words—the topic we discussed the other <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">day</a>. Ken first knew him for his <a href="https://epubs.siam.org/doi/10.1137/0213018">proof</a> than <img alt="{N \times N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N \times N}"/> checkers is <img alt="{\mathsf{EXPTIME}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BEXPTIME%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{EXPTIME}}"/>-complete and similar hardness results for chess and Go.</p>
<p>
Today I want to talk about his theorem that any two words can be separated by an automaton with relataivley few states.</p>
<p>
In his famous paper from 1989, he proved an upper bound on the <i>Separating Word Problem</i>. This is the question: Given two strings <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, how many states does a deterministic automaton need to be able to accept <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and reject <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>? His theorem is:</p>
<blockquote><p><b>Theorem 1 (Robson’s Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{O(n^{0.4}\log^{0.6} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B0.4%7D%5Clog%5E%7B0.6%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{0.4}\log^{0.6} n)}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
The story of his result is involved. For starters, it is still the best upper bound after almost three decades. Impressive. Another issue is that a web search does not quickly, at least for for me, find a PDF of the original paper. I tried to find it and could not. More recent papers on the separating word problem reference his 1989 paper, but they do not explain how he proves it. </p>
<p>
Recall the problem of separating words is: Given two distinct words of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, is there a deterministic finite automaton that accepts one and rejects the other? And the machine has as few states as possible. Thus his theorem shows that roughly the number of states grows at most like the square root of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. </p>
<p>
I did finally track the paper down. The trouble for me is the paper is encrypted. Well not exactly, but the version I did find is a poor copy of the original. Here is an example to show what I mean:</p>
<p/><p/>
<p>&lt;/tr</p><table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/r/" rel="attachment wp-att-16248"><img alt="" class="aligncenter size-medium wp-image-16248" height="137" src="https://rjlipton.files.wordpress.com/2019/09/r.png?w=300&amp;h=137" width="300"/></a>
</td>

</tr><tr>
<td class="caption alignright"><font size="-2">[ An Example ]</font>
</td>
</tr>
</tbody></table>
<p>
So the task of decoding the proof is a challenge. A challenge, but a rewarding one.</p>
<p>
</p><p/><h2> A Cool Trick </h2><p/>
<p/><p>
Robson’s proof uses two insights. The first is he uses some basic <a href="http://www.stringology.org">string-ology</a>. That is he uses some basic facts about strings. For example he uses that a non-periodic string cannot overlap itself too much.</p>
<p>
He also uses a clever trick on how to simulate two deterministic machines for the price of one. This in general is not possible, and is related to deep questions about automata that we have discussed before <a href="https://rjlipton.wordpress.com/2012/11/08/the-power-of-guessing/">here</a>. Robson shows that it can be done in a special but important case.</p>
<p>
Let me explain. Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a string. We can easily design an automaton that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> if and only if <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. The machine will have order the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> states. So far quite simple. </p>
<p>
Now suppose that we have a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and wish to find a particular occurrence of the pattern <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. We assume that there are <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. The task is to construct an automaton that accepts at the end of the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Robson shows that this can be done by a automaton that has order 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) + |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) + |\alpha| "/></p>
<p>Here <img alt="{|\alpha|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Calpha%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\alpha|}"/> is the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>.</p>
<p>
This is a simple, clever, and quite useful observation. Clever indeed. The obvious automaton that can do this would seem to require a cartesian product of two machines. This would imply that it would require 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) \times |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%5Ctimes+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) \times |\alpha| "/></p>
<p>number of states: Note the times operator <img alt="{\times}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctimes%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\times}"/> rather than addition. Thus Robson’s trick is a huge improvement.</p>
<p>
Here is how he does this.</p>
<p>
</p><p/><h2> His Trick </h2><p/>
<p/><p>
Robson’s uses a clever trick in his proof of the main lemma. Let’s work through an example with the string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. The goal is to see if there is a copy of this string starting at a position that is a multiple of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>.</p>
<p>
The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to find the correct string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/> as input. If it does, then it reaches the accepting state <img alt="{(3,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,Y)}"/>. If while doing this it gets a wrong input, then it switches to states that have stopped looking for the input <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. After seeing three inputs the machine reaches <img alt="{(3,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,N)}"/> and then moves back to the start state. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/rfig/" rel="attachment wp-att-16249"><img alt="" class="aligncenter  wp-image-16249" src="https://rjlipton.files.wordpress.com/2019/09/rfig.png?w=500" width="500"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ The automaton  ]</font>
</td>
</tr>
</tbody></table>
<p/><h2> The Lemmas </h2><p/>
<p>We will now outline the proof in some detail.</p>
<p>
</p><p/><h3> Hashing </h3><p/>
<p/><p>
The first lemma is a simple fact about hashing.</p>
<blockquote><p><b>Lemma 2</b> <em> Suppose <img alt="{1 \le r \le m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+r+%5Cle+m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \le r \le m}"/> and 	</em></p><em>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Then all but <img alt="{{O}(m \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m+%5Clog+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(m \log n)}"/> primes satisfy 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+%5Ctext%7B+if+and+only+if+%7D+i+%3Dr.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Consider the quantity <img alt="{|k_{r} - k_{i}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Ck_%7Br%7D+-+k_%7Bi%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|k_{r} - k_{i}|}"/> for <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> not equal to <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. Call a prime <i>bad</i> if it divides this quantity. This quantity can be divisible by at most <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> primes. So there are at most <img alt="{{O}(m\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{O}(m\log n)}"/> bad primes in total. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Strings </h3><p/>
<p/><p>
We need some definitions about strings. Let <img alt="{| \alpha |}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Calpha+%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{| \alpha |}"/> be the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Also let <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> be the number of occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the <i>period</i> <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> provided 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+p}, "/></p>
<p>for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> so that <img alt="{i+p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i+p}"/> is defined. A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is <i>periodic</i> provided it has a period <img alt="{p&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;0}"/> that is less than half its length. Note, the shorter the period the more the string is really “periodic”: for example, the string 	</p>
<p align="center"><img alt="\displaystyle  10101010101010 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10101010101010+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10101010101010 "/></p>
<p>is more “periodic” than 	</p>
<p align="center"><img alt="\displaystyle  10000001000000. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10000001000000.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10000001000000. "/></p>
<blockquote><p><b>Lemma 3</b> <em> For any string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u}"/> either <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u0}"/> or <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u1}"/> is not periodic. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Suppose that <img alt="{\beta=u\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3Du%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta=u\sigma}"/> is periodic with period <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> where <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sigma}"/> is a single character. Let the length of <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> equal <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. So by definition, <img alt="{1 \le p \le l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+p+%5Cle+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le p \le l/2}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  \beta_{i} = \beta_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bi%7D+%3D+%5Cbeta_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{i} = \beta_{i+p}, "/></p>
<p>for <img alt="{1 \le i \le l-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+i+%5Cle+l-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le i \le l-p}"/>. So it follows that 	</p>
<p align="center"><img alt="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bl-p%7D+%3D+%5Cbeta_%7Bl%7D+%3D+%5Csigma.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. "/></p>
<p>This shows that <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> cannot both be periodic, since 	</p>
<p align="center"><img alt="\displaystyle  1 \le l-p \le l/2 &lt; l. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+l-p+%5Cle+l%2F2+%3C+l.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le l-p \le l/2 &lt; l. "/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 4</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not a periodic string. Then the number of copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is upper bounded by <img alt="{{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(M)}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \frac{|S|}{|\alpha|}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5Cfrac%7B%7CS%7C%7D%7B%7C%5Calpha%7C%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \frac{|S|}{|\alpha|}. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The claim follows once we prove that no two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> can overlap more than <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/> where <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/> is the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. This will immediately imply the lemma.</p>
<p>
If <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has two copies in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> that overlap then clearly 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+d}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bd%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+d}, "/></p>
<p>for some <img alt="{d&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d&gt;0}"/> and all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> in the range <img alt="{1,\dots,l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C%5Cdots%2Cl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,\dots,l-d}"/>. This says that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the period <img alt="{l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l-d}"/>. Since <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not periodic it follows that <img alt="{d &gt; l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%3E+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d &gt; l/2}"/>. This implies that the overlap of the two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> are at most length <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/>. Thus we have shown that they cannot overlap too much. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Main Lemma </h3><p/>
<p/><p>
Say an automaton <i>finds</i> the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> provided it enters a special state after scanning the last bit of this occurrence.</p>
<blockquote><p><b>Lemma 5</b> <em> Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> be a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string.Then, there is an automaton with at most <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> states that can find the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \#(S,\alpha) + |\alpha|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \#(S,\alpha) + |\alpha|. "/></p>
</em><p><em/>
</p></blockquote>
<p>Here <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> allows factors that are fixed powers of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. This lemma is the main insight of Robson and will be proved later.</p>
<p>
</p><p/><h2> The Main Theorem </h2><p/>
<p/><p>
The following is a slightly weaker version of Robson’s theorem. I am still confused a bit about his stronger theorem, to be honest. </p>
<blockquote><p><b>Theorem 6 (Robson’s Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Since <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> are distinct we can assume that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> starts with the prefix <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> starts with the prefix <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> for some string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/>. If the length of <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is less than order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> the theorem is trivial. Just construct an automaton that accepts <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and rejects <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/>.</p>
<p>
So we can assume that <img alt="{u = w\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+w%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u = w\alpha}"/> for some strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> where the latter is order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> in length. By lemma we can assume that <img alt="{\alpha1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha1}"/> is not periodic. So by lemma we get that 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha1%29+%3D+%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). "/></p>
<p>Then by lemma we are done. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Proof of Main Lemma </h2><p/>
<p/><p>
<em>Proof:</em>  Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> have length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. Also let <img alt="{\#(S,\alpha) = m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29+%3D+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha) = m}"/>. By the overlap lemma it follows that <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bounded by <img alt="{\widetilde{O}(|S|/|\alpha|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%7CS%7C%2F%7C%5Calpha%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(|S|/|\alpha|)}"/>. </p>
<p>
Let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> occur at locations 	</p>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Suppose that we are to construct a machine that finds the <img alt="{r^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. By the hashing lemma there is a prime <img alt="{p=\widetilde{O}(m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3D%5Cwidetilde%7BO%7D%28m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p=\widetilde{O}(m)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p "/></p>
<p>if and only if <img alt="{i=r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3Dr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=r}"/>. Note we can also assume that <img alt="{p &gt; l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3E+l%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p &gt; l}"/>. </p>
<p>
Let’s argue the special case where <img alt="{k_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_{r}}"/> is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> modulo <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. If it is congruent to another value the same argument can be used. This follows by having the machine initially skip a fixed amount of the input and then do the same as in the congruent to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> case.</p>
<p>
The automaton has states <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> and <img alt="{(i,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,N)}"/> for <img alt="{i=0,\dots,p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3D0%2C%5Cdots%2Cp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=0,\dots,p}"/>. The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to get to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>. The transitions include: 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CY%29+%5Cunderset%7B%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CY%29+%5Cunderset%7B%5Calpha_%7B3%7D%7D%7B%5Crightarrow%7D+%5Ccdots+%5Cunderset%7B%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CY%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). "/></p>
<p>This means that the machine keeps checking the input to see if it is scanning a copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. If it gets all the way to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>, then it stops.</p>
<p>
Further transitions are: 	</p>
<p align="center"><img alt="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%281%2CN%29+%5Crightarrow+%282%2CN%29+%5Crightarrow+%5Ccdots+%5Crightarrow+%28p%2CN%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), "/></p>
<p>and 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CN%29%2C+%281%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CN%29%2C+%5Cdots%2C+%28l-1%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CN%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). "/></p>
<p>The second group means that if a wrong input happens, then <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> moves to <img alt="{(i+1,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2B1%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i+1,N)}"/>. Finally, the state <img alt="{(p,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28p%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(p,N)}"/> resets and starts the search again by going to the start state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> with an epsilon move.</p>
<p>
Clearly this has the required number of states and it operates correctly. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The open problem is: Can the SWP be solved with a better bound? The lower bound is still order <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. So the gap is exponential. </p></font></font></div>
    </content>
    <updated>2019-09-16T21:26:18Z</updated>
    <published>2019-09-16T21:26:18Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="automaton"/>
    <category term="deterministic"/>
    <category term="separating words"/>
    <category term="strings"/>
    <category term="trick"/>
    <category term="words"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-09-17T11:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18035</id>
    <link href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/" rel="alternate" type="text/html"/>
    <title>Alef’s corner: Bicycles and the Art of  Planar Random Maps</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The artist behind Alef’s corner has a few mathematical designs and here are two new ones. (See Alef’s  website offering over 100 T-shirt designs.)   which was used for the official T-shirt for Jean-François Le Gall’s birthday conference. See also … <a href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The artist behind <a href="https://gilkalai.wordpress.com/?s=alef">Alef’s corner</a> has a few mathematical designs and here are two new ones. (See Alef’s  <a href="https://tembelone.com/?fbclid=IwAR27VIu9gIgfgTWSYu88Xz1H9GneVoZsLZb1sw6jQ6IiE9w7cFo0jlISUas">website offering over 100 T-shirt designs</a>.)</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/legal.png"><img alt="" class="alignnone size-full wp-image-18040" height="529" src="https://gilkalai.files.wordpress.com/2019/09/legal.png?w=640&amp;h=529" width="640"/></a></p>
<p>which was used for the official T-shirt for Jean-François Le Gall’s <a href="https://www.math.u-psud.fr/~jf60/">birthday conference</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg"><img alt="" class="alignnone size-full wp-image-18041" src="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/curien.png"><img alt="" class="alignnone size-full wp-image-18036" src="https://gilkalai.files.wordpress.com/2019/09/curien.png?w=640"/></a></p>
<p>See also <a href="https://www.quantamagazine.org/random-surfaces-hide-an-intricate-order-20190702/">this quanta magazine article</a> by Kevin Hartness.</p></div>
    </content>
    <updated>2019-09-16T21:23:03Z</updated>
    <published>2019-09-16T21:23:03Z</published>
    <category term="Art"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Probability"/>
    <category term="Alef's corner"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-09-17T11:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6037506695705789893</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6037506695705789893/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html" rel="alternate" type="text/html"/>
    <title>this paper from 2015 cracks Diffie-Hellman. What to tell the students?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am teaching cryptography this semester for the second time (I taught it in Fall 2019) and will soon tell the students about the paper from 2015:<br/>
<a href="https://weakdh.org/imperfect-forward-secrecy.pdf">Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice</a>. There are 14 authors.<br/>
<br/>
The upshot is that as Diffie-Hellman was implemented in 2015, many cases were crackable. In summary (and probably too simple):<br/>
<br/>
DH in a 512-bit group can be cracked by the authors<br/>
<br/>
DH in a 1024-bit group they speculate can be cracked with nation-state resources. <br/>
<br/>
<br/>
<br/>
Is this a big deal? If YES then what is being done, and if NOT then why not?<br/>
<br/>
I have come up with some statements that I DO NOT KNOW if they are true, but I am ASKING you, to shed some light on the BIG DEAL or NO BIG DEAL question. (Note- Idea for a game show: BIG DEAL or NO BIG DEAL where contestants are asked if a news story is a BIG DEAL or not.)<br/>
<br/>
So, please comment on the following question:<br/>
<br/>
1) Since 2015 the people who use DH have upped their game and are now using bigger parameters. (I doubt this is true)<br/>
<br/>
2) DH is mostly not used on things that hackers are not interested in, so this is not a big deal.<br/>
<br/>
3) The expertise required to crack DH via this paper is rather difficult, so hackers don't have the skills.<br/>
<br/>
4) This paper is not a problem for a bad reason: Hackers don't need to  use the number field sieve DL algorithm when all they need to do is (1) guess that the pin numer is 1234 or the year the user was born (or close to it), (2) put on a uniform from Geek-Squad or some such organization and claim they are here to help, (3) exploit a known security flaw that the company has not bothered fixing.  <br/>
<br/>
5) The 14 authors have mysteriously disappeared. (I doubt this is true.)<br/>
<br/>
<br/>
(Misc: My spell checker thinks that Diffie and crackable are not words, but Hellman is.)</div>
    </content>
    <updated>2019-09-16T13:10:00Z</updated>
    <published>2019-09-16T13:10:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-17T09:54:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/" rel="alternate" type="text/html"/>
    <title>faculty at University of Sydney (apply by November 15, 2019)</title>
    <summary>Multiple continuing positions in the School Computer Science at the University of Sydney Website: https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1 Email: joachim.gudmundsson@sydney.edu.au</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple continuing positions in the School Computer Science at the University of Sydney</p>
<p>Website: <a href="https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1">https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1</a><br/>
Email: joachim.gudmundsson@sydney.edu.au</p></div>
    </content>
    <updated>2019-09-16T11:34:31Z</updated>
    <published>2019-09-16T11:34:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-17T11:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06292</id>
    <link href="http://arxiv.org/abs/1909.06292" rel="alternate" type="text/html"/>
    <title>Enumerating Isolated Cliques in Temporal Networks</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renken:Malte.html">Malte Renken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06292">PDF</a><br/><b>Abstract: </b>Isolation has been shown to be a valuable concept in the world of clique
enumeration. Motivated by recent work on enumerating cliques in temporal (or
time-varying) graphs, we lift the isolation concept to this setting. We
discover that the addition of the time dimension leads to six distinct natural
isolation concepts. Our main contribution are algorithms for the enumeration of
five of these six clique types, that are fixed-parameter-tractable with respect
to the "degree of isolation". On the empirical side, we implement and test
these algorithms on (temporal) social network data, obtaining encouraging
preliminary results.
</p></div>
    </summary>
    <updated>2019-09-16T23:21:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06226</id>
    <link href="http://arxiv.org/abs/1909.06226" rel="alternate" type="text/html"/>
    <title>Branch-and-cut and iterated local search for the weighted $k$-traveling repairman problem: an application to the maintenance of speed cameras</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Muritiba:Albert_Einstein_Fernandes.html">Albert Einstein Fernandes Muritiba</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonates:Tib=eacute=rius_O=.html">Tibérius O. Bonates</a>, Stênio Oliveira Da Silva, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iori:Manuel.html">Manuel Iori</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06226">PDF</a><br/><b>Abstract: </b>Private enterprises and governments around the world use speed cameras to
control traffic flow and limit speed excess. Cameras may be exposed to
difficult weather conditions and typically require frequent maintenance. When
deciding the order in which maintenance should be performed, one has to
consider both the traveling times between the cameras and the traffic flow that
each camera is supposed to monitor. In this paper, we study the problem of
routing a set of technicians to repair cameras by minimizing the total weighted
latency, that is, the sum of the weighted waiting times of each camera, where
the weight is a parameter proportional to the monitored traffic. The resulting
problem, called weighted k-traveling repairman problem (wkTRP), is a
generalization of the well-known traveling repairman problem and can be used to
model a variety of real-world applications. To solve the wkTRP, we propose an
iterated local search heuristic and an exact branch-and-cut algorithm enriched
with valid inequalities. The effectiveness of the two methods is proved by
extensive computational experiments performed both on instances derived from a
real-world case study, as well as on benchmark instances from the literature on
the wkTRP and on related problems.
</p></div>
    </summary>
    <updated>2019-09-16T23:25:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.06210</id>
    <link href="http://arxiv.org/abs/1909.06210" rel="alternate" type="text/html"/>
    <title>Cayley path and quantum computational supremacy: A proof of average-case $\#P-$hardness of Random Circuit Sampling with quantified robustness</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Movassagh:Ramis.html">Ramis Movassagh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.06210">PDF</a><br/><b>Abstract: </b>A one-parameter unitary-valued interpolation between any two unitary matrices
(e.g., quantum gates) is constructed based on the Cayley transformation, which
extends our previous work [15]. We prove that this path provides scrambled
unitaries with probability distributions arbitrarily close to the Haar measure.
We then prove the simplest known average-case #$P$-hardness of random circuit
sampling (RCS), which is the task of sampling from the output distribution of a
quantum circuit whose local gates are random Haar unitaries, and is the lead
candidate for demonstrating quantum supremacy in the NISQ era. We show that
previous work based on the truncations of the power series representation of
the exponential function does not provide practical robustness. Explicit bound
on noise resilience is proved, which for an $n-$qubit device with the near term
experimental parameters is $2^{-\Theta(n^{3.51})}$ robustness with respect to
additive error. Improving this to $\mathcal{O}(2^{-n}/\text{poly}(n))$ would
prove the quantum supremacy conjecture; and proving our construction optimal
would disprove it
</p></div>
    </summary>
    <updated>2019-09-16T23:20:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05981</id>
    <link href="http://arxiv.org/abs/1909.05981" rel="alternate" type="text/html"/>
    <title>Oracle complexity classes and local measurements on physical Hamiltonians</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharibian:Sevag.html">Sevag Gharibian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Piddock:Stephen.html">Stephen Piddock</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yirka:Justin.html">Justin Yirka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05981">PDF</a><br/><b>Abstract: </b>The canonical problem for the class Quantum Merlin-Arthur (QMA) is that of
estimating ground state energies of local Hamiltonians. Perhaps surprisingly,
[Ambainis, CCC 2014] showed that the related, but arguably more natural,
problem of simulating local measurements on ground states of local Hamiltonians
(APX-SIM) is likely harder than QMA. Indeed, [Ambainis, CCC 2014] showed that
APX-SIM is P^QMA[log]-complete, for P^QMA[log] the class of languages decidable
by a P machine making a logarithmic number of adaptive queries to a QMA oracle.
In this work, we show that APX-SIM is P^QMA[log]-complete even when restricted
to more physical Hamiltonians, obtaining as intermediate steps a variety of
related complexity-theoretic results.
</p>
<p>We first give a sequence of results which together yield P^QMA[log]-hardness
for APX-SIM on well-motivated Hamiltonians: (1) We show that for NP, StoqMA,
and QMA oracles, a logarithmic number of adaptive queries is equivalent to
polynomially many parallel queries. These equalities simplify the proofs of our
subsequent results. (2) Next, we show that the hardness of APX-SIM is preserved
under Hamiltonian simulations (a la [Cubitt, Montanaro, Piddock, 2017]). As a
byproduct, we obtain a full complexity classification of APX-SIM, showing it is
complete for P, P^||NP, P^||StoqMA, or P^||QMA depending on the Hamiltonians
employed. (3) Leveraging the above, we show that APX-SIM is P^QMA[log]-complete
for any family of Hamiltonians which can efficiently simulate spatially sparse
Hamiltonians, including physically motivated models such as the 2D Heisenberg
model.
</p>
<p>Our second focus considers 1D systems: We show that APX-SIM remains
P^QMA[log]-complete even for local Hamiltonians on a 1D line of 8-dimensional
qudits. This uses a number of ideas from above, along with replacing the "query
Hamiltonian" of [Ambainis, CCC 2014] with a new "sifter" construction.
</p></div>
    </summary>
    <updated>2019-09-16T23:21:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05968</id>
    <link href="http://arxiv.org/abs/1909.05968" rel="alternate" type="text/html"/>
    <title>Tracking Down the Bad Guys: Reset and Set Make Feasibility for Flip-Flop Net Derivatives NP-complete</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tredup:Ronny.html">Ronny Tredup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05968">PDF</a><br/><b>Abstract: </b>Boolean Petri nets are differentiated by types of nets $\tau$ based on which
of the interactions nop, inp, out, set, res, swap, used, and free they apply or
spare. The synthesis problem relative to a specific type of nets $\tau$ is to
find a boolean $\tau$-net $N$ whose reachability graph is isomorphic to a given
transition system $A$. The corresponding decision version of this search
problem is called feasibility. Feasibility is known to be polynomial for all
types of flip flop derivates that contain at least the interactions nop, swap
and an arbitrary selection of inp, out, used, free. In this paper, we replace
inp and out by res and set, respectively, and show that feasibility becomes
NP-complete for the types that contain nop, swap and a non empty selection of
res, set and a non empty selection of used, free. The reduction guarantees a
low degree for A's states and, thus, preserves hardness of feasibility even for
considerable input restrictions.
</p></div>
    </summary>
    <updated>2019-09-16T23:20:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05953</id>
    <link href="http://arxiv.org/abs/1909.05953" rel="alternate" type="text/html"/>
    <title>Optimized Synthesis of Snapping Fixtures</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tom Tsabar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fogel:Efi.html">Efi Fogel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Halperin:Dan.html">Dan Halperin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05953">PDF</a><br/><b>Abstract: </b>This paper deals with the following separability problem in 3D space: Given a
rigid polyhedron $P$ with $n$ vertices, does a semi-rigid polyhedron $G$ exist,
such that both polyhedra can be transformed into an inseparable assembled
state, where the fixture snaps on to $P$, by applying a linear force and
exploiting the mild flexibility of $G$? If such a flexible snapping polyhedron
exists, devise an efficient and robust algorithm that constructs it. In simple
words, we are looking for s semi-rigid polyhedron $G$, such that when $P$ and
$G$ are separate, we can push $G$ towards $P$, slightly bending $G$ on the way,
and obtain a configuration, where $G$ is back in its original shape, and both
$P$ and $G$ are inseparable as rigid bodies. We define certain properties such
a pair of polyhedron and its snapping fixture may possess, and prove two
theorems related to the pair. We introduce an algorithm that produces a
snapping fixture with such properties in $O(n^5)$ time, if a snapping fixture
exists, and an efficient and robust implementation of this algorithm.
</p></div>
    </summary>
    <updated>2019-09-16T23:26:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.05901</id>
    <link href="http://arxiv.org/abs/1909.05901" rel="alternate" type="text/html"/>
    <title>Examples, counterexamples, and structure in bounded width algebras</title>
    <feedworld_mtime>1568592000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brady:Zarathustra.html">Zarathustra Brady</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05901">PDF</a><br/><b>Abstract: </b>We study bounded width algebras which are minimal in the sense that every
proper reduct does not have bounded width. We show that minimal bounded width
algebras can be arranged into a pseudovariety with one basic ternary operation.
We classify minimal bounded width algebras which have size at most three, and
prove a structure theorem for minimal bounded width algebras which have no
majority subalgebra, which form a pseudovariety with a commutative binary
operation. As a byproduct of our results, we also classify minimal clones which
have a Taylor term.
</p></div>
    </summary>
    <updated>2019-09-16T23:21:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/09/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/09/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Lee Bollinger, president of Columbia University: “No, I won’t start spying on my foreign-born students” ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.washingtonpost.com/opinions/no-i-wont-start-spying-on-my-foreign-born-students/2019/08/29/01c80e84-c9b2-11e9-a1fe-ca46e8d573c0_story.html">Lee Bollinger, president of Columbia University: “No, I won’t start spying on my foreign-born students”</a> (<a href="https://mathstodon.xyz/@11011110/102718751083310854"/>).</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/08/30/update-on-the-safe-toc-initiative-guest-post-by-sandy-irani/">Update on the Safe ToC initiative</a> (<a href="https://mathstodon.xyz/@11011110/102725927728134229"/>). Sandy Irani describes progress in combatting harassment and discrimination at theoretical computer science conferences, and calls for volunteer advocates to serve as contact points at conferences.</p>
  </li>
  <li>
    <p><a href="http://isohedral.ca/escher-like-spiral-tilings/">Escher-like spiral tilings, by Craig Kaplan</a> (<a href="https://mathstodon.xyz/@11011110/102732614495435403"/>, <a href="https://news.ycombinator.com/item?id=20854644">via</a>). Sadly with no angels, devils, fish, or geese, but maybe some talented artist will take up that challenge.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00263">How to peel self-intersecting onions</a> (<a href="https://mathstodon.xyz/@jeffgerickson/102734672335961160"/>). Gabriel Nivasch extends the <a href="https://11011110.github.io/blog/2017/10/11/peeling-vs-shortening.html">conjectured equivalence</a> between <a href="https://en.wikipedia.org/wiki/Convex_layers">convex layers</a> and the <a href="https://en.wikipedia.org/wiki/Curve-shortening_flow#Related_flows">affine curve-shortening flow</a> to non-convex and self-intersecting curves. The generalized onion-peeling process alternates between steps that jump over grid points and steps that shrink curves to the shortest curve that passes between the same grid points. See also Gabriel’s animations of this process for <a href="https://mathstodon.xyz/@gnivasch/102741204463574303">grid points</a> and for <a href="https://mathstodon.xyz/@gnivasch/102753301344471044">random points</a>.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00917">New stick number bounds from random sampling of confined polygons</a> (<a href="https://mathstodon.xyz/@shonk/102742716819892997"/>). Tom Eddy and Clayton Shonkwiler do knot theory on large numbers of random 3d polygons, in the process finding polygonal representations of many knots with fewer segments than were known before.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/2019/09/42-is-the-answer-to-the-question-what-is-80538738812075974%c2%b3-80435758145817515%c2%b3-12602123297335631%c2%b3/">42 is the answer</a>. The question is: What is ?</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1177/2378023118823946">Who Counts as a Notable Sociologist on Wikipedia? Gender, Race, and the “Professor Test”</a> (<a href="https://mathstodon.xyz/@11011110/102755324164533099"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-08-30/Recent_research">via</a>). After authors Adams, Brückner, and Naslund factored out seniority and impact of sociologists, white men remained more likely than others to have Wikipedia articles. Surprisingly to me, the disparity happens at article creation, not deletion. So we should create more articles about women! Or be less quick to create them on borderline-notable men…</p>
  </li>
  <li>
    <p><a href="https://www.flickr.com/photos/132410114@N04/24230683269/">Permutations in the real world: 12784563</a> (<a href="https://mathstodon.xyz/@11011110/102763393307640430"/>). Actually I have sentimental reasons to prefer 15426378, but I couldn’t find a nice photo of that one.</p>
  </li>
  <li>
    <p><a href="https://simon.lc/the-history-of-tetris-randomizers">The history of Tetris randomizers</a> (<a href="https://mathstodon.xyz/@11011110/102766825773116819"/>, <a href="https://www.metafilter.com/182935/let-piece-I-J-L-TMathfloorMathrandom-4">via</a>). Truly uniformly random distributions tend to be more clustered than people expect (having runs of the same piece or of mostly the same piece). So later versions took measures to make the piece distribution less random and more non-clustered.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1908.07097">An  lower bound for random universal sets for planar graphs</a> (<a href="https://mathstodon.xyz/@11011110/102771230722757397"/>). Random subsets of a square act like grids in lots of ways. Here’s one, from the linked preprint: to draw all -vertex planar graphs with chosen points as vertices, you need either a grid or a random point set of  points. The reason is that drawings of the nested triangles graph contain a sequence of  points (corners of bounding boxes of triangles) that’s monotone in both coordinate directions, and smaller random sets (or grids) don’t have such sequences.</p>
  </li>
  <li>
    <p><a href="https://codepen.io/collection/eErLu/">CSS polyhedra</a> (<a href="https://mathstodon.xyz/web/statuses/102775320989084287"/>). Visualizations of 3d rotating polyhedra, coded entirely in html/css and embeddable in other web pages.</p>
  </li>
  <li>
    <p><a href="https://www.maths.ox.ac.uk/node/30217">Random minimum spanning trees</a> (<a href="https://mathstodon.xyz/@11011110/102786143581334329"/>). Did you know that in random graphs with edge probability  (just below the appearance of the giant component) there are lots of components of size  that all look nearly the same as uniformly random spanning trees of a complete graph? And that the minimum spanning tree of a randomly-weighted complete graph, instead, looks like one of these components with a lot of others all glued onto it? Christina Goldschmidt describes her work in this area.</p>
  </li>
  <li>
    <p><a href="https://www.gwern.net/Turing-complete">A big list of unlikely or surprising Turing-complete systems</a> (<a href="https://mathstodon.xyz/@11011110/102789724968251958"/>, <a href="https://www.metafilter.com/183095/On-having-sufficient-complexity-to-allow-for-arbitrary-computation">via</a>). My favorite: <a href="https://github.com/tom-p-reichel/svg-is-turing-complete">SVG is Turing-complete</a> because it can be used to (slowly) simulate Rule 110 (and one hopes also simulate the weird boundary conditions needed to make Rule 110 Turing complete).</p>
  </li>
  <li>
    <p><a href="https://www.english.cam.ac.uk/cmt/?p=5751">Milton’s hand-annotated volume of Shakespeare’s plays discovered sitting on a library shelf in Philly</a> (<a href="https://mathstodon.xyz/@11011110/102791968928048975"/>, <a href="https://www.metafilter.com/183100/Miltons-Shakespeare">via</a>).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Vojt%C4%9Bch_Jarn%C3%ADk">Vojtěch Jarník, now a good article on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/102798710399112671"/>). I teach his algorithm for minimum spanning trees in my classes, but lately in my research I’ve been citing him more for his work on the number of integer grid points on convex curves. He also did important work on Diophantine approximation and nowhere-differentiable functions.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-09-15T17:51:00Z</updated>
    <published>2019-09-15T17:51:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-09-16T01:18:08Z</updated>
    </source>
  </entry>
</feed>
