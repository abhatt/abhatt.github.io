<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2018-12-31T12:22:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4045</id>
    <link href="https://www.scottaaronson.com/blog/?p=4045" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4045#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4045" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Incompleteness ex machina</title>
    <summary xml:lang="en-US">I have a treat with which to impress your friends at New Year’s Eve parties tomorrow night: a rollicking essay graciously contributed by a reader named Sebastian Oberhoff, about a unified and simplified way to prove all of Gödel’s Incompleteness Theorems, as well as Rosser’s Theorem, directly in terms of computer programs. In particular, this […]
      <div class="commentbar">
        <p/>
        <span class="commentbutton" href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4045"/>
        <a href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4045">
          <img class="commenticon" src="/images/feed-icon.png"/> Subscribe to comments
        </a>  | 
        <a href="https://www.scottaaronson.com/blog/?p=4045#comments">
          <img class="commenticon" src="/images/post-icon.png"/> Post a comment
        </a>
      </div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have a treat with which to impress your friends at New Year’s Eve parties tomorrow night: a <a href="https://www.scottaaronson.com/incompleteness.pdf">rollicking essay</a> graciously contributed by a reader named Sebastian Oberhoff, about a unified and simplified way to prove all of Gödel’s Incompleteness Theorems, as well as Rosser’s Theorem, directly in terms of computer programs.  In particular, this improves over my treatments in <em>Quantum Computing Since Democritus</em> and my <a href="https://www.scottaaronson.com/blog/?p=710">Rosser’s Theorem via Turing machines</a> post.  While there won’t be anything new here for the experts, I loved the style—indeed, it brings back wistful memories of how <em>I</em> used to write, before I accumulated too many imaginary (and non-imaginary) readers tut-tutting at crass jokes over my shoulder.  May 2019 bring us all the time and the courage to express ourselves authentically, even in ways that might be sneered at as incomplete, inconsistent, or unsound.</p></div>
    </content>
    <updated>2018-12-31T02:04:18Z</updated>
    <published>2018-12-31T02:04:18Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2018-12-31T02:04:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.11003</id>
    <link href="http://arxiv.org/abs/1812.11003" rel="alternate" type="text/html"/>
    <title>Sequential algorithms and the computational content of classical proofs</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Powell:Thomas.html">Thomas Powell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.11003">PDF</a><br/><b>Abstract: </b>We develop a correspondence between the theory of sequential algorithms and
classical reasoning, via Kreisel's no-counterexample interpretation. Our
framework views realizers of the no-counterexample interpretation as dynamic
processes which interact with an oracle, and allows these processes to be
modelled at any given level of abstraction. We discuss general constructions on
algorithms which represent specific patterns which often appear in classical
reasoning, and in particular, we develop a computational interpretation of the
rule of dependent choice which is phrased purely on the level of algorithms,
giving us a clearer insight into the computational meaning of proofs in
classical analysis.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:36:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10977</id>
    <link href="http://arxiv.org/abs/1812.10977" rel="alternate" type="text/html"/>
    <title>Compact and Efficient Representation of General Graph Databases</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sandra Álvarez-García, Borja Freire, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Ladra:Susana.html">Susana Ladra</a>, Óscar Pedreira <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10977">PDF</a><br/><b>Abstract: </b>In this paper, we propose a compact data structure to store labeled
attributed graphs based on the k2-tree, which is a very compact data structure
designed to represent a simple directed graph. The idea we propose can be seen
as an extension of the k2-tree to support property graphs. In addition to the
static approach, we also propose a dynamic version of the storage
representation, which allows exible schemas and insertion or deletion of data.
We provide an implementation of a basic set of operations, which can be
combined to form complex queries over these graphs with attributes. We evaluate
the performance of our proposal with existing graph database systems and prove
that our compact attributed graph representation obtains also competitive time
results.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:24:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10974</id>
    <link href="http://arxiv.org/abs/1812.10974" rel="alternate" type="text/html"/>
    <title>A Grammar-based Compressed Representation of 3D Trajectories</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brisaboa:Nieves_R=.html">Nieves R. Brisaboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oacute=mez=Brand=oacute=n:Adri=aacute=n.html">Adrián Gómez-Brandón</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mart=iacute=nez=Prieto:Miguel_A=.html">Miguel A. Martínez-Prieto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Param=aacute=:Jos=eacute=_R=.html">José R. Paramá</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10974">PDF</a><br/><b>Abstract: </b>Much research has been published about trajectory management on the ground or
at the sea, but compression or indexing of flight trajectories have usually
been less explored. However, air traffic management is a challenge because
airspace is becoming more and more congested, and large flight data collections
must be preserved and exploited for varied purposes. This paper proposes
3DGraCT, a new method for representing these flight trajectories. It extends
the GraCT compact data structure to cope with a third dimension (altitude),
while retaining its space/time complexities. 3DGraCT improves space
requirements of traditional spatio-temporal data structures by two orders of
magnitude, being competitive for the considered types of queries, even leading
the comparison for a particular one.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:25:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10950</id>
    <link href="http://arxiv.org/abs/1812.10950" rel="alternate" type="text/html"/>
    <title>Fast Breadth-First Search in Still Less Space</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hagerup:Torben.html">Torben Hagerup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10950">PDF</a><br/><b>Abstract: </b>It is shown that a breadth-first search in a directed or undirected graph
with $n$ vertices and $m$ edges can be carried out in $O(n+m)$ time with
$n\log_2 3+O((\log n)^2)$ bits of working memory.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:24:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10854</id>
    <link href="http://arxiv.org/abs/1812.10854" rel="alternate" type="text/html"/>
    <title>Fair Coresets and Streaming Algorithms for Fair k-Means Clustering</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Melanie.html">Melanie Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwiegelshohn:Chris.html">Chris Schwiegelshohn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sohler:Christian.html">Christian Sohler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10854">PDF</a><br/><b>Abstract: </b>We study fair clustering problems as proposed by Chierichetti et al. Here,
points have a sensitive attribute and all clusters in the solution are required
to be balanced with respect to it (to counteract any form of data-inherent
bias). Previous algorithms for fair clustering do not scale well. We show how
to model and compute so-called coresets for fair clustering problems, which can
be used to significantly reduce the input data size. We prove that the coresets
are composable and show how to compute them in a streaming setting. We also
propose a novel combination of the coreset construction with a sketching
technique due to Cohen et al. which may be of independent interest. We conclude
with an empirical evaluation.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:23:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10837</id>
    <link href="http://arxiv.org/abs/1812.10837" rel="alternate" type="text/html"/>
    <title>On the Approximability of Time Disjoint Walks</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexandre Bayen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodman:Jesse.html">Jesse Goodman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinitsky:Eugene.html">Eugene Vinitsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10837">PDF</a><br/><b>Abstract: </b>We introduce the combinatorial optimization problem Time Disjoint Walks. This
problem takes as input a digraph $G$ with positive integer arc lengths, and $k$
pairs of vertices that each represent a trip demand from a source to a
destination. The goal is to find a path and delay for each demand so that no
two trips occupy the same vertex at the same time, and so that the sum of trip
times is minimized. We show that even for DAGs with max degree $\Delta\leq3$,
Time Disjoint Walks is APX-hard. We also present a natural approximation
algorithm, and provide a tight analysis. In particular, we prove that it
achieves an approximation ratio of $\Theta(k/\log k)$ on bounded-degree DAGs,
and $\Theta(k)$ on DAGs and bounded-degree digraphs.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10808</id>
    <link href="http://arxiv.org/abs/1812.10808" rel="alternate" type="text/html"/>
    <title>Above guarantee parameterization for vertex cover on graphs with maximum degree 4</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10808">PDF</a><br/><b>Abstract: </b>In the vertex cover problem, the input is a graph $G$ and an integer $k$, and
the goal is to decide whether there is a set of vertices $S$ of size at most
$k$ such that every edge of $G$ is incident on at least one vertex in $S$. We
study the vertex cover problem on graphs with maximum degree 4 and minimum
degree at least 2, parameterized by $r = k-n/3$. We give an algorithm for this
problem whose running time is $O^*(1.6253^r)$. As a corollary, we obtain an
$O^*(1.2403^k)$-time algorithm for vertex cover on graphs with maximum degree
4.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:33:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10797</id>
    <link href="http://arxiv.org/abs/1812.10797" rel="alternate" type="text/html"/>
    <title>Reinforcement learning architecture for automated quantum-adiabatic-algorithm design</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Jian.html">Jian Lin</a>, Zhong Yuan Lai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xiaopeng.html">Xiaopeng Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10797">PDF</a><br/><b>Abstract: </b>Quantum algorithm design lies in the hallmark of applications of quantum
computation and quantum simulation. Here we put forward a deep reinforcement
learning (RL) architecture for automated algorithm design in the framework of
quantum adiabatic algorithm, where the optimal Hamiltonian path to reach a
quantum ground state that encodes a compution problem is obtained by RL
techniques. We benchmark our approach in Grover search and 3-SAT problems, and
find that the adiabatic algorithm obtained by our RL approach leads to
significant improvement in the success probability and computing speedups for
both moderate and large number of qubits compared to conventional algorithms.
The RL-designed algorithm is found to be qualitatively distinct from the linear
algorithm in the resultant distribution of success probability. Considering the
established complexity-equivalence of circuit and adiabatic quantum algorithms,
we expect the RL-designed adiabatic algorithm to inspire novel circuit
algorithms as well. Our approach offers a recipe to design quantum algorithms
for generic problems through a machinery RL process, which paves a novel way to
automated quantum algorithm design using artificial intelligence, potentially
applicable to different quantum simulation and computation platforms from
trapped ions and optical lattices to superconducting-qubit devices.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:35:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10771</id>
    <link href="http://arxiv.org/abs/1812.10771" rel="alternate" type="text/html"/>
    <title>Approximate counting and NP search problems</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Leszek Aleksander Kołodziejczyk, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thapen:Neil.html">Neil Thapen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10771">PDF</a><br/><b>Abstract: </b>We study a new class of NP search problems, those which can be proved total
in the theory $\mathrm{APC}_2$ of [Je\v{r}\'abek 2009]. This is an axiomatic
theory in bounded arithmetic which can formalize standard combinatorial
arguments based on approximate counting. In particular, the Ramsey and weak
pigeonhole search problems lie in the class. We give a purely computational
characterization of this class and show that, relative to an oracle, it does
not contain the problem CPLS, a strengthening of PLS.
</p>
<p>As CPLS is provably total in the theory $T^2_2$, this shows that
$\mathrm{APC}_2$ does not prove every $\forall \Sigma^b_1$ sentence which is
provable in bounded arithmetic. This answers the question posed in [Buss,
Ko{\l}odziejczyk, Thapen 2014] and represents some progress in the programme of
separating the levels of the bounded arithmetic hierarchy by low-complexity
sentences.
</p>
<p>Our main technical tool is an extension of the "fixing lemma" from [Pudl\'ak,
Thapen 2017], a form of switching lemma, which we use to show that a random
partial oracle from a certain distribution will, with high probability,
determine an entire computation of a $\textrm{P}^{\textrm{NP}}$ oracle machine.
The paper is intended to be accessible to someone unfamiliar with NP search
problems or with bounded arithmetic.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10770</id>
    <link href="http://arxiv.org/abs/1812.10770" rel="alternate" type="text/html"/>
    <title>Complex Semidefinite Programming and Max-k-Cut</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Alantha.html">Alantha Newman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10770">PDF</a><br/><b>Abstract: </b>In a second seminal paper on the application of semidefinite programming to
graph partitioning problems, Goemans and Williamson showed how to formulate and
round a complex semidefinite program to give what is to date still the
best-known approximation guarantee of .836008 for Max-$3$-Cut. (This
approximation ratio was also achieved independently by De Klerk et al.) Goemans
and Williamson left open the problem of how to apply their techniques to
Max-$k$-Cut for general $k$. They point out that it does not seem
straightforward or even possible to formulate a good quality complex
semidefinite program for the general Max-$k$-Cut problem, which presents a
barrier for the further application of their techniques.
</p>
<p>We present a simple rounding algorithm for the standard semidefinite
programmming relaxation of Max-$k$-Cut and show that it is equivalent to the
rounding of Goemans and Williamson in the case of Max-$3$-Cut. This allows us
to transfer the elegant analysis of Goemans and Williamson for Max-3-Cut to
Max-$k$-Cut. For $k \geq 4$, the resulting approximation ratios are about $.01$
worse than the best known guarantees. Finally, we present a generalization of
our rounding algorithm and conjecture (based on computational observations)
that it matches the best-known guarantees of De Klerk et al.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:36:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10629</id>
    <link href="http://arxiv.org/abs/1812.10629" rel="alternate" type="text/html"/>
    <title>Complexity of Reconfiguration Problems for Constraint Satisfaction</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hatanaka:Tatsuhiko.html">Tatsuhiko Hatanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Xiao.html">Xiao Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10629">PDF</a><br/><b>Abstract: </b>Constraint satisfaction problem (CSP) is a well-studied combinatorial search
problem, in which we are asked to find an assignment of values to given
variables so as to satisfy all of given constraints. We study a reconfiguration
variant of CSP, in which we are given an instance of CSP together with its two
satisfying assignments, and asked to determine whether one assignment can be
transformed into the other by changing a single variable assignment at a time,
while always remaining satisfying assignment. This problem generalizes several
well-studied reconfiguration problems such as Boolean satisfiability
reconfiguration, vertex coloring reconfiguration, homomorphism reconfiguration.
In this paper, we study the problem from the viewpoints of polynomial-time
solvability and parameterized complexity, and give several interesting
boundaries of tractable and intractable cases.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:28:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10582</id>
    <link href="http://arxiv.org/abs/1812.10582" rel="alternate" type="text/html"/>
    <title>Hierarchical Clustering for Euclidean Data</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatziafratis:Vaggos.html">Vaggos Chatziafratis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niazadeh:Rad.html">Rad Niazadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaroslavtsev:Grigory.html">Grigory Yaroslavtsev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10582">PDF</a><br/><b>Abstract: </b>Recent works on Hierarchical Clustering (HC), a well-studied problem in
exploratory data analysis, have focused on optimizing various objective
functions for this problem under arbitrary similarity measures. In this paper
we take the first step and give novel scalable algorithms for this problem
tailored to Euclidean data in R^d and under vector-based similarity measures, a
prevalent model in several typical machine learning applications. We focus
primarily on the popular Gaussian kernel and other related measures, presenting
our results through the lens of the objective introduced recently by Moseley
and Wang [2017]. We show that the approximation factor in Moseley and Wang
[2017] can be improved for Euclidean data. We further demonstrate both
theoretically and experimentally that our algorithms scale to very high
dimension d, while outperforming average-linkage and showing competitive
results against other less scalable approaches.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:31:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10563</id>
    <link href="http://arxiv.org/abs/1812.10563" rel="alternate" type="text/html"/>
    <title>The Prophet Inequality Can Be Solved Optimally with a Single Set of Samples</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jack.html">Jack Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10563">PDF</a><br/><b>Abstract: </b>The setting of the classic prophet inequality is as follows: a gambler is
shown the probability distributions of $n$ independent, non-negative random
variables with finite expectations. In their indexed order, a value is drawn
from each distribution, and after every draw the gambler may choose to accept
the value and end the game, or discard the value permanently and continue the
game. What is the best performance that the gambler can achieve in comparison
to a prophet who can always choose the highest value? Krengel, Sucheston, and
Garling solved this problem in 1978, showing that there exists a strategy for
which the gambler can achieve half as much reward as the prophet in
expectation. Furthermore, this result is tight.
</p>
<p>In this work, we consider a setting in which the gambler is allowed much less
information. Suppose that the gambler can only take one sample from each of the
distributions before playing the game, instead of knowing the full
distributions. We provide a simple and intuitive algorithm that recovers the
original approximation of $\frac{1}{2}$. Our algorithm works against even an
almighty adversary who always chooses a worst-case ordering, rather than the
standard offline adversary. The result also has implications for mechanism
design -- there is much interest in designing competitive auctions with a
finite number of samples from value distributions rather than full
distributional knowledge.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:21:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10530</id>
    <link href="http://arxiv.org/abs/1812.10530" rel="alternate" type="text/html"/>
    <title>Group evolution patterns in running races</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Y. Diez, M. Fort, M. Korman, J. A. Sellarès <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10530">PDF</a><br/><b>Abstract: </b>We address the problem of tracking and detecting interactions between the
different groups of runners that form during a race. In athletic races control
points are set to monitor the progress of athletes over the course.
Intuitively, a {\it group} is a sufficiently large set of athletes that cross a
control point together. After adapting an existing definition of group to our
setting we go on to study two types of group evolution patterns. The primary
focus of this work are {\it evolution patterns}, i.e. the transformation and
interaction of groups of athletes between two consecutive control points. We
provide an accurate geometric model of the following evolution patterns:
survives, appears, disappears, expands, shrinks, merges, splits, coheres and
disbands, and present algorithms to efficiently compute these patterns. Next,
based on the algorithms introduced for identifying evolution patterns,
algorithms to detect {\it long-term patterns} are introduced. These patterns
track global properties over several control points: surviving, traceable
forward, traceable backward and related forward and backward. Experimental
evaluation of the algorithms provided is presented using real and synthetic
data. Using the data currently available, our experiments show how our
algorithms can provide valuable insight into how running races develop.
Moreover, we also show how, even if dense (synthetic) data is considered, our
algorithms are also able to process it in real time.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:20:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10499</id>
    <link href="http://arxiv.org/abs/1812.10499" rel="alternate" type="text/html"/>
    <title>Removing Sequential Bottleneck of Dijkstra's Algorithm for the Shortest Path Problem</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Vijay_K=.html">Vijay K. Garg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10499">PDF</a><br/><b>Abstract: </b>All traditional methods of computing shortest paths depend upon
edge-relaxation where the cost of reaching a vertex from a source vertex is
possibly decreased if that edge is used. We introduce a method which maintains
lower bounds as well as upper bounds for reaching a vertex. This method enables
one to find the optimal cost for multiple vertices in one iteration and thereby
reduces the sequential bottleneck in Dijkstra's algorithm.
</p>
<p>We present four algorithms in this paper --- $SP_1$, $SP_2$, $SP_3$ and
$SP_4$. $SP_1$ and $SP_2$ reduce the number of heap operations in Dijkstra's
algorithm. For directed acyclic graphs, or directed unweighted graphs they have
the optimal complexity of $O(e)$ where $e$ is the number of edges in the graph
which is better than that of Dijkstra's algorithm. For general graphs, their
worst case complexity matches that of Dijkstra's algorithm for a sequential
implementation but allows for greater parallelism. Algorithms $SP_3$ and $SP_4$
allow for even more parallelism but with higher work complexity. Algorithm
$SP_3$ requires $O(n + e(\max(\log n, \Delta)))$ work where $n$ is the number
of vertices and $\Delta$ is the maximum in-degree of a node. Algorithm $SP_4$
has the most parallelism. It requires $O(ne)$ work. These algorithms generalize
the work by Crauser, Mehlhorn, Meyer, and Sanders on parallelizing Dijkstra's
algorithm.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:21:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1812.10309</id>
    <link href="http://arxiv.org/abs/1812.10309" rel="alternate" type="text/html"/>
    <title>Efficiently list-edge coloring multigraphs asymptotically optimally</title>
    <feedworld_mtime>1546214400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iliopoulos:Fotis.html">Fotis Iliopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinclair:Alistair.html">Alistair Sinclair</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1812.10309">PDF</a><br/><b>Abstract: </b>We give polynomial time algorithms for the seminal results of Kahn, who
showed that the Goldberg-Seymour and List-Coloring conjectures for (list-)edge
coloring multigraphs hold asymptotically. Kahn's arguments are based on the
probabilistic method and are non-constructive. Our key insight is to show that
the main result of Achlioptas, Iliopoulos and Kolmogorov for analyzing local
search algorithms can be used to make constructive applications of a powerful
version of the so-called Lopsided Lovasz Local Lemma. In particular, we use it
to design algorithms that exploit the fact that correlations in the probability
spaces on matchings used by Kahn decay with distance.
</p></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-31T02:34:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2018-12-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:typepad.com,2003:post-6a00d83452383469e2022ad3ca27b2200b</id>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html" rel="alternate" type="text/html"/>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html" rel="replies" type="text/html"/>
    <title>Steal This Book!</title>
    <summary>Today I'm finally releasing a final (or more honestly, “final”) pre-publication draft of my Algorithms textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years....
      <div class="commentbar">
        <p/>
        <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">
          <img class="commenticon" src="/images/post-icon.png"/> Post a comment
        </a>
      </div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="asset-img-link" href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup"><img alt="BookCover" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" style="display: block; margin-left: auto; margin-right: auto;" title="BookCover"/></a><br/>Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>
    </content>
    <updated>2018-12-29T22:50:59Z</updated>
    <published>2018-12-29T22:50:59Z</published>
    <category term="Algorithms"/>
    <category term="Books"/>
    <category term="Writing"/>
    <author>
      <name>Jeff Erickson</name>
    </author>
    <source>
      <id>tag:typepad.com,2003:weblog-6686</id>
      <link href="https://3dpancakes.typepad.com/ernie/atom.xml" rel="self" type="application/atom+xml"/>
      <link href="https://3dpancakes.typepad.com/ernie/" rel="alternate" type="text/html"/>
      <subtitle>Let Σ be a combinatorial surface with n vertices, genus g, and b boundaries.  Amen.</subtitle>
      <title>Ernie's 3D Pancakes</title>
      <updated>2018-12-29T22:50:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:typepad.com,2003:post-6a00d83452383469e2022ad3aa81e9200d</id>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book.html" rel="alternate" type="text/html"/>
    <link href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book.html" rel="replies" type="text/html"/>
    <title>Steal This Book!</title>
    <summary>Today I'm finally releasing a final (or more honestly, “final”) pre-publication draft of my Algorithms textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years....
      <div class="commentbar">
        <p/>
        <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book.html">
          <img class="commenticon" src="/images/post-icon.png"/> Post a comment
        </a>
      </div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="asset-img-link" href="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-popup"><img alt="BookCover" class="asset  asset-image at-xid-6a00d83452383469e2022ad3aa81d3200d img-responsive" src="https://3dpancakes.typepad.com/.a/6a00d83452383469e2022ad3aa81d3200d-320wi" style="display: block; margin-left: auto; margin-right: auto;" title="BookCover"/></a><br/>Today I'm <em>finally</em> releasing a final (or more honestly, “final”) pre-publication draft of my <em>Algorithms</em> textbook under a CC-BY license. This 448-page textbook evolved out of a subset of the algorithms lecture notes I've been maintaining for about 20 years.</p>
<p>There are still a few more steps before this becomes an actual paper book—most notably an index—but I wanted to get this out the door this year. I expect to publish the actual paper book in a few weeks; it will also be licensed CC-BY.</p>
<p>Meanwhile, I've set up an issue-tracker on Github where anyone can report errors or provide other feedback.</p>
<p>The book site also includes copies of the lecture notes that I left out of the book (because I wanted a finite book in a finite amount of time), along with a complete archive of old homeworks, exams, lab handouts, and the like.</p>
<p>Enjoy!</p>
<ul>
<li>Official book site: <a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">http://jeffe.cs.illinois.edu/teaching/algorithms/</a></li>
<li>Mnemonic shortcut: <a href="http://algorithms.wtf">http://algorithms.wtf</a></li>
<li><strong>Please report errors:</strong> <a href="https://github.com/jeffgerickson/algorithms">https://github.com/jeffgerickson/algorithms</a></li>
<li>Archival copy: <a href="https://archive.org/details/Algorithms-Jeff-Erickson">https://archive.org/details/Algorithms-Jeff-Erickson</a></li>
</ul></div>
    </content>
    <updated>2018-12-29T22:50:49Z</updated>
    <published>2018-12-29T22:50:49Z</published>
    <author>
      <name>Jeff Erickson</name>
    </author>
    <source>
      <id>tag:typepad.com,2003:weblog-6686</id>
      <link href="https://3dpancakes.typepad.com/ernie/atom.xml" rel="self" type="application/atom+xml"/>
      <link href="https://3dpancakes.typepad.com/ernie/" rel="alternate" type="text/html"/>
      <subtitle>Let Σ be a combinatorial surface with n vertices, genus g, and b boundaries.  Amen.</subtitle>
      <title>Ernie's 3D Pancakes</title>
      <updated>2018-12-29T22:50:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3371</id>
    <link href="https://agtb.wordpress.com/2018/12/28/sigecom-test-of-time-award/" rel="alternate" type="text/html"/>
    <title>SIGecom Test of Time Award</title>
    <summary>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation. To be eligible, a paper or series of papers must be on a topic in […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>The SIGecom Test of Time Award recognizes the author or authors of an influential paper or series of papers published between ten and twenty-five years ago that has significantly impacted research or applications exemplifying the interplay of economics and computation.</div>
<div/>
<p/>
<div>To be eligible, a paper or series of papers must be on a topic in the intersection of economics and computation, including topics in electronic commerce, and must have been first published, in preliminary or final form, in an archival journal or conference proceedings no less than ten years and no more than twenty-five years before the year the award is conferred. Papers for which all authors are deceased at the time the Award Committee makes its decision are not eligible for the award.</div>
<div/>
<p/>
<div>The 2019 SIGecom Test of Time Award will be given for papers published no earlier than 1994 and no later than 2009. Nominations are due by February 20th, 2019, and must be made by email to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a>) with “ACM SIGecom Test of Time Award” in the subject.</div>
<div/>
<p/>
<div>Any member of SIGecom may submit a nomination. Self-nomination is not allowed. Nominations must include the following, preferably in a single PDF file:</div>
<div/>
<p/>
<div>1. Bibliographic data for the paper or series of papers demonstrating publication, in preliminary or final form, at least ten years and at most twenty-five years before the award year.</div>
<div/>
<p/>
<div>2. An endorsement letter by the nominator of no more than two pages describing the content of the paper or series of papers and the lasting contribution, significance, and impact of the work.</div>
<div/>
<p/>
<div>3. The names, email addresses, and affiliations of at least two and at most three other endorsers. Endorsers, like the nominator, may not be authors of the paper or papers under consideration.</div>
<div/>
<p/>
<div>4. A one-sentence statement that describes the contribution of the paper or series of papers.</div>
<div/>
<p/>
<div>The additional endorsers should send letters directly to the Award Committee (<a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a>) by the same deadline. Each letter should specify the relationship of the endorser to nominees and describe, in 500 words or fewer, the lasting contribution, significance, and impact of the paper or papers.</div>
<div/>
<p/>
<div>An unsuccessful nomination can be reconsidered for three award cycles, with the option of updating the original nomination to reflect additional impact. Subsequently, a new nomination must be provided. All matters relating to the selection process that are not specified here are left to the discretion of the Award Committee.</div>
<div/>
<p/>
<div>The award, conferred annually at the ACM Conference on Economics and Computation, includes a plaque and complimentary conference registration for each winner and an honorarium of $1,000 to be shared among the winners. The award may not be given if the nominations are judged not to meet the standards of the award.</div>
<div/>
<p/>
<div>It is expected that at least one of the nominated authors, if selected for the award, will attend the next ACM Conference on Economics and Computation on June 24-28, 2019, in Phoenix, AZ, USA, to accept the award and give a presentation on the work. The award includes complimentary registration but does not cover travel expenses to attend the conference.</div>
<div/>
<p/>
<div>The Award Committee welcomes questions from anyone considering or intending to submit a nomination. The Award Committee is happy to provide feedback on informal proposals for potential nominees, should it be needed.</div>
<div/>
<p/>
<div>On behalf of the 2019 Award Committee:</div>
<div/>
<p/>
<div>Nikhil Devanur</div>
<div>Robert Kleinberg</div>
<div>Tim Roughgarden (Chair)</div>
<div><a href="mailto:sigecom-awards-tot@acm.org" rel="noopener" target="_blank">sigecom-awards-tot@acm.org</a></div></div>
    </content>
    <updated>2018-12-28T20:52:18Z</updated>
    <published>2018-12-28T20:52:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2018-12-31T12:22:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2018/213</id>
    <link href="https://eccc.weizmann.ac.il/report/2018/213" rel="alternate" type="text/html"/>
    <title>TR18-213 |  The Power of Distributed Verifiers in Interactive Proofs | 

	Eylon Yogev, 

	Moni Naor, 

	Merav Parter</title>
    <summary>We explore the power of interactive proofs with a distributed verifier. In this setting, the verifier consists of $n$ nodes and a graph $G$ that defines their communication pattern. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ belongs to some language in a small number of rounds, and with small communication bound, i.e., the proof size.

This interactive model was introduced by Kol, Oshman and Saxena (PODC 2018) as a generalization of non-interactive distributed proofs. They demonstrated the power of interaction in this setting by constructing protocols for problems as Graph Symmetry and Graph Non-Isomorphism -- both of which require proofs of $\Omega(n^2)$-bits without interaction.

In this work, we provide a new general framework for distributed interactive proofs that allows one to translate standard interactive protocols (i.e., with a centralized verifier) to ones where the verifier is distributed with a proof size that depends on the computational complexity of the verification algorithm run by the centralized verifier.
We show the following:

* Every (centralized) computation that can be performed in time $O(n)$ can be translated into three-round distributed interactive protocol with $O(\log n)$ proof size. This implies that many graph problems for sparse graphs have succinct proofs (e.g., testing planarity).

* Every (centralized) computation implemented by either a small space or by uniform NC circuit can be translated into a distributed protocol with $O(1)$ rounds and $O(\log n)$ bits proof size for the low space case and $polylog(n)$ many rounds and proof size for NC.

* We also demonstrate the power of our compilers for problems not captured by the above families. We show that for Graph Non-Isomorphism, one of the striking demonstrations of the power of interaction, there is a 4-round protocol with $O(\log n)$ proof size, improving upon the $O(n \log n)$ proof size of Kol et al.

* For many problems we show how to reduce proof size below the naturally seeming barrier of $\log n$. By employing our RAM compiler, we get a 5-round protocols with proof size $O(\log \log n)$ for a family of problems including Fixed Automorphism, Clique and Leader Election (for the later two problems we actually get $O(1)$ proof size).

* Finally we discuss how to make these proofs non-interactive arguments via random oracles.

Our compilers capture many natural problems and demonstrates the difficultly in showing lower bounds in these regimes.
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-28T08:02:29Z</updated>
    <published>2018-12-28T08:02:29Z</published>
    <source>
      <id>https://example.com/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://example.com/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2018-12-31T12:22:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15551</id>
    <link href="https://rjlipton.wordpress.com/2018/12/27/acm-great-results/" rel="alternate" type="text/html"/>
    <title>ACM Great Results</title>
    <summary>A Puck-ish take on promised technological advances Wikimedia Commons source Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. Puck. The Simpsons’ dog “Santa’s Little Helper” is named “Knecht Ruprecht” […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A Puck-ish take on promised technological advances</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg"><img alt="" class="alignright wp-image-15552" height="189" src="https://rjlipton.files.wordpress.com/2018/12/KnechtRuprecht.jpg?w=189&amp;h=189" width="189"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Das_festliche_Jahr_img398_(Ruprecht).jpg">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Knecht Ruprecht accompanies Santa Claus in Germany. He brings gifts to good children but lumps of coal to naughty ones. He is regarded more generally as the German counterpart to England’s Robin Goodfellow, aka. <a href="https://en.wikipedia.org/wiki/Puck_(folklore)">Puck</a>. The Simpsons’ <a href="https://en.wikipedia.org/wiki/Santa's_Little_Helper">dog</a> “Santa’s Little Helper” is named “Knecht Ruprecht” in the show’s German edition.</p>
<p>
Today we do a nice-or-naughty riff on technological gifts suggested by yesterday’s ACM TechNews mailing.</p>
<p>
The ACM mailings highlight the achievements of the whole field: from quantum to everything else. We thought it might be fun to be a bit puckish ourselves and deliver some “coal” to ACM. The stories can be sometimes a bit much. We hope that all involved are in good spirits and accept the “coal” as a holiday-inspired gift—with some echo of the general discussion about naughty-or-nice effects of tech advances.</p>
<p>
</p><p/><h2> Our Versions of the Stories </h2><p/>
<p>
</p><p>
Here are some that could be reported in the near future. The originals are <a href="https://technews.acm.org/archives.cfm?fo=2018-12-dec/dec-26-2018.html">here</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Real-Time Readouts of Thinking in Faculty</i>. <br/>
Mighty News<br/>
December 19, 2018<br/>
Researchers from a university consortium have developed an open source system delivering fast, precise neural decoding and real-time readouts of where CS faculty think they are. The neural decoding software decrypts hippocampal spatiotemporal patterns detected from tetrode recordings without requiring spike sorting, an error-prone computational process. Implementing this software on a graphical processing unit (GPU) chip demonstrated a 20- to 50-fold upgrade in decoding and analysis speed over conventional multicore central processing unit (CPU) chips. This builds on work previous done on rats as reported by ACM previously. The lab director says that the CS faculty work presented many challenges beyond that required for rats. The applications—she says—are immense. Faculty currently cannot always tell where they are, and the new system could help them get to classes on time.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A Robotic Hand Able To Type At Desktop Keyboard At 20 Words Per Minute</i>.<br/>
New Yolk Times<br/>
December 19, 2018 <br/>
Researchers at Can’t-Abridge University have for the first time taught a robotic hand to type on a normal keyboard. The researchers claim that their system can type at rates in excess of 20 words per minute. They say, “this could change the way that computers interact with others.” The system, which now weighs about 500 pounds, could be reduced in size and cost in the future. That the robot sometimes destroys the keys by hitting them too hard continues to be a challenge.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>How AI Spotted Every Solar Panel in the U.S.</i><br/>
Pretty Big Solar NewsHour<br/>
December 19, 2018<br/>
Engineers at the University of St. Anford have located every solar panel in the contiguous U.S. via a network built around a deep learning computer model called Inception. The network completed this task in less than a month, ascertaining that regions with more sun exposure had greater solar panel adoption than areas with less average sunlight. DeepSolar also learned that adoption was higher in locations of increasing average household income. Unbelievable—who would have guessed this?</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>An Amoeba Just Found an Entirely New Way to Write Articles</i>. <br/>
ScienceAlarm <br/>
December 21, 2018<br/>
Researchers at Knockout University in Japan gave an assistant professorship to a “true slime mold” amoeba, and found as the papers-per-year target increased from four to eight, the single-celled organism only needed a linear amount of more time to generate minimum publishable units. This is part of an ongoing project on using lower-level organisms to do research. The project previously used graduate students. The leader of the multiple institution project said that using amoebae could reduce the costs of writing up research by up to 50%. He also said that the amoeba sometimes made various grammar errors, but that the project was attempting to fix this issue.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A Quantum Computer Just Found an Entirely Old Way to Visit Cities</i>. <br/>
ScienceAllure <br/>
December 21, 2018<br/>
Researchers at TKO University in Japan gave the Traveling Salesman Problem (TPS) to a vast array of noisy astronomical scale quantum (NASQ) processors, and found that as the cities increased from four to eight, the system only needed a linear amount of more time to determine a single reasonable route. This was fresh off its success at factoring numbers higher than 291,311 = 523*557 that it didn’t even <a href="https://en.wikipedia.org/wiki/Integer_factorization_records#Records_for_efforts_by_quantum_computers">know</a> it was factoring. TPS is an optimization problem requiring a computer to look at a list of cities and determine the shortest route in which each city is visited exactly once. The team said their results “may lead to the development of quantum algorithms for problems on as many as ten cities.” </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg"><img alt="" class="aligncenter size-medium wp-image-15555" height="148" src="https://rjlipton.files.wordpress.com/2018/12/SantasLittleHelperOrlando.jpg?w=300&amp;h=148" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Modified from <a href="https://www.flickr.com/photos/jared422/11839818825">source</a><br/>
</font>
</td>
</tr>
</tbody></table>
<p><img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Programming Proteins to Pair Precisely</i>.<br/>
C++ News<br/>
December 19, 2018<br/>
The <b>std::pair</b> construct in C++ is a common annoyance because human programmers frequently forget its implicit presence when iterating over maps or inserting into sets. This necessitates the re-typing of millions of lines of source code per annum. Absent the development of a robotic hand able to type at a desktop keyboard at 20 words per minute, software companies can improve productivity by optimizing the nutritional intake of programmers. Nanosoft has partnered with CodeURIKA to provide protein-rich drinks worldwide, after a study of electronic sweatshops found that proteins minimize both syntactic and semantic bugs better over the long term than sugars and PEDs. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Room for Improvement? New Hotelier Tests an Algorithmic System</i>.<br/>
Wallbanger Street Journal<br/>
December 19, 2018<br/>
The Lite House hotelier is experimenting with an algorithmic pricing system to set different room rates for guests who arrive in self-driving cars. Once customers book for the first time at a standard rate, they fill out a questionnaire of 200 questions to specify how often they will need the car, how frequently they visit the hotel bar, and other details. The hotelier then activates a key to drive the car into an appropriate space. The optimized use of vertical space and savings from not hiring car valets will enable conference participants who are not staying at the hotel to park there at a rate low enough to include in the conference registration fee. A spokesman said, “Most of the big hotel operating companies are not focused on their conference guests,” while Lite House’s algorithmic rate-setting “is next-generation.”</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>Companies Use VR to Train Employees for Difficult Customers</i>.<br/>
ESPN Technology Review<br/>
December 20, 2018.<br/>
Major corporations like Wallstore, ChippedPot, and Horizon are using virtual reality (VR) to prepare employees for potentially difficult situations on the job. For example, Horizon has more than 1,600 stores in the U.S. whose front-line employees participate in a digital scenario in which a customer asks to use the bathroom. In a “Harry Potter-Style Photos for Muggles” twist, researchers have developed software that can animate the central character in a photograph while leaving the rest of the image untouched. Its skeleton can then be animated to create the sense of movement, solving the problem of pose estimation for a limited set of circumstances in which bathroom requests occur. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <i>New Attack Intercepts Keystrokes Via Digital Watches</i>.<br/>
TubeNet<br/>
December 19, 2018<br/>
A team of researchers from Burning Man University has developed a new side-channel attack that exploits the heat generated by people wearing Orange Digital Watches while working on their PCs. Heat amplifies the watches’ ability to detect keystrokes from both hands. Videos known to generate large amounts of heat include comic videos and videos on carpet cleaning. The attack becomes more adept at guessing correct keys as the user gets hotter, as it amasses more key presses from graphic libraries. </p>
<p/><p><br/>
There are some other items, including one particularly chilling, that we chose not to parody.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Will the next year’s advances in AI and other areas of tech be anything like we imagine? Will they bring humanity more gifts than lumps of coal?</p>
<p/></font></font></div>
    </content>
    <updated>2018-12-28T01:39:40Z</updated>
    <published>2018-12-28T01:39:40Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ACM"/>
    <category term="ACM TechNews"/>
    <category term="AI"/>
    <category term="Christmas"/>
    <category term="gifts"/>
    <category term="Knecht Ruprecht"/>
    <category term="tech"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2018-12-31T12:22:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4043</id>
    <link href="https://www.scottaaronson.com/blog/?p=4043" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4043#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4043" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Announcements</title>
    <summary xml:lang="en-US">I’m planning to be in Australia soon—in Melbourne January 4-10 for a friend’s wedding, then in Sydney January 10-11 to meet colleagues and give a talk. It will be my first trip down under for 12 years (and Dana’s first ever). If there’s interest, I might be able to do a Shtetl-Optimized meetup in Melbourne […]
      <div class="commentbar">
        <p/>
        <span class="commentbutton" href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4043"/>
        <a href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4043">
          <img class="commenticon" src="/images/feed-icon.png"/> Subscribe to comments
        </a>  | 
        <a href="https://www.scottaaronson.com/blog/?p=4043#comments">
          <img class="commenticon" src="/images/post-icon.png"/> Post a comment
        </a>
      </div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m planning to be in Australia soon—in Melbourne January 4-10 for a friend’s wedding, then in Sydney January 10-11 to meet colleagues and give a talk.  It will be my first trip down under for 12 years (and Dana’s first ever).  If there’s interest, I might be able to do a <em>Shtetl-Optimized</em> meetup in Melbourne the evening of Friday the 4th (or the morning of Saturday the 5th), and/or another one in Sydney the evening of Thursday the 10th.  Email me if you’d go, and then we’ll figure out details.</p>



<p>The <a href="https://www.congress.gov/bill/115th-congress/house-bill/6227/text">National Quantum Initiative Act</a> is now law.  Seeing the photos of Trump signing it, I felt … well, whatever emotions you might imagine I felt.</p>



<p>Frank Verstraete asked me to announce that the University of Vienna is seeking a full professor in quantum algorithms; <a href="https://personalwesen.univie.ac.at/jobs-recruiting/professuren/detail-seite/news/quantum-algorithms-1/">see here</a> for details.</p></div>
    </content>
    <updated>2018-12-27T08:35:15Z</updated>
    <published>2018-12-27T08:35:15Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2018-12-31T02:04:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2018/212</id>
    <link href="https://eccc.weizmann.ac.il/report/2018/212" rel="alternate" type="text/html"/>
    <title>TR18-212 |  Constructing Faithful Homomorphisms over Fields of Finite Characteristic | 

	Prerona Chatterjee, 

	Ramprasad Saptharishi</title>
    <summary>We study the question of algebraic rank or transcendence degree preserving homomorphisms over finite fields. This concept was first introduced by Beecken, Mittmann and Saxena (Information and Computing, 2013), and exploited by them, and Agrawal, Saha, Saptharishi and Saxena (Journal of Computing, 2016) to design algebraic independence based identity tests using the Jacobian criterion over characteristic zero fields. An analogue of such constructions over finite characteristic fields was unknown due to the failure of the Jacobian criterion over finite characteristic fields.
Building on a recent criterion of Pandey, Sinhababu and Saxena (MFCS, 2016), we construct explicit faithful maps for some natural classes of polynomials in the positive characteristic field setting, when a certain parameter called the inseparable degree of the underlying polynomials is bounded (this parameter is always 1 in fields of characteristic zero). This presents the first generalisation of some of the results of Beecken et al. and Agrawal et al. in the positive characteristic setting.
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-26T14:56:28Z</updated>
    <published>2018-12-26T14:56:28Z</published>
    <source>
      <id>https://example.com/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://example.com/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2018-12-31T12:22:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16645</id>
    <link href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/" rel="alternate" type="text/html"/>
    <title>Amazing: Karim Adiprasito proved the g-conjecture for spheres!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Karim in his youth with a fan Congratulations, Karim! Update: Here is the link to the paper From the arXive, Dec 26, 2018. (Link will be added tomorrow.) COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY by Karim Adiprasito Abstract: Consider a simplicial complex … <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">Continue reading <span class="meta-nav">→</span></a></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg"><img alt="" class="alignnone size-full wp-image-12390" height="853" src="https://gilkalai.files.wordpress.com/2015/01/gilkarim.jpg?w=640&amp;h=853" width="640"/></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Karim in his youth with a fan</span></p>
<p>Congratulations, Karim!</p>
<p><strong>Update</strong>: <a href="https://arxiv.org/abs/1812.10454">Here is the link to the paper</a></p>
<p><em>From the arXive, Dec 26, 2018. (Link will be added tomorrow.)</em></p>
<p>COMBINATORIAL LEFSCHETZ THEOREMS BEYOND POSITIVITY</p>
<p>by Karim Adiprasito</p>
<p><strong>Abstract:</strong> Consider a simplicial complex that allows for an embedding into <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. How many faces of dimension <img alt="d/2" class="latex" src="https://s0.wp.com/latex.php?latex=d%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d/2"/> or higher can it have? How dense can they be?</p>
<p>This basic question goes back to Descartes. Using it and other fundamental combinatorial<br/>
problems, we will introduce a version of the Kähler package beyond positivity,<br/>
allowing us to prove the Lefschetz theorem for toric varieties even when the ample<br/>
cone is empty. A particular focus lies on replacing the Hodge-Riemann relations by a<br/>
non-degeneracy relation at torus-invariant subspaces, allowing us to state and prove a<br/>
generalization of the theorems of Hall and Laman in the setting of toric varieties. Of<br/>
the many applications, we highlight two main applications, one because it is the most<br/>
well-known, the other because it provided the most guiding light.</p>
<p>(1) We fully characterize the possible face numbers of simplicial spheres, resolving the<br/>
so called <em>g</em>-conjecture of McMullen in full generality and generalizing Stanley’s<br/>
earlier proof for simplicial polytopes.</p>
<p>(2) We prove that for a simplicial complex <em>K</em> that embeds into <img alt="\mathbb R^{2d}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5E%7B2d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^{2d}"/>, the number of <em>d</em>-dimensional simplices exceeds the number of <em>(d − 1)</em>-dimensional simplices by a factor of at most <em>d + 2</em>. This generalizes a result of Descartes, and resolves the Grünbaum-Kalai-Sarkaria conjecture.</p>
<p>_______</p>
<p>(GK:) A few further comments. Probably the <em>g</em>-conjecture for spheres is the single problem I knock my head against the most. It is great to see it settled and it is even greater to see it settled by my friend and colleague Karim Adiprasito.</p>
<p>To the three ingredients of the standard conjectures (See also the <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">previous post</a>), Poincare duality <strong>(PD</strong>), Hard Lefschetz (<strong>HL</strong>) and Hodge-Riemann (<strong>HR</strong>), Karim adds the <strong>Hall-Laman relations</strong>. Very roughly, the Hall-Laman relations  substitute<strong> (HR)</strong> and apply genericity (rather than definiteness) toward <strong>(HL)</strong>.</p>
<p>(We still need a good acronym for Hall-Laman, maybe <strong>(AHL)</strong>.)</p>
<p>One very nice feature of Karim’s proof is that <strong>vertex decomposable</strong> spheres play a special role in the path toward the proof. Those were introduced by Provan and Billera in the context of the Hirsch conjecture.</p>
<p>We have devoted <a href="https://gilkalai.wordpress.com/tag/g-conjecture/">plenty of posts</a> to the <em>g</em>-conjecture for spheres, and mentioned it in <a href="https://gilkalai.wordpress.com/page/2/?s=g-conjecture">even more posts</a>.  For an introduction to the conjecture see <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">Eran Nevo introductory post</a>, and the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/" rel="bookmark">How the g-Conjecture Came About</a>. There is also plenty left to be done <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">beyond the g-conjecture</a>.</p>
<p><span style="color: #0000ff;">Merry X-mas and Happy new year 2019 to all our readers.</span></p></div>
    </content>
    <updated>2018-12-25T14:38:23Z</updated>
    <published>2018-12-25T14:38:23Z</published>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="g-conjecture"/>
    <category term="Karim Adiprasito"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2018-12-31T12:21:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16429</id>
    <link href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/" rel="alternate" type="text/html"/>
    <title>ICM 2018 Rio (4): Huh; Balog &amp; Morris; Wormald</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">  This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures … <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/">Continue reading <span class="meta-nav">→</span></a></div>
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p>This is my fourth report from ICM2018. (I plan one more.)  As I already mentioned, Combinatorics  was very nicely represented at ICM2018.  The combinatorics session itself was great, and there were quite a few other sessions and other lectures related to combinatorics. I also met quite a few combinatorialists. As I mentioned in my <a href="https://gilkalai.wordpress.com/2012/11/17/a-few-mathematical-snapshots-from-india-icm2010/">ICM 2010 post</a>, one thing that I enjoyed was to unexpectedly meet some old friends and this also happened in Rio (maybe a little less compared to Hyderabad as I learned to expect the unexpected). I also had an irrational expectation to unexpectedly meet the <em>same</em> people that I met unexpectedly in India. It was a pleasure meeting  Tadeusz Januszkiewicz again   but I was irrationally disappointed not to bump again into <a href="http://www-ma4.upc.edu/~oserra">Oriol Serra</a> and Anna Llado whom I had met  by surprise in Hyderabad.</p>
<p>This post will be about the Monday afternoon Session in combinatorics. Let me mention that the <a href="https://www.youtube.com/channel/UCnMLdlOoLICBNcEzjMLOc7w">ICM 2018 You Tube channel</a> now contains high quality videos for plenary and invited talks (as well as discussion panels, public lectures, and various other activities). This is a valuable resource! Here is the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmVE7DUBxr4CFu4TNhiJM8Hj">combinatorics session playlist</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWQ9pIGF1ObG4Ag472sg2hm">CS session</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmXn3FrOaMN7ZVNqsY_fWDHw">probability and statistics</a> session, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmW5F1S9OGR6esa9XpTOTq6e">plenary lectures</a>, and the <a href="https://www.youtube.com/playlist?list=PLOrjUJw2wOmWTsHKdFtIP7H2zsvwI0Uq4">public lectures</a>. Also, here is the most recent version of my ICM paper <a href="https://gilkalai.files.wordpress.com/2018/12/icm-draft-Dec-2018.pdf">THREE PUZZLES ON MATHEMATICS, COMPUTATION, AND GAMES</a>. Last minute corrections and comments are most welcome.</p>
<h1>Monday’s afternoon combinatorics</h1>
<p>The Monday afternoon combinatorics session featured three lectures that knocked my socks off. The talks were great and I was in a perfect position to enjoy them as I knew something about the problems and some related results  and yet each lecture surprised me.  The three talks were <span class="watch-title" dir="ltr" id="eow-title" title="Combinatorial applications of the Hodge&#x2013;Riemann relations &#x2013; June Huh &#x2013; ICM2018"><a href="https://youtu.be/ceGEZdjnxRw">Combinatorial applications of the Hodge–Riemann relations</a> </span>by June Huh, <span class="watch-title" dir="ltr" title="The method of hypergraph containers &#x2013; J&#xF3;zsef Balogh &amp; Robert Morris &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> by József Balogh &amp; Robert Morris,  </span><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a> by Nicholas Wormald. Bella Bollobas chaired the session and gave a very nice and thoughtful introduction to each of the four speakers.</span></p>
<p><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"> </span></p>
<h2>June Huh, and the Lefschetz package in combinatorics</h2>
<p/>
<blockquote><p><strong><span style="color: #ff0000;">June Huh: The standard conjectures are both ubiquitous and fundamental</span></strong></p></blockquote>
<p class="watch-title-container"><a href="https://youtu.be/ceGEZdjnxRw"><span class="watch-title" dir="ltr" id="eow-title" title="Combinatorial applications of the Hodge&#x2013;Riemann relations &#x2013; June Huh &#x2013; ICM2018">Combinatorial applications of the Hodge–Riemann relations</span></a></p>
<p>June Huh talked about a mysterious package of conjectures (PD), (HL) and (HR), referred to as the standard conjectures,  for certain algebras associated with geometric and combinatorial objects. PD stands for the Poincare Duality, and it asserts that certain vector spaces <img alt="A_i" class="latex" src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i"/> and <img alt="A_{d-i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{d-i}"/> are dual. HD stands for Hard Lefschetz and it asserts that certain linear maps <img alt="\phi_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi_k"/> from <img alt="A_k" class="latex" src="https://s0.wp.com/latex.php?latex=A_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k"/> to <img alt="A_k+1" class="latex" src="https://s0.wp.com/latex.php?latex=A_k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_k+1"/>  have the property that their composition from <img alt="A_i" class="latex" src="https://s0.wp.com/latex.php?latex=A_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i"/> all the way to <img alt="A_{d-i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bd-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{d-i}"/> is an injection. (HR) stands for Hodge Riemann relations. (PD) and (HD) imply that a certain bilinear form  is nondegenerate and (HR) is a stronger statement that this form is definite!</p>
<p>June started with some startling applications of the Hard-Lefschetz theorem in combinatorics pioneered by Stanley. He then mentioned a startling new application with Wang: Consider <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points spanning a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional space.  Let <img alt="w_i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_i"/> be the number of flats of dimension <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> spanned by the point.  Motzkin  conjectured in 1936 and proved over the reals that  <img alt="w_1 \le w_d" class="latex" src="https://s0.wp.com/latex.php?latex=w_1+%5Cle+w_d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_1 \le w_d"/>. The planar case follows from the classic Erdos deBruijn theorem. Hu and Wang used {HL} to prove <img alt="w_i \le w_d-i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i+%5Cle+w_d-i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_i \le w_d-i"/>, <img alt="i \le [d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cle+%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \le [d/2]"/> which was conjectured by Dowling and Wilson.</p>
<p>Next came applications of (HR), starting with Huh’s proof of the log concavity of coefficients of chromatic polynomials for graphs (Read conjecture ) and the far-reaching extension by Adiprasito-Huh-Kats to general matroids (Rota’s conjecture). We mentioned the Adiprasito-Huh-Katz solution of the Rota-Heron conjecture in <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/">the previous post</a> and in <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">this one</a>.</p>
<p>Here is the link to the ICM paper by June Huh: <a href="https://arxiv.org/abs/1711.11176">Combinatorial applications of the Hodge-Riemann relations</a>.</p>
<p> </p>
<h2>József Balogh and Rob Morris and the container method</h2>
<p/>
<p><span class="watch-title" dir="ltr" title="The method of hypergraph containers &#x2013; J&#xF3;zsef Balogh &amp; Robert Morris &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=y1zH5Hq24OA">The method of hypergraph containers</a> </span></p>
<p>The container theorem for hypergraphs is one of the most important tools in extremal combinatorics with many applications also to random graphs and hypergraphs, additive combinatorics, discrete geometry, and more.</p>
<p>Rob Morris explained the container theorem for triangle-free graphs. It asserts that there is a collection <img alt="\cal C" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cal C"/> of graphs on <img alt="n vertices" class="latex" src="https://s0.wp.com/latex.php?latex=n+vertices&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n vertices"/> with the following three properties:</p>
<p>(1) Every graph in the collection contains <img alt="o(n^3)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5E3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="o(n^3)"/> triangles,</p>
<p>(2) The number of graphs in the collection is <img alt="n^{C \cdot 3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7BC+%5Ccdot+3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{C \cdot 3/2}"/>,</p>
<p>(3) Each triangle free graph is contained in a graph in the collection.</p>
<p>Rob explained the origins of this theorem, how it follows from a container theorem for 3-uniform hypergraphs,   and how the later extends to the very general and important container theorem for <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-uniform hypergraphs that was achieved in 2012 independently by Saxton and Thomason (Here is the link to <a href="https://arxiv.org/abs/1204.6595">their paper</a>), and by Balogh, Morris, and Samotij (Here is a link to <a href="https://arxiv.org/abs/1204.6530">their paper</a>).</p>
<p>Jozsef Balogh described two consequences of the container theorem to additive combinatorics and to discrete geometry. Let me describe the result in discrete geometry by Balogh and Solymosi. The (4,3) problem ask for the size $\alpha (n)$ of the largest subset of points in general position (no three on a line) that can always be found in a planar configuration of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points with the property that no four points lie on a line. The container method is used to show (surprisingly!) that <img alt="\alpha(n)=n^{5/6+o(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%28n%29%3Dn%5E%7B5%2F6%2Bo%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha(n)=n^{5/6+o(1)}"/> .</p>
<p>For a recent beautiful application to <img alt="(p,q)" class="latex" src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(p,q)"/>-Helly type theorems see <a href="https://arxiv.org/abs/1809.06451">A new lower bound on Hadwiger-Debrunner numbers in the plane</a> by Chaya Keller and Shakhar Smorodinsky.</p>
<p>Here is a link to the ICM survey paper: <a href="https://arxiv.org/abs/1801.04584">The method of hypergraph containers</a>, by József Balogh, Robert Morris, and Wojciech Samotij</p>
<p>(In a previous post  <a href="https://gilkalai.wordpress.com/2015/01/20/midrasha-mathematicae-18-in-and-around-combinatorics/" rel="bookmark">Midrasha Mathematicae #18: In And Around Combinatorics, </a>we gave links to a series of lectures Wojiech Samotij: Toward the hypergraph “container” theorem (4 lectures) <a href="https://www.youtube.com/watch?v=SpAyBN4rccU">Video 1, </a><a href="http://youtu.be/N6rP1yUcE0M">video 2</a> <a href="https://www.youtube.com/watch?v=cSFfKhcyN14">video 3</a> <a href="https://www.youtube.com/watch?v=efVlsmiws-I">video 4</a>.)</p>
<h2>Nick Wormald and counting regular graphs.</h2>
<p/>
<p><span class="watch-title" dir="ltr" id="eow-title" title="Asymptotic enumeration of graphs with given degree sequence &#x2013; Nicholas Wormald &#x2013; ICM2018"><a href="https://www.youtube.com/watch?v=fNisXEdZhlQ">Asymptotic enumeration of graphs with given degree sequence</a></span></p>
<p>How many <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-regular graphs are there? This is a very central problem in combinatorics and Nick Wormald was quite interested in its solution ever since his Ph. D.  The talk describes the early history of the problem, the early works by Wormald and McKay from the 90s,  the recent breakthrough by Antia Liebenau and Nick Wormald,  the techniques involved in the old and new proofs and some related results.</p>
<p>A good place to start is with Read’s 1958 formula for the number <img alt="g_3(n)" class="latex" src="https://s0.wp.com/latex.php?latex=g_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_3(n)"/> of 3-regular graphs with n labelled vertices</p>
<p><img alt="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}." class="latex" src="https://s0.wp.com/latex.php?latex=g_3%28n%29+%5Csim+%283n%29%21+e%5E%7B-2%7D%2F%283n%2F2%29%21288%5E%7Bn%2F2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_3(n) \sim (3n)! e^{-2}/(3n/2)!288^{n/2}."/></p>
<p>Following an important model of Bollobas for creating regular graphs, general formulas were developed for low degrees, By McKay, McKay and Wormald, and others that depend on the probability of a random graph in Bollobas’ model to be simple. (See pictures below). Some results were proven also for the high degree regime and McKay and Wormald gave in 1990 and 1997 unified conjectural formulas for the number of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-regular graphs for a wide range of parameters. Moreover these conjectures extend to a large range of vectors of degree sequences.</p>
<p>In 2017 Anita Liebenau and Nick Wormald proved all these conjectures!!! (<a href="https://arxiv.org/abs/1702.08373">Here is a link to the paper</a>.)</p>
<p>The formula for the behavior of the number of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-regular graphs with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is remarkably elegant</p>
<p><img alt="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=e%5E%7B1%2F4%7D%5Csqrt%7B2%7Dd%5Ed%28n-1-d%29%5E%7Bn-1-d%7D%28n-1%29%5E%7B-%28n-1%29%7D%7B%7Bn-1%7D+%5Cchoose+%7Bd%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e^{1/4}\sqrt{2}d^d(n-1-d)^{n-1-d}(n-1)^{-(n-1)}{{n-1} \choose {d}}^n"/>.</p>
<p>The full result is very general, and the method extends further in various directions.</p>
<p>Here is the link to paper: <a href="https://arxiv.org/abs/1702.08373">Asymptotic enumeration of graphs by degree sequence, and the degree sequence of a random graph</a>, by Anita Liebenau and Nick Wormald.</p>
<h3>A bit psychedelic pictures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg"><img alt="" class="alignnone size-medium wp-image-16681" height="225" src="https://gilkalai.files.wordpress.com/2018/12/IMG_2149.jpg?w=300&amp;h=225" width="300"/></a>    <a href="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg"><img alt="" class="alignnone size-medium wp-image-16682" height="225" src="https://gilkalai.files.wordpress.com/2018/12/IMG_2150.jpg?w=300&amp;h=225" width="300"/></a></p>
<p>With Nick Wormald and Yoshi Kohayakawa just before my lecture.</p>
<h2>Some important pictures from the Session</h2>
<h3>Bela Bollobas</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/bela.png"><img alt="" class="alignnone size-full wp-image-16650" src="https://gilkalai.files.wordpress.com/2018/12/bela.png?w=640"/></a></p>
<p><span style="color: #ff0000;">Bela Bollobas served as the session chair</span></p>
<h3>Nick Wormald on enumeration of regular graphs</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W2.png"><img alt="" class="alignnone size-full wp-image-16660" height="406" src="https://gilkalai.files.wordpress.com/2018/12/W2.png?w=640&amp;h=406" width="640"/></a></p>
<p><span style="color: #ff0000;">Read’s formula and Bollobas model.</span></p>
<p><img alt="" class="alignnone size-full wp-image-16661" height="368" src="https://gilkalai.files.wordpress.com/2018/12/W3.png?w=640&amp;h=368" width="640"/></p>
<p><span style="color: #ff0000;">Formulas by McKay and McKay-Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W4.png"><img alt="" class="alignnone size-full wp-image-16662" height="352" src="https://gilkalai.files.wordpress.com/2018/12/W4.png?w=640&amp;h=352" width="640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W5.png"><img alt="" class="alignnone size-full wp-image-16663" height="370" src="https://gilkalai.files.wordpress.com/2018/12/W5.png?w=640&amp;h=370" width="640"/></a></p>
<p><span style="color: #ff0000;">General conjectures (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W6.png"><img alt="" class="alignnone size-full wp-image-16664" height="365" src="https://gilkalai.files.wordpress.com/2018/12/W6.png?w=640&amp;h=365" width="640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W7.png"><img alt="" class="alignnone size-full wp-image-16665" height="353" src="https://gilkalai.files.wordpress.com/2018/12/W7.png?w=640&amp;h=353" width="640"/></a></p>
<p><span style="color: #ff0000;">The Theorem by Liebenau and Wormald (above and below)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/W8.png"><img alt="" class="alignnone size-full wp-image-16666" height="356" src="https://gilkalai.files.wordpress.com/2018/12/W8.png?w=640&amp;h=356" width="640"/></a></p>
<p> </p>
<h3>Balogh and Morris on containers</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers1.png"><img alt="" class="alignnone size-full wp-image-16614" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers1.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The Container theorem for triangle-free graphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers2.png"><img alt="" class="alignnone size-full wp-image-16615" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers2.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem for 3-uniform hypergraphs</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container3.png"><img alt="" class="alignnone size-full wp-image-16616" height="360" src="https://gilkalai.files.wordpress.com/2018/12/container3.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The hypergraph container theorem in full generality.</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container4.png"><img alt="" class="alignnone size-full wp-image-16653" height="371" src="https://gilkalai.files.wordpress.com/2018/12/container4.png?w=640&amp;h=371" width="640"/></a></p>
<p><span style="color: #ff0000;">An application for the number of subsets of integers without k-term arithmetic progressions.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers5.png"><img alt="" class="alignnone size-full wp-image-16654" height="348" src="https://gilkalai.files.wordpress.com/2018/12/containers5.png?w=640&amp;h=348" width="640"/></a></p>
<p><span style="color: #ff0000;">What was known and expected on the (4,3) problem (above) and the new breakthrough (below)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers6.png"><img alt="" class="alignnone size-full wp-image-16655" height="368" src="https://gilkalai.files.wordpress.com/2018/12/containers6.png?w=640&amp;h=368" width="640"/></a></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/containers7.png"><img alt="" class="alignnone size-full wp-image-16656" height="360" src="https://gilkalai.files.wordpress.com/2018/12/containers7.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Applications of the container method</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/container8.png"><img alt="" class="alignnone size-full wp-image-16690" height="332" src="https://gilkalai.files.wordpress.com/2018/12/container8.png?w=640&amp;h=332" width="640"/></a></p>
<h3>June Huh on the standard conjectures</h3>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png"><img alt="" class="alignnone size-full wp-image-16607" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh1.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Five seemingly unrelated mathematical objects</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png"><img alt="" class="alignnone size-full wp-image-16609" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh3.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Poincare duality (PD), Hard Lefschetz (HL), and Hodge Riemann (HR).</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png"><img alt="" class="alignnone size-full wp-image-16610" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm-huh5.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">A 1964 letter from Serre to Grothendieck on young Bombieri</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png"><img alt="" class="alignnone size-full wp-image-16611" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm-huh6.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">The algebraic setting for the standard conjectures. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png"><img alt="" class="alignnone size-full wp-image-16612" height="360" src="https://gilkalai.files.wordpress.com/2018/12/icm2018-huh9.png?w=640&amp;h=360" width="640"/></a></p>
<p><span style="color: #ff0000;">Five cases were the standard conjectures are known and the original open case.</span></p></div>
    </content>
    <updated>2018-12-24T20:00:59Z</updated>
    <published>2018-12-24T20:00:59Z</published>
    <category term="Combinatorics"/>
    <category term="ICM2018"/>
    <category term="Anita Libenau"/>
    <category term="J&#xF3;zef Balogh"/>
    <category term="June Huh"/>
    <category term="Nick Wormald"/>
    <category term="Rob Morris"/>
    <category term="Wojtek Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2018-12-31T12:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7021</id>
    <link href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/" rel="alternate" type="text/html"/>
    <title>Introduction to Quantum Walks</title>
    <summary>author: Beatrice Nash Abstract In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><hr class="wp-block-separator"/>



<p>author: Beatrice Nash</p>



<p>Abstract</p>



<p>In this blog post, we give a broad overview of quantum walks and some quantum walks-based algorithms, including traversal of the glued trees graph, search, and element distinctness [3; 7; 1]. Quantum walks can be viewed as a model for quantum computation, providing an advantage over classical and other non-quantum walks based algorithms for certain applications.</p>



<h1>Continuous time quantum walks</h1>



<p>We begin our discussion of quantum walks by introducing the quantum analog of the continuous random walk. First, we review the behavior of the classical continuous random walk in order to develop the definition of the continuous quantum walk.</p>



<p>Take a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> with vertices <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and edges <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/>. The adjacency matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is defined as follows:</p>



<p><img alt="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{i,j} = \begin{cases} 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}"/></p>



<p>And the Laplacian <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> is given by:</p>



<p><img alt="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%2Cj%7D+%3D+%5Cbegin%7Bcases%7D+-%5Ctext%7Bdegree%7D%28i%29+%5Cquad+%26%5Ctext%7Bif+++%7D++i+%3D+j+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+++%7D+%28i%2Cj%29+%5Cin+E+%5C%5C+0+%5Cquad+%26%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i,j} = \begin{cases} -\text{degree}(i) \quad &amp;\text{if   }  i = j \\ 1 \quad &amp;\text{if   } (i,j) \in E \\ 0 \quad &amp;\text{otherwise}. \end{cases}"/></p>



<p>The Laplacian determines the behavior of the classical continuous random walk, which is described by a length <img alt="|V|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CV%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|V|"/> vector of probabilities, <strong>p</strong>(t). The <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th entry of <strong>p</strong>(t) represents the probability of being at vertex <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. <strong>p</strong>(t) is given by the following differential equation:</p>



<p><img alt="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Ctext%7Bp%7D_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Ctext%7Bp%7D_%7Bj%7D%28%5Ctext%7Bt%7D%29%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \frac{\text{d}}{\text{dt}} \text{p}_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \text{p}_{j}(\text{t}),\end{aligned}"/></p>



<p>which gives the solution <img alt="\textbf{p}(t) = e^{Lt}\textbf{p}(0)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7Bp%7D%28t%29+%3D+e%5E%7BLt%7D%5Ctextbf%7Bp%7D%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textbf{p}(t) = e^{Lt}\textbf{p}(0)"/>.</p>



<p>Recalling the Schrödinger equation <img alt="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cleft%7C%5Cpsi%5Cright%3E%3D+H+%5Cleft%7C%5Cpsi%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \frac{\text{d}}{\text{dt}} \left|\psi\right&gt;= H \left|\psi\right&gt;"/>, one can see that by inserting a factor of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> on the left hand side of the equation for <strong>p</strong>(t) above, the Laplacian can be treated as a Hamiltonian. One can see that the Laplacian preserves the normalization of the state of the system. Then, the solution to the differential equation:</p>



<p><img alt="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+i+%5Cfrac%7B%5Ctext%7Bd%7D%7D%7B%5Ctext%7Bdt%7D%7D+%5Cpsi_%7Bi%7D%28%5Ctext%7Bt%7D%29+%3D+%5Cunderset%7B%28i%2Cj%29+%5Cin+E%7D%7B%5Csum%7D+L_%7Bi%2Cj%7D+%5Cpsi_%7Bj%7D%28%5Ctext%7Bt%7D%29%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} i \frac{\text{d}}{\text{dt}} \psi_{i}(\text{t}) = \underset{(i,j) \in E}{\sum} L_{i,j} \psi_{j}(\text{t})\end{aligned}"/>,</p>



<p>which is <img alt="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%28t%29%5Cright%3E+%3D+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(t)\right&gt; = e^{-iLt} \left|\psi(0)\right&gt;"/>, determines the behavior of the quantum analog of the continuous random walk defined previously. A general quantum walk does not necessarily have to be defined by the Laplacian; it can be defined by any operator which “respects the structure of the graph,” that is, only allows transitions to between neighboring vertices in the graph or remain stationary [7]. To get a sense of how the behavior of the quantum walk differs from the classical one, we first discuss the example of the continuous time quantum walk on the line, before moving on to the discrete case.</p>



<h2>Continuous time quantum walk on the line</h2>



<p>An important example of the continuous time quantum walk is that defined on the infinite line. The eigenstates of the Laplacian operator for the graph representing the infinite line are the momentum states with eigenvalues <img alt="2(\text{cos}(p) - 1)" class="latex" src="https://s0.wp.com/latex.php?latex=2%28%5Ctext%7Bcos%7D%28p%29+-+1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2(\text{cos}(p) - 1)"/>, for <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> in range <img alt="[-\pi,\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-%5Cpi%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-\pi,\pi]"/>. This can be seen by representing the momentum states in terms of the position states and applying the Laplacian operator:</p>



<p><img alt="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+L%5Cleft%7Cp%5Cright%3E+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+e%5E%7Bipx%7D+%5Cleft%7Cx%2B1%5Cright%3E%2B+e%5E%7Bipx%7D+%5Cleft%7Cx-1%5Cright%3E+-+2e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+%5Cunderset%7Bx%7D%7B%5Csum%7D+%28e%5E%7Bip%7D+%2B+e%5E%7B-ip%7D+-+2%29+e%5E%7Bipx%7D+%5Cleft%7Cx%5Cright%3E+%5C%5C+%26%3D+2%28%5Ctext%7Bcos%7D%28p%29+-+1%29+%5Cleft%7Cp%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x\right&gt; \\ L\left|p\right&gt; &amp;= \underset{x}{\sum} e^{ipx} \left|x+1\right&gt;+ e^{ipx} \left|x-1\right&gt; - 2e^{ipx} \left|x\right&gt; \\ &amp;= \underset{x}{\sum} (e^{ip} + e^{-ip} - 2) e^{ipx} \left|x\right&gt; \\ &amp;= 2(\text{cos}(p) - 1) \left|p\right&gt;.\end{aligned}"/></p>



<p>Hence the probability distribution at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, <img alt="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%7C+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x,t) = |\left&lt; x\right| e^{-iLt} \left|\psi(0)\right&gt; | ^{2}"/>, with initial position <img alt="\left|\psi(0)\right&gt; = \left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \left|0\right&gt;"/> is given by:</p>



<p><img alt="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cleft%3C+x%5Cright%7C+e%5E%7B-iLt%7D+%5Cleft%7C0%5Cright%3E+%7C+%5E%7B2%7D+%26%3D++%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+%5Cleft%3C+x%7Cp%5Cright%3E+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%5Cbigg%7C+%5Cfrac%7B1%7D%7B2%5Cpi%7D+%5Cint_%7B-%5Cpi%7D%5E%7B%5Cpi%7D+e%5E%7B-2it%28%5Ctext%7Bcos%7Dp+-+1%29%7D+e%5E%7Bipx%7D+%5Ctext%7Bd%7Dp+%5Cbigg%7C%5E%7B2%7D+%5C%5C+%26%3D+%7C+J_%7Bx%7D%282t%29+%7C%5E%7B2%7D.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\left&lt; x\right| e^{-iLt} \left|0\right&gt; | ^{2} &amp;=  \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} \left&lt; x|p\right&gt; \text{d}p \bigg|^{2} \\ &amp;= \bigg| \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-2it(\text{cos}p - 1)} e^{ipx} \text{d}p \bigg|^{2} \\ &amp;= | J_{x}(2t) |^{2}.\end{aligned}"/></p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7071" src="https://windowsontheory.files.wordpress.com/2018/12/quantum-1.png?w=451" width="451"/>Figure 1.a) Probability distribution for continuous time quantum walk on the infinite line at time <img alt="t = 80" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+80&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 80"/>.</figure>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7073" height="300" src="https://windowsontheory.files.wordpress.com/2018/12/classical-1.png?w=451&amp;h=300" width="451"/><br/>Figure 1.b) Approximate probability<br/> distribution of the continuous time random walk on the infinite line at<br/> time <img alt="t=30" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=30"/>.<br/></figure>



<p>While the probability distribution for the classical continuous time<br/> random walk on the same graph approaches, for large <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, <img alt="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B4%5Cpi+t%7D%7D+e%5E%7B%5Cfrac%7B-x%5E%7B2%7D%7D%7B4t%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{4\pi t}} e^{\frac{-x^{2}}{4t}}"/>, or a Gaussian of width <img alt="2\sqrt{t}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\sqrt{t}"/>. One can see that the quantum walk has its largest peaks at the extrema, with oscillations in between that decrease in amplitude as one approaches the starting position at <img alt="x=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=0"/>. This is due to the destructive interference between states of different phases that does not occur in the classical case. The probability distribution of the classical walk, on the other hand, has no oscillations and instead a single peak centered at <img alt="x=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=0"/>, which widens and flattens as <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> increases.</p>



<h2>Walk on the glued trees graph</h2>



<p>A <em>glued tree</em> is a graph obtained by taking two binary trees of equal height and connecting each of the leaves of one of the trees to exactly two leaves of the other tree so that each node that was a leaf in one of the original trees now has degree exactly <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>. An example of such a graph is shown in Figure 2.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-7077" src="https://windowsontheory.files.wordpress.com/2018/12/glued-1.png?w=1024"/>Figure 2: An example of a glued tree graph, from [2].</figure>



<p>The time for the quantum walk on this graph to reach the right root from the left one is exponentially faster than in the classical case. Consider the classical random walk on this graph. While in the left tree, the probability of transitioning to a node in the level one to the right is twice that of transitioning to a node in the level one to the left. However, while in the right tree, the opposite is true. Therefore, one can see that in the middle of the graph, the walk will get lost, as, locally, there is no way to determine which node is part of which tree. It will instead get stuck in the cycles of identical nodes and will have exponentially small probability of reaching the right node.</p>



<p>To construct a continuous time quantum walk on this graph, we consider the graph in terms of <em>columns</em>. One can visualize the columns of Figure 2 as consisting of all the nodes equidistant from the entrance and exit nodes. If each tree is height <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, then we label the columns <img alt="0,1,\text{...},2n,2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Ctext%7B...%7D%2C2n%2C2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0,1,\text{...},2n,2n+1"/>, where column <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> contains the nodes with shortest path of length <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> from the leftmost root node. We describe the state of each column as a superposition of the states of each node in that column. The number of nodes in column <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, <img alt="N_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=N_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N_{i}"/>, will be <img alt="2^{i}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{i}"/> for <img alt="i \in [0,n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B0%2Cn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [0,n]"/> and <img alt="2^{2n+1-i}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%2B1-i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2n+1-i}"/> for <img alt="i \in [n+1,2n+1]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B1%2C2n%2B1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n+1,2n+1]"/>. Then, we can define the state <img alt="\left|\text{col} \; i\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\text{col} \; i\right&gt;"/> as:</p>



<p><img alt="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cunderset%7Bj+%5Cin+%5Ctext%7Bcol%7D+%5C%3B+i%7D%7B%5Csum%7D+%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\text{col} \; i\right&gt; = \frac{1}{\sqrt{N_{i}}} \underset{j \in \text{col} \; i}{\sum} \left|j\right&gt;.\end{aligned}"/></p>



<p>The factor of <img alt="\frac{1}{\sqrt{N_{i}}} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{N_{i}}} "/>latex  ensures that the state is normalized. Since the adjacency matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of the glued tree is Hermitian, then we can treat <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> as the Hamiltonian of the system determining the behavior of the quantum walk. By acting on this state with the adjacency matrix operator <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>, we get the result (for <img alt="i \in [1,n-1]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5B1%2Cn-1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [1,n-1]"/>):</p>



<p><img alt="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%5Cright%3E++%26%3D+2%5Cfrac%7B%5Csqrt%7BN_%7Bi-1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Cfrac%7B%5Csqrt%7BN_%7Bi%2B1%7D%7D%7D%7B%5Csqrt%7BN_%7Bi%7D%7D%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E+%5C%5C+%26%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i-1%5Cright%3E+%2B+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+i%2B1%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} A\left|\text{col} \; i\right&gt;  &amp;= 2\frac{\sqrt{N_{i-1}}}{\sqrt{N_{i}}} \left|\text{col} \; i-1\right&gt; + \frac{\sqrt{N_{i+1}}}{\sqrt{N_{i}}} \left|\text{col} \; i+1\right&gt; \\ &amp;= \sqrt{2} \left|\text{col} \; i-1\right&gt; + \sqrt{2} \left|\text{col} \; i+1\right&gt;.\end{aligned}"/><br/></p>



<p>Then for <img alt="i \in [n+2,2n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%2B2%2C2n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n+2,2n]"/>, we get the same result, because of symmetry.<br/></p>



<p>For <img alt="i = n" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = n"/>:</p>



<p><img alt="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+A%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E+%3D+%5Csqrt%7B2%7D+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3Bn-1%5Cright%3E+%2B+2+%5Cleft%7C%5Ctext%7Bcol%7D+%5C%3B+n%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} A\left|\text{col} \; n\right&gt; = \sqrt{2} \left|\text{col} \;n-1\right&gt; + 2 \left|\text{col} \; n\right&gt;.\end{aligned}"/></p>



<p>The case of <img alt="i = n+1" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = n+1"/> is symmetric. One can see that the walk on this graph is equivalent to the quantum walk on the finite line with nodes corresponding to the columns. All of the edges, excluding that between columns <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/>, have weight <img alt="\sqrt{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{2}"/>. The edge between column <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/> has weight <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>.</p>



<p>The probability distribution of the quantum walk on this line can be roughly approximated using the infinite line. In the case of the infinite line, the probability distribution can be seen as a wave propagating with speed linear in the time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. Thus, in time linear in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, the probability that the state is measured at distance <img alt="2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2n+1"/> from the starting state is <img alt="\frac{1}{\text{poly} \; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D+%5C%3B+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\text{poly} \; n}"/>. In [3] it is shown that the fact that the line is finite and has a single differently weighted edge from the others (that between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="n+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n+1"/>) does not change the fact that in polynomial time, the quantum walk will travel from the left root node to the right one, although in this case there is no limiting distribution as the peaks oscillate. This was the first result that gives an exponential speed up over the classical case using quantum walks.</p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7082" height="291" src="https://windowsontheory.files.wordpress.com/2018/12/glued-tree-1.png?w=451&amp;h=291" width="451"/>Figure 3: Although the quantum walk on the glued trees graph does not have a limiting distribution, this is an example of the resulting probability distribution at time <img alt="t=30" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D30&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=30"/> for a <img alt="n=4" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=4"/> column glued tree graph.  The x-axis corresponds to the columns.  One can see that the probability of being at the columns at either extremes is significantly larger than that of being in the middle of the graph. In contrast, the classical random walk takes exponential time to ever reach the exit root node.</figure>



<h1>Discrete time quantum walks</h1>



<p>In this section, we will first give an introduction to the discrete quantum walk, including the discrete quantum walk on the line and the Markov chain quantum walk, as defined in [7]. Next, we discuss how Grover search can be viewed as a quantum walk algorithm, which leads us into Ambainis’s quantum-walks based algorithm from [1] for the element distinctness problem, which gives a speed up over classical and other quantum non-walks based algorithms.</p>



<p>The discrete time quantum walk is defined by two operators: the <em>coin flip</em> operator, and the <em>shift</em> operator. The coin flip operator <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> determines the direction of the walk, while the shift operator <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> makes the transition to the new state conditioned on the result of the coin flip. The Hilbert space governing the walk is <img alt="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D%7BC%7D+%5Cotimes+%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} = \mathcal{H}{C} \otimes \mathcal{H}{S}"/>, where <img alt="\mathcal{H}{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}{C}"/> corresponds to the space associated with the result of the coin flip operator, and <img alt="\mathcal{H}{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%7BS%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}{S}"/> corresponds to the locations in the graph on which the walk is defined.</p>



<p>For example, consider the discrete time walk on the infinite line. Since there are two possible directions (left or right), then the Hilbert space associated with the coin flip operator is two dimensional. In the unbiased case, the coin flip is the Hadamard operator,</p>



<p><img alt="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bbmatrix%7D+1+%26+1+%5C%5C+1+%26+-1++%5Cend%7Bbmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1  \end{bmatrix},\end{aligned}"/></p>



<p>and shift operator that produces the transition from state <img alt="\left|j\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j\right&gt;"/> to <img alt="\left|j+1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j+1\right&gt;"/> or <img alt="\left|j-1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cj-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|j-1\right&gt;"/>,<br/> conditioned on the result of the coin flip, is <img alt="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|" class="latex" src="https://s0.wp.com/latex.php?latex=S+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%3C+0%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj%2B1%5Cright%3E+%5Cleft%3C+j%5Cright%7C+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%3C+1%5Cright%7C+%5Cotimes+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Cleft%7Cj+-+1%5Cright%3E+%5Cleft%3C+j%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S = \left|0\right&gt;\left&lt; 0\right| \otimes \underset{j}{\sum} \left|j+1\right&gt; \left&lt; j\right| + \left|1\right&gt;\left&lt; 1\right| \otimes \underset{j}{\sum} \left|j - 1\right&gt; \left&lt; j\right|"/>.</p>



<p>Each step of the walk is determined by an application of the unitary<br/> operator <img alt="U = S \cdot (H \otimes I)" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+S+%5Ccdot+%28H+%5Cotimes+I%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = S \cdot (H \otimes I)"/>. If the walk starts at position<br/> <img alt="\left|x\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x\right&gt;"/>, then measuring the state after one application of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> gives <img alt="\left|x+1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx%2B1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x+1\right&gt;"/> with probability <img alt="\frac{1}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2}"/> and <img alt="\left|x-1\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Cx-1%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|x-1\right&gt;"/> with probability <img alt="\frac{1}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2}"/>. This is exactly the same as the case of the classical random walk on the infinite line; the difference between the two walks becomes apparent after a few steps.</p>



<p>For example, the result of the walk starting at state <img alt="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \left|0\right&gt;\left|0\right&gt;"/> after 4 steps gives:</p>



<p><img alt="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+3%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E-%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( \left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(\left|0\right&gt;\left|3\right&gt; + \left|1\right&gt;\left|1\right&gt; + 2\left|0\right&gt;\left|1\right&gt; -\left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (\left|0\right&gt;\left|4\right&gt; + \left|1\right&gt;\left|2\right&gt; + 3\left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; -\left|0\right&gt;\left|0\right&gt; -\left|1\right&gt;\left|-2\right&gt; +\left|0\right&gt;\left|-2\right&gt;-\left|1\right&gt;\left|-4\right&gt;).\end{aligned}"/></p>



<p>One can see that the distribution is becoming increasingly skewed<br/> towards the right, while in the classical case the distribution will be<br/> symmetric around the starting position. This is due to the destructive<br/> interference discussed earlier. The distribution after <img alt="t = 20" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 20"/> time<br/> steps is shown in Figure 4.</p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-7090" height="291" src="https://windowsontheory.files.wordpress.com/2018/12/discrete.png?w=451&amp;h=291" width="451"/>Figure 4: Distribution at time <img alt="t = 20" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = 20"/>, with <img alt="20" class="latex" src="https://s0.wp.com/latex.php?latex=20&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="20"/> on the x-axis corresponding to position <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>.</figure>



<p>Now, consider the walk starting at state <img alt="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = -\left|1\right&gt;\left|0\right&gt;"/>:</p>



<p><img alt="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cleft%7C%5Cpsi%281%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%282%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28+-%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%283%29%5Cright%3E+%26%3D+%5Cfrac%7B1%7D%7B2%5Csqrt%7B2%7D%7D%5Cleft%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C3%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C1%5Cright%3E+%2B+2%5Cleft%7C1%5Cright%3E%5Cleft%7C-1%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C-1%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C-3%5Cright%3E+%5Cright%29+%5C%5C+%5Cleft%7C%5Cpsi%284%29%5Cright%3E+%26%3D++%5Cfrac%7B1%7D%7B4%7D+%28-%5Cleft%7C0%5Cright%3E%5Cleft%7C4%5Cright%3E+-%5Cleft%7C1%5Cright%3E%5Cleft%7C2%5Cright%3E+-+%5Cleft%7C0%5Cright%3E%5Cleft%7C2%5Cright%3E+%2B+%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E+-3%5Cleft%7C1%5Cright%3E%5Cleft%7C-2%5Cright%3E+%2B+%5Cleft%7C0%5Cright%3E%5Cleft%7C-2%5Cright%3E+-+%5Cleft%7C1%5Cright%3E%5Cleft%7C-4%5Cright%3E%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\left|\psi(1)\right&gt; &amp;= \frac{1}{\sqrt{2}}\left( -\left|0\right&gt;\left|1\right&gt; + \left|1\right&gt;\left|-1\right&gt; \right) \\ \left|\psi(2)\right&gt; &amp;= \frac{1}{2}\left( -\left|0\right&gt;\left|2\right&gt; - \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; - \left|1\right&gt;\left|-2\right&gt; \right) \\ \left|\psi(3)\right&gt; &amp;= \frac{1}{2\sqrt{2}}\left(-\left|0\right&gt;\left|3\right&gt; - \left|1\right&gt;\left|1\right&gt; + 2\left|1\right&gt;\left|-1\right&gt; - \left|0\right&gt;\left|-1\right&gt; + \left|1\right&gt;\left|-3\right&gt; \right) \\ \left|\psi(4)\right&gt; &amp;=  \frac{1}{4} (-\left|0\right&gt;\left|4\right&gt; -\left|1\right&gt;\left|2\right&gt; - \left|0\right&gt;\left|2\right&gt; + \left|1\right&gt;\left|0\right&gt; + \left|0\right&gt;\left|0\right&gt; -3\left|1\right&gt;\left|-2\right&gt; + \left|0\right&gt;\left|-2\right&gt; - \left|1\right&gt;\left|-4\right&gt;).\end{aligned}"/></p>



<p><br/> This distribution given by this walk is the mirror image of the first.<br/> To generate a symmetric distribution, consider the start state <img alt="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%280%29%5Cright%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%5Cleft%7C0%5Cright%3E+-i%5Cleft%7C1%5Cright%3E%29%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi(0)\right&gt; = \frac{1}{\sqrt{2}}(\left|0\right&gt; -i\left|1\right&gt;)\left|0\right&gt;"/>. The resulting distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps will be <img alt="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%2Ct%29+%3D+%5Cfrac%7B1%7D%7B2%7D+p_%7B0%7D%28x%2Ct%29+%2B+%5Cfrac%7B1%7D%7B2%7D+p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x,t) = \frac{1}{2} p_{0}(x,t) + \frac{1}{2} p_{1}(x,t)"/>, where <img alt="p_{0}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}(x,t)"/> is the probability distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps resulting from the start state <img alt="\psi(0) = \left|0\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+%5Cleft%7C0%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi(0) = \left|0\right&gt;\left|0\right&gt;"/> and <img alt="p_{1}(x,t)" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B1%7D%28x%2Ct%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{1}(x,t)"/> is the probability distribution after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps resulting from the start state <img alt="\psi(0) = -\left|1\right&gt;\left|0\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+-%5Cleft%7C1%5Cright%3E%5Cleft%7C0%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi(0) = -\left|1\right&gt;\left|0\right&gt;"/>. The result will be symmetric, with peaks near the extrema, as we saw in the continuous case.</p>



<h2>Markov chain quantum walk</h2>



<p>A reversible, ergodic Markov chain with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> states can be represented by a <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> transition matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> with <img alt="P_{j,i}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7Bj%2Ci%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{j,i}"/> equal to the probability of transitioning from state <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> to state <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="P = P^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=P+%3D+P%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P = P^{*}"/>. Then, <img alt="p_{0}P" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}P"/>, where <img alt="p_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{0}"/> is an initial probability distribution over the states, gives the distribution after one step.<br/>Since <img alt="\sum_{j} P_{i,j} = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bj%7D+P_%7Bi%2Cj%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_{j} P_{i,j} = 1"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is stochastic and thus preserves normalization.</p>



<p>There are multiple ways to define a discrete quantum walk, depending on the properties of the transition matrix and the graph on which it is defined (overview provided in [4]). Here we look at the quantum walk on a Markov chain as given in [2]. For the quantum walk on this graph, we define state <img alt="\left|i\right&gt;\left|j\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|i\right&gt;\left|j\right&gt;"/> as the state that represents currently being at position <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and facing in the direction of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>. Then, we define the state <img alt="\left|\psi_{j}\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi_%7Bj%7D%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi_{j}\right&gt;"/> as a superposition of the states associated with position <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>:</p>



<p><img alt="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E+%3D+%5Cunderset%7Bj%7D%7B%5Csum%7D+%5Csqrt%7BP_%7Bj%2Ci%7D%7D+%5Cleft%7Ci%5Cright%3E%5Cleft%7Cj%5Cright%3E.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left|\psi_{i}\right&gt; = \underset{j}{\sum} \sqrt{P_{j,i}} \left|i\right&gt;\left|j\right&gt;.\end{aligned}"/></p>



<p>The unitary operator,</p>



<p><img alt="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I" class="latex" src="https://s0.wp.com/latex.php?latex=D+%3D+2+%5Cunderset%7Bi%7D%7B%5Csum%7D+%5Cleft%7C%5Cpsi_%7Bi%7D%5Cright%3E%5Cleft%3C+%5Cpsi_%7Bi%7D%5Cright%7C+-+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D = 2 \underset{i}{\sum} \left|\psi_{i}\right&gt;\left&lt; \psi_{i}\right| - I"/>,</p>



<p>acts as a coin flip for the walk on this graph. Since <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is reversible, we can let the shift operator be the unitary <img alt="SWAP" class="latex" src="https://s0.wp.com/latex.php?latex=SWAP&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SWAP"/> operator:</p>



<p><img alt="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|" class="latex" src="https://s0.wp.com/latex.php?latex=SWAP+%3D+%5Cunderset%7Bi%2Cj%7D%7B%5Csum%7D+%5Cleft%7Ci%2Cj%5Cright%3E%5Cleft%3C+j%2Ci%5Cright%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SWAP = \underset{i,j}{\sum} \left|i,j\right&gt;\left&lt; j,i\right|"/>.</p>



<p>A quantum walk can also be defined for a non-reversible Markov chain using a pair of reflection operators (the coin flip operator is an example of a reflection operator). This corresponds to the construction given in [7].</p>



<h2>Search as a quantum walk algorithm</h2>



<p>Given a black box function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and a set of inputs <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> with <img alt="|S| = N" class="latex" src="https://s0.wp.com/latex.php?latex=%7CS%7C+%3D+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|S| = N"/>, say we want to find whether an input <img alt="x \in S" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in S"/> exists for which <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x)"/> equals some output value. We refer to the set of inputs <img alt="M" class="latex" src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M"/> for which this is true as marked. Classically, this requires <img alt="O(N/|M|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%2F%7CM%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N/|M|)"/> queries, for nonempty <img alt="M" class="latex" src="https://s0.wp.com/latex.php?latex=M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M"/>. Using the Grover search algorithm, this problem requires <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/> quantum queries. In this section, we give a quantum walks based algorithm that also solves this problem in <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/> time. If we define a doubly stochastic matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> with uniform transitions, then we can construct a new transition matrix <img alt="P'" class="latex" src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P'"/> from <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> as:</p>



<p><img alt="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7Bi%2Cj%7D%27+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B1%7D%7BN-1%7D+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cnotin+M+%5C%5C+1+%5Cquad+%26%5Ctext%7Bif+%7D+i+%3D+j+%5Ctext%7B+and+%7D+i+%5Cin+M+%5C%5C+0+%5Cquad+%26%5Ctext%7Bif+%7D+i+%5Cneq+j+%5Ctext%7B+and+%7D+i+%5Cin+M.+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{i,j}' = \begin{cases} \frac{1}{N-1} \quad &amp;\text{if } i \neq j \text{ and } i \notin M \\0 \quad &amp;\text{if } i = j \text{ and } i \notin M \\ 1 \quad &amp;\text{if } i = j \text{ and } i \in M \\ 0 \quad &amp;\text{if } i \neq j \text{ and } i \in M. \end{cases}"/></p>



<p>Then, when the state of the first register is unmarked, the operator <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> defined in the previous section acts as a diffusion over its neighbors. When the state in the first register is marked, then <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> will act as the operator <img alt="-I" class="latex" src="https://s0.wp.com/latex.php?latex=-I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-I"/>, and the walk stops, as a marked state has been reached. This requires two queries to the black box function: one to check whether the input is marked, and then another to uncompute. By rearranging the order of the columns in <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> so that the columns corresponding to the non-marked elements come before the columns corresponding to the marked elements, we get:</p>



<p><img alt="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%27+%3D+%5Cbegin%7Bpmatrix%7D+P_%7B0%7D+%26+0+%5C%5C+P_%7B1%7D+%26+I+%5Cend%7Bpmatrix%7D%2C%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} P' = \begin{pmatrix} P_{0} &amp; 0 \\ P_{1} &amp; I \end{pmatrix},\end{aligned}"/></p>



<p>where <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/> gives the transitions between non-marked elements and <img alt="P_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{1}"/> gives the transitions from non-marked to marked elements.</p>



<p>We now look at the hitting time of the classical random walk. Assume<br/> that there is zero probability of starting at a marked vertex. Then, we<br/> can write the starting distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/>, where the last <img alt="|M|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|M|"/> elements of <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/>, corresponding to the marked elements, are zero, as<br/> <img alt="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+%5Cunderset%7B%5Clambda%7D%7B%5Csum%7D+%5Calpha_%7B%5Clambda%7D+%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p = \underset{\lambda}{\sum} \alpha_{\lambda} \left|\lambda\right&gt;"/>, where <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda"/> are the eigenvalues of <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/>, and <img alt="\left|\lambda\right&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Clambda%5Cright%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\lambda\right&gt;"/> are the corresponding eigenvectors, with the last <img alt="|M|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CM%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|M|"/> entries zero. Let <img alt="\lambda^{}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda%5E%7B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda^{}"/> be the principal (largest) eigenvalue. Then, the probability that, after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps, a marked element has not yet been reached will be <img alt="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum+%28P_%7B0%7D%5E%7Bt%7Dp%29_%7Bi%7D+%5Cleq+%5Clambda%5E%7B%2At%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum (P_{0}^{t}p)_{i} \leq \lambda^{*t}"/>. Then, the<br/> probability that a marked element has been reached in that time will be<br/> <img alt="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+1+-+%5Clambda%5E%7Bt%7D+%5Cgeq+1+-+t+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\geq 1 - \lambda^{t} \geq 1 - t \lambda^{*}"/>. Setting<br/> <img alt="t = \frac{1}{1-\lambda^{*}}" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t = \frac{1}{1-\lambda^{*}}"/> gives probability <img alt="\Omega(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega(1)"/> that a marked element will be reached in that time.</p>



<p>The eigenvalues of <img alt="P_{0}" class="latex" src="https://s0.wp.com/latex.php?latex=P_%7B0%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P_{0}"/> will be <img alt="\frac{N-|M|-1}{N-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{N-|M|-1}{N-1}"/> and<br/> <img alt="\frac{-1}{N-|M|-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B-1%7D%7BN-%7CM%7C-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{-1}{N-|M|-1}"/>. Then, the classical hitting time will be:</p>



<p><img alt="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t+%26%3D+%5Cfrac%7B1%7D%7B1-%5Clambda%5E%7B%2A%7D%7D+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B1-%5Cfrac%7BN-%7CM%7C-1%7D%7BN-1%7D%7D+%5C%5C+%26%3D+O%5Cleft%28%5Cfrac%7BN%7D%7B%7CM%7C%7D%5Cright%29.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t &amp;= \frac{1}{1-\lambda^{*}} \\ &amp;= \frac{1}{1-\frac{N-|M|-1}{N-1}} \\ &amp;= O\left(\frac{N}{|M|}\right).\end{aligned}"/></p>



<p>It can be showed that for a walk defined by a Markov chain, the<br/> classical hitting time will be <img alt="O(\frac{1}{\delta \epsilon})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{1}{\delta \epsilon})"/>, where <img alt="\delta = 1 - \lambda^{*}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3D+1+-+%5Clambda%5E%7B%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta = 1 - \lambda^{*}"/>, the <em>spectral gap</em>, and <img alt="\epsilon \leq \frac{|M|}{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cleq+%5Cfrac%7B%7CM%7C%7D%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon \leq \frac{|M|}{N}"/> [2].</p>



<p>Magniez <em>et al</em> proved in [6] that for a reversible, ergodic<br/> Markov chain, the quantum hitting time for a walk on this chain is<br/> within a factor of the square root of the classical hitting time. Since<br/> the walk on this input acts as a walk on a reversible Markov chain until<br/> a marked element is reached, then this is also true for a walk defined<br/> by our transition matrix <img alt="P'" class="latex" src="https://s0.wp.com/latex.php?latex=P%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P'"/>. This arises from the fact that the<br/> spectral gap of the matrix describing the quantum walk corresponding to<br/> stochastic matrix <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is quadratically larger than the spectral gap of<br/> the matrix describing the classical random walk corresponding to <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, the proof of which is given in [2]. Thus, the quantum hitting time<br/> is <img alt="O(\sqrt{N/|M|})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%2F%7CM%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{N/|M|})"/>, which exactly matches the quantum query complexity of Grover search.</p>



<h2>Element distinctness problem</h2>



<p>Now, we describe Ambainis’s algorithm given in [1] for solving<br/> the <em>element distinctness problem</em> in <img alt="O(N^{\frac{2}{3}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{2}{3}})"/> time, which<br/> produces a speed up over the classical algorithm, which requires <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N)"/> queries, and also over other known quantum algorithms that do not make use of quantum walks, which require <img alt="O(N^{\frac{3}{4}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B3%7D%7B4%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{3}{4}})"/> queries. The element distinctness problem is defined as follows: given a function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> on a size <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> set of inputs</p>



<p><img alt="S=\{x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5C%7Bx_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=\{x_{1}"/>,…,<img alt="x_{N}\}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7BN%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{N}\}"/>,</p>



<p>determine whether there exists a pair <img alt="x_{1},\; x_{2} \in S" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2C%5C%3B+x_%7B2%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},\; x_{2} \in S"/> for which <img alt="f(x_{1}) = f(x_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x_%7B1%7D%29+%3D+f%28x_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x_{1}) = f(x_{2})"/>.  As in the search problem defined in the previous section, this is a decision problem; we are not concerned with finding the values of these pairs, only whether at least one exists.</p>



<p>The algorithm is similar to the search algorithm described in the previous section, except we define the walk on a <em>Hamming graph</em>. A Hamming graph <img alt="H(N,m)" class="latex" src="https://s0.wp.com/latex.php?latex=H%28N%2Cm%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(N,m)"/> is defined as follows: each vertex <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> corresponds to an <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-tuple, (<img alt="i_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{1}"/>,…,<img alt="i_{m}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{m}"/>), where <img alt="i_{k} \in S" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D+%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{k} \in S"/> for all <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> and repetition is allowed (that is, <img alt="i_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{k}"/> may equal <img alt="i_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j}"/> for <img alt="k \neq j" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cneq+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \neq j"/>), and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> is a parameter we will choose. Edges will exist between vertices that differ in exactly one coordinate (order matters in this graph). We describe the state of each vertex as:</p>



<p><img alt="\left|i \right&gt;=| i_{1},i_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7Ci+%5Cright%3E%3D%7C+i_%7B1%7D%2Ci_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|i \right&gt;=| i_{1},i_{2}"/>,…,<img alt="i_{m},f(i_{1})" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bm%7D%2Cf%28i_%7B1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{m},f(i_{1})"/>,…,<img alt="f(i_{m})&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bm%7D%29%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{m})&gt;"/></p>



<p>Then, moving along each edge that replaces the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th coordinate with <img alt="x_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{k}"/> such that <img alt="i_{j} \neq x_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+x_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j} \neq x_{k}"/>  requires two queries to the black box function to erase <img alt="f(i_{j})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{j})"/> and compute <img alt="f(x_{k})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x_{k})"/>. In the case, the marked vertices will be those that contain some <img alt="f(i_{k}) = f(i_{j})" class="latex" src="https://s0.wp.com/latex.php?latex=f%28i_%7Bk%7D%29+%3D+f%28i_%7Bj%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(i_{k}) = f(i_{j})"/> for <img alt="i_{j} \neq i_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=i_%7Bj%7D+%5Cneq+i_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i_{j} \neq i_{k}"/>. Since the function values are stored in the description of the state, then no additional queries to the black box are required to check if in a marked state.</p>



<p>The transition matrix is given by <img alt="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=P+%3D+%5Cfrac%7B1%7D%7Bm%28n-1%29%7D+%5Cunderset%7Bi+%5Cin+%5B1%2Cm%5D%7D%7B%5Csum%7D+%28J+-+I%29%5E%7B%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P = \frac{1}{m(n-1)} \underset{i \in [1,m]}{\sum} (J - I)^{(i)}"/>. <img alt="J" class="latex" src="https://s0.wp.com/latex.php?latex=J&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J"/> is the <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> all one matrix, and the superscript <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> denotes the operator acting on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th coordinate. The factor of <img alt="\frac{1}{m(n-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{m(n-1)}"/> normalizes the degree, since the graph is regular. We can compute the spectral gap of this graph to be <img alt="\frac{n}{m(n-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bn%7D%7Bm%28n-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{n}{m(n-1)}"/> (for details of this computation, see [2]). Then, noting that that the fraction of marked vertices, <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, is<br/> <img alt="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Cfrac%7Bm%28m-1%29%28n-2%29%5E%7Bm-2%7D%7D%7Bn%5E%7Bm%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\geq \frac{m(m-1)(n-2)^{m-2}}{n^{m}}"/>, classically, the query complexity is <img alt="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})" class="latex" src="https://s0.wp.com/latex.php?latex=m+%2B+O%28%5Cfrac%7B1%7D%7B%5Cdelta+%5Cepsilon%7D%29+%3D+m+%2B+O%28%5Cfrac%7Bn%5E%7B2%7D%7D%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m + O(\frac{1}{\delta \epsilon}) = m + O(\frac{n^{2}}{m})"/>, where <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> is the queries required to construct the initial state. Setting the parameters equal to minimize with respect to <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> gives classical query complexity <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N)"/>, as expected.</p>



<p>Then in the quantum case, <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> queries are still required to set up the state. <img alt="O(\frac{n}{\sqrt{m}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7B%5Csqrt%7Bm%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{n}{\sqrt{m}})"/> queries are required to perform the walk until a marked state is reached, by [6]. Setting parameters equal gives <img alt="O(N^{\frac{2}{3}})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%5E%7B%5Cfrac%7B2%7D%7B3%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(N^{\frac{2}{3}})"/> queries, as desired.</p>



<p>[1] Ambainis, A. Quantum walk algorithm for element distinctness, SIAM Journal on Computing 37(1):210-239 (2007). arXiv:quant-ph/0311001</p>



<p>[2] Childs, A. Lecture Notes on Quantum Algorithms (2017). <a href="https://www.cs.umd.edu/&#xA0;amchilds/qa/qa.pdf" rel="nofollow">https://www.cs.umd.edu/ amchilds/qa/qa.pdf</a></p>



<p>[3] Childs, A., Farhi, E. Gutmann, S. An example of the difference between<br/> quantum and classical random walks. Journal of Quantum Information<br/> Processing, 1:35, 2002. Also quant-ph/0103020.</p>



<p>[4] Godsil, C., Hanmeng, Z. Discrete-Time Quantum Walks and Graph Structures<br/> (2018). arXiv:1701.04474</p>



<p>[5] Kempe, J. Quantum random walks: an introductory overview, Contemporary<br/> Physics, Vol. 44 (4) (2003) 307:327. arXiv:quant-ph/0303081</p>



<p>[6] Magniez, F., Nayak, A., Richter, P.C. et al. On the hitting times of<br/> quantum versus random walks, Algorithmica (2012) 63:91.<br/> <a href="https://doi.org/10.1007/s00453-011-9521-6" rel="nofollow">https://doi.org/10.1007/s00453-011-9521-6</a></p>



<p>[7] Szegedy, M. Quantum Speed-up of Markov Chain Based Algorithms, 45th<br/> Annual IEEE Symposium on Foundations of Computer Science (2004).<br/> <a href="https://ieeexplore.ieee.org/abstract/document/1366222" rel="nofollow">https://ieeexplore.ieee.org/abstract/document/1366222</a></p></div>
    </content>
    <updated>2018-12-23T17:45:32Z</updated>
    <published>2018-12-23T17:45:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>beanash</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2018/12/23/postdoc-in-cs-focused-on-sat-solving-at-kth-royal-institute-of-technology-apply-by-february-4-2019/</id>
    <link href="https://cstheory-jobs.org/2018/12/23/postdoc-in-cs-focused-on-sat-solving-at-kth-royal-institute-of-technology-apply-by-february-4-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc in CS focused on SAT solving at KTH Royal Institute of Technology (apply by February 4, 2019)</title>
    <summary>The TCS Group at KTH invites applications for postdoc positions focusing on algorithms for solving the Boolean satisfiability problem (SAT) very efficiently for large classes of instances, and on analyzing and understanding such algorithms. The application deadline is February 4, 2019. Informal enquiries are welcome and may be sent to jakobn@kth.se . Website: http://www.csc.kth.se/~jakobn/openings/J-2018-3178-Eng.php Email: […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The TCS Group at KTH invites applications for postdoc positions focusing on algorithms for solving the Boolean satisfiability problem (SAT) very efficiently for large classes of instances, and on analyzing and understanding such algorithms. The application deadline is February 4, 2019. Informal enquiries are welcome and may be sent to jakobn@kth.se .</p>
<p>Website: <a href="http://www.csc.kth.se/~jakobn/openings/J-2018-3178-Eng.php">http://www.csc.kth.se/~jakobn/openings/J-2018-3178-Eng.php</a><br/>
Email: jakobn@kth.se</p></div>
    </content>
    <updated>2018-12-23T10:53:36Z</updated>
    <published>2018-12-23T10:53:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2018-12-31T12:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2018/12/23/postdoc-positions-in-tcs-at-kth-royal-institute-of-technology-apply-by-february-4-2019/</id>
    <link href="https://cstheory-jobs.org/2018/12/23/postdoc-positions-in-tcs-at-kth-royal-institute-of-technology-apply-by-february-4-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc positions in TCS at KTH Royal Institute of Technology (apply by February 4, 2019)</title>
    <summary>The TCS Group at KTH Royal Institute of Technology invites applications for postdoc positions in TCS. The application deadline is February 4, 2019. See https://apc.eecs.kth.se/J-2018-3169-Eng.php for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to apc@eecs.kth.se . Website: https://apc.eecs.kth.se/J-2018-3169-Eng.php Email: apc@eecs.kth.se
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The TCS Group at KTH Royal Institute of Technology invites applications for postdoc positions in TCS. The application deadline is February 4, 2019. See <a href="https://apc.eecs.kth.se/J-2018-3169-Eng.php">https://apc.eecs.kth.se/J-2018-3169-Eng.php</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to apc@eecs.kth.se .</p>
<p>Website: <a href="https://apc.eecs.kth.se/J-2018-3169-Eng.php">https://apc.eecs.kth.se/J-2018-3169-Eng.php</a><br/>
Email: apc@eecs.kth.se</p></div>
    </content>
    <updated>2018-12-23T10:03:32Z</updated>
    <published>2018-12-23T10:03:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2018-12-31T12:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6939</id>
    <link href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/" rel="alternate" type="text/html"/>
    <title>Towards Quantum PCP: A Proof of the NLETS Theorem</title>
    <summary>By Abhijit Mudigonda, Richard Wang, and Lisa Yang This is part of a series of blog posts for CS 229r: Physics and Computation. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By Abhijit Mudigonda, Richard Wang, and Lisa Yang</p>



<p><i>This is part of a series of blog posts for <a href="https://www.boazbarak.org/fall18seminar/">CS 229r: Physics and Computation</a>. In this post, we will talk about progress made towards resolving the quantum PCP conjecture. We’ll briefly talk about the progression from the quantum PCP conjecture to the NLTS conjecture to the NLETS theorem, and then settle on providing a proof of the NLETS theorem. This new proof, due to Nirkhe, Vazirani, and Yuen, makes it clear that the Hamiltonian family used to resolve the NLETS theorem cannot help us in resolving the NLTS conjecture.</i></p>



<h2>Introduction</h2>
<p>We are all too familiar with <b>NP</b> problems. Consider now an upgrade to <b>NP</b> problems, where an omniscient prover (we’ll call this prover Merlin) can send a polynomial-sized proof to a <b>BPP</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#BPP">bounded-error probabilistic polynomial-time</a>) verifier (and we’ll call this verifier Arthur). Now, we have more decision problems in another complexity class, <b>MA</b> (<a href="https://complexityzoo.uwaterloo.ca/Petting_Zoo#MA">Merlin-Arthur</a>). Consider again, the analogue in the quantum realm where now the prover sends over qubits instead and the verifier is in <b>BQP</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:B#bqp">bounded-error quantum polynomial-time</a>). And now we have <b>QMA</b> (<a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qma">quantum Merlin-Arthur</a>).</p>

<p>We can show that there is a hierarchy to these classes, where <b>NP</b> <img alt="\subseteq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\subseteq "/> <b>MA</b> <img alt="\subseteq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csubseteq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\subseteq "/> <b>QMA</b>.</p>

<p>Our goal is to talk about progress towards a <b>quantum PCP theorem</b> (and since nobody has proved it in the positive or negative, we’ll refer to it as a quantum PCP <i>conjecture</i> for now), so it might be a good idea to first talk about the PCP theorem. Suppose we take a Boolean formula, and we want to verify that it is satisfiable. Then someone comes along and presents us with a certificate — in this case, a satisfying assignment — and we can check in polynomial time that either this is indeed a satisfying assignment to the formula (a correct certificate) or it is not (an incorrect certificate).</p>

<p>But this requires that we check the entire certificate that is presented to us. Now, in comes the <b>PCP Theorem</b> (for <i>probabilistically checkable proofs</i>), which tells us that a certificate can be presented to us such that we can read a constant number of bits from the certificate, and have two things guaranteed: one, if this certificate is correct, then we will never think that it is incorrect even if we are not reading the entire certificate, and two, if we are presented with an incorrect certificate, we will reject it with high probability [<a href="https://windowsontheory.org/feed/#arora2009computational">1</a>].</p>

<p>In short, one formulation of the PCP theorem tells us that, puzzingly, we might not need to read the entirety of a proof in order to be convinced with high probability that it is a good proof or a bad proof. But a natural question arises, which is to ask: is there a quantum analogue of the PCP theorem?</p>

<h2>Progress</h2>

<p>The answer is, we’re still not sure. But to make progress towards resolving this question, we will present the work of <a href="https://arxiv.org/pdf/1802.07419.pdf">Nirkhe, Vazirani, and Yuen</a> in providing an alternate proof of an earlier result of <a href="https://arxiv.org/pdf/1510.02082.pdf">Eldar and Harrow</a> on the NLETS theorem.

</p><p>Before we state the quantum PCP conjecture, it would be helpful to review information about local Hamiltonians and the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem. <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">A previous blog post by Ben Edelman</a> covers these topics. Now, let’s state the quantum PCP conjecture:</p>

<p><b>(<i>Quantum PCP Conjecture</i>)</b>: It is QMA-hard to decide whether a given local Hamiltonian <img alt="H = H_{1} + ... + H_{m} " class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+H_%7B1%7D+%2B+...+%2B+H_%7Bm%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = H_{1} + ... + H_{m} "/> (where each <img alt="||H_{i}|| \leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7CH_%7Bi%7D%7C%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||H_{i}|| \leq 1"/>) has ground state energy at most <img alt="a " class="latex" src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a "/> or at least <img alt="b " class="latex" src="https://s0.wp.com/latex.php?latex=b+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b "/> when <img alt="b-a \geq c||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b-a \geq c||H|| "/> for some universal constant <img alt="c &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=c+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c &gt; 0"/>.</p>

<p>Recall that MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-SAT being NP-hard corresponds to the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem being QMA-hard when <img alt="b-a \geq 1/poly(n)" class="latex" src="https://s0.wp.com/latex.php?latex=b-a+%5Cgeq+1%2Fpoly%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b-a \geq 1/poly(n)"/>. (We can refer to <a href="https://www.cs.cmu.edu/~odonnell/quantum15/lecture24.pdf">Theorem 4.1 in these scribed notes of Ryan O’Donnell’s lecture</a>, and more specifically to  <a href="https://arxiv.org/pdf/quant-ph/0406180.pdf">Kempe-Kitaev-Regev’s original paper</a> for proof of this fact.) The quantum PCP conjecture asks if this is still the case when the gap is <img alt="c||H||" class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H||"/>.</p>

<p>Going back to the PCP theorem, an implication of the PCP theorem is that it is NP-hard to approximate certain problems to within some factor. Just like its classical analogue, the qPCP conjecture can be seen as stating that it is QMA-hard to approximate the ground state energy to a factor better than <img alt="c||H||" class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H||"/>.</p>

<h3>Reformulation: NLTS conjecture</h3>
<p>Let’s make the observation that, taking <img alt="a " class="latex" src="https://s0.wp.com/latex.php?latex=a+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a "/> to be the ground state energy, the qPCP conjecture sort of says that there exists a family of Hamiltonians for which there is no trivial state (a state generated by a low depth circuit) such that the energy is at most <img alt="c||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=c%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c||H|| "/> above the ground state energy.</p>

<p>Freedman and Hastings came up with an easier goal called the <b>No Low-Energy Trivial States conjecture</b>, or <b>NLTS conjecture</b>. We expect that ground states of local Hamiltonians are sufficiently hard to describe (if NP <img alt="\neq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq "/> QMA). So low-energy states might not be generated by a quantum circuit of constant depth. More formally:</p>

<p><b>(<i>NLTS Conjecture</i>)</b>: <i>There exists a universal constant <img alt="\epsilon &gt; 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt; 0 "/> and a family of local Hamiltonians <img alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\}_{n=1}^{\infty} "/> where <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> acts on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles and consists of <img alt="m_{n} " class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{n} "/> local terms, s.t. any family of states <img alt="\{|\psi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\psi_{n}\rangle\} "/> satisfying <img alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) "/> requires circuit depth that grows faster than any constant.</i></p>

<p>To reiterate, if we did have such a family of NLTS Hamiltonians, then it we wouldn’t be able to give “easy proofs” for the minimal energy of a Hamiltonian, because we couldn’t just give a small circuit which produced a low energy state.</p>

<h2>Progress: NLETS theorem</h2>
<p><img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>-error states are states that differ from the ground state in at most <img alt="\epsilon n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon n "/> qubits. Now, consider <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states (which “agree” with the ground state on most qubits). Then for bounded-degree local Hamiltonians (analogously in the classical case, those where each variable participates in a bounded number of clauses), these states are also low energy. So any theorem which applies to low energy states (such as the NLTS conjecture), should also apply to states with <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error (as in the NLETS theorem).</p>

<p>To define low-error states more formally:</p>

<p><b>Definition 2.1</b> (<img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>-error states): <i>Let <img alt="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho%2C+%5Csigma+%5Cin+D%28%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho, \sigma \in D((\mathbb{C}^{d})^{\otimes n}) "/> (the space of positive semidefinite operators of trace norm equal to 1 on <img alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{d})^{\otimes n}"/>). Let <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> be a local Hamiltonian acting on <img alt="(\mathbb{C}^{d})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bd%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{d})^{\otimes n}"/>. Then:</i></p>

<p/><ul>
    <li><img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state of <img alt="\rho " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho "/> if <img alt="\exists S \subseteq [n] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexists+S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exists S \subseteq [n] "/> of size at most <img alt="\epsilon n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon n "/> s.t. <img alt="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D%28%5Crho%29+%3D+%5Ctext%7BTr%7D_%7BS%7D%28%5Csigma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_{S}(\rho) = \text{Tr}_{S}(\sigma)"/>.</li>
    <li><img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state for <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> if <img alt="\exists \rho " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexists+%5Crho+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\exists \rho "/> s.t. <img alt="\text{Tr}(H\rho) = \lambda_{min}(H) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28H%5Crho%29+%3D+%5Clambda_%7Bmin%7D%28H%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(H\rho) = \lambda_{min}(H) "/> and <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> is an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state for <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>.</li>
</ul><p/>

<p>Here, see that <img alt="\text{Tr}_{S} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_%7BS%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_{S} "/> is just the partial trace on some subset of integers <img alt="S " class="latex" src="https://s0.wp.com/latex.php?latex=S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S "/>, like we’re tracing out or “disregarding” some subset of <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits.</p>

<p>In 2017, Eldar and Harrow showed the following result which is the NLETS theorem.</p>

<p><b>Theorem 1</b> (NLETS Theorem): <i>There exists a family of 16-local Hamiltonians <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> s.t. any family of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states <img alt="\{|\Phi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5CPhi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\Phi_{n}\rangle\} "/> for <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> requires circuit depth <img alt="\Omega(\log n) " class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Clog+n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega(\log n) "/> where <img alt="\epsilon = 10^{-9}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+10%5E%7B-9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon = 10^{-9}"/>.</i></p>

<p>In the next two sections, we will provide background for an alternate proof of the NLETS theorem due to Nirkhe, Vazirani, and Yuen. After this, we will explain why the proof of NLETS cannot be used to prove NLTS, since the local Hamiltonian family we construct for NLETS can be linearized. Nirkhe, Vazirani, and Yuen’s proof of NLETS makes use of the Feynman-Kitaev clock Hamiltonian corresponding to the circuit generating the cat state (Eldar and Harrow make use of the Tillich-Zemor hypergraph product construction; refer to section 8 of <a href="https://arxiv.org/pdf/1510.02082.pdf">their paper</a>). What is this circuit? It is this one:</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-6977" height="210" src="https://windowsontheory.files.wordpress.com/2018/12/cat_state.png?w=326&amp;h=210" width="326"/>Image from [2]</figure></div>



<p>First, we apply the Hadamard gate (drawn as <img alt="\boxed{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboxed%7BH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boxed{H}"/>) which maps the first qubit <img alt="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle+%5Crightarrow+%5Cfrac%7B%7C0%5Crangle+%2B+%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle \rightarrow \frac{|0\rangle + |1\rangle}{\sqrt{2}}"/>. Then we can think of the CNOT gates (drawn as <img alt="\bullet-\oplus" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbullet-%5Coplus&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bullet-\oplus"/>) as propagating whatever happens to the first qubit to the rest of the qubits. If we had the first qubit mapping to 0, then the rest of the qubits map to 0, and likewise for 1. This generates the cat state <img alt="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bn%7D%5Crangle+%3D+%5Cfrac%7B%7C0%5Crangle%5E%7B%5Cotimes+n%7D+%2B+%7C1%5Crangle%5E%7B%5Cotimes+n%7D%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{CAT}_{n}\rangle = \frac{|0\rangle^{\otimes n} + |1\rangle^{\otimes n}}{\sqrt{2}}"/>, which is highly entangled.</p>

<p>Why do we want a highly entangled state? Roughly our intuition for using the cat state is this: if the ground state of a Hamiltonian is highly entangled, then any quantum circuit which generates it has non-trivial depth. So if our goal is to show the existence of local Hamiltonians which have low energy or low error states that need deep circuits to generate, it makes sense to use a highly entangled state like the cat state.</p>

<h2>Quantum circuits</h2>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-6978" height="221" src="https://windowsontheory.files.wordpress.com/2018/12/operators.png?w=446&amp;h=221" width="446"/>Image from [2]</figure></div>



<p>(We’ll write that the state of a qudit – a generalization of a qubit to more than two dimensions, and in this case <img alt="q " class="latex" src="https://s0.wp.com/latex.php?latex=q+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q "/> dimensions – is a vector in <img alt="\mathbb{C}^{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5E%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{C}^{q}"/>. In our diagram above, we’ll see 4 qudits, labelled appropriately.)</p>

<p>Let’s briefly cover the definitions for the quantum circuits we’ll be using.</p>

<p>Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a unitary operator acting on a system of <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qudits (in other words, acting on <img alt="(\mathbb{C}^{q})^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathbb%7BC%7D%5E%7Bq%7D%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\mathbb{C}^{q})^{\otimes n}"/>), where <img alt="U = U_{m} \hdots U_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+U_%7Bm%7D+%5Chdots+U_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = U_{m} \hdots U_{1}"/>. Here, each <img alt="U_{i} " class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{i} "/> is a unitary operator (a gate) acting on at most two qudits, and <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is a product of <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> such operators.</p>

<p>If there exists a partition <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> into products of non-overlapping two-qudit unitaries (we call these layers and denote them as <img alt="L_{i} = \bigotimes_{j}U_{ij}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D+%3D+%5Cbigotimes_%7Bj%7DU_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i} = \bigotimes_{j}U_{ij}"/>, where each <img alt="U_{j} " class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bj%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{j} "/> here is in layer <img alt="L_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=L_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_{i}"/>) such that <img alt="U = L_{d} \hdots L_{1} " class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = L_{d} \hdots L_{1} "/> then we say <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> has <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> layers.</p>

<p>In other words, <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> has size <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> and circuit depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>.</p>

<h3>Lightcones, effect zones, shadow zones</h3>
<p>Consider <img alt="U = L_{d} \hdots L_{1} " class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+L_%7Bd%7D+%5Chdots+L_%7B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = L_{d} \hdots L_{1} "/> and <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> an operator.</p>

<p>For <img alt="j &lt; d " class="latex" src="https://s0.wp.com/latex.php?latex=j+%3C+d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j &lt; d "/> define <img alt="K^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j)} "/> as the gates in layer <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> whose supports overlap that of any gate in <img alt="K^{(j+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j+1)}"/>, …, <img alt="K^{(d)} " class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28d%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(d)} "/> or with <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>.</p>

<p><b>Definition 3.1</b> (lightcone): <i>The <i>lightcone</i> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the union of <img alt="K^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(j)}"/>: <img alt="K_{U} \triangleq \bigcup_{j} K^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=K_%7BU%7D+%5Ctriangleq+%5Cbigcup_%7Bj%7D+K%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_{U} \triangleq \bigcup_{j} K^{(j)}"/>.</i></p>

<p>So we can think of the lightcone as the set of gates spreading out of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> all the way to the first layer of the circuit. In our diagram, the lightcone of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> is the dash-dotted region. We have <img alt="K^{(3)} = \varnothing" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%283%29%7D+%3D+%5Cvarnothing&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(3)} = \varnothing"/>, <img alt="K^{(2)} = \{U_{21}\}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(2)} = \{U_{21}\}"/>, and <img alt="K^{(1)} = \{U_{11}, U_{12}\}" class="latex" src="https://s0.wp.com/latex.php?latex=K%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K^{(1)} = \{U_{11}, U_{12}\}"/>.</p>

<p>We also want a definition for what comes back from the lightcone: the set of gates from the first layer (the widest part of the cone) back to the last layer.</p>

<p>Define <img alt="E^{(1)} = K^{(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+K%5E%7B%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(1)} = K^{(1)}"/>. For <img alt="j \geq 2" class="latex" src="https://s0.wp.com/latex.php?latex=j+%5Cgeq+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j \geq 2"/>, let <img alt="E^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(j)} "/> be the set of gates whose supports overlap with any gate in <img alt="E^{(j-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%28j-1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(j-1)}"/>.</p>

<p><b>Definition 3.2</b> (effect zone): <i>The <i>effect zone</i> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the union <img alt="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=E_%7BU%7D%28A%29+%5Ctriangleq+%5Cbigcup_%7Bj%7D+E%5E%7B%28j%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_{U}(A) \triangleq \bigcup_{j} E^{(j)}"/>.</i></p>

<p>In our diagram, see that <img alt="E^{(1)} = \{U_{11}, U_{12}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%281%29%7D+%3D+%5C%7BU_%7B11%7D%2C+U_%7B12%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(1)} = \{U_{11}, U_{12}\}"/>, <img alt="E^{(2)} = \{U_{21}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%282%29%7D+%3D+%5C%7BU_%7B21%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(2)} = \{U_{21}\}"/>, and <img alt="E^{(3)} = \{U_{31}\}" class="latex" src="https://s0.wp.com/latex.php?latex=E%5E%7B%283%29%7D+%3D+%5C%7BU_%7B31%7D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E^{(3)} = \{U_{31}\}"/>. The effect zone of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> is the dotted region.</p>

<p><b>Definition 3.3</b> (shadow of the effect zone): <i>The <i>shadow of the effect zone</i> <img alt="W_{U}(A) " class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A) "/> of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> with respect to <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> is the set of qudits acted on by the gates in the effect zone.</i></p>

<p>In our diagram, the first three qudits are effected by gates in the effect zone. So <img alt="W_{U}(A) = \{1, 2, 3\}" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29+%3D+%5C%7B1%2C+2%2C+3%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A) = \{1, 2, 3\}"/>.</p>

<p>Given all of these definitions, we make the following claim which will be important later, in a proof of a generalization of NLETS.</p>

<p><b><a id="claim3"/>Claim 3.1</b> (Disjoint lightcones): <i>Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a circuit and <img alt="A, B " class="latex" src="https://s0.wp.com/latex.php?latex=A%2C+B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A, B "/> operators. If the qudits <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/> acts on are disjoint from <img alt="W_{U}(A)" class="latex" src="https://s0.wp.com/latex.php?latex=W_%7BU%7D%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W_{U}(A)"/>, then the lightcones of <img alt="A " class="latex" src="https://s0.wp.com/latex.php?latex=A+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A "/> and <img alt="B " class="latex" src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B "/> in <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> are disjoint.</i></p>

<h2>Toward the Feynman-Kitaev clock</h2>
<p>Now we’ll give some definitions that will become necessary when we make use of the Feynman-Kitaev Hamiltonian in our later proofs.</p>

<p>Let’s define a unary clock. It will basically help us determine whatever happened at any time little <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> along the total time big <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. Let <img alt="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle+%3D+%7C0%5Crangle%5E%7B%5Cotimes%28T-t%29%7D+%5Cotimes+%7C1%5Crangle%5E%7B%5Cotimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t, T)\rangle = |0\rangle^{\otimes(T-t)} \otimes |1\rangle^{\otimes t}"/>. For our purposes today, we won’t worry about higher dimensional clocks. So we’ll write <img alt="|\textsf{clock}_{k}(t, T)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{clock}_{k}(t, T)\rangle"/>, but we’ll really only consider the case where <img alt="k = 1" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 1"/>, which corresponds to <img alt="|\textsf{unary}(t, T)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%2C+T%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t, T)\rangle"/>. For simplicity’s sake, we will henceforth just write <img alt="|\textsf{unary}(t)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{unary}(t)\rangle"/>.</p>

<p>Our goal is to construct something a little similar to the tableaux in the Cook-Levin theorem, so we also want to define a history state:</p>

<p><b>Definition 4.1</b> (History state): <i>Let <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> be a quantum circuit that acts on a witness register and an ancilla register. Let <img alt="C_{1}, ..., C_{T} " class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B1%7D%2C+...%2C+C_%7BT%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{1}, ..., C_{T} "/> denote the sequence of two-local gates in <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. Then for all <img alt="k \in \mathbb{N}" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \in \mathbb{N}"/>, a state <img alt="|\Psi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle "/> is a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-dimensional history state of <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> if:</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7BT%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5E%7BT%7D%7C%5Ctextsf%7Bclock%7D_%7Bk%7D%28t%2C+T%29%5Crangle+%5Cotimes+%7C%5Cpsi_%7Bt%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}|\textsf{clock}_{k}(t, T)\rangle \otimes |\psi_{t}\rangle\end{aligned} "/></p></div>

<p>where we have the clock state to keep track of time and <img alt="\psi_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_{t} "/> is some state such that <img alt="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7Bt%7D%5Crangle+%3D+C_%7Bt%7D%7C%5Cpsi_%7Bt-1%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_{t}\rangle = C_{t}|\psi_{t-1}\rangle "/> and <img alt="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%7B0%7D%5Crangle+%3D+%7C%5Cxi%5Crangle_%7Bwitness%7D+%5Cotimes+%7C0%5Crangle_%7Bancilla%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_{0}\rangle = |\xi\rangle_{witness} \otimes |0\rangle_{ancilla}"/>. With this construction, we should be able to make a measurement to get back the state at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>.</p>

<h2>Proof of NLETS</h2>
<p>We provide a proof of (a simplified case of) the NLETS theorem proved by Nirkhe, Vazirani, and Yuen in [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>].</p>

<p><b>Theorem 2</b> (NLETS): <i>There exists a family of <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local Hamiltonians <img alt="\{H^{(n)}\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\} "/> on a line (Each Hamiltonian <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> can be defined on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles arranged on a line such that each local Hamiltonian acts on a particle and its two neighbors) such that for all <img alt="n \in \mathbb{N}" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \in \mathbb{N}"/>, the circuit depth of any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error ground state for <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> is at least logarithmic in <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/>.</i></p>

<p>First, we’ll show the circuit lower bound.  Then we’ll explain why these Hamiltonians can act on particles on a line and what this implies about the potential of these techniques for proving NLTS.</p>

<p><i>Proof</i>: We will use the <b>Feynman-Kitaev clock construction</b> to construct a <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local Hamiltonian <img alt="\mathcal{H}^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H}^{(n)} "/> for the circuit <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>: <img alt="|0^n\rangle \to |\textsf{CAT}_n\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5En%5Crangle+%5Cto+%7C%5Ctextsf%7BCAT%7D_n%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0^n\rangle \to |\textsf{CAT}_n\rangle "/>.</p>

<p>Fix <img alt="n \in \mathbb{N} " class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cin+%5Cmathbb%7BN%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \in \mathbb{N} "/> and let <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> have size <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>.  The Hamiltonian <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> acts on <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubits and consists of several local terms depending on <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>:</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t+%2B+H_%7Bout%7D+%2B+H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\mathcal{H} = H_{in} + \sum_{t=1}^T H_t + H_{out} + H_{stab}\end{aligned} "/></p></div>

<p>We can think of a <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state as representing a <img alt="T " class="latex" src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T "/> step computation on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits (i.e. for each time <img alt="t \in [0,T]" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B0%2CT%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \in [0,T]"/>, we have a <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> bit computation state <img alt="\textsf{state}_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_t "/> of <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>).  Intuitively, a <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state has energy <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> with respect to <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> iff it is the history state of <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.  This is because <img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> checks that at time <img alt="t=0" class="latex" src="https://s0.wp.com/latex.php?latex=t%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=0"/>, <img alt="\textsf{state}_0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_0 "/> consists of the input <img alt="|0\rangle^n " class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5En+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle^n "/> to <img alt="C_n" class="latex" src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n"/>.  Each <img alt="H_t " class="latex" src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_t "/> checks that <img alt="\textsf{state}_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_{t} "/> proceed correctly from <img alt="\textsf{state}_{t-1} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextsf%7Bstate%7D_%7Bt-1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textsf{state}_{t-1} "/> (i.e. that the <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>th gate of <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> is applied correctly).  Then <img alt="H_{out} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bout%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{out} "/> checks that at time <img alt="t=T" class="latex" src="https://s0.wp.com/latex.php?latex=t%3DT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=T"/>, the output is <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>.  Finally, <img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> checks that the <img alt="T+n " class="latex" src="https://s0.wp.com/latex.php?latex=T%2Bn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T+n "/> qubit state is a superposition only over states where the first <img alt="T " class="latex" src="https://s0.wp.com/latex.php?latex=T+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T "/> qubits represent “correct times” (i.e. a unary clock state where time <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> is represented by <img alt="T-t " class="latex" src="https://s0.wp.com/latex.php?latex=T-t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T-t "/> zeros followed by <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> ones).</p>

<p>Therefore, <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> has a unique ground state, the history state of <img alt="C_n|0^n\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=C_n%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n|0^n\rangle"/>, with energy <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>:</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes+%7C%5Cpsi_t%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7Bunary%7D%28t%29%5Crangle%5Cotimes%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes+%7C0%5Crangle%5E%7B%5Cotimes+%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes |\psi_t\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\textsf{unary}(t)\rangle\otimes|\textsf{CAT}_{t}\rangle\otimes |0\rangle^{\otimes (n-t)}\end{aligned} "/></p></div>

<p>Later we will show how to transform <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> into a Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qutrits on a line.  Intuitively, the structure of <img alt="C_n " class="latex" src="https://s0.wp.com/latex.php?latex=C_n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_n "/> allows us to fuse the <img alt="T=n " class="latex" src="https://s0.wp.com/latex.php?latex=T%3Dn+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T=n "/> time qubits and <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> state qubits and represent unused state qubits by <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>.  For the Hamiltonian <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, the ground state becomes</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5CPsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%2B1%7D%7D%5Csum_%7Bt%3D0%7D%5En+%7C%5Cpsi_t%5Crangle+%3D+%5Csum_%7Bt%3D0%7D%5En+%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle%5Cotimes%7C2%5Crangle%5E%7B%5Cotimes%28n-t%29%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\Psi\rangle = \frac{1}{\sqrt{n+1}}\sum_{t=0}^n |\psi_t\rangle = \sum_{t=0}^n |\textsf{CAT}_{t}\rangle\otimes|2\rangle^{\otimes(n-t)}\end{aligned} "/></p></div>

<p>For the rest of this proof, we work with respect to <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>

<p>Let <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> be an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state and let <img alt="S \subseteq [n] " class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5Bn%5D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S \subseteq [n] "/> be the subset of qutrits such that <img alt="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D_S%28%5Csigma%29+%3D+%5Ctext%7BTr%7D_S%28%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}_S(\sigma) = \text{Tr}_S(|\Psi\rangle\langle\Psi|)"/>.  We define two projection operators which, when applied to <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> alone, produce nontrivial measurements, but when applied to <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> together, produce trivial measurements.</p>

<p><b>Definition 5.1</b>: <i>For any <img alt="i\in[n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in[n]"/>, the projection operator</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DA_i+%3D+%7C0%5Crangle%5Clangle+0%7C_i+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}A_i = |0\rangle\langle 0|_i \end{aligned} "/></p></div>

<p><i>projects onto the subspace spanned by <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit.</i></p>

<p><i>For any <img alt="j\in[n]" class="latex" src="https://s0.wp.com/latex.php?latex=j%5Cin%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j\in[n]"/>, the projection operator</i></p>

<div style="text-align: center;"><p><img alt="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+B_j+%3D+%7C1%5Crangle%5Clangle+1%7C_i%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} B_j = |1\rangle\langle 1|_i\end{aligned} "/></p></div>

<p><i>projects onto the subspace spanned by <img alt="1 " class="latex" src="https://s0.wp.com/latex.php?latex=1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 "/> on the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrit.</i></p>

<p><b>Claim 5.1</b>:
<i>For <img alt="i\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\not\in S"/>, <img alt="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i\sigma) = \frac{1}{2} + \frac{-i}{2(n+1)}"/>.  For <img alt="j\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=j%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j\not\in S"/>, <img alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}"/>.  Note that these values are positive for any <img alt="i,j\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j\in [n]"/>.</i></p>

<p><i>Proof</i>: If <img alt="i \not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \not\in S"/>, then measurements on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit are the same for <img alt="\sigma " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma "/> and <img alt="|\Psi\rangle\langle\Psi|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\Psi\rangle\langle\Psi|"/>.</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i%7C%5CPsi%5Crangle%5Clangle%5CPsi%7C%29%5C%5C+++++%26%3D+%5Ctext%7BTr%7D%5Cleft%28A_i+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%5Cright%29%5C%5C+++++%26%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%2Ct%27%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%27%7D%7C%29+++%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}     \text{Tr}(A_i\sigma) &amp;= \text{Tr}(A_i|\Psi\rangle\langle\Psi|)\\     &amp;= \text{Tr}\left(A_i \frac{1}{n+1}\sum_{t,t'}|\psi_t\rangle\langle\psi_{t'}|\right)\\     &amp;= \frac{1}{n+1}\sum_{t,t'} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t'}|)   \end{aligned} "/></p></div>

<p>If <img alt="t=t'" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Dt%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=t'"/>, then any <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qutrit pure state cannot have nonzero weight in both <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> and <img alt="\psi_{t'} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_%7Bt%27%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_{t'} "/> (every pure state ends in some number of <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>s which tells which <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> (if any) it can be a part of). Therefore,</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+++++%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_%7Bt%7D+%5Ctext%7BTr%7D%28A_i%7C%5Cpsi_t%5Crangle%5Clangle%5Cpsi_%7Bt%7D%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle+%5Cpsi_t%7CA_i%7C%5Cpsi_t%5Crangle+%5Censpace.+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}     \text{Tr}(A_i\sigma) = \frac{1}{n+1}\sum_{t} \text{Tr}(A_i|\psi_t\rangle\langle\psi_{t}|) = \frac{1}{n+1}\sum_t \langle \psi_t|A_i|\psi_t\rangle \enspace. \end{aligned} "/></p></div>

<p>If <img alt="i \le t" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \le t"/>, then projecting onto the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit gives <img alt="0 " class="latex" src="https://s0.wp.com/latex.php?latex=0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0 "/> with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>. Therefore, <img alt="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i%5Csigma%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Cleft%28%5Cfrac%7Bn-i%2B1%7D%7B2%7D%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-i%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i\sigma) = \frac{1}{n+1}\left(\frac{n-i+1}{2}\right) = \frac{1}{2} + \frac{-i}{2(n+1)}"/>.</p>

<p>Similarly, <img alt="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28B_j%5Csigma%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B-j%7D%7B2%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(B_j\sigma) = \frac{1}{2} + \frac{-j}{2(n+1)}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p><b>Claim 5.2</b>: <i>For <img alt="i,j \not\in S " class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj+%5Cnot%5Cin+S+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j \not\in S "/> such that <img alt="i &lt; j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; j"/>, <img alt="\text{Tr}(A_i \otimes B_j \sigma) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\text{Tr}(A_i \otimes B_j \sigma) = 0"/>.</i></p>

<p><i>Proof</i>:
As before, we can calculate</p>

<div style="text-align: center;"><p><img alt="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%26%3D+%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C%29+%3D+%5Cfrac%7B1%7D%7Bn%2B1%7D%5Csum_t+%5Clangle%5Cpsi_t%7CA_i%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \text{Tr}(A_i \otimes B_j \sigma) &amp;= \text{Tr}(A_i \otimes B_j |\Psi\rangle \langle\Psi|) = \frac{1}{n+1}\sum_t \langle\psi_t|A_i\otimes B_j|\psi_t\rangle \end{aligned} "/></p></div>

<p>If <img alt="j &gt; t" class="latex" src="https://s0.wp.com/latex.php?latex=j+%3E+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j &gt; t"/>, then the <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrit of <img alt="\psi_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpsi_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\psi_t "/> is <img alt="2 " class="latex" src="https://s0.wp.com/latex.php?latex=2+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2 "/> so <img alt="B_j|\psi_t\rangle = 0" class="latex" src="https://s0.wp.com/latex.php?latex=B_j%7C%5Cpsi_t%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B_j|\psi_t\rangle = 0"/>. If <img alt="j \le t" class="latex" src="https://s0.wp.com/latex.php?latex=j+%5Cle+t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j \le t"/>, then <img alt="A_i \otimes B_j|\psi_t\rangle = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=A_i+%5Cotimes+B_j%7C%5Cpsi_t%5Crangle+%3D+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i \otimes B_j|\psi_t\rangle = 0 "/> because the first <img alt="t " class="latex" src="https://s0.wp.com/latex.php?latex=t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t "/> qutrits of <img alt="|\psi_t\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_t%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_t\rangle "/> contain the <img alt="|\textsf{CAT}_{t}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7BCAT%7D_%7Bt%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{CAT}_{t}\rangle "/> state so under any measurement, the <img alt="i " class="latex" src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i "/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/>th qutrits must be the same. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p>Now we use these claims to prove a circuit lower bound.  Let <img alt="U " class="latex" src="https://s0.wp.com/latex.php?latex=U+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U "/> be a circuit generating (a state with density matrix) <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/>.  Let <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> be the depth of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>.</p>

<p>Consider some <img alt="i\not\in S" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cnot%5Cin+S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\not\in S"/>.  For any operator acting on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit, its lightcone consists of at most <img alt="2^d " class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d "/> gates so its effect zone consists of at most <img alt="2^{2d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d} "/> gates which act on at most <img alt="2^{2d+1} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} "/> qudits (called the shadow of the effect zone).</p>

<p>Assume towards contradiction that <img alt="2^{2d+1} &lt; n-\epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%3C+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} &lt; n-\epsilon n"/>. Then the shadow of any operator acting only on the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>th qutrit has size at most <img alt="2^{2d+1} \le n - |S| " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cle+n+-+%7CS%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} \le n - |S| "/> since <img alt="|S| \le \epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=%7CS%7C+%5Cle+%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|S| \le \epsilon n"/>.  So there is some <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> outside of the shadow which is in the complement of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/>.  By <a href="https://windowsontheory.org/feed/#claim3">Claim 3.1</a>, we have found two indices <img alt="i,j " class="latex" src="https://s0.wp.com/latex.php?latex=i%2Cj+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i,j "/> such that any pair of operators acting on <img alt="i " class="latex" src="https://s0.wp.com/latex.php?latex=i+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i "/> and <img alt="j " class="latex" src="https://s0.wp.com/latex.php?latex=j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j "/> have disjoint lightcones in <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/>. WLOG let <img alt="i &lt; j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3C+j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i &lt; j"/>.  The lightcones of <img alt="A_i,B_j " class="latex" src="https://s0.wp.com/latex.php?latex=A_i%2CB_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_i,B_j "/> are disjoint which implies
<img alt="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Ctext%7BTr%7D%28A_i+%5Cotimes+B_j+%5Csigma%29+%3D+%5Ctext%7BTr%7D%28A_i+%5Csigma%29%5Ccdot%5Ctext%7BTr%7D%28B_j+%5Csigma%29.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\text{Tr}(A_i \otimes B_j \sigma) = \text{Tr}(A_i \sigma)\cdot\text{Tr}(B_j \sigma).\end{aligned} "/></p>

<p>By the two claims above, we get a contradiction.</p>

<p>Therefore, <img alt="2^{2d+1} \ge n-\epsilon n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2d%2B1%7D+%5Cge+n-%5Cepsilon+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{2d+1} \ge n-\epsilon n"/>.  We can take any constant epsilon: letting <img alt="\epsilon = 1/2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon = 1/2"/>, we get</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7Dd+%5Cge+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28%5Clog+%5Cfrac%7Bn%7D%7B2%7D+-+1%5Cright%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}d \ge \frac{1}{2}\left(\log \frac{n}{2} - 1\right)\end{aligned} "/></p></div>

<p><img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<p>This analysis relies crucially on the fact that any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error state matches the groundstate on most qudits.  However, NLTS is concerned with states which may differ from the groundstate on many qudits, as long as they have low energy.</p>

<p><b>Remark 2.1</b>: <i>The paper of Nirkhe, Vazirani, and Yuen [<a href="https://windowsontheory.org/feed/#nirkhe2018approximate">2</a>] actually proves more:
</i></p><ul><i>
    </i><li><i>A more general lower bound: logarithmic lower bound on the circuit depth of any <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta"/>-approximate (<img alt="\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta "/> far in L1 norm) <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-noisy state (probability distribution over <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-error states).</i></li><i>
    </i><li><i>Assuming QCMA <img alt="\neq " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq "/> QMA (QCMA takes a <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> bit witness string instead of a <img alt="m " class="latex" src="https://s0.wp.com/latex.php?latex=m+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m "/> qubit state as witness), they show a superpolynomial lower bound (on the circuit depth of any <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta"/>-approximate <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-noisy state).</i></li><i>
    </i><li><i>“Approximate qLWC codes”, using techniques from their superpolynomial lower bound.</i></li><i>
</i></ul><p/>

<h2>Back to NLTS – Tempering our Optimism</h2>

<p>So far, we’ve shown a local Hamiltonian family for which all low-error (in “Hamming distance”) states require logarithmic quantum circuit depth to compute, thus resolving the NLETS conjecture. Now, let’s try to tie this back into the NLTS conjecture. Since it’s been a while, let’s recall the statement of the conjecture:</p>

<p><b>Conjecture</b> (NLTS): <i>There exists a universal constant <img alt="\epsilon &gt; 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt; 0 "/> and a family of local Hamiltonians <img alt="\{H^{(n)}\}_{n=1}^{\infty} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH%5E%7B%28n%29%7D%5C%7D_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H^{(n)}\}_{n=1}^{\infty} "/> where <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> acts on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> particles and consists of <img alt="m_{n} " class="latex" src="https://s0.wp.com/latex.php?latex=m_%7Bn%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m_{n} "/> local terms, s.t. any family of states <img alt="\{|\psi_{n}\rangle\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%7C%5Cpsi_%7Bn%7D%5Crangle%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{|\psi_{n}\rangle\} "/> satisfying <img alt="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi_%7Bn%7D+%7C+H%5E%7B%28n%29%7D+%7C+%5Cpsi_%7Bn%7D%5Crangle+%5Cleq+%5Cepsilon%7C%7CH%5E%7B%28n%29%7D%7C%7C+%2B+%5Clambda_%7Bmin%7D%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi_{n} | H^{(n)} | \psi_{n}\rangle \leq \epsilon||H^{(n)}|| + \lambda_{min}(H^{(n)}) "/> requires circuit depth that grows faster than any constant.</i></p>

<p>In order to resolve the NLTS conjecture, it thus suffices to exhibit a local Hamiltonian family for which all low-energy states require logarithmic quantum circuit depth to compute. We might wonder if the local Hamiltonian family we used to resolve NLETS, which has “hard ground states”, might also have hard low-energy states. Unfortunately, as we shall show, this cannot be the case. We will start by showing that Hamiltonian families that lie on constant-dimensional lattices (in a sense that we will make precise momentarily) cannot possibly be used to resolve NLTS,  and then show that the Hamiltonian family we used to prove NLTS can be linearized (made to lie on a one-dimensional lattice!).</p>

<h3>The Woes of Constant-Dimensional Lattices</h3>
<p><b>Definition 6.1</b>: <i>A local Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> acting on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits is said to <b>lie on a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/></b> if there is an injection of qubits into vertices of the graph such that the set of qubits in any interaction term correspond to a connected component in the graph</i>.</p>

<p><b>Theorem 2</b>: <i>If <img alt="(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H^{(n)}) "/> is a local Hamiltonian family that lies on an <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>-dimensional lattice, then <img alt="(H^{(n)}) " class="latex" src="https://s0.wp.com/latex.php?latex=%28H%5E%7B%28n%29%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H^{(n)}) "/> has a family of low-energy states with low circuit complexity. In particular, if <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> is a local Hamiltonian on a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice acting on <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> qubits for large enough <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, then for any <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, there exists a state <img alt="|\psi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle "/> that can be generated by a circuit of constant depth and such that <img alt="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle+%5Cleq+H_0+%2B+%5Cepsilon+%7C%7CH%7C%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle \psi | H | \psi \rangle \leq H_0 + \epsilon ||H|| "/> where <img alt="H_0 " class="latex" src="https://s0.wp.com/latex.php?latex=H_0+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_0 "/> is the ground-state energy.</i></p>

<p><i>Proof</i>: In what follows, we’ll omit some of the more annoying computational details in the interest of communicating the high-level idea.</p>

<p>Start by partitioning the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice (the one that <img alt="H^(n) " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%28n%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^(n) "/> lives on) into hypercubes of side length <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/>. We can “restrict” <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> to a given hypercube (let’s call it <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>) by throwing away all local terms containing a qubit not in <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>. This gives us a well-defined Hamiltonian <img alt="H_{\rho} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{\rho} "/> on the qubits in <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/>. Define <img alt="|\phi_{\rho}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_{\rho}\rangle "/> to be the <img alt="L^d" class="latex" src="https://s0.wp.com/latex.php?latex=L%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L^d"/>-qubit ground state of <img alt="H_{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Crho%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{\rho}"/>, and define</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cphi%5Crangle+%3A%3D+%5Cbigotimes_%7B%5Ctext%7Bhypercubes+%7D+%5Crho%7D+%7C%5Cphi_%7B%5Crho%7D%5Crangle%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\phi\rangle := \bigotimes_{\text{hypercubes } \rho} |\phi_{\rho}\rangle\end{aligned} "/></p></div>

<p>where <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> is an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit state. Each <img alt="|\phi_{\rho}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_%7B%5Crho%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi_{\rho}\rangle "/> can be generated by a circuit with at most <img alt="2^{L^d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d} "/> gates, hence at most <img alt="2^{L^d} " class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d} "/> depth. Then, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by putting all of these individual circuits in parallel – this doesn’t violate any sort of no-cloning condition because the individual circuits act on disjoint sets of qubits. Therefore, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by a circuit of depth at most <img alt="2^{L^d}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BL%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{L^d}"/>. <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> and <img alt="d " class="latex" src="https://s0.wp.com/latex.php?latex=d+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d "/> are both constants, so <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> can be generated by a constant-depth circuit.</p>

<p>We claim that, for the right choice of <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/>, <img alt="|\phi\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cphi%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\phi\rangle "/> is also a low-energy state. Intuitively, this is true because <img alt="\phi " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi "/> can only be “worse” than a true ground state of <img alt="H^{(n)} " class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)} "/> on local Hamiltonian terms that do not lie entirely within a single hypercube (i.e. the boundary terms), and by choosing <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> appropriately we can make this a vanishingly small fraction of the local terms of <img alt="H^{(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=H%5E%7B%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H^{(n)}"/>. Let’s work this out explicitly.</p>

<p>Each hypercube has surface area <img alt="2dL^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=2dL%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2dL^{d-1}"/>, and there are <img alt="n/L^d " class="latex" src="https://s0.wp.com/latex.php?latex=n%2FL%5Ed+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n/L^d "/> hypercubes in the lattice. Thus, the total number of qubits on boundaries is at most <img alt="2d\frac{n}{L}" class="latex" src="https://s0.wp.com/latex.php?latex=2d%5Cfrac%7Bn%7D%7BL%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2d\frac{n}{L}"/>. The number of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-connected components containing a given point in a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-dimensional lattice is a function of <img alt="k " class="latex" src="https://s0.wp.com/latex.php?latex=k+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k "/> and <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>. Both of these are constants. Therefore, the number of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-connected components containing a given vertex, and hence the number of local Hamiltonian terms containing a given qubit, is constant. Thus, the total number of violated local Hamiltonian terms is at most <img alt="O(\frac{n}{L})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cfrac%7Bn%7D%7BL%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\frac{n}{L})"/>. Taking <img alt="L " class="latex" src="https://s0.wp.com/latex.php?latex=L+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L "/> to be <img alt="\frac{1}{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\epsilon}"/>, we get the desired bound. Note that to be fully rigorous, we need to justify that the boundary terms don’t blow up the energy, but this is left as an exercise for the reader. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>

<h3>Linearizing the Hamiltonian</h3>
<p>Now that we have shown that Hamiltonians that live on constant-dimensional lattices cannot be used to prove NLTS, we will put the final nail in the coffin by showing that our NLETS Hamiltonian (the Feynman-Kitaev clock Hamiltonian <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> on the circuit <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>) can be made to lie on a line (a <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>-dimensional lattice). To do so, we will need to understand the details of <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> a bit better.</p>

<p><b><a id="prop6">Proposition 6.1</a></b>: <i><img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> for the circuit <img alt="C " class="latex" src="https://s0.wp.com/latex.php?latex=C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C "/> is <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local.</i></p>

<p><i>Proof</i>: Recall that we defined</p>

<div style="text-align: center;"><p><img alt="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%5Cmathcal%7BH%7D+%3A%3D+H_%7Bin%7D+%2B+%5Csum_%7Bt%3D1%7D%5ET+H_t%2B++H_%7Bstab%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}\mathcal{H} := H_{in} + \sum_{t=1}^T H_t+  H_{stab}\end{aligned} "/></p></div>

<p>Let’s go through the right-hand-side term-by-term. We will use <img alt="|\mathsf{time}(t)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Btime%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathsf{time}(t)\rangle "/> to denote the <img alt="t^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t^{\text{th}} "/> qubit of the time register and <img alt="|\mathsf{state}(s)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathsf%7Bstate%7D%28s%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathsf{state}(s)\rangle "/> to denote the <img alt="s^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=s%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s^{\text{th}} "/> qubit of the state register.</p>

<p>
  </p><ul>
    <li><img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> needs to serially access the qubit pairs

    <img alt="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Cmathsf%7Btime%7D%280%29%5Crangle%5Cotimes%5Ctextsf%7Bstate%7D%28s%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\mathsf{time}(0)\rangle\otimes\textsf{state}(s) \end{aligned} "/>

    for all <img alt="s " class="latex" src="https://s0.wp.com/latex.php?latex=s+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s "/> and ensure that they are all set to <img alt="|0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|0\rangle"/>. Thus, <img alt="H_{in} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bin%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{in} "/> is <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>-local.</li>
    <li>Each <img alt="H_t " class="latex" src="https://s0.wp.com/latex.php?latex=H_t+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_t "/> term needs to access the states <img alt="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t-1%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle%2C+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle%2C+%7C%5Ctextsf%7Bstate%7D%28s%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(t-1)\rangle, |\textsf{time}(t)\rangle, |\textsf{time}(t+1)\rangle, |\textsf{state}(s)\rangle"/>, and  <img alt="|\textsf{state}(t)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{state}(t)\rangle "/> and ensure that the state transitions are correct. Thus, <img alt="H_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bt%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{t} "/> is <img alt="5" class="latex" src="https://s0.wp.com/latex.php?latex=5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="5"/>-local.</li>
    <li><img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> needs to access the states

    <img alt="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Btime%7D%28t%2B1%29%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}|\textsf{time}(t)\rangle \otimes |\textsf{time}(t+1)\rangle \end{aligned} "/>

    and ensure that the progression of the time register is correct. Thus, <img alt="H_{stab} " class="latex" src="https://s0.wp.com/latex.php?latex=H_%7Bstab%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_{stab} "/> is <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>-local. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></li>
  </ul>
<p/>


<p>Now, we follow an approach of [<a href="https://windowsontheory.org/feed/#aharonov2017">3</a>] to embed <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> into a line.</p>

<p><b>Theorem 3</b>: <i>The Feynman-Kitaev clock Hamiltonian <img alt="H " class="latex" src="https://s0.wp.com/latex.php?latex=H+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H "/> can be manipulated into a <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local Hamiltonian acting on qutrits on a line.</i></p>

<p><i>Proof</i>: Rather than having <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> act on <img alt="2n " class="latex" src="https://s0.wp.com/latex.php?latex=2n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2n "/> total qubits (<img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> time qubits and <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/> state qubits), let’s fuse each <img alt="|\textsf{time}(i)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(i)\rangle "/> and <img alt="|\textsf{state}(i)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{state}(i)\rangle "/> pair into a single qudit of dimension <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>. If we view <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> as acting on the space of particles <img alt="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28i%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28i%29%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(i)\rangle \otimes |\textsf{state}(i)\rangle"/>, we observe that, following <a href="https://windowsontheory.org/feed/#prop6">Proposition 6.1</a>, each local term needs to check at most the particles corresponding to times <img alt="t-1" class="latex" src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t-1"/>, <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, and <img alt="t+1" class="latex" src="https://s0.wp.com/latex.php?latex=t%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t+1"/>. Therefore, <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> is <img alt="3" class="latex" src="https://s0.wp.com/latex.php?latex=3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3"/>-local and on a line, as desired.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6979" src="https://windowsontheory.files.wordpress.com/2018/12/qutrits.png?w=600"/>Image from [2]</figure>



<p>To see that we can have <img alt="\mathcal{H} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{H} "/> act on particles of dimension <img alt="3 " class="latex" src="https://s0.wp.com/latex.php?latex=3+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3 "/> (qutrits) rather than particles of dimension <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>, note that the degree of freedom corresponding to <img alt="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctextsf%7Btime%7D%28t%29%5Crangle+%5Cotimes+%7C%5Ctextsf%7Bstate%7D%28t%29%5Crangle+%3D+%7C0%5Crangle+%5Cotimes+%7C1%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\textsf{time}(t)\rangle \otimes |\textsf{state}(t)\rangle = |0\rangle \otimes |1\rangle "/> is unused, as the <img alt="t^{\text{th}} " class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B%5Ctext%7Bth%7D%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t^{\text{th}} "/> qubit of the state is never nonzero until timestamp <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. Thus, we can take the vectors</p>

<div style="text-align: center;"><p><img alt="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C0%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C0%5Crangle%2C+%7C1%5Crangle+%3A%3D+%7C1%5Crangle%5Cotimes%7C1%5Crangle%2C+%7C2%5Crangle+%3A%3D+%7C0%5Crangle%5Cotimes%7C0%5Crangle+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |0\rangle := |1\rangle\otimes|0\rangle, |1\rangle := |1\rangle\otimes|1\rangle, |2\rangle := |0\rangle\otimes|0\rangle \end{aligned} "/></p></div>

<p>as a basis for each qutrit.</p>

<p>Even though we’ve shown that the clock Hamiltonian for our original circuit cannot be used to prove NLTS (which is still weaker than the original Quantum PCP conjecture) this does not necessarily rule out the use of this approach for other “hard” circuits which might then allow us to prove NLTS. Furthermore, NLETS is independently interesting, as the notion of being low “Hamming distance” away from vectors is exactly what is used in error-correcting codes.</p>

<h1>References</h1>
<ul>
<li><a id="arora2009computational">[1]</a> Sanjeev Arora and Boaz Barak. <i>Computational complexity: a modern approach.</i> Cambridge University Press, 2009.</li>
<li><a id="nirkhe2018approximate">[2]</a> Chinmay Nirkhe, Umesh Vazirani,  and Henry Yuen. Approximate low-weight check codes and circuit lower bounds for noisy ground states. <i>arXiv preprint arXiv:1802.07419</i>, 2018.</li>
<li><a id="aharonov2017">[3]</a> Dorit Aharonov, Wim van Dam, Julia Kempe, Zeph Landau, Seth Lloyd, and Oded Regev. Adiabatic quantum computation is equivalent to standard quantum computation. <i>SIAM J. Comput.</i>, 2007.</li></ul></div>
    </content>
    <updated>2018-12-23T01:45:21Z</updated>
    <published>2018-12-23T01:45:21Z</published>
    <category term="physics"/>
    <author>
      <name>richardmwang</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6948</id>
    <link href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/" rel="alternate" type="text/html"/>
    <title>Quantum Approximate Optimization Algorithm and Applications</title>
    <summary>Motivation   Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Motivation</h2>
<p> </p>
<p>Quantum computers have demonstrated great potential for solving certain problems more efficiently than their classical counterpart. Algorithms based on the quantum Fourier transform (QFT) such as Shor’s algorithm offer an exponential speed-up, while amplitude-amplification algorithms such as Grover’s search algorithm provide us with a polynomial speedup. The concept of “quantum supremacy” (quantum computers outperforming classical computers) has been explored for three general groups of problems:</p>
<ol>
<li>Structured problems, such as factoring and discrete logarithm. Out quantum computer takes advantage of the structure of these classes of problems to offer an exponential speedup compared to the best known classical alternative. While these speedups are the most promising, they require a large number of resources and are cannot be feasibly implemented in the near future.</li>
<li>Quantum Simulations, originally proposed by Richard Feynman in the late 80s was thought to be the first motivation behind exploring quantum computation. Due to the fact that the space of all possible states of the system scales exponentially with the addition of a new element (eg. an atom), complex systems are very difficult to simulate classically. It has been shown that we can use a quantum computer to tackle interesting problems in quantum chemistry and chemical engineering. Furthermore, there are results on sampling the output of random quantum circuits which have been used for “quantum supremacy experiments”.</li>
<li>General constraint satisfaction and optimization problems. Since these problems are NP-hard it is widely believed that we cannot gain an exponential speedup using a quantum computer, however, we can obtain quadratic speedup but utilizing a variation of Grover’s algorithm.</li>
</ol>
<p>While these quantum algorithms are very exciting, they are beyond the capabilities of our near-term quantum computers; for example, any useful application of Shor’s factoring algorithm requires anywhere between tens of thousands to millions of qubits with error correction compared to quantum devices with hundreds of qubits that we might have available in the next few years.</p>
<p>Recently there has been increasing interest in hybrid classical-quantum algorithms among the community. The general idea behind this approach is to supplement the noisy intermediate-scale quantum (NISQ) devices with classical computers. In this blog post, we discuss the Quantum Approximate Optimization Algorithm (QAOA), which is a hybrid algorithm, alongside some of its applications.</p>
<h2>Introduction</h2>
<p>QAOA is used for optimizing combinatorial problems. Let’s assume a problem with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> bits and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> clauses. Each clause is a constraint on a subset of the bits which satisfies a certain assignment. We can define a cost function as follows:</p>
<p><img alt="C(z)=\sum_{\alpha=1}^m C_\alpha (z) " class="latex" src="https://s0.wp.com/latex.php?latex=C%28z%29%3D%5Csum_%7B%5Calpha%3D1%7D%5Em+C_%5Calpha+%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(z)=\sum_{\alpha=1}^m C_\alpha (z) "/></p>
<p>where <img alt="z=z_1z_2...z_n" class="latex" src="https://s0.wp.com/latex.php?latex=z%3Dz_1z_2...z_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z=z_1z_2...z_n"/> is the bit string. In this article we consider a minimization problem, therefore we want <img alt="C_\alpha(z)=0" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha%28z%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha(z)=0"/> if <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> satisfies clause <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> and 1 otherwise. Note that in the case of a maximization problem we only need to switch the value assigned to a satisfactory clause to 1. Our objective is to find a (qu)bit string that minimizes (or maximizes) our cost function.</p>
<p>At a higher level, we start with a quantum state in a uniform superposition of all possible inputs <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/>. This can be accomplished with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits which span a space of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>. Our goal is to come up with a series of operations that would evolve our initial quantum state into a superposition of states in which the valid solutions would have a significantly higher probability than other states. In manner, upon sampling the quantum state we are likely to get the correct solution with high probability. QAOA uses the cost function to construct a set of operations that would be able to efficiently map the unifrom superposition state into the desired quantum state. These operators involve single qubits rotations around the x-axis, and multiqubit rotations around the z-axis of our qubits.</p>
<p>Now let’s discuss the details of QAOA. For this algorithm we assume that our quantum computer works in the computation basis of <img alt="\left |0 \right &gt; , \left | 1 \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C0+%5Cright+%3E+%2C+%5Cleft+%7C+1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left |0 \right &gt; , \left | 1 \right &gt; "/>. We start by setting our initial state to a uniform superposition over computational basis states:</p>
<p><img alt="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7Cs+%5Cright+%3E+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5En%7D%7D%5Csum_%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%5Cleft+%7Cz+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left |s \right &gt; = \frac{1}{\sqrt{2^n}}\sum_{z \in \{0,1\}^n} \left |z \right &gt; "/></p>
<p>Next, we define a unitary operator using the cost function as follows:</p>
<p><img alt="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha}&#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=U%28%5Chat%7BC%7D%2C%5Cgamma%29+%3D+e%5E%7Bi%5Cgamma+%5Chat%7BC%7D%7D%3D+%5Cprod_%7B%5Calpha+%3D+1%7D%5Em+e%5E%7B-i%5Cgamma+%5Chat%7BC%7D_%5Calpha%7D%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(\hat{C},\gamma) = e^{i\gamma \hat{C}}= \prod_{\alpha = 1}^m e^{-i\gamma \hat{C}_\alpha}&#xA0;"/></p>
<p>Here we convert every clause <img alt="C_\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha"/> to a Hamiltonian <img alt="\hat{C_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}"/> consisting of Pauli Z ($\sigma^z$) operators. Just as a review, the two Pauli operators (X and Z) used in this blog post are representated as follows:</p>
<p><img alt="\sigma^x = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 0 &amp; 1 \\&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\&#xA0;&#xA0;&#xA0; 0 &amp; -1 \\\end{pmatrix} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ex+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+0+%26+1+%5C%5C%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%5Cend%7Bpmatrix%7D+%5C%3A+%5C%3A+%5C%3A+%5C%3A++%5Csigma%5Ez+%3D+%5Cbegin%7Bpmatrix%7D%C2%A0%C2%A0%C2%A0+1+%26+0+%5C%5C%C2%A0%C2%A0%C2%A0+0+%26+-1+%5C%5C%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma^x = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 0 &amp; 1 \\&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\\end{pmatrix} \: \: \: \:  \sigma^z = \begin{pmatrix}&#xA0;&#xA0;&#xA0; 1 &amp; 0 \\&#xA0;&#xA0;&#xA0; 0 &amp; -1 \\\end{pmatrix} "/></p>
<p>For example if <img alt="C_\alpha=x \oplus y" class="latex" src="https://s0.wp.com/latex.php?latex=C_%5Calpha%3Dx+%5Coplus+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_\alpha=x \oplus y"/> we can map the clause to <img alt="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D%3D%5Cfrac%7B1%7D%7B2%7D%281%2B%5Csigma%5Ez_x+%5Csigma%5Ez_y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}=\frac{1}{2}(1+\sigma^z_x \sigma^z_y)"/> for a minimization problem. If <img alt="x=\left |0 \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C0+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=\left |0 \right &gt; &#xA0;"/> , then <img alt="\sigma^z_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma%5Ez_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma^z_x"/> will return a value of 1, and if <img alt="x=\left |1 \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%5Cleft+%7C1+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=\left |1 \right &gt; "/> the operator will return -1. The same applies to qubit <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> as well. Therefore it is not hard to see that if <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> have the same value, then the operator <img alt="\hat{C_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC_%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C_\alpha}"/> as defined above will result in a 1, and it’ll result in 0 otherwise. Furthermore, since <img alt="\hat{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C}"/> has integer eigenvalues we can restrict the angle <img alt="\gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gamma"/> to lie in <img alt="[0,2\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C2%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,2\pi]"/>.</p>
<p>Next, we define the admixing Hamiltonian:</p>
<p><img alt="B=\sum_{j=1}^n \sigma^x_j " class="latex" src="https://s0.wp.com/latex.php?latex=B%3D%5Csum_%7Bj%3D1%7D%5En+%5Csigma%5Ex_j+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B=\sum_{j=1}^n \sigma^x_j "/></p>
<p>and use it to define a unitary operator which consists of a product of commuting one qubit operations:</p>
<p><img alt="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}&#xA0;&#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29+%3D+e%5E%7B-i%5Cbeta+B%7D%3D+%5Cprod_%7Bj%3D1%7D%5En+e%5E%7B-i+%5Cbeta+%5Csigma_j%5Ex%7D%C2%A0%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(B,\beta) = e^{-i\beta B}= \prod_{j=1}^n e^{-i \beta \sigma_j^x}&#xA0;&#xA0;"/></p>
<p>where <img alt="\beta \in [0,\pi]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cin+%5B0%2C%5Cpi%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta \in [0,\pi]"/>. It’s easy to see that <img alt="U(\Hat{C},\gamma)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28%5CHat%7BC%7D%2C%5Cgamma%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(\Hat{C},\gamma)"/> couples 2 or more qubits, while <img alt="U(B,\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28B%2C%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(B,\beta)"/> performs a single qubit rotation on the qubits in our system. Using these unitaries and our initial state we define a QAOA angle-dependent “ansatz” state as follows:</p>
<p><img alt="\left | &#xA0;\boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%C2%A0%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E%3D+U%28B%2C%5Cbeta_p%29U%28%5CHat%7BC%7D%2C%5Cgamma_p%29...U%28B%2C%5Cbeta_1%29U%28%5CHat%7BC%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | &#xA0;\boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;= U(B,\beta_p)U(\Hat{C},\gamma_p)...U(B,\beta_1)U(\Hat{C},\gamma_1) \left |s \right &gt; "/></p>
<p>Here <img alt="p\geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=p%5Cgeq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p\geq 1"/> is the “depth” of our QAOA circuit, and <img alt="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cgamma%7D%3D%28%5Cgamma_p%2C...%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boldsymbol{\gamma}=(\gamma_p,...,\gamma_1)"/>, <img alt="\boldsymbol{\beta}=(\beta_p,...,\beta_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cboldsymbol%7B%5Cbeta%7D%3D%28%5Cbeta_p%2C...%2C%5Cbeta_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\boldsymbol{\beta}=(\beta_p,...,\beta_1)"/> are each a vector of length <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> controlling the angles for each layer. In the worst case scenario this state can be produce by a quantum circuit of depth <img alt="mp+p" class="latex" src="https://s0.wp.com/latex.php?latex=mp%2Bp&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="mp+p"/>, however by taking advantage of the structure of the instance we can further reduce the number of layers required. Let <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> be the expectation of <img alt="\hat{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat{C}"/> in our ansatz:</p>
<p><img alt="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29%3D%5Cleft+%3C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%7C+%5Chat%7BC%7D+%5Cleft+%7C+%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\boldsymbol{\gamma},\boldsymbol{\beta})=\left &lt; \boldsymbol{\gamma},\boldsymbol{\beta} \right | \hat{C} \left | \boldsymbol{\gamma},\boldsymbol{\beta} \right &gt;  "/></p>
<p>and let <img alt="M_p" class="latex" src="https://s0.wp.com/latex.php?latex=M_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p"/> be the minimum of <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> over angles,</p>
<p><img alt="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  " class="latex" src="https://s0.wp.com/latex.php?latex=M_p%3D%5Cmin_%7B%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%7D+F_p%28%5Cboldsymbol%7B%5Cgamma%7D%2C%5Cboldsymbol%7B%5Cbeta%7D%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p=\min_{\boldsymbol{\gamma},\boldsymbol{\beta}} F_p(\boldsymbol{\gamma},\boldsymbol{\beta}).  "/></p>
<p>Note that minimization at <img alt="p-1" class="latex" src="https://s0.wp.com/latex.php?latex=p-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p-1"/> layers can be viewed as a constrained minimization at <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> layers, therefore</p>
<p><img alt="M_p \leq M_{p-1}  " class="latex" src="https://s0.wp.com/latex.php?latex=M_p+%5Cleq+M_%7Bp-1%7D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M_p \leq M_{p-1}  "/></p>
<p>Using an adiabatic approach [1] We can show that</p>
<p><img alt="\lim_{p \rightarrow \infty} M_p = \min_z C(z) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bp+%5Crightarrow+%5Cinfty%7D+M_p+%3D+%5Cmin_z+C%28z%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim_{p \rightarrow \infty} M_p = \min_z C(z) "/></p>
<p>Based on these results our QAOA algorithm will look like the following:</p>
<ul>
<li> c: pick a <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/></li>
<li>c: choose a set of angles <img alt="(\Vec{\gamma}_0,\Vec{\beta}_0)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D_0%2C%5CVec%7B%5Cbeta%7D_0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\Vec{\gamma}_0,\Vec{\beta}_0)"/></li>
<li>q: prepare <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/></li>
<li>q: compute <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/></li>
<li>c: perform gradient descend/ascend on <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> and get a new set of angles <img alt="(\Vec{\gamma},\Vec{\beta})" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\Vec{\gamma},\Vec{\beta})"/></li>
<li>repeat from step 3 till convergence</li>
<li>report the measurement result of <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/> in computational basis</li>
</ul>
<p>If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> does not asymptotically grow with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> <img alt="F_p(\Vec{\gamma},\Vec{\beta})" class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})"/> can be efficiently computed in <img alt="O(m^2+mn)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E2%2Bmn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(m^2+mn)"/></p>
<h2>Application: MaxCut</h2>
<p>In this section we apply the QAOA algorithm to the MaxCut problem with bounded degree. MaxCut is an NP-hard problem that asks for a subset <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of the vertex set such that the number of edges between <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> and the complementary subset is as large as possible. While QAOA does not offer a theoretical guarantee to solve MaxCut in polynomial time, it offers a path to utilizing NISQ devices for tackling such optimization problems and discuss patterns in such problems that can be used for reducing the number of steps required.</p>
<p>For this section, let’s assume <img alt="p=O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=p%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p=O(1)"/>, and we have a graph with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices and an edge set <img alt="\{&lt;jk&gt;\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%3Cjk%3E%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{&lt;jk&gt;\}"/> of size <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>. We can construct a cost function to be maximized as follows:</p>
<p><img alt="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} " class="latex" src="https://s0.wp.com/latex.php?latex=C+%3D+%5Csum_%7B%3Cjk%3E%7D+C_%7B%3Cjk%3E%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C = \sum_{&lt;jk&gt;} C_{&lt;jk&gt;} "/></p>
<p><img alt="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  " class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%281-%5Csigma%5Ez_j+%5Csigma%5Ez_k%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{&lt;jk&gt;} = \frac{1}{2} (1-\sigma^z_j \sigma^z_k)  "/></p>
<p>We can the compute the angle dependent cost of our ansatz as follows:</p>
<p><img alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_%7B%3Cjk%3E%7D%5Cleft+%3C%7Bs%7D+%5Cright+%7C+U%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29+%5Cleft+%7Cs+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_{&lt;jk&gt;}\left &lt;{s} \right | U^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1) \left |s \right &gt;  "/></p>
<p>Let’s consider the operation associated with some edge <img alt="&lt;jk&gt;" class="latex" src="https://s0.wp.com/latex.php?latex=%3Cjk%3E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&lt;jk&gt;"/>:</p>
<p><img alt="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  " class="latex" src="https://s0.wp.com/latex.php?latex=U+%5E%5Cdagger%28C%2C%5Cgamma_1%29...U%5E%5Cdagger%28B%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B%2C%5Cbeta_p%29+...+U%28C%2C%5Cgamma_1%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U ^\dagger(C,\gamma_1)...U^\dagger(B,\beta_p) C_{&lt;jk&gt;}U(B,\beta_p) ... U(C,\gamma_1)  "/></p>
<p>Since QAOA consists of local operations, we may take advantage by thinking about the problem in terms of subproblems (or subgraphs) involving certain nodes. This property will allow us to simplify our clauses even further depending on the desired depth <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> of our quantum circuit, therefore decreasing the amount of resources necessary to implement the algorithm.</p>
<p>The operator <img alt="C_{&lt;jk&gt;}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7B%3Cjk%3E%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{&lt;jk&gt;}"/> includes qubits (nodes) <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>, therefore the sequence of operators above will only involve qubits that are at most distance <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> away from qubits <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> and <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. Let’s consider the example of <img alt="p=1" class="latex" src="https://s0.wp.com/latex.php?latex=p%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p=1"/>:</p>
<p><img alt="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crightarrow+U%5E%5Cdagger%28C%2C%5Cgamma_1%29e%5E%7Bi%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+C_%7B%3Cjk%3E%7D+e%5E%7B-i%5Cbeta_1%28%5Csigma%5Ex_j+%2B+%5Csigma%5Ex_k%29%7D+U%28C%2C%5Cgamma_1%29.++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rightarrow U^\dagger(C,\gamma_1)e^{i\beta_1(\sigma^x_j + \sigma^x_k)} C_{&lt;jk&gt;} e^{-i\beta_1(\sigma^x_j + \sigma^x_k)} U(C,\gamma_1).  "/></p>
<p>It’s easy to see that any factor of <img alt="U(C,\gamma_1)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28C%2C%5Cgamma_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(C,\gamma_1)"/> that does not depend on <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> or <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> will commute through and cancel out. Since the degree is bounded, each subgraph contains a number of qubits that is independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, which allows for the evaluation of <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> in terms of subsystems of size independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>.</p>
<p>For an subgraph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> define:</p>
<p><img alt="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}&#xA0; \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} " class="latex" src="https://s0.wp.com/latex.php?latex=C_G%3D%5Csum_%7B%3Cl+l%5E%5Cprime%3E%7D+C_%7B%3Cl+l%5E%5Cprime%3E%7D%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28C_G%2C%5Cgamma%29%3De%5E%7B-i+%5Cgamma+C_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_G=\sum_{&lt;l l^\prime&gt;} C_{&lt;l l^\prime&gt;}&#xA0; \: \: \: \: U(C_G,\gamma)=e^{-i \gamma C_G} "/></p>
<p><img alt="B_G = \sum_{j \in G} \sigma^x_j&#xA0; \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} " class="latex" src="https://s0.wp.com/latex.php?latex=B_G+%3D+%5Csum_%7Bj+%5Cin+G%7D+%5Csigma%5Ex_j%C2%A0+%5C%3A+%5C%3A+%5C%3A+%5C%3A+U%28B_G%2C%5Cbeta%29+%3D+e%5E%7B-i+%5Cbeta+B_G%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B_G = \sum_{j \in G} \sigma^x_j&#xA0; \: \: \: \: U(B_G,\beta) = e^{-i \beta B_G} "/></p>
<p><img alt="\left | s,G \right &gt; &#xA0;&#xA0;= \prod_{l \in G} \left |+ \right &gt; _l  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+s%2CG+%5Cright+%3E+%C2%A0%C2%A0%3D+%5Cprod_%7Bl+%5Cin+G%7D+%5Cleft+%7C%2B+%5Cright+%3E+_l++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | s,G \right &gt; &#xA0;&#xA0;= \prod_{l \in G} \left |+ \right &gt; _l  "/></p>
<p>We can define our total cost as a sum over the cost of each subgraph:</p>
<p><img alt="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |&#xA0; U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  " class="latex" src="https://s0.wp.com/latex.php?latex=f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Cleft+%3C+s%2Cg%28j%2Ck%29+%5Cright+%7C%C2%A0+U+%5E%5Cdagger%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29...U%5E%5Cdagger%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+C_%7B%3Cjk%3E%7DU%28B_%7Bg%28j%2Ck%29%7D%2C%5Cbeta_p%29+...+U%28C_%7Bg%28j%2Ck%29%7D%2C%5Cgamma_1%29+%5Cleft+%7Cs%2Cg%28j%2Ck%29+%5Cright+%3E++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_g(\Vec{\gamma},\Vec{\beta})=\left &lt; s,g(j,k) \right |&#xA0; U ^\dagger(C_{g(j,k)},\gamma_1)...U^\dagger(B_{g(j,k)},\beta_p) C_{&lt;jk&gt;}U(B_{g(j,k)},\beta_p) ... U(C_{g(j,k)},\gamma_1) \left |s,g(j,k) \right &gt;  "/></p>
<p>where <img alt="g(j,k)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28j%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(j,k)"/> is a subgraph of type <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> and “…” is used to omit the sequence of angle depending unitaries constructed using the elements of <img alt="\Vec{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Vec{\gamma}"/> and <img alt="\Vec{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CVec%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Vec{\beta}"/>. <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> is then</p>
<p><img alt="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  " class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29%3D%5Csum_g+w_g+f_g%28%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%29++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\Vec{\gamma},\Vec{\beta})=\sum_g w_g f_g(\Vec{\gamma},\Vec{\beta})  "/></p>
<p>where <img alt="w_g" class="latex" src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_g"/> is the number of occurrence of the subgraph <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> in the original edge sum. The function <img alt="f_g" class="latex" src="https://s0.wp.com/latex.php?latex=f_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_g"/> does not depend on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>, and the only dependence on these variables comes through the weights <img alt="w_g" class="latex" src="https://s0.wp.com/latex.php?latex=w_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w_g"/> from the original graph. The maximum number of qubits that can appear in our sequence of operators comes when the subgraph is a tree. For a graph with maximum degree <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, the number of qubits in this tree is</p>
<p><img alt="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  " class="latex" src="https://s0.wp.com/latex.php?latex=q_%7Btree%7D%3D2%5B%5Cfrac%7B%28v-1%29%5E%7Bp%2B1%7D-1%7D%7B%28v-1%29-1%7D%5D++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q_{tree}=2[\frac{(v-1)^{p+1}-1}{(v-1)-1}]  "/></p>
<p>(or <img alt="2p+2" class="latex" src="https://s0.wp.com/latex.php?latex=2p%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2p+2"/> if <img alt="v=2" class="latex" src="https://s0.wp.com/latex.php?latex=v%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v=2"/>), which is independent of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> and <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>. Therefore we can see that for constant <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> <img alt="F_p" class="latex" src="https://s0.wp.com/latex.php?latex=F_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p"/> can be efficiently computed.</p>
<p>Next, let’s consider the spread of C measured in the state <img alt="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \Vec{\gamma},\Vec{\beta} \right &gt; &#xA0;"/>.</p>
<p><img alt="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt; &#xA0;-\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%3C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C%5E2%5Cleft+%7C%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D%5Cright+%3E+%C2%A0-%5Cleft+%3C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%7C+C+%5Cleft+%7C+%5CVec%7B%5Cgamma%7D%2C%5CVec%7B%5Cbeta%7D+%5Cright+%3E+%5E2+%5Cleq+2%5B%5Cfrac%7B%28v-1%29%5E%7B2p%2B2%7D-1%7D%7B%28v-1%29-1%7D%5D.m++&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left &lt;\Vec{\gamma},\Vec{\beta} \right | C^2\left |\Vec{\gamma},\Vec{\beta}\right &gt; &#xA0;-\left &lt; \Vec{\gamma},\Vec{\beta} \right | C \left | \Vec{\gamma},\Vec{\beta} \right &gt; ^2 \leq 2[\frac{(v-1)^{2p+2}-1}{(v-1)-1}].m  "/></p>
<p>For fixed <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> we see that the standard deviation of <img alt="C(z)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28z%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(z)"/> is upper-bounded by <img alt="O(\sqrt{m})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bm%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\sqrt{m})"/>. Using this fact and the appropriate probability bounds we can see that the result of measuring the cost function of the state <img alt="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt; &#xA0;" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft+%7C+%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2Cvec%7B%5Cbeta_%7Bopt%7D%7D+%5Cright+%3E+%C2%A0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left | \vec{\gamma_{opt}},vec{\beta_{opt}} \right &gt; &#xA0;"/> will be very close to the intended value of <img alt="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})" class="latex" src="https://s0.wp.com/latex.php?latex=F_p%28%5Cvec%7B%5Cgamma_%7Bopt%7D%7D%2C%5Cvec%7B%5Cbeta_%7Bopt%7D%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="F_p(\vec{\gamma_{opt}},\vec{\beta_{opt}})"/> which bounds the uncertainty present in quantum measurement.</p>
<h2>Bibliography</h2>
<p>[1] E. Farhi, J. Goldstone, and S. Gutmann, “A Quantum Approximate Optimization Algorithm,” 2014.</p>
<p>[2] J. S. Otterbach, et. al, “Unsupervised Machine Learning on a Hybrid Quantum Computer,” 2017.</p></div>
    </content>
    <updated>2018-12-22T23:36:23Z</updated>
    <published>2018-12-22T23:36:23Z</published>
    <category term="physics"/>
    <author>
      <name>karamlou</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15529</id>
    <link href="https://rjlipton.wordpress.com/2018/12/21/explanations-and-explorations/" rel="alternate" type="text/html"/>
    <title>Explanations and Explorations</title>
    <summary>Comparing proofs for the Jaccard metric BetterExplained source Kalid Azad is the founder of the website Better Explained. It is devoted to explaining mathematical concepts. He also has written two books. Today we discuss how some proofs provide a concise explanation whereas others promote exploration of related concepts. Azad’s site has a rich page titled, […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Comparing proofs for the Jaccard metric</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg"><img alt="" class="alignright wp-image-15530" height="158" src="https://rjlipton.files.wordpress.com/2018/12/KalidAzad.jpg?w=142&amp;h=158" width="142"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">BetterExplained <a href="https://betterexplained.com/about/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Kalid Azad is the founder of the <a href="https://betterexplained.com/">website</a> <em>Better Explained</em>. It is devoted to explaining mathematical concepts. He also has written <a href="https://betterexplained.com/ebook/math/">two</a> <a href="https://www.amazon.com/gp/product/B017ZXWY3U/">books</a>. </p>
<p>
Today we discuss how some proofs provide a concise <em>explanation</em> whereas others promote <em>exploration</em> of related concepts.<br/>
<span id="more-15529"/></p>
<p>
Azad’s site has a rich <a href="https://betterexplained.com/articles/proofs-vs-explanations/">page</a> titled, “Math Proofs vs. Explanations (aka Nutrition vs. Taste).” It argues that the best <em>explanations</em> start with an analogy to a relation that readers already understand. Even if the connection is not sharp, it can be refined once the reader’s attention is solid. This is opposed to a formal proof in which every step is sharp and correct but intuition is wanting.</p>
<p>
To this we add the role proofs can play in <em>exploration</em>. If you have one proof of a theorem that you understand, there is value in seeking other proofs that use other ideas. Usually we think of ideas as coming first—as thoughts we refine into a proof. The advantage of starting with a proof is already having certitude and sharpness—you know a recipe that works and now can try varying and augmenting it. </p>
<p>
</p><p/><h2> Jaccard Distance as Example </h2><p/>
<p/><p>
Azad’s page gives examples of proofs for the Pythagorean Theorem and for <img alt="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%7D+%3D+%5Ccos%28%5Ctheta%29+%2B+i%5Csin%28%5Ctheta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{i\theta} = \cos(\theta) + i\sin(\theta)}"/>. It then quotes from William Thurston’s <a href="http://arxiv.org/abs/math/9404236">essay</a> “On Proofs and Progress in Mathematics,” which we once <a href="https://rjlipton.wordpress.com/2014/09/18/lets-mention-foundations/">mentioned</a>. We will use the example of Jaccard distance <img alt="{J_\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta}"/> from our previous <a href="https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/">post</a>. We start with this definition: </p>
<p align="center"><img alt="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CB%29+%3D+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  J_\delta(A,B) = \frac{|A \;\Delta\; B|}{|A \cup B|}, "/></p>
<p>now using <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> for the symmetric difference <img alt="{(A \cup B) \setminus (A \cap B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Ccup+B%29+%5Csetminus+%28A+%5Ccap+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A \cup B) \setminus (A \cap B)}"/>. So the triangle inequality becomes, for any finite sets <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/>: <a name="triangle"/></p><a name="triangle">
<p align="center"><img alt="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CA+%5Ccup+C%7C%7D+%5Cleq+%5Cfrac%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D%7B%7CA+%5Ccup+B%7C%7D+%2B+%5Cfrac%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D%7B%7CB+%5Ccup+C%7C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{|A \;\Delta\; C|}{|A \cup C|} \leq \frac{|A \;\Delta\; B|}{|A \cup B|} + \frac{|B \;\Delta\; C|}{|B \cup C|}. \ \ \ \ \ (1)"/></p>
</a><p><a name="triangle"/> We think the proof we gave in the last post is simple and direct and intuitive but maybe not explorative. It first connects the solid understanding that without the denominators this would be the well-known triangle inequality for Hamming distance. To reprise, it considers <img alt="{A,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,C}"/> fixed and varies <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to arrive at that simpler fact in three steps:</p>
<ol>
<li>
If <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> contains <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> elements not in <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/> then removing them subtracts <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> from both right-hand numerators and both right-hand denominators. Since those fractions are each <img alt="{&lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt; 1}"/> (else <a href="https://rjlipton.wordpress.com/feed/#triangle">1</a> would be immediately true), the right-hand side goes down. <p/>
</li><li>
Then we have <img alt="{B \subseteq A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq A \cup C}"/> and can replace the denominators by <img alt="{|A \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup C|}"/> without increasing the right-hand side. <p/>
</li><li>
Now we have a common denominator and a statement equivalent to the known truth about Hamming distance. Since undoing the first two steps to restore the original <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> can only increase the right-hand side, (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is proved in all cases.
</li></ol>
<p>
This reasoning readily extends to nonnegative measures <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/> besides simple counting, provided the removal of elements from <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> makes the same additive-or-proportional change to <img alt="{f(A \;\Delta\; B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5C%3B%5CDelta%5C%3B+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(A \;\Delta\; B)}"/> as it does to <img alt="{f(A \cup B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28A+%5Ccup+B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(A \cup B)}"/>, and likewise for the other fraction. </p>
<p>
</p><p/><h2> Three Snapshot Proofs </h2><p/>
<p/><p>
The first short proof should join the pantheon of half-page journal papers. Under fair use, here it is in one screenshot:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png"><img alt="" class="aligncenter wp-image-15547" height="410" src="https://rjlipton.files.wordpress.com/2018/12/GilbertProof1972b.png?w=295&amp;h=410" width="295"/></a></p>
<p>
Perhaps this is <i>too</i> short. We think this proof would have been more satisfying if a few more lines of calculation had been added. Let us divide the region <img alt="{T_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_1}"/> into its inner part <img alt="{T_{1i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B1i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{1i}}"/> and outer part <img alt="{T_{1o}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B1o%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{1o}}"/> and do likewise for <img alt="{T_2,T_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_2%2CT_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_2,T_3}"/>. Then it seems the intent was: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++d%28S_1%2CS_3%29+%26%3D%26+1+-+%5Cfrac%7B%7CS_1+%5Ccap+S_3%7C%7D%7B%7CS_1+%5Ccup+S_3%7C%7D++%3D+1+-+%5Cfrac%7B%7CT_%7B2i%7D%7C+%2B+%7CV%7C%7D%7B%7CU%7C+-+%7CT_%7B2o%7D%7C%7D%5C%5C+%26%5Cleq%26+1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CU%7C+-+%7CV%7C%7D%7B%7CU%7C%7D+%3D+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C%7D%5C%5C+%26%5Cleq%26+%5Cfrac%7B%7CT_1%7C+%2B+%7CT_2%7C%7D%7B%7CU%7C+-+%7CT_%7B3o%7D%7C%7D+%2B+%5Cfrac%7B%7CT_2%7C+%2B+%7CT_3%7C%7D%7B%7CU%7C+-+%7CT_%7B1o%7D%7C%7D+%3D+d%28S_1%2CS_2%29+%2B+d%28S_2%2CS_3%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  d(S_1,S_3) &amp;=&amp; 1 - \frac{|S_1 \cap S_3|}{|S_1 \cup S_3|}  = 1 - \frac{|T_{2i}| + |V|}{|U| - |T_{2o}|}\\ &amp;\leq&amp; 1 - \frac{|V|}{|U|} = \frac{|U| - |V|}{|U|} = \frac{|T_1| + |T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U|} + \frac{|T_2| + |T_3|}{|U|}\\ &amp;\leq&amp; \frac{|T_1| + |T_2|}{|U| - |T_{3o}|} + \frac{|T_2| + |T_3|}{|U| - |T_{1o}|} = d(S_1,S_2) + d(S_2,S_3). \end{array} "/></p>
<p>The end uses the symmetric-difference definition of <img alt="{J_{\delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_{\delta}}"/>, so perhaps fully expanding this paper’s intent would have been longer. One can also begin with that definition to get a shorter calculation, but it skips over the <img alt="{1 - \frac{|V|}{|U|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B%7CV%7C%7D%7B%7CU%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 - \frac{|V|}{|U|}}"/> step. Indeed, it does not mention <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> at all, so it was not intended. The proof by Artur Grygorian and Ionut Iacob in a short <a href="https://www.tandfonline.com/doi/abs/10.1080/07468342.2018.1526020">paper</a> in last October’s <em>College J. Math.</em> strikes us as a similar-style proof. </p>
<p>
The second proof comes from a MathOverflow <a href="https://mathoverflow.net/q/315845">thread</a>. It assigns a variable to each region of the Venn diagram, forms the fractions, and cross-multiplies to obtain “the following monstrosity”:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg"><img alt="" class="aligncenter wp-image-15532" height="232" src="https://rjlipton.files.wordpress.com/2018/12/JaccardEquation.jpg?w=400&amp;h=232" width="400"/></a></p>
<p>
The fact that no coefficient is negative completes the proof. This is clear from a computer algebra system, but what about <em>why</em> no negative term appears? </p>
<p>
We have realized since the last post that the second of two proofs given in the 2016 <a href="https://arxiv.org/pdf/1612.02696.pdf">paper</a> by Sven Kosub, which we linked in that post, is really equivalent to ours. This is easier to see if one just presumes <img alt="{f(\emptyset) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(\emptyset) = 0}"/> in the following:</p>
<p><a href="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png"><img alt="" class="aligncenter wp-image-15533" height="360" src="https://rjlipton.files.wordpress.com/2018/12/KosubProof.png?w=500&amp;h=360" width="500"/></a></p>
<p>
Here <em>sub-modularity</em> is a standard property for which Kosub cites the equivalent condition that whenever <img alt="{B \subseteq D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq D}"/> and <img alt="{x \notin D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cnotin+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \notin D}"/>, </p>
<p align="center"><img alt="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28B+%5Ccup%5C%7Bx%5C%7D%29+-+f%28B%29+%5Cgeq+f%28D+%5Ccup+%5C%7Bx%5C%7D%29+-+f%28D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f(B \cup\{x\}) - f(B) \geq f(D \cup \{x\}) - f(D). "/></p>
<p>This suffices for step 1 of our earlier proof, first taking <img alt="{D = A \cup B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+A+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = A \cup B}"/> then <img alt="{D = B \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+B+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = B \cup C}"/>; the rest of that proof needs only that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is monotone (and implicitly <img alt="{f(\emptyset) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cemptyset%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(\emptyset) = 0}"/>). </p>
<p>
</p><p/><h2> A Magical Proof </h2><p/>
<p/><p>
Now we look at proofs that add ideas. The first one still strikes us as clean and magical. We are computer scientists so it is natural to think of finite sets as binary-valued vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. They have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in position <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> precisely when <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> is in the set. Of course <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the size of the “universe.” </p>
<p>
Now let <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> be such a non-zero vector. The key is to use a probabilistic proof. We will show that we can relate the Jaccard distance to the outcome of a simple random experiment. The experiment once selected leads to a simple proof—it only requires the union bound. Recall this is the fact that 	</p>
<p align="center"><img alt="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%5BE_%7B1%7D+%5Cvee+E_%7B2%7D%5D+%5Cle+P%5BE_%7B1%7D%5D+%2BP%5BE_%7B2%7D%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P[E_{1} \vee E_{2}] \le P[E_{1}] +P[E_{2}], "/></p>
<p>for any two events <img alt="{E_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_{1}}"/> and <img alt="{E_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_{2}}"/>. </p>
<p>
The cool idea is to look at the permutations of the vector <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. For a permutation <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> let us define <img alt="{\pi(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi(X)}"/> to be 	</p>
<p align="center"><img alt="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_%7B%5Cpi%281%29%7D%2C%5Ccdots%2Cx_%7B%5Cpi%28n%29%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x_{\pi(1)},\cdots,x_{\pi(n)}. "/></p>
<p>Let <img alt="{\mathsf{first}(X)=i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28X%29%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(X)=i}"/> provided <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is the first value that is equal to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Of course since <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is non-empty it follows that this is well defined. </p>
<p>
Note <img alt="{\mathsf{first}(\pi(X))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X))}"/> is a random variable that depends on the choice of the permutation <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/>. The key is to see that the probability that <img alt="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29%3D%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X))=\mathsf{first}(\pi(Y))}"/> when we average over all permutations uniformly is equal to 	</p>
<p align="center"><img alt="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%7CX+%5Ccap+Y%7C%7D%7B%7CX+%5Ccup+Y%7C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{|X \cap Y|}{|X \cup Y|}. "/></p>
<p>This follows by noting that there are <img alt="{|XY|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CXY%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|XY|}"/> ways to select the same <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and there are <img alt="{|X \cup Y|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CX+%5Ccup+Y%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|X \cup Y|}"/> total ways to select an <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. Complementing gives us that the probability of <img alt="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%28%5Cpi%28X%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28Y%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}(\pi(X)) \neq \mathsf{first}(\pi(Y))}"/> equals <img alt="{J_\delta(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta(X,Y)}"/>.</p>
<p>
Now hark back to our sets <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/>. The event </p>
<p align="center"><img alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(C)) "/></p>
<p>is subsumed by the disjunction of events </p>
<p align="center"><img alt="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bfirst%7D%28%5Cpi%28A%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cvee+%5Cmathsf%7Bfirst%7D%28%5Cpi%28B%29%29+%5Cneq+%5Cmathsf%7Bfirst%7D%28%5Cpi%28C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{first}(\pi(A)) \neq \mathsf{first}(\pi(B)) \vee \mathsf{first}(\pi(B)) \neq \mathsf{first}(\pi(C)) "/></p>
<p>regardless of what <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> is. By the simple union bound, the probability of the first event is at most the sum of the probabilities of the latter two events. We have thus proved </p>
<p align="center"><img alt="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J_%5Cdelta%28A%2CC%29+%5Cleq+J_%5Cdelta%28A%2CB%29+%2B+J_%5Cdelta%28B%2CC%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  J_\delta(A,C) \leq J_\delta(A,B) + J_\delta(B,C). "/></p>
<p>
The last step is the same as in the proof that Hamming distance is a metric. What does the randomized view gain us? It gains a nice interpretation of <img alt="{J_\delta(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ_%5Cdelta%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J_\delta(A,B)}"/> as the probability that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> hash to different values under the <em>min-hash</em> function <img alt="{\mathsf{first}\circ\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bfirst%7D%5Ccirc%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{first}\circ\pi}"/> for random <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/>. Min-hashing is used all the time—see this <a href="http://infolab.stanford.edu/~ullman/mmds/ch3.pdf">book chapter</a> by Jure Leskovec, Anand Rajaraman, and Jeffrey Ullman, with this proof in section 3.3.3. 		 </p>
<p/><h2> A Gradient Idea </h2><p/>
<p/><p>
Atri Rudra suggested to us the “game” of adjusting <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> one element at a time to walk it toward an extreme value. The sets <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> can be adjusted too. We start by assuming the triangle inequality (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) is false and make moves that can only keep it that way, until we reach a case where it is obviously true. </p>
<p>
Step 1 of our proof already plays this game by removing from <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> any elements not in <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/>. So we really start the game with <img alt="{B \subseteq A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Csubseteq+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B \subseteq A \cup C}"/> and we want to walk it to <img alt="{B = A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+A+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B = A \cup C}"/>. Simply replacing the denominators <img alt="{|A \cup B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup B|}"/> and <img alt="{|B \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \cup C|}"/> in (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) by <img alt="{|A \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \cup C|}"/> was good in step 2 of the proof but is not a legal move in this game. </p>
<p>
What we can do legally is add elements from <img alt="{A \cap C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cap C}"/> to <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>: those leave the denominators unchanged but lower the numerators <img alt="{|A \;\Delta\; B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \;\Delta\; B|}"/> and <img alt="{|B \;\Delta\; C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \;\Delta\; C|}"/>. The interesting case is when we want to add to <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> an element from <img alt="{A \setminus C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Csetminus+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \setminus C}"/> or from <img alt="{C \setminus A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Csetminus+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \setminus A}"/>. The former add decreases the numerator <img alt="{|A \;\Delta\; B|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA+%5C%3B%5CDelta%5C%3B+B%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|A \;\Delta\; B|}"/> and increases the denominator <img alt="{|B \cup C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5Ccup+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \cup C|}"/> while leaving <img alt="{A \cup B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup B}"/> unchanged, but it <em>increases</em> the numerator <img alt="{|B \;\Delta\; C|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CB+%5C%3B%5CDelta%5C%3B+C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|B \;\Delta\; C|}"/>. Let us abstract the right-hand side of (<a href="https://rjlipton.wordpress.com/feed/#triangle">1</a>) to <img alt="{\frac{p}{q} + \frac{r}{s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{p}{q} + \frac{r}{s}}"/>. Then the former add converts it to </p>
<p align="center"><img alt="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+%5Cqquad%5Ctext%7Band+the+latter+add+to%7D%5Cqquad+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p-1}{q} + \frac{r+1}{s+1} \qquad\text{and the latter add to}\qquad \frac{p+1}{q+1} + \frac{r-1}{s}. "/></p>
<p>If <em>both</em> moves increase the right-hand side, then we must have </p>
<p align="center"><img alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp-1%7D%7Bq%7D+%2B+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D%2C+%5Cquad%5Ctext%7Bso%7D%5Cquad+%5Cfrac%7B1%7D%7Bq%7D+%3C+%5Cfrac%7Br%2B1%7D%7Bs%2B1%7D+-+%5Cfrac%7Br%7D%7Bs%7D+%3D+%5Cfrac%7Bs-r%7D%7Bs%28s%2B1%29%7D+%3C+%5Cfrac%7B1%7D%7Bs%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p-1}{q} + \frac{r+1}{s+1}, \quad\text{so}\quad \frac{1}{q} &lt; \frac{r+1}{s+1} - \frac{r}{s} = \frac{s-r}{s(s+1)} &lt; \frac{1}{s+1}. "/></p>
<p>And from </p>
<p align="center"><img alt="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bp%7D%7Bq%7D+%2B+%5Cfrac%7Br%7D%7Bs%7D+%3C+%5Cfrac%7Bp%2B1%7D%7Bq%2B1%7D+%2B+%5Cfrac%7Br-1%7D%7Bs%7D%2C+%5Cquad%5Ctext%7Bwe+get%7D%5Cquad+%5Cfrac%7B1%7D%7Bs%7D+%3C+%5Cfrac%7B1%7D%7Bq%2B1%7D%5C%3B.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{p}{q} + \frac{r}{s} &lt; \frac{p+1}{q+1} + \frac{r-1}{s}, \quad\text{we get}\quad \frac{1}{s} &lt; \frac{1}{q+1}\;. "/></p>
<p>But cross-multiplying gives the contradiction <img alt="{q+ 1 &lt; s &lt; s+1 &lt; q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%2B+1+%3C+s+%3C+s%2B1+%3C+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q+ 1 &lt; s &lt; s+1 &lt; q}"/>. So one or both moves must always be possible. This grows <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> to include either all of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> or all of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The rest of the argument to gobble up all of <img alt="{A \cup C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ccup+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \cup C}"/> we leave to you, dear readers.</p>
<p>
Compared to the above proofs, this is tedious. But it captures some tensions among the sizes of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>, <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>, and <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> that may inform intuitions about Jaccard similarity under changes in the sets. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Which proof do you like best for explanation and which for creative impulse? </p>
<p>
This is our <img alt="{801^{st}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B801%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{801^{st}}"/> post. We intended this discussion as number 800 but were surprised to find the simple proof by reduction to triangle for Hamming distance (steps numbered 1-2-3 above). Are we really the first to write it down, with acknowledgment also to Kosub?</p>
<p>
[some typo fixes]</p></font></font></div>
    </content>
    <updated>2018-12-22T01:59:19Z</updated>
    <published>2018-12-22T01:59:19Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="trick"/>
    <category term="Better Explained"/>
    <category term="explanations"/>
    <category term="exploration"/>
    <category term="ideas"/>
    <category term="Jaccard metric"/>
    <category term="Kalid Azad"/>
    <category term="triangle inequality"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2018-12-31T12:22:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6524</id>
    <link href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/" rel="alternate" type="text/html"/>
    <title>Tensor Networks, Matrix Product States and Density Matrix Renormalization Group</title>
    <summary>In this note, we introduce the notions of tensor networks and matrix product states (MPS). These objects are particularly useful in describing quantum states of low entanglement.

We then discuss how to efficiently compute the ground states of the Hamiltonians of 1D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>by Fred Zhang</strong></p>
<p><em>This is the second installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given by the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. For the basic definitions of local Hamiltonians, see <a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">Ben’s first post</a>. Also check out <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">Boriana and Prayaag’s followup note</a> on area laws.</em></p>
<p>This post introduces tensor networks and matrix product states (MPS). These are useful linear-algebraic objects for describing quantum states of low entanglement.</p>
<p>We then discuss how to efficiently compute the ground states of the Hamiltonians of <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{1}"/>D quantum systems (using classical computers). The density matrix renormalization group (DMRG), due to White (1992, 1993), is arguably the most successful heuristic for this problem. We describe it in the language of tensor networks and MPS.</p>
<p><b>1. Introduction </b></p>
<p class="p1">We are interested in computing the ground state—the minimum eigenvector—of a quantum Hamiltonian, a <img alt="2^n \times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n \times 2^n"/> complex matrix that governs the evolution of a quantum system of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits. We restrict our attention to the local Hamiltonian, where the matrix is a sum of Hamiltonians each acting only on <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> qubits.  In the previous article, we discussed some hardness results. Namely, a local Hamiltonian can be used to encode SAT instances, and we further gave a proof that computing the ground state is QMA-Complete.</p>
<p>Despite the hardness results, physicists have come up with a variety of heuristics for solving this problem. If quantum interactions occur locally, we would hope that its ground state has low entanglement and thus admits a succinct classical representation. Further, we hope to find such a representation efficiently, using classical computers.</p>
<p>In this note, we will see <i>tensor networks</i> and <i>matrix product states</i> that formalize the idea of succinctly representing quantum states of low entanglement. As a side remark for the theoretical computer scientists here, one motivation to study tensor network is that it provides a powerful visual tool for thinking about linear algebra. It turns indices into edges in a graph and summations over indices into contractions of edges. In particular, we will soon see that the most useful inequality in TCS and mathematics can be drawn as a cute tensor network.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6535" style="width: 276px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note0x.png"><img alt="" class="wp-image-6535 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600"/></a><p class="wp-caption-text">Guess what this is?</p></div><p/>
<p>In the end, we will discuss the density matrix renormalization group (DMRG), which has established itself as “the most powerful tool for treating 1D quantum systems” over the last decade [<a href="https://windowsontheory.org/feed/#Xfehske2007computational">FSW07</a>]. For many 1D systems that arise from practice, the heuristic efficiently finds an (approximate) ground state in its matrix product state, specified only by a small number of parameters.</p>
<p><b>2. Tensor Networks </b></p>
<p>Now let us discuss our first subject, <i>tensor networks</i>. If you have not seen <i>tensors</i> before, it is a generalization of matrices. In computer scientists’ language, a matrix is a two-dimensional array, and a tensor is a multi-dimensional array. In other words, if we think of a matrix as a square, then a 3 dimensional tensor looks like a cube. Formally, a (complex) n dimensional tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{T}"/> maps <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> indices to complex values, namely, to its entries:</p>
<p align="center"><img alt="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T+%3A+%5Bd_1%5D+%5Ctimes+%5Bd_2%5D+%5Ctimes+%5Ccdots+%5Ctimes+%5Bd_n%5D+%5Crightarrow+%5Cmathbb%7BC%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle T : [d_1] \times [d_2] \times \cdots \times [d_n] \rightarrow \mathbb{C}."/></p>
<p>The simplest tensor network is a graphical notation for a tensor. For an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{n}"/>-dimensional tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, we draw a star graph and label the center as <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> and the edges as the indices. To evaluate this tensor network, we put values on the edges, <i>i.e.</i>, indices, and then the tensor network would spit out its entry specified by the indices.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6550" style="width: 170px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note2x.png"><img alt="" class="wp-image-6550 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note2x.png?w=600"/></a><p class="wp-caption-text">A simple tensor network of 4 dimensions <a name="figsimp-1"/></p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6551" style="width: 354px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note3x.png"><img alt="" class="wp-image-6551 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note3x.png?w=600"/></a><p class="wp-caption-text">Evaluating a simple tensor network, <img alt="{T(1,5,3,1)=1/\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%281%2C5%2C3%2C1%29%3D1%2F%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(1,5,3,1)=1/\sqrt{2}}"/>. The numbers are chosen arbitrarily.<a name="figsimp-2"/></p></div><p/>
<p>Notice that the degree of the center is the number of indices. Hence, a tensor network of degree <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> is a vector, and that of degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> is a matrix, and so forth.<a name="figsimple-tn"/></p>
<p/><div class="wp-caption aligncenter" id="attachment_6574" style="width: 34px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note6x.png"><img alt="" class="wp-image-6574 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note6x.png?w=600"/></a><p class="wp-caption-text">A vector</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6575" style="width: 106px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note7x.png"><img alt="" class="wp-image-6575 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note7x.png?w=600"/></a><p class="wp-caption-text">A matrix</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6576" style="width: 158px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note8x.png"><img alt="" class="wp-image-6576 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note8x.png?w=600"/></a><p class="wp-caption-text">A 3d tensor</p></div><p/>
<p>How is this related to quantum information? For the sake of genearlity we will deal with qudits in <img alt="{\mathbb{C}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb{C}^d}"/>, instead of qubits in <img alt="{\mathbb{C}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb{C}^2}"/>. Now recall that a quantum state <img alt="{|\psi_n\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi_n%5Crangle%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{|\psi_n\rangle}"/> of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{n}"/> qudits can be encoded as an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> dimensional tensor. It can be written as</p>
<p style="text-align: center;"><img alt="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_n%5Crangle+%3D+%5Cdisplaystyle%5Csum_%7Bi_1%2C%5Ccdots%2Ci_n+%3D+0%7D%5E%7Bd-1%7D+T%28i_1%2C%5Ccdots%2C+i_n%29+%7Ci_1%2C%5Ccdots%2C+i_n+%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_n\rangle = \displaystyle\sum_{i_1,\cdots,i_n = 0}^{d-1} T(i_1,\cdots, i_n) |i_1,\cdots, i_n \rangle."/></p>
<p>It is easy to see that all the information, namely, the amplitudes, is just the tensor <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. In the later sections, we will see more powerful examples of using tensor networks to represent a quantum state.</p>
<p>So far our discussion is focused merely on these little pictures. The power of tensor networks come from its composition rules, which allow us to join two simple tensor networks together and impose rich internal structures.</p>
<p><b> 2.1. Composition Rules </b></p>
<p>We introduce two ways of joining two simple tensor networks. Roughly speaking, they correspond to multiplication and summation, and I will give the definitions by showing examples, instead of stating them in the full formalism</p>
<p><strong>Rule #1: Tensor Product.</strong> The product rule allows us to put two tensor networks together and view them as a whole. The resulting tensor is the tensor product of the two if we think of them as vectors. More concretely, consider the following picture.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6564" style="width: 364px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note10x.png"><img alt="" class="wp-image-6564 size-full" src="https://windowsontheory.files.wordpress.com/2018/12/note10x.png?w=600"/></a><p class="wp-caption-text">This is viewed as a single tensor network <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of 7 edges<span> </span>.<a name="figtp"/></p></div><p/>
<p>The definition of this joint tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{T}"/> is</p>
<p style="text-align: center;"><img alt="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)." class="latex" src="https://s0.wp.com/latex.php?latex=T%28i_1%2Ci_2%2C%5Ccdots%2C+i_7%29+%3D+T_1%28i_1%2Ci_2%2Ci_3%2Ci_4%29+T_2%28i_5%2Ci_6%2Ci_7%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T(i_1,i_2,\cdots, i_7) = T_1(i_1,i_2,i_3,i_4) T_2(i_5,i_6,i_7)."/></p>
<p><strong>Rule #2: Edge Contractions</strong>. At this moment, we can only make up disconnected tensor networks. Edge contractions allow us to link two tensor networks. Suppose we have two <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> dimensional tensor networks. Contracting two edges, one from each, gives us a tensor network of <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> <i>free edges</i>. This now corresponds a tensor of <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> dimensions.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6579" style="width: 310px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note12x.png"><img alt="" class="size-medium wp-image-6579" height="116" src="https://windowsontheory.files.wordpress.com/2018/12/note12x.png?w=300&amp;h=116" width="300"/></a><p class="wp-caption-text">Two 3d tensors</p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6563" style="width: 310px;"><a href="https://windowsontheory.files.wordpress.com/2018/12/note13x.png"><img alt="" class="size-medium wp-image-6563" height="116" src="https://windowsontheory.files.wordpress.com/2018/12/note13x.png?w=300&amp;h=116" width="300"/></a><p class="wp-caption-text">Join two tensor networks by contracting an edge</p></div><p/>
<p>We name the contracted edge as <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. The definition of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is</p>
<p style="text-align: center;"><img alt="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+T%28i_1%2Ci_2%2Cj_1%2Cj_2%29+%3D%5Csum_k+T_1%28i_1%2Ci_2%2C+k%29+T_2%28j_1%2Cj_2%2C+k%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle T(i_1,i_2,j_1,j_2) =\sum_k T_1(i_1,i_2, k) T_2(j_1,j_2, k)."/></p>
<p><b> 2.2. Useful Examples </b></p>
<p>Before we move on, let’s take some examples. Keep in mind that the degree of the vertex determines the number of indices (dimensions of this tensor).</p>
<p/><div class="wp-caption aligncenter" id="attachment_6584" style="width: 127px;"><img alt="note15x" class="alignnone size-full wp-image-6584" src="https://windowsontheory.files.wordpress.com/2018/12/note15x.png?w=600"/><p class="wp-caption-text">vector inner product <img alt="{\langle u,v \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle u,v \rangle}"/></p></div><p/>
<p/><div class="wp-caption aligncenter" id="attachment_6585" style="width: 178px;"><img alt="note16x" class="alignnone size-full wp-image-6585" src="https://windowsontheory.files.wordpress.com/2018/12/note16x.png?w=600"/><p class="wp-caption-text">Matrix inner product</p></div><p/>
<p>Here, one needs to remember that an edge between two tensor nodes is a summation over the index corresponding to the edge. For example, in the vector inner product picture, <img alt="{\langle u,v\rangle = \sum_i u_i \cdot v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+u%2Cv%5Crangle+%3D+%5Csum_i+u_i+%5Ccdot+v_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle u,v\rangle = \sum_i u_i \cdot v_i}"/>, where edge is labeled as <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. Now you would realize that this picture</p>
<p><img alt="" class="wp-image-6535 size-full aligncenter" src="https://windowsontheory.files.wordpress.com/2018/12/note0x.png?w=600"/></p>
<p>is the famous</p>
<p style="text-align: center;"><img alt="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle+u%2Cv+%5Crangle%5E2+%5Cleq+%5C%7Cu%5C%7C%5E2+%5C%7Cv%5C%7C%5E2.+%5Cquad%5Cquad+%28%5Ctext%7BCauchy-Schwarz+inequality%7D%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle u,v \rangle^2 \leq \|u\|^2 \|v\|^2. \quad\quad (\text{Cauchy-Schwarz inequality}) "/></p>
<p>For us, the most important building block is matrix multiplication. Let <img alt="{H=MN}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%3DMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H=MN}"/>. By definition</p>
<p style="text-align: center;"><img alt="H(i,j) = \sum_k M(i,k) N(k, j). " class="latex" src="https://s0.wp.com/latex.php?latex=H%28i%2Cj%29+%3D+%5Csum_k+M%28i%2Ck%29+N%28k%2C+j%29.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(i,j) = \sum_k M(i,k) N(k, j). "/></p>
<p>This is precisely encoded in the picture below.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6587" style="width: 276px;"><img alt="note20x.png" class="alignnone size-full wp-image-6587" src="https://windowsontheory.files.wordpress.com/2018/12/note20x.png?w=600"/><p class="wp-caption-text">Matrix multiplication, <img alt="{MN}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BMN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{MN}"/>.<span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span><a name="figmat-mul" style="color: #3d596d; font-size: 16px;"/><span style="background-color: #ffffff; color: #3d596d; font-size: 16px;"> </span></p></div><p/>
<p>We are ready to talk about matrix product states. In the language of tensor network, a matrix product state is the following picture.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6588" style="width: 590px;"><img alt="note21x" class="alignnone size-full wp-image-6588" src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600"/><p class="wp-caption-text">A matrix product state.</p></div><p/>
<p>As the degrees indicate, the two boundary vertices <img alt="{A_1,A_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1%2CA_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1,A_n}"/> represent matrices and the internal vertices represent <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>-dimensional tensors. We can view each matrix as a set of (column) vectors and each <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>-dimensional tensor as a stack of matrices. Then each one of the free edges picks out a vector or a matrix, and the contracted edges multiply them together which gives out a scalar. If this confused you, move on to the next section. I will introduce the formal definition of matrix product states, and you will see that it is just the picture above.</p>
<p><b>3. Matrix Product States </b></p>
<p>Before giving the definition, let’s talk about how matrix product state (MPS) naturally arises from the study of quantum states with low entanglement. Matrix product state can be viewed as a generalization of <i>product state</i>—(pure) quantum state with no entanglement. Let’s consider a simple product state <img alt="{|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\psi\rangle}"/> of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> qubits. It can be factorized: <a name="eqnmps0"/></p>
<p align="center"><a name="eqnmps0"/><img alt="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cpsi%5Crangle+%3D+%5Cleft%28%5Csum_%7Bi%3D0%7D%5E1+%5Calpha_1%5Ei%5C+%7Ci%5Crangle+%5Cright%29%5Cleft%28%5Csum_%7Bj%3D0%7D%5E1+%5Calpha_2%5Ej+%5C+%7Cj%5Crangle%5Cright%29%5Cnonumber+%3D+%5Csum_%7Bi%2Cj%3D0%7D%5E1+%5Calpha_1%5Ei+%5Calpha_2%5Ej%5C+%7Cij%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle |\psi\rangle = \left(\sum_{i=0}^1 \alpha_1^i\ |i\rangle \right)\left(\sum_{j=0}^1 \alpha_2^j \ |j\rangle\right)\nonumber = \sum_{i,j=0}^1 \alpha_1^i \alpha_2^j\ |ij\rangle \ \ \ \ \ (1)"/></p>
<p><a name="eqnmps0"/><br/>
<a name="eqnmps0"/> This state is described by <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4}"/> complex scalars <img alt="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B%5Calpha_1%5E0%2C%5Calpha_1%5E1%2C%5Calpha_2%5E0%2C%5Calpha_2%5E1%5Cright%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{\alpha_1^0,\alpha_1^1,\alpha_2^0,\alpha_2^1\right\}}"/>, and there is nothing quantum about it. However, if the state has entanglement among its qubits, then we know that it is impossible to be factorized and thereby written as (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>). MPS generalizes the form of (<a href="https://windowsontheory.org/feed/#eqnmps0">1</a>) by replacing the scalars with matrices and vectors.</p>
<p>More formally, a matrix product state starts with the following setup. For an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-qudit system, we associate</p>
<ul>
<li>a qudit in <img alt="{\{1,n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,n\}}"/> with <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> vectors <img alt="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_1%5E%7Bj_1%7D%5Cright%5C%7D%2C+%5Cleft%5C%7BA_n%5E%7Bj_n%7D%5Cright%5C%7D+%5Cin+%5Cmathbb%7BR%7D%5ED%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_1^{j_1}\right\}, \left\{A_n^{j_n}\right\} \in \mathbb{R}^D}"/>; and</li>
<li>a qudit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> in <img alt="{\{2,3,\cdots, n-1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B2%2C3%2C%5Ccdots%2C+n-1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{2,3,\cdots, n-1\}}"/> with <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> matrices <img alt="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D%5Cin+%5Cmathbb%7BR%7D%5E%7BD%5Ctimes+D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_i^{j_i}\right\}\in \mathbb{R}^{D\times D}}"/>.</li>
</ul>
<p>Here, <img alt="{j_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j_i}"/> range from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to <img alt="{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d-1}"/>, and <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is called <i>bond dimension</i>. One can think of the set of vectors as a <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> by <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> matrix and the set of matrices as a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> by <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> by <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> three-dimensional tensor. Then let them correspond to the vertices in MPS picture. With this setup, a quantum state is in matrix product state if it can be written as</p>
<p style="text-align: center;"><img alt="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj_1%2C%5Ccdots%2Cj_n%3D1%7D%5En+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D+%7Cj_1+j_2%5Ccdots+j_n%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle = \sum_{j_1,\cdots,j_n=1}^n A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n} |j_1 j_2\cdots j_n\rangle."/></p>
<p>It is important to keep in mind that <img alt="{A_1^{j_1},A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1%5E%7Bj_1%7D%2CA_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1^{j_1},A_n^{j_n}}"/> are two vectors, and the other inner terms are matrices, and we get a scalar from the product. Thus, this represents the tensor <img alt="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%28j_1%2Cj_2%2C%5Ccdots%2C+j_n%29+%3D+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(j_1,j_2,\cdots, j_n) = A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}"/>.</p>
<p>Now back to the picture,</p>
<p/><div class="wp-caption aligncenter" id="attachment_6588" style="width: 590px;"><img alt="note21x" class="alignnone size-full wp-image-6588" src="https://windowsontheory.files.wordpress.com/2018/12/note21x.png?w=600"/><p class="wp-caption-text">MPS</p></div><p/>
<p>notice that each amplitude <img alt="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+A_1%5E%7Bj_1%7D+A_2%5E%7Bj_2%7D+%5Ccdots+A_n%5E%7Bj_n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ A_1^{j_1} A_2^{j_2} \cdots A_n^{j_n}}"/> from the equation above is an output of the tensor in the picture, where the free edges take values <img alt="{j_1, j_2 ,\cdots, j_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj_1%2C+j_2+%2C%5Ccdots%2C+j_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j_1, j_2 ,\cdots, j_n}"/>. Also, as discussed earlier, the contracted edges in MPS tensor network correspond to matrix and vector multiplications, so the tensor <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is precisely represented by the picture.</p>
<p>The complexity of the MPS is closely related to the bond dimension <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. In particular, the number of parameters in this model is <img alt="{O(ndD^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28ndD%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(ndD^2)}"/>. We would expect that with higher <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>, we may describe quantum states of more entanglement. In other words, the representation power of an MPS increases with <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. In principle, one can represent any quantum state as an MPS; however, <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> can be exponentially large. See, <i>e.g.</i>, Section 4.1.3 of~\cite{schollwock2011density} for a proof. On the other extreme, the product state example shows that if <img alt="{D=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D=1}"/>, one can represent and <i>only</i> represent unentangled states. To summarize, here is the picture you should keep in mind.</p>
<p/><div class="wp-caption alignnone" id="attachment_6594" style="width: 776px;"><img alt="note33x" class="alignnone size-full wp-image-6594" src="https://windowsontheory.files.wordpress.com/2018/12/note33x.png?w=600"/><p class="wp-caption-text">Representation power of MPS increases with bond dimension D.</p></div><p/>
<p><a name="figpower"/></p>
<p> </p>
<p><b>4. Density Matrix Renormalization Group </b></p>
<p>We are now ready to describe Density Matrix Renormalization Group, proposed originally in [<a href="https://windowsontheory.org/feed/#XPhysRevLett.69.2863">Whi92</a>, <a href="https://windowsontheory.org/feed/#XPhysRevB.48.10345">Whi93</a>]. As mentioned earlier, it does not come with provable guarantees. In fact, one can construct artificial hard instances such that the algorithm get stuck at certain local minima [<a href="https://windowsontheory.org/feed/#Xschuch2008computational">SCV08</a>]. However, it has remained one of the most successful heuristics for <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D systems. We refer the readers to [<a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>] for a complete survey.</p>
<p>DMRG is a simple alternating minimization scheme for computing the ground state of a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D Hamiltonian. We start with an arbitrary MPS. Then each step we optimize over the set of matrices <img alt="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7BA_i%5E%7Bj_i%7D%5Cright%5C%7D_%7Bj_i%3D0%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{A_i^{j_i}\right\}_{j_i=0}^d}"/> associated with site <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, while fixing everything else, and iterate until convergence. (You may wonder if one can simultaneously optimize over multiple sites. It turns out that it is an NP-hard problem<span class="LinLibertineT-tlf-ot-1x-x-90"> </span><span class="cite"><span class="LinLibertineT-tlf-ot-1x-x-90">[</span><a href="https://windowsontheory.org/feed/#XPhysRevLett.97.260501">Eis06</a><span class="LinLibertineT-tlf-ot-1x-x-90">]</span></span>.)</p>
<p>Formally, the Hamiltonian problem can be phrased as a eigenvalue problem given a Hermitian matrix <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/>, and thus we want to optimize over all <img alt="{|\psi\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\psi\rangle}"/> in MPS of a fixed bond dimension <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> <a name="eqnham"/></p>
<p style="text-align: center;"><img alt="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5Cfrac%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\min_{|\psi\rangle}\frac{\langle \psi| H | \psi \rangle}{\langle \psi ||\psi \rangle}. "/></p>
<p>Here, we assume that the input Hamiltonian is in the product form. In particular, it means that it can be written as a tensor network as</p>
<p/><div class="wp-caption aligncenter" id="attachment_6596" style="width: 430px;"><img alt="note36x" class="alignnone size-full wp-image-6596" src="https://windowsontheory.files.wordpress.com/2018/12/note36x.png?w=600"/><p class="wp-caption-text">Input <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D Hamiltonian is of the particular product form.</p></div><p/>
<p>so the numerator of the optimization objective looks like</p>
<p><img alt="note37x" class=" size-full wp-image-6597 aligncenter" src="https://windowsontheory.files.wordpress.com/2018/12/note37x.png?w=600"/><a name="figdmrg1"/></p>
<p>The DMRG works with the Langrangian of the objective. For some <img alt="{\lambda&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda&gt;0}"/>, we will consider <a name="eqndmrg2"/></p>
<p align="center"><a name="eqndmrg2"/><img alt="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7B%7C%5Cpsi%5Crangle%7D%5C%2C%5C%2C+%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{|\psi\rangle}\,\, {\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}. \ \ \ \ \ (2)"/></p>
<p><a name="eqndmrg2"/><br/>
<a name="eqndmrg2"/>DMRG optimizes over the set of matrices associated with one qudit. Both terms in (<a href="https://windowsontheory.org/feed/#eqndmrg2">2</a>) are quadratic in this set of matrices.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6598" style="width: 919px;"><img alt="note39x" class="alignnone size-full wp-image-6598" src="https://windowsontheory.files.wordpress.com/2018/12/note39x.png?w=600"/><p class="wp-caption-text">The Langrangian <img alt="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Clangle+%5Cpsi%7C+H+%7C+%5Cpsi+%5Crangle%7D+-+%5Clambda+%7B%5Clangle+%5Cpsi+%7C%7C%5Cpsi+%5Crangle%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\langle \psi| H | \psi \rangle} - \lambda {\langle \psi ||\psi \rangle}}"/> as a tensor network.</p></div><p/>
<p>Now to optimize over the set of parameters associated with one site, calculus tells you to set the (partial) derivative to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>, and the derivative of a quadratic thing is linear. Without going through any algebra, we can guess that the derivative of  with respect to a particular site, say the second one, is the same picture except removing the second site on one side.</p>
<p/><div class="wp-caption alignnone" id="attachment_6599" style="width: 919px;"><img alt="note40x" class="alignnone size-full wp-image-6599" src="https://windowsontheory.files.wordpress.com/2018/12/note40x.png?w=600"/><p class="wp-caption-text">The derivative that we set to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and solve.</p></div><p/>
<p>Notice that the unknown is still there, on the bottom side of each term. The trick of DMRG is to view the rest of the network as a linear map applied to the unknown.</p>
<p><img alt="note41x" class="alignnone size-full wp-image-6600" src="https://windowsontheory.files.wordpress.com/2018/12/note41x.png?w=600"/></p>
<p>Given <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>, we now have a clean numerical linear algebra problem of solving</p>
<p align="center"><img alt="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H%27x+%3D+%5Clambda+Bx.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle H'x = \lambda Bx. \ \ \ \ \ (3)"/></p>
<p>This is called a generalized eigenvalue problem, and it is well studied. Importantly, for <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>D systems, <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> is typically very sparse, which enables very fast solvers in practice. Finally, DMRG sweeps over the sites one after another and stops until convergence is achieved.</p>
<p><b>5. Concluding Remarks </b></p>
<p class="noindent">Our presentation of tensor networks and MPS roughly follows <span class="cite">[<a href="https://windowsontheory.org/feed/#Xgharibian2015quantum">GHLS15</a>]</span>, a nice introductory survey on quantum Hamiltonian complexity.</p>
<p>The notion of tensor networks extends well beyond 1D systems, and a generalization of MPS is called tensor product state. It leads to algorithms for higher dimensional quantum systems. One may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcirac2009renormalization">CV09</a>]</span> for a comprehensive survey.</p>
<p>Tensor network has been interacting with other concepts. Within physics, it has been used in quantum error correction <span class="cite">[<a href="https://windowsontheory.org/feed/#Xferris2014tensor">FP14</a>, <a href="https://windowsontheory.org/feed/#Xpastawski2015holographic">PYHP15</a>]</span>, conformal field theory <span class="cite">[<a href="https://windowsontheory.org/feed/#Xorus2014advances">Orú14</a>]</span>, and statistical mechanics <span class="cite">[<a href="https://windowsontheory.org/feed/#XPhysRevLett.115.180405">EV15</a>]</span>. In TCS , we have found its connections with Holographic algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xvaliant2008holographic">Val08</a>, <a href="https://windowsontheory.org/feed/#Xcai2016complete">CGW16</a>]</span>, arithmetic complexity <span class="cite">[<a href="https://windowsontheory.org/feed/#Xbeaudry2007complexity">BH07</a>, <a href="https://windowsontheory.org/feed/#Xcapelli2016arithmetic">CDM16</a>, <a href="https://windowsontheory.org/feed/#Xaustrin19">AKK19</a>]</span>, and spectral algorithms <span class="cite">[<a href="https://windowsontheory.org/feed/#Xmoitra2018spectral">MW18</a>]</span>. In machine learning, it has been applied to probabilistic graphical models <span class="cite">[<a href="https://windowsontheory.org/feed/10.1093/imaiai/iay009">RS18</a>]</span>, tensor decomposition <span class="cite">[<a href="https://windowsontheory.org/feed/#Xcichocki2016low">CLO16</a>]</span>, and quantum machine learning <span class="cite">[<a href="https://windowsontheory.org/feed/#X10.1088/2058-9565/aaea94">HPM18</a>]</span>.</p>
<p>For DMRG, we have only given a rough outline, with many details omitted, such as how to set <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> and how to obtain the Hamiltonian in the matrix product form, and how to compute the linear maps <img alt="{H'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H'}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> for each iteration. An interested reader may read <span class="cite">[<a href="https://windowsontheory.org/feed/#Xschollwock2005density">Sch05</a>, <a href="https://windowsontheory.org/feed/#Xschollwock2011density">Sch11</a>]</span>.</p>
<p><strong>References</strong></p>
<p class="bibitem"><span class="biblabel">[AKK19] <span class="bibsp">   </span></span><a id="Xaustrin19"/>Per Austrin, Peeri Kaski, and Kaie Kubjas. Tensor network complexity of multilinear maps. In <span class="LinLibertineTI-tlf-ot-1x-x-109">Proceedings of the 2019 Conference on Innovations in Theoretical Computer Science</span>. ACM, 2019.</p>
<p class="bibitem"><span class="biblabel">[BH07] <span class="bibsp">   </span></span><a id="Xbeaudry2007complexity"/>Martin Beaudry and Markus Holzer. The complexity of tensor circuit evaluation. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Complexity</span>, 16(1):60, 2007.</p>
<p class="bibitem"><span class="biblabel">[CDM16] <span class="bibsp">   </span></span><a id="Xcapelli2016arithmetic"/>Florent Capelli, Arnaud Durand, and Stefan Mengel. e arithmetic complexity of tensor contraction. <span class="LinLibertineTI-tlf-ot-1x-x-109">eory of Computing Systems</span>, 58(4):506{527, 2016.</p>
<p class="bibitem"><span class="biblabel">[CGW16] <span class="bibsp">   </span></span><a id="Xcai2016complete"/>Jin-Yi Cai, Heng Guo, and Tyson Williams. A complete dichotomy rises from the capture of vanishing signatures. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 45(5):1671{1728, 2016.</p>
<p class="bibitem"><span class="biblabel">[CLO16] <span class="bibsp">   </span></span><a id="Xcichocki2016low"/>Andrzej Cichocki, Namgil Lee, Ivan V Oseledets, A-H Phan, Qibin Zhao, and D Mandic. Low-rank tensor networks for dimensionality reduction and large-scale optimization problems: Perspectives and challenges part 1. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint arXiv:1609.00893</span>, 2016.</p>
<p class="bibitem"><span class="biblabel">[CV09] <span class="bibsp">   </span></span><a id="Xcirac2009renormalization"/>J Ignacio Cirac and Frank Verstraete. Renormalization and tensor product states in spin chains and laices. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of Physics A: Mathematical and Theoretical</span>, 42(50):504004, 2009.</p>
<p class="bibitem"><span class="biblabel">[Eis06] <span class="bibsp">   </span></span><a id="XPhysRevLett.97.260501"/>Jens Eisert. Computational difficulty of global variations in the density matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 97:260501, Dec 2006.</p>
<p class="bibitem"><span class="biblabel">[EV15] <span class="bibsp">   </span></span><a id="XPhysRevLett.115.180405"/>G. Evenbly and G. Vidal. Tensor network renormalization. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 115:180405, Oct 2015.</p>
<p class="bibitem"><span class="biblabel">[FP14] <span class="bibsp">   </span></span><a id="Xferris2014tensor"/>Andrew J Ferris and David Poulin. Tensor networks and quantum error correction. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 113(3):030501, 2014.</p>
<p class="bibitem"><span class="biblabel">[FSW07] <span class="bibsp">   </span></span><a id="Xfehske2007computational"/>Holger Fehske, Ralf Schneider, and Alexander Weie. <span class="LinLibertineTI-tlf-ot-1x-x-109">Computational Many-Particle Physics</span>. Springer, 2007.</p>
<p class="bibitem"><span class="biblabel">[GHLS15] <span class="bibsp">   </span></span><a id="Xgharibian2015quantum"/>Sevag Gharibian, Yichen Huang, Zeph Landau, and Seung Woo Shin. Quantum Hamiltonian complexity. <span class="LinLibertineTI-tlf-ot-1x-x-109">Foundations and Trends in Theoretical Computer Science</span>, 10(3):159, 2015.</p>
<p class="bibitem"><span class="biblabel">[HPM18]<span class="bibsp">   </span></span><a id="X10.1088/2058-9565/aaea94"/>William James Huggins, Piyush Patil, Bradley Mitchell, K Birgia Whaley, and Miles Stoudenmire. Towards quantum machine learning with tensor networks. Qu<span class="LinLibertineTI-tlf-ot-1x-x-109">antum Science and</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Technology</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[MW18] <span class="bibsp">   </span></span><a id="Xmoitra2018spectral"/>Ankur Moitra and Alexander S Wein. Spectral methods from tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv preprint</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">arXiv:1811.00944</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Orú14] <span class="bibsp">   </span></span><a id="Xorus2014advances"/>Román Orús. Advances on tensor network theory: symmetries, fermions, entanglement, and holography. <span class="LinLibertineTI-tlf-ot-1x-x-109">e European Physical Journal B</span>, 87(11):280, 2014.</p>
<p class="bibitem"><span class="biblabel">[PYHP15] <span class="bibsp">   </span></span><a id="Xpastawski2015holographic"/>Fernando Pastawski, Beni Yoshida, Daniel Harlow, and John Preskill. Holographic quantum error-correcting codes: Toy models for the bulk/boundary correspondence. <span class="LinLibertineTI-tlf-ot-1x-x-109">Journal of High Energy</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Physics</span>, 2015(6):149, 2015.</p>
<p class="bibitem"><span class="biblabel">[RS18] <span class="bibsp">   </span></span><a id="Xdoi:10.1093/imaiai/iay009"/>Elina Robeva and Anna Seigal. Duality of graphical models and tensor networks. <span class="LinLibertineTI-tlf-ot-1x-x-109">Information</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">and Inference: A Journal of the IMA</span>, 2018.</p>
<p class="bibitem"><span class="biblabel">[Sch05] <span class="bibsp">   </span></span><a id="Xschollwock2005density"/>Ulrich Schollwöck. The density-matrix renormalization group. <span class="LinLibertineTI-tlf-ot-1x-x-109">Rev. Mod. Phys.</span>, 77(1):259, 2005.</p>
<p class="bibitem"><span class="biblabel">[Sch11] <span class="bibsp">   </span></span><a id="Xschollwock2011density"/>Ulrich Schollwöck. The density-matrix renormalization group in the age of matrix product states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Annals of Physics</span>, 326(1):96, 2011.</p>
<p class="bibitem"><span class="biblabel">[SCV08] <span class="bibsp">   </span></span><a id="Xschuch2008computational"/>Norbert Schuch, Ignacio Cirac, and Frank Verstraete. Computational difficulty of finding matrix product ground states. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev. Le.</span>, 100(25):250501, 2008.</p>
<p class="bibitem"><span class="biblabel">[Val08] <span class="bibsp">   </span></span><a id="Xvaliant2008holographic"/>Leslie G Valiant. Holographic algorithms. <span class="LinLibertineTI-tlf-ot-1x-x-109">SIAM Journal on Computing</span>, 37(5):1565, 2008.</p>
<p class="bibitem"><span class="biblabel">[Whi92] <span class="bibsp">   </span></span><a id="XPhysRevLett.69.2863"/>Steven R. White. Density matrix formulation for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">Le.</span>, 69:2863, Nov 1992.</p>
<p class="bibitem"><span class="biblabel">[Whi93] <span class="bibsp">   </span></span><a id="XPhysRevB.48.10345"/>Steven R. White. Density-matrix algorithms for quantum renormalization groups. <span class="LinLibertineTI-tlf-ot-1x-x-109">Phys. Rev.</span> <span class="LinLibertineTI-tlf-ot-1x-x-109">B</span>, 48:10345, Oct 1993.</p></div>
    </content>
    <updated>2018-12-20T21:59:13Z</updated>
    <published>2018-12-20T21:59:13Z</published>
    <category term="physics"/>
    <category term="cs229r"/>
    <author>
      <name>Fred Zhang</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6720</id>
    <link href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/" rel="alternate" type="text/html"/>
    <title>Efficient preparation of thermal states of quantum systems: natural or artificial</title>
    <summary>Cross-posted from https://wsmoses.com/blog/2018/12/18/boaz/ Lecturer: Aram Harrow Scribes: Sinho Chewi, William S. Moses, Tasha Schoenstein, Ary Swaminathan November 9, 2018 Outline Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><article class="post-content"><p>Cross-posted from <a href="https://wsmoses.com/blog/2018/12/18/boaz/">https://wsmoses.com/blog/2018/12/18/boaz/</a></p><p>Lecturer: Aram Harrow</p><p>Scribes: Sinho Chewi, <a href="http://wsmoses.com">William S. Moses,</a> Tasha Schoenstein, Ary Swaminathan</p><p>November 9, 2018</p></article><p><br/></p><article class="post-content"><h3 id="outline">Outline</h3><p>Sampling from thermal states was one of the first and (initially) most important uses of computers. In this blog post, we will discuss both classical and quantum Gibbs distributions, also known as thermal equilibrium states. We will then discuss Markov chains that have Gibbs distributions as stationary distributions. This leads into a discussion of the equivalence of mixing in time (i.e. the Markov chain quickly equilibrates over time) and mixing in space (i.e. sites that are far apart have small correlation). For the classical case, this equivalence is known. After discussing what is known classically, we will discuss difficulties that arise in the quantum case, including (approximate) Quantum Markov states and the equivalence of mixing in the quantum case.</p><h1 id="gibbs-distributions">Gibbs distributions</h1><p>We have already learned about phase transitions in a <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">previous blog post</a>, but they are important, so we will review them again. The <strong>Gibbs</strong> or <strong>thermal distribution</strong> is defined as follows: Suppose that we have an <strong>energy function</strong> <img alt="E : {\{0,1\}}^n \to {\mathbb R}" class="latex" src="https://s0.wp.com/latex.php?latex=E+%3A+%7B%5C%7B0%2C1%5C%7D%7D%5En+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E : {\{0,1\}}^n \to {\mathbb R}"/> , which takes <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> -bit strings to real numbers. Usually, <img alt="E = \sum_{i=1}^m E_i" class="latex" src="https://s0.wp.com/latex.php?latex=E+%3D+%5Csum_%7Bi%3D1%7D%5Em+E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E = \sum_{i=1}^m E_i"/> , where each <img alt="E_i" class="latex" src="https://s0.wp.com/latex.php?latex=E_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_i"/> term depends only on a few bits. For example, the energy might be the number of unsatisfied clauses in a 3-SAT formula, or it may arise from the Ising model. The Gibbs distribution is</p><p><span style="display: block;"> <img alt="p(x) = \frac{\exp\{-E(x)/T\}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%5Cfrac%7B%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x) = \frac{\exp\{-E(x)/T\}}{Z}"/> </span></p><p>where the normalization factor in the denominator, also called the <strong>partition function</strong>, is <img alt="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}" class="latex" src="https://s0.wp.com/latex.php?latex=Z+%3D+%5Csum_%7Bx+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En%7D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z = \sum_{x \in {\{0,1\}}^n} \exp\{-E(x)/T\}"/> . Another, perhaps more operational, way to define the Gibbs distribution is:</p><p><span style="display: block;"> <img alt="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}." class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%3B%5Cmathrm%7Barg%5C%2Cmax%7D_%7Bq+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29%7D+H%28q%29%7E%5Ctext%7Bsubject+to+the+constraint%7D%7E+%5Clangle%7Bq%2CE%7D%5Crangle+%3D+%5Cbar%7BE%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p = \;\mathrm{arg\,max}_{q \in {\mathcal{P}}({\{0,1\}}^n)} H(q)~\text{subject to the constraint}~ \langle{q,E}\rangle = \bar{E}."/> </span></p><p>In this expression, <img alt="{\mathcal{P}}({\{0,1\}}^n)" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D%28%7B%5C%7B0%2C1%5C%7D%7D%5En%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{P}}({\{0,1\}}^n)"/> is the set of probability distributions on <img alt="{\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\{0,1\}}^n"/> , <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is the Shannon entropy, and <img alt="\bar E" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar+E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bar E"/> is a constant representing the average energy. We are thinking of probability distributions and <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> as vectors of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> . It turns out that if we solve this optimization problem, then the Gibbs distribution is the unique solution.</p><h2 id="uses-of-gibbs-distributions">Uses of Gibbs distributions</h2><p>Why is it useful to work with Gibbs distributions?</p><ul><li><p>Gibbs distributions arise naturally in statistical physics systems, such as constraint satisfaction problems (CSPs), the Ising model, and spin glasses. One approach to deal with Gibbs distributions is through <a href="https://windowsontheory.org/feed/https_//windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">belief propagation</a> (BP), which yields exact inference on tree graphical models and sometimes phase transition predictions on loopy graphs. Instead, we will focus on a different approach, namely, <em>sampling</em> from the Gibbs distribution.</p></li><li><p>If we want to minimize <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> (say, to find a 3-SAT solution), we can use <strong>simulated annealing</strong>. The idea of annealing is that we want to produce a crystal; a crystal is the lowest energy configuration of molecules. If we heat up the substance to a liquid and then cool it quickly, we will not get a nice crystal, because little bits of the material will point in different directions. In order to form a crystal, we need to cool the system slowly.</p><p>In computer science terms, we take a sample from a high temperature because sampling is generally easier at a higher temperature than at a lower temperature. We then use that sample as the starting point for an equilibration process at a slightly lower temperature, and repeat this procedure. If we reach zero temperature, then we are sampling from the minimizers of <img alt="E" class="latex" src="https://s0.wp.com/latex.php?latex=E&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E"/> . In practice, the system will usually stop mixing before we get to zero temperature, but this is a good heuristic. You can think of this process as gradient descent, with some additional randomness.</p></li><li><p>Gibbs distributions are used to simulate physical systems.</p></li><li><p>Gibbs distributions are used in Bayesian inference due to the Hammersley-Clifford theorem, which will be discussed next.</p></li><li><p>Gibbs distributions are also connected to multiplicative weights for linear programming (not discussed in this blog post).</p></li></ul><h2 id="bayesian-inference--the-hammersley-clifford-theorem">Bayesian inference &amp; the Hammersley-Clifford theorem</h2><p>In order to present the Hammersley-Clifford theorem, we must first discuss Markov networks. For this part, we will generalize our setup to a finite alphabet <img alt="\Sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma"/> , so the energy function is now a function <img alt="\Sigma^n \to \mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma%5En+%5Cto+%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma^n \to \mathbb R"/> .</p><h3 id="markov-chains">Markov chains</h3><p>First, let us recall the idea of a <strong>Markov chain</strong> with variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> .</p></article>


<figure class="wp-block-image"><img alt="" class="wp-image-6784" src="https://windowsontheory.files.wordpress.com/2018/12/p1.png?w=600"/></figure>



<p>The random variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> form a Markov chain if their joint distribution can be written in a factored way: <img alt="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B1%2C2%7D%28x_1%2Cx_2%29p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2,x_3) = p_{1,2}(x_1,x_2)p_{3 \mid 2}(x_3 \mid x_2)"/> . For example, imagine that <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> , <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> , <img alt="X_3" class="latex" src="https://s0.wp.com/latex.php?latex=X_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_3"/> represent the weather on Monday, Tuesday, and Wednesday respectively. These random variables form a Markov chain if, conditioned on the weather on Tuesday, we have all of the information we need to forecast the weather on Wednesday. Another way to say this is that conditioned on the weather on Tuesday, then the weather on Monday and the weather on Wednesday are <strong>conditionally independent</strong>. Note that the weather on Monday and the weather on Wednesday are <em>not</em> independent; there can be correlations, but these correlations are mediated through the weather on Tuesday. It is important to note that the definition of a Markov chain is symmetric with respect to going forwards or backwards in time, so we can also write the conditional independence condition as <img alt="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%2Cx_3%29+%3D+p_%7B2%2C3%7D%28x_2%2Cx_3%29+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2,x_3) = p_{2,3}(x_2,x_3) p_{1 \mid 2}(x_1 \mid x_2)"/> .</p>



<p>The conditional independence condition can also be written as <img alt="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)." class="latex" src="https://s0.wp.com/latex.php?latex=p_%7B1%2C3+%5Cmid+2%7D%28x_1%2C+x_3+%5Cmid+x_2%29+%3D+p_%7B1+%5Cmid+2%7D%28x_1+%5Cmid+x_2%29+p_%7B3+%5Cmid+2%7D%28x_3+%5Cmid+x_2%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{1,3 \mid 2}(x_1, x_3 \mid x_2) = p_{1 \mid 2}(x_1 \mid x_2) p_{3 \mid 2}(x_3 \mid x_2)."/> Recall that for two random variables <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/> and <img alt="X_2" class="latex" src="https://s0.wp.com/latex.php?latex=X_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_2"/> with joint distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> , they are independent, i.e., <img alt="p(x_1,x_2) = p_1(x_1) p_2(x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x_1%2Cx_2%29+%3D+p_1%28x_1%29+p_2%28x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x_1,x_2) = p_1(x_1) p_2(x_2)"/> , if and only if <img alt="I(X_1; X_2) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_2%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1; X_2) = 0"/> , where <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> here denotes the mutual information. Similarly, conditional independence is equivalent to the <strong>conditional mutual information</strong> <img alt="I(X_1; X_3 \mid X_2)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3B+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1; X_3 \mid X_2)"/> equaling zero. This quantity is defined as <img alt="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_1%3BX_3+%5Cmid+X_2%29+%3D+H%28X_1+%5Cmid+X_2%29+%2B+H%28X_3+%5Cmid+X_2%29+-+H%28X_1%2C+X_3+%5Cmid+X_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_1;X_3 \mid X_2) = H(X_1 \mid X_2) + H(X_3 \mid X_2) - H(X_1, X_3 \mid X_2)"/> .</p>



<p>Keep in mind that conditional independence is characterized in two equivalent ways: via an algebraic condition on the distributions, and via mutual information.</p>



<h3 id="markov-networks">Markov networks</h3>



<p>A <strong>Markov network</strong> is like a Markov chain, but with more random variables and a more interesting structure. Imagine that we have a graph, where each node is associated with a random variable and the edges encode possible correlations. A Markov network has the property that if we take any disjoint collection of nodes <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> such that <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> are fully separated by <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> (that is, any path from <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> must go through <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , or alternatively, removing <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> leaves <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> disconnected), then <img alt="I(X_A; X_C \mid X_B) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28X_A%3B+X_C+%5Cmid+X_B%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(X_A; X_C \mid X_B) = 0"/> . The notation <img alt="X_A" class="latex" src="https://s0.wp.com/latex.php?latex=X_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_A"/> here means the collection of random variables associated with the nodes in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> .</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6785" src="https://windowsontheory.files.wordpress.com/2018/12/p2.png?w=600"/></figure>



<p>For example:</p>



<p>Here, if <img alt="A=\{1,5,6\}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3D%5C%7B1%2C5%2C6%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=\{1,5,6\}"/> , <img alt="B=\{2,7\}" class="latex" src="https://s0.wp.com/latex.php?latex=B%3D%5C%7B2%2C7%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B=\{2,7\}"/> , and <img alt="C=\{3,4\}" class="latex" src="https://s0.wp.com/latex.php?latex=C%3D%5C%7B3%2C4%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C=\{3,4\}"/> , then <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> separates <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> .</p>



<p>A Markov network is also called a <strong>graphical model</strong> or a <strong>Markov random field</strong>; and yet another name for them is <em>Gibbs distribution</em>, which is the content of the following theorem:</p>



<p><strong>Theorem 1</strong> (Hammersley-Clifford Theorem): <em>Let <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> be a strictly positive distribution on <img alt="\Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Sigma^n"/> . Then, <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> can be represented as a Markov network with respect to a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> if and only if <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> can be expressed as a Gibbs distribution <img alt="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}" class="latex" src="https://s0.wp.com/latex.php?latex=p%28x%29+%5Cpropto+%5Cexp%5C%7B-%5Csum_%7BC+%5Cin+%7B%5Cmathcal%7BC%7D%7D%28G%29%7D+E_C%28x_C%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(x) \propto \exp\{-\sum_{C \in {\mathcal{C}}(G)} E_C(x_C)\}"/> , where <img alt="{\mathcal{C}}(G)" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{C}}(G)"/> is the set of cliques (fully connected subsets) of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> . </em></p>



<p>This theorem says that Markov networks are the same as Gibbs states, <em>with the same notion of locality</em>.</p>



<p>The Hammersley-Clifford theorem implies an area law for mutual information; we will explain what this is and sketch why this is true. Divide a system into two disjoint pieces <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . We want to know about the mutual information between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , <img alt="I(A;B)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A;B)"/> . The Hammersley-Clifford theorem gives us a bound which depends only on the size of the boundary <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> between these sets. For simplicity, assume <img alt="\partial \subseteq B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial \subseteq B"/> . Also, assume that the interactions have bounded range; then, the Hammersley-Clifford theorem tells us that <img alt="I(A; B \mid \partial) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B \mid \partial) = 0"/> .</p>



<p>Now, we will use the fact <img alt="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B+%5Cmid+%5Cpartial%29+%3D+I%28A%3B+B%2C%5Cpartial%29+-+I%28A%3B+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B \mid \partial) = I(A; B,\partial) - I(A; \partial)"/> . We can see this by writing out the expressions, but the intuition is that the term on the left asks about how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , having already known about <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> . This equals how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> and <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> combined, minus how much <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> knows about <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> alone. In this case, since we said <img alt="\partial \subseteq B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Csubseteq+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial \subseteq B"/> , then <img alt="I(A; B)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B)"/> is the same as <img alt="I(A; B, \partial)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+B%2C+%5Cpartial%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; B, \partial)"/> . In general, however, we have an upper bound:</p>



<p> <img alt="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3BB%29+%5Cle+I%28A%3B+B%2C+%5Cpartial%29+%3D+I%28A%3B+%5Cpartial%29+%2B+I%28A%3BB+%5Cmid+%5Cpartial%29+%5Cle+H%28%5Cpartial%29+%5Cle+%7C%5Cpartial%7C+%5Clog+%7C%5CSigma%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A;B) \le I(A; B, \partial) = I(A; \partial) + I(A;B \mid \partial) \le H(\partial) \le |\partial| \log |\Sigma|"/> </p>



<p>In this calculation, we have used <img alt="I(A; \partial) = H(\partial) - H(\partial \mid A)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28A%3B+%5Cpartial%29+%3D+H%28%5Cpartial%29+-+H%28%5Cpartial+%5Cmid+A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I(A; \partial) = H(\partial) - H(\partial \mid A)"/> (the information between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> is the amount by which the entropy of <img alt="\partial" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial"/> gets reduced once we know <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> ) and <img alt="H(\partial \mid A) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=H%28%5Cpartial+%5Cmid+A%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H(\partial \mid A) \ge 0"/> (which is true classically).</p>



<p>Since the mutual information only scales with the <em>surface area</em> of the boundary and not with the area of the two regions <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , this is known as an <em>area law</em> <a href="https://windowsontheory.org/feed/#gharibian">[1]</a>.</p>



<h3 id="relationship-to-bayesian-inference">Relationship to Bayesian inference</h3>



<p>In Bayesian inference, we have a model for a system which can be very complicated. The model represents our assumptions on how parts of the system are causally related to the rest of the system. We have some observations, and we want to sample from a distribution conditionally on the fixed observations. Sampling from a conditional distribution is not the same as sampling from the original distribution, but we can still formally represent the conditional distribution as a Markov network. Therefore, sampling from Markov networks is a broadly useful task.</p>



<p>As an example of a complicated Bayesian model, consider a <em>hierarchical Bayesian model</em> <a href="https://windowsontheory.org/feed/#keener">[2]</a>. Bayesian statistics requires choosing a prior distribution, and when there is a natural parameterized family of priors that a statistician can use, it may make sense to introduce a distribution over the priors; this is known as <em>introducing a hyperparameter</em>, and inference in the resulting hierarchical model (including computation of the posterior distribution) is frequently intractable. However, it is still desirable to work with these models because they are often more accurate than models in which the prior is handpicked by a statistician.</p>



<h1 id="sampling-from-gibbs-distributions">Sampling from Gibbs distributions</h1>



<p>The task of sampling from an arbitrary Gibbs distribution is MA-complete <a href="https://windowsontheory.org/feed/#crosson_making_2010">[3]</a>, and it is not hard to see that at low enough temperatures this problem is at least NP-hard. So, how do we sample from these distributions?</p>



<p>This section will discuss Monte Carlo Markov chain (MCMC) methods, namely the Metropolis-Hastings algorithm and Glauber dynamics. Readers familiar with these methods may wish to skip to the discussion of <a href="https://windowsontheory.org/feed/#scn_mixing_in_time">mixing in time</a>. For readers who wish to build more intuition about Markov chains before proceeding, see the <a href="https://windowsontheory.org/feed/#scn_appendix">Appendix</a>, where the simple example of the random walk on a cycle is treated in detail.</p>



<h2 id="monte-carlo-markov-chain-mcmc-methods">Monte Carlo Markov chain (MCMC) methods</h2>



<p>The general approach is to use a Markov chain. Let <img alt="\Omega=\Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%3D%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega=\Sigma^n"/> be the possible states of the system. Effectively, a Markov chain is a way of doing a random walk over <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> .</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6786" src="https://windowsontheory.files.wordpress.com/2018/12/p3.png?w=600"/></figure>



<p>The transition probabilities of the Markov chain are<sup><a href="https://windowsontheory.org/feed/#fn_1">1</a></sup> <img alt="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}." class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%28t%2B1%29+%3D+y+%5Cmid+X%28t%29+%3D+x%5C%7D+%3D+T_%7By%2Cx%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{X(t+1) = y \mid X(t) = x\} = T_{y,x}."/> Here, <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is the <strong>transition probability matrix</strong>. The column at index <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is the probability distribution of the next state of the Markov chain, if the current state is <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . The row at index <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a row of probability values which give the probabilities of jumping into state <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> from every other state. It has the properties that its entries are non-negative and for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> , <img alt="\sum_{y \in \Omega} T_{y,x} = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7By+%5Cin+%5COmega%7D+T_%7By%2Cx%7D+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_{y \in \Omega} T_{y,x} = 1"/> . These properties say that <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is a (column) <strong>stochastic matrix</strong>.</p>



<p>Suppose we start at a state <img alt="x(0)" class="latex" src="https://s0.wp.com/latex.php?latex=x%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(0)"/> ; or, more generally, we will start with a distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> over <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> . If we move according to the chain once, the distribution will be <img alt="Tp" class="latex" src="https://s0.wp.com/latex.php?latex=Tp&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tp"/> . If we move agian, the distribution will be <img alt="T^2 p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5E2+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^2 p"/> . In general, after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> movements, the distribution is <img alt="T^t p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t p"/> . So, we can express the dynamics of the chain as matrix-vector multiplication.</p>



<p>It is worth mentioning that if we are simulating the chain on a computer and we are manipulating <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> -bit numbers, then these probability vectors are of size <img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/> so it becomes impractical to store the entire probability distributions.</p>



<p>The justification for our algorithms is the following theorem.</p>



<p><strong>Theorem 2</strong> (Perron-Frobenius Theorem): <em>If <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is a stochastic aperiodic matrix, then one of the eigenvalues is <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> , and all other eigenvalues have magnitude strictly less than <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . There is a unique probability distribution <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> such that <img alt="T\pi = \pi" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Cpi+%3D+%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T\pi = \pi"/> . </em></p>



<p>The theorem implies that <img alt="T^t p" class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t p"/> will converge to the stationary distribution <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> as <img alt="t\to\infty" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\to\infty"/> . So, if we want to sample from a distribution, this provides a method of doing so: cook up a Markov chain that equilibrates to the desired distribution, and then run the Markov chain until convergence. <em>A priori</em>, it is not obvious how we can design the Markov chain. At first, our problem was to sample from a probability distribution (a vector), and now we have changed the problem to designing an entire matrix, which does not appear to make our task easier.</p>



<p>Now, the question becomes: how does one come up with Markov chains that give you the desired stationary distribution?</p>



<h2 id="metropolis-hastings-algorithm">Metropolis-Hastings algorithm</h2>



<p>The first algorithm we will introduce is the <strong>Metropolis-Hastings algorithm</strong>. One more desirable feature of a Markov chain is that it satisfies <strong>detailed balance</strong>, which says <img alt="\pi_x T_{y,x} = \pi_y T_{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x+T_%7By%2Cx%7D+%3D+%5Cpi_y+T_%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x T_{y,x} = \pi_y T_{x,y}"/> for all <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> . This condition says that if we pick a point with probability according to the stationary distribution and transition, the probability of picking <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and then moving to <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> should be the same as picking <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and then moving to <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> .</p>



<p>For a Markov chain in equilibrium, the total amount of probability flowing out of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> must equal the total amount of probability flowing into <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . For example, the United States might export products to Europe and import from China. Detailed balance says that the flow along each edge must balance, which is a more demanding condition. In the example with country trade deficits, we are requiring that all bilateral trade deficits must be zero.</p>



<p>Mathematically, detailed balance implies that <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> can be transformed, via similarity transformations, into a symmetric matrix. The Metropolis-Hastings algorithm says that we should choose <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> with the property <img alt="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BT_%7Bx%2Cy%7D%7D%7BT_%7By%2Cx%7D%7D+%3D+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{T_{x,y}}{T_{y,x}} = \frac{\pi_x}{\pi_y}."/> Suppose that we have an underlying graph on our state space, and suppose that we are at a state <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . The algorithm chooses a random neighbor, say <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> , and then accepts or rejects this move with some probability. If the move is accepted, then we move to <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and continue the algorithm from there. Otherwise, if the move is rejected, then we stay at <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> . We are free to choose any underlying graph (as long as it is connected and has a self-loop), and then we will tune the acceptance probability so that detailed balance holds.</p>



<p>Look at the trial move <img alt="x\to y" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cto+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\to y"/> . One way we can accomplish detailed balance is by looking at the ratio <img alt="\pi_y/\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x"/> . If <img alt="\pi_y/\pi_x \ge 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%5Cge+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x \ge 1"/> , then always accept the move. If <img alt="\pi_y/\pi_x &lt; 1 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x+%3C+1+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x &lt; 1 "/> , then accept the move with probability <img alt="\pi_x/\pi_y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x%2F%5Cpi_y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x/\pi_y"/> .</p>



<p>To get an idea for how the algorithm works, suppose that our underlying graph is <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> -regular. Then, for neighbors <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> ,</p>



<p> <img alt="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7DT_%7By%2Cx%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%2C+%5C%5C+T_%7Bx%2Cy%7D+%26%3D+%5Cmin%5CBigl%5C%7B1%2C+%5Cfrac%7B%5Cpi_x%7D%7B%5Cpi_y%7D%5CBigr%5C%7D+%5Cfrac%7B1%7D%7Bd%7D%5C%3B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned}T_{y,x} &amp;= \min\Bigl\{1, \frac{\pi_y}{\pi_x}\Bigr\} \frac{1}{d}, \\ T_{x,y} &amp;= \min\Bigl\{1, \frac{\pi_x}{\pi_y}\Bigr\} \frac{1}{d}\;\end{aligned} "/> </p>



<p><strong>Claim</strong>: <img alt="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\}," class="latex" src="https://s0.wp.com/latex.php?latex=T_%7By%2Cx%7D+%5Cpi_x+%3D+%5Cfrac%7B1%7D%7Bd%7D+%5Cmin%5C%7B%5Cpi_x%2C%5Cpi_y%5C%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_{y,x} \pi_x = \frac{1}{d} \min\{\pi_x,\pi_y\},"/> which is manifestly symmetric in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> ; thus, we have reversibility. This is the basic idea of the Metropolis-Hastings algorithm.</p>



<p>How does it work for a Gibbs distribution <img alt="\pi_x = \exp\{-E(x)/T\}/Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x+%3D+%5Cexp%5C%7B-E%28x%29%2FT%5C%7D%2FZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x = \exp\{-E(x)/T\}/Z"/> , where the energy function might, for example, count the number of violated clauses in a 3-SAT formula? In this case, we might be a little worried. The numerator of <img alt="\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_x"/> is pretty easy to compute (we can count how many violated constraints there are), but the denominator is hard to compute. In general, it is #P-hard to compute the denominator, because as <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> drops to <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> , the partition function in this case approaches the number of 3-SAT solutions. So, how do we calculate the ratios <img alt="\pi_y/\pi_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_y%2F%5Cpi_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_y/\pi_x"/> that the algorithm requires? We’re able to do this because the ratio does not depend on <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> :</p>



<p> <img alt="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpi_y%7D%7B%5Cpi_x%7D+%3D+%5Cexp+%5Cfrac%7BE%28x%29-E%28y%29%7D%7BT%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{\pi_y}{\pi_x} = \exp \frac{E(x)-E(y)}{T}."/> </p>



<p>Suppose that the energy is a sum of local terms, and the underlying graph corresponds to modifying one site at at a time. What this means is that the graph is <img alt="\Omega = {\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%3D+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega = {\{0,1\}}^n"/> and the edges in the graph correspond to flipping exactly one bit. In this case, it becomes very easy to evaluate the computations needed for the algorithm; in fact, we can even do them in parallel.</p>



<p>How do we choose the underlying graph? The key idea is that we do not want the majority of our moves to be rejected. A good example to keep in mind is the <strong>Ising model</strong>, where the configurations are <img alt="x \in {\{0,1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B0%2C1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in {\{0,1\}}^n"/> and the energy is <img alt="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+-%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = -\sum_{i,j=1}^n J_{i,j} x_i x_j"/> . If <img alt="J_{i,j} \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} \ge 0"/> for all <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> , <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> , then we say that the model is <strong>ferromagnetic</strong> (we obtain lower energy by making the sites agree with each other). Of course, an <strong>antiferromagnetic</strong> model is just the opposite of this.</p>



<p>Assume that the bits are laid out in a square and <img alt="J_{i,j} = J" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+J&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} = J"/> if <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> are neighbors on the square, and <img alt="J_{i,j} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=J_%7Bi%2Cj%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J_{i,j} = 0"/> if they are not. As we vary the quantity <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> , we observe a <em>phase transition</em>. If <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> is small, then the coupling between the random variables is weak and the different parts of the system are almost independent; we call this the <strong>disordered phase</strong>. If <img alt="J/T" class="latex" src="https://s0.wp.com/latex.php?latex=J%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="J/T"/> is large, then the spins want to align in the same direction and the Gibbs distribution will look almost like the following: with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> , all spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> , and with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> , all spins are <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> ; we call this the <strong>ordered phase</strong>.</p>



<p>In the disordered phase, when the spins do not need to align so closely, the Metropolis-Hastings algorithm will work well. In the ordered phase, the algorithm is doomed. Indeed, suppose that most of the spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . As time proceeds, any <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> s will switch to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . There may be islands of <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> spins initially, but it will be energetically favorable for these islands to shrink over time. Therefore, there will be an exponentially small chance for the system to switch to a configuration with mostly <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> ’s, and thus the chain takes exponentially long to mix. Here, people are interested in understanding the <em>autocorrelation time</em>, because the goal is to run the chain for some time, get one sample, run the chain for some more time, get another sample, etc.</p>



<h2 id="glauber-dynamics">Glauber dynamics</h2>



<p>This next method (<strong>Glauber dynamics</strong>) is essentially the same as Metropolis-Hastings, but this is not immediately obvious. We are at a state <img alt="x = (x_1,\dotsc,x_n) \in \Sigma^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%3D+%28x_1%2C%5Cdotsc%2Cx_n%29+%5Cin+%5CSigma%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x = (x_1,\dotsc,x_n) \in \Sigma^n"/> . (For the Metropolis-Hastings algorithm, we could be walking on a state space without a product structure. However, Glauber dynamics requires a product structure.) Then, we update <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> to <img alt="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_i%27%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_1,\dotsc,x_{i-1},x_i',x_{i+1},\dotsc,x_n)"/> with chance <img alt="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi%5Cmid+-i%7D%28x_i%27+%5Cmid+x_1%2C%5Cdotsc%2Cx_%7Bi-1%7D%2Cx_%7Bi%2B1%7D%2C%5Cdotsc%2Cx_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_{i\mid -i}(x_i' \mid x_1,\dotsc,x_{i-1},x_{i+1},\dotsc,x_n)"/> . In other words, we hold all other bits fixed, and conditioned on those other bits, we resample the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> th bit. Like Metropolis-Hastings, <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> is stationary for this chain.</p>



<p>It is not obvious that these conditional distributions can be computed efficiently, but it is possible since normalizing the conditional distribution only requires summing over the possible configurations for a single random variable. On a Markov network, the conditional probability is <img alt="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bi+%5Cmid+N%28i%29%7D%28x_i%27+%5Cmid+x_%7BN%28i%29%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi_{i \mid N(i)}(x_i' \mid x_{N(i)})"/> , where <img alt="N(i)" class="latex" src="https://s0.wp.com/latex.php?latex=N%28i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N(i)"/> denotes the set of neighbors of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> . This makes the computation a constant-sized calculation (i.e., does not depend on the size of the system).</p>



<p>For example, in the Ising model, suppose we are at state <img alt="x \in {\{\pm 1\}}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in {\{\pm 1\}}^n"/> . In Glauber dynamics, we pick a vertex <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> u.a.r. and update it to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> with probability <img alt="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}." class="latex" src="https://s0.wp.com/latex.php?latex=p_%7Bi+%5Cmid+N%28i%29%7D%28%2B+%5Cmid+x_%7BN%28i%29%7D%29+%3D+%5Cfrac%7B%5Cexp%28T%5E%7B-1%7D%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D%7B%5Cexp%28-T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29+%2B+%5Cexp%28T%5E%7B-1%7D+%5Csum_%7Bj%5Cin+N%28i%29%7D+x_j%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{i \mid N(i)}(+ \mid x_{N(i)}) = \frac{\exp(T^{-1}\sum_{j\in N(i)} x_j)}{\exp(-T^{-1} \sum_{j\in N(i)} x_j) + \exp(T^{-1} \sum_{j\in N(i)} x_j)}."/></p>



<h1 id="scn:mixing_in_time">Mixing in time</h1>



<p>Mixing in time means that the dynamics will equilibrate rapidly. It turns out that this is equivalent to mixing in space, which means that <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> itself has decaying correlations. For example, the Ising model at low temperature has a lot of long-range correlations, but at high temperature it does not. For the high temperature regime, we can prove that mixing in time occurs. We will prove this for the ferromagnetic Ising model. The result is known more generally, but the proofs are much easier for the Ising model.</p>



<p>People have known about the Metropolis-Hastings algorithm since the 1950s, but only recently have researchers been able to prove convergence guarantees for the 2D Ising model. There is a large gap between theory and practice, but in some situations we can prove that the algorithm works.</p>



<p>Sampling from the distribution is roughly equivalent to estimating the partition function (sampling-counting equivalence). There have been many papers addressing tasks such as estimating the non-negative permanent, the number of colorings of a graph, etc.<sup><a href="https://windowsontheory.org/feed/#fn_2">2</a></sup> A dominant way of accomplishing these tasks is proving that the Metropolis-Hastings algorithm converges for these problems. It is easy to find algorithms for these problems that converge to Gibbs distributions, but the convergence may take exponential time.</p>



<p>We will look at the situation when the energy function looks like the Ising model, in the sense that the interactions are local and reflect the structure of some underlying space. Also, assume that the interactions are of size <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> and that the scaling comes from the size of the system. When can we expect that our algorithms work? There are two main cases when we can argue that there should be rapid mixing.</p>



<ul><li>High temperature regime: The system is very disordered, and in the limit as the temperature approaches infinity, we get the uniform distribution.</li><li>One-dimension: In 1D, we can exactly compute the partition function using dynamic programming. Before, we mentioned that if there are a sea of <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> s and an island of <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> s, then it is energetically favorable for the island to shrink; note that this is no longer true in 1D. In a way, 1D systems are more “boring” because they cannot exhibit arbitrarily long-range correlations.</li></ul>



<p>In this part of the blog post, we will try to be more proof-oriented. We will start by explaining why it is plausible that high temperature means that the chain will mix rapidly in time.</p>



<h2 id="coupling-method">Coupling method</h2>



<p>One method of proving rates of convergence for Markov chains is by analzying the spectral gap. Another method is the <strong>coupling method</strong>.</p>



<p>The idea behind the coupling method is to start with two configurations <img alt="X(0),Y(0) \in \Omega" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29%2CY%280%29+%5Cin+%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0),Y(0) \in \Omega"/> . We want each one to evolve under the Markov chain.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-6787" src="https://windowsontheory.files.wordpress.com/2018/12/p4.png?w=600"/></figure>



<p>The key part is that there is still some freedom with respect to what the dynamics looks like. In particular, we are allowed to correlate the <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> processes. Thus, we are defining a joint transition probability <img alt="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7BX%281%29%3Dx%281%29%2CY%281%29%3Dy%281%29+%5Cmid+X%280%29%2CY%280%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{X(1)=x(1),Y(1)=y(1) \mid X(0),Y(0)\}"/> . We want to design the process such that <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> are closer together than <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> . Imagine that we have two particles bouncing around. Each particle follows the dynamics of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> , but they are correlated so that they drift together, and once they meet, they stick together. It turns out that the mixing time can be upper bounded by the time it takes for the particles to meet each other.</p>



<p>Assume we have some sort of distance function <img alt="\;\mathrm{dist}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}"/> on the underlying space and we can prove that <img alt="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%28X%281%29%2CY%281%29%29+%5Cle+%5Cexp%28-%5Calpha%29+%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\;\mathrm{dist}(X(1),Y(1)) \le \exp(-\alpha) \;\mathrm{dist}(X(0),Y(0))"/> . Then, it turns out that the mixing time <img alt="t_{\rm mix}(\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon)"/> , i.e. the time required to get within <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> of the stationary distribution, is upper bounded as</p>



<p> <img alt="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%5C%7B%28%5C%3B%5Cmathrm%7Bdiam%7D%5COmega%29%2F%5Cepsilon%5C%7D%7D%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) \le \frac{\log\{(\;\mathrm{diam}\Omega)/\epsilon\}}{\alpha}"/> </p>



<p>Initially, the two particles can be <img alt="\;\mathrm{diam}\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiam%7D%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{diam}\Omega"/> apart, but the expected distance is exponentially shrinking as we run the coupling, so the mixing time is logarithmic in the diameter.</p>



<p>The distance between probability distributions is defined as follows. Let <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> be two probability distributions on <img alt="\Omega" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega"/> . Then, the metric is:<sup><a href="https://windowsontheory.org/feed/#fn_3">3</a></sup></p>



<p> <img alt="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+%5C%7Cp-q%5C%7C_1+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bx+%5Cin+%5COmega%7D%7Cp%28x%29-q%28x%29%7C+%3D+%5Cmin_%7B%5Csubstack%7B%28X%2CY%29+%5Csim+r+%5Cin+%7B%5Cmathcal%7BP%7D%7D%28%5COmega+%5Ctimes+%5COmega%29+%5C%5C+r_1+%3D+p+%5C%5C+r_2+%3D+q%7D%7D+%7B%5Cmathbb+P%7D_r%5C%7BX+%5Cne+Y%5C%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{2} \|p-q\|_1 = \frac{1}{2}\sum_{x \in \Omega}|p(x)-q(x)| = \min_{\substack{(X,Y) \sim r \in {\mathcal{P}}(\Omega \times \Omega) \\ r_1 = p \\ r_2 = q}} {\mathbb P}_r\{X \ne Y\}."/> </p>



<p>In this expression, <img alt="r_1" class="latex" src="https://s0.wp.com/latex.php?latex=r_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_1"/> and <img alt="r_2" class="latex" src="https://s0.wp.com/latex.php?latex=r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_2"/> denote the first and second marginals of <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> respectively. The minimum is taken over all <em>couplings</em> of <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> . This is the correct way to measure the distance between distributions. To give some intuition for this quantity, the quantity on the right represents the best <em>test</em> to distinguish the two distributions. If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> are the same, we can take a coupling in which <img alt="X \sim p" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csim+p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \sim p"/> and <img alt="Y \sim q" class="latex" src="https://s0.wp.com/latex.php?latex=Y+%5Csim+q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y \sim q"/> are always identical. If <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> and <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> have disjoint supports, then no matter what coupling we use, <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> will never be equal.</p>



<p>It suffices to consider when <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> are neighbors, i.e. at distance <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> apart. This is because if we have <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> far apart, then we could look at the path between them and reduce to the case when they are neighbors. Formally, this is known as <em>path coupling</em>. The formal statement is in Theorem 12.3 of <a href="https://windowsontheory.org/feed/#nature">[4]</a>:</p>



<p><strong>Theorem 3</strong>: <em>Let <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> be a connected weighted graph on the state space, where no edge has weight less than <img alt="d_{\min}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmin%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{\min}"/> . Let <img alt="d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d(C,C')"/> be the length of the shortest path from <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> to <img alt="C'" class="latex" src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'"/> in <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> and let <img alt="d_{\max} = \max_{C,C' \in \Omega} d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7B%5Cmax%7D+%3D+%5Cmax_%7BC%2CC%27+%5Cin+%5COmega%7D+d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{\max} = \max_{C,C' \in \Omega} d(C,C')"/> be the diameter of <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> . Suppose there is a coupling such that for some <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta &gt; 0"/> </em>,</p>



<p> <img alt="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5Cbigl%5Bd%5Cbigl%28X%281%29%2CY%281%29%5Cbigr%29+%5Cbigm%5Cvert+%5Cbigl%28X%280%29%2CY%280%29%5Cbigr%29+%3D+%28C%2CC%27%29%5Cbigr%5D+%5Cle+%281-%5Cdelta%29d%28C%2CC%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\bigl[d\bigl(X(1),Y(1)\bigr) \bigm\vert \bigl(X(0),Y(0)\bigr) = (C,C')\bigr] \le (1-\delta)d(C,C')"/> </p>



<p><em>for all neighboring pairs <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> , <img alt="C'" class="latex" src="https://s0.wp.com/latex.php?latex=C%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C'"/> , i.e., those pairs connected by an edge in <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> . Then, the mixing time is bounded by </em></p>



<p> <img alt="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}." class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%5Cle+%5Cfrac%7B%5Clog%28%5Cepsilon%5E%7B-1%7Dd_%7B%5Cmax%7D%2Fd_%7B%5Cmin%7D%29%7D%7B%5Cdelta%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) \le \frac{\log(\epsilon^{-1}d_{\max}/d_{\min})}{\delta}."/> </p>



<h2 id="glauber-dynamics-at-high-temperature">Glauber dynamics at high temperature</h2>



<p>Recall that in Glauber dynamics, we pick a site <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> randomly and then update the site conditioned on its neighbors. The first way we will couple together <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> is by picking the <em>same</em> site for both of them.</p>



<ol><li>Pick a random <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> .</li><li>If <img alt="{X(0)}_{N(i)} = {Y(0)}_{N(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_%7BN%28i%29%7D+%3D+%7BY%280%29%7D_%7BN%28i%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_{N(i)} = {Y(0)}_{N(i)}"/> , then set <img alt="{X(1)}_i = {Y(1)}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%281%29%7D_i+%3D+%7BY%281%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(1)}_i = {Y(1)}_i"/> (if the neighborhoods of the two points agree, then update them the same way). Otherwise, update them using the best possible coupling, i.e., pick a coupling for <img alt="({X(1)}_i, {Y(1)}_i)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%7BX%281%29%7D_i%2C+%7BY%281%29%7D_i%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="({X(1)}_i, {Y(1)}_i)"/> which minimizes <img alt="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb+P%7D%5C%7B+%7BX%281%29%7D_i+%5Cne+%7BY%281%29%7D_i+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathbb P}\{ {X(1)}_i \ne {Y(1)}_i \}"/> .</li></ol>



<p>So if <img alt="X(0) = Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29+%3D+Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0) = Y(0)"/> , then the points will never drift apart. The reason why analyzing this coupling is non-trivial is because there is a chance that the distance between the two points can <em>increase</em>.</p>



<p>Assume that the degree of the graph is <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> . Suppose that <img alt="\;\mathrm{dist}(X(0),Y(0)) = 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28X%280%29%2CY%280%29%29+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}(X(0),Y(0)) = 1"/> , that is, there is a single <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> such that <img alt="{X(0)}_a \ne {Y(0)}_a" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_a \ne {Y(0)}_a"/> . What will happen to <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> ? We start by picking a random <img alt="i \in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in [n]"/> . There are three cases:</p>



<ol><li><img alt="i \notin (\{a\} \cup N(a))" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cnotin+%28%5C%7Ba%5C%7D+%5Ccup+N%28a%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \notin (\{a\} \cup N(a))"/> (with probability <img alt="1 - (\Delta + 1)/n" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%28%5CDelta+%2B+1%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 - (\Delta + 1)/n"/> ): Nothing changes; <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> agree at <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> , and <img alt="X(1)" class="latex" src="https://s0.wp.com/latex.php?latex=X%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(1)"/> and <img alt="Y(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(1)"/> will also agree at <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> . The distance remains at <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> .</li><li><img alt="i = a" class="latex" src="https://s0.wp.com/latex.php?latex=i+%3D+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i = a"/> (with probability <img alt="1/n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/n"/> ): We picked the one spot in which the two configurations differ. The neighborhoods of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> are the same for <img alt="X(0)" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0)"/> and <img alt="Y(0)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%280%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y(0)"/> , so we update in the same way for both processes, and the distance drops to <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> .</li><li><img alt="i \in N(a)" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+N%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \in N(a)"/> (with probability <img alt="\Delta/n" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta/n"/> ): We could have different updates. Here, we have to use the high temperature assumption, which says that if we change one bit, the probability of a configuration cannot change too much.In the Ising model, <img alt="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D+x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = \sum_{i,j=1}^n J_{i,j} x_i x_j"/> . Changing <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> can bias the energy by at most <img alt="\Delta\max_i J_{i,a}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta%5Cmax_i+J_%7Bi%2Ca%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta\max_i J_{i,a}"/> , so the expected distance afterwards is <img alt="1 + O(\max_{i,j=1}^n J_{i,j}/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2B+O%28%5Cmax_%7Bi%2Cj%3D1%7D%5En+J_%7Bi%2Cj%7D%2FT%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 + O(\max_{i,j=1}^n J_{i,j}/T)"/> .</li></ol>



<p>Adding these cases up to get the overall expected distance gives</p>



<p> <img alt="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7B%5Cmathbb+E%7D%5C%3B%5Cmathrm%7Bdist%7D%5Cbigl%28X%281%29%2C+Y%281%29%5Cbigr%29+%3D+1-%5Cfrac%7B1%7D%7Bn%7D+%2B+%5Cunderbrace%7BO%5CBigl%28%5Cfrac%7B%5CDelta+J_%7B%5Cmax%7D%7D%7BT%7D%5CBigr%29%7D_%7B%5Cle+1%7D%5Cfrac%7B1%7D%7Bn%7D+%3D+1+-+%5Cfrac%7Bc%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{\mathbb E}\;\mathrm{dist}\bigl(X(1), Y(1)\bigr) = 1-\frac{1}{n} + \underbrace{O\Bigl(\frac{\Delta J_{\max}}{T}\Bigr)}_{\le 1}\frac{1}{n} = 1 - \frac{c}{n}"/> </p>



<p>for <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> large enough, so the expected distance will shrink. This argument also tells us how large the temperature must be, which is important for applications. This gives us <img alt="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D%28%5Cepsilon%29+%3D+O%5CBigl%28n%5Clog%5Cfrac%7Bn%7D%7B%5Cepsilon%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix}(\epsilon) = O\Bigl(n\log\frac{n}{\epsilon}\Bigr)."/> Notice that this is the same dependence as the coupon collector problem. Therefore, in the high temperature regime, the system behaves qualitatively as if there are no correlations.</p>



<h2 id="temporal-and-spatial-mixing-equivalence">Temporal and spatial mixing equivalence</h2>



<p>The analysis of Glauber dynamics at high temperature is already a version of the equivalence between mixing in time and mixing in space. It says that if the correlations even with the immediate neighbors of a node are weak, then Glauber dynamics rapidly mixes.</p>



<p>Now, we want to consider the situation in which there can be strong correlations between immediate neighbors, but weak correlation with far away sites. We want to show that spatial mixing implies temporal mixing.</p>



<p>We will give a few definitions of correlation decay. (Note: The definitions of correlation decay below are not exactly the ones from Aram’s lecture. These definitions are from <a href="https://windowsontheory.org/feed/#martinelli1">[5]</a> and <a href="https://windowsontheory.org/feed/#martinelli2">[6]</a>.)</p>



<p>For non-empty <img alt="W \subseteq V" class="latex" src="https://s0.wp.com/latex.php?latex=W+%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W \subseteq V"/> and <img alt="\tau \in \Sigma^{V\setminus W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau \in \Sigma^{V\setminus W}"/> , let <img alt="\mu_W^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_W^\tau"/> be the distribution of the spins in <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> conditional on the spins in <img alt="V \setminus W" class="latex" src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V \setminus W"/> being fixed to <img alt="\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau"/> . For <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> , let <img alt="\mu_{W,\Delta}^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_{W,\Delta}^\tau"/> be the marginal of <img alt="\mu_W^\tau" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_W%5E%5Ctau&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mu_W^\tau"/> on the spins in <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> . We will assume that the interactions between the spins have finite range <img alt="r &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=r+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r &gt; 0"/> , and <img alt="\partial_r W" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial_r+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial_r W"/> denotes the <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> -boundary of <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> , i.e., <img alt="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%5Cin+V+%5Csetminus+W+%3A+%5C%3B%5Cmathrm%7Bdist%7D%28v%2CW%29+%5Cle+r%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v \in V \setminus W : \;\mathrm{dist}(v,W) \le r\}"/> .</p>



<ul><li>(<strong>Weak decay of correlations</strong>) Weak spatial mixing holds for <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> if there exist constants <img alt="C, \xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=C%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C, \xi &gt; 0"/> such that for any subset <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> , <img alt="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Csum_%7Bx%5Cin%5CDelta%2C+%5C%3B+y+%5Cin+%5Cpartial_r+W%7D+%5Cexp%5CBigl%28-+%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28x%2Cy%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sup_{\tau,\tau' \in \Sigma^{V\setminus W}}\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\sum_{x\in\Delta, \; y \in \partial_r W} \exp\Bigl(- \frac{\;\mathrm{dist}(x,y)}{\xi}\Bigr)."/></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing holds for <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="W"/> if there exist constants <img alt="C,\xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=C%2C%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C,\xi &gt; 0"/> such that for every <img alt="\Delta \subseteq W" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta+%5Csubseteq+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta \subseteq W"/> and every <img alt="\tau,\tau' \in \Sigma^{V\setminus W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctau%2C%5Ctau%27+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\tau,\tau' \in \Sigma^{V\setminus W}"/> differing only at site <img alt="y \in V\setminus W" class="latex" src="https://s0.wp.com/latex.php?latex=y+%5Cin+V%5Csetminus+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y \in V\setminus W"/> , <img alt="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7C%5Cmu_%7BW%2C%5CDelta%7D%5E%5Ctau+-+%5Cmu_%7BW%2C%5CDelta%7D%5E%7B%5Ctau%27%7D%5C%7C_1+%5Cle+C%5Cexp%5CBigl%28-%5Cfrac%7B%5C%3B%5Cmathrm%7Bdist%7D%28y%2C%5CDelta%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\|\mu_{W,\Delta}^\tau - \mu_{W,\Delta}^{\tau'}\|_1 \le C\exp\Bigl(-\frac{\;\mathrm{dist}(y,\Delta)}{\xi}\Bigr)."/></li><li>(<strong>Strong decay of correlations</strong>) Strong spatial mixing in the <em>truncated</em> sense holds for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> if there exist <img alt="n, \xi &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=n%2C+%5Cxi+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n, \xi &gt; 0"/> such that for all functions <img alt="f, g : \Omega \to {\mathbb R}" class="latex" src="https://s0.wp.com/latex.php?latex=f%2C+g+%3A+%5COmega+%5Cto+%7B%5Cmathbb+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f, g : \Omega \to {\mathbb R}"/> which depend only on the sites at <img alt="\Lambda_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5CLambda_f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Lambda_f"/> and <img alt="\Lambda_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5CLambda_g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Lambda_g"/> respectively and such that <img alt="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdist%7D%28%5CLambda_f%2C%5CLambda_g%29+%5Cge+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{dist}(\Lambda_f,\Lambda_g) \ge n"/> , <img alt="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7B%5Ctau+%5Cin+%5CSigma%5E%7BV%5Csetminus+W%7D%7D+%5C%3B%5Cmathrm%7Bcov%7D_%7B%5Cmu_W%5E%5Ctau%7D%28f%2C+g%29+%5Cle+%7C%5CLambda_f%7C%7C%5CLambda_g%7C%5C%7Cf%5C%7C_%5Cinfty+%5C%7Cg%5C%7C_%5Cinfty+%5Cexp%5CBigl%28-%5Cfrac%7Bd%28%5CLambda_f%2C%5CLambda_g%29%7D%7B%5Cxi%7D%5CBigr%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sup_{\tau \in \Sigma^{V\setminus W}} \;\mathrm{cov}_{\mu_W^\tau}(f, g) \le |\Lambda_f||\Lambda_g|\|f\|_\infty \|g\|_\infty \exp\Bigl(-\frac{d(\Lambda_f,\Lambda_g)}{\xi}\Bigr)."/></li></ul>



<p>Here, <img alt="\xi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\xi"/> is the <strong>correlation length</strong> (in physics, it is the characteristic length scale of a system). In the disordered phase, the correlation length is a constant independent of system size. For our purposes, the main consequence of these definitions is that the effective interaction range of each spin is <img alt="O(\xi)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cxi%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\xi)"/> . For the Ising model, there is a key simplification due to <em>monotonicity</em>. Namely, the ferromagnetic Ising model has the nice property (which is not true for other models) that if we flip a sign from <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> to <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> , this only makes <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> more likely everywhere. This is because the spins want to agree. There are a lot of boundary conditions to consider, but here, due to monotonicity, we only need to consider two: all of the spins are <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> , and all of the spins are <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> . All <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spins will give the highest probability of a <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spin, and all <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> spin will give the lowest probability of a <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> spin. This monotonicity property is generally not required for time-space mixing equivalence to hold, but it greatly simplifies proofs.</p>



<p>It is a very non-obvious fact that all of these notions of spatial mixing are equivalent. We will sketch a proof that strong correlation decay implies that <img alt="t_{\rm mix} = O(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=t_%7B%5Crm+mix%7D+%3D+O%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_{\rm mix} = O(n\log n)"/> .</p>



<p>The idea is to use another coupling argument. Let <img alt="X(0), Y(0) \in {\{\pm 1\}}^V" class="latex" src="https://s0.wp.com/latex.php?latex=X%280%29%2C+Y%280%29+%5Cin+%7B%5C%7B%5Cpm+1%5C%7D%7D%5EV&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X(0), Y(0) \in {\{\pm 1\}}^V"/> differ in one coordinate, i.e., <img alt="{X(0)}_a \ne {Y(0)}_a" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_a+%5Cne+%7BY%280%29%7D_a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_a \ne {Y(0)}_a"/> and <img alt="{X(0)}_i = {Y(0)}_i" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%280%29%7D_i+%3D+%7BY%280%29%7D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{X(0)}_i = {Y(0)}_i"/> for <img alt="i \ne a" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i \ne a"/> . We want to argue that the expected distance between the processes will decrease. The proof uses a generalization of Glauber dynamics called <strong>block Glauber dynamics</strong>. In Glauber dynamics, we take a single spin and resample it conditioned on its neighbors. In block Glauber dynamics, we take an <img alt="L\times L" class="latex" src="https://s0.wp.com/latex.php?latex=L%5Ctimes+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L\times L"/> box and resample it conditioned on its neighbors. There is an argument, called <em>canonical paths</em>, which can be used to show that if block Glauber dynamics mixes, then regular Glauber dynamics also mixes (slightly more slowly; we lose a <img alt="\;\mathrm{poly}(L)" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bpoly%7D%28L%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{poly}(L)"/> factor, but anyway <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> will be a large constant) so analyzing block Glauber dynamics is fine.</p>



<p>If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> lies in the box, then the expected change in distance is <img alt="-L^2/n" class="latex" src="https://s0.wp.com/latex.php?latex=-L%5E2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-L^2/n"/> . If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> is far away from the box, then there is no change. If <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> is in the boundary of the box, then it is possible for the distance to increase. However, strong spatial mixing allows us to control the influence of a single site, so the expected change in distance is bounded by <img alt="O(L\xi^2/n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28L%5Cxi%5E2%2Fn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(L\xi^2/n)"/> . Now, since <img alt="\xi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cxi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\xi"/> is a constant, if we choose <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L"/> sufficiently large, then we will have the same situation as in the high temperature case: the expected distance will exponentially shrink over time.</p>



<h1 id="quantum-systems">Quantum systems</h1>



<p>The quantum version of Markov chains has many more difficulties. The first difficulty is that the Hammersley-Clifford theorem (which we have been relying on throughout this blog post) fails.</p>



<h2 id="notation">Notation</h2>



<p>To properly discuss what we mean, let’s set up some notation. Readers already familiar with density matrices, quantum entropy, and quantum mutual information may wish to skip to the next subsection. Most of the time we discuss quantum objects here, we’ll be using density matricies, often denoted <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> . A density matrix can be thought of as an extension to regular quantum states <img alt="|{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle "/> , where there is some classical source of uncertainty.</p>



<p>A density matrix is a positive semidefinite matrix with trace <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . This extends the notion of a classical probability distribution; in the quantum setting, a classical probability distribution <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> (thought of as a vector whose entries sum to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> ) is represented as the density matrix <img alt="\;\mathrm{diag}(p)" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{diag}(p)"/> .</p>



<p>For example, we can consider a situation in which there is a <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> probability that we started with the quantum state <img alt="|{\psi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle "/> and a <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> probability that we started with the quantum state <img alt="|{\phi}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cphi%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\phi}\rangle "/> . This would be denoted as follows:</p>



<p> <img alt="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5Clangle%7B%5Cpsi%7D%7C+%2B+%5Cfrac%7B1%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle+%5Clangle%7B%5Cphi%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho = \frac{1}{2} |{\psi}\rangle \langle{\psi}| + \frac{1}{2} |{\phi}\rangle \langle{\phi}| "/> </p>



<p>Density matricies are generally useful for a lot of tasks, but for our purposes a density matrix will be used to discuss both the classical and quantum “uncertainty” we have about what state we have.</p>



<p>Now let’s also talk about a second important piece of notation: the tensor product. Often when discussing quantum states, it is important to discuss multiple quantum states simultaneously. For example, Alice has one system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and Bob has another system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . However, these systems might be entangled, meaning that the results of the two systems are correlated.</p>



<p>For instance, let us consider the following state:</p>



<p> <img alt="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+_A+%7C%7B%2B%7D%5Crangle+_B+%2B+%7C%7B-%7D%5Crangle+_A+%7C%7B-%7D%5Crangle+_B+%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\psi}\rangle = \frac{1}{\sqrt{2}}\left( |{+}\rangle _A |{+}\rangle _B + |{-}\rangle _A |{-}\rangle _B \right)"/> </p>



<p>This particular state has the property that Alice and Bob will always both measure <img alt="+" class="latex" src="https://s0.wp.com/latex.php?latex=%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+"/> or they will both measure <img alt="-" class="latex" src="https://s0.wp.com/latex.php?latex=-&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-"/> . The notation for tensors is often ambiguous in the literature as there are many ways of specifying tensors. For instance, above we used subscripts to explicitly denote which particle was in system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and which was in system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . One may also choose to simply use the index of the system as below. The symbol <img alt="\otimes" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cotimes&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\otimes"/> is used to denote a tensor between states (where it is assumed that the first state is system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and the second, system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> ). Gradually folks may shorten the notation as follows:</p>



<p> <img alt="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%7D%5Crangle+%7C%7B%2B%7D%5Crangle+%2B+%7C%7B-%7D%5Crangle+%7C%7B-%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29%5C%5C+%7C%7B%5Cpsi%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%5Cbegin%7Bpmatrix%7D+1%5C%5C0+%5Cend%7Bpmatrix%7D+%5Cotimes+%5Cbegin%7Bpmatrix%7D+0%5C%5C1+%5Cend%7Bpmatrix%7D+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{+}\rangle |{+}\rangle + |{-}\rangle |{-}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}}\left( |{++}\rangle + |{--}\rangle \right)\\ |{\psi}\rangle &amp;= \frac{1}{\sqrt{2}} \begin{pmatrix} 1\\0 \end{pmatrix} \otimes \begin{pmatrix} 0\\1 \end{pmatrix} \end{aligned} "/> </p>



<p>These are all notations for the same state. Let’s now talk about this state in the context of a density matrix. The density matrix of this state is as follows:</p>



<p> <img alt="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%2B+%7C%7B--%7D%5Crangle+%5Cright%29+%5Cleft%28+%5Clangle%7B%2B%2B%7D%7C+%2B+%5Clangle%7B--%7D%7C+%5Cright%29%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%5C%5C+%5Crho_%7BA%2CB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1%260%260%261%5C%5C0%260%260%260%5C%5C0%260%260%260%5C%5C1%260%260%261+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle + |{--}\rangle \right) \left( \langle{++}| + \langle{--}| \right)\\ \rho_{A,B} &amp;= \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) \\ \rho_{A,B} &amp;= \frac{1}{2} \begin{pmatrix} 1&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\\1&amp;0&amp;0&amp;1 \end{pmatrix}\end{aligned} "/> </p>



<p>Writing the density matrix <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> as <img alt="\rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B}"/> makes explicit that this is the density matrix over systems <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> .</p>



<p>A crucial operation that one will often perform using density matricies is the partial trace. The partial trace is a way of allowing us to consider only a smaller part of the larger part of the system, while taking into account the influence of the larger system around it.</p>



<p>Here’s an example: Suppose Bob wants to know what his state is. However, Bob really doesn’t care about Alice’s system and just wants to know what the density matrix for his system is. Bob’s density matrix is simply the following density matrix (a 50% chance of being in <img alt="|{+}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%2B%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{+}\rangle "/> and a 50% chance of being in <img alt="|{-}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B-%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{-}\rangle "/> ).</p>



<p> <img alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+%5Clangle%7B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+%5Clangle%7B-%7D%7C+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle \langle{+}| + |{-}\rangle \langle{-}| \right) \end{aligned} "/> </p>



<p>More explicitly, we could write the following:</p>



<p> <img alt="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Crho_%7BB%7D+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \rho_{B} &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) \end{aligned} "/> </p>



<p>The partial trace is an operation that will let us take our original density matrix <img alt="\rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B}"/> and generates a new density matrix <img alt="\rho_B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_B"/> that ignores system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> . This is specifically called the partial trace over <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , or <img alt="\;\mathrm{tr}_A" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}_A"/> .</p>



<p>So how do we do this? We simply sum over the state <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> (effectively taking a trace, but only along one axis):</p>



<p> <img alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Csum_i+%5Clangle%7Bi%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7Bi%7D%5Crangle+_A%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \sum_i \langle{i}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{i}\rangle _A\end{aligned} "/> </p>



<p>This is easier to evaluate using certain choices of notation:</p>



<p> <img alt="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D+%26%3D+%5Clangle%7B%2B%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%5C%5C%26%5Cqquad+%7B%7D%2B+%5Clangle%7B-%7D%7C+_A+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%2B%7D%5Crangle+%5Clangle%7B--%7D%7C+%2B+%7C%7B--%7D%5Crangle+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B%2B%7D%5Crangle+_A+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B%2B%2B%7D%7C+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B--%7D%7C+%5Cright%29+%7C%7B-%7D%5Crangle+_A%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%5Cright%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%7C%7B%2B%7D%5Crangle+_B+%5Clangle%7B%2B%7D%7C+_B+%2B+%7C%7B-%7D%5Crangle+_B+%5Clangle%7B-%7D%7C+_B+%5Cright%29+%3D+%5Crho_B%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \;\mathrm{tr}_A \rho_{A,B} &amp;= \langle{+}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{+}\rangle _A \\&amp;\qquad {}+ \langle{-}| _A \frac{1}{2} \left( |{++}\rangle \langle{++}| + |{--}\rangle \langle{++}| + |{++}\rangle \langle{--}| + |{--}\rangle \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{++}| + |{+}\rangle _B \langle{--}| \right) |{+}\rangle _A + \frac{1}{2} \left( |{-}\rangle _B \langle{++}| + |{-}\rangle _B \langle{--}| \right) |{-}\rangle _A\\ &amp;= \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B \right) + \frac{1}{2} \left( |{-}\rangle _B \langle{-}| _B \right) = \frac{1}{2} \left( |{+}\rangle _B \langle{+}| _B + |{-}\rangle _B \langle{-}| _B \right) = \rho_B\end{aligned} "/> </p>



<p>This gives us the answer that we had expected.</p>



<p>We now have all of the tools we need to talk about quantum entropy. Intuitively, entropy can be thought of as the amount of uncertainty we have for our system, or equivalently the amount of information it takes to define our system. The entropy for a quantum system <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is defined as follows:</p>



<p> <img alt="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H%28%5Crho%29+%26%3D+-%5C%3B%5Cmathrm%7Btr%7D%28%5Crho+%5Clog_2+%5Crho%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H(\rho) &amp;= -\;\mathrm{tr}(\rho \log_2 \rho)\end{aligned} "/> </p>



<p>Note that here we use the shorthand <img alt="\rho_B" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_B"/> to denote <img alt="\;\mathrm{tr}_A \rho_{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D_A+%5Crho_%7BA%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}_A \rho_{A,B}"/> . Here, writing <img alt="\;\mathrm{tr}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%3B%5Cmathrm%7Btr%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\;\mathrm{tr}"/> without the subscript indicates that this is the full or normal trace that one might expect (or equivalently performing the partial trace over all systems). We can now define the conditional entropy of a system as follows:</p>



<p> <img alt="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BH%28A+%5Cmid+B%29%7D_%5Crho+%26%3D+H%28%5Crho_%7BA%2CB%7D%29+-+H%28%5Crho_B%29%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {H(A \mid B)}_\rho &amp;= H(\rho_{A,B}) - H(\rho_B)\end{aligned} "/> </p>



<p>This definition intuitively makes sense since we can think of conditional entropy as the amount of information it takes to describe our joint system <img alt="(A,B)" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A,B)"/> , given that we already know what <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is.</p>



<p>We can now discuss quantum mutual information, the amount of information that measuring system <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> will provide you about system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . Like the classical case, this is defined as follows:</p>



<p> <img alt="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB%29%7D_%5Crho+%26%3D+%7BH%28A%2CB%29%7D_%5Crho+-+%7BH%28A%5Cmid+B%29%7D_%5Crho+-+%7BH%28B%5Cmid+A%29%7D_%5Crho%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {I(A;B)}_\rho &amp;= {H(A,B)}_\rho - {H(A\mid B)}_\rho - {H(B\mid A)}_\rho\end{aligned} "/> </p>



<p>We can now finally discuss <strong>quantum mutual information (QCMI)</strong>, defined as follows: <img alt="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%3D+%7BI%28A%3BB%2CC%29%7D_%5Crho+-+%7BI%28A%3BC%29%7D_%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{I(A;B \mid C)}_\rho = {I(A;B,C)}_\rho - {I(A;C)}_\rho"/> . With some algebraic simplifications, one can arrive at the expression:</p>



<p> <img alt="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7BI%28A%3BB+%5Cmid+C%29%7D_%5Crho+%26%3D+%7BH%28A%2CC%29%7D_%5Crho+%2B+%7BH%28B%2CC%29%7D_%5Crho+-+%7BH%28A%2CB%2CC%29%7D_%5Crho+-+%7BH%28C%29%7D_%5Crho.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} {I(A;B \mid C)}_\rho &amp;= {H(A,C)}_\rho + {H(B,C)}_\rho - {H(A,B,C)}_\rho - {H(C)}_\rho.\end{aligned} "/> </p>



<p>The QCMI equals <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> if and only if <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is a <strong>quantum Markov state</strong>. Classically, the entropic characterization of conditional independence corresponds to an algebraic characterization.</p>



<h2 id="recovery-maps">Recovery Maps</h2>



<p>Here, the algebraic characterization is more grueling. We have</p>



<p> <img alt="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Cexp%28%5Clog+%5Crho_%7BAB%7D+%2B+%5Clog+%5Crho_%7BBC%7D+-+%5Clog+%5Crho_B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC} = \exp(\log \rho_{AB} + \log \rho_{BC} - \log \rho_B)"/> </p>



<p>Equivalently,</p>



<p> <img alt="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BBC%7D%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%3D+R_%7BB%5Cto+AB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC} = \rho_{AB}^{1/2} \rho_B^{-1/2} \rho_{BC}\rho_B^{-1/2} \rho_{AB}^{1/2} = R_{B\to AB}(\rho_{BC})"/> </p>



<p>Here, <img alt="R_{B\to AB}" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+AB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to AB}"/> is called the <strong>Petz recovery map</strong>,<sup><a href="https://windowsontheory.org/feed/#fn_4">4</a></sup> <img alt="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BB%5Cto+AB%7D%28X%29+%3D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D+%5Crho_B%5E%7B-1%2F2%7D+X%5Crho_B%5E%7B-1%2F2%7D+%5Crho_%7BAB%7D%5E%7B1%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{B\to AB}(X) = \rho_{AB}^{1/2} \rho_B^{-1/2} X\rho_B^{-1/2} \rho_{AB}^{1/2}"/> . One can think of a recovery may as a way that we can reconstruct the entire system <img alt="A, B" class="latex" src="https://s0.wp.com/latex.php?latex=A%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A, B"/> using just system <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . It is not obvious that this is a quantum channel, but it is.</p>



<p>Suppose <img alt="\rho" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho"/> is a probability distribution, so <img alt="\rho =\;\mathrm{diag}(p)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho+%3D%5C%3B%5Cmathrm%7Bdiag%7D%28p%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho =\;\mathrm{diag}(p)"/> for some vector <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> . Then, all of the density matrices are diagonal and commuting. Then, the recovery map means that we divide by <img alt="p_B" class="latex" src="https://s0.wp.com/latex.php?latex=p_B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_B"/> and multiply by <img alt="p_{AB}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7BAB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{AB}"/> , i.e., multiply by <img alt="p_{A \mid B}" class="latex" src="https://s0.wp.com/latex.php?latex=p_%7BA+%5Cmid+B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_{A \mid B}"/> . This is the natural thing to do if we lost our information about <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and were trying to figure out what <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> was based on our knowledge of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> . This is why <img alt="R_{B\to A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to A,B}"/> is known as a <em>recovery</em> map, and it is used to discuss conditional distributions in the quantum setting. In the classical case, if we start with <img alt="B, C" class="latex" src="https://s0.wp.com/latex.php?latex=B%2C+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B, C"/> , look only at <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , and use this to reconstruct <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , then we would have the whole state in a Markov chain. That is why this is a plausible quantum version of being a Markov chain.</p>



<p>However, quantum Gibbs states are not, in general, quantum Markov chains. The failure of this statement to hold is related to <em>topological order</em>, which is similar to the degrees of freedom that show up in error correcting codes.</p>



<h2 id="quantum-markov-networks">Quantum Markov Networks</h2>



<p>Here, we will formally define a quantum Markov network. The reference for this is <a href="https://windowsontheory.org/feed/#leifer">[7]</a>.</p>



<p>Let <img alt="G = (V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=G+%3D+%28V%2C+E%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G = (V, E)"/> be a finite graph. We associate with each vertex <img alt="v \in V" class="latex" src="https://s0.wp.com/latex.php?latex=v+%5Cin+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v \in V"/> a Hilbert space <img alt="{\mathcal{H}}_v" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\mathcal{H}}_v"/> and we consider a density matrix <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> acting on <img alt="\bigotimes_{v\in V} {\mathcal{H}}_v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbigotimes_%7Bv%5Cin+V%7D+%7B%5Cmathcal%7BH%7D%7D_v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\bigotimes_{v\in V} {\mathcal{H}}_v"/> . Then, <img alt="(G, \rho_V)" class="latex" src="https://s0.wp.com/latex.php?latex=%28G%2C+%5Crho_V%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(G, \rho_V)"/> is a <strong>quantum Markov network</strong> if for all <img alt="U\subseteq V" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Csubseteq+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\subseteq V"/> , <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is conditionally independent of <img alt="V \setminus (U \cup \partial U)" class="latex" src="https://s0.wp.com/latex.php?latex=V+%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V \setminus (U \cup \partial U)"/> given <img alt="\partial U" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpartial+U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\partial U"/> , where the conditional independence statement is w.r.t. <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> and means that the corresponding QCMI satisfies <img alt="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%28U%3B+V%5Csetminus+%28U+%5Ccup+%5Cpartial+U%29+%5Cmid+%5Cpartial+U%29%7D_%7B%5Crho_V%7D+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{I(U; V\setminus (U \cup \partial U) \mid \partial U)}_{\rho_V} = 0"/> .</p>



<p>A quantum Markov network is called <strong>positive</strong> if <img alt="\rho_V" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_V"/> has full rank. (Recall that in the statement of the Hammersley-Clifford Theorem, , it is assumed that the distribution is strictly positive.)</p>



<p>Now, consider the following example. First, we introduce the Pauli matrices</p>



<p> <img alt="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csigma%5Ex+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ez+%3A%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%5C%5C+0+%26+-1+%5Cend%7Bbmatrix%7D%2C+%5Cqquad+%5Csigma%5Ey+%3A%3D+%5Cbegin%7Bbmatrix%7D+0+%26+-i+%5C%5C+i+%26+0+%5Cend%7Bbmatrix%7D.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \sigma^x := \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}, \qquad \sigma^z := \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{bmatrix}, \qquad \sigma^y := \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}.\end{aligned} "/> </p>



<p>We define a Hamiltonian on three qubits <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> , <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> , <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> by</p>



<p> <img alt="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3A%3D+%28%5Csigma_A%5Ex+%5Csigma_B%5Ex+%2B+%5Csigma_A%5Ey+%5Csigma_B%5Ey+%2B+%5Csigma_A%5Ez+%5Csigma_B%5Ez%29+I_C+%2B+I_A+%28%5Csigma_B%5Ex+%5Csigma_C%5Ex+%2B+%5Csigma_B%5Ey+%5Csigma_C%5Ey+%2B+%5Csigma_B%5Ez+%5Csigma_C%5Ez%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H := (\sigma_A^x \sigma_B^x + \sigma_A^y \sigma_B^y + \sigma_A^z \sigma_B^z) I_C + I_A (\sigma_B^x \sigma_C^x + \sigma_B^y \sigma_C^y + \sigma_B^z \sigma_C^z)"/> </p>



<p>(Juxtaposition in the above expression signifies the tensor product as discussed before.) Finally, for <img alt="\beta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3E+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta &gt; 0"/> , we define the Gibbs state</p>



<p> <img alt="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D%28%5Cbeta%29+%3A%3D+%5Cfrac%7B1%7D%7BZ%28%5Cbeta%29%7D+%5Cexp%28-%5Cbeta+H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B,C}(\beta) := \frac{1}{Z(\beta)} \exp(-\beta H)"/> </p>



<p>The Hamiltonian here has local terms which correspond to interactions <img alt="(A,B)" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%2CB%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A,B)"/> , <img alt="(B, C)" class="latex" src="https://s0.wp.com/latex.php?latex=%28B%2C+C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(B, C)"/> . However, it can be shown that the QCMI between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> conditioned on <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> w.r.t. <img alt="\rho_{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{A,B,C}"/> is non-zero, which means that this is not a quantum Markov network w.r.t. the line graph <img alt="A \leftrightarrow B \leftrightarrow C" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Cleftrightarrow+B+%5Cleftrightarrow+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A \leftrightarrow B \leftrightarrow C"/> . This demonstrates the failure of the Hammersley-Clifford Theorem in the quantum setting.</p>



<h2 id="important-results">Important Results</h2>



<p>We will briefly discuss the results of two papers.</p>



<ol><li><a href="https://windowsontheory.org/feed/#brandao1">[8]</a> This paper shows that mixing in space implies mixing in time in the quantum case. However, the result of the paper only applies to commuting Hamiltonians. For commuting Hamiltonians, it turns out that quantum Gibbs states are quantum Markov networks. They use a version of Glauber dynamics, which can be simulated on a quantum computer but are also plausible dynamics for a physical system in nature. This is a difficult paper to read, but it is worth digesting if you want to work in the field.</li><li><a href="https://windowsontheory.org/feed/#brandao2">[9]</a> This second paper is much easier and more general, covering non-commuting Hamiltonians, but it requires more conditions. They give a method of preparing the Gibbs state which can run on a quantum computer, but the dynamics are not plausible as a physical system because they are too complicated. The more complicated dynamics allows them to make the proof work. The paper also uses QCMI.They have two assumptions. The first assumption looks like mixing in space (weak correlation decay). The second assumption is that the state looks approximately like a quantum Markov network (this is definitely not met in general). A very important paper in this space is a recent breakthrough (<a href="https://windowsontheory.org/feed/#fawzi">[10]</a>) which characterizes quantum Markov chains. They show that if the QCMI is bounded by <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> , then the recovery map <img alt="R_{B\to A,B}(\rho_{BC})" class="latex" src="https://s0.wp.com/latex.php?latex=R_%7BB%5Cto+A%2CB%7D%28%5Crho_%7BBC%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_{B\to A,B}(\rho_{BC})"/> is <img alt="\epsilon'" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon'"/> -close to <img alt="\rho_{ABC}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7BABC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{ABC}"/> , i.e., low QCMI implies that the recovery map works well. This is trivial to prove classically, but very difficult in the quantum world.The algorithm in <a href="https://windowsontheory.org/feed/#brandao2">[9]</a> is very elegant. Essentially, we take the entire system and punch out constant-sized boxes. If we can reconstruct the region outside of the boxes, then we can use the recovery maps to reconstruct the regions inside of the boxes, and the boxes are far apart enough so they are almost independent. For this argument, we must assume that the QCMI decays exponentially. Whenever we have exponential decay, we get a correlation decay that sets the size of the boxes. It is very difficult to condition on quantum states, but recovery maps provide a sense in which it is meaningful to do so. The paper gives an efficient method of preparing Gibbs states and simulating quantum systems on quantum computers.</li></ol>



<h1 id="additional-reading">Additional reading</h1>



<p>The standard treatment of information theory is <a href="https://windowsontheory.org/feed/#info">[11]</a>. This book contains definitions and properties of entropy, conditional entropy, mutual information, and conditional mutual information.</p>



<p>To see a treatment of the subject of Markov chains from the perspective of probability theory, see <a href="https://windowsontheory.org/feed/#durrett1">[12]</a> or the mathematically more sophisticated counterpart <a href="https://windowsontheory.org/feed/#durrett2">[13]</a>. An introduction to coupling can be found in <a href="https://windowsontheory.org/feed/#mitzenmacher">[14]</a>, as well as <a href="https://windowsontheory.org/feed/#nature">[4]</a> (the latter also contains an exposition to spatial mixing). The connection between Markov chain mixing and the so-called <em>logarithmic Sobolev inequality</em> is described in <a href="https://windowsontheory.org/feed/#cesi">[15]</a>.</p>



<h1 id="scn:appendix">Appendix: Intuition for Markov chains</h1>



<h2 id="random-walk-on-the-cycle">Random walk on the cycle</h2>



<p>We have <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points on the cycle, <img alt="0,1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0,1,\dotsc,n-1"/> . At each step, we move left or right with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/> . We can write the transition matrix as</p>



<p> <img alt="T = \frac{S + S^{-1}}{2}" class="latex" src="https://s0.wp.com/latex.php?latex=T+%3D+%5Cfrac%7BS+%2B+S%5E%7B-1%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T = \frac{S + S^{-1}}{2}"/> </p>



<p>where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is the shift operator <img alt="S |{x}\rangle = |{x+1 \bmod n}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=S+%7C%7Bx%7D%5Crangle+%3D+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S |{x}\rangle = |{x+1 \bmod n}\rangle "/> . The matrix <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is diagonalized by the Fourier transform. Define, for <img alt="k=0,1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D0%2C1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=0,1,\dotsc,n-1"/> ,</p>



<p> <img alt="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7B%5Ctilde+k%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|{\tilde k}\rangle = \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x}\rangle "/> </p>



<p>We have the same amount of amplitude at every point, but there is a varying phase which depends on <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> . If <img alt="k = 0" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 0"/> , we get the all-ones vector. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is small, then the phase is slowly varying. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is large, then the phase is rapidly varying. Look at what happens after we apply the shift operator:</p>



<p> <img alt="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+S+%7C%7B%5Ctilde+k%7D%5Crangle+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D0%7D%5E%7Bn-1%7D+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+x%7D%7Bn%7D+%5CBigr%29+%7C%7Bx%2B1+%5Cbmod+n%7D%5Crangle+%5C%5C+%26%3D+%5Cfrac%7B1%7D%7B%5Csqrt+n%7D+%5Csum_%7Bx%3D1%7D%5En+%5Cexp%5CBigl%28+%5Cfrac%7B2%5Cpi+i+k+%28x-1%29%7D%7Bn%7D+%5CBigr%29+%7C%7Bx+%5Cbmod+n%7D%5Crangle+%3D+%5Cexp%5CBigl%28-+%5Cfrac%7B2%5Cpi+i+k%7D%7Bn%7D+%5CBigr%29+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} S |{\tilde k}\rangle &amp;= \frac{1}{\sqrt n} \sum_{x=0}^{n-1} \exp\Bigl( \frac{2\pi i k x}{n} \Bigr) |{x+1 \bmod n}\rangle \\ &amp;= \frac{1}{\sqrt n} \sum_{x=1}^n \exp\Bigl( \frac{2\pi i k (x-1)}{n} \Bigr) |{x \bmod n}\rangle = \exp\Bigl(- \frac{2\pi i k}{n} \Bigr) |{\tilde k}\rangle .\end{aligned} "/> </p>



<p>After the shift, we pick up an additional phase based on how rapidly the phase is varying. From this, we get:</p>



<p> <img alt="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%26%3D+%5Cfrac%7B%5Cexp%282%5Cpi+i+k+%2F+n%29+%2B+%5Cexp%28-2%5Cpi+i+k+%2F+n%29%7D%7B2%7D+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Ccos%5CBigl%28%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%5CBigr%29+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+.%5Cend%7Baligned%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} T |{\tilde{k}}\rangle &amp;= \frac{\exp(2\pi i k / n) + \exp(-2\pi i k / n)}{2} |{\tilde{k}}\rangle = \cos\Bigl(\frac{2\pi k}{n}\Bigr) |{\tilde{k}}\rangle .\end{aligned} "/> </p>



<p>The eigenvalues are</p>



<p> <img alt="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%3D+%5Ccos+%5Cfrac%7B2%5Cpi+k%7D%7Bn%7D%2C+%5Cqquad+k%3D0%2C1%2C%5Cdotsc%2Cn-1.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_k = \cos \frac{2\pi k}{n}, \qquad k=0,1,\dotsc,n-1."/> </p>



<p>Only <img alt="k = 0" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k = 0"/> will give me an eigenvalue of <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> .</p>



<p>How do we analyze <img alt="T^t |{p}\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+%7C%7Bp%7D%5Crangle+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t |{p}\rangle "/> ? We should Fourier transform the distribution.</p>



<p> <img alt="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+T%5Et+%7C%7Bp%7D%5Crangle+%3D+T%5Et+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%7C%7B%5Ctilde%7Bk%7D%7D%5Crangle+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D+p_k+%5Clambda_k%5Et+%7C%7B%5Ctilde+k%7D%5Crangle+.%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} T^t |{p}\rangle = T^t \sum_{k=0}^{n-1} p_k |{\tilde{k}}\rangle = \sum_{k=0}^{n-1} p_k \lambda_k^t |{\tilde k}\rangle .\end{aligned}"/> </p>



<p>If <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> is odd, then as <img alt="t\rightarrow\infty" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Crightarrow%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\rightarrow\infty"/> , <img alt="\lambda_k^t \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k%5Et+%5Cto+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_k^t \to 0"/> for all <img alt="k=1,\dotsc,n-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D1%2C%5Cdotsc%2Cn-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=1,\dotsc,n-1"/> , so <img alt="T^t \to |{\pi}\rangle \langle{1_n}| " class="latex" src="https://s0.wp.com/latex.php?latex=T%5Et+%5Cto+%7C%7B%5Cpi%7D%5Crangle+%5Clangle%7B1_n%7D%7C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T^t \to |{\pi}\rangle \langle{1_n}| "/> . Whatever you put into this operator, you get <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pi"/> out.</p>



<h2 id="spectral-gap">Spectral gap</h2>



<p>The example of the random walk on the cycle shows that there is generally a unique stationary distribution and suggests that the speed of convergence is determined by how close the other eigenvalues are to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> . Specifically, suppose for simplicity that the eigenvalues of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> are <img alt="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=1+%3D+%5Clambda_0+%5Cge+%5Clambda_1%5Cge%5Ccdots+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1 = \lambda_0 \ge \lambda_1\ge\cdots \ge 0"/> (real and positive). Then, the convergence time is on the order of <img alt="\sim 1/(1-\lambda_1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sim 1/(1-\lambda_1)"/> .</p>



<p>Typically, the distance of the eigenvalues from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> reflects the size of the physical system. Even from the simple example, we can get some physical intuition from this. If <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is small, then the spectral gap is <img alt="\cos(2\pi k/n) = 1-O(k^2/n^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccos%282%5Cpi+k%2Fn%29+%3D+1-O%28k%5E2%2Fn%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cos(2\pi k/n) = 1-O(k^2/n^2)"/> . Thus, the convergence time is <img alt="\sim 1/(1-\lambda_1) \sim n^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim+1%2F%281-%5Clambda_1%29+%5Csim+n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sim 1/(1-\lambda_1) \sim n^2"/> , which is indeed the convergence time for a random walk on a cycle.</p>



<h2 id="references">References</h2>



<hr class="wp-block-separator"/>



<ol><li>S. Gharibian, Y. Huang, Z. Landau, and S. W. Shin, “Quantum Hamiltonian complexity,” <em>Found. Trends Theor. Comput. Sci.</em>, vol. 10, no. 3, pp. front matter, 159–282, 2014. </li><li>R. W. Keener, <em>Theoretical statistics</em>. Springer, New York, 2010, p. xviii+538. </li><li>E. Crosson, D. Bacon, and K. R. Brown, “Making Classical Ground State Spin Computing Fault-Tolerant,” <em>Physical Review E</em>, vol. 82, no. 3, Sep. 2010. </li><li>C. Moore and S. Mertens, <em>The nature of computation</em>. Oxford University Press, Oxford, 2011, p. xviii+985. </li><li>F. Martinelli, “Lectures on Glauber dynamics for discrete spin models,” in <em>Lectures on probability theory and statistics (Saint-Flour, 1997)</em>, vol. 1717, Springer, Berlin, 1999, pp. 93–191. </li><li>F. Martinelli and E. Olivieri, “Finite volume mixing conditions for lattice spin systems and exponential approach to equilibrium of Glauber dynamics,” in <em>Cellular automata and cooperative systems (Les Houches, 1992)</em>, vol. 396, Kluwer Acad. Publ., Dordrecht, 1993, pp. 473–490. </li><li>M. S. Leifer and D. Poulin, “Quantum graphical models and belief propagation,” <em>Ann. Physics</em>, vol. 323, no. 8, pp. 1899–1946, 2008. </li><li>M. J. Kastoryano and F. G. S. L. Brandão, “Quantum Gibbs samplers: the commuting case,” <em>Comm. Math. Phys.</em>, vol. 344, no. 3, pp. 915–957, 2016. </li><li>F. G. S. L. Brandão and M. J. Kastoryano, “Finite correlation length implies efficient preparation of quantum thermal states,” <em>ArXiv e-prints</em>, Sep. 2016. </li><li>O. Fawzi and R. Renner, “Quantum conditional mutual information and approximate Markov chains,” <em>Comm. Math. Phys.</em>, vol. 340, no. 2, pp. 575–611, 2015. </li><li>T. M. Cover and J. A. Thomas, <em>Elements of information theory</em>, Second. Wiley-Interscience [John Wiley &amp; Sons], Hoboken, NJ, 2006, p. xxiv+748. </li><li>R. Durrett, <em>Essentials of stochastic processes</em>. Springer, Cham, 2016, p. ix+275. </li><li>R. Durrett, <em>Probability: theory and examples</em>, Fourth., vol. 31. Cambridge University Press, Cambridge, 2010, p. x+428. </li><li>M. Mitzenmacher and E. Upfal, <em>Probability and computing</em>, Second. Cambridge University Press, Cambridge, 2017, p. xx+467. </li><li>F. Cesi, “Quasi-factorization of the entropy and logarithmic Sobolev inequalities for Gibbs random fields,” <em>Probab. Theory Related Fields</em>, vol. 120, no. 4, pp. 569–584, 2001. </li></ol>



<hr class="wp-block-separator"/>



<ol><li>This is the opposite of the probabilists’ convention, i.e., the transition probability matrix that we define here is the <em>transpose</em> of the one usually found in most probability theory textbooks. <a href="https://windowsontheory.org/feed/#fnref_1"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>As a side note, it may be a good research question to investigate to what extent quantum algorithms can be used to compute summations whose terms are possibly negative. In quantum Monte Carlo, the quantum Hamiltonian is converted to a classical energy function; this conversion always works, but sometimes you end up with complex energies, which is terrible for estimating the partition function because terms can cancel each other out. <a href="https://windowsontheory.org/feed/#fnref_2"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>You may recognize this as the total variation norm. <a href="https://windowsontheory.org/feed/#fnref_3"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li><li>Petz wrote about quantum relative entropy in 1991, way before it was cool. <a href="https://windowsontheory.org/feed/#fnref_4"><img alt="&#x21A9;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" style="height: 1em;"/></a></li></ol></div>
    </content>
    <updated>2018-12-20T21:57:08Z</updated>
    <published>2018-12-20T21:57:08Z</published>
    <category term="Uncategorized"/>
    <category term="physics"/>
    <author>
      <name>wsmoses</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6778</id>
    <link href="https://windowsontheory.org/2018/12/20/theory-blog-aggregator-up/" rel="alternate" type="text/html"/>
    <title>Theory Blog Aggregator Up!</title>
    <summary>The Theory of Computing Blog Aggregator is now back online at a new website: http://cstheory-feed.org/ . There is also a twitter feed at https://twitter.com/cstheory . See this blog post by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <strong>Theory of Computing Blog Aggregator</strong> is now back online at a new website: <a href="http://cstheory-feed.org/" rel="nofollow">http://cstheory-feed.org/</a> . There is also a twitter feed at <a href="https://twitter.com/cstheory" rel="nofollow">https://twitter.com/cstheory</a> .</p>
<p>See <a href="http://blog.geomblog.org/2018/12/the-theorycs-blog-aggregator-reborn.html">this blog post</a> by Suresh Venkatasubramanian (who, together with Arnab Bhattacharyya, is responsible for the aggregator’s revival – thank you!!) for more details. This is a good opportunity to thank Arvind Narayanan who created the software to run it and maintained it all these years.</p>
<p>If you don’t want to rely on the aggregator to follow windows on theory, you can use the <strong>“Follow Blog by email”</strong> button on our side bar, and join the 590 other happy customers who don’t need to wait to the feed to get the <a href="https://windowsontheory.org/category/physics/">latest lecture notes</a> from our physics and computation seminar.</p></div>
    </content>
    <updated>2018-12-20T21:50:02Z</updated>
    <published>2018-12-20T21:50:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>windowsontheory</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=6358</id>
    <link href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/" rel="alternate" type="text/html"/>
    <title>What is Quantum Hamiltonian Complexity?</title>
    <summary>by Ben Edelman This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in Boaz and Tselil’s seminar. The second installment is here, and the third installment is here. Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>by Ben Edelman</strong></p>
<p><em>This is the first installment of a three-part series of posts on quantum Hamiltonian complexity based on lectures given the authors in <a href="https://www.boazbarak.org/fall18seminar/">Boaz and Tselil’s seminar</a>. The second installment is <a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">here</a>, and the third installment is <a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">here</a>.</em></p>
<p>Quantum Hamiltonian complexity is a growing area of study that has important ramifications for both physics and computation. Our hope is that these three posts will provide an accessible (and incomplete) preview of the subject for readers who know the basics of theoretical computer science and quantum information. Much of the material is adapted from an <a href="https://arxiv.org/abs/1401.3916">excellent survey by Gharibian et al.</a>.</p>
<p>In a nutshell, quantum Hamiltonian complexity is the study of the <em>local Hamiltonian problem</em>. Why is this problem important enough to justify the existence of an entire subfield? To illustrate why, here are two informal characterizations of it:</p>
<ol>
<li>To a <strong>physicist</strong>, the local Hamiltonian problem is a formalization of the difficulty of simulating and understanding many-particle quantum systems. There are deep connections between the complexity of this problem and the amount of quantum entanglement in a system. In practical terms, physicists would love to be able to solve this problem on a regular basis, and they’ve developed a rich theory of heuristics to that end.</li>
<li>To a <strong>computer scientist</strong>, local Hamiltonian problem is the quantum version of constraint satisfaction problems. Any CSP can be written as a local Hamiltonian problem; and just as constraint satisfaction is the prototypical NP-complete problem by the Cook-Levin theorem, the local Hamiltonian problem plays the equivalent role for QMA (a quantum analogue of NP) by the “quantum Cook-Levin theorem.” The connections to classical complexity go on… there is even a <a href="https://arxiv.org/pdf/1309.7495.pdf">quantum PCP conjecture</a>!</li>
</ol>
<p>But let’s take a step back and start at the beginning. To make sure we understand what a quantum Hamiltonian is and why it is important, it will be instructive to briefly rehash some of the <a href="https://windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">fundamentals of classical statistical mechanics</a>.</p>
<h2>Classical energy and ground states</h2>
<p>In the classical world, a physical system can be in any one of various states <img alt="x \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in \mathcal{X}"/>, each of which is a vector, with different coordinates representing different particles. Every state of the system has an <em>energy</em>, given by an energy function <img alt="E: \mathcal{X} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=E%3A+%5Cmathcal%7BX%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E: \mathcal{X} \to \mathbb{R}"/>. For example, in the classic Ising model of ferromagnetism, <img alt="\mathcal{X} = \{\pm 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D+%3D+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{X} = \{\pm 1\}^n"/>. Each coordinate <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> represents the spin of atom <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>, and atoms <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> and <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> interact with each other whenever <img alt="(i,j)" class="latex" src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(i,j)"/> is an edge in a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, which is usually a low-dimensional lattice. Energy for this system is defined as <img alt="E(x) = \sum_{(i,j) \in G}-x_i x_j" class="latex" src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7B%28i%2Cj%29+%5Cin+G%7D-x_i+x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E(x) = \sum_{(i,j) \in G}-x_i x_j"/>.</p>
<p>Suppose we ignore our system for a long time, letting it interact with its external environment until, in the limit, it reaches thermal equilibrium at temperature <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>. Then the probability the system is in state <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> is given by Boltzmann’s distribution: <img alt="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Bx%5D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+E%28x%29%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[x] = \frac{e^{-\beta E(x)}}{Z}"/>, where <img alt="\beta \propto 1/T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cpropto+1%2FT&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta \propto 1/T"/> and <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> is the partition function required to normalize the probabilities. As the temperature tends to infinity, this distribution will approach the uniform distribution over <img alt="\mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathcal{X}"/>, and as the temperature tends to absolute zero, the distribution will approach the uniform distribution over the states with minimum energy. We call these minimum energy states <em>ground states</em>, and we call their energy the <em>ground state energy</em>. If we want to calculate something about a system, then it is often crucial to know the ground states and ground state energy of the system. Going back to our example, the Ising model has two ground states whenever <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is connected. These are the states <img alt="(+1,+1,\ldots,+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%2B1%2C%2B1%2C%5Cldots%2C%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(+1,+1,\ldots,+1)"/> and <img alt="(-1,-1,\ldots,-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28-1%2C-1%2C%5Cldots%2C-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(-1,-1,\ldots,-1)"/> in which all atoms have the same spin. The ground state energy is <img alt="-|\{i,j:(i,j) \in G\}|" class="latex" src="https://s0.wp.com/latex.php?latex=-%7C%5C%7Bi%2Cj%3A%28i%2Cj%29+%5Cin+G%5C%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-|\{i,j:(i,j) \in G\}|"/>.</p>
<h2>Quantum Hamiltonians</h2>
<p>A quantum Hamiltonian is essentially the quantum analogue of the classical energy function. Unlike with classical systems, when a quantum system is in a given <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-qubit state <img alt="\left|\psi\right\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Cpsi%5Cright%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\left|\psi\right\rangle"/>, it doesn’t have a determinate energy. Instead, when we measure the energy, the value we obtain may be probabilistic and will correspond to one of the eigenvalues of the observable matrix for energy. This Hermitian matrix, denoted <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/>, is the quantum Hamiltonian, and just as the energy function characterizes a classical system, the Hamiltonian characterizes a quantum system. For a given eigenvector <img alt="|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_i\rangle"/> of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> with eigenvalue <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/>, when we measure the energy of <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> we obtain the result <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/> with probability <img alt="\langle\psi|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\langle\psi|\lambda_i\rangle"/>, and the system collapses to the state <img alt="|\lambda_i\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_i\rangle"/> (assuming the eigenvalue <img alt="\lambda_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_i"/> has multiplicity 1). Thus, the ground state and ground state energy of a quantum system with eigenvalue <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> are the minimum eigenvalue <img alt="\lambda_0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0"/> of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> and the corresponding eigenvector <img alt="|\lambda_0\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clambda_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\lambda_0\rangle"/>.</p>
<p>The Boltzmann distribution also has a quantum analogue. A quantum system at thermal equilibrium will be in the following mixed state: <img alt="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D+%3D+%5Cfrac%7Be%5E%7B-%5Cbeta+H%7D%7D%7BZ%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\text{eq}} = \frac{e^{-\beta H}}{Z}"/>. As the temperature approaches absolute zero, <img alt="\rho_{\text{eq}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Ctext%7Beq%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\text{eq}}"/> will approach a superposition over the ground states.</p>
<p>Not only does the Hamiltonian tell us the energy of a system, it also describes the time evolution of the system (as long as it is closed). Schrödinger’s equation states that <img alt="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=-i+%5Chbar+%5Cfrac%7Bd%7C%5Cpsi%5Crangle%7D%7Bdt%7D+%3D+H%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-i \hbar \frac{d|\psi\rangle}{dt} = H|\psi\rangle"/>, where <img alt="\hbar" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chbar&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hbar"/> is Planck’s constant and <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> is time. Thus, if a closed system is in the state <img alt="|\psi\rangle_0" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_0"/> at time 0, its state at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> will be <img alt="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_t+%3D+e%5E%7B-itH%2F%5Chbar%7D%7C%5Cpsi%5Crangle_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle_t = e^{-itH/\hbar}|\psi\rangle_0"/>. Since <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is Hermitian, <img alt="e^{-itH/\hbar}" class="latex" src="https://s0.wp.com/latex.php?latex=e%5E%7B-itH%2F%5Chbar%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e^{-itH/\hbar}"/> is unitary, which is another way of saying that quantum mechanical states are subject to unitary evolution.</p>
<h1>The Local Hamiltonian problem</h1>
<p>As we have seen, understanding the Hamiltonian of a quantum system is crucial for understanding both the system’s equilibrium behavior and its time evolution. There are a huge variety of questions physicists are interested in asking about systems, all of which boil down to questions about equilibrium behavior, time evolution, or both. There is a single problem that captures the complexity of many of these questions, in the sense that most of the questions can’t be answered without solving it. This is the problem of estimating the ground state energy of the Hamiltonian. Especially in condensed matter physics, this problem is ubiquitous.</p>
<p>Formally, we will study the following promise problem: (note: this will not be our final formulation)</p>
<hr/>
<p><strong>The “Hamiltonian Problem”</strong></p>
<p>Given a Hermitian matrix <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/> and non-negative reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> with <img alt="b \geq a+1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b \geq a+1"/>,</p>
<ul>
<li>If <img alt="\lambda_0(H) \leq a" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \leq a"/>, output YES<p/>
</li>
<li>
<p>If <img alt="\lambda_0(H) \geq b" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \geq b"/>, output NO</p>
</li>
</ul>
<hr/>
<p>One issue with this definition is that the input includes an enormous <img alt="2^n \times 2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En+%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n \times 2^n"/> matrix. For a reasonable-sized system, there’d be no use in even trying to solve this problem through classical computation, and how to deal with it in the quantum computing setting is far from obvious. Luckily, physicists have found that in real-life systems, interactions tend to be <em>local</em>, and if we consider the special case of <em>local Hamiltonians</em>, the input for the problem is of reasonable size.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6361" style="width: 295px;"><img alt="circle_diagram0" class="aligncenter size-medium wp-image-6361" height="300" src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram0.png?w=285&amp;h=300" width="285"/><p class="wp-caption-text">Hamiltonians are too big to work with. What if we restrict our focus to local Hamiltonians?</p></div><p/>
<p>A <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian is a Hamiltonian that is decomposed into a sum of terms, each of which represents a Hamiltonian acting on a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-unit subset of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> qubits in the system. In other words, <img alt="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_i+%28H_i%29_%7BS_i%7D+%5Cotimes+I_%7B%5Bn%5D%5Cbackslash+S_i%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = \sum_i (H_i)_{S_i} \otimes I_{[n]\backslash S_i}"/>, where each <img alt="S_i" class="latex" src="https://s0.wp.com/latex.php?latex=S_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_i"/> is a subset of <img alt="[n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]"/> of size <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. For brevity’s sake, we abuse notation and write <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> as <img alt="\sum_i H_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_i+H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum_i H_i"/>. We can think of the <img alt="H_i" class="latex" src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_i"/>’s as local constraints, and the ground state as the state that simultaneously satisfies the constraints to the maximal possible extent. Here, then, is the new-and-improved problem definition:</p>
<hr/>
<p><strong><img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-Local Hamiltonian Problem</strong></p>
<p>Given a Hamiltonian <img alt="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D+%5Ctimes+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H \in (\mathbb{C}^2)^{\otimes n} \times (\mathbb{C}^2)^{\otimes n}"/> specified as a collection of <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> local interactions <img alt="\{H_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H_i\}"/>, and non-negative reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> with <img alt="b \geq a+1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%5Cgeq+a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b \geq a+1"/>,</p>
<ul>
<li>If <img alt="\lambda_0(H) \leq a" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cleq+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \leq a"/>, output YES</li>
<li>If <img alt="\lambda_0(H) \geq b" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_0%28H%29+%5Cgeq+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_0(H) \geq b"/>, output NO</li>
</ul>
<hr/>
<p>Presuming the matrices <img alt="\{H_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BH_i%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{H_i\}"/> and the reals <img alt="a, b" class="latex" src="https://s0.wp.com/latex.php?latex=a%2C+b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a, b"/> are specified to polynomial precision, then the input size is polynomial in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, since <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> is a constant and each of the matrices <img alt="H_i" class="latex" src="https://s0.wp.com/latex.php?latex=H_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_i"/> has <img alt="2^k \cdot 2^k" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ccdot+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^k \cdot 2^k"/> entries. Thus, not only is our new problem physically realistic, it is also a problem we might hope to attack with classical computation. However, we will later see that in fact this problem is likely hard even for quantum computers. The remaining installments in this series of notes will deal with further restrictions of the class of Hamiltonians for which the local Hamiltonian problem may be tractable.</p>
<h2>Computer science motivation</h2>
<p>As we mentioned in the intro, the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian problem (henceforth denoted <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH) doesn’t just have myriad applications in physics—it is also important from a computer science perspective because it is a quantum generalization of constraint satisfiability (you may have noticed that quantum analogues of classical concepts are a running theme). Specifically, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP is a special case of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH.</p>
<p>Suppose we have a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP instance <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/>, and we want to turn it into a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH instance. A clause <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> with constituent variables <img alt="x_1, \ldots, x_k" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cldots%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1, \ldots, x_k"/> becomes a <img alt="2^k \times 2^k" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ek+%5Ctimes+2%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^k \times 2^k"/> diagonal <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/> matrix <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> acting on the qubits <img alt="|x_1\rangle,\ldots,|x_k\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx_1%5Crangle%2C%5Cldots%2C%7Cx_k%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|x_1\rangle,\ldots,|x_k\rangle"/>. Note that the rows and columns of this matrix are indexed by the assignment vectors <img alt="x \in \{0,1\}^k" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B0%2C1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in \{0,1\}^k"/>. Formally, <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> encodes the truth table of <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> in the following manner: <img alt="(H_C)_{x,x} = 1 - C(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%28H_C%29_%7Bx%2Cx%7D+%3D+1+-+C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(H_C)_{x,x} = 1 - C(x)"/>. Another way of stating this is <img alt="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|" class="latex" src="https://s0.wp.com/latex.php?latex=H_C+%3D+%5Csum_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5Ek%5Ctext%7B+s.t.+%7DC%28x%29%3D0%7D%7Cx%5Crangle%5Clangle%7Bx%7D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C = \sum_{x \in \{0,1\}^k\text{ s.t. }C(x)=0}|x\rangle\langle{x}|"/>.</p>
<p>Informally, <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> takes the clauses of <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> and turns them into local quantum interactions. We’ve constructed <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> so that it has two eigenvalues: 0 and 1. The eigenspace corresponding to 0 is spanned by the set of computational basis vectors <img alt="|x\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|x\rangle"/> that satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>, and the eigenspace corresponding to 1 is spanned by the computational basis vectors that don’t satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. In effect, when we consider <img alt="H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_C"/> as a term of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, we are giving an energy penalty to any variable assignment that doesn’t satisfy <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/>. <img alt="H = \sum_{C}H_C" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+%5Csum_%7BC%7DH_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = \sum_{C}H_C"/> will have the eigenvalue 0 (in other words, a ground state energy of 0) if and only if there is some assignment of the variables <img alt="x_1,\ldots,x_n" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C%5Cldots%2Cx_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,\ldots,x_n"/> that satisfies all of the clauses (in other words, iff <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable). Otherwise, the ground state energy of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> will be at least 1, so determining whether <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable is equivalent to solving <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH with inputs <img alt="a = 0" class="latex" src="https://s0.wp.com/latex.php?latex=a+%3D+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a = 0"/>, and <img alt="b = 1" class="latex" src="https://s0.wp.com/latex.php?latex=b+%3D+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b = 1"/>. (In fact, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH generalizes MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP, since the ground state energy of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is exactly the number of clauses minus the maximum number of satisfiable clauses.)</p>
<p><span id="more-6358"/></p>
<p><!--more--></p>
<p><!--more--></p>
<p>Let’s work through an example. Consider the following 2-SAT formula:</p>
<p><img alt="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi%28x_1%2Cx_2%2Cx_3%29+%3D+%28x_1+%5Cvee+x_2%29+%5Cwedge+%28%5Coverline%7Bx_1%7D+%5Cvee+x_3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi(x_1,x_2,x_3) = (x_1 \vee x_2) \wedge (\overline{x_1} \vee x_3)"/></p>
<p>The truth table for the first clause <img alt="C_1 = (x_1 \vee x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=C_1+%3D+%28x_1+%5Cvee+x_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_1 = (x_1 \vee x_2)"/> is:</p>
<table>
<tbody>
<tr>
<th style="text-align: center;"> <img alt="x_1" class="latex" src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1"/></th>
<th style="text-align: center;"> <img alt="x_2" class="latex" src="https://s0.wp.com/latex.php?latex=x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_2"/></th>
<th style="text-align: center;"> <img alt="x_1 \vee x_2" class="latex" src="https://s0.wp.com/latex.php?latex=x_1+%5Cvee+x_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1 \vee x_2"/></th>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>So <img alt="H_1" class="latex" src="https://s0.wp.com/latex.php?latex=H_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_1"/> is the following matrix:</p>
<p><img alt="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=H_1+%3D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_1 = \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}"/></p>
<p>We also have</p>
<p><img alt="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=H_2+%3D+%5Cbegin%7Bpmatrix%7D+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H_2 = \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix}"/></p>
<p>Then,<br/>
<img alt="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+H+%26%3D+%28H_1%29_%7B1%2C2%7D+%5Cotimes+I_%7B3%7D+%2B+%28H_2%29_%7B1%2C3%7D+%5Cotimes+I_%7B2%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%260%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%260%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%2B+%5Cbegin%7Bpmatrix%7D+0%26%26%26%26%26%26%26+%5C%5C+%260%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D+%5C%5C+%26%3D+%5Cbegin%7Bpmatrix%7D+1%26%26%26%26%26%26%26+%5C%5C+%261%26%26%26%26%26%26+%5C%5C+%26%260%26%26%26%26%26+%5C%5C+%26%26%260%26%26%26%26+%5C%5C+%26%26%26%261%26%26%26+%5C%5C+%26%26%26%26%260%26%26+%5C%5C+%26%26%26%26%26%261%26+%5C%5C+%26%26%26%26%26%26%260+%5Cend%7Bpmatrix%7D%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} H &amp;= (H_1)_{1,2} \otimes I_{3} + (H_2)_{1,3} \otimes I_{2} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;0&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;0&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} + \begin{pmatrix} 0&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;0&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix} \\ &amp;= \begin{pmatrix} 1&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;1&amp;&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;0&amp;&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;0&amp;&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;1&amp;&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;0&amp;&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;1&amp; \\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;0 \end{pmatrix}\end{aligned}"/></p>
<p><img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> has diagonal entries that are zero, so it has 0 as an eigenvalue. We can therefore conclude that <img alt="\varphi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\varphi"/> is satisfiable. (In this example it was easy to write out <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> and see that it has zeros on the diagonal, but when <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> is large, <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> becomes exponentially big, so we can’t just compute it explicitly and look through its diagonal entries.)</p>
<h1>Quantum Cook-Levin Theorem</h1>
<p>We’ve seen that any <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP problem can be thought of as a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH problem (with a diagonal Hamiltonian matrix). And the analogy can be drawn even further. One reason <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-CSP is so useful is that it (and in particular 3-SAT) is NP-complete, according to the Cook-Levin Theorem. 3-SAT captures the difficulty of classical efficiently verifiable computation. It may not come as a surprise, then, that <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH captures the difficulty of <em>quantum</em> efficiently verifiable computation. This result is the “quantum Cook-Levin theorem”, but before we see it we need to define the complexity class QMA, the quantum analogue of NP.</p>
<p>Because quantum computation is probabilistic, QMA is more precisely the quantum analogue of MA (Merlin Arthur), which allows the verifier to have a chance of error:</p>
<hr/>
<p><strong>MA</strong></p>
<p><img alt="L \in \text{MA}" class="latex" src="https://s0.wp.com/latex.php?latex=L+%5Cin+%5Ctext%7BMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L \in \text{MA}"/> iff there exists a probabilistic poly-time verifier <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and a polynomial <img alt="p(n)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(n)"/> such that</p>
<ul>
<li><img alt="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L%2C+%5Cexists+y+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \in L, \exists y \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \geq \frac{2}{3}"/><p/>
</li>
<li>
<p><img alt="\forall x \notin L" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \notin L"/>, <img alt="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bp%28n%29%7D%2C%5Cquad+%5CPr%5BV%28x%2Cy%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall |y\rangle \in \{0,1\}^{p(n)},\quad \Pr[V(x,y) = 1] \leq \frac{1}{3}"/></p>
</li>
</ul>
<hr/>
<p>For QMA, the verifier is a quantum computer and the witness is a quantum state. Moreover, we’re interested in the complexity of promise problems:</p>
<hr/>
<p><strong>QMA</strong></p>
<p>A promise problem <img alt="L = L_{yes} \cup L_{no} \in \text{QMA}" class="latex" src="https://s0.wp.com/latex.php?latex=L+%3D+L_%7Byes%7D+%5Ccup+L_%7Bno%7D+%5Cin+%5Ctext%7BQMA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L = L_{yes} \cup L_{no} \in \text{QMA}"/> iff there exists a quantum poly-time verifier <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> and a polynomial <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p"/> such that</p>
<ul>
<li><img alt="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cin+L_%7Byes%7D%2C+%5Cexists+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cgeq+%5Cfrac%7B2%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \in L_{yes}, \exists |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \geq \frac{2}{3}"/><p/>
</li>
<li>
<p><img alt="\forall x \notin L_{no}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+x+%5Cnotin+L_%7Bno%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall x \notin L_{no}"/>, <img alt="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+%7Cy%5Crangle+%5Cin+%28%5Cmathbb%7BC%7D%5E2%29%5E%7B%5Cotimes+p%28%7Cx%7C%29%7D%2C%5Cquad+%5CPr%5BV%28%7Cx%5Crangle%7Cy%5Crangle%29+%3D+1%5D+%5Cleq+%5Cfrac%7B1%7D%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\forall |y\rangle \in (\mathbb{C}^2)^{\otimes p(|x|)},\quad \Pr[V(|x\rangle|y\rangle) = 1] \leq \frac{1}{3}"/></p>
</li>
</ul>
<hr/>
<p>A problem is QMA-complete if it is in QMA and if any problem in QMA can be reduced to it in polynomial time. In 2002, Kitaev proved that <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH is QMA-complete for all <img alt="k \geq 5" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cgeq+5&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k \geq 5"/>. This was the first time a natural problem was shown to be QMA-complete. In 2003 Kempe and Regev proved that 3-LH is QMA-complete, and finally in 2006 Kempe, Kitaev and Regev proved that 2-LH is QMA complete, achieving the best possible result unless P = QMA. (3-SAT is NP-complete but 2-SAT is in P, so it may seem curious that 2-LH is QMA-complete. But in fact, this isn’t too surprising, because as we mentioned earlier, <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-LH corresponds to MAX-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-SAT, and MAX-2-SAT is NP-complete.)</p>
<hr/>
<p><strong>“Quantum Cook-Levin Theorem”</strong></p>
<p>The 2-local Hamiltonian problem is QMA-complete.</p>
<hr/>
<p><em>A very sketchy proof sketch.    </em>This theorem is called the quantum Cook-Levin theorem not just because of the result, but also because the proof is along the same lines as the proof of the Cook-Levin theorem.</p>
<p>Recall that in the proof of the Cook-Levin theorem, we start with a verifier Turing machine that takes as input <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> and, in time <img alt="p(n)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p(n)"/> accepts iff <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> being in the language. We then devise (for each <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>) a 3-SAT formula such that any satisfying solution to the instance must be an encoding of a valid history of the Turing machine from start to finish on the input <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>. The constraints must guarantee that (a) the input indeed starts with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, (b) at every time step <img alt="t \in [1,p(n)]" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cin+%5B1%2Cp%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t \in [1,p(n)]"/> the state of the machine correctly follows from its state at time <img alt="t-1" class="latex" src="https://s0.wp.com/latex.php?latex=t-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t-1"/>, and that (c) the final state of the machine indicates acceptance. The constraints for (a) and (c) are trivial, and the reason we can do (b) is because Turing machines compute <em>locally</em>.</p>
<p>For our quantum Cook-Levin proof, we follow the same template. Given a quantum circuit, we construct a local Hamiltonian that has ground energy below some constant only if there is a quantum encoding of the circuit that includes the proper (a) initial state, (b) intermediate computation, and (c) final state. As before, (a) and (c) are easy, because the parts of the initial and final states we need to ‘inspect’ (with the local terms of the Hamiltonian) are essentially classical. But when we try to compute local constraints for (b), we run into a big problem: entanglement.</p>
<p>Consider some step of the computation. This will consist of applying a quantum gate <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> to a state <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> to obtain <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/>. Even assuming we’ve already written down constraints to verify that <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> is correct, it is non-trivial to write down constraints to verify that <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/> because <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> may differ from <img alt="U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U|\psi\rangle"/> in a highly <em>non-local</em> way if there is entanglement between far-flung qubits. For example, suppose for the sake of illustration that <img alt="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> and <img alt="U = I" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = I"/>. And suppose we want to check that <img alt="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> with 1-local constraints. Unfortunately, there is no way to distinguish <img alt="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+%2B+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)"/> from <img alt="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C00%5Crangle+-+%7C11%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)"/> by looking at one qubit at a time: the reduced density matrix of either state for either qubit is the same: <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/>/2. There are examples like this that apply for <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local constraints for any <img alt="k &gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k &gt;1"/>, so we can’t even verify the ‘trivial’ gate <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/>, let alone gates that actually change the state. It would seem that we are stuck.</p>
<p>Luckily, although quantum superposition makes this problem more difficult, we can actually use superposition in a clever manner in order to surmount the difficulty. Instead of encoding the states <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> and <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> separately, we can put them in superposition in a way that will allow us to verify that <img alt="|\psi'\rangle = U|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+U%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = U|\psi\rangle"/>. Suppose again that <img alt="U = I" class="latex" src="https://s0.wp.com/latex.php?latex=U+%3D+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U = I"/>, so we want to check that <img alt="|\psi'\rangle = |\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle+%3D+%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle = |\psi\rangle"/>. Let <img alt="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%7C%5Cpsi%5Crangle%7C0%5Crangle+%2B+%7C%5Cpsi%27%5Crangle%7C1%5Crangle%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle = \frac{1}{\sqrt{2}}(|\psi\rangle|0\rangle + |\psi'\rangle|1\rangle)"/>. Then, just by looking at the last qubit of <img alt="|\eta\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle"/>, we can tell how close <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/> is to <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/>: the reduced density matrix of the last qubit contains information about the angle between <img alt="|\psi\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi\rangle"/> and <img alt="|\psi'\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%27%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi'\rangle"/>:</p>
<p><img alt="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bpmatrix%7D+1+%26+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%5C%5C+%5Clangle%5Cpsi%7C%5Cpsi%27%5Crangle+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{pmatrix} 1 &amp; \langle\psi|\psi'\rangle \\ \langle\psi|\psi'\rangle &amp; 1 \end{pmatrix}"/></p>
<p>The challenge is to describe a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-local Hamiltonian <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that has a state with energy below some parameter <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> whenever <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, and otherwise has no state with energy below <img alt="b&gt;a" class="latex" src="https://s0.wp.com/latex.php?latex=b%3Ea&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b&gt;a"/>. We won’t cover the details here, but the crucial idea is that when <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> is a valid witness for <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, the following ‘witness state’ (which is a superposition of the states of the quantum computer over all the time steps) will have low energy for a carefully-devised <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>:</p>
<p><img alt="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta%5Crangle+%3D+%5Cfrac%7B1%7D%7Bp%28n%29%7D%5Csum_%7Bt%3D0%7D%5E%7Bp%28n%29%7D%28U_t%5Ccdots+U_1%7C%5Cpsi_0%5Crangle%29%5Cotimes%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\eta\rangle = \frac{1}{p(n)}\sum_{t=0}^{p(n)}(U_t\cdots U_1|\psi_0\rangle)\otimes|t\rangle"/></p>
<p>where <img alt="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7Cx%5Crangle%7Cy%5Crangle%7C0%5Crangle%5E%7B%5Cotimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\psi_0\rangle = |x\rangle|y\rangle|0\rangle^{\otimes m}"/> is the initial state of the computation, and <img alt="|t\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ct%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|t\rangle"/> is called the “clock register”. Note that because the size of the clock register is logarithmic in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, we actually need to use <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log(n)"/>-local constraints. For 5-local constraints to suffice, the witness state will need to be a little more complicated (the proof for 2-local constraints is even more difficult). Even for the case of <img alt="\log(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log(n)"/>-LH, the complete proof must demonstrate that no state besides the witness state has low energy.</p>
<p style="text-align: right;">□</p>
<h1>Roadmap</h1>
<p>The upshot is that 2-LH is the canonical QMA-complete problem. This is a beautiful result from a quantum complexity theory perspective, but from a physics perspective it is very bad news. The QMA-completeness of the local Hamiltonian problem means that (presuming BQP <img alt="\neq" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\neq"/> QMA) we can’t solve 2-LH, and we couldn’t even solve it with a quantum computer. Because of the central importance of finding the ground energy, this in turn means that <em>almost anything a physicist would like to compute about a system is intractable</em>.</p>
<p>So is all hope lost? No! Just as we started out wanting to understand Hamiltonians in general and restricted our focus to <em>local</em> Hamiltonians, the approach the physics community has taken is to focus on even more restricted classes of Hamiltonians that still capture interesting physical systems. One route is to restrict the topology of the system encoded by the Hamiltonian: for example, in many physics models, the particles form a low-dimensional lattice and the only interactions between them are 2-local interactions along edges. Even this isn’t enough, though: the problem remains QMA-hard on many simple topologies like lattices (for example, 2-LH on the 2-D lattice is QMA-complete, and 2-LH on even the 1-D lattice is QMA-complete when instead of qubits we are dealing with 8-dimensional qudits). So we add a further restriction, which is to focus on <em>gapped</em> Hamiltonians: these are Hamiltonians for which there is a constant gap between the ground energy and the second-lowest energy.</p>
<p/><div class="wp-caption aligncenter" id="attachment_6405" style="width: 392px;"><img alt="circle_diagram1.png" class="  wp-image-6405 aligncenter" height="336" src="https://windowsontheory.files.wordpress.com/2018/12/circle_diagram1.png?w=382&amp;h=336" width="382"/><p class="wp-caption-text">Even local Hamiltonians are intractable in general. Gapped Hamiltonians on low-dimensional lattices, though, may be tractable.</p></div><p/>
<p>Thus, in the notes to follow, we will focus our energies on trying to solve the gapped local Hamiltonian problem for 1-D and 2-D lattices. The reason there is hope in these settings is that entanglement is (or is conjectured to be) limited by ‘area laws’. In the next post, Fred Zhang will describe a diagrammatic language (‘tensor networks’) for thinking about low-entanglement quantum states, and he’ll show how physicists solve the local Hamiltonian problem for gapped 1-D systems.</p></div>
    </content>
    <updated>2018-12-20T21:15:11Z</updated>
    <published>2018-12-20T21:15:11Z</published>
    <category term="physics"/>
    <category term="cs229r"/>
    <category term="quantum hamiltonian complexity"/>
    <author>
      <name>benedelman</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2018-12-31T12:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5365</id>
    <link href="https://adamsheffer.wordpress.com/2018/12/20/incidences-in-a-recent-work-of-walsh/" rel="alternate" type="text/html"/>
    <title>Incidences in a Recent Work of Walsh</title>
    <summary>Recently, Miguel Walsh posted a very interesting paper on arXiv. The main purpose of the paper is to study various properties of polynomials and varieties. These properties are related to incidence problems – some originally arose from studying incidences. Walsh also presents new incidence bounds as applications of his results. In this post I’ll briefly […]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <updated>2018-12-20T17:26:10Z</updated>
    <published>2018-12-20T17:26:10Z</published>
    <category term="Incidences"/>
    <category term="Recent Results"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2018-12-31T12:20:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=614</id>
    <link href="https://emanueleviola.wordpress.com/2018/12/20/50m-to-northeastern-computer-science/" rel="alternate" type="text/html"/>
    <title>$50M to Northeastern Computer Science</title>
    <summary>Northeastern Computer Science is receiving a $50M gift.  If you are looking for a faculty position, check out our many openings, including the joint math-cs position. Also if you are applying for a PhD take a look at our college.  In particular as I mentioned already I am looking for students. Advertisements
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: justify;"><a href="https://www.bostonglobe.com/business/2018/12/17/northeastern-receives-million-gift-further-studies/ygZaKf1F56SzNSCB818zJO/story.html">Northeastern Computer Science is receiving a $50M gift</a>.  If you are looking for a faculty position, check out our many openings, including the <a href="https://cstheory-jobs.org/2018/10/21/faculty-at-northeastern-university-apply-by-december-22-2018/">joint math-cs position</a>. Also if you are applying for a PhD take a look at our college.  In particular as I mentioned already <a href="https://emanueleviola.wordpress.com/2018/12/03/i-am-looking-for-students/">I am looking for students</a>.</p></div>
    </content>
    <updated>2018-12-20T15:09:24Z</updated>
    <published>2018-12-20T15:09:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>By Emanuele Viola</subtitle>
      <title>Thoughts</title>
      <updated>2018-12-31T12:20:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2018/12/19/goldstine-postdoctoral-fellow-at-ibm-t-j-watson-research-center-apply-by-january-31-2019/</id>
    <link href="https://cstheory-jobs.org/2018/12/19/goldstine-postdoctoral-fellow-at-ibm-t-j-watson-research-center-apply-by-january-31-2019/" rel="alternate" type="text/html"/>
    <title>Goldstine Postdoctoral Fellow at IBM T.J. Watson Research Center (apply by January 31, 2019)</title>
    <summary>The Mathematical Sciences department of the IBM T.J. Watson Research Center invites applications for the Herman Goldstine Memorial Postdoctoral Fellowship for research in mathematical and computer sciences. The department provides an atmosphere in which basic research is combined with work on practical applications. More details are available at https://www.research.ibm.com/goldstine/ Website: https://www.research.ibm.com/goldstine/ Email: gldpost2@us.ibm.com
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Mathematical Sciences department of the IBM T.J. Watson Research Center invites applications for the Herman Goldstine Memorial Postdoctoral Fellowship for research in mathematical and computer sciences. The department provides an atmosphere in which basic research is combined with work on practical applications. More details are available at <a href="https://www.research.ibm.com/goldstine/">https://www.research.ibm.com/goldstine/</a></p>
<p>Website: <a href="https://www.research.ibm.com/goldstine/">https://www.research.ibm.com/goldstine/</a><br/>
Email: gldpost2@us.ibm.com</p></div>
    </content>
    <updated>2018-12-19T22:16:35Z</updated>
    <published>2018-12-19T22:16:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2018-12-31T12:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1470</id>
    <link href="https://theorydish.blog/2018/12/18/2019-godel-prize/" rel="alternate" type="text/html"/>
    <title>2019 Gödel Prize</title>
    <summary>If I write a post and the blog aggregator is down, does it still make a sound?   The call for nomination for the 2019 Gödel Prize is out and the deadline is February 15th. For all awards, we sometimes have the tendency to think that worthy candidates have surely been nominated by others. Often it is not the case (and thus worthy candidates are often left behind). So if there is a paper or papers deserving nomination, please nominate! The call for nomination is below.   The Gödel Prize 2019 – Call for Nominations Deadline: February 15, 2019 The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Association for Computing Machinery, Special Interest Group on Algorithms and Computation Theory (ACM SIGACT). The award is presented annually, with the presentation taking place alternately at the International Colloquium on Automata, Languages, and Programming (ICALP) and the ACM Symposium on Theory of Computing (STOC). The 27th Gödel Prize will be awarded at 51st Annual ACM Symposium on the Theory of Computing to be held during June 23-26, 2019 in Phoenix, AZ. The Prize is [...]
      <div class="commentbar">
        <p/>
      </div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If I write a post and the blog aggregator is down, does it still make a sound?</p>
<hr/>
<p> </p>
<p>The call for nomination for the 2019 Gödel Prize is out and the deadline is February 15th. For all awards, we sometimes have the tendency to think that worthy candidates have surely been nominated by others. Often it is not the case (and thus worthy candidates are often left behind). So if there is a paper or papers deserving nomination, please nominate! The call for nomination is below.</p>
<hr/>
<p> </p>
<h1>The Gödel Prize 2019 – Call for Nominations</h1>
<p>Deadline: February 15, 2019</p>
<p>The Gödel Prize for outstanding papers in the area of theoretical computer science is sponsored jointly by the European Association for Theoretical Computer Science (EATCS) and the Association for Computing Machinery, Special Interest Group on Algorithms and Computation Theory (ACM SIGACT). The award is presented annually, with the presentation taking place alternately at the International Colloquium on Automata, Languages, and Programming (ICALP) and the ACM Symposium on Theory of Computing (STOC). The 27th Gödel Prize will be awarded at 51st Annual ACM Symposium on the Theory of Computing to be held during June 23-26, 2019 in Phoenix, AZ. The Prize is named in honor of Kurt Gödel in recognition of his major contributions to mathematical logic and of his interest, discovered in a letter he wrote to John von Neumann shortly before von Neumann’s death, in what has become the famous “P versus NP” question. The Prize includes an award of USD 5,000.</p>
<p><strong>Award Committee: </strong>The 2019 Award Committee consists of Anuj Dawar (Cambridge University), Robert Krauthgamer (Weizmann Institute), Joan Feigenbaum (Yale University), Giuseppe Persiano (Università di Salerno), Omer Reingold (Chair, Stanford University) and Daniel Spielman (Yale University).</p>
<p><strong>Eligibility:</strong> The 2019 Prize rules are given below and they supersede any different interpretation of the generic rule to be found on websites of both SIGACT and EATCS. Any research paper or series of papers by a single author or by a team of authors is deemed eligible if: – The main results were not published (in either preliminary or final form) in a journal or conference proceedings before January 1st, 2006. – The paper was published in a recognized refereed journal no later than December 31, 2018. The research work nominated for the award should be in the area of theoretical computer science. Nominations are encouraged from the broadest spectrum of the theoretical computer science community so as to ensure that potential award winning papers are not overlooked. The Award Committee shall have the ultimate authority to decide whether a particular paper is eligible for the Prize.</p>
<p><strong>Nominations:</strong></p>
<p>Nominations for the award should be submitted by email to the Award Committee Chair: <a href="mailto:reingold@stanford.edu">reingold@stanford.edu</a>. Please make sure that the Subject line of all nominations and related messages begin with “Goedel Prize 2019.” To be considered, nominations for the 2019 Prize must be received by February 15, 2019.</p>
<p>A nomination package should include:</p>
<p>1. A printable copy (or copies) of the journal paper(s) being nominated, together with a complete citation (or citations) thereof.</p>
<p>2. A statement of the date(s) and venue(s) of the first conference or workshop publication(s) of the nominated work(s) or a statement that no such publication has occurred.</p>
<p>3. A brief summary of the technical content of the paper(s) and a brief explanation of its significance.</p>
<p>4. A support letter or letters signed by at least two members of the scientific community.</p>
<p>Additional support letters may also be received and are generally useful. The nominated paper(s) may be in any language. However, if a nominated publication is not in English, the nomination package must include an extended summary written in English.</p>
<p>Those intending to submit a nomination should contact the Award Committee Chair by email well in advance. The Chair will answer questions about eligibility, encourage coordination among different nominators for the same paper(s), and also accept informal proposals of potential nominees or tentative offers to prepare formal nominations. The committee maintains a database of past nominations for eligible papers, but fresh nominations for the same papers (especially if they highlight new evidence of impact) are always welcome.</p>
<p><strong>Selection Process:</strong></p>
<p>The Award Committee is free to use any other sources of information in addition to the ones mentioned above. It may split the award among multiple papers, or declare no winner at all. All matters relating to the selection process left unspecified in this document are left to the discretion of the Award Committee.</p>
<p><strong>Recent Winners</strong></p>
<p>(all winners since 1993 are listed at <a href="http://www.sigact.org/Prizes/Godel/">http://www.sigact.org/Prizes/Godel/</a> and <a href="http://eatcs.org/index.php/goedel-prize">http://eatcs.org/index.php/goedel-prize</a>):</p>
<p><strong>2018:</strong> Oded Regev, On lattices, learning with errors, random linear codes, and cryptography, Journal of the ACM (JACM), Volume 56 Issue 6, 2009 (preliminary version in Symposium on Theory of Computing, STOC 2005).</p>
<p><strong>2017:</strong> Cynthia Dwork, Frank McSherry, Kobbi Nissim and Adam Smith, Calibrating Noise to Sensitivity in Private Data Analysis, Journal of Privacy and Confidentiality, Volume 7, Issue 3, 2016 (preliminary version in Theory of Cryptography, TCC 2006).</p>
<p><strong>2016:</strong> Stephen Brookes, A Semantics for Concurrent Separation Logic. Theoretical Computer Science 375(1-3): 227-270 (2007). Peter W. O’Hearn, Resources, Concurrency, and Local Reasoning. Theoretical Computer Science 375(1-3): 271-307 (2007).</p>
<p><strong>2015:</strong> Dan Spielman and Shang-Hua Teng, Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems, Proc. 36th ACM Symposium on Theory of Computing, pp. 81-90, 2004; Spectral sparsification of graphs, SIAM J. Computing 40:981-1025, 2011; A local clustering algorithm for massive graphs and its application to nearly linear time graph partitioning, SIAM J. Computing 42:1-26, 2013; Nearly linear time algorithms for preconditioning and solving symmetric, diagonally dominant linear systems, SIAM J. Matrix Anal. Appl. 35:835-885, 2014.</p>
<p><strong>2014: </strong>Ronald Fagin, Amnon Lotem, and Moni Naor, Optimal Aggregation Algorithms for Middleware, Journal of Computer and System Sciences 66(4): 614–656, 2003.</p>
<p><strong>2013: </strong>Antoine Joux, A one round protocol for tripartite Diffie-Hellman, J. Cryptology 17(4): 263-276, 2004. Dan Boneh and Matthew K. Franklin, Identity-Based Encryption from the Weil pairing, SIAM J. Comput. 32(3): 586-615, 2003.</p></div>
    </content>
    <updated>2018-12-18T20:14:50Z</updated>
    <published>2018-12-18T20:14:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2018-12-31T12:21:15Z</updated>
    </source>
  </entry>
</feed>
