<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-07-02T19:22:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8161</id>
    <link href="https://windowsontheory.org/2021/07/02/itc-2021-call-for-participation-guest-post-by-benny-applebaum/" rel="alternate" type="text/html"/>
    <title>ITC 2021: Call for participation (guest post by Benny Applebaum)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The second edition of the recently created conference on Information-Theoretic Cryptography (ITC 2021) will take place virtually on July 24-26, 2021. The final program is out and contains exciting new works and invited talks that highlight the recent advances in the area by Benny Applebaum, Elaine Shi, Irit Dinur, Salman Avestimehr, Matthieu Bloch, and Mark … <a class="more-link" href="https://windowsontheory.org/2021/07/02/itc-2021-call-for-participation-guest-post-by-benny-applebaum/">Continue reading <span class="screen-reader-text">ITC 2021: Call for participation (guest post by Benny Applebaum)</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The second edition of the recently created conference on <em>Information-Theoretic Cryptography (ITC 2021)</em> will take place virtually on July 24-26, 2021. The final program is out and contains exciting new works and invited talks that highlight the recent advances in the area by Benny Applebaum, Elaine Shi, Irit Dinur, Salman Avestimehr, Matthieu Bloch, and Mark Zhandry.</p>



<p>Registration to the conference is free (but required!)</p>



<p>Visit the webpage <a href="https://itcrypto.github.io/2021/index.html" rel="noreferrer noopener" target="_blank">https://itcrypto.github.io/2021/index.html</a> for more information and for the full program.  </p>



<p>Hope to see you there!</p>



<p>– The Organising Committee</p></div>
    </content>
    <updated>2021-07-02T13:08:48Z</updated>
    <published>2021-07-02T13:08:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-07-02T19:21:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1542</id>
    <link href="https://ptreview.sublinear.info/?p=1542" rel="alternate" type="text/html"/>
    <title>Looking back at WOLA’21: Videos available</title>
    <summary>The fifth Workshop on Local Algorithms (WOLA’21) took place earlier this month, and the recordings of the invited talks are now available on YouTube. If you missed the workshop, or want to refresh your memory, here are the recordings (ordered by the workshop schedule): James Aspnes (Yale) on Population Protocols Uri Stemmer (Ben-Gurion University) on […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The fifth <a href="http://www.local-algorithms.com/">Workshop on Local Algorithms</a> (WOLA’21) took place <a href="https://ptreview.sublinear.info/?p=1517">earlier this month</a>, and the recordings of the invited talks are now <a href="https://www.youtube.com/watch?v=aFaJz3HPluM&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm">available on YouTube</a>. If you missed the workshop, or want to refresh your memory, here are the recordings (ordered by the workshop schedule):</p>



<ul><li>James Aspnes (Yale) on <a href="https://www.youtube.com/watch?v=aFaJz3HPluM&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=2"><em>Population Protocols</em></a></li><li>Uri Stemmer (Ben-Gurion University) on <em><a href="https://www.youtube.com/watch?v=yxOmND76k4M&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=4">The Local Model of Differential Privacy: A Survey</a></em></li><li>Mary Wootters (Stanford University) on <em><a href="https://www.youtube.com/watch?v=oHGvGgSdvAc&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=7">Lifted Codes and Disjoint Repair Groups</a></em></li><li>Christian Sohler (University of Cologne) on <em><a href="https://www.youtube.com/watch?v=DuJQe0pv224&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=6">Property Testing in Planar Graphs</a></em></li><li>Elaine Shi (Carnegie Mellon University) on <em><a href="https://www.youtube.com/watch?v=jq5MuJJLnDk&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=5">Game-Theoretically Secure Protocols Inspired by Blockchains</a></em></li><li>Jelani Nelson (UC Berkeley) on <em><a href="https://www.youtube.com/watch?v=ZQ1ekannlw0&amp;list=PLrzWWJ35eA2wG5aGbagb6bVo8HMH4FrNm&amp;index=3">Optimal bounds for approximate counting</a></em></li></ul>



<p>Thanks again to the speakers and organizers, and looking forward to WOLA’22!</p></div>
    </content>
    <updated>2021-07-02T04:59:48Z</updated>
    <published>2021-07-02T04:59:48Z</published>
    <category term="Conference reports"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2021-07-02T05:21:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/092" rel="alternate" type="text/html"/>
    <title>TR21-092 |  A Note on One-way Functions and Sparse Languages | 

	Yanyi Liu, 

	Rafael Pass</title>
    <summary>We show equivalence between the existence of one-way
functions and the existence of a \emph{sparse} language that is
hard-on-average w.r.t. some efficiently samplable ``high-entropy''
distribution.
In more detail, the following are equivalent:
  - The existentence of a $S(\cdot)$-sparse language $L$ that is
    hard-on-average with respect to some samplable distribution with
    Shannon entropy $h(\cdot)$ such that $h(n)-\log(S(n)) \geq 4\log n$;
  - The existentence of a $S(\cdot)$-sparse language $L \in
    \NP$, that is
    hard-on-average with respect to some samplable distribution with
    Shannon entropy $h(\cdot)$ such that $h(n)-\log(S(n)) \geq n/3$;
  - The existence of one-way functions.

Our results are insipired by, and generalize, the recent elegant paper by Ilango,
Ren and Santhanam (ECCC'21), which presents similar characterizations for
concrete sparse languages.</summary>
    <updated>2021-07-02T01:24:40Z</updated>
    <published>2021-07-02T01:24:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4580221543262282386</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4580221543262282386/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/07/intersecting-classes.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4580221543262282386" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4580221543262282386" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/07/intersecting-classes.html" rel="alternate" type="text/html"/>
    <title>Intersecting Classes</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you have two complexity classes that have complete sets, the intersection might not, for example NP ∩ co-NP. The world of total-function classes acts differently.</p><p>Christos Papadimitriou and others defined a <a href="https://en.wikipedia.org/wiki/TFNP">number of classes</a> based on finding solutions to problems where solutions are known to exists for some combinatorial reason. While TFNP, the set of all such problems, might not have complete sets, all the other classes are defined basically based on the complete search problem for the class, such as <a href="https://en.wikipedia.org/wiki/TFNP#PLS">PLS</a>, finding a local minimum. If you have two such classes <b><span style="font-family: Cedarville Cursive;">A</span></b> and <b><span style="font-family: Cedarville Cursive;">B</span></b> with complete search problems A and B define the search problem D as </p><p style="text-align: center;">D(x,y): Find a solution to either A(x) or B(y)</p><p>D is complete for the intersection of <b><span style="font-family: Cedarville Cursive;">A</span></b> and <span style="font-family: Cedarville Cursive; font-weight: bold;">B</span><span style="font-family: inherit;">:</span><span style="font-family: inherit;"><span style="font-family: inherit;"> </span>First the </span><span style="font-family: inherit;">pr</span>oblem D is in <b><span style="font-family: Cedarville Cursive;">A</span></b> since you can reduce the problem of finding a solution to either A or B to finding a solution to A. Likewise D is in <span style="font-family: Cedarville Cursive;"><b>B</b></span>.</p><p>Suppose you have a problem Z in <b><span style="font-family: Cedarville Cursive;">A</span></b>∩<span style="font-family: Cedarville Cursive; font-weight: bold;">B</span>.<span style="font-family: inherit;"> Then since Z is in </span><b><span style="font-family: Cedarville Cursive;">A</span></b><span style="font-family: inherit;"> and A is complete for </span><span style="font-family: Cedarville Cursive;">A</span><span style="font-family: inherit;">, finding a solution to Z(u) reduces a finding a solution of A(x) where x is easily computed from u. Likewise Z(u) reduces to finding a solution of B(y). So whatever solution D(x,y) gives you, it allows you to find a solution to Z(u). Thus D is complete for </span><b><span style="font-family: Cedarville Cursive;">A</span></b>∩<span style="font-family: Cedarville Cursive; font-weight: bold;">B</span><span>.</span></p><p>Some people nerd out to <a href="https://mars.nasa.gov/technology/helicopter">helicopters on mars</a>. I nerd out to the complexity of complete sets. </p><p>I learned about complete sets of intersections of total function classes from the talk by one of <a href="http://acm-stoc.org/stoc2021/STOCprogram.html">last week's STOC</a> best paper awardees, <a href="https://doi.org/10.1145/3406325.3451052">The Complexity of Gradient Descent</a> by John Fearnley, Paul W. Goldberg, Alexandros Hollender and Rahul Savani. The part above was well known but the paper goes much further.</p><p>Consider <a href="https://blog.computationalcomplexity.org/2005/12/what-is-ppad.html">PPAD</a> famously with Nash Equilibrium as a complete problem and PLS. PPAD ∩ PLS has complete sets by the argument above. But we can go further.</p><p>The class <a href="https://en.wikipedia.org/wiki/TFNP#CLS">CLS</a> is a variation of PLS where you find a local minimum in a continuous domain under some Lipschitz conditions and is known to sit in the intersection of PPAD and PLS. Fearnley et al. look at finding a minimum using gradient descent (the main tool for deep learning), and showing not only is it CLS-compete but complete for PPAD ∩ PLS. As a consequence CLS = PPAD ∩ PLS. Pretty cool stuff.</p></div>
    </content>
    <updated>2021-07-01T14:44:00Z</updated>
    <published>2021-07-01T14:44:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-07-02T15:22:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16218</id>
    <link href="http://arxiv.org/abs/2106.16218" rel="alternate" type="text/html"/>
    <title>Logarithmic Weisfeiler-Leman Identifies All Planar Graphs</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grohe:Martin.html">Martin Grohe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kiefer:Sandra.html">Sandra Kiefer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16218">PDF</a><br/><b>Abstract: </b>The Weisfeiler-Leman (WL) algorithm is a well-known combinatorial procedure
for detecting symmetries in graphs and it is widely used in graph-isomorphism
tests. It proceeds by iteratively refining a colouring of vertex tuples. The
number of iterations needed to obtain the final output is crucial for the
parallelisability of the algorithm.
</p>
<p>We show that there is a constant k such that every planar graph can be
identified (that is, distinguished from every non-isomorphic graph) by the
k-dimensional WL algorithm within a logarithmic number of iterations. This
generalises a result due to Verbitsky (STACS 2007), who proved the same for
3-connected planar graphs.
</p>
<p>The number of iterations needed by the k-dimensional WL algorithm to identify
a graph corresponds to the quantifier depth of a sentence that defines the
graph in the (k+1)-variable fragment C^{k+1} of first-order logic with counting
quantifiers. Thus, our result implies that every planar graph is definable with
a C^{k+1}-sentence of logarithmic quantifier depth.
</p></div>
    </summary>
    <updated>2021-07-01T22:43:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16213</id>
    <link href="http://arxiv.org/abs/2106.16213" rel="alternate" type="text/html"/>
    <title>On the Power of Saturated Transformers: A View from Circuit Complexity</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Merrill:William.html">William Merrill</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Yoav.html">Yoav Goldberg</a>, Roy Schwartz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smith:Noah_A=.html">Noah A. Smith</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16213">PDF</a><br/><b>Abstract: </b>Transformers have become a standard architecture for many NLP problems. This
has motivated theoretically analyzing their capabilities as models of language,
in order to understand what makes them successful, and what their potential
weaknesses might be. Recent work has shown that transformers with hard
attention are quite limited in capacity, and in fact can be simulated by
constant-depth circuits. However, hard attention is a restrictive assumption,
which may complicate the relevance of these results for practical transformers.
In this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We show that saturated
transformers transcend the limitations of hard-attention transformers. With
some minor assumptions, we prove that the number of bits needed to represent a
saturated transformer memory vector is $O(\log n)$, which implies saturated
transformers can be simulated by log-depth circuits. Thus, the jump from hard
to saturated attention can be understood as increasing the transformer's
effective circuit depth by a factor of $O(\log n)$.
</p></div>
    </summary>
    <updated>2021-07-01T22:37:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16180</id>
    <link href="http://arxiv.org/abs/2106.16180" rel="alternate" type="text/html"/>
    <title>Grid Recognition: Classical and Parameterized Computational Perspectives</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Siddharth.html">Siddharth Gupta</a>, Guy Sa'ar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16180">PDF</a><br/><b>Abstract: </b>Grid graphs, and, more generally, $k\times r$ grid graphs, form one of the
most basic classes of geometric graphs. Over the past few decades, a large body
of works studied the (in)tractability of various computational problems on grid
graphs, which often yield substantially faster algorithms than general graphs.
Unfortunately, the recognition of a grid graph is particularly hard -- it was
shown to be NP-hard even on trees of pathwidth 3 already in 1987. Yet, in this
paper, we provide several positive results in this regard in the framework of
parameterized complexity (additionally, we present new and complementary
hardness results). Specifically, our contribution is threefold. First, we show
that the problem is fixed-parameter tractable (FPT) parameterized by $k+\mathsf
{mcc}$ where $\mathsf{mcc}$ is the maximum size of a connected component of
$G$. This also implies that the problem is FPT parameterized by $\mathtt{td}+k$
where $\mathtt{td}$ is the treedepth of $G$ (to be compared with the hardness
for pathwidth 2 where $k=3$). Further, we derive as a corollary that strip
packing is FPT with respect to the height of the strip plus the maximum of the
dimensions of the packed rectangles, which was previously only known to be in
XP. Second, we present a new parameterization, denoted $a_G$, relating graph
distance to geometric distance, which may be of independent interest. We show
that the problem is para-NP-hard parameterized by $a_G$, but FPT parameterized
by $a_G$ on trees, as well as FPT parameterized by $k+a_G$. Third, we show that
the recognition of $k\times r$ grid graphs is NP-hard on graphs of pathwidth 2
where $k=3$. Moreover, when $k$ and $r$ are unrestricted, we show that the
problem is NP-hard on trees of pathwidth 2, but trivially solvable in
polynomial time on graphs of pathwidth 1.
</p></div>
    </summary>
    <updated>2021-07-01T22:52:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16173</id>
    <link href="http://arxiv.org/abs/2106.16173" rel="alternate" type="text/html"/>
    <title>String Comparison on a Quantum Computer Using Hamming Distance</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mushahid Khan, Andriy Miranskyy <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16173">PDF</a><br/><b>Abstract: </b>The Hamming distance is ubiquitous in computing. Its computation gets
expensive when one needs to compare a string against many strings. Quantum
computers (QCs) may speed up the comparison.
</p>
<p>In this paper, we extend an existing algorithm for computing the Hamming
distance. The extension can compare strings with symbols drawn from an
arbitrary-long alphabet (which the original algorithm could not). We implement
our extended algorithm using the QisKit framework to be executed by a
programmer without the knowledge of a QC (the code is publicly available). We
then provide four pedagogical examples: two from the field of bioinformatics
and two from the field of software engineering. We finish by discussing
resource requirements and the time horizon of the QCs becoming practical for
string comparison.
</p></div>
    </summary>
    <updated>2021-07-01T22:59:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16172</id>
    <link href="http://arxiv.org/abs/2106.16172" rel="alternate" type="text/html"/>
    <title>Backgammon is Hard</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Witter:R=_Teal.html">R. Teal Witter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16172">PDF</a><br/><b>Abstract: </b>We study the computational complexity of the popular board game backgammon.
We show that deciding whether a player can win from a given board configuration
is NP-Hard, PSPACE-Hard, and EXPTIME-Hard under different settings of known and
unknown opponents' strategies and dice rolls. Our work answers an open question
posed by Erik Demaine in 2001. In particular, for the real life setting where
the opponent's strategy and dice rolls are unknown, we prove that determining
whether a player can win is EXPTIME-Hard. Interestingly, it is not clear what
complexity class strictly contains each problem we consider because backgammon
games can theoretically continue indefinitely as a result of the capture rule.
</p></div>
    </summary>
    <updated>2021-07-01T22:47:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16147</id>
    <link href="http://arxiv.org/abs/2106.16147" rel="alternate" type="text/html"/>
    <title>Nearly-Tight and Oblivious Algorithms for Explainable Clustering</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamlath:Buddhima.html">Buddhima Gamlath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:Xinrui.html">Xinrui Jia</a>, Adam Polak, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16147">PDF</a><br/><b>Abstract: </b>We study the problem of explainable clustering in the setting first
formalized by Moshkovitz, Dasgupta, Rashtchian, and Frost (ICML 2020). A
$k$-clustering is said to be explainable if it is given by a decision tree
where each internal node splits data points with a threshold cut in a single
dimension (feature), and each of the $k$ leaves corresponds to a cluster. We
give an algorithm that outputs an explainable clustering that loses at most a
factor of $O(\log^2 k)$ compared to an optimal (not necessarily explainable)
clustering for the $k$-medians objective, and a factor of $O(k \log^2 k)$ for
the $k$-means objective. This improves over the previous best upper bounds of
$O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\Omega(\log
k)$ lower bound for $k$-medians and our new $\Omega(k)$ lower bound for
$k$-means. The algorithm is remarkably simple. In particular, given an initial
not necessarily explainable clustering in $\mathbb{R}^d$, it is oblivious to
the data points and runs in time $O(dk \log^2 k)$, independent of the number of
data points $n$. Our upper and lower bounds also generalize to objectives given
by higher $\ell_p$-norms.
</p></div>
    </summary>
    <updated>2021-07-01T22:59:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16115</id>
    <link href="http://arxiv.org/abs/2106.16115" rel="alternate" type="text/html"/>
    <title>The Power of Adaptivity for Stochastic Submodular Cover</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghuge:Rohan.html">Rohan Ghuge</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagarajan:Viswanath.html">Viswanath Nagarajan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16115">PDF</a><br/><b>Abstract: </b>In the stochastic submodular cover problem, the goal is to select a subset of
stochastic items of minimum expected cost to cover a submodular function.
Solutions in this setting correspond to sequential decision processes that
select items one by one "adaptively" (depending on prior observations). While
such adaptive solutions achieve the best objective, the inherently sequential
nature makes them undesirable in many applications. We ask: how well can
solutions with only a few adaptive rounds approximate fully-adaptive solutions?
We give nearly tight answers for both independent and correlated settings,
proving smooth tradeoffs between the number of adaptive rounds and the solution
quality, relative to fully adaptive solutions. Experiments on synthetic and
real datasets show qualitative improvements in the solutions as we allow more
rounds of adaptivity; in practice, solutions with a few rounds of adaptivity
are nearly as good as fully adaptive solutions.
</p></div>
    </summary>
    <updated>2021-07-01T23:00:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16112</id>
    <link href="http://arxiv.org/abs/2106.16112" rel="alternate" type="text/html"/>
    <title>Coresets for Clustering with Missing Values</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Shaofeng_H==C=.html">Shaofeng H.-C. Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xuan.html">Xuan Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16112">PDF</a><br/><b>Abstract: </b>We provide the first coreset for clustering points in $\mathbb{R}^d$ that
have multiple missing values (coordinates). Previous coreset constructions only
allow one missing coordinate. The challenge in this setting is that objective
functions, like $k$-Means, are evaluated only on the set of available
(non-missing) coordinates, which varies across points. Recall that an
$\epsilon$-coreset of a large dataset is a small proxy, usually a reweighted
subset of points, that $(1+\epsilon)$-approximates the clustering objective for
every possible center set.
</p>
<p>Our coresets for $k$-Means and $k$-Median clustering have size
$(jk)^{O(\min(j,k))} (\epsilon^{-1} d \log n)^2$, where $n$ is the number of
data points, $d$ is the dimension and $j$ is the maximum number of missing
coordinates for each data point. We further design an algorithm to construct
these coresets in near-linear time, and consequently improve a recent
quadratic-time PTAS for $k$-Means with missing values [Eiben et al., SODA 2021]
to near-linear time.
</p>
<p>We validate our coreset construction, which is based on importance sampling
and is easy to implement, on various real data sets. Our coreset exhibits a
flexible tradeoff between coreset size and accuracy, and generally outperforms
the uniform-sampling baseline. Furthermore, it significantly speeds up a
Lloyd's-style heuristic for $k$-Means with missing values.
</p></div>
    </summary>
    <updated>2021-07-01T22:54:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.16015</id>
    <link href="http://arxiv.org/abs/2106.16015" rel="alternate" type="text/html"/>
    <title>Close relatives (of Feedback Vertex Set), revisited</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Hugo.html">Hugo Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Defrain:Oscar.html">Oscar Defrain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.16015">PDF</a><br/><b>Abstract: </b>At IPEC 2020, Bergougnoux, Bonnet, Brettell, and Kwon showed that a number of
problems related to the classic Feedback Vertex Set (FVS) problem do not admit
a $2^{o(k \log k)} \cdot n^{\mathcal{O}(1)}$-time algorithm on graphs of
treewidth at most $k$, assuming the Exponential Time Hypothesis. This contrasts
with the $3^{k} \cdot k^{\mathcal{O}(1)} \cdot n$-time algorithm for FVS using
the Cut&amp;Count technique.
</p>
<p>During their live talk at IPEC 2020, Bergougnoux et al.~posed a number of
open questions, which we answer in this work.
</p>
<p>- Subset Even Cycle Transversal, Subset Odd Cycle Transversal, Subset
Feedback Vertex Set can be solved in time $2^{\mathcal{O}(k \log k)} \cdot n$
in graphs of treewidth at most $k$. This matches a lower bound for Even Cycle
Transversal of Bergougnoux et al.~and improves the polynomial factor in some of
their upper bounds.
</p>
<p>- Subset Feedback Vertex Set and Node Multiway Cut can be solved in time
$2^{\mathcal{O}(k \log k)} \cdot n$, if the input graph is given as a
clique-width expression of size $n$ and width $k$.
</p>
<p>- Odd Cycle Transversal can be solved in time $4^k \cdot k^{\mathcal{O}(1)}
\cdot n$ if the input graph is given as a clique-width expression of size $n$
and width $k$. Furthermore, the existence of a constant $\varepsilon &gt; 0$ and
an algorithm performing this task in time $(4-\varepsilon)^k \cdot
n^{\mathcal{O}(1)}$ would contradict the Strong Exponential Time Hypothesis.
</p></div>
    </summary>
    <updated>2021-07-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15992</id>
    <link href="http://arxiv.org/abs/2106.15992" rel="alternate" type="text/html"/>
    <title>Perfect Sampling in Infinite Spin Systems via Strong Spatial Mixing</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anand:Konrad.html">Konrad Anand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jerrum:Mark.html">Mark Jerrum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15992">PDF</a><br/><b>Abstract: </b>We present a simple algorithm that perfectly samples configurations from the
unique Gibbs measure of a spin system on a potentially infinite graph $G$. The
sampling algorithm assumes strong spatial mixing together with subexponential
growth of $G$. It produces a finite window onto a perfect sample from the Gibbs
distribution. The run-time is linear in the size of the window.
</p></div>
    </summary>
    <updated>2021-07-01T22:51:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15969</id>
    <link href="http://arxiv.org/abs/2106.15969" rel="alternate" type="text/html"/>
    <title>On Completeness of Cost Metrics and Meta-Search Algorithms in \$-Calculus</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eberbach:Eugene.html">Eugene Eberbach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15969">PDF</a><br/><b>Abstract: </b>In the paper we define three new complexity classes for Turing Machine
undecidable problems inspired by the famous Cook/Levin's NP-complete complexity
class for intractable problems. These are U-complete (Universal complete),
D-complete (Diagonalization complete) and H-complete (Hypercomputation
complete) classes. We started the population process of these new classes. We
justify that some super-Turing models of computation, i.e., models going beyond
Turing machines, are tremendously expressive and they allow to accept arbitrary
languages over a given alphabet including those undecidable ones. We prove also
that one of such super-Turing models of computation -- the \$-Calculus,
designed as a tool for automatic problem solving and automatic programming, has
also such tremendous expressiveness. We investigate also completeness of cost
metrics and meta-search algorithms in \$-calculus.
</p></div>
    </summary>
    <updated>2021-07-01T22:43:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15907</id>
    <link href="http://arxiv.org/abs/2106.15907" rel="alternate" type="text/html"/>
    <title>Parameterized Complexities of Dominating and Independent Set Reconfiguration</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodlaender:Hans_L=.html">Hans L. Bodlaender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Groenland:Carla.html">Carla Groenland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swennenhuis:C=eacute=line_M=_F=.html">Céline M. F. Swennenhuis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15907">PDF</a><br/><b>Abstract: </b>We settle the parameterized complexities of several variants of independent
set reconfiguration and dominating set reconfiguration, parameterized by the
number of tokens. We show that both problems are XL-complete when there is no
limit on the number of moves and XNL-complete when a maximum length $\ell$ for
the sequence is given in binary in the input. The problems are known to be
XNLP-complete when $\ell$ is given in unary instead, and $W[1]$- and
$W[2]$-hard respectively when $\ell$ is also a parameter. We complete the
picture by showing membership in those classes.
</p>
<p>Moreover, we show that for all the variants that we consider, token sliding
and token jumping are equivalent under pl-reductions. We introduce partitioned
variants of token jumping and token sliding, and give pl-reductions between the
four variants that have precise control over the number of tokens and the
length of the reconfiguration sequence.
</p></div>
    </summary>
    <updated>2021-07-01T22:47:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15901</id>
    <link href="http://arxiv.org/abs/2106.15901" rel="alternate" type="text/html"/>
    <title>Optimally rescheduling jobs with a LIFO buffer</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nicosia:Gaia.html">Gaia Nicosia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pacifici:Andrea.html">Andrea Pacifici</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pferschy:Ulrich.html">Ulrich Pferschy</a>, Julia Resch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Righini:Giovanni.html">Giovanni Righini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15901">PDF</a><br/><b>Abstract: </b>This paper considers single-machine scheduling problems in which a given
solution, i.e. an ordered set of jobs, has to be improved as much as possible
by re-sequencing the jobs. The need for rescheduling may arise in different
contexts, e.g. due to changes in the job data or because of the local objective
in a stage of a supply chain \red{that is} not aligned with the given sequence.
A common production setting entails the movement of jobs (or parts) on a
conveyor. This is reflected in our model by facilitating the re-sequencing of
jobs via a buffer of limited capacity accessible by a LIFO policy. We consider
the classical objective functions of total weighted completion time, maximum
lateness and (weighted) number of late jobs and study their complexity. For
three of these problems we present strictly polynomial-time dynamic programming
algorithms, while for the case of minimizing the weighted number of late jobs
NP-hardness is proven and a pseudo-polynomial algorithm is given.
</p></div>
    </summary>
    <updated>2021-07-01T23:04:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15885</id>
    <link href="http://arxiv.org/abs/2106.15885" rel="alternate" type="text/html"/>
    <title>Optimal Construction for Time-Convex Hull with Two Orthogonal Highways in the L1-metric</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Jyun=Yu.html">Jyun-Yu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Po=Hsuan.html">Po-Hsuan Chen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15885">PDF</a><br/><b>Abstract: </b>We consider the time-convex hull problem in the presence of two orthogonal
highways H. In this problem, the travelling speed on the highway is faster than
off the highway, and the time-convex hull of a point set P is the closure of P
with respect to the inclusion of shortest time-paths. In this paper, we provide
the algorithm for constructing the time-convex hull with two orthogonal
highways. We reach the optimal result of O(n log n) time for arbitrary highway
speed in the L1-metric. For the L2-metric with infinite highway speed, we hit
the goal of O(n log n) time as well.
</p></div>
    </summary>
    <updated>2021-07-01T23:06:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15740</id>
    <link href="http://arxiv.org/abs/2106.15740" rel="alternate" type="text/html"/>
    <title>Importance of Diagonal Gates in Tensor Network Simulations</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Danylo Lykov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alexeev:Yuri.html">Yuri Alexeev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15740">PDF</a><br/><b>Abstract: </b>In this work we present two techniques that tremendously increase the
performance of tensor-network based quantum circuit simulations. The techniques
are implemented in the QTensor package and benchmarked using Quantum
Approximate Optimization Algorithm (QAOA) circuits. The techniques allowed us
to increase the depth and size of QAOA circuits that can be simulated. In
particular, we increased the QAOA depth from 2 to 5 and the size of a QAOA
circuit from 180 to 244 qubits. Moreover, we increased the speed of simulations
by up to 10 million times. Our work provides important insights into how
various techniques can dramatically speed up the simulations of circuits.
</p></div>
    </summary>
    <updated>2021-07-01T22:59:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15731</id>
    <link href="http://arxiv.org/abs/2106.15731" rel="alternate" type="text/html"/>
    <title>Near-Optimal Deterministic Single-Source Distance Sensitivity Oracles</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bil=ograve=:Davide.html">Davide Bilò</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Sarel.html">Sarel Cohen</a>, Tobias Friedrich, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schirneck:Martin.html">Martin Schirneck</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15731">PDF</a><br/><b>Abstract: </b>Given a graph with a source vertex $s$, the Single Source Replacement Paths
(SSRP) problem is to compute, for every vertex $t$ and edge $e$, the length
$d(s,t,e)$ of a shortest path from $s$ to $t$ that avoids $e$. A Single-Source
Distance Sensitivity Oracle (Single-Source DSO) is a data structure that
answers queries of the form $(t,e)$ by returning the distance $d(s,t,e)$. We
show how to deterministically compress the output of the SSRP problem on
$n$-vertex, $m$-edge graphs with integer edge weights in the range $[1,M]$ into
a Single-Source DSO of size $O(M^{1/2}n^{3/2})$ with query time
$\widetilde{O}(1)$. The space requirement is optimal (up to the word size) and
our techniques can also handle vertex failures.
</p>
<p>Chechik and Cohen [SODA 2019] presented a combinatorial, randomized
$\widetilde{O}(m\sqrt{n}+n^2)$ time SSRP algorithm for undirected and
unweighted graphs. Grandoni and Vassilevska Williams [FOCS 2012, TALG 2020]
gave an algebraic, randomized $\widetilde{O}(Mn^\omega)$ time SSRP algorithm
for graphs with integer edge weights in the range $[1,M]$, where $\omega&lt;2.373$
is the matrix multiplication exponent. We derandomize both algorithms for
undirected graphs in the same asymptotic running time and apply our compression
to obtain deterministic Single-Source DSOs. The $\widetilde{O}(m\sqrt{n}+n^2)$
and $\widetilde{O}(Mn^\omega)$ preprocessing times are polynomial improvements
over previous $o(n^2)$-space oracles.
</p>
<p>On sparse graphs with $m=O(n^{5/4-\varepsilon}/M^{7/4})$ edges, for any
constant $\varepsilon &gt; 0$, we reduce the preprocessing to randomized
$\widetilde{O}(M^{7/8}m^{1/2}n^{11/8})=O(n^{2-\varepsilon/2})$ time. This is
the first truly subquadratic time algorithm for building Single-Source DSOs on
sparse graphs.
</p></div>
    </summary>
    <updated>2021-07-01T23:03:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.15662</id>
    <link href="http://arxiv.org/abs/2106.15662" rel="alternate" type="text/html"/>
    <title>Exponential Weights Algorithms for Selective Learning</title>
    <feedworld_mtime>1625097600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiao:Mingda.html">Mingda Qiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Gregory.html">Gregory Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.15662">PDF</a><br/><b>Abstract: </b>We study the selective learning problem introduced by Qiao and Valiant
(2019), in which the learner observes $n$ labeled data points one at a time. At
a time of its choosing, the learner selects a window length $w$ and a model
$\hat\ell$ from the model class $\mathcal{L}$, and then labels the next $w$
data points using $\hat\ell$. The excess risk incurred by the learner is
defined as the difference between the average loss of $\hat\ell$ over those $w$
data points and the smallest possible average loss among all models in
$\mathcal{L}$ over those $w$ data points.
</p>
<p>We give an improved algorithm, termed the hybrid exponential weights
algorithm, that achieves an expected excess risk of $O((\log\log|\mathcal{L}| +
\log\log n)/\log n)$. This result gives a doubly exponential improvement in the
dependence on $|\mathcal{L}|$ over the best known bound of
$O(\sqrt{|\mathcal{L}|/\log n})$. We complement the positive result with an
almost matching lower bound, which suggests the worst-case optimality of the
algorithm.
</p>
<p>We also study a more restrictive family of learning algorithms that are
bounded-recall in the sense that when a prediction window of length $w$ is
chosen, the learner's decision only depends on the most recent $w$ data points.
We analyze an exponential weights variant of the ERM algorithm in Qiao and
Valiant (2019). This new algorithm achieves an expected excess risk of
$O(\sqrt{\log |\mathcal{L}|/\log n})$, which is shown to be nearly optimal
among all bounded-recall learners. Our analysis builds on a generalized version
of the selective mean prediction problem in Drucker (2013); Qiao and Valiant
(2019), which may be of independent interest.
</p></div>
    </summary>
    <updated>2021-07-01T22:58:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-07-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2021/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Flow lines (\(\mathbb{M}\)). Web gadget editable open source code thingy to draw streamlines of mathematical formulas, in svg format, by Maksim Surguy.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://maxoffsky.com/code-blog/flow-lines/">Flow lines</a> (<a href="https://mathstodon.xyz/@11011110/106428733923482392">\(\mathbb{M}\)</a>). Web gadget editable open source code thingy to draw streamlines of mathematical formulas, in svg format, by Maksim Surguy.</p>
  </li>
  <li>
    <p><a href="https://daily.jstor.org/the-soap-bubble-trope/">The soap bubble trope</a> (<a href="https://mathstodon.xyz/@11011110/106430498906810187">\(\mathbb{M}\)</a>, <a href="https://3quarksdaily.com/3quarksdaily/2021/06/soap-bubbles.html">via</a>). Soap bubbles as a recurring theme in art, literature, and popular culture, including “the roof of the Munich Olympic Stadium, Glinda the Good Witch, the first viral ad campaign of the late Victorian era, and morose Dutch still-life paintings”.</p>
  </li>
  <li>
    <p><a href="http://gosper.org/homeplate.html">Officially, home plate doesn’t exist</a> (<a href="https://mathstodon.xyz/@esoterica/106435964222477352">\(\mathbb{M}\)</a>). The rules of baseball define it as a 90-45-90-90-45 pentagon with two 12” sides at one of the right angles and a 17” side between the other two, not possible.</p>
  </li>
  <li>
    <p><a href="https://www.natureindex.com/news-blog/microsoft-academic-graph-discontinued-whats-next">Microsoft Academic Graph being discontinued</a> (<a href="https://mathstodon.xyz/@11011110/106438809410223323">\(\mathbb{M}\)</a>, <a href="https://retractionwatch.com/2021/06/19/weekend-reads-biotech-ceo-on-leave-after-allegations-on-pubpeer-a-researcher-disavows-his-own-paper-plagiarism-here-there-and-everywhere/">via</a>). I didn’t much use that one but I live in fear that one day Google will do the same thing to Google Scholar, as they have to so many other useful but nonprofitable Google services.</p>
  </li>
  <li>
    <p>My current workflow for preparing technical talk videos (<a href="https://mathstodon.xyz/@11011110/106444988062063872">\(\mathbb{M}\)</a>):</p>

    <ul>
      <li>
        <p>Use LaTeX+beamer (169 option) to make pdf talk slides</p>
      </li>
      <li>
        <p>For each slide, print open-in-Preview with custom 16x9 zero-margin layout then export to png</p>
      </li>
      <li>
        <p>Write a script and use quicktime to record 1-2 minute voiceover clips</p>
      </li>
      <li>
        <p>Compose slides and audio in iMovie, export to a huge mp4</p>
      </li>
      <li>
        <p>Use Handbrake to convert to reasonably-sized mp4</p>
      </li>
    </ul>

    <p>It works, but is a bit tedious and produces very dry results. The discussion includes suggestion of alternatives.</p>
  </li>
  <li>
    <p><a href="https://youtu.be/7vEgc7cNarI">The points rotated, and the lines danced</a> (<a href="https://mastodon.social/@sarielhp/106439137323288004">\(\mathbb{M}\)</a>). Video illustrating point-line duality by Sariel Har-Peled.</p>
  </li>
  <li>
    <p><a href="https://www.bbc.com/future/article/20210616-how-the-forgotten-tricks-of-letterlocking-shaped-history">Letterlocking</a> (<a href="https://mathstodon.xyz/@11011110/106458633659042049">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27549256">via</a>, <a href="https://en.wikipedia.org/wiki/Letterlocking">see also</a>): the art of folding your letters so intricately that readers will be forced to tear the paper to unfold and read them.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">Bill Gasarch summarizes an online debate</a> (<a href="https://mathstodon.xyz/@11011110/106463907058053228">\(\mathbb{M}\)</a>) with Richard DeMillo and Richard Lipton, moderated by Harry Lewis, looking back at the idea of proving programs correct and at <a href="https://doi.org/10.1145/359104.359106">a classic 1979 paper by DeMillo, Lipton, and Perlis</a> arguing that this idea was already problematic.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting">\(X+Y\) sorting</a> (<a href="https://mathstodon.xyz/@11011110/106468019908924208">\(\mathbb{M}\)</a>), now a Good Article on Wikipedia. This is on an old open problem in comparison sorting: can you sort pairs of elements from two sets by their sums, faster than unstructured data of the same length? It’s still an active topic of research; see e.g. <a href="https://doi.org/10.1145%2F3285953">Kane, Lovett, and Moran, “Near-optimal linear decision trees for \(k\)-sum and related problems”, <em>JACM</em> 2019</a>.</p>

    <p>It was not easy to persuade the GA reviewer that this article was as accessible as it could be. I have hopes of <a href="https://en.wikipedia.org/wiki/Dehn_invariant">Dehn invariant</a> also becoming a Good Article but its “Realizability” section is far more advanced.</p>
  </li>
  <li>
    <p>This week I participated in the International Workshop on Graph-Theoretic Concepts in Computer Science, WG (<a href="https://mathstodon.xyz/@11011110/106474212936524737">\(\mathbb{M}\)</a>). The 9-hour time difference made live participation awkward for me, but fortunately prerecorded contributed talks and the three invited talks (Dujmović on product structures, Samotij on independent set numeration, and Bonnet on twin-width) are linked from <a href="https://wg2021.mimuw.edu.pl/program/">the conference program</a>. The proceedings is not yet out but many preprints of papers are also linked.</p>
  </li>
  <li>
    <p><a href="https://theintercept.com/2021/06/23/anming-hu-trial-fbi-china/">“A juror says the FBI owes an apology to University of Tennessee scientist Anming Hu”</a> (<a href="https://mathstodon.xyz/@11011110/106481625501499687">\(\mathbb{M}\)</a>, <a href="https://retractionwatch.com/2021/06/25/weekend-reads-the-obesity-wars-and-the-education-of-a-researcher-zombie-research-hijacked-journals/">via</a>) after putting Hu on trial for allegedly hiding ties to China despite his repeated disclosures of those ties and possibly in retaliation for his refusal to become a spy in China for the FBI. Beyond hurting US research both directly and by motivating good people to go elsewhere, this racist witch hunt has provided fuel for Chinese propaganda.</p>
  </li>
  <li>
    <p>The Wikipedia “Book:” namespace for curated collections of articles is being killed off (<a href="https://mathstodon.xyz/@11011110/106484876399456966">\(\mathbb{M}\)</a>) after the software to collate them into pdfs stopped working. I created five of these, and used two as readings for my courses. All five have moved to my user space:</p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Fundamental_Data_Structures"><em>Fundamental Data Structures</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Graph_Algorithms"><em>Graph Algorithms</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Graph_Drawing"><em>Graph Drawing</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Matroid_Theory"><em>Matroid Theory</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Perfect_Graphs"><em>Perfect Graphs</em></a></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://danilafe.com/blog/math_rendering_is_wrong/">Math rendering is wrong</a> (<a href="https://mathstodon.xyz/@11011110/106492765314826160">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27656446">via</a>). This blog post from a year ago argues that, for the same reasons one might write a web site in a markup language before compiling it to html, we should also compile LaTeX to html at that time rather than using browser-side scripts (as in most deploys of MathJax or KaTeX) or conversion to images (Wikipedia). It doesn’t present a solution, but is more a call for that solution to be made.</p>
  </li>
  <li>
    <p><a href="https://kleinbottle.com/#AMAZON%20BRAND%20HIJACKING">Amazon stands by and does nothing as Chinese scammers hijack Cliff Stoll’s Klein bottle business to usurp its positive reviews</a> (<a href="https://mathstodon.xyz/@11011110/106500881370367192">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27684807">via</a>).</p>
  </li>
</ul></div>
    </content>
    <updated>2021-06-30T10:36:00Z</updated>
    <published>2021-06-30T10:36:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-06-30T17:39:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18933</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/" rel="alternate" type="text/html"/>
    <title>Scaling and Fame</title>
    <summary>Scaling the pandemic is different from scaling the US budget Sydney Morning Herald interview source Terence Tao is now “properly” famous. He was cited earlier this month in the NYT science section for help in explaining large numbers. Numbers such as the US federal budget. Today we discuss caveats on such explanations, after a riff […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Scaling the pandemic is different from scaling the US budget</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/tt/" rel="attachment wp-att-18935"><img alt="" class="alignright wp-image-18935" height="126" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/tt.png?resize=225%2C126&amp;ssl=1" width="225"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Sydney Morning Herald interview <a href="https://www.smh.com.au/lifestyle/terence-tao-the-mozart-of-maths-20150216-13fwcv.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Terence Tao is now “properly” famous. He was cited earlier this month in the NYT <a href="https://www.nytimes.com/2021/06/17/science/math-numbers-federal-budget-tao.html">science</a> section for help in explaining large numbers. Numbers such as the US federal budget.</p>
<p>
Today we discuss caveats on such explanations, after a riff on the popular explanation of mathematics.</p>
<p>
Regarding that, let us forget Tao’s work on primes in progressions with Ben Green, forget the Erdős discrepancy problem, and forget his almost-resolution of the Collatz conjecture. Forget it all. Better than a headline, he got his name embedded into the NYT article’s URL. This was for something much less deep that he wrote in 2009—as a blogger. </p>
<p>
<em>En passant</em>, we mention that Ken has an event tomorrow (Wed. 6/30) at 3:30 ET. It is a webinar hosted by Marc Rotenberg, who heads the Washington-based Center for AI and Digital Policy (<a href="https://www.caidp.org">CAIDP</a>), on “Chess and AI: The Role of Transparency.” Registration is free at this <a href="https://www.caidp.org/events/chess/">link</a>. One aspect of transparency in Ken’s work is that he writes about his model’s methodology here—as a blogger.</p>
<p>
</p><p/><h2> Rescaling the Budget </h2><p/>
<p/><p>
Tao was referenced for a <a href="https://terrytao.wordpress.com/2009/05/04/the-federal-budget-rescaled/">post</a> he wrote in May 2009 when Barack Obama was working on his first budget as President. The ratio of $100 million to $3 that he used scaled the budget income to about $75,000. </p>
<p>
With Joe Biden engaged in budget deliberations, Aiyana Green and Steven Strogatz wrote the NYT <a href="https://www.human.cornell.edu/pam/news/aiyana_green_nyt">article</a> on explaining the US federal budget. Green is a student at Cornell: she just completed her junior year in the Department of Policy Analysis and Management. </p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/agss/" rel="attachment wp-att-18936"><img alt="" class="aligncenter wp-image-18936" height="200" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/AGSS.png?resize=355%2C200&amp;ssl=1" width="355"/></a></p>
<p/><p><br/>
They updated Tao’s post to scale the income to $100,000. Besides being a round number, this is close to the estimated <a href="https://www.in2013dollars.com/us/inflation/2009">inflation since 2009</a>. Here is the NYT graphic of the numbers. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/bud-2/" rel="attachment wp-att-18938"><img alt="" class="aligncenter wp-image-18938" height="500" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/bud.png?resize=545%2C500&amp;ssl=1" width="545"/></a></p>
<p>
</p><p/><h2> A Scaling Caveat </h2><p/>
<p/><p>
It is attractive to apply this scaling trick elsewhere, even to grim subjects like the coronavirus pandemic. But there we find an element that does not scale.</p>
<p>
Suppose we use the same figure of 100,000 to scale down the world’s population. Besides its famous pandemic numbers <a href="https://www.worldometers.info/coronavirus/">pages</a>, Worldometer also keeps a running <a href="https://www.worldometers.info/world-population/">estimate</a> of the total world population, now nearing 7.9 billion. Scaling down means multiplying every ther human number by <img alt="{\gamma =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> 0.000012697445274. </p>
<p>
We can think of 100,000 people as a city that is not a metropolis. Scaling down the current pandemic figures, we get:</p>
<ul>
<li>
182,000,000 total cases become <b>2,309</b>. <p/>
</li><li>
11,496,147 active cases become <b>145</b>. <p/>
</li><li>
4 million total deaths (the numbers are approaching that millstone as we write) become <b>50</b> deaths. <p/>
</li><li>
80,346 currently listed in critical or serious condition become <b>exactly one</b>.
</li></ul>
<p>
These numbers are not at all unusual for our size of city if one considers all kinds of illness and mortality. The scaling trick may seem to have reduced the scope of the pandemic, as opposed to statements such as 182 million being over half the US population. Yet in terms of the raw numbers it preserves the proportions.</p>
<p>
What the scaling doesn’t preserve is the proportion of <em>relations</em>. The number of possible binary relations—person <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> knows person <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—is quadratic in the number <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of people. Suppose the number of pairs who know each other is <img alt="{an^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ban%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a small but fixed constant. (Note: we will redo this with something more reasonable below.) If we then scale <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> down to <img alt="{n' = n\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%27+%3D+n%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the situation becomes:</p>
<ul>
<li>
If we estimate the relatedness of our city, we get <img alt="{an'^2 = an^2\gamma^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ban%27%5E2+%3D+an%5E2%5Cgamma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. <p/>
</li><li>
But if we scaled down the number of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-knows-<img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> relations directly we would get <img alt="{an^2\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ban%5E2%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is substantially bigger by a factor of <img alt="{\frac{1}{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li></ul>
<p>
Thus what the scaling really underestimates is the impact of how people are affected by their loved ones being among the 182 million (or the worse numbers). The underestimation logic applies to any form <img alt="{an^c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ban%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where <img alt="{c &gt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This is not an issue with the budget because dollar bills don’t feel relatedness—at least not so much, even absent a line-item veto. Now we will make values of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> approaching <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> more reasonable.</p>
<p>
</p><p/><h2> Small World: Tao and Strogatz Again </h2><p/>
<p/><p>
Let’s consider people <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> who have <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> degrees of separation in the graph of who-knows-who. Then there are <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> who know each other such that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> knows <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> knows <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. If something strikes <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will feel a deep connection by that impact. The feeling is amplified if <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> have multiple pairs <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that make a path. This quantifies the relation that Tao calls “awareness” in his “Lecture Notes 3 FOR 254A” course <a href="https://rjlipton.wpcomstaging.com/feed/LECTURE NOTES 3 FOR 254A">notes</a> (pages 51–57 overall). A fact way more basic than what Tao is actually talking about in those notes is the following:</p>
<blockquote><p><b> </b> <em> The sum over pairs <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the number of pairs <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> between them who would be affected equals the sum over edges <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the number of pairs <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> they can be struck by: both are equal to the number of paths of length <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the graph. </em>
</p></blockquote>
<p/><p>
That number of paths is what we say is reasonable to model by a function <img alt="{an^c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ban%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with <img alt="{c \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This is the simplest way of approaching why we feel that treating the pandemic like the US budget underestimates its human effect. One can still rebut that other kinds of illness and death have the same scaling properties, but ultimately we are talking about the <em>excess</em> caused by the pandemic—the effect on top of everything else.</p>
<p>
We have not tried to make this analysis become rigorous using more-realistic models of human networks. Perhaps our readers can point us to such analysis. But one inkling of why we expect our point to be borne out comes from a key conclusion of the famous 1998 <a href="https://www.nature.com/articles/30918">paper</a> of Strogatz with Duncan Watts on ‘small-world’ networks: The phase transition from a lattice network with large average distances to a small-world network with small distances takes place in a range where small clusters cannot recognize it happening locally. </p>
<p>
Thus, if our scaling carried the intuitive picture of an isolated city, it would miss the expanding sphere of relations. At the opposite extreme would be taking the union of Monaco and central Venice, which sum to 100,000 people who fan out mightily. There is also the argument that while small-world networks are held tight by “<a href="https://sociology.stanford.edu/sites/g/files/sbiybj9501/f/publications/the_strength_of_weak_ties_and_exch_w-gans.pdf">weak ties</a>,” the shared knowledge of misery is something that most tends to strengthen ties. And of course, our point about relations extends to many other activities impacted by the pandemic.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What should govern the appropriateness of scaling down?</p>
<p>
It should be noted that if we scale down the US to 100,000 people, the numbers are appreciably higher:</p>
<ul>
<li>
34.5 million total cases become <b>10,366</b>. <p/>
</li><li>
4,928,564 active cases become <b>1,480</b>. <p/>
</li><li>
620,000 total deaths become <b>186</b> deaths. <p/>
</li><li>
3,833 currently listed in critical or serious condition still become <b>exactly one</b>.
</li></ul></font></font></div>
    </content>
    <updated>2021-06-29T23:09:46Z</updated>
    <published>2021-06-29T23:09:46Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Aiyana Green"/>
    <category term="coronavirus"/>
    <category term="mathematical writing"/>
    <category term="New York Times"/>
    <category term="pandemic"/>
    <category term="scaling"/>
    <category term="Steven Strogatz"/>
    <category term="Terence Tao"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-07-02T19:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=2420</id>
    <link href="https://theorydish.blog/2021/06/29/trace-reconstruction/" rel="alternate" type="text/html"/>
    <title>Trace Reconstruction from Complex Analysis</title>
    <summary>Suppose that is an unknown binary string of length . We are asked to recover from its traces, and each trace is a random subsequence obtained by deleting the bits of independently with probability . More formally, let denote the distribution of traces obtained from string . For example, when , assigns a probability mass of to each element in the multiset We then ask: what is the smallest number such that we can recover any (say, with probability ) given independent samples from ? This trace reconstruction problem was first formulated by Batu-Kannan-Khanna-McGregor in 2004, and their central motivation is from the multiple sequence alignment problem in computational biology. Trace reconstruction is also a fundamental problem related to the deletion channel in communication theory: We view the hidden string as the transmitted message, and each trace as a received message that went through a deletion channel, which drops each bit with probability . Then the sample complexity tells us the number of independent copies that need to be sent for the receiver to determine the original message. Despite being a natural problem, trace reconstruction is still far from being well-understood, even from the information-theoretic perspective (i.e., without considering the [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Suppose that <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an unknown binary string of length <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We are asked to recover <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from its <em>traces</em>, and each <em>trace</em> <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a random subsequence obtained by deleting the bits of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> independently with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>More formally, let <img alt="\mathcal{D}_s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> denote the distribution of traces obtained from string <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. For example, when <img alt="s = 110" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+110&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="\mathcal{D}_s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> assigns a probability mass of <img alt="1/8" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F8&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to each element in the multiset<br/></p>



<p class="has-text-align-center"><img alt="\{\text{empty}, 1, 1, 0, 11, 10, 10, 110\}." class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7Bempty%7D%2C+1%2C+1%2C+0%2C+11%2C+10%2C+10%2C+110%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/></p>



<p>We then ask: what is the smallest number <img alt="M(n)" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that we can recover any <img alt="s \in \{0, 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (say, with probability <img alt="\ge 0.99" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+0.99&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) given <img alt="M(n)" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> independent samples from <img alt="\mathcal{D}_s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>?</p>



<p>This <em>trace reconstruction</em> problem was first formulated by <a href="https://people.cs.umass.edu/~mcgregor/papers/04-soda.pdf" rel="noreferrer noopener" target="_blank">Batu-Kannan-Khanna-McGregor</a> in 2004, and their central motivation is from the <a href="https://en.wikipedia.org/wiki/Multiple_sequence_alignment" rel="noreferrer noopener" target="_blank">multiple sequence alignment</a> problem in computational biology. Trace reconstruction is also a fundamental problem related to the <a href="https://en.wikipedia.org/wiki/Deletion_channel" rel="noreferrer noopener" target="_blank">deletion channel</a> in communication theory: We view the hidden string as the transmitted message, and each trace as a received message that went through a deletion channel, which drops each bit with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then the sample complexity <img alt="M(n)" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> tells us the number of independent copies that need to be sent for the receiver to determine the original message.</p>



<p>Despite being a natural problem, trace reconstruction is still far from being well-understood, even from the information-theoretic perspective (i.e., without considering the computational complexity). In 2017, <a href="https://arxiv.org/pdf/1612.03148.pdf" rel="noreferrer noopener" target="_blank">De-O’Donnell-Servedio</a> and <a href="https://arxiv.org/pdf/1612.03599.pdf" rel="noreferrer noopener" target="_blank">Nazarov-Peres</a> independently proved <img alt="M(n) \le \exp(O(n^{1/3}))" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29+%5Cle+%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. A very recent breakthrough due to <a href="https://arxiv.org/pdf/2009.03296.pdf" rel="noreferrer noopener" target="_blank">Chase</a> further improved this bound to <img alt="\exp(\tilde O(n^{1/5}))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Ctilde+O%28n%5E%7B1%2F5%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is still super-polynomial. On the other hand, the best known sample complexity lower bound is merely <img alt="\tilde\Omega(n^{3/2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%5COmega%28n%5E%7B3%2F2%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, proved by <a href="https://arxiv.org/pdf/1905.03031.pdf" rel="noreferrer noopener" target="_blank">Chase</a> in another recent work.</p>



<p>In this blog post, I will explain why this problem is much more non-trivial than it might appear at first glance. I will also give an overview on the work of [DOS17, NP17], which, interestingly, reduces this seemingly combinatorial problem to complex analysis.</p>



<p><strong>Observation: reconstruction <img alt="\approx" class="latex" src="https://s0.wp.com/latex.php?latex=%5Capprox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> distinguishing <img alt="\approx" class="latex" src="https://s0.wp.com/latex.php?latex=%5Capprox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> TV-distance.</strong> Let us start with a natural first attempt at the problem. Define <img alt="\delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as the minimum statistical distance between the trace distribution of two different length-<img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> strings:<br/></p>



<p class="has-text-align-center"><img alt="\delta_n = \min_{x \ne y \in \{0, 1\}^n}d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta_n+%3D+%5Cmin_%7Bx+%5Cne+y+%5Cin+%5C%7B0%2C+1%5C%7D%5En%7Dd_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/></p>



<p>It is not hard to show that <img alt="1/\delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> bounds <img alt="M(n)" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on both sides, up to a polynomial factor:<br/></p>



<p class="has-text-align-center"><img alt="1/\delta_n \lesssim M(n) \lesssim n/\delta_n^2." class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cdelta_n+%5Clesssim+M%28n%29+%5Clesssim+n%2F%5Cdelta_n%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/></p>



<p class="has-black-color has-text-color">The lower bound holds because any trace reconstruction algorithm must be able to distinguish <img alt="s = x" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from <img alt="s = y" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for every pair of different strings <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and this requires <img alt="\Omega(1 / \delta_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%281+%2F+%5Cdelta_n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> samples for the minimizer <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the definition of <img alt="\delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. For the upper bound, we note that every pair <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be distinguished with an <img alt="o(2^{-n})" class="latex" src="https://s0.wp.com/latex.php?latex=o%282%5E%7B-n%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> error probability using <img alt="O(n/\delta_n^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%2F%5Cdelta_n%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> samples. We say that string <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> “beats” <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, if the distinguisher for <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> decides that “<img alt="s = x" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>“. By a union bound, the correct answer <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> “beats” every other string with high probability. We can then obtain a reconstruction algorithm by running the distinguisher for every string pair, and outputting the unique string that “beats” the other <img alt="2^n-1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En-1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> strings.</p>



<p>Thus, to determine whether the sample complexity <img alt="M(n)" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is polynomial in <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, it suffices to determine whether <img alt="\delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> scales as <img alt="1/\mathrm{poly}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or is much smaller. Unfortunately, it turns out to be highly non-trivial to bound <img alt="\delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and even bounding <img alt="d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y)" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for “simple” <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be hard. Imagine that we try to reason about the distribution <img alt="\mathcal{D}_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: the probability mass that <img alt="\mathcal{D}_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> assigns to string <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is proportional to the number of times that <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> appears as a subsequence in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, but this count is already hard to express or control, unless <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has a very simple pattern. This is roughly where this natural attempt gets stuck.</p>



<p><strong>Distinguishing using estimators.</strong> Now we turn to a different approach that underlies the recent breakthrough on trace reconstruction algorithms. As discussed earlier, we can focus on the problem of distinguishing the case <img alt="s = x" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from <img alt="s = y" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for fixed strings <img alt="x \ne y \in \{0, 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cne+y+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Let <img alt="f: \{0, 1\}^{\le n} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C+1%5C%7D%5E%7B%5Cle+n%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be a function defined over all possible traces from a length-<img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> string. We consider the following algorithm for distinguishing <img alt="\mathcal{D}_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from <img alt="\mathcal{D}_y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:<br/><br/><strong>Step 1.</strong> Given traces <img alt="\tilde s_1, \tilde s_2, \ldots" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s_1%2C+%5Ctilde+s_2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, compute the average of <img alt="f(\tilde s_1), f(\tilde s_2), \ldots" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s_1%29%2C+f%28%5Ctilde+s_2%29%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/><strong>Step 2.</strong> Output <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if the average is closer to <img alt="\mathbb{E}_{\tilde x \sim \mathcal{D}_x}[f(\tilde x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+x+%5Csim+%5Cmathcal%7BD%7D_x%7D%5Bf%28%5Ctilde+x%29%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> than to <img alt="\mathbb{E}_{\tilde y \sim \mathcal{D}_y}[f(\tilde y)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+y+%5Csim+%5Cmathcal%7BD%7D_y%7D%5Bf%28%5Ctilde+y%29%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and output <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> otherwise.<br/></p>



<p>For the above to succeed, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> needs to satisfy the following two conditions:<br/></p>



<p><strong>(Separation)</strong> <img alt="\mathcal{D}_x" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="\mathcal{D}_y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are well-separated under <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, namely <img alt="|\mathbb{E}[f(\tilde x)] - \mathbb{E}[f(\tilde y)]| \ge \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D%5Bf%28%5Ctilde+x%29%5D+-+%5Cmathbb%7BE%7D%5Bf%28%5Ctilde+y%29%5D%7C+%5Cge+%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for some <img alt="\epsilon &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.<br/><strong>(Boundedness)</strong> Expectation of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can be efficiently estimated. This can be guaranteed if for some <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="|f(\tilde s)| \le B" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cf%28%5Ctilde+s%29%7C+%5Cle+B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> holds for every <img alt="\tilde s \in \{0, 1\}^{\le n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s+%5Cin+%5C%7B0%2C+1%5C%7D%5E%7B%5Cle+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.<br/></p>



<p>Assuming the above, a standard concentration argument shows that we can distinguish <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> using <img alt="O((B/\epsilon)^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%28B%2F%5Cepsilon%29%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> samples, and thus <img alt="M(n) \lesssim n \cdot (B/\epsilon)^2" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29+%5Clesssim+n+%5Ccdot+%28B%2F%5Cepsilon%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>In principle, a near-optimal choice of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> would be setting <img alt="f(\tilde s)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be the indicator of <img alt="\mathcal{D}_x(\tilde s) \ge \mathcal{D}_y(\tilde s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x%28%5Ctilde+s%29+%5Cge+%5Cmathcal%7BD%7D_y%28%5Ctilde+s%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which gives boundedness <img alt="B = 1" class="latex" src="https://s0.wp.com/latex.php?latex=B+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and separation <img alt="\epsilon = d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y) \ge \delta_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+d_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29+%5Cge+%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. However, as argued above, this optimal choice of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can still be hard to analyze. Instead, we focus on choosing a simpler function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which potentially gives a suboptimal <img alt="B/\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=B%2F%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> but admits simple analyses.</p>



<p><strong>Sketch of the <img alt="\exp(O(n^{1/3}))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Upper Bound.</strong> The main results of [DOS17] and [NP17] follow from choosing <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be a linear function. Given a trace <img alt="\tilde s = \tilde s_0 \tilde s_1 \tilde s_2 \cdots" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s+%3D+%5Ctilde+s_0+%5Ctilde+s_1+%5Ctilde+s_2+%5Ccdots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we consider the following polynomial with coefficients being the bits of <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:<br/></p>



<p class="has-text-align-center"><img alt="\tilde S(z) = \sum_{k}\tilde s_k z^k = \tilde s_0 + \tilde s_1 z + \tilde s_2 z^2 + \cdots." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+S%28z%29+%3D+%5Csum_%7Bk%7D%5Ctilde+s_k+z%5Ek+%3D+%5Ctilde+s_0+%2B+%5Ctilde+s_1+z+%2B+%5Ctilde+s_2+z%5E2+%2B+%5Ccdots.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/></p>



<p>For some number <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be determined later, we consider the estimator <img alt="f(\tilde s) = \tilde S(z) = \tilde s_0 + \tilde s_1 z + \tilde s_2 z^2 + \cdots" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s%29+%3D+%5Ctilde+S%28z%29+%3D+%5Ctilde+s_0+%2B+%5Ctilde+s_1+z+%2B+%5Ctilde+s_2+z%5E2+%2B+%5Ccdots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is indeed a linear function in the trace <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>At first glance, it might be unclear why we choose the coefficients to be powers of <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The following fact justifies this choice by showing that polynomials interact with the deletion channel very nicely: The expectation of <img alt="\tilde S(z)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+S%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is exactly the evaluation of the polynomial <img alt="S(\cdot)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Ccdot%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with coefficients <img alt="s_0, s_1, \ldots, s_{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=s_0%2C+s_1%2C+%5Cldots%2C+s_%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, but at a slightly different point.<br/></p>



<p><strong>Fact:</strong> For any string <img alt="s \in \{0, 1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,<br/></p>



<p class="has-text-align-center"><img alt="\mathbb{E}_{\tilde s \sim \mathcal{D}_s}\left[\tilde S(z)\right] = \frac{1}{2}S\left(\frac{z+1}{2}\right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+s+%5Csim+%5Cmathcal%7BD%7D_s%7D%5Cleft%5B%5Ctilde+S%28z%29%5Cright%5D+%3D+%5Cfrac%7B1%7D%7B2%7DS%5Cleft%28%5Cfrac%7Bz%2B1%7D%7B2%7D%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/></p>



<p>Equivalently, we have <img alt="\mathbb{E}[\tilde S(2z-1)] = \frac{1}{2}S(z)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5B%5Ctilde+S%282z-1%29%5D+%3D+%5Cfrac%7B1%7D%7B2%7DS%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which allows us to rephrase our requirements on the choice of <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as follows:<br/></p>



<p><strong>(Separation)</strong> <img alt="|X(z) - Y(z)| \ge \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%7CX%28z%29+-+Y%28z%29%7C+%5Cge+%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for some <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is not too small.<br/><strong>(Boundedness)</strong> <img alt="|\tilde S(2z - 1)| \le B" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctilde+S%282z+-+1%29%7C+%5Cle+B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for all possible trace <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, for some <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is not too large.<br/></p>



<p>After some thought, it is beneficial to choose <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that both <img alt="|z|" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cz%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="|2z - 1|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C2z+-+1%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are close to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, since this ensures that different bits in the string are assigned weights of similar magnitudes in the polynomials above. These two conditions hold if and only if <img alt="z \approx 1" class="latex" src="https://s0.wp.com/latex.php?latex=z+%5Capprox+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2442" height="230" src="https://theorydish.files.wordpress.com/2021/06/plan.png?w=1024" width="512"/>The overall plan for distinguishing strings <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</figure></div>



<p>The crucial idea in both papers [DOS17, NP17] is to consider the polynomials in the complex plane <img alt="\mathbb{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> instead of on the real line. Fortunately, all the previous discussion still holds for complex numbers, with <img alt="|\cdot|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ccdot%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> interpreted as modulus instead of absolute value. In [NP17], the authors chose <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from a small arc of the unit circle:</p>



<p class="has-text-align-center"><img alt="A_L = \{e^{i\theta}: \theta\in[-\pi/L, \pi/L]\}" class="latex" src="https://s0.wp.com/latex.php?latex=A_L+%3D+%5C%7Be%5E%7Bi%5Ctheta%7D%3A+%5Ctheta%5Cin%5B-%5Cpi%2FL%2C+%5Cpi%2FL%5D%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2445" height="262" src="https://theorydish.files.wordpress.com/2021/06/a_l.png?w=622" width="311"/>Arc <img alt="A_L" class="latex" src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> marked by the red box and dotted lines.</figure></div>



<p>For every <img alt="z \in A_L" class="latex" src="https://s0.wp.com/latex.php?latex=z+%5Cin+A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, it is easy to upper bound <img alt="|\tilde S(2z - 1)|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ctilde+S%282z+-+1%29%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: it follows from simple calculus that <img alt="|2z - 1| \le 1 + O(L^{-2})" class="latex" src="https://s0.wp.com/latex.php?latex=%7C2z+-+1%7C+%5Cle+1+%2B+O%28L%5E%7B-2%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and thus for every <img alt="\tilde s" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:<br/></p>



<p class="has-text-align-center"><img alt="\left|\tilde S(2z-1)\right| \le \sum_{k=0}^{n-1}\left|(2z-1)^k\right| \le n \cdot \left[1 + O(L^{-2})\right]^n = e^{O(n/L^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctilde+S%282z-1%29%5Cright%7C+%5Cle+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D%5Cleft%7C%282z-1%29%5Ek%5Cright%7C+%5Cle+n+%5Ccdot+%5Cleft%5B1+%2B+O%28L%5E%7B-2%7D%29%5Cright%5D%5En+%3D+e%5E%7BO%28n%2FL%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>To lower bound <img alt="X(z) - Y(z)" class="latex" src="https://s0.wp.com/latex.php?latex=X%28z%29+-+Y%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, note that since both <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are binary, all the coefficients of <img alt="X-Y" class="latex" src="https://s0.wp.com/latex.php?latex=X-Y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are in <img alt="\{-1, 0, 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B-1%2C+0%2C+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Such polynomials are known as <em>Littlewood polynomials</em>. The separation condition is then reduced to the following claim in complex analysis:</p>



<p class="has-text-align-center"><em><strong>Littlewood polynomials cannot to be too “flat” over a short arc around 1.</strong></em></p>



<p>This is indeed the case:</p>



<p id="lemma-1"><strong>Lemma 1.</strong> (<a href="https://www.jstor.org/stable/pdf/24899666.pdf" rel="noreferrer noopener" target="_blank">[Borwein and Erdélyi, 1997]</a>) For every nonzero Littlewood polynomial <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,<br/></p>



<p class="has-text-align-center"><img alt="\max_{z \in A_L}|p(z)| \ge e^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C+%5Cge+e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.<br/></p>



<p>By <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a>, there exists <img alt="z \in A_L" class="latex" src="https://s0.wp.com/latex.php?latex=z+%5Cin+A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that the separation condition holds for <img alt="\epsilon = e^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Recall that the boundedness holds for <img alt="B = e^{O(n/L^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=B+%3D+e%5E%7BO%28n%2FL%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This shows that the sample complexity is upper bounded by <img alt="(B/\epsilon)^2 = \exp(O(n/L^2 + L))" class="latex" src="https://s0.wp.com/latex.php?latex=%28B%2F%5Cepsilon%29%5E2+%3D+%5Cexp%28O%28n%2FL%5E2+%2B+L%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is minimized at <img alt="L = n^{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=L+%3D+n%5E%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This proves the upper bound <img alt="M(n) = \exp(O(n^{1/3}))" class="latex" src="https://s0.wp.com/latex.php?latex=M%28n%29+%3D+%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p><strong>Proof of a weaker lemma.</strong> While the original proof of <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a> is a bit technical, [NP17] presented a beautiful and much simpler proof of the following weaker result, in which the <img alt="e^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> lower bound is replaced by <img alt="n^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the degree of the Littlewood polynomial.</p>



<p><strong>Lemma 2.</strong> ([Lemma 3.1, NP17]) For every nonzero Littlewood polynomial <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of degree <img alt="&lt; n" class="latex" src="https://s0.wp.com/latex.php?latex=%3C+n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,<br/></p>



<p class="has-text-align-center"><img alt="\max_{z \in A_L}|p(z)| \ge n^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C+%5Cge+n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.<br/></p>



<p><strong>Proof.</strong> Without loss of generality, we assume that the constant term of <img alt="p(z)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Suppose otherwise, that the lowest order term of <img alt="p(z)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="z^m" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Em&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for some <img alt="m \ge 1" class="latex" src="https://s0.wp.com/latex.php?latex=m+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We may consider the polynomial <img alt="p(z) / z^m" class="latex" src="https://s0.wp.com/latex.php?latex=p%28z%29+%2F+z%5Em&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> instead.</p>



<p>Let <img alt="M = \max_{z \in A_L}|p(z)|" class="latex" src="https://s0.wp.com/latex.php?latex=M+%3D+%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be the maximum modulus of <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> over arc <img alt="A_L" class="latex" src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="\omega = e^{2\pi i/L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega+%3D+e%5E%7B2%5Cpi+i%2FL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be an <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-th root of unity. Consider the following polynomial:<br/></p>



<p class="has-text-align-center"><img alt="q(z) = \prod_{j=0}^{L-1}p(\omega^j z) = p(z) \cdot p(\omega z) \cdot \cdots \cdot p(\omega^{L-1} z)" class="latex" src="https://s0.wp.com/latex.php?latex=q%28z%29+%3D+%5Cprod_%7Bj%3D0%7D%5E%7BL-1%7Dp%28%5Comega%5Ej+z%29+%3D+p%28z%29+%5Ccdot+p%28%5Comega+z%29+%5Ccdot+%5Ccdots+%5Ccdot+p%28%5Comega%5E%7BL-1%7D+z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>For every <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on the unit circle, at least one point <img alt="\omega^j z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5Ej+z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> falls into the arc <img alt="A_L" class="latex" src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so that <img alt="|p(\omega^j z)| \le M" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cp%28%5Comega%5Ej+z%29%7C+%5Cle+M&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. (See <a href="https://theorydish.blog/feed/#windmill">figure below</a> for a proof by picture.) The moduli of the remaining <img alt="L - 1" class="latex" src="https://s0.wp.com/latex.php?latex=L+-+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> factors are trivially bounded by <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus, <img alt="|q(z)| \le M\cdot n^{L-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cq%28z%29%7C+%5Cle+M%5Ccdot+n%5E%7BL-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>



<p>On the other hand, we note <img alt="q(0) = [p(0)]^L = 1" class="latex" src="https://s0.wp.com/latex.php?latex=q%280%29+%3D+%5Bp%280%29%5D%5EL+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The <a href="https://en.wikipedia.org/wiki/Maximum_modulus_principle" rel="noreferrer noopener" target="_blank">maximum modulus principle</a> implies that for some <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on the unit circle, we have <img alt="|q(z)| \ge 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cq%28z%29%7C+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Therefore, we must have <img alt="M \cdot n^{L - 1} \ge 1" class="latex" src="https://s0.wp.com/latex.php?latex=M+%5Ccdot+n%5E%7BL+-+1%7D+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which implies <img alt="M \ge n^{-(L - 1)} = n^{-O(L)}" class="latex" src="https://s0.wp.com/latex.php?latex=M+%5Cge+n%5E%7B-%28L+-+1%29%7D+%3D+n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and completes the proof. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>



<div class="wp-block-image" id="windmill"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2449" height="261" src="https://theorydish.files.wordpress.com/2021/06/example.png?w=924" width="462"/>Points involved in the definition of <img alt="q(z)" class="latex" src="https://s0.wp.com/latex.php?latex=q%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for <img alt="L=4" class="latex" src="https://s0.wp.com/latex.php?latex=L%3D4&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.<br/>In this case, <img alt="\omega^3 z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Comega%5E3+z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is inside arc <img alt="A_L" class="latex" src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is marked by the red lines.</figure></div>



<p><strong>Beyond linear estimators?</strong> The work of [DOS17, NP17] not only proved the <img alt="\exp(O(n^{1/3}))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> upper bound, but also showed that this is the best sample complexity we can get from linear estimator <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The recent work of [Cha20] goes beyond these linear estimators by taking the higher moments of the trace into account. The idea turns out to be a natural one: consider the “<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-grams” (i.e., length-<img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> substrings) of the string for some <img alt="k &gt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=k+%3E+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. In more detail, we fix some string <img alt="w \in \{0, 1\}^k" class="latex" src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5C%7B0%2C+1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and consider the binary polynomial with coefficients corresponding to the positions at which <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> appears as a (contiguous) substring. The key observation is that there exists a choice of <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that the resulting polynomial is sparse (in the sense that the degrees of the nonzero monomials are far away). The technical part of [Cha20] is then devoted to proving an analogue of <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a> that is specialized to these “sparse” Littlewood polynomials.</p>



<p><strong>Acknowledgments.</strong> I would like to thank Moses Charikar, Li-Yang Tan and Gregory Valiant for being on my quals committee and for helpful discussions about this problem.</p></div>
    </content>
    <updated>2021-06-29T16:20:49Z</updated>
    <published>2021-06-29T16:20:49Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Mingda Qiao</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2021-07-02T19:21:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/06/29/greedy-orderings-transposition</id>
    <link href="https://11011110.github.io/blog/2021/06/29/greedy-orderings-transposition.html" rel="alternate" type="text/html"/>
    <title>Greedy orderings with transposition</title>
    <summary>I’m a big fan of using antimatroids to model vertex-ordering processes in graphs such as the construction of topological orderings in directed acyclic graphs and perfect elimination orderings in chordal graphs. In each case a vertex can be removed from the graph and added to the order when it obeys a local condition: its remaining neighbors are all outgoing for topological orderings, or all adjacent for perfect elimination orderings. Once this condition becomes true of a vertex it remains true until the vertex is added to the order, the defining property of an antimatroid. Because of this property, a greedy algorithm for finding these orderings can never make a mistake: if there exists an ordering of all of the vertices, it is always a safe choice to add any vertex that can be added.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m a big fan of using <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroids</a> to model vertex-ordering processes in graphs such as the construction of <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological orderings</a> in <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graphs</a> and perfect elimination orderings in <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a>. In each case a vertex can be removed from the graph and added to the order when it obeys a local condition: its remaining neighbors are all outgoing for topological orderings, or all adjacent for perfect elimination orderings. Once this condition becomes true of a vertex it remains true until the vertex is added to the order, the defining property of an antimatroid. Because of this property, a greedy algorithm for finding these orderings can never make a mistake: if there exists an ordering of all of the vertices, it is always a safe choice to add any vertex that can be added.</p>

<p>But there are some greedy vertex-ordering processes that do not form antimatroids, even though they do have the same inability to make mistakes. Two of these are the dismantling orders of <a href="https://en.wikipedia.org/wiki/Cop-win_graph">cop-win graphs</a> and the reverse construction orders of <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a>. I wrote about cop-win graphs <a href="https://11011110.github.io/blog/2016/08/18/game-of-cop.html">here in 2016</a>; a graph is cop-win if a cop can always land on the same vertex as a robber when they take turns either moving from a vertex to a neighboring vertex or staying put. In distance-hereditary graphs, all induced subgraphs have the same distances; <a href="https://11011110.github.io/blog/2005/10/11/delta-confluent-drawing-paper.html">these graphs also have nice confluent drawings</a>. Both of these classes of graphs can be recognized by greedy algorithms that remove one vertex at a time until either getting stuck (for graphs not in the class) or succeeding by reaching a single-vertex graph. But although the conditions for removing vertices in these algorithms are local, they are not antimatroidal.</p>

<h1 id="an-example-graph">An example graph</h1>

<p style="text-align: center;"><img alt="A six-vertex graph with six vertices A, B, C, D, E, and F, and seven edges AD, BC, BD, BE, CE, and EF" src="https://11011110.github.io/blog/assets/2021/Ptolemaic.svg"/></p>

<p>The graph shown above happens to be chordal, distance-hereditary, and cop-win, making it a convenient example both of how to order the vertices of these graph classes and of why the distance-hereditary and cop-win orderings are not antimatroidal.</p>

<ul>
  <li>
    <p>In chordal graphs, a perfect elimination ordering can be constructed by repeatedly removing <em>simplicial vertices</em>, vertices whose neighborhoods form a clique. For an elimination ordering of the example graph, vertices \(A\), \(C\), and \(F\) are already available to be listed: \(A\) and \(F\) only have one neighbor (automatically a clique), and \(C\) has two neighbors forming a two-vertex clique. The other vertices will become available later in the removal process, once enough of their neighbors have been removed and all remaining vertices become adjacent. For instance, once \(A\) has been removed, \(D\) will become available, and once \(C\) has been removed, \(B\) will become available. Once this removal process makes a vertex simplicial, it remains simplicial until removed, so elimination orderings form an antimatroid.</p>
  </li>
  <li>
    <p>Distance-hereditary graphs can be constructed from a single vertex by repeatedly adding leaf vertices (with one neighbor connecting to previous vertices) or twins (duplicates of previous vertices). Reversing this process, these graphs can be deconstructed by repeatedly removing leaves or twins. The graph above has no twins, but \(A\) and \(F\) are leaves, and can be removed immediately. If \(A\) is removed, \(C\) and \(D\) become false twins (not adjacent to each other), and either of them can be removed. Similarly, if \(F\) is removed, \(B\) and \(E\) become true twins (adjacent to each other), after which one can be removed, but not both: after removing \(F\) and \(B\), \(E\) is no longer a leaf or a twin (because its twin, \(B\), has gone), and must remain until later steps. Because the removal orders can start \(FB\) or \(FE\) but not \(FBE\), they are not described by an antimatroid.</p>
  </li>
  <li>
    <p>Similarly, cop-win graphs can be dismantled by repeatedly removing a vertex \(v\) that is dominated by another vertex \(w\), meaning that the neighborhood of \(v\) (including \(v\) itself) is a subset of the neighborhoood of \(w\). In the given graph, \(A\) is dominated by \(D\), \(B\) is dominated by \(E\), \(C\) is dominated by both \(B\) and \(E\), and \(F\) is dominated by \(E\). So any one of these four dominated vertices starts out as removable. But if we remove first \(F\) and then \(E\) (dominated by \(B\) after the removal of \(F\)) we can no longer remove \(B\). So because the ability to be removed can go away before the removal happens, we do not have an antimatroid.</p>
  </li>
</ul>

<p>There’s another complication here as well. For both distance-hereditary graphs and cop-win graphs, removing leaves and twins or dominated vertices will never eliminate all graph vertices. Instead, both removal processes stop when we reach a single remaining vertex. But this is different from antimatroids, where all elements must be included in all orderings.</p>

<h1 id="some-axiomatics">Some axiomatics</h1>

<p>To understand why greedy orderings still work in these cases, I think it’s helpful to start by understanding why they work for antimatroids, as a general class of structures. The following is not quite the usual system of axioms for antimatroids, but they can be defined as non-empty formal languages (that is, sets of strings over a finite alphabet) with the following properties:</p>

<dl>
  <dt>Hereditary:</dt>
  <dd>
    <p>Every prefix of a string in the language is also in the language. Thinking about this in the other direction: every string in the language can be built up by adding one character at a time, starting from the empty string, at all times remaining within the language.</p>
  </dd>
  <dt>Normal:</dt>
  <dd>
    <p>Every character occurs at most once in any string in the language. An element can only be added to the sequence of elements once. Because we are assuming the alphabet to be finite, this means that the language itself is also finite.</p>
  </dd>
  <dt>Oblivious:</dt>
  <dd>
    <p>If \(S\) and \(T\) are permutations of each other in the language, then for every character \(x\), \(Sx\) is in the language if and only if \(Tx\) is in the language. This means that what can be added next depends only on the set of characters that have been added already, forgetting about the order in which they were added.</p>
  </dd>
  <dt>Anti-exchange:</dt>
  <dd>
    <p>If \(S\) is a string, \(x\) and \(y\) are different characters, and \(Sx\) and \(Sy\) both belong to the language, then so does \(Sxy\). Adding \(x\) doesn’t prevent \(y\) from being added later. This is the key property of an antimatroid and the one that is violated by the distance-hereditary and cop-win orderings.</p>
  </dd>
</dl>

<p>Usually a stronger version of obliviousness is used, stating that when \(S\) and a permutation of \(Sx\) are in the language, then \(Sx\) is in the language, but it’s not immediately obvious why this should be true for the vertex-ordering processes I’m considering here, so I’ve gone with a weaker version. We’ll see later that the stronger version is implied by a combination of this and other properties. It is standard to also require that all characters be usable, but I haven’t done this, because I want to understand the behavior of antimatroidal greedy algorithms on graphs not in the given graph class, for which they get stuck before ordering the whole graph. But this is not important, because one could instead redefine the alphabet to consist only of usable characters.</p>

<p>Given a language that satisfies all of these properties, one can show that all non-extendable strings are equally long and use the same alphabet as each other. For, if we have two different non-extendable strings \(S\) and \(T\), we can morph \(S\) into \(T\) one step at a time, never shortening it or changing its character set, by finding the first position at which \(S\) and \(T\) differ, finding the character \(t\) that \(T\) has at that position (necessarily also used later in \(S\) because it was usable at that position and would have remained usable until it was used), and repeatedly using the anti-exchange axiom to swap \(t\) for the previous character in \(S\) until it has been swapped into a match with \(T\). The oblivious property ensures that the part of the string after the swap remains valid. So \(S\) cannot be shorter than or miss any characters from \(T\), nor vice versa.</p>

<p>Instead of the anti-exchange axiom, the distance-hereditary and cop-win orderings satisfy a weaker property, based on the notion of swapping two characters.</p>

<dl>
  <dt>Transposition:</dt>
  <dd>
    <p>Suppose \(S\) is a string, \(x\) and \(y\) are different characters, and \(Sx\) and \(Sy\) both belong to the language, but \(Sxy\) does not. Then for all \(T\) not containing \(x\) or \(y\), \(SxT\) is in the language if and only if \(SyT\) is also in the language, and \(SxTy\) is in the language if and only if \(SyTx\) is also in the language.</p>
  </dd>
</dl>

<p>The last part of the transposition property, about \(SxTy\) and \(SyTx\), is only included because we used a weak version of obliviousness; if we used the stronger version, it would follow from the earlier part of the transposition property.</p>

<h1 id="cop-win-and-distance-hereditary-orderings-have-the-transposition-property">Cop-win and distance-hereditary orderings have the transposition property</h1>

<p>Let’s suppose we’re trying to dismantle a cop-win graph by repeatedly removing dominated vertices, in the hope of getting down to a single vertex. After we’ve removed some vertices already in a sequence \(S\), two vertices \(x\) and \(y\) might become included in the set of dominated vertices. This can happen in several different ways:</p>

<ul>
  <li>It might be the case that \(x\) is dominated by a vertex that is not \(y\), and that \(y\) is dominated by a vertex that is not \(x\). When this happens, they can be removed in either order: removing one won’t change the fact that the other is dominated by whatever other vertex dominated it already.</li>
  <li>It might be the case that \(x\) is dominated by \(y\), and \(y\) is dominated by a third vertex \(z\). But then \(x\) is also dominated by \(z\), and again they can be removed in either order. When one is removed, the other is still dominated by \(z\).</li>
  <li>The only remaining case is that \(x\) and \(y\) are each dominated only by the other of these two vertices. In this case, we can remove one or the other but not both. But if \(x\) and \(y\) dominate each other, they have the same neighbors (they are twins), and there is a symmetry of the remaining subgraph swapping \(x\) and \(y\). So in this case, any continuation of the removal sequence \(S\) can have \(x\) replaced by \(y\) and vice versa, and still be a valid continuation. This is exactly what the transposition property states.</li>
</ul>

<p>The argument for distance-hereditary orderings is even easier. If \(x\) and \(y\) are not twins of each other, then removing one won’t affect the removability of the other. If they are twins, then they are symmetric and any continuation of the removal sequence can exchange \(x\) for \(y\) without changing its validity.</p>

<h1 id="orderings-with-transposition-form-greedoids">Orderings with transposition form greedoids</h1>

<p>If we can’t obtain an antimatroid from the cop-win or distance-hereditary graphs, we might at least hope for a more general structure, a greedoid. The key property of greedoids (viewed as hereditary normal languages rather than their usual definition as set systems) is the following axiom:</p>

<dl>
  <dt>Exchange:</dt>
  <dd>If \(S\) is a longer string in the language of a greedoid, and \(T\) is a longer string in the same language, then there is a character \(x\) in \(T\) such that \(Sx\) is a string in the language.</dd>
</dl>

<p>This implies that all maximal strings in the language have the same length, and in the cop-win and distance-hereditary cases it implies that all greedy dismantling or deconstruction sequences reach a single vertex without getting stuck along the way. The greedoid exchange property also immediately implies the strong version of the obliviousness property, by plugging in a permutation of \(Sx\) as the string \(T\) in the exchange property.</p>

<p>To prove that indistinguishability implies the exchange property, let \(S\) be any string in an indistinguishable (hereditary normal oblivious) language, and let \(T\) be a longer string, which we might as well assume to be maximal. If \(S\) is a prefix of \(T\), then obviously we can satisfy the exchange property: just take the prefix of \(T\) that has one more character.</p>

<p>Otherwise, I claim that we can replace \(T\) by a different string \(T'\) of the same length that agrees with \(S\) for more positions. To find \(T'\), let \(y\) be the first character of \(S\) that differs from the corresponding character of \(T\); this must exist by the assumption that \(S\) is not a prefix of \(T\). Obviously, at the position of \(y\) in \(S\), we could have added it to \(T\), but instead some other character was chosen. Maybe, \(y\) remained available to be chosen throughout the remaining positions of \(T\), until it actually was chosen. If so, just as in the antimatroid case, we could repeatedly swap \(y\) with its predecessor in \(T\) until reaching a string \(T'\) where \(y\) is in the correct position. Alternatively, maybe at some point during the construction of sequence \(T\), we chose a character \(z\) causing \(y\) to become unavailable. In this case, by the transposition property, we can swap \(y\) for \(z\) in \(T\) and then as before repeatedly swap \(y\) with its predecessor in \(T\) until reaching a string \(T'\) where \(y\) is in the correct position.</p>

<p>By repeatedly replacing \(T\) by equally long strings that agree with more and more positions of \(S\), we eventually reach a string for which \(S\) is a prefix, and can append one more character. This construction of \(T'\) from \(T\) does not include any new characters that weren’t already in \(S\) or \(T\), so the appended character must have come from \(T\), proving the exchange axiom.</p>

<p>The use of the transposition property to form greedoids is standard; these greedoids are called transposition greedoids, and are described e.g. by Björner and Ziegler in their introduction to greedoids in the book <em>Matroid Applications</em>. Another <a href="https://doi.org/10.1007/978-3-642-58191-5_10">book chapter on transposition greedoids</a>, in the book <em>Greedoids</em> by Korte, Schrader, and Lovász, includes another graph-theoretic example where the elements are edges of series-parallel graphs. The part that appears to be less standard is the use of this property to explain the ability of greedy algorithms to recognize cop-win and distance-hereditary graphs. I looked, but was unable to find publications observing that these two classes of graphs lead to greedoids or transposition greedoids, despite some suspiciously-similar terminology (“twins”, “dismantling”) on both sides. If anyone knows of such publications, I’d appreciate hearing of them, so that I could add this connection to their Wikipedia articles.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106495619434427598">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-06-29T12:02:00Z</updated>
    <published>2021-06-29T12:02:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-06-30T17:39:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/091" rel="alternate" type="text/html"/>
    <title>TR21-091 |  Expander Random Walks: The General Case and Limitations | 

	Gil Cohen, 

	Dor Minzer, 

	Shir Peleg, 

	Aaron Potechin, 

	Amnon Ta-Shma</title>
    <summary>Cohen, Peri and Ta-Shma (STOC'21) considered the following question: Assume the vertices of an expander graph are labelled by $\pm 1$. What "test" functions $f : \{\pm 1\}^t \to \{\pm1 \}$ can or cannot distinguish $t$ independent samples from those obtained by a random walk? [CPTS'21] considered only balanced labelling, and proved that all symmetric functions are fooled by random walks on expanders with constant spectral gap. Furthermore, it was shown that functions computable by $\mathbf{AC}^0$ circuits are fooled by expanders with vanishing spectral expansion. 

We continue the study of this question and, in particular, resolve all open problems raised by [CPTS'21]. First, we generalize the result to all labelling, not merely balanced. In doing so, we improve the known bound for symmetric functions and prove that the bound we obtain is optimal (up to a multiplicative constant). Furthermore, we prove that a random walk on expanders with constant spectral gap does not fool $\mathbf{AC}^0$. In fact, we prove that the bound obtained by [CPTS'21] for $\mathbf{AC}^0$ circuits is optimal up to a polynomial factor.</summary>
    <updated>2021-06-29T07:19:40Z</updated>
    <published>2021-06-29T07:19:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5479161699112157490</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5479161699112157490/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/someone-thinks-i-am-fine-artist-why.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5479161699112157490" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5479161699112157490" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/someone-thinks-i-am-fine-artist-why.html" rel="alternate" type="text/html"/>
    <title>Someone thinks I am a fine artist! Why?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A while back I got an  email asking me to submit to a Fine Arts Journal. Why me? Here are some possibilities:</p><p>1) They were impressed with my play: </p><p><b>Sure he created the universe, but would he get Tenure?</b> (see <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/god.html">here</a>) which did get into a play-writing contest and was performed (one of the actresses  scolded me since I took a slot from <i>a real</i> <i>playwrigh</i>t).</p><p>2) They were impressed  with my <b>Daria Fan Fiction</b> (see the four entries <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/mywritings.html">here</a> labelled as Daria Fan Fiction).</p><p>3) They were impressed with my play <b>JFK: The Final chapter</b> (see <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/jfk.html">here</a>). Unlikely since this was rejected by a play writing contest and is not well known (as opposed to my other works in the fine arts which are well known?)</p><p>4) They were impressed with my collection of satires of  Nobel Laureate Bob Dylan (<a href="https://www.cs.umd.edu/users/gasarch/dylan/dylan.html">here</a>) .</p><p>5) They were impressed with some subset of (a) complexityblog, (b) <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279729/ref=sr_1_3?dchild=1&amp;keywords=gasarch&amp;qid=1609867944&amp;sr=8-3" target="_blank">Problems with a Point</a>,  (c)  <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics/dp/9811215979/ref=sr_1_2?dchild=1&amp;keywords=gasarch&amp;qid=1609868018&amp;sr=8-2">Mathematical Muffin Morsels</a>, and (d) <a href="https://www.amazon.com/Bounded-Queries-Recursion-Progress-Computer-ebook/dp/B000W98WU4/ref=sr_1_4?dchild=1&amp;keywords=gasarch&amp;qid=1609868084&amp;sr=8-4">Bounded Queries in Recursion Theory</a>. Or maybe just having 3 books on amazon is their threshold.  If it's complexityblog then Lance and I should co-author something for them.</p><p>6) It is a vanity-journal where you pay to  publish. So why email me who (a)  is not an artist, (b) is  not a fine artist, and most important (3) <b>does not think of himself as a fine artist</b>. The PRO of emailing me or people like me is they cast a wide net. The CON is--- there is no CON! It costs nothing to email me, and emailing me does not affect their credibility. That still raises the question of how they got my name.</p><p>7) Could it be a phishing? If I click on something in the email would they  get my credit card number? Their email begins <i>Dear Professor</i> not  <i>Dear Professor Gasarch. </i>  So they know I am a professor. Then again, I have known of ugrads who get emails that begin <i>Dear Professor</i>. (The emails to HS student Naveen and ugrad Nichole in the story I tell <a href="https://blog.computationalcomplexity.org/search?q=Naveen">here</a> were addressed to <i>Dear Professor.) </i></p><p>8) They mistook me for my parents who, in 1973,  put together an anthology of short stories titled <i>Fiction:The Universal elements</i>,  for a Freshman Comp course my mom taught, see <a href="https://www.amazon.com/Fiction-Universal-Element-P-Gasarch/dp/0442226322">here</a>. I note that their book ranks around 18,000,000, so even that explanation is unlikely. Actually the rank changes a lot- it was 12,000,000 this morning. Still, not what one would call a best seller. It's fun to see what is doing better: <i>Bounded Queries in Recursion Theory (currently at around rank 6.000.000) </i> or <i>Fiction: The Universal Elements.</i></p><p> If I ever get one of these emails from a History Journal I will submit my Satirical <i>Ramsey Theory and the History of Pre-Christian England: An Example of Interdisciplinary Research</i> (see <a href="https://www.cs.umd.edu/~gasarch/COURSES/389/W14/ramseykings.pdf">here</a>) just to see what happens- but  I will stop short of paying-to-publish. Or maybe I will pay-to-publish so that the next time I try to fool a class with it I can point to a seemingly real journal which has the article. </p><p><br/></p><div class="gE iv gt" style="background-color: white; color: #222222; cursor: auto; font-family: Roboto, RobotoDraft, Helvetica, Arial, sans-serif; font-size: 0.875rem; padding: 20px 0px 0px;"><table cellpadding="0" class="cf gJ"><tbody style="display: block;"><tr class="acZ" style="display: flex; height: auto;"><td class="gF gK" style="display: block; line-height: 20px; margin: 0px; padding: 0px; vertical-align: top; white-space: nowrap; width: 571.172px;"><br/></td></tr></tbody></table></div></div>
    </content>
    <updated>2021-06-28T03:00:00Z</updated>
    <published>2021-06-28T03:00:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-07-02T15:22:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/090" rel="alternate" type="text/html"/>
    <title>TR21-090 |  On Secret Sharing, Randomness, and Random-less Reductions for Secret Sharing | 

	Divesh Aggarwal, 

	Maciej Obremski, 

	Eldon Chung, 

	Joao Ribeiro</title>
    <summary>Secret-sharing is one of the most basic and oldest primitives in cryptography, introduced by Shamir and Blakely in the 70s. It allows to strike a meaningful balance between availability and confidentiality of secret information. It has a host of applications most notably in threshold cryptography and multi-party computation. All known constructions of secret sharing (with the exception of those with a pathological choice of parameters) require access to uniform randomness. In practice, it is extremely challenging to generate a source of uniform randomness. This has led to a large body of research devoted to designing randomized algorithms and cryptographic primitives from imperfect sources of randomness.

Motivated by this, 15 years ago, Bosley and Dodis asked whether it is even possible to build 2-out-of-2 secret sharing without access to uniform randomness. In this work, we make progress towards resolving this question.

We answer this question for secret sharing schemes with important additional properties, i.e., either leakage-resilience or non-malleability. We prove that, unfortunately, for not too small secrets, it is impossible to construct any of 2-out-of-2 leakage-resilient secret sharing or 2-out-of-2 non-malleable secret sharing without access to uniform randomness.

Given that the problem whether 2-out-of-2 secret sharing requires uniform randomness has been open for a long time, it is reasonable to consider intermediate problems towards resolving the open question. In a spirit similar to NP-completeness, we study how the existence of a t-out-of-n secret sharing without access to uniform randomness is related to the existence of a t'-out-of-n' secret sharing without access to uniform randomness for a different choice of the parameters t,n,t',n'.</summary>
    <updated>2021-06-27T05:51:49Z</updated>
    <published>2021-06-27T05:51:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/089</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/089" rel="alternate" type="text/html"/>
    <title>TR21-089 |  A Relativization Perspective on Meta-Complexity | 

	Rahul Santhanam, 

	Hanlin Ren</title>
    <summary>Meta-complexity studies the complexity of computational problems about complexity theory, such as the Minimum Circuit Size Problem (MCSP) and its variants. We show that a relativization barrier applies to many important open questions in meta-complexity. We give relativized worlds where:

* MCSP can be solved in deterministic polynomial time, but the search version of MCSP cannot be solved in deterministic polynomial time, even approximately. In contrast, Carmosino, Impagliazzo, Kabanets, Kolokolova [CCC'16] gave a randomized approximate search-to-decision reduction for MCSP with a relativizing proof.

* The complexities of MCSP[2^{n/2}] and MCSP[2^{n/4}] are different, in both worst-case and average-case settings. Thus the complexity of MCSP is not "robust" to the choice of the size function.

* Levin's time-bounded Kolmogorov complexity Kt(x) can be approximated to a factor (2+epsilon) in polynomial time, for any epsilon &gt; 0.

* Natural proofs do not exist, and neither do auxiliary-input one-way functions. In contrast, Santhanam [ITCS'20] gave a relativizing proof that the non-existence of natural proofs implies the existence of one-way functions under a conjecture about optimal hitting sets.

* DistNP does not reduce to GapMINKT by a family of "robust" reductions. This presents a technical barrier for solving a question of Hirahara [FOCS'20].</summary>
    <updated>2021-06-25T15:28:02Z</updated>
    <published>2021-06-25T15:28:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8156</id>
    <link href="https://windowsontheory.org/2021/06/25/stoc-feedback-and-tcs-wikipedia-guest-post-by-clement-canonne/" rel="alternate" type="text/html"/>
    <title>STOC feedback and TCS Wikipedia (guest post by Clément Canonne )</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The 53rd Annual ACM Symposium on Theory of Computing (STOC’21) concludes today, after 5 days of action-packed, Gather-power talks, workshops, plenary talks, and posters. A huge thank you to all volunteers, organizers, speakers, and attendees, who helped make this virtual conference a success! We would like to ask for your feedback on the conference. Whether … <a class="more-link" href="https://windowsontheory.org/2021/06/25/stoc-feedback-and-tcs-wikipedia-guest-post-by-clement-canonne/">Continue reading <span class="screen-reader-text">STOC feedback and TCS Wikipedia (guest post by Clément Canonne )</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 53rd Annual ACM <a href="http://acm-stoc.org/stoc2021/">Symposium on Theory of  Computing </a> (STOC’21) concludes today, after 5 days of action-packed, Gather-power talks, workshops, plenary talks, and posters. A huge thank you to all volunteers, organizers, speakers, and attendees, who helped make this virtual conference a success!</p>



<p>We would like to ask for your feedback on the conference. Whether you attended this virtual edition of STOC or not, please fill <a href="https://forms.gle/r1A4zCS6umbhZTrMA">this form </a> to help us make future TheoryFests even better!</p>



<p>Moreover, as part of one of the STOC social event (and in line with initiatives in 2017 by Shuchi Chawla and the <a href="https://thmatters.wordpress.com/2019/06/11/wikipedia-edit-a-thon-at-stoc19/">Edit-a-Thon from STOC 2019</a> , a spreadsheet aiming to crowdsource which TCS Wikipedia pages need improvement/creation has been set up:<br/><a href="https://docs.google.com/spreadsheets/d/1ZswaweUvsjVHnItMBnIxaiBZxcs-gEaUoODFoH4FGms/edit" rel="noreferrer noopener" target="_blank">https://docs.google.com/spreadsheets/d/1ZswaweUvsjVHnItMBnIxaiBZxcs-gEaUoODFoH4FGms/edit</a>. </p>



<p>Feel free to use or edit it in view of improving the TCS coverage in Wikipedia.</p>



<p>Clément Canonne (on behalf of the STOC and TheoryFest organizers)</p></div>
    </content>
    <updated>2021-06-25T14:38:34Z</updated>
    <published>2021-06-25T14:38:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-07-02T19:21:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/06/25/postdoc-at-uc-san-diego-apply-by-july-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/06/25/postdoc-at-uc-san-diego-apply-by-july-1-2021/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by July 30, 2021)</title>
    <summary>The UCSD CSE Fellows Program is intended to support exceptional postdoctoral researchers in computer science. The program seeks to recruit 1-3 fellows a year for a two year postdoctoral appointment working alongside a UCSD CSE faculty mentor. Website: https://cse.ucsd.edu/research/uc-san-diego-cse-fellows-program Email: shachar.lovett@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UCSD CSE Fellows Program is intended to support exceptional postdoctoral researchers in computer science. The program seeks to recruit 1-3 fellows a year for a two year postdoctoral appointment working alongside a UCSD CSE faculty mentor.</p>
<p>Website: <a href="https://cse.ucsd.edu/research/uc-san-diego-cse-fellows-program">https://cse.ucsd.edu/research/uc-san-diego-cse-fellows-program</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2021-06-25T14:08:42Z</updated>
    <published>2021-06-25T14:08:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-07-02T19:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4913288096208854339</id>
    <link href="http://processalgebra.blogspot.com/feeds/4913288096208854339/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4913288096208854339" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4913288096208854339" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4913288096208854339" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/06/the-detecter-runtime-verification-tool.html" rel="alternate" type="text/html"/>
    <title>The detectEr runtime-verification tool for Erlang programs</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Thanks to the huge amount of excellent work done by <a href="https://duncanatt.github.io/" target="_blank">Duncan Paul Attard</a> and <a href="http://staff.um.edu.mt/afra1/" target="_blank">Adrian Francalanza</a>, we now have a tutorial on detectEr that some of you might want to check out. See <a href="https://duncanatt.github.io/detecter/index.html">this web page</a> for all the material, tool download and links to the videos of the tutorial Duncan delivered at the <a href="https://www.discotec.org/2021/tutorials" target="_blank">DisCoTec 2021 Tutorial Day</a>. </p><p>detectEr is a runtime verification tool for asynchronous component systems that run on the <a href="https://blog.erlang.org/a-brief-BEAM-primer/" target="_blank">Erlang Virtual Machine</a>. It also supports monitoring systems that can execute outside of the EVM, so long as these can produce traces that are formatted in a way that is parsable by detectEr. The tool itself is developed in <a href="https://www.erlang.org/" target="_blank">Erlang</a>, and is the product of five years of theoretical and practical development. (Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability.)  </p> <p>Enjoy!</p></div>
    </content>
    <updated>2021-06-24T08:16:00Z</updated>
    <published>2021-06-24T08:16:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-06-24T08:16:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6958131418382007261</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6958131418382007261/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6958131418382007261" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6958131418382007261" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html" rel="alternate" type="text/html"/>
    <title>I went to the ``debate'' about Program Verif and the Lipton-Demillo-Perlis paper</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>On Thursday June 17 I went to (on zoom- does that need to be added anymore?)</p><p><i>A Debate on Program Correctness</i></p><p>There was no subtitle but it could have been:</p><p>Have the points made in <i>Social Processes and Proofs of Theorems and Programs</i> by DeMillo, Lipton, Perlis, survived the test of time ? (Spoiler Alert: Yes.)</p><p>I found out about it from the Lipton-Regan blog <a href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/">here</a></p><p>The debaters were Richard DeMillo and Richard Lipton and the moderator was Harry Lewis (Alan Perlis passed away in 1990).  Calling it a debate is not correct since DeMillo and Lipton (and Lewis) all agree. (DeMillo and Lipton even have the same first name!)  The DLP paper is in Harry Lewis's collection<i> Ideas that created the future.</i>  The event  should have been advertised as a discussion. However, it was a good discussion so this is not a complaint.</p><p>Here are some things that came out of the discussion.</p><p>1) The main topic was the 1979 DeMillo-Lipton-Perlis paper (see <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">here</a>) that gave arguments why Proofs of Program correctness could not work.</p><p>An all-to-brief summary of the DLP paper: Some researchers are trying to set up frameworks for doing proofs that programs are correct, analogous to the certainty  we get with a proof of a Theorem in Mathematics. But proofs in Mathematics are, in reality, NOT that rigorous. Often details are left out or left to the reader. This is fine for mathematics (more on that later) but unacceptable for programs which need rather precise and rigorous proofs.</p><p>How do theorems in mathematics really get verified? By having enough people look at them and make sure they match intuitions, what DLP call <i>A Social Process</i>.  (NOTE FROM BILL: Papers that are not important do not get looked at so there may well be errors.)</p><p>2) The notion of proving-programs-correct was very seductive; however, the people who were trying to do this had a blind spot about how the analogy of proving-programs-correct and proving-theorem-correct differ.  In particular, a program is rather complicated and even stating carefully what you want to prove is difficult. By contrast, for most math statements, what you want to prove is clear. Note also that a program has lots of code (far more now than when DLP was written) and so much can happen that you cannot account for.</p><p>3) The DLP paper had a large effect on the field of program verification.  Funding for it was reduced and students were discouraged from going into it.</p><p>4) When DLP appeared DeMillo and Lipton were pre-tenure. Hence it took lots of courage to publish it. Alan Perlis had tenure and had already won a Turing award.  This did give DeMillo and Lipton some cover; however, it still took courage.</p><div><div>5) How did the Program Verification  Community deal with the objections in DLP?  DeMillo said that he looked at a large set of papers in the field, and very few even mentioned DLP. He recommends reading the book <i>Mechanizing Proof: Computing, Risk, and Trust by David McKenzie </i>see <a href="https://www.amazon.com/exec/obidos/ASIN/0262632950">here</a>.</div><div><br/></div><div>6) So how can we be more certain that programs are correct?</div><div><br/></div><div>a) Testing.</div><div>b) Modularize and test. Fix errors. Modularize  and test. Fix errors...</div><div>c) Try to isolate side effects.</div><div>d) More testing.</div><div><br/></div><div>Some point to Model Checking, which could be considered very sophisticated testing, but that's used to verify circuits and perhaps low-level code, not programs. Model checking is a success story and note that Ed Clark, E. Allen Emerson, and Joseph Sifakis shared a (well deserved) Turing award for this work. But see next note.</div><div><br/></div><div>6.5) An audience member pointed out that Program Verification people have won several Turing Awards</div><div><br/></div><div>Dijkstra 1972</div><div><br/></div><div>Floyd 1978 </div><div><br/></div><div>Hoare 1980</div><div><br/></div><div>Pnueli 1996</div><div><br/></div><div>(Are there more?) </div><div><br/></div><div>so the field is alive and healthy. DeMillo responded that prizes for academic research are a poor measure of  success. </div><div><br/></div><div>7) Can computers themselves help with proofs of correctness? That is the only hope; however, there are scaling problems.</div><div><br/></div><div>8) When DLP was written a program with 100,000 lines of code was considered large. Now we have programs with millions of lines of code. And now we have more concurrency. So the lessons of the DLP paper are probably more relevant now then they were then.</div><div><br/></div><div>9) Since Program Verification does not seem to be used, how come we don't have a Software crisis?</div><div><br/></div><div>a) We do! The Q+A mechanism at the meeting was terrible. </div><div>b) We do! FILL IN YOUR OWN FAVORITE STORY OF BAD SOFTWARE.</div><div>c) See the answer to question 6.</div><div><br/></div><div>10) SPECS are a problem. Tony Hoare once gave a talk where he proves that a program sorted correctly and then pointed out that if the program just output 0,...0 that would have also satisfied the SPEC since all that was required was that the output be sorted, not the (overlooked!) requirement that it be the same numbers as the input. So one needs to be careful!</div><div><br/></div><div>11) Despite being a leader in the field, Tony Hoare has come to see the limitations of the Proofing-programs-correct approach to Software Verification.  His paper An Axiomatic basis for Computer Programming (1969)  (which is also in Harry Lewis's collection <i>Ideas that Created the Future</i>).</div><div>Much later, commenting on the paper,  Hoare says the following:</div><div><br/></div><div>Ten years ago, researchers into formal methods (and I was the most mistaken among them) predicted that the programming world would embrace with gratitude every assistance promised by formalization to solve the problems of reliability that arise when programs get large and more safety-critical. Programs have now got very large and very critical--well beyond the scale which can be comfortably tackled by formal methods. There have been many problems and failures, but these have nearly always been attributable to inadequate analysis of requirements or inadequate management control. It has turned out that the world just does not suffer significantly from the kind of problem that our research was originally intended to solve.'</div><div><br/></div></div><div><div>12) Richard Lipton told a story where he showed that the program in question satisfied the SPEC, but the SPEC was a tautology that any program would satisfy.  Again, one needs to be careful!</div><div><br/></div><div>13) The test of time: Verifying large scale programs does not seem to be common in industry. Is industrial adaptation a fair measure? </div><div><br/></div><div>14) Harry Lewis's  book <i>Ideas that created the future</i> collects up, edits, and comments on 46 important papers in Computer Science (I reviewed it in the issue of SIGACT News that is in your mailbox---I will blog about it at a later time.) There are several papers in it about program verification, including DLP, Hoare's paper, and three papers by Dijkstra.</div><div><br/></div><div>a) When Harry discussed including DLP some people said `You're going to include that!  Its a polemic, not a paper!'</div><div><br/></div><div>b) When Harry teaches a course from this book (it must be an awesome class!) and asks the students at the end which papers they learned the most from, the top two are an excerpt from Fred Brooks <i>The</i> <i>Mythical Man Month</i> (see my post on Brook's work <a href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html">here</a> ) and DLP.</div><div><br/></div><div>c) I am hoping that this is just one of 46 talks with authors of the papers in his book.  I look forward to his interview with Aristotle, Leibnitz, Boole, Turing, ...</div></div><div><br/></div></div>
    </content>
    <updated>2021-06-24T03:37:00Z</updated>
    <published>2021-06-24T03:37:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-07-02T15:22:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5549</id>
    <link href="https://www.scottaaronson.com/blog/?p=5549" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5549#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5549" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">STOC’2021 and BosonSampling</title>
    <summary xml:lang="en-US">Happy birthday to Alan Turing! This week I’m participating virtually in STOC’2021, which today had a celebration of the 50th anniversary of NP-completeness (featuring Steve Cook, Richard Karp, Leonid Levin, Christos Papadimitriou, and Avi Wigderson), and which tomorrow will have a day’s worth of quantum computing content, including a tutorial on MIP*=RE, two quantum sessions, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Happy birthday to Alan Turing!</p>



<p>This week I’m participating virtually in <a href="http://acm-stoc.org/stoc2021/">STOC’2021</a>, which today had a celebration of the 50th anniversary of NP-completeness (featuring Steve Cook, Richard Karp, Leonid Levin, Christos Papadimitriou, and Avi Wigderson), and which tomorrow will have a day’s worth of quantum computing content, including a tutorial on MIP*=RE, two quantum sessions, and an invited talk on quantum supremacy by John Martinis.  I confess that I’m not a fan of GatherTown, the platform being used for STOC.  Basically, you get a little avatar who wanders around a virtual hotel lobby and enters sessions—but it seems to reproduce all of the frustrating and annoying parts of experience without any of the good parts.</p>



<p>Ah!  But I got the surprising news that Alex Arkhipov and I are among the winners of STOC’s first-ever <a href="https://sigact.org/prizes/stoc_tot.html">“Test of Time Award,”</a> for our <a href="https://www.scottaaronson.com/papers/optics.pdf">paper on BosonSampling</a>.  It feels strange to win a “Test of Time” award for work that we did in 2011, which still seems like yesterday to me.  All the more since the experimental status and prospects of quantum supremacy via BosonSampling are still very much live, unresolved questions.</p>



<p>Speaking of which: on Monday, Alexey Rubtsov, of the Skolkovo Institute in Moscow, gave a talk for our quantum information group meeting at UT, about his <a href="https://arxiv.org/abs/2106.01445">recent work with Popova</a> on classically simulating Gaussian BosonSampling.  From the talk, I learned something extremely important.  I had imagined that their simulation must take advantage of the high rate of photon loss in actual experiments (like the <a href="https://www.scottaaronson.com/blog/?p=5159">USTC experiment</a> from late 2020), because how else are you going to simulate BosonSampling efficiently?  But Rubtsov explained that that’s not how it works at all.  While their algorithm is heuristic and remains to be rigorously analyzed, numerical studies suggest that it works even with <em>no</em> photon losses or other errors.  Having said that, their algorithm works:</p>



<ul><li>only for Gaussian BosonSampling, not Fock-state BosonSampling (as Arkhipov and I had originally proposed),</li><li>only for threshold detectors, not photon-counting detectors, and</li><li>only for a small number of modes (say, linear in the number of photons), not for a large number of modes (say, quadratic in the number of photons) as in the original proposal.</li></ul>



<p>So, bottom line, it now looks like the USTC experiment, amazing engineering achievement though it was, is not hard to spoof with a classical computer.  If so, this is because of multiple ways in which the experiment differed from my and Arkhipov’s original theoretical proposal.  We know exactly what those ways are—indeed, you can find them in my earlier blog posts on the subject—and hopefully they can be addressed in future experiments.  All in all, then, we’re left with a powerful demonstration of the continuing relevance of formal hardness reductions, and the danger of replacing them with intuitions and “well, it still seems hard to <em>me</em>.”  So I hope the committee won’t rescind my and Arkhipov’s Test of Time Award based on these developments in the past couple weeks!</p></div>
    </content>
    <updated>2021-06-23T16:44:51Z</updated>
    <published>2021-06-23T16:44:51Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-23T16:44:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1325</id>
    <link href="https://thmatters.wordpress.com/2021/06/23/tcs-visioning-2020-report-and-slides/" rel="alternate" type="text/html"/>
    <title>TCS Visioning 2020 report and slides</title>
    <summary>In July 2020, the CATCS organized a visioning workshop. We are happy to announce the release of a report and posters based on this workshop. Material produced from this workshop is available and free to use by any member of the TCS community. We gratefully acknowledge financial as well as organizational support by the SIGACT […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In July 2020, the <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> organized a <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">visioning workshop</a>. We are happy to announce the release of a report and posters based on this workshop. Material produced from this workshop is available and free to use by any member of the TCS community. We gratefully acknowledge financial as well as organizational support by the <a href="https://www.sigact.org/">SIGACT</a> and <a href="https://cra.org/ccc/">CCC</a> for this activity.</p>



<p>We are planning a follow-up event for disseminating the report and posters to funding agencies in the next few months. Details are forthcoming.</p>



<p>TCS Visioning Full Report: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-report.pdf">here</a></p>



<p>Short Report (CCC Quadrennial paper): <a href="https://cra.org/ccc/wp-content/uploads/sites/2/2020/10/Theoretical-Computer-Science_.pdf">here</a></p>



<p>TCS Visioning Slides: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides.pptx">in PPT</a> and <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides-1.pdf">in PDF</a></p></div>
    </content>
    <updated>2021-06-23T16:21:23Z</updated>
    <published>2021-06-23T16:21:23Z</published>
    <category term="reports"/>
    <category term="Visioning"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2021-07-02T19:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/088</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/088" rel="alternate" type="text/html"/>
    <title>TR21-088 |  Open Problems in Property Testing of Graphs | 

	Oded Goldreich</title>
    <summary>We briefly discuss a few open problems in the study of various models of testing graph properties, focusing on the query complexity of the various tasks. In the dense graph model, we discuss several open problems, including:

* Determining the complexity of testing triangle-freeness.
* Characterizing the class of properties that are testable within extremely low complexity. 

Turning to the bounded-degree graph model, we discuss several open problems, including:

* Characterizing the class of properties that are testable within size-oblivious complexity.
* Determining the complexity of graph isomorphism. 
In each of the foregoing models, we also discuss a favorite open problem that was recently resolved. Lastly, we discuss the vast lack of knowledge with respect to testing graph properties in the general graph model.</summary>
    <updated>2021-06-23T13:30:16Z</updated>
    <published>2021-06-23T13:30:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/087</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/087" rel="alternate" type="text/html"/>
    <title>TR21-087 |  Eliminating Intermediate Measurements using Pseudorandom Generators | 

	Uma Girish, 

	Ran Raz</title>
    <summary>We show that quantum algorithms of time T and space $S \ge \log T$ with intermediate measurements can be simulated by quantum algorithms of time $T\cdot \mathrm{poly}(S)$ and space $O(S\cdot \log T)$ without intermediate measurements. The best simulations prior to this work required either $\Omega(T)$ space (by the deferred measurement principle) or $\mathrm{poly}(2^S)$ time [FR21, GRZ21]. Our result is thus a time-efficient and space-efficient simulation of algorithms with intermediate measurements by algorithms without intermediate measurements.

To prove our result, we study pseudorandom generators for quantum space-bounded algorithms. We show that (an instance of) the INW pseudorandom generator for classical space-bounded algorithms [INW94] also fools quantum space-bounded algorithms. More precisely, we show that for quantum space-bounded algorithms that have access to a read-once tape consisting of random bits, the final state of the algorithm when the random bits are drawn from the uniform distribution is nearly identical to the final state when the random bits are drawn using the INW pseudorandom generator.</summary>
    <updated>2021-06-22T16:04:22Z</updated>
    <published>2021-06-22T16:04:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/086</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/086" rel="alternate" type="text/html"/>
    <title>TR21-086 |  Linear Space Streaming Lower Bounds for Approximating CSPs | 

	Chi-Ning  Chou, 

	Alexander Golovnev, 

	Madhu Sudan, 

	Ameya Velingker, 

	Santhoshini Velusamy</title>
    <summary>We consider the approximability of constraint satisfaction problems in the streaming setting. For every constraint satisfaction problem (CSP) on $n$ variables taking values in $\{0,\ldots,q-1\}$, we prove that improving over the trivial approximability by a factor of $q$ requires $\Omega(n)$ space even on instances with $O(n)$ constraints. We also identify a broad subclass of problems for which any improvement over the trivial approximability requires $\Omega(n)$ space. The key technical core is an optimal, $q^{-(k-1)}$-inapproximability for the case where every constraint is given by a system of $k-1$ linear equations $\bmod\; q$ over $k$ variables. Prior to our work, no such hardness was known for an approximation factor less than $1/2$ for any CSP. Our work builds on and extends the work of Kapralov and Krachun (Proc. STOC 2019) who showed a linear lower bound on any non-trivial approximation of the max cut in graphs. This corresponds roughly to the case of  Max $k$-LIN-$\bmod\; q$ with $k=q=2$. Each one of the extensions provides non-trivial technical challenges that we overcome in this work.</summary>
    <updated>2021-06-22T14:47:13Z</updated>
    <published>2021-06-22T14:47:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/</id>
    <link href="https://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/" rel="alternate" type="text/html"/>
    <title>Annual Symposium on Combinatorial Pattern Matching (summer school + conference))</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 4, 2021 – July 7, 2021 Wrocław, Poland and online https://cpm2021.ii.uni.wroc.pl/ The Annual Symposium on Combinatorial Pattern Matching (CPM) has by now over 30 years of tradition and is considered to be the leading conference for the community working on Stringology. The objective of the annual CPM meetings is to provide an international forum … <a class="more-link" href="https://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/">Continue reading <span class="screen-reader-text">Annual Symposium on Combinatorial Pattern Matching (summer school + conference))</span></a></div>
    </summary>
    <updated>2021-06-22T08:09:22Z</updated>
    <published>2021-06-22T08:09:22Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2021-07-02T19:21:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/085</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/085" rel="alternate" type="text/html"/>
    <title>TR21-085 |  The Final Nail in the Coffin of Statistically-Secure Obfuscator. | 

	Ilya Volkovich</title>
    <summary>We present an elementary, self-contained proof of the result of Goldwasser and Rothblum [GR07] that the existence of a (perfect) statistically secure obfuscator implies a collapse of the polynomial hierarchy. In fact, we show that an existence of a weaker object implies a somewhat stronger statement. In addition, we extend the result of [GR07] to the case of imperfect statistically secure obfuscator.</summary>
    <updated>2021-06-21T16:17:33Z</updated>
    <published>2021-06-21T16:17:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-07-02T19:20:32Z</updated>
    </source>
  </entry>
</feed>
