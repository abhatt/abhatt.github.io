<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-08-25T04:22:21Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3407</id>
    <link href="https://agtb.wordpress.com/2019/08/24/2020-call-for-profiles-of-sigecom-job-market-candidates/" rel="alternate" type="text/html"/>
    <title>2020 Call for profiles of SIGecom job market candidates</title>
    <summary>Continuing the tradition from 2016, 2017, 2018, and 2019, this year there will be an article in the upcoming edition of the SIGecom Exchanges, profiling junior job market candidates (both for postdoc and faculty positions) of the SIGecom community for 2019-2020. These profiles will include the candidates’ thesis title, research summary, brief biography, and citations to three representative papers, as well as links to each candidate’s homepage and CV. To be considered, each candidate should complete the submission form by September […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Continuing the tradition from <a href="http://www.sigecom.org/exchanges/volume_14/1/PROFILES.pdf" rel="noopener noreferrer" target="_blank">2016</a>, <a href="http://www.sigecom.org/exchanges/volume_15/1/PROFILES.pdf" rel="noopener noreferrer" target="_blank">2017</a>, <a href="http://www.sigecom.org/exchanges/volume_16/1/PROFILES.pdf" rel="noopener noreferrer" target="_blank">2018</a>, and <a href="http://www.sigecom.org/exchanges/volume_17/1/PROFILES.pdf" rel="noopener noreferrer" target="_blank" title="http://www.sigecom.org/exchanges/volume_17/1/PROFILES.pdf">2019</a>, this year there will be an article in the upcoming edition of the SIGecom Exchanges, profiling junior job market candidates (both for postdoc and faculty positions) of the SIGecom community for 2019-2020. These profiles will include the candidates’ thesis title, research summary, brief biography, and citations to three representative papers, as well as links to each candidate’s homepage and CV.</div>
<div/>
<div>To be considered, each candidate should complete the <a href="https://docs.google.com/forms/d/1Xv7dfnaHOXgKKPs3cyaBKcWKq0QLTHwQhOJ6T0pGnJc" rel="noopener noreferrer" target="_blank" title="https://docs.google.com/forms/d/1Xv7dfnaHOXgKKPs3cyaBKcWKq0QLTHwQhOJ6T0pGnJc">submission form</a> by <b>September 2</b>, and then submit the final version of their LaTeX source files (a link to which is provided in the form) by <b>September 5</b>. The article will be co-edited by Vasilis Gkatzelis and myself. Please forward this call to whoever you think would be interested.</div></div>
    </content>
    <updated>2019-08-24T14:57:19Z</updated>
    <published>2019-08-24T14:57:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-08-25T04:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08411</id>
    <link href="http://arxiv.org/abs/1908.08411" rel="alternate" type="text/html"/>
    <title>Generalized Metric Repair on Graphs</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fan:Chenglin.html">Chenglin Fan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gilbert:Anna_C=.html">Anna C. Gilbert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raichel:Benjamin.html">Benjamin Raichel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sonthalia:Rishi.html">Rishi Sonthalia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buskirk:Gregory_Van.html">Gregory Van Buskirk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08411">PDF</a><br/><b>Abstract: </b>Many modern data analysis algorithms either assume or are considerably more
efficient if the distances between the data points satisfy a metric. These
algorithms include metric learning, clustering, and dimension reduction. As
real data sets are noisy, distances often fail to satisfy a metric. For this
reason, Gilbert and Jain and Fan et al. introduced the closely related sparse
metric repair and metric violation distance problems. The goal of these
problems is to repair as few distances as possible to ensure they satisfy a
metric. Three variants were considered, one admitting a polynomial time
algorithm. The other variants were shown to be APX-hard, and an
$O(OPT^{1/3})$-approximation was given, where $OPT$ is the optimal solution
size.
</p>
<p>In this paper, we generalize these problems to no longer consider all
distances between the data points. That is, we consider a weighted graph $G$
with corrupted weights $w$, and our goal is to find the smallest number of
weight modifications so that the resulting weighted graph distances satisfy a
metric. This is a natural generalization and is more flexible as it takes into
account different relationships among the data points. As in previous work, we
distinguish among the types of repairs permitted and focus on the increase only
and general versions. We demonstrate the inherent combinatorial structure of
the problem, and give an approximation-preserving reduction from MULTICUT.
Conversely, we show that for any fixed constant $\varsigma$, for the large
class of $\varsigma$-chordal graphs, the problems are fixed parameter
tractable. Call a cycle broken if it contains an edge whose weight is larger
than the sum of all its other edges, and call the amount of this difference its
deficit. We present approximation algorithms, one which depends on the maximum
number of edges in a broken cycle, and one which depends on the number of
distinct deficit values.
</p></div>
    </summary>
    <updated>2019-08-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08384</id>
    <link href="http://arxiv.org/abs/1908.08384" rel="alternate" type="text/html"/>
    <title>Covering convex bodies and the Closest Vector Problem</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nasz=oacute=di:M=aacute=rton.html">Márton Naszódi</a>, Moritz Venzin <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08384">PDF</a><br/><b>Abstract: </b>We present algorithms for the $(1+\epsilon)$-approximate version of the
closest vector problem for certain norms. The currently fastest algorithm
(Dadush and Kun 2016) for general norms has running time of $2^{O(n)}
(1/\epsilon)^n$. We improve this substantially in the following two cases.
</p>
<p>For $\ell_p$-norms with $p&gt;2$ (resp. $p \in [1,2]$) fixed, we present an
algorithm with a running time of $2^{O(n)} (1/\epsilon)^{n/2}$ (resp. $2^{O(n)}
(1/\epsilon)^{n/p}$). This result is based on a geometric covering problem,
that was introduced in the context of CVP by Eisenbrand et al.: How many convex
bodies are needed to cover the ball of the norm such that, if scaled by two
around their centroids, each one is contained in the $(1+\epsilon)$-scaled
homothet of the norm ball? We provide upper bounds for this problem by
exploiting the \emph{modulus of smoothness} of the $\ell_p$-balls. Applying a
covering scheme, we can boost any $2$-approximation algorithm for CVP to a
$(1+\epsilon)$-approximation algorithm with the improved run time, either using
a straightforward sampling routine or using the deterministic algorithm of
Dadush for the construction of an epsilon net.
</p>
<p>Furthermore, we consider polyhedral and zonotopal norms. For centrally
symmetric polytopes (resp. zonotopes) with $O(n)$ facets (resp. generated by
$O(n)$ line segments), we provide a deterministic
$O(\log_2(1/\epsilon))^{O(n)}$ time algorithm. This generalizes the result of
Eisenbrand et al. which applies to the $\ell_\infty$-norm.
</p>
<p>As it is the case for the covering procedure of Eisenbrand et al., our
approach boosts any constant factor approximation algorithm to a
$(1+\epsilon)$-approximate algorithm. By assuming the existence of a
$poly(n)$-space and $2^{O(n)}$ time algorithm for 2-approximate CVP, the space
complexity of our algorithm can be reduced to a polynomial.
</p></div>
    </summary>
    <updated>2019-08-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08365</id>
    <link href="http://arxiv.org/abs/1908.08365" rel="alternate" type="text/html"/>
    <title>Optimal Morphs of Planar Orthogonal Drawings II</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goethem:Arthur_van.html">Arthur van Goethem</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Speckmann:Bettina.html">Bettina Speckmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verbeek:Kevin.html">Kevin Verbeek</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08365">PDF</a><br/><b>Abstract: </b>Van Goethem and Verbeek recently showed how to morph between two planar
orthogonal drawings $\Gamma_I$ and $\Gamma_O$ of a connected graph $G$ while
preserving planarity, orthogonality, and the complexity of the drawing during
the morph. Necessarily drawings $\Gamma_I$ and $\Gamma_O$ must be equivalent,
that is, there exists a homeomorphism of the plane that transforms $\Gamma_I$
into $\Gamma_O$. Van Goethem and Verbeek use $O(n)$ linear morphs, where $n$ is
the maximum complexity of the input drawings. However, if the graph is
disconnected their method requires $O(n^{1.5})$ linear morphs. In this paper we
present a refined version of their approach that allows us to also morph
between two planar orthogonal drawings of a disconnected graph with $O(n)$
linear morphs while preserving planarity, orthogonality, and linear complexity
of the intermediate drawings.
</p>
<p>Van Goethem and Verbeek measure the structural difference between the two
drawings in terms of the so-called spirality $s = O(n)$ of $\Gamma_I$ relative
to $\Gamma_O$ and describe a morph from $\Gamma_I$ to $\Gamma_O$ using $O(s)$
linear morphs. We prove that $s+1$ linear morphs are always sufficient to morph
between two planar orthogonal drawings, even for disconnected graphs. The
resulting morphs are quite natural and visually pleasing.
</p></div>
    </summary>
    <updated>2019-08-24T23:25:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08347</id>
    <link href="http://arxiv.org/abs/1908.08347" rel="alternate" type="text/html"/>
    <title>On Explicit Branching Programs for the Rectangular Determinant and Permanent Polynomials</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>V. Arvind, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Abhranil.html">Abhranil Chatterjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Datta:Rajit.html">Rajit Datta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Partha.html">Partha Mukhopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08347">PDF</a><br/><b>Abstract: </b>We study the arithmetic circuit complexity of some well-known family of
polynomials through the lens of parameterized complexity. Our main focus is on
the construction of explicit algebraic branching programs (ABP) for determinant
and permanent polynomials of the \emph{rectangular} symbolic matrix in both
commutative and noncommutative settings. The main results are:
</p>
<p>1. We show an explicit $O^{*}({n\choose {\downarrow k/2}})$-size ABP
construction for noncommutative permanent polynomial of $k\times n$ symbolic
matrix. We obtain this via an explicit ABP construction of size
$O^{*}({n\choose {\downarrow k/2}})$ for $S_{n,k}^*$, noncommutative
symmetrized version of the elementary symmetric polynomial $S_{n,k}$.
</p>
<p>2. We obtain an explicit $O^{*}(2^k)$-size ABP construction for the
commutative rectangular determinant polynomial of the $k\times n$ symbolic
matrix.
</p>
<p>3. In contrast, we show that evaluating the rectangular noncommutative
determinant over rational matrices is $W[1]$-hard.
</p></div>
    </summary>
    <updated>2019-08-24T23:20:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08273</id>
    <link href="http://arxiv.org/abs/1908.08273" rel="alternate" type="text/html"/>
    <title>Representing Graphs and Hypergraphs by Touching Polygons in 3D</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Evans:William.html">William Evans</a>, Paweł Rzążewski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saeedi:Noushin.html">Noushin Saeedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shin:Chan=Su.html">Chan-Su Shin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08273">PDF</a><br/><b>Abstract: </b>Contact representations of graphs have a long history.
</p>
<p>Most research has focused on problems in 2d, but 3d contact representations
have also been investigated, mostly concerning fully-dimensional geometric
objects such as spheres or cubes. In this paper we study contact
representations with convex polygons n~3d. We show that every graph admits such
a representation.
</p>
<p>Since our representations use super-polynomial coordinates, we also construct
representations on grids of polynomial size for specific graph classes
(bipartite, subcubic). For hypergraphs, we represent their duals, that is, each
vertex is represented by a point and each edge by a polygon.
</p>
<p>We show that even regular and quite small hypergraphs do not admit such
representations. On the other hand, the Steiner triple systems $S(2,3,7)$ and
$S(2,3,9)$ can be represented.
</p></div>
    </summary>
    <updated>2019-08-24T23:24:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08266</id>
    <link href="http://arxiv.org/abs/1908.08266" rel="alternate" type="text/html"/>
    <title>Interactive Duplicate Search in Software Documentation</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>D. V. Luciv, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koznov:D=_V=.html">D. V. Koznov</a>, A. A. Shelikhovskii, K. Yu. Romanovsky, G. A. Chernishev, A. N. Terekhov, D. A. Grigoriev, A. N. Smirnova, D. V. Borovkov, A. I. Vasenina <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08266">PDF</a><br/><b>Abstract: </b>Various software features such as classes, methods, requirements, and tests
often have similar functionality. This can lead to emergence of duplicates in
their descriptive documentation. Uncontrolled duplicates created via copy/paste
hinder the process of documentation maintenance. Therefore, the task of
duplicate detection in software documentation is of importance. Solving it
makes planned reuse possible, as well as creating and using templates for
unification and automatic generation of documentation. In this paper, we
present an interactive process for duplicate detection that involves the user
in order to conduct meaningful search. It includes a new formal definition of a
near duplicate, a pattern-based, and the proof of its completeness. Moreover,
we demonstrate the results of experimenting on a collection of documents of
several industrial projects.
</p></div>
    </summary>
    <updated>2019-08-24T23:21:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08151</id>
    <link href="http://arxiv.org/abs/1908.08151" rel="alternate" type="text/html"/>
    <title>Multi-level Graph Drawing using Infomap Clustering</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Seok=Hee.html">Seok-Hee Hong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eades:Peter.html">Peter Eades</a>, Marnijati Torkel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Ziyang.html">Ziyang Wang</a>, David Chae, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Sungpack.html">Sungpack Hong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langerenken:Daniel.html">Daniel Langerenken</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chafi:Hassan.html">Hassan Chafi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08151">PDF</a><br/><b>Abstract: </b>Infomap clustering finds the community structures that minimize the expected
description length of a random walk trajectory; algorithms for infomap
clustering run fast in practice for large graphs. In this paper we leverage the
effectiveness of Infomap clustering combined with the multi-level graph drawing
paradigm. Experiments show that our new Infomap based multi-level algorithm
produces good visualization of large and complex networks, with significant
improvement in quality metrics.
</p></div>
    </summary>
    <updated>2019-08-24T23:22:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08129</id>
    <link href="http://arxiv.org/abs/1908.08129" rel="alternate" type="text/html"/>
    <title>Extending Simple Drawings</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arroyo:Alan.html">Alan Arroyo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Derka:Martin.html">Martin Derka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08129">PDF</a><br/><b>Abstract: </b>Simple drawings of graphs are those in which each pair of edges share at most
one point, either a common endpoint or a proper crossing. In this paper we
study the problem of extending a simple drawing $D(G)$ of a graph $G$ by
inserting a set of edges from the complement of $G$ into $D(G)$ such that the
result is a simple drawing. In the context of rectilinear drawings, the problem
is trivial. For pseudolinear drawings, the existence of such an extension
follows from Levi's enlargement lemma. In contrast, we prove that deciding if a
given set of edges can be inserted into a simple drawing is NP-complete.
Moreover, we show that the maximization version of the problem is APX-hard. We
also present a polynomial-time algorithm for deciding whether one edge $uv$ can
be inserted into $D(G)$ when $\{u,v\}$ is a dominating set for the graph $G$.
</p></div>
    </summary>
    <updated>2019-08-24T23:26:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.08111</id>
    <link href="http://arxiv.org/abs/1908.08111" rel="alternate" type="text/html"/>
    <title>Engineering Faster Sorters for Small Sets of Items</title>
    <feedworld_mtime>1566604800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jasper Marianczuk <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.08111">PDF</a><br/><b>Abstract: </b>Sorting a set of items is a task that can be useful by itself or as a
building block for more complex operations. The more sophisticated and fast
sorting algorithms become asymptotically, the less efficient they are for small
sets of items due to large constant factor. This thesis aims to determine if
there is a faster way to sort base case sizes than using insertion sort. For
that we looked at sorting networks and how to implement them efficiently.
Because sorting networks need to be implemented explicitly for each input size,
providing networks for larger sizes becomess less efficient. That is why we
modified Super Scalar Sample Sort to break down larger sets into sizes that can
in turn be sorted by sorting networks. We show that the task of sorting only
small sets can be greatly improved by at least 25% when using sorting networks
compared to insertion sort, but that when integrating them into other sorting
algorithms the speed-up is hindered by the limited L1 instruction cache size.
On a machine with 64KiB of L1 instruction cache we achieved over 6% of
improvement when using sorting networks as a base case sorter instead of
insertion sort.
</p></div>
    </summary>
    <updated>2019-08-24T23:21:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/109</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/109" rel="alternate" type="text/html"/>
    <title>TR19-109 |  Decoding Downset codes over a finite grid | 

	Utkarsh Tripathi, 

	Srikanth Srinivasan, 

	S Venkitesh</title>
    <summary>In a recent paper, Kim and Kopparty (Theory of Computing, 2017) gave a deterministic algorithm for the unique decoding problem for polynomials of bounded total degree over a general grid $S_1\times\cdots \times S_m.$ We show that their algorithm can be adapted to solve the unique decoding problem for the general family of Downset codes. Here, a downset code is specified by a family $\mathcal{D}$ of monomials closed under taking factors: the corresponding code is the space of evaluations of all polynomials that can be written as linear combinations of monomials from $\mathcal{D}.$</summary>
    <updated>2019-08-23T13:39:00Z</updated>
    <published>2019-08-23T13:39:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/108</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/108" rel="alternate" type="text/html"/>
    <title>TR19-108 |  Beating the probabilistic lower bound on perfect hashing | 

	Chaoping Xing, 

	chen yuan</title>
    <summary>For an interger $q\ge 2$, a perfect $q$-hash code $C$  is a  block code over $\ZZ_q:=\ZZ/ q\ZZ$ of length $n$ in which every subset $\{\bc_1,\bc_2,\dots,\bc_q\}$ of $q$ elements is separated, i.e., there exists $i\in[n]$ such that $\{\proj_i(\bc_1),\proj_i(\bc_2),\dots,\proj_i(\bc_q)\}=\ZZ_q$, where $\proj_i(\bc_j)$ denotes the $i$th position of $\bc_j$. Finding the maximum size $M(n,q)$ of  perfect $q$-hash codes of length $n$, for given $q$ and $n$, is  a fundamental problem in combinatorics, information theory, and computer science. In this paper, we are interested in asymptotical behavior of this problem. More precisely speaking, we will focus on the quantity $R_q:=\limsup_{n\rightarrow\infty}\frac{\log_2 M(n,q)}n$.

A well-known probabilistic argument shows an existence lower bound on $R_q$, namely $R_q\ge\frac1{q-1}\log_2\left(\frac1{1-q!/q^q}\right)$ \cite{FK,K86}.  This is still the best-known lower bound till now except for the case $q=3$  for which K\"{o}rner and Matron \cite{KM} found that the concatenation technique could lead to a perfect $3$-hash code beating this the probabilistic lower bound. The improvement on the lower bound on $R_3$ was discovered in 1988 and there has been no any progress on lower bound on $R_q$ for more than 30 years despite of some work on upper bounds on $R_q$.
 In this paper we show that this  probabilistic lower bound can be improved for $q=4,8$ and all odd integers between $3$ and $25$, and \emph{every sufficiently large odd} $q$. Our idea is based on a modified concatenation which is different from the classical concatenation for which both the inner and outer codes are separated. However, for our concatenation we do not require that the inner code is a perfect $q$-hash code. This gives  a more flexible choice of inner codes and hence we are able to beat the  probabilistic  existence lower bound on $R_q$.</summary>
    <updated>2019-08-23T13:37:39Z</updated>
    <published>2019-08-23T13:37:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=14329</id>
    <link href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/" rel="alternate" type="text/html"/>
    <title>Amazing:  Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang made dramatic progress on the Sunflower Conjecture</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">WOW! The new paper https://arxiv.org/abs/1908.08483 improved bounds for the sunflower lemma gives the most dramatic progress on the sunflowe conjecture since it was asked. Congratulations to Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang.   (Written on my smartphone will … <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>WOW! The new paper <a href="https://arxiv.org/abs/1908.08483" rel="nofollow">https://arxiv.org/abs/1908.08483</a> improved bounds for the sunflower lemma gives the most dramatic progress on the sunflowe conjecture since it was asked. Congratulations to Ryan Alweiss, Shachar Lovett, Kewen Wu, Jiapeng Zhang.</p>
<p> </p>
<p>(Written on my smartphone will expand it when reconnected to my laptop.)</p></div>
    </content>
    <updated>2019-08-23T05:47:59Z</updated>
    <published>2019-08-23T05:47:59Z</published>
    <category term="Combinatorics"/>
    <category term="Uncategorized"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-25T04:20:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/22/serpentine-belts</id>
    <link href="https://11011110.github.io/blog/2019/08/22/serpentine-belts.html" rel="alternate" type="text/html"/>
    <title>Serpentine belts</title>
    <summary>Many car engines use a serpentine belt, passing across multiple pulleys and tensioner wheels, to transmit mechanical power and timing information from the car’s crankshaft to its alternator, engine fan, water pump, air conditioning, steering pump, and other systems. Another (usually separate) belt, the timing belt, similarly connects the crankshaft to the camshaft, which controls and drives the timing of the engine’s valves. The Volvo bus engine below shows both of these belts:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many car engines use a <a href="https://en.wikipedia.org/wiki/Serpentine_belt">serpentine belt</a>, passing across multiple pulleys and <a href="https://en.wikipedia.org/wiki/Tensioner">tensioner wheels</a>, to transmit mechanical power and timing information from the car’s crankshaft to its alternator, engine fan, water pump, air conditioning, steering pump, and other systems. Another (usually separate) belt, the <a href="https://en.wikipedia.org/wiki/Timing_belt_(camshaft)">timing belt</a>, similarly connects the crankshaft to the camshaft, which controls and drives the timing of the engine’s valves.
The <a href="https://commons.wikimedia.org/wiki/File:Belt_drive_systen_01.JPG">Volvo bus engine</a> below shows both of these belts:</p>

<p style="text-align: center;"><img alt="Timing and serpentine belts of a Volvo bus engine; CC-BY-SA photo by Miya.m from https://commons.wikimedia.org/wiki/File:Belt_drive_systen_01.JPG" src="https://11011110.github.io/blog/assets/2019/Volvo-bus-engine-belts.jpg" style="border-style: solid; border-color: black;" width="60%"/></p>

<p>But suppose you encounter such an engine with its belt removed. How can you tell where to run the belt to connect it all back together again? There may be many different orderings in which you can connect a given set of wheels by a belt. On a real engine (such as the one in a Ford Escort on which I loosely modeled the top image below), you might get a little more information from which of the wheels are ribbed (inside the belt) and which are smooth (outside the belt) but even that extra information won’t always give you a unique solution:</p>

<p style="text-align: center;"><img alt="Two serpentine belts for the Ford Escort" src="https://11011110.github.io/blog/assets/2019/escort.svg"/></p>

<p>Connecting wheels with belts like this is the topic of my latest preprint, “Existence and hardness of conveyor belts” (<a href="https://arxiv.org/abs/1908.07668">arXiv:1908.07668</a>, with a large group of co-authors merging groups from the University of Washington and the Bellairs workshops). The name isn’t really accurate, because most conveyor belts have simpler geometry, but that’s what the question was called in past work. At least we managed to avoid the misspelling “conveyer” of some of that work.</p>

<p>To be tight, a belt for a system of disjoint disks (representing the pulleys and wheels) must be a smooth simple closed curve, made by connecting arcs of the disks with <a href="https://en.wikipedia.org/wiki/Tangent_lines_to_circles#Tangent_lines_to_two_circles">bitangents</a> between pairs of disks. It was already known that some systems of disks have no belt, and conjectured that unit disks always have one. Our work shows that it’s -complete to tell whether a belt exists, that they do exist for certain special systems of disks (e.g. when no vertical line crosses multiple disks), and that by adding a linear number of extra disks one can always make a belt exist.</p>

<p>The question of how many different belts can connect the same system of disks (posed to me by co-author Sara Billey) was to a large extent the inspiration for <a href="https://11011110.github.io/blog/2019/03/12/counting-polygon-triangulations.html">my earlier paper on counting triangulations</a>. If counting simple polygons through a set of points is hard, then so is counting belts for tiny disks. And when I couldn’t prove that counting simple polygons is hard, I turned to other problems for which the proof was easier.</p>

<p>As part of this project I wrote <a href="https://11011110.github.io/blog/assets/2019/drawbelts.py">a little Python program to draw systems of disks and their belts</a>, used for the image above and for some of the images in the paper. It doesn’t find which belts are possible itself; instead, you have to specify the belt by listing the disks that it touches in order (allowing repetitions although some of the versions of the problem that we studied do not) and specifying for each disk which direction it turns when the belt touches it (equivalently, whether it is inside or outside the belt). To use it, you’ll need my <a href="https://www.ics.uci.edu/~eppstein/PADS/">PADS Python library</a>, or at least <a href="https://www.ics.uci.edu/~eppstein/PADS/SVG.py">the package in it for generating SVG files</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102664433496197083">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-22T21:19:00Z</updated>
    <published>2019-08-22T21:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3404</id>
    <link href="https://agtb.wordpress.com/2019/08/21/papafest-schedule-announced/" rel="alternate" type="text/html"/>
    <title>PapaFest schedule announced</title>
    <summary>The schedule for PapaFest (celebrating Christos Papadimitriou) has been posted at http://papafest.cs.columbia.edu/ When/where: September 6-8, 2019, at Columbia University in Davis Auditorium. (Register at the URL above, for free.) Confirmed speakers: Sanjeev Arora, Michael Collins, Michael Jordan, Anna Karlin, Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The schedule for PapaFest (celebrating Christos Papadimitriou) has been posted at <a href="http://papafest.cs.columbia.edu/">http://papafest.cs.columbia.edu/</a></p>
<p>When/where: September 6-8, 2019, at Columbia University in Davis Auditorium. (Register at the URL above, for free.)</p>
<p>Confirmed speakers: Sanjeev Arora, Michael Collins, Michael Jordan, Anna Karlin, Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>There will also be two panels led by Richard Karp and Jitendra Malik, and a rock concert by Errors in Bars on Saturday night!</p></div>
    </content>
    <updated>2019-08-21T15:12:07Z</updated>
    <published>2019-08-21T15:12:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-08-25T04:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/21/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/21/assistant-professor-tenure-track-and-professor-positions-in-computer-science-at-institute-of-science-and-technology-austria-apply-by-october-31-2019/" rel="alternate" type="text/html"/>
    <title>Assistant professor (tenure-track) and professor positions in computer science at Institute of Science and Technology Austria (apply by October 31, 2019)</title>
    <summary>We invite applications in all areas of computer science for several open positions. Female researchers are strongly encouraged to apply. Website: https://ist.ac.at/en/jobs/faculty/ Email: professors@ist.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications in all areas of computer science for several open positions. Female researchers are strongly encouraged to apply.</p>
<p>Website: <a href="https://ist.ac.at/en/jobs/faculty/">https://ist.ac.at/en/jobs/faculty/</a><br/>
Email: <a href="mailto:professors@ist.ac.at" rel="noopener" target="_blank"> professors@ist.ac.at</a></p></div>
    </content>
    <updated>2019-08-21T11:55:31Z</updated>
    <published>2019-08-21T11:55:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-25T04:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17855</id>
    <link href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/" rel="alternate" type="text/html"/>
    <title>The Argument against Quantum Computers – a CERN Colloquium and a New Paper</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me announce my CERN colloquium this Thursday, August 22, 2019, 16:30-17:30 entitled “The argument against quantum computers.” If you are at CERN or the neighborhood, please please come to the lecture. (Tea and coffee will be served at 16:00. … <a href="https://gilkalai.wordpress.com/2019/08/21/the-argument-against-quantum-computers-a-cern-colloquium-and-a-new-paper/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me announce <a href="https://indico.cern.ch/event/839574/?fbclid=IwAR0JHF8kcQ_tQKJrbJcNYTu9lQvMjOEvcSk6Jsh_Tq4uH4EbjeaDz7qv30k">my CERN colloquium</a> this Thursday, August 22, 2019, 16:30-17:30 entitled “The argument against quantum computers.” If you are at CERN or the neighborhood, please please come to the lecture. (Tea and coffee will be served at 16:00. ) If you are further away, there is a <a href="https://webcast.web.cern.ch/event/i839574">live broadcast</a>.</p>
<p>A few weeks ago I uploaded to the arXive a new paper with the same title “<a href="https://arxiv.org/abs/1908.02499">The argument against quantum computers</a>“. The paper will appear in the volume: Quantum, Probability, Logic: Itamar Pitowsky’s Work and Influence, Springer, Nature (2019), edited by Meir Hemmo and Orly Shenker. A short abstract for the lecture and the paper is:</p>
<blockquote><p><em><strong><span style="color: #008080;">We give a computational complexity argument against the feasibility of quantum computers. We identify a very low complexity class of probability distributions described by noisy intermediate-scale quantum computers, and explain why it will allow neither good-quality quantum error-correction nor a demonstration of “quantum supremacy.”  Some general principles governing the behavior of noisy quantum systems are derived.</span></strong></em></p></blockquote>
<p>The new paper and lecture have the same title as my 2018 <a href="https://www.quantamagazine.org/gil-kalais-argument-against-quantum-computers-20180207/">interview</a> with Katia Moskvitch at Quanta Magazine (see also <a href="https://gilkalai.wordpress.com/2018/02/08/my-argument-against-quantum-computers-an-interview-with-katia-moskvitch-on-quanta-magazine/">this post</a>).  Note that Christopher Monroe has recently <a href="https://www.quantamagazine.org/gil-kalais-argument-against-quantum-computers-20180207/#comment-4559220424">contributed a very interesting comment</a> to the Quanta article. My paper is dedicated to the memory of Itamar Pitowsky, and for more on Itamar see the post <a href="https://gilkalai.wordpress.com/2010/02/15/itamar-pitowski-probability-in-physics-where-does-it-come-from/" rel="bookmark">Itamar Pitowsky: Probability in Physics, Where does it Come From?</a> See also this <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">previous post</a> for two other quantum events in Jerusalem: a seminar in the first semester and a winter school on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/sasb.png"><img alt="" class="alignnone size-full wp-image-17856" height="481" src="https://gilkalai.files.wordpress.com/2019/08/sasb.png?w=640&amp;h=481" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">A slide from a lecture by Scott Aaronson where he explains why soap bubble computers cannot solve the NP-complete Steiner-tree problem. Noisy intermediate scale quantum (NISQ) circuits are <em>computationally </em>much more primitive than Scott’s soap bubble computers and this will prevent them from achieving neither “quantum supremacy” nor good quality quantum error correcting codes.  </span></strong><span style="color: #ff0000;">(<a href="https://www.scottaaronson.com/blog/?p=4199">source</a> for the picture)</span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/entn.png"><img alt="" class="alignnone size-full wp-image-17860" height="360" src="https://gilkalai.files.wordpress.com/2019/08/entn.png?w=640&amp;h=360" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Low-entropy quantum states give probability distributions described by low degree polynomials, and very low-entropy quantum states give chaotic behavior. Higher entropy enables classical information. </span></strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/cern.png"><img alt="" class="alignnone size-full wp-image-17862" height="371" src="https://gilkalai.files.wordpress.com/2019/08/cern.png?w=640&amp;h=371" width="640"/></a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-08-21T01:26:28Z</updated>
    <published>2019-08-21T01:26:28Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Physics"/>
    <category term="Quantum"/>
    <category term="CERN"/>
    <category term="Quantum computers"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-25T04:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16180</id>
    <link href="https://rjlipton.wordpress.com/2019/08/20/our-trip-to-monte-carlo/" rel="alternate" type="text/html"/>
    <title>Our Trip To Monte Carlo</title>
    <summary>Why does randomness help? Kathryn Farley is my dear wife. She and I are currently on a cruise through the Mediterranean. Our trip started in Barcelona and is stopping daily at various cities as we journey to Rome. “Tough duty,” but we are trying to enjoy it. Today I wish to talk about our visit […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Why does randomness help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/08/kathrynmontecarlo2.png"><img alt="" class="alignright wp-image-16183" height="180" src="https://rjlipton.files.wordpress.com/2019/08/kathrynmontecarlo2.png?w=141&amp;h=180" width="141"/></a></p>
<p>
Kathryn Farley is my dear wife. She and I are currently on a cruise through the Mediterranean. Our trip started in Barcelona and is stopping daily at various cities as we journey to Rome. “Tough duty,” but we are trying to enjoy it. </p>
<p>
Today I wish to talk about our visit to Monte Carlo. </p>
<p>
Our ship, the <a href="https://en.wikipedia.org/wiki/MV_Seabourn_Encore">Encore</a>, just docked there Sunday. The day was warm and clear, and we spent some time exploring the city. We did manage to avoid losing any money at the famous casino. Our secret was simple: do not play, do not gamble, do not lose.</p>
<p>
Over lunch I started to explain to Kathryn why Monte Carlo is an important city for complexity theorists. I felt a bit like we were at a theory shrine.</p>
<p>
</p><p/><h2> Why Randomness Helps </h2><p/>
<p/><p>
Indeed. I realized that it is not so simple to explain why randomness helps. Kathryn has a Ph.D in theatre. She is smart, is a member of Mensa, but is not a complexity theorist. How do I explain that randomness is powerful? Indeed.</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2019/08/randkinmontecarlo2.png"><img alt="" class="aligncenter size-medium wp-image-16186" height="251" src="https://rjlipton.files.wordpress.com/2019/08/randkinmontecarlo2.png?w=300&amp;h=251" width="300"/></a></p>
<p/><p><br/>
I started to explain, but my examples were lame. I think she got the main idea, but I also think that I did not do a great job. Russell Impagliazzo has a nice <a href="https://simons.berkeley.edu/sites/default/files/docs/6119/doesrandomnesshelp.pdf">explanation</a> on the role of randomness—I wish Russell had been there to help explain randomness to Kathryn. </p>
<p>
After lunch I started to think more about the role of randomness. I looked at our friends over at Wikipedia and discovered they had a pretty good <a href="https://en.wikipedia.org/wiki/Applications_of_randomness">page</a>. Some reasons are:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Games</i></p>
<p>
Randomness was first investigated in the context of gambling. Dice, playing cards, roulette wheels, all have been studied by those interested in gambling. Clearly, betting on the roll of dice, deal of cards, or spin of the wheel, only makes sense when these actions are unpredictable. Random. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Political</i></p>
<p>
Randomness is often used to create “fairness”. For example, in the US and UK, juror selection is done by a lottery. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Science</i></p>
<p>
Monte Carlo methods in physics and computer science require random numbers.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Cryptography</i></p>
<p>
Random keys for encryption algorithms should be unpredictable. Random. Otherwise, they can be guessed by others. The password “password” is usually not allowed.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Arts</i></p>
<p>
Kathryn is interested in the arts: in plays and in painting and other fine arts. Some theories of art claim that all art is random. One thinks of artists like Jackson Pollock with his famous drip paintings. He was a major player in the abstract expressionist movement.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/08/jpollock.png"><img alt="" class="aligncenter size-full wp-image-16188" src="https://rjlipton.files.wordpress.com/2019/08/jpollock.png?w=600"/></a></p>
<p/><h2> Pseudo or True? </h2><p/>
<p/><p>
Ken has been paying intensive devotions at the same shrine. As he wrote in the previous <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">post</a>, he has been conducting millions of randomized tests of his new chess model. </p>
<p>
Why random? What he needs to do is show that his model will not tend to “cry wolf” by giving a too-high <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-score to a set of games in a tournament by an honest player. He wants to show that his model is equally tempered no matter the rating of the player. So he runs trials at different rating levels ranging from Elo 1000 for novice players to Elo 2800 which is championship level. To show that the <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-scores given by his model conform to a normal bell curve, he needs to do 10,000s or 100,000s of tests at each level. </p>
<p>
The problem is there just don’t exist enough games. Most large tournaments give only the games played on their “top boards” which use special auto-recording equipment, and the losers on those boards in one round may play on lower boards in the next round. Thus out of about 60,000 player-tournament pairs Ken can track each year, most are only partial samples. So what Ken does is generate “synthetic players” by randomly taking subsets of (say) 9 games—from his data set of 1,000 or so games for each level—and randomly choosing white or black for each game. This is a common <a href="https://en.wikipedia.org/wiki/Resampling_(statistics)#Subsampling">resampling</a> technique, and it uses Monte Carlo.</p>
<p>
Ken uses pseudo-random generators (PRGs). He starts a C++ library PRG on a seed <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> based on the current time. The fact that the choices are deterministic once <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> is given might allow him to reproduce an entire run exactly (after a model tweak) by preserving the <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> it used. This is a paradox: we might want our “random” bits to be deterministic. Monte Carlo with predestined loaded dice.</p>
<p>
From time to time on this blog we have mused about what a world <a href="https://rjlipton.wordpress.com/2013/08/23/a-world-without-randomness/">without</a> randomness or with <a href="https://rjlipton.wordpress.com/2018/04/01/the-entropy-of-baseball/">reduced</a> entropy would be like. We were struck a few weeks ago when the noted physics blogger Sabine Hossenfelder wrote about “<a href="http://backreaction.blogspot.com/2019/07/the-forgotten-solution-superdeterminism.html">superdeterminism</a>.” That post provoked a few hundred comments in her blog, as did her <a href="http://backreaction.blogspot.com/2019/08/the-problem-with-quantum-measurements.html">post</a> last week on the quantum measurement problem—including long exchanges with Peter Shor. Ken and I don’t know which side to take, but I can say that the side of a ship is a great place to think about possible real effects of these differences.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What is your take on randomness? Do you employ it? How “true” do you need it to be? </p>
<p/></font></font></div>
    </content>
    <updated>2019-08-20T16:24:54Z</updated>
    <published>2019-08-20T16:24:54Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="art"/>
    <category term="cruise"/>
    <category term="Kathryn Farley"/>
    <category term="Monte Carlo"/>
    <category term="Peter Shor"/>
    <category term="Physics"/>
    <category term="quantum"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <category term="Sabine Hossenfelder"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-25T04:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/20/algorithms-postdoc-at-university-of-california-berkeley-apply-by-october-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/20/algorithms-postdoc-at-university-of-california-berkeley-apply-by-october-1-2019/" rel="alternate" type="text/html"/>
    <title>Algorithms Postdoc at University of California Berkeley (apply by October 1, 2019)</title>
    <summary>Multiple Postdoctoral positions available to work on Fine-grained Complexity, Approximation Algorithms and Additive Combinatorics. Please email directly to Barna with resume and contact information of three references. The start date is flexible. Website: https://barnasaha.net/ Email: barnas@berkeley.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple Postdoctoral positions available to work on Fine-grained Complexity, Approximation Algorithms and Additive Combinatorics. Please email directly to Barna with resume and contact information of three references. The start date is flexible.</p>
<p>Website: <a href="https://barnasaha.net/">https://barnasaha.net/</a><br/>
Email: barnas@berkeley.edu</p></div>
    </content>
    <updated>2019-08-20T04:00:50Z</updated>
    <published>2019-08-20T04:00:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-25T04:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17848</id>
    <link href="https://gilkalai.wordpress.com/2019/08/19/equiangular-lines-with-a-fixed-angle-and-other-breakthroughs-from-yufei-zhaos-blog/" rel="alternate" type="text/html"/>
    <title>Equiangular lines with a fixed angle and other breakthroughs from Yufei Zhao’s blog</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today I would like to report about some breakthroughs in the area of combinatorics, and about blog posts in Yufei Zhao’s blog that describe these remarkable results (better than I can). Many of the coauthors in these breakthroughs are undergraduate … <a href="https://gilkalai.wordpress.com/2019/08/19/equiangular-lines-with-a-fixed-angle-and-other-breakthroughs-from-yufei-zhaos-blog/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today I would like to report about some breakthroughs in the area of combinatorics, and about blog posts in <a href="https://yufeizhao.wordpress.com/">Yufei Zhao’s blog</a> that describe these remarkable results (better than I can). <span style="color: #993366;"><strong>Many of the coauthors in these breakthroughs are undergraduate students</strong>.</span></p>
<h2><a href="https://arxiv.org/abs/1907.12466">Equiangular lines with a fixed angle</a></h2>
<h3>by Zilin Jiang, Jonathan Tidor, Yuan Yao, Shengtong Zhang and Yufei Zhao.</h3>
<p><a href="https://arxiv.org/abs/1907.12466">Paper </a>; <a href="https://yufeizhao.wordpress.com/2019/07/29/equiangular-lines-with-a-fixed-angle/">blog post</a> (end of July, 2019)</p>
<p>A collection of equiangular lines is a collection of lines so that the angles between every pair of lines in the same?</p>
<p>Here are two classical questions:</p>
<ol>
<li>What is the maximum number of equiangular lines in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>?</li>
<li>Given an angle <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> what is the maximum number of equiangular lines in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>? so that the angle between every two lines is <img alt="\alpha?" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%3F&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha?"/></li>
</ol>
<p>In 2000 Dom de Caen found for the first time an equiangular set of lines in <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> space of size <img alt="cd^2" class="latex" src="https://s0.wp.com/latex.php?latex=cd%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="cd^2"/>. (The crucial observation that one of the graphs in the Cameron–Seidel association scheme has a certain eigenvalue of large multiplicity.  Prior to this construction, the largest sets had sizes of order <img alt="d^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d^{3/2}"/>.  In de Caen’s example the lines have angles approaching 90 degrees, and question 2 for a fixed value of <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> led to very different bounds. (For another result by Dom, see <a href="https://gilkalai.wordpress.com/2011/06/15/the-combinatorics-of-cocycles-and-borsuks-problem/">this post</a>.)</p>
<p>There were some important progress on this problem by Igor Balla, Felix Dräxler, Peter Keevash, and Benny Sudakov, as featured in this  <a href="https://www.quantamagazine.org/a-new-path-to-equal-angle-lines-20170411/">Quanta Magazine article</a> written by Kevin Hartnett. Zilin, Jonathan, Yuan, Shengtong, and Yufei  finished off the problem in a clean and crisp manner, in a 10-page paper with a self-contained proof. On the way they proved the following very interesting theorem.</p>
<p><strong>Theorem:</strong> A bounded degree graph must have sublinear second eigenvalue multiplicity.</p>
<h2><a href="https://arxiv.org/abs/1906.10482">Impartial digraphs</a></h2>
<h3>by Yufei Zhao and Yunkun Zhou.</h3>
<p><a href="https://arxiv.org/abs/1906.10482">Paper</a>, <a href="https://yufeizhao.wordpress.com/2019/06/27/impartial-digraphs/">blog post</a> (end of June 2019)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/yzb.png"><img alt="" class="alignnone size-full wp-image-17875" height="386" src="https://gilkalai.files.wordpress.com/2019/08/yzb.png?w=640&amp;h=386" width="640"/></a></p>
<p><strong>Abstract</strong>: We prove a conjecture of Fox, Huang, and Lee that characterizes directed graphs <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> that have constant density in all tournaments: they are disjoint unions of trees that are each constructed in a certain recursive way.</p>
<p>“Constant density in all tournaments” means that for some <img alt="n_0" class="latex" src="https://s0.wp.com/latex.php?latex=n_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_0"/> (and hence for all <img alt="n \ge n_0" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cge+n_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \ge n_0"/>, every tournament with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices has the same number of copies of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>. (On the nose!)</p>
<p>This result is related to the famous Sidorenko’s conjecture. Let me copy its description from the paper:</p>
<p>For undirected graphs, conjectures of Sidorenko and Erdős–Simonovits (commonly referred to as Sidorenko’s conjecture) say that for every bipartite graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>, the <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>-density in a graph of fixed density is minimized asymptotically by a random graph. Lately the conjecture has been proved for many families of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> though the conjecture remains open in general. In particular, the case <img alt="H = K_{5,5}\backslash C_{10}" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+K_%7B5%2C5%7D%5Cbackslash+C_%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H = K_{5,5}\backslash C_{10}"/> is open.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/yz.jpg"><img alt="" class="alignnone size-full wp-image-17879" height="427" src="https://gilkalai.files.wordpress.com/2019/08/yz.jpg?w=640&amp;h=427" width="640"/></a></h2>
<p><span style="color: #ff0000;"><strong>Yufei Zhao</strong></span></p>
<h2>More</h2>
<p>Let me describe briefly three additional posts on Yufei’s blog with two results from 2018 and one result from 2014.</p>
<h3>Ashwin Sah, Mehtaab Sawhney, David Stoner, and Yufei Zhao  <a href="https://arxiv.org/abs/1809.09462">A reverse Sidorenko inequality</a>; (<a href="https://yufeizhao.wordpress.com/2018/09/25/a-reverse-sidorenko-inequality/">blog post</a>) ; <a href="https://arxiv.org/abs/1805.04021">The number of independent sets in an irregular graph</a>; <a href="https://yufeizhao.wordpress.com/2018/05/12/the-number-of-independent-sets-in-an-irregular-graph/">blog post</a>.</h3>
<p>These are two remarkable papers by the same team of researchers. The paper  on the number of independent sets in a regular graph settled a famous 2001 conjecture by Jeff Kahn. An earlier breakthrough on the problem was made by Zhao in 2009 when he was an undergraduate student.</p>
<h3><a href="http://research.microsoft.com/en-us/um/people/eyal/">Eyal Lubetzky</a> and Yufei Zhao,  <em><a href="http://arxiv.org/abs/1402.6011">On the variational problem for upper tails of triangle counts in sparse random graphs</a></em>. <a href="https://yufeizhao.wordpress.com/2014/02/25/upper-tail/">Blog post</a>.</h3>
<p>Recently  I wrote a post <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="bookmark">Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</a> describing a major breakthrough on the infamous upper tail problem. Over the years I heard a lot of lectures and private explanation on upper tails and the remarkable related mathematics. I remember lectures by Kim and Vu from the early 2000’s and by Varadhan from ICM 2010 describing (among other things) the fundamental paper by  <a href="http://www.ams.org/mathscinet-getitem?mr=2825532">Chatterjee and Varadhan</a>,  and later works by  <a href="http://www.ams.org/mathscinet-getitem?mr=2925307">DeMarco and Kahn, </a> and by  <a href="http://arxiv.org/abs/1401.3495">Chatterjee and Dembo</a>  and Lubetzky and Zhao and others. But when I wrote the post I realized my knowledge is too sparse for giving a thorough description, and I decided not to wait and write a short post. This post by Yufei describes some of the history very nicely as well as the major papers by Eyal and Yufei from 2012 and 2014.</p></div>
    </content>
    <updated>2019-08-19T18:33:52Z</updated>
    <published>2019-08-19T18:33:52Z</published>
    <category term="Combinatorics"/>
    <category term="Ashwin Sah"/>
    <category term="David Stoner"/>
    <category term="Eyal Lubetzky"/>
    <category term="Jonathan Tidor"/>
    <category term="Mehtaab Sawhney"/>
    <category term="Shengtong Zhang"/>
    <category term="Yuan Yao"/>
    <category term="Yufei Zhao"/>
    <category term="Yunkun Zhou"/>
    <category term="Zilin Jiang"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-25T04:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/107</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/107" rel="alternate" type="text/html"/>
    <title>TR19-107 |  The Power of a Single Qubit: Two-way Quantum/Classical Finite Automata and the Word Problem for Linear Groups | 

	Zachary Remscrim</title>
    <summary>The two-way quantum/classical finite automaton (2QCFA), defined by Ambainis and Watrous, is a model of quantum computation whose quantum part is extremely limited; however, as they showed, 2QCFA are surprisingly powerful: a 2QCFA, with a single qubit, can recognize, with one-sided bounded-error, the language $L_{eq}=\{a^m b^m |m \in \mathbb{N}\}$ in expected polynomial time and the language $L_{pal}=\{w \in \{a,b\}^*|w \text{ is a palindrome}\}$ in expected exponential time.  

We further demonstrate the power of 2QCFA by showing that they can recognize the word problems of a broad class of groups. In particular, we first restrict our attention to 2QCFA that: $(1)$ have a single qubit, $(2)$ recognize their language with one-sided bounded-error, and $(3)$ have transition amplitudes which are algebraic numbers. We show that such 2QCFA can recognize the word problem of any finitely-generated virtually abelian group in expected polynomial time, as well as the word problem of a large class of linear groups in expected exponential time. This latter class includes all groups whose word problem is a context-free language as well as all groups whose word problem is known to be the intersection of finitely many context-free languages. As a corollary, we obtain a direct improvement on the original Ambainis and Watrous result by showing that $L_{eq}$ can be recognized by a 2QCFA with better parameters. 

We also consider those word problems which a 2QCFA can recognize with one-sided unbounded-error, and show that this class includes the word problem of more exotic groups such as the free product of any finite collection of finitely-generated free abelian groups. As a corollary of this result, we demonstrate that a new class of group word problems are co-stochastic languages. Lastly, we exhibit analogous results for 2QCFA with any finite number of qubits or with more general transition amplitudes, as well as results for other classic QFA models.</summary>
    <updated>2019-08-18T13:27:03Z</updated>
    <published>2019-08-18T13:27:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/106</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/106" rel="alternate" type="text/html"/>
    <title>TR19-106 |  Semialgebraic Proofs and Efficient Algorithm Design | 

	Noah Fleming, 

	Pravesh Kothari, 

	Toniann Pitassi</title>
    <summary>Over the last twenty years, an exciting interplay has emerged between proof systems and algorithms. Some natural families of algorithms can be viewed as a generic translation from a proof that a solution exists into an algorithm for finding the solution itself. This connection has perhaps been the most consequential in the context of semi-algebraic proof systems and basic primitives in algorithm design such as linear and semidefinite programming. The proof system perspective, in this context, has provided fundamentally new tools for both algorithm design and analysis. These news tools have helped in both designing better algorithms for well-studied problems and proving tight lower bounds on such techniques.

This monograph is aimed at expositing this interplay between proof systems and efficient algorithm design and surveying the state-of-the-art for two of the most important semi-algebraic proof systems: Sherali-Adams and Sum-of-Squares.

We rigorously develop and survey the state-of-the-art for Sherali-Adams and Sum-of-Squares both as proof systems, as well as a general family of optimization algorithms, stressing that  these perspectives are formal duals to one-another. Our treatment relies on interpreting the outputs of the Sum-of-Squares and Sherali-Adams algorithms as generalized expectation functions -- a viewpoint that has been essential in obtaining both algorithmic results and lower bounds. The emphasis is on illustrating the main ideas by presenting a small fraction of representative results with detailed intuition and commentary. The monograph is self-contained and includes a review of the necessary mathematical background including basic theory of linear and semi-definite programming.</summary>
    <updated>2019-08-18T06:14:17Z</updated>
    <published>2019-08-18T06:14:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5432</id>
    <link href="https://adamsheffer.wordpress.com/2019/08/18/abstraction-is-hard/" rel="alternate" type="text/html"/>
    <title>Abstraction is Hard</title>
    <summary>A few weeks ago I read Malcolm Gladwell’s book The Tipping Point. The book doesn’t really deal with mathematics, but it does contain one math-related anecdote. This anecdote demonstrates an interesting principle of learning mathematics, so I wanted to share it. Problem 1. We have a deck of cards, such that each card contains a […]</summary>
    <updated>2019-08-18T02:03:50Z</updated>
    <published>2019-08-18T02:03:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-08-25T04:21:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/17/footprints-in-snow</id>
    <link href="https://11011110.github.io/blog/2019/08/17/footprints-in-snow.html" rel="alternate" type="text/html"/>
    <title>Footprints in the snow</title>
    <summary>Given an abstract optimization problem with multiple solutions, how much partial information about a solution do you have to know in order to uniquely identify that solution? That has been the topic of some of my earlier research, on how many creases of an origami folding pattern you have to force to be mountain or valley folds in order to cause the remaining folds to go the way you want. And it’s the topic of my new preprint “Tracking paths in planar graphs” (arXiv:1908.05445, with Mike Goodrich, James Liu, and Pedro Matias).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Given an abstract optimization problem with multiple solutions, how much partial information about a solution do you have to know in order to uniquely identify that solution? That has been the topic of some of my earlier research, on <a href="https://11011110.github.io/blog/2014/10/08/forced-creases-in.html">how many creases of an origami folding pattern you have to force to be mountain or valley folds in order to cause the remaining folds to go the way you want</a>. And it’s the topic of my new preprint “Tracking paths in planar graphs” (<a href="https://arxiv.org/abs/1908.05445">arXiv:1908.05445</a>, with Mike Goodrich, James Liu, and Pedro Matias).</p>

<p>There’s an old story about how to design the footpaths on a college campus: wait for it to snow, see where the heaviest sets of footprints cross the snow from building to building, and then once the snow melts place paths in those same places. But what if you live somewhere like Irvine where it never snows? Or what if you want to perform some other type of data analysis on a data set of the paths that people take? For instance, in order to design improvements to the road networks used by commuter traffic, it would be helpful to figure out where all the traffic actually goes each day. How can you collect that data?</p>

<p>Our paper takes the point of view that you can attach sensors to the network that record the times and identities of people passing by them, but that these sensors are expensive. The goal is (for a given network with designated start and destination vertices  and ) to place as few of these sensors as possible at graph vertices, in such a way that every simple -path is uniquely identified by the sequence of sensors that it passes through.</p>

<p>The problem turns out to be -complete, even on planar networks. But there’s a simple approximation ratio based on the idea that the optimal number of sensors is always going to be proportional to the number of faces in the network. Each face (in the sequence of biconnected components between  and ) has to have at least one sensor, to distinguish paths that go one way around the face from paths that go the other way around. It turns out that placing one sensor at a vertex shared by many faces doesn’t work — those faces still need a proportional number of additional sensors. And our approximation algorithm ensures that the number of sensors is at most proportional to the number of faces.</p>

<p>We also use <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a> to prove that the exact solution is fixed-parameter tractable in the clique-width of the graph. Like most or all uses of Courcelle’s theorem, the resulting algorithm is impractical, so it would be of interest to find a more direct algorithm, perhaps for a weaker parameter.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102634545213040458">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-17T14:42:00Z</updated>
    <published>2019-08-17T14:42:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/105</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/105" rel="alternate" type="text/html"/>
    <title>TR19-105 |  A note on the relation between XOR and Selective XOR Lemmas | 

	Ragesh Jaiswal</title>
    <summary>Given an unpredictable Boolean function $f: \{0, 1\}^n \rightarrow \{0, 1\}$, the standard Yao's XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in [k]}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$, whereas the Selective XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in S}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$ and $S \subseteq \{1, ..., k\}$. We give a reduction from the Selective XOR lemma to the standard XOR lemma. Our reduction gives better quantitative bounds for certain choice of parameters and does not require the assumption of being able to sample $(x, f(x))$ pairs.</summary>
    <updated>2019-08-16T08:16:51Z</updated>
    <published>2019-08-16T08:16:51Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16160</id>
    <link href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/" rel="alternate" type="text/html"/>
    <title>Predicting Chess and Horses</title>
    <summary>Using predictivity both to sharpen and cross-check models Cropped from article source Patrice Miller and Jeff Seder look under the hide of horses. Their company EQB does predictive modeling for horse racing based on biometric data. They are famous for having advised the owner of American Pharoah not to sell because the horse had a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Using predictivity both to sharpen and cross-check models</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/patti-miller-and-jeff-seder-of-eqb-agents-consulting-2/" rel="attachment wp-att-16163"><img alt="" class="aligncenter wp-image-16163" height="204" src="https://rjlipton.files.wordpress.com/2019/08/patti-miller-and-jeff-seder-of-eqb-agents-consulting-1.jpg?w=212&amp;h=204" width="212"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from article <a href="https://www.inverse.com/article/31250-jeff-seder-kentucky-derby-horse-genetics-big-data">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Patrice Miller and Jeff Seder look under the hide of horses. Their company <a href="https://www.eqb.com/">EQB</a> does predictive modeling for horse racing based on biometric data. They are famous for having <a href="https://www.nytimes.com/2015/06/05/sports/american-pharoah-cant-erase-all-of-ahmed-zayats-missteps.html">advised</a> the owner of American Pharoah not to sell because the horse had a powerful heart. In 2015, American Pharoah became the first Triple Crown winner since the also-hearty Secretariat in 1978.</p>
<p>
Today I am happy to announce an extended version of my predictive model for chess and discuss how it gains accuracy by looking under the hood of chess positions.<br/>
<span id="more-16160"/></p>
<p>
I had thought to credit Charles Babbage and Ada Lovelace for being the first to envision computational predictive modeling, but the evidence connected to her design of betting schemes for horse racing is scant and <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/babbage/bio.htm">secondhand</a> <a href="https://blog.stephenwolfram.com/2015/12/untangling-the-tale-of-ada-lovelace/">accounts</a> <a href="https://books.google.com/books?id=RUDdYIL5TG0C&amp;pg=PR21&amp;lpg=PR21&amp;dq=charles+babbage+horse+races&amp;source=bl&amp;ots=VxqMznLIj0&amp;sig=ACfU3U0d6jICkDy2sSZ0MVlPyLQT_rGj6g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj5iNLB_ITkAhUB2VkKHYMyAoA4ChDoATAEegQICRAB#v=onepage&amp;q=charles babbage horse races&amp;f=false">differ</a>. It is known that Babbage compiled voluminous data on the medical fitness and diet of animals, including heart function by taking their pulse. We have discussed their computing work <a href="https://rjlipton.wordpress.com/2010/03/23/its-ada-lovelace-day/">here</a> and <a href="https://rjlipton.wordpress.com/2015/02/17/ada-the-amplifier/">here</a>. </p>
<p>
I will use horse racing as a device for explaining the main new ingredient of my model. It sharpens the prediction of moves—and the results of cheating tests—by using deeper information to “beat the bookie” as Lovelace tried to do. I have described the basic form of my model—and previous efforts to extend it—in <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">previous</a> <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">posts</a> <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">on</a> <a href="https://rjlipton.wordpress.com/2012/03/30/when-is-a-law-natural/">this</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">blog</a>. Last month, besides being involved in <a href="https://www.spiegel.de/sport/sonst/schach-wie-der-weltverband-betrueger-erwischt-a-1277439.html">several</a> <a href="https://www.foxnews.com/world/chess-grandmaster-caught-using-phone-inside-bathroom-during-a-tournament">media</a> <a href="https://www.chess.com/news/view/igors-rausis-58-under-investigation-of-cheating">stories</a> involving a grandmaster caught in the act of cheating in France, I was invited to discuss this work by Ben Johnson for his “Perpetual Chess” <a href="https://www.perpetualchesspod.com/new-blog/2019/7/23/episode-136-im-kenneth-regan">podcast</a>.</p>
<p>
</p><p/><h2> Betting the Favorite </h2><p/>
<p/><p>
My chess model does the same thing to a chess position—given information about the skill set of the player deciding on a move—that a bookie does to a horse race. It sets odds on each legal move <img alt="{m_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_i}"/> to “win” by being played in the game. The probabilities <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> need to be accurate for the same reason bookmakers need their “initial betting lines” to be close to how bets will ultimately balance, so they can preserve their <a href="https://en.wikipedia.org/wiki/Vigorish">margin</a>. A horse with highest <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/>—perhaps a tie—is the bookie’s <em>favorite</em>. The favorite might be “odds-on,” meaning <img alt="{p_i \gg 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i \gg 0.5}"/>, or might be a “narrow favorite” among several horses with near-equal chances.</p>
<p>
Suppose you don’t care how much money you might win but just want to maximize your chance of being right—of winning something. Unless you have reason to doubt the bookie, you should bet on the favorite. That is what my basic chess model does. Whichever move is given the highest value by the computer at the end of its search is declared the favorite, regardless of the player’s <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a> or other skill factors. </p>
<p>
That the best move—we’ll label it <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/>—should <em>always</em> be most likely even for the weakest players runs counter to sense. Aren’t weaker players weaker because they prefer weaker moves? When the right move is obvious, say a forced recapture or a checkmate in one, of course we expect any player to find it. But when <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/> is subtle, what then? </p>
<p/><p><br/>
My basic model still makes it the favorite. This doesn’t mean its probability <img alt="{p_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1}"/> is greater than half. My model might make <img alt="{p_1 \gg 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1 \gg 0.5}"/> for world champion level players but only, say, <img alt="{p_1 = 0.25}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1+%3D+0.25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1 = 0.25}"/> for beginning players. Thus it will still say the beginner is 75% likely to play an inferior move. What my base model shies away from is saying any other particular move—any other horse—is more likely to win than <img alt="{m_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1}"/>. As the rating gets lower it bunches up the probabilities so that while <img alt="{p_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1}"/> is lower, no other probability passes it.</p>
<p>
This is borne out in practice. The lowest Elo rating used by the World Chess Federation (FIDE) is 1000. Let’s take ratings between that and 1200 (which used to be the lowest rating) as denoting the novice class. Consider only those positions that have many reasonable choices—say at least ten moves valued within 0.25 (figuratively, a quarter of a pawn) of optimal. My main training set has 6.082 such positions in games between evenly-matched players of this level. Here are the frequencies of their playing the best through the tenth-best move in such <em>many-choice positions</em>:</p>
<p align="center">
</p><table align="center">
<tbody><tr>
<td align="right"> Rank </td>
<td align="right"> Pct.</td>
<td/>
<td/>
</tr>
<tr>
<td align="right"> 1 </td>
<td align="right"> 17.76%</td>
</tr>
<tr>
<td align="right"> 2 </td>
<td align="right"> 13.22%</td>
</tr>
<tr>
<td align="right"> 3 </td>
<td align="right"> 9.95%</td>
</tr>
<tr>
<td align="right"> 4 </td>
<td align="right"> 7.66%</td>
</tr>
<tr>
<td align="right"> 5 </td>
<td align="right"> 6.25%</td>
</tr>
<tr>
<td align="right"> 6 </td>
<td align="right"> 5.18%</td>
</tr>
<tr>
<td align="right"> 7 </td>
<td align="right"> 4.41%</td>
</tr>
<tr>
<td align="right"> 8 </td>
<td align="right"> 4.55%</td>
</tr>
<tr>
<td align="right"> 9 </td>
<td align="right"> 3.50%</td>
</tr>
<tr>
<td align="right"> 10 </td>
<td align="right"> 3.03%</td>
</tr>
<tr>
<td align="right"> 11+ </td>
<td align="right"> 24.49%</td>
</tr>
<tr>
<td align="right"> </td>
</tr>
</tbody></table>
<p>
Both my basic model and the new one, when fitted over the entire training set for this class but then restricted to the many-choices subset, give projections close to these actual values. The basic model, always betting the favorite, is right on under 18% of its projections. Can we do better? That is, can we “beat the bookie” at chess? </p>
<p>
</p><p/><h2> Predicting Inferior Moves </h2><p/>
<p/><p>
It is almost four years since the idea for improving predictions was <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">described</a> on this blog. In place of “weaker players prefer weaker moves,” it advanced a hypothesis that we can state as follows:</p>
<blockquote><p><b> </b> <em> Weaker players are more likely to be diverted by shiny objects. </em>
</p></blockquote>
<p/><p>
Most in particular, they will fall for moves that look attractive early on, but which are revealed (by the computer) to be inferior after deeper consideration. The computer programs output values for each depth of search, and when these moves’ values are graphed against the depth, they start high but “swing down” at higher depths. Weaker players are more likely to be satisfied by the early flash and not think deeper. The old <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">post</a> has a great example of such a move from the pivotal game in the 2008 world championship match, where Viswanathan Anand set a deep trap that caught the previous world champion, Vladimir Kramnik. </p>
<p>
The flip side are moves that look poor at low depths but whose high value emerges at high depths. My basic model, which uses only the final values of moves, gives too high a projection on these cases, and too low a likelihood of falling into traps. I have figured that these two kinds of ‘misses’ offset over a few dozen positions. Moreover, in both kinds of misses, the player is given express benefit of doubt by the projections. It is edgier, after all, to project that a player is more likely to fall into a trap than to find the safest and best move.</p>
<p>
The effect of lower-depth values is still too powerful to ignore in identifiable cases. Including them, however, makes the whole model edgier, as I have <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">described</a> here <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">before</a>. Simply put, the lower-depth values are subject to more noise, from which we are trying to extract greater information. It has been like trying to catch lightning—or <a href="https://www.pppl.gov/news/2019/08/improving-magnetic-bottle-controls-fusion-power-earth">fusion</a>—in a bottle.</p>
<p>
</p><p/><h2> Modest But Effective Success </h2><p/>
<p/><p>
My new model implements the “swing” feature without adding any more free parameters for fitting. It has new parameters but those are set “by hand” after an initial fitting of the free parameters under the “sliding-scale” regime I <a href="https://rjlipton.wordpress.com/2018/09/07/sliding-scale-problems/">described</a> last September, which is followed by a second round of re-fitting. It required heavy clamps on the weighting of lower-depth values and more-intense conditioning of inputs overall. It required a solution to the “firewall at zero” <a href="https://rjlipton.wordpress.com/2016/01/21/a-chess-firewall-at-zero/">phenomenon</a> that was the exact opposite of what I’d envisioned.</p>
<p>
After all this, here is what it delivers in the above case—and quite generally:</p>
<blockquote><p><b> </b> <em> It improves the prediction success rate—for the weakest players in the most difficult kind of positions to forecast—from 17.76% to <b>20.04%</b>. </em>
</p></blockquote>
<p/><p>
For the elite class—2600 to 2800—in the same kind of many-choice positions, the new model does even better. Much more data on elite players is available, so I have 49,793 such positions faced by them: </p>
<blockquote><p><b> </b> <em> Whereas elite players found the best move in 30.85% of these difficult positions, my new model finds <b>their</b> move in <b>34.64%</b> of them. </em>
</p></blockquote>
<p/><p>
Over all positions, the average <em>prediction gain</em> ranges from about 1 percentage point for the lowest players to over 2% for masters. These gains may not sound like much, but for cheating tests they give prime value. The reasons are twofold:</p>
<ul>
<li>
The gained predictions are all <em>against</em> their finding the computer’s move, so the act of finding the best move is more exposed. <p/>
</li><li>
The standard deviation is typically 3–5 percentage points depending on the volume of moves. Thus the prediction gain can enhance the measured <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> by upwards of 0.5 or more.
</li></ul>
<p>
Initial applications in recent cases seem to prove this out more often than not. Of course, the larger purpose is to have a better model of human chess play overall.</p>
<p>
</p><p/><h2> Cross-Checks and Caveats </h2><p/>
<p/><p>
In recent years, several new dimensions of quality and safety with predictive models have emerged. They supplement the two classic ones:</p>
<ul>
<li>
<em>Avoiding false positives.</em> In particular, over a natural population (such as the mass of honest players), the rate of outlier scores generated by the model must stay within the bounds of natural frequency for the population. Call this “natural safety.” <p/>
</li><li>
<em>Avoiding false negatives</em>. The model should provide enough <a href="https://en.wikipedia.org/wiki/Power_(statistics)">statistical power</a> to flag unnatural outliers without becoming unsafe.
</li></ul>
<p>
I vetted my model’s natural safety by processing tens of millions of generated z-scores under resampling after my final design tweaks earlier this month. This was over a link between departmental machines and UB’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>) where my data is generated. The previous discussion has all been about greater power. The first new factor updates the idea of <a href="https://en.wikipedia.org/wiki/Calibration_(statistics)#In_prediction_and_forecasting">calibration</a>:</p>
<ul>
<li>
<em>Non-bias and fairness.</em> More general than the societal context, which we discussed <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">here</a>, this means avoiding bias along functional lines that the model is not intended to distinguish.
</li></ul>
<p>
I have a suite of cross-checking measures besides those tests that are expressly fitted to be unbiased estimators. They include checking how my model performs on various different types of positions, such as those with many choices as above, or the opposite: those having one standout move. For example, the model’s best-move projection in the many-choice positions by elite players, using the general settings for 2700 rating, is 31.07%. That’s within 0.28%. Another check is figuratively how much “probability money” my model wagered to get its 34.64% hit rate. The sum of <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> it projected on its own most-likely moves, in the 68.4% of the many-choice positions where it agreed with the computer’s favorite plus 31.6% where it did not, was 35.00%. If I fit all 282,060 positions by these players, rather than use “2700,” and then re-select the subset, the model comes within <b>0.01%</b> on the first-move projection and <b>0.11%</b> on its own betting forecasts. I will say more about the cross-checks, use of <a href="https://en.wikipedia.org/wiki/Brier_score">prediction</a>–<a href="https://en.wikipedia.org/wiki/Score_(statistics)">scoring</a> <a href="https://en.wikipedia.org/wiki/Scoring_rule">metrics</a>, and conformance to normal distribution at a later time. The relevant point is to ask:</p>
<blockquote><p><b> </b> <em> How well does your model perform on pertinent tests besides those it was expressly trained for? </em>
</p></blockquote>
<p/><p>
Beyond fairness, good <em>wide-range</em> calibration alleviates dangers of “mission creep.” </p>
<p>
The second newer factor is:</p>
<ul>
<li>
<em><a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adversarial</a> performance.</em> This is apart from “natural safety.” Simply put: how resistant is the model to being deceived? Can it be gamed?
</li></ul>
<p>
My impressions over the long haul of this work is that the new model’s more-powerful heart inevitably brings greater “springiness.” By dint of its being more sensitive to moves whose high value emerges only after deep search, it is possible to create shorter sequences of such moves that make it jump to conclusions. The z-score vetting turned up a few games that were agreed drawn after some “book” moves—openings known by heart to many professional players—whose entirety the model would flag, except for the standard procedure of identifying and removing book moves from cheating tests. These outliers came from over a hundred thousand games between evenly-matched players, so they still conformed to the natural rate, but one can be concerned about the “unnatural rate.” On the flip side, I believe my more-intensive conditioning of values has made the model more robust against being gamed by cheaters playing a few inferior moves to cover their tracks. </p>
<p>
In general, and especially with nonlinear models, the caveat is that amplifying statistical power brings greater susceptibility to adversarial conditions. Trying to “beat the bookie” requires more model introspection. My model retains its <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainability</a> and ability to provide audits for its determinations. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What lessons from similar situations with other predictive models can be identified and brought to bear on this one?</p>
<p>
<b>Update 8/24:</b> Here is a timely <a href="https://cse.buffalo.edu/~regan/chess/computer/ModelTradeoffs.png">example</a> of the tradeoff between amplifying the prediction accuracy and the overall stability of the model.</p></font></font></div>
    </content>
    <updated>2019-08-16T00:52:25Z</updated>
    <published>2019-08-16T00:52:25Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Ada Lovelace"/>
    <category term="algorithmic fairness"/>
    <category term="Charles Babbage"/>
    <category term="cheating"/>
    <category term="horse racing"/>
    <category term="Jeff Seder"/>
    <category term="model safety"/>
    <category term="Patrice Miller"/>
    <category term="predictive modeling"/>
    <category term="predictivity"/>
    <category term="statistical power"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-25T04:20:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/08/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Tricolor pyramids (). In this logic puzzle by @jsiehler, you have to 3-color hexagonal tiles avoiding 2-colored upright triangles. What interests me is not that, but the following: it’s the time-space diagram of a 3-state cellular automaton (with time flowing upward and each cell taking the color that makes the triangle below it work). But turned it’s still the time-space diagram of the same automaton! I haven’t seen this sort of CA symmetry before.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/pyramids-start.html">Tricolor pyramids</a> (<a href="https://mathstodon.xyz/@11011110/102546072670351246"/>). In this logic puzzle by @jsiehler, you have to 3-color hexagonal tiles avoiding 2-colored upright triangles. What interests me is not that, but the following: it’s the time-space diagram of a 3-state cellular automaton (with time flowing upward and each cell taking the color that makes the triangle below it work). But turned  it’s still the time-space diagram of the same automaton! I haven’t seen this sort of CA symmetry before.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/08/02/publicsphere-v-elsevier.html">Elsevier sends copyright threat to site for linking to Sci-Hub</a> (<a href="https://mathstodon.xyz/@11011110/102551592262978036"/>). Apparently if you tell people they can find free copies of paywalled journal papers on pirate web site sci-hub, and link directly to sci-hub to make it even easier to find free copies of paywalled journal papers, you get a nasty letter from the corporate leeches who made it necessary to set up a pirate web site for free copies of paywalled journal papers . But if you <a href="https://en.wikipedia.org/wiki/Sci-Hub">go to Wikipedia</a> you can find the link in the infobox. And it turns out that <a href="https://eve.gd/2019/08/03/elsevier-threatens-others-for-linking-to-sci-hub-but-does-it-itself/">Elsevier journals themselves contain plenty of links to sci-hub</a> (<a href="https://boingboing.net/2019/08/03/zero">via</a>). Sci-hub sci-hub sci-hub.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@Breakfastisready/102554576764536048">@Breakfastisready recommends the new graphic novel “Prime Suspects”</a>, by Andrew and Jennifer Granville with illustrations by Robert J. Lewis: “It’s all about analytic number theory in metaphors.”</p>
  </li>
  <li>
    <p><a href="https://mati.naukas.com/">Mati y sus mateaventuras</a> (<a href="https://mathstodon.xyz/@11011110/102559401183096120"/>), blog of popularized mathematics stories by mathematician Clara Grima and illustrator Raquel Gu (in Spanish). The latest one (from a year ago; it hasn’t updated much recently) is <a href="https://en.wikipedia.org/wiki/Wythoff%27s_game">on Wythoff’s game</a>.</p>
  </li>
  <li>
    <p><a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Manu suggests reducing our impact on the planet by making conferences virtual</a> (<a href="https://mathstodon.xyz/@11011110/102568139862446088"/>). Or we could, you know, publish our papers in journals instead of conferences, like everyone else, and not need to go to quite so many conferences.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html">Why modern integer factoring algorithms have the time bounds they do, and what would be needed to improve them</a> (<a href="https://mathstodon.xyz/@11011110/102577633871564197"/>).</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/08/08/california-scientists-pull-support-elsevier-journals">The University of California’s fight with Elsevier spills over to editorships</a> (<a href="https://mathstodon.xyz/@11011110/102584940498877427"/>). 30 UC editors of Elsevier journals “will no longer provide editorial services” to Elsevier unless/until a satisfactory deal with Elsevier is reached.</p>
  </li>
  <li>
    <p><a href="https://senate.universityofcalifornia.edu/_files/reports/rm-jn-racialization-academic-espionage-concerns.pdf">A letter from the University of California Academic Council</a> (<a href="https://mathstodon.xyz/@11011110/102601263075559877"/>) expressing their alarm at “the increasingly racialized ways in which international scholars and students—especially those from China, Iran, and Russia—are being targeted in national conversations about academic espionage” and their support for the open exchange of research.</p>
  </li>
  <li>
    <p><a href="https://blogs.scientificamerican.com/roots-of-unity/the-longest-matrilineal-chain-in-math/">The longest matrilineal chain in math</a> (<a href="https://mathstodon.xyz/@11011110/102604836636431847"/>). Evelyn Lamb finds “five advisor-advisee chains of length four containing only women” in the Mathematics Genealogy Project, all starting with Olga Ladyzhenskaya and her student Nina Ivochkina. But her searches were haphazard so there may be longer ones still to find.</p>
  </li>
  <li>
    <p><a href="https://mathenchant.wordpress.com/2018/08/16/knots-and-narnias/">Knots and Narnias</a> (<a href="https://mathstodon.xyz/@11011110/102613921012752632"/>). Riffing on a video of a Bill Thurston lecture, Jim Propp explains that when a portal to another dimension has a knotted boundary, it can actually be a portal to several other dimensions.</p>
  </li>
  <li>
    <p><a href="https://gi.de/meldung/konrad-zuse-medaille-dorothea-wagner-erhaelt-hoechste-informatik-auszeichnung/">Dorothea Wagner wins the 2019 Konrad Zuse Medal</a> (<a href="https://mathstodon.xyz/@11011110/102616186862477955"/>). This is the highest award of the German Computer Science Society, and the first time since its establishment in 1987 that the winner is a woman. Dorothea’s research includes graph drawing, route planning, optimization, and social network analysis; see <a href="https://en.wikipedia.org/wiki/Dorothea_Wagner">her Wikipedia article</a> for more.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/new-proof-settles-how-to-approximate-numbers-like-pi-20190814/">Duffin–Schaeffer conjecture solved</a> (<a href="https://mathstodon.xyz/@11011110/102623251151301461"/>, <a href="https://arxiv.org/abs/1907.04593">original paper</a>). This is about finding rational approximations to irrational numbers, like . Given a criterion for how good an approximation you want, depending only on the denominator (for instance, allowing only prime denominators and seeking an approximation accurate to  for denominator ) the new theorem tells you when almost all irrationals have a good-enough approximation.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-08-15T16:07:00Z</updated>
    <published>2019-08-15T16:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16151</id>
    <link href="https://rjlipton.wordpress.com/2019/08/11/leaps-and-bounds-practice-meets-theory/" rel="alternate" type="text/html"/>
    <title>Leaps and Bounds: Practice Meets Theory</title>
    <summary>Solving the runtime selection problem Composite from src1, src2 Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s workshop at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.” Today I will discuss their talks, which I enjoyed greatly at the workshop. The workshop’s general theme was the use of machine-learning techniques […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Solving the runtime selection problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png"><img alt="" class="alignright wp-image-16153" height="129" src="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png?w=180&amp;h=129" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite from <a href="https://www.microsoft.com/en-us/research/people/brlucier/">src1</a>, <a href="https://www.microsoft.com/en-us/research/video/sparse-stochastic-bandits/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s <a href="http://www.cs.cmu.edu/~ckingsf/AutoAlg2019/">workshop</a> at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.”</p>
<p>
Today I will discuss their talks, which I enjoyed greatly at the workshop.<br/>
<span id="more-16151"/></p>
<p>
The workshop’s general theme was the use of machine-learning techniques to improve the tuning of algorithms. Indeed, the goal is to have the algorithm tune itself by selecting strategies from a collection of possible ones. Besides better performance with less human work, this promises better logical reliability than with hand-tuning programs and debugging. </p>
<p>
A common component of this work used in both talks is an interesting oracle model. Since oracles are familiar to many of us theorists this will give us an avenue into the talks and the <a href="https://pdfs.semanticscholar.org/0dce/10ed863423e2e9b1b77a0becfc23111578be.pdf">two</a> recent <a href="https://arxiv.org/pdf/1807.00755.pdf">papers</a> they were based on.</p>
<p>
</p><p/><h2> Runtime Oracles </h2><p/>
<p/><p>
The oracle has a nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> of shape <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/>. Think of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> as the <i>runtime</i> of the <img alt="{i^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i^{th}}"/> program on the <img alt="{j^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j^{th}}"/> input. You know <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, but must ask the oracle for information about <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/>. You may ask the oracle a question <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/>:</p>
<blockquote><p><b> </b> <em> <i>Is the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> less than or equal to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>?</i> </em>
</p></blockquote>
<p/><p>
Here <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is a time bound. Further they assume that the oracle charges you 	</p>
<p align="center"><img alt="\displaystyle  \min(R(i,j),t). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin%28R%28i%2Cj%29%2Ct%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min(R(i,j),t). "/></p>
<p>Thus an algorithm is charged in total 	</p>
<p align="center"><img alt="\displaystyle  \sum_{t} \min(R(i,j),t), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%7D+%5Cmin%28R%28i%2Cj%29%2Ct%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{t} \min(R(i,j),t), "/></p>
<p>where the sum is over all questions <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/> you asked. 	 The rationale is that the oracle can run a program <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> on a task <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and stop after at most <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> steps. Thus returning the minimum is realistic. Since their research is motivated by practical problems, this is a useful model for studying questions about program performance. </p>
<p>
In passing I believe the reason this oracle model is new is that theorists do not often think about running arbitrary programs. Well those in recursion type did, but those designing classic algorithms do not. </p>
<p>
</p><p/><h2> A Selection Problem </h2><p/>
<p/><p>
This model to used to study a selection problem. Assume <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is as above. The task is to find the row with the smallest row sum <img alt="{s_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_{i}}"/>: </p>
<p align="center"><img alt="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%3D+%5Csum_%7Bj%3D1%7D%5E%7BM%7D+R%28i%2Cj%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). "/></p>
<p>That is to find the program that takes the least total time on the inputs—hence the least average time.</p>
<p>
The trouble is that in the worst case this can require examining all the entries. So they introduce approximations to make the problem doable, but still useful in practice:</p>
<ol>
<li>
The rows need only be a <img alt="{(1+\epsilon)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2B%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1+\epsilon)}"/> approximation to the smallest row. <p/>
</li><li>
The entries can be assumed to be truncated by a value <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tau}"/>. That is you can assume that 	<p/>
<p align="center"><img alt="\displaystyle  R(i,j) \le \tau. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28i%2Cj%29+%5Cle+%5Ctau.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  R(i,j) \le \tau. "/></p>
</li><li>
The governing algorithm can be randomized and need only meet the performance goal with high probability.
</li></ol>
<p>
Now we can state the problem formally. It is parameterized by <img alt="{(\epsilon, \tau)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C+%5Ctau%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon, \tau)}"/>:</p>
<blockquote><p><b> </b> <em> <b>Runtime Selection Problem (RSP)</b>: Given a matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R}"/> with all entries bounded by <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\tau}"/>, find a row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/> so that 	</em></p><em>
<p align="center"><img alt="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%5Cle+%281+%2B+%5Cepsilon%29s_%7Bk%7D%2C+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, "/></p>
</em><p><em>for all <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, while minimizing the oracle charges for all questions “is <img alt="{R(i,j) \leq t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cleq+t%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j) \leq t}"/>?” that are asked. </em>
</p></blockquote>
<p>The talks gave a variety of randomized algorithms that solve such problems for various parameter assumptions. </p>
<p>
</p><p/><h2> Fast and Slow </h2><p/>
<p/><p>
See their papers for details on the results. The algorithms they have are interesting not only from a theory viewpoint but also in practice. Indeed, they not only prove theorems but also give experimental timings.</p>
<p>
In order to establish some intuition, let’s look at the following simple case. Assume that all entries <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> are either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or some <img alt="{\alpha \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \gg 1}"/>. This is the “fast-or-slow” running time stipulation. As theorists we often are drawn to binary values, so this might be a good case to look at initially.</p>
<p>
The first observation is that we will always ask questions of the form 	</p>
<p align="center"><img alt="\displaystyle  (i, j, 1.0001). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28i%2C+j%2C+1.0001%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (i, j, 1.0001). "/></p>
<p>This gives us the value of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> for almost unit cost: if it is the <img alt="{R(i,j) \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j) \gg 1}"/> case then we are only charged <img alt="{1.0001}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1.0001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1.0001}"/>. Thus, we have reduced the original problem to a classic oracle problem. There is no complicated oracle cost measure: the cost is just the number of entries we read. Well okay the cost is slightly higher, but we can make it as close as we wish.</p>
<p>
The selection problem then comes down to this: </p>
<ul>
<li>
We have a <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/> nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> whose entries are all either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. <p/>
</li><li>
We must find a row sum that is within a factor of <img alt="{1+\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1+\epsilon}"/> of the smallest.
</li></ul>
<p>
I believe that the analysis of this problem should be generally known. In any event it seems clear that randomly sampling each row is a good start.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Are there other natural problems where the runtime cost oracle is useful?</p>
<p>[Edited typo]</p></font></font></div>
    </content>
    <updated>2019-08-12T02:34:46Z</updated>
    <published>2019-08-12T02:34:46Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="fast"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="Algorithms"/>
    <category term="Brendan Lucier"/>
    <category term="complexity"/>
    <category term="Csaba Szepesvari"/>
    <category term="machine learning"/>
    <category term="oracles"/>
    <category term="practice"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-25T04:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/104</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/104" rel="alternate" type="text/html"/>
    <title>TR19-104 |  Reconstruction of Depth-$4$ Multilinear Circuits | 

	Vishwas Bhargava, 

	Shubhangi Saraf, 

	Ilya Volkovich</title>
    <summary>We present a deterministic algorithm for reconstructing multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits, i.e. multilinear depth-$4$ circuits with fan-in $k$ at the top $+$ gate. For any fixed $k$, given black-box access to a polynomial $f \in \mathbb{F}[x_{1},x_{2},\ldots ,x_{n}]$ computable by a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size $s$, the algorithm runs in time quasi-poly($n,s,{|\mathbb{F}|}$) and outputs a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size quasi-poly($n,s$) that computes $f$. 

Our result solves an open problem posed in \cite{GKL12} (STOC, 2012). Indeed, prior to our work, efficient reconstruction algorithms for multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits were known only for the case of $k=2$ \cite{GKL12, Volkovich17}.</summary>
    <updated>2019-08-11T04:14:43Z</updated>
    <published>2019-08-11T04:14:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/103</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/103" rel="alternate" type="text/html"/>
    <title>TR19-103 |  Query-to-Communication Lifting Using Low-Discrepancy Gadgets | 

	Or Meir, 

	Sajin Koroth, 

	Arkadev Chattopadhyay, 

	Toniann Pitassi, 

	Yuval Filmus</title>
    <summary>Lifting theorems are theorems that relate the query complexity of a function $f:\left\{ 0,1 \right\}^n\to \left\{ 0,1 \right\}$ to the communication complexity of the composed function $f\circ g^n$, for some “gadget” $g:\left\{ 0,1 \right\}^b\times \left\{ 0,1 \right\}^b\to \left\{ 0,1 \right\}$. Such theorems allow transferring lower bounds from query complexity to the communication complexity, and have seen numerous applications in the recent years. In addition, such theorems can be viewed as a strong generalization of a direct-sum theorem for the gadget $g$.

We prove a new lifting theorem that works for all gadgets $g$ that have logarithmic length and exponentially-small discrepancy, for both deterministic and randomized communication complexity. Thus, we significantly increase the range of gadgets for which such lifting theorems hold.

Our result has two main motivations: First, allowing a larger variety of gadgets may support more applications. In particular, our work is the first to prove a randomized lifting theorem for logarithmic-size gadgets, thus improving some applications of the theorem. Second, our result can be seen as a strong generalization of a direct-sum theorem for functions with low discrepancy.</summary>
    <updated>2019-08-11T04:04:36Z</updated>
    <published>2019-08-11T04:04:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://blog.ilyaraz.org/rss/12</id>
    <link href="https://blog.ilyaraz.org/?go=all/cuckoo-hashing-for-sketching-sets/" rel="alternate" type="text/html"/>
    <title>Cuckoo hashing for sketching sets</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>Below I show a neat application of <a href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hashing</a>, which is one of my favorite (cluster of) algorithms. Amazingly, we use it to obtain a purely information-theoretic (rather than algorithmic) statement.</p>
<p>Suppose we have a finite universe $U$ of size $n$ and a $k$-element subset of it $S \subseteq U$ with $k \ll n$. How many bits do we need to encode it? The obvious answer is $\log_2 \binom{n}{k} = \Theta(k \cdot \log(n / k))$.<br/>
Can we, however, improve this bound if we allow some approximation?</p>
<p>Even if $n = 2k$, it is not difficult to show the lower bound of $k \cdot \log_2(1 / \delta)$ bits if we allow to be wrong when answering queries “does $x$ belong to $S$?” with probability at most $\delta$ (hint: $\varepsilon$-nets). Can we match this lower bound?</p>
<p>One approach that does not quite work is to hash each element of $S$ to an $l$-bit string using a sufficiently good hash function $h \colon U \to \{0, 1\}^l$, and, when checking if $x$ lies in $S$, compute $h(x)$ and check if this value is among the hashes of $S$. To see why it does not work, let us analyze it: if $x \notin S$, then the probability that $h(x)$ coincides with at least one hash of an element of $S$ is around $k \cdot 2^{-l}$. To make the latter less than $\delta$, we need to take $l = \log_2(k / \delta)$ yielding the overall bound of $k \cdot \log_2(k / \delta)$ falling short of the desired size.</p>
<p>To get the optimal size, we need to avoid using the union bound in the above argument. In order to accomplish this, let us use perfect hashing on top of the above hashing scheme! It is convenient to use a particular approach to perfect hashing called <a href="https://en.wikipedia.org/wiki/Cuckoo_hashing">Cuckoo hashing</a>. In short, there is a way to generate two simple hash functions $h_1, h_2 \in U \to [m]$ for $m = O(k)$ and place the elements of our set $S$ into $m$ bins without collisions so that for every $x \in S$, the element $x$ is placed either in $h_1(x)$ or in $h_2(x)$. Now, to encode our set $S$, we build a Cuckoo hash table for it, and then for each of the $m$ bins, we either store one bit indicating that it’s empty, or store an $l$-bit hash of an element that is placed into it. Now we can set $l = \log_2(2 / \delta)$, since we compare the hash of a query to merely two hashes, instead of $k$. This gives the overall size $m + k \cdot \log_2 (2 / \delta) = k \cdot (\log_2(1 / \delta) + O(1))$, which is optimal up to a low-order term. Of course, the encoding should include $h_1$, $h_2$ and $h$, but it turns out they can be taken to be sufficiently simple so that their size does not really matter.</p>
<p>Two remarks are in order. First, in this context people usually bring up <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a>. However, they require space, which is $1.44$ times bigger, and, arguably, they are more mysterious (if technically simple). Second, one may naturally wonder why anyone would care about distinguishing bounds like $k \cdot \log_2 (1 / \delta)$ and $k \cdot \log_2(k / \delta)$. In my opinion, there are two answers to this. First, it is just a cool application of perfect hashing (an obligatory link to <a href="https://www.smbc-comics.com/comic/2010-12-09">one of my favorite comic strips</a>). Second, compressing sets is actually important in practice and constant factors do matter, for instance when we are aiming to transfer the set over the network.</p>
<p><b>Update</b> <a href="https://cs.au.dk/~larsen/">Kasper Green Larsen</a> observed that we can combine the naive and not-quite-working solutions to obtain the optimal bound. Namely, by hashing everything to $\log_2(k / \delta)$ bits, we effectively reduce the universe size to $n’ = k / \delta$. Then, the naive encoding takes $\log_2 \binom{n’}{k} \approx H(\delta) \cdot n’ = H(\delta) \cdot k / \delta \approx<br/>
k \cdot \log_2 (1 / \delta)$ bits.</p></div>
    </summary>
    <updated>2019-08-11T01:21:23Z</updated>
    <published>2019-08-11T01:21:23Z</published>
    <source>
      <id>https://blog.ilyaraz.org/</id>
      <author>
        <name>Ilya Razenshteyn</name>
      </author>
      <link href="https://blog.ilyaraz.org/" rel="alternate" type="text/html"/>
      <link href="https://blog.ilyaraz.org/rss/" rel="self" type="application/rss+xml"/>
      <title>Lullaby of Cape Cod</title>
      <updated>2019-08-24T23:29:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/102</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/102" rel="alternate" type="text/html"/>
    <title>TR19-102 |  Testing Isomorphism in the Bounded-Degree Graph Model | 

	Oded Goldreich</title>
    <summary>We consider two versions of the problem of testing graph isomorphism in the bounded-degree graph model: A version in which one graph is fixed, and a version in which the input consists of two graphs.
We essentially determine the query complexity of these testing problems in the special case of $n$-vertex graphs with connected components of size at most $\poly(\log n)$. 
This is done by showing that these problems are computationally equivalent (up to polylogarithmic factors) to corresponding problems regarding isomorphism between sequences (over a large alphabet). 
Ignoring the dependence on the proximity parameter, our main results are: 
\begin{enumerate}
\item 
The query complexity of testing isomorphism to a fixed object (i.e., an $n$-vertex graph or an $n$-long sequence) is ${\widetilde{\Theta}(n^{1/2})$. 
\item 
The query complexity of testing isomorphism between two input objects is ${\widetilde{\Theta}}(n^{2/3})$. 
\end{enumerate}
Testing isomorphism between two sequences is shown to be related to testing that two distributions are equivalent, and this relation yields reductions in three of the four relevant cases. 
Failing to reduce the problem of testing the equivalence of two distribution to the problem of testing isomorphism between two sequences, we adapt the proof of the lower bound on the complexity of the first problem to the second problem.
This adaptation constitutes the main technical contribution of the current work. 

Determining the complexity of testing graph isomorphism (in the bounded-degree graph model), in the general case (i.e., for arbitrary bounded-degree graphs), is left open.</summary>
    <updated>2019-08-10T16:22:55Z</updated>
    <published>2019-08-10T16:22:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-25T04:20:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/10/report-from-cccg</id>
    <link href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html" rel="alternate" type="text/html"/>
    <title>Report from CCCG</title>
    <summary>After WADS, I stayed in Edmonton for CCCG. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">WADS</a>, I stayed in Edmonton for <a href="https://sites.ualberta.ca/~cccg2019/">CCCG</a>. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</p>

<p>Like WADS, CCCG had three invited speakers. In past years, two were named the Paul Erdős Memorial Lecture and the Ferran Hurtado Memorial Lecture. This year, sadly, the third one has also been named, as the Godfried Toussaint Memorial Lecture.</p>

<ul>
  <li>
    <p>The Erdős Lecture was by Vida Dujmović, who spoke on her breakthrough work with several other Barbados workshop participants showing that <a href="https://arxiv.org/abs/1904.04791">every planar graph is a subgraph of a strong product of a path graph and a bounded-treewidth graph</a>, from which it follows that these graphs have bounded <a href="https://en.wikipedia.org/wiki/Queue_number">queue number</a>, that they can be embedded into 3d grids of linear volume, and many other nice properties. The timing of the lecture invitation to Vida was good, as the breakthrough happened after she had already agreed to speak!</p>
  </li>
  <li>
    <p>The Toussaint Lecture was by Joseph O’Rourke. Joe spoke on <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting the boundary of a polyhedron into a surface that can unfold into a simple polygon in the plane. One of the points of his talk was to rationalize some of the terminology in this area. The standard version of the problem asks for (in his new terminology) an <em>edge-unfolding</em>, a set of cuts along edges of the polyhedron, forming a spanning tree for its vertices, such that the resulting cut surface unfolds to a flat polygon. But one can also ask for an anycut-unfolding, using cuts that do not have to follow the edges. Or one can ask for an edge-unzipping or anycut-unzipping, in which the cuts must form a single (Hamiltonian) path through the vertices of the polyhedron. In this terminology <a href="http://www.openproblemgarden.org/op/d_urers_conjecture">Dürer’s conjecture</a> becomes the statement that every convex polyhedron has an edge-unfolding, and the example I recently posted of a <a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">zipless polycube</a> shows that not every polycube has an edge-unzipping. Another well-known open question in this area asks whether every polycube whose boundary forms a topological sphere has an edge-unfolding. Joe conjectured that with high probability the convex hull of many random points on a sphere does not have an anycut-unzipping.</p>
  </li>
  <li>
    <p>Mark de Berg presented the Hurtado Lecture. His topic involved subexponential algorithms for disk intersection graphs and <a href="https://en.wikipedia.org/wiki/Unit_disk_graph">unit disk graphs</a>. At STOC 2018 he had a paper on <a href="https://arxiv.org/abs/1803.10633">finding the maximum independent set in disk graphs</a> in time , matching the time for planar graphs. In planar graphs, you can use the <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">planar separator theorem</a>: for each of the  independent subsets of the separator, recurse on both sides. This turns out to work in disk graphs by replacing the usual size bound on the separator (it should have  vertices) with a decomposition into a union of cliques  with . The separators can be found analogously to classical circle-packing methods for planar separators. Each clique can contribute one vertex to any independent set from which it follows that the separator again has  independent subsets. The same idea works for other problems like dominating sets in unit disk graphs (where the unit assumption is used to get a bounded contribution from each clique), and generalizes to fat objects in higher dimensions. The time bound is optimal assuming the <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">exponential time hypothesis</a>. And in FOCS 2018 de Berg obtained similar <a href="https://arxiv.org/abs/1807.06933">ETH-tight time bounds for the Euclidean traveling salesperson problem</a> by using separators of point sets with the property that few points are very close to the separator boundary.</p>
  </li>
</ul>

<p>I can’t find links for all the contributed papers, but you can find them in the <a href="https://sites.ualberta.ca/~cccg2019/cccg2019_proceedings.pdf">complete proceedings</a>. Among them:</p>

<ul>
  <li>
    <p>In “Three-Coloring Three-Dimensional Uniform Hypergraphs”, Biniaz, Bose, Cardinal, and Payne prove that, for  points in the plane and a fixed triangle shape, one can -color the points so that every scaled and translated copy of the triangle containing six or more points has more than one color. It was already known that if you change “six or more” to “two or more” you need four colors, and if you change it to “nine or more” you need only two colors.</p>
  </li>
  <li>
    <p>Audrey St. John’s talk on “Redundant Persistent Acyclic Formations for Vision-Based Control of Distributed Multi-Agent Formations” (with Burns, Klemperer, and Solyst) was beset by technical difficulties, but from it I learned that there is a theory of directed bar-and-joint frameworks, analogous to undirected rigidity theory, called “persistence theory”, and that the <a href="https://11011110.github.io/blog/2013/12/07/kinematic-chains-and.html">pebble game</a> for testing rigidity of an undirected framework produces an orientation of the network that is persistent. She used the analogy of a flock of geese, walking in formation: each goose pays attention only to the other geese in front, but the whole formation can keep its shape as the leading goose moves arbitrarily. Her goal is to get robots to do the same thing.</p>
  </li>
  <li>
    <p>In “Chirotopes of Random Points in Space are Realizable on a Small Integer Grid”, Cardinal, Fabila-Monroy and Hidalgo-Toscano prove that, with high probability, random point sets in  can be rounded to a grid of polynomial size without changing their order type.</p>
  </li>
  <li>
    <p>We had enough folding and unfolding papers to spill out over more than one section. Among them, I particularly liked “Efficient Segment Folding is Hard” by Klute, Parada, Horiyama, Korman, Uehara and Yamanaka. The question they asked is: given disjoint line segments on a piece of paper, when can you make a sequence of simple folds (that is, for a given fold line, folding all the layers of the paper that are crossed by the line), with each fold on a line through one of the segments that misses all the other segments? It turns out to be -complete. If you do allow fold lines to pass through other segments, folding sequences can be infinite, and it’s unknown whether every set of segments has a finite sequence.</p>
  </li>
  <li>
    <p>Pilar Cano spoke on generating triangulations of point sets in an affine-invariant way (“Affine invariant triangulations” with Bose and Silveira). The main trick is to use covariance to choose a canonical affine transformation for the points, after which you can use Delaunay, minimum weight, or your favorite other triangulation algorithm. But there are necessarily some general position assumptions (as there already are for using Delaunay triangulation without the affine invariance): for points in a parallelogram, there is no affine-invariant way of choosing which diagonal to use.</p>
  </li>
</ul>

<p>The excursion was to the <a href="https://royalalbertamuseum.ca/">Royal Alberta Museum</a>, where I skipped the special exhibit on Vikings (having gone to museum exhibits on them in Copenhagen a year earlier) and instead learned much about Great Plains geology and the historical mistreatment of the <a href="https://en.wikipedia.org/wiki/M%C3%A9tis">Métis</a>, local people descending both from First Nations and Europeans. (The First Nations themselves were of course also badly mistreated, but I had more of an idea of that already.)</p>

<p>From the business meeting, we heard that the acceptance ratio was a little higher than last year, but still approximately . Two papers were withdrawn because the authors had visa issues, double the number from last year, and several others were presented by non-authors after their authors were unable to attend. One possible improvement would be to move the submission and acceptance dates earlier to provide authors more time to obtain visas. The main topic of discussion was the conference’s status as a conference: should papers at CCCG continue to count as publications (in which case why are they still limited to only six pages) or should they be considered as preliminary announcements of papers that can still be sent to other more prestigious symposia? One possible compromise involves giving authors a choice: either publish your paper in the proceedings or give up the proceedings slot but still present your work in some other way (possibly as a poster, as GD does).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102595225020207137">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-10T15:34:00Z</updated>
    <published>2019-08-10T15:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/09/university-alberta-botanic</id>
    <link href="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic.html" rel="alternate" type="text/html"/>
    <title>University of Alberta Botanic Gardens</title>
    <summary>The WADS excursion was to the University of Alberta Botanic Gardens. Here are a few photos I took there:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The WADS excursion was to the University of Alberta Botanic Gardens.
Here are a few photos I took there:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Source Fountain" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain-m.jpg" style="border-style: solid; border-color: black;" width="300"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Jilau Khana" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana-m.jpg" style="border-style: solid; border-color: black;" width="405"/></a></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Mahtabi" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi-m.jpg" style="border-style: solid; border-color: black;" width="390"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock.html"><img alt="University of Alberta Botanic Gardens, Wetland Walk, May's Dock" src="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock-m.jpg" style="border-style: solid; border-color: black;" width="385"/></a></td>
</tr></tbody></table></div>

<p>(<a href="https://mathstodon.xyz/@11011110/102588301669141700">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-09T11:46:00Z</updated>
    <published>2019-08-09T11:46:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17820</id>
    <link href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/" rel="alternate" type="text/html"/>
    <title>Two Important Quantum Announcements!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on … <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on Sundays 14:00-16:00. Second, I would also like to announce The 4th Advanced School in Computer Science and Engineering on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019, at IIAS HUJI.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/ghen.png"><img alt="" class="alignnone size-medium wp-image-17833" height="190" src="https://gilkalai.files.wordpress.com/2019/08/ghen.png?w=300&amp;h=190" width="300"/></a></h2>
<p><span style="color: #ff0000;">Emmy Noether (left) Grete Hermann (right)</span></p>
<h2>A quantum “Kazhdan’s seminar” at HUJI: Computation, quantization, symplectic geometry, and information.</h2>
<p>“In the fall of 2019 Dorit Aharonov, Gil Kalai, Guy Kindler and Leonid Polterovich intend to run a new one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.  The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. (See below for a full description.)”</p>
<p>The course will by on Sundays 14:00-16:00 in Ross building.</p>
<p>See also the post  <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/" rel="bookmark">Symplectic Geometry, Quantization, and Quantum Noise</a> from January 2013. (The seminar was initially planned to 2014 but some bumps in the road delayed it to 2019.)</p>
<h2>A winter school at IIAS: The Mathematics of Quantum Computation</h2>
<p><a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation</a><br/>
The 4th Advanced School in Computer Science and Engineering<br/>
Event date: December 15 – December 19, 2019</p>
<p>“We will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area. (See below for a full description.)</p>
<p>Organizers: Dorit Aharonov, Zvika Brakerski, Or Sattath, Amnon Ta-Shma,</p>
<p dir="LTR"><strong>Main (confirmed) Speakers: </strong>Sergey Bravyi, Matthias Christandl, Sandy Irani, Avishay Tal, Thomas Vidick, (1-2 additional speakers may be added later).</p>
<p dir="LTR"><strong>Additional (confirmed) lectures will be given by: </strong>Dorit Aharonov,  Zvika Brakerski,  and/ Or Sattath. (1-2 additional speakers may be added later).”</p>
<p dir="LTR">The Isreali Institute of Advanced Study hosted already a 2014 <a href="http://www.as.huji.ac.il/schools/phys31">school about quantum information</a> as part of its legendary physics series of schools, and also hosted <a href="https://gilkalai.wordpress.com/2013/04/12/qstart/">QSTART</a> in 2013.</p>
<h2>More details</h2>
<p><span id="more-17820"/></p>
<h3><strong><span style="color: #ff0000;">Kazhdan’s seminar: Computation, quantization, symplectic geometry, and information.</span></strong></h3>
<p>In the fall of 2019 Aharonov, Kalai, Kindler and Polterovich intend to run a new<br/>
one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be<br/>
highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.</p>
<p>The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. Students who attend it will be awarded two N”Z after passing an exam. The goal of the course is to initiate and lead to new connections between the seemingly unrelated areas of quantum computation and symplectic geometry.</p>
<p>The topics will include:</p>
<p>– Introduction to quantum computation, quantum universality, quantum algorithms<br/>
and quantum computational complexity classes such as BQP and Quantum NP (QMA)</p>
<p>– quantum measurement and quantum noise explained using the standard quantum computational model.</p>
<p>– questions about quantum error correction and quantum noise – fault tolerance,<br/>
quantum error correcting codes, and the breakdown of robustness when the locality of<br/>
the noise does not hold.</p>
<p>– quantum measurement/quantum information (noise and speed limit) having classical counterparts, studied from the symplectic geometry perspective.</p>
<p>– Konsevich theorem and quantization,</p>
<p>– towards a the semi classical approximation of quantum computers.</p>
<p>Examples of questions we would like to initiate research on are:</p>
<p>1) what would be a semi classical model of quantum computation, and what would be<br/>
its computational power?</p>
<p>2) what is a good notion of complexity in a symplextic geometry computational model?</p>
<p>3) What can we learn from basic symplectic geometry results (such as non squeezing)<br/>
about the limitations on quantum computation in the semi classical limit?</p>
<p>4) Can noise in quantum computation be related in any way with the semi classical limit<br/>
of quantum computing systems?</p>
<p>5) can we learn anything about the possible noise models in quantum computers,<br/>
using our knowledge from symplectic geometry?</p>
<p>Hope to see you in the course!</p>
<h3><span style="color: #ff0000;"><strong>The Mathematics of Quantum Computation -The 4th Advanced School in Computer Science and Engineering</strong></span></h3>
<p>On 15-19 December 2019, we will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area.</p>
<p>To achieve this, we will have several mini-courses, each of two or three hours, about central topics in the area.   These will include quantum algorithms, quantum error correction, quantum supremacy, delegation and verification, interactive proofs, cryptography, and Hamiltonian complexity. We will emphasize concepts, open questions, and links to mathematics. We will have daily TA sessions with hands-on exercises, to allow for a serious process of learning.</p>
<p>There will be two rounds of registration. The first deadline is 23rd of August. If there is room, there will be another deadline sometime in October; please follow <a href="http://ias.huji.ac.il/SchoolCSE4">this page</a> for further announcements.</p>
<p>Hope to see you this coming December!</p></div>
    </content>
    <updated>2019-08-09T08:58:55Z</updated>
    <published>2019-08-09T08:58:55Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Conferences"/>
    <category term="Quantum"/>
    <category term="Teaching"/>
    <category term="Quantization"/>
    <category term="Quantum computers"/>
    <category term="Quantum mechanics"/>
    <category term="Symplectic geometry"/>
    <category term="Theory of Computing"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-25T04:20:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/" rel="alternate" type="text/html"/>
    <title>Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 27, 2019)</title>
    <summary>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development. Website: https://santafe.edu/sfifellowship Email: sfifellowship@santafe.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development.</p>
<p>Website: <a href="https://santafe.edu/sfifellowship">https://santafe.edu/sfifellowship</a><br/>
Email: sfifellowship@santafe.edu</p></div>
    </content>
    <updated>2019-08-08T19:38:52Z</updated>
    <published>2019-08-08T19:38:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-25T04:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Chennai Mathematical Institute, Chennai, India. (apply by September 30, 2019)</title>
    <summary>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata. Website: http://www.cmi.ac.in Email: registrar@cmi.ac.in</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata.</p>
<p>Website: <a href="http://www.cmi.ac.in">http://www.cmi.ac.in</a><br/>
Email: registrar@cmi.ac.in</p></div>
    </content>
    <updated>2019-08-08T03:48:33Z</updated>
    <published>2019-08-08T03:48:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-25T04:21:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-337501791513204418</id>
    <link href="https://blog.computationalcomplexity.org/feeds/337501791513204418/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html" rel="alternate" type="text/html"/>
    <title>Obstacles to improving Classical Factoring Algorithms</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In Samuel Wagstaff's excellent book The Joy of Factoring (see <a href="https://mathcs.clarku.edu/~fgreen/SIGACTReviews/bookrev/47-2.pdf">here</a> for a review) there is a discussion towards the end about why factoring algorithms have not made much progress recently. I<br/>
paraphrase it:<br/>
<br/>
<br/>
--------------------------------------------------------<br/>
<br/>
The time complexities of the fastest known algorithms can be expressed as a formula of the following form (where N is the number to be factored):<br/>
<br/>
(*)                      exp(c(ln N)^t (ln(ln N))^{1-t})<br/>
<br/>
for some constants c and for 0 &lt; t &lt; 1.  For the Quadratic Sieve (QS) and Elliptic Curve Method (ECM) t=1/2. For the Number Field Sieve (NFS) t=1/3. The reason for this shape for the time complexity is the requirement of finding one or more smooth numbers (numbers that have only small primes as factors).<br/>
<br/>
----------------------------------------------------------<br/>
<br/>
This got me thinking: Okay, there may not be a drastic improvement anytime soon but what about just improving t? Is there a mathematical reason<br/>
why an algorithm with (say) t=1/4 has not been discovered? In an earlier era I would have had to write a letter to Dr. Wagstaff to ask him. Buy an envelope, buy a  stamp, find his address, the whole nine yards (my younger readers should ask their grandparents what envelopes and stamps were). In the current era I emailed him. And got a response.<br/>
<br/>
<br/>
Samuel Wagstaff:<br/>
<br/>
The fastest known factoring algorithms find smooth numbers subject to parameter choice(s).  In all these algorithms, one parameter choice is the smoothness bound B:  a number is smooth if all its prime factors are &lt; B. The NFS has the degree of a polynomial as an additional parameter.<br/>
<br/>
One analyzes the complexity of these algorithms by estimating the total work required (to find enough smooth numbers) for an arbitrary parameter choice using Dickman's function to predict the density of smooth numbers.  Then one uses calculus to find the parameter choice(s) that minimize the total work function.  Calculus also yields the optimal values for the parameter(s).<br/>
<br/>
If you have k parameters to choose, you will get the time complexity (*) with t = 1/(1+k).  If you have no parameters (k = 0),you get (*) with t = 1, basically exponential time N^c.  With one parameter to optimize, as in CFRAC  (continued fractions algorithm) and QS, you get t = 1/2.  NFS has two parameters, so t = 1/3. ECM also has t = 1/2 because it uses only one parameter, the smoothness bound B. If you want to get t = 1/4, you have to find a third parameter to optimize.  No one has found one yet. That is the answer to your question.<br/>
<br/>
Note that some choices made in some factoring algorithms don't count as parameters.  For example, the number of polynomials used in the multiple-polynomial quadratic sieve, and the upper bound on large primes kept, don't affect t.  They affect the running time only in making c smaller.  So you have to find a third parameter that matters in order to get (*) with t = 1/4.  Or find three completely different new parameters.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-08-07T19:27:00Z</updated>
    <published>2019-08-07T19:27:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-24T13:29:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/07/report-from-wads</id>
    <link href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html" rel="alternate" type="text/html"/>
    <title>Report from WADS</title>
    <summary>I’m in Edmonton, Canada for WADS, which just finished, and CCCG, which is just about to begin.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m in Edmonton, Canada for <a href="http://wads.org/">WADS</a>, which just finished, and <a href="http://cccg.ca/">CCCG</a>, which is just about to begin.</p>

<p>The three invited talks at WADS were by Rasmus Pagh, Bob Tarjan, and me. Pagh spoke on methods for representing sets of elements by concise sketches so that the size of intersections or unions of the sets could be rapidly and accurately estimated. A famous method for this is <a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>, in which one represents a set by the  elements with the smallest values of some hash function; the size of the overlap in representations is then an accurate estimator for the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity</a> of pairs of sets. New to me were -bit variations of MinHash, in which you can get almost as accurate a representation in much less space by mapping each element of the MinHash set to  by another hash function. This works well when the Jaccard similarity is bounded away from both  and , and Pagh spoke about some recent research he and others had done on finding even more accurate methods when it is near  or near .</p>

<p>Tarjan spoke about <a href="https://arxiv.org/abs/1812.06177">parallel algorithms for connected components in graphs</a>, an old area but one in which apparently there have been frequent published mistakes. He presented a modular analysis of the algorithms in this area according to some basic operations they perform (hooking together roots of trees on components, propagating that root information downwards through the trees, flattening the trees to make the information propagate more quickly, and the like) and showed that simple combinations of these operations lead to new, simple, efficient and more importantly provably-correct algorithms.</p>

<p>My talk, “Graphs in Nature”, was about finding graph-theoretic characterizations of surface-embedded graphs arising in natural processes, and using those characterizations to find algorithms to reconstruct synthetic geometric structures of the same type from their graphs. I also gave roughly the same talk a month earlier, at the Symposium on Geometry Processing in Milan. <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-19.pdf">I’ve put my talk slides online</a> in case anyone else is interested.</p>

<p>The best paper award went to Hüseyin Acan, Sankardeep Chakraborty, Seungbum Jo and Srinivasa Rao Satti for their paper “<a href="https://arxiv.org/abs/1902.09228">Succinct Data Structures for Families of Interval Graphs</a>”. I can’t tell you much about the talk because, unfortunately, I missed it. I didn’t know it was the best paper until the business meeting that evening, so I went to the other parallel session instead.</p>

<p>I think the contributed talk from Tuesday that most stood out to me was Bryce Sandlund’s, on offline dynamic graph algorithms. This is a type of problem <a href="https://doi.org/10.1006/jagm.1994.1033">I worked on long ago for minimum spanning trees</a> in which you get as input a whole sequence of edge insertions and deletions in a graph, and must produce as output the sequence of changes to the solution to whatever you’re trying to solve. <a href="http://doi.org/10.1007/978-3-030-24766-9_40">Bryce’s new paper with Peng and Sleator</a> solves similar problems for higher-order graph connectivity. The main idea is to hierarchically decompose the update sequence into intervals, and then represent the non-dynamic part of the graph within each interval by a smaller equivalent replacement graph whose size is proportional to the interval length. At the end of his talk, Bryce hinted that he could also solve incremental problems (where the updates are given one at a time rather than all in advance, but are only insertions) using similar methods in a forthcoming paper.</p>

<p>I was inspired by Caleb Levy’s talk on <a href="https://en.wikipedia.org/wiki/Splay_tree">splay trees</a> (in which he showed that <a href="https://arxiv.org/abs/1907.06309">inserting elements in either the preorder or postorder of another binary search tree takes linear time</a>) to ask the following question: we know either by time-reversing the tree rotation operations or from the <a href="https://en.wikipedia.org/wiki/Geometry_of_binary_search_trees">geometric model of dynamic search trees</a> that any given access sequence should have the same optimal cost as its reverse. So from the <a href="https://en.wikipedia.org/wiki/Optimal_binary_search_tree">dynamic optimality conjecture</a> it should also be true that (up to constant factors) splay trees have the same performance on the reverse of any access sequence as they do on the unreversed sequence. Can this be proven?</p>

<p>From the business meeting, we learned that attendance and paper submissions were down by around 15% from the previous WADS. The acceptance rate is roughly the same, just under 50%. I suspect the smaller size is because the location is not as appealing, but it turns out to be a perfectly pleasant place to have a conference: the weather in Edmonton is pleasant this time of year (except for the thunderstorm), and there are abundant restaurants, good coffee shops, and lodging within walking distance of the conference center. WADS alternates with SWAT, which next year will be in the Faroe Islands. And then WADS 2021 (and CCCG 2021) will be in Halifax, Nova Scotia, which is both more touristy than Edmonton and easier to reach from the east coast and Europe. So I suspect the numbers will improve again.</p>

<p>WADS is moving towards a more democratically elected steering committee formed from some combination of past PC chairs and at-large elections. They have already started implementing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">SafeTOC recommendations</a> for combatting harassment and discrimination in theory conferences. And in a show of hands at the business meeting, the attendees were strongly in favor of moving towards double blind peer review for submissions. The conference is not really open access, though (its proceedings are published by Springer LNCS with special issues in Springer’s <em>Algorithmica</em> and Elsevier’s <em>Computational Geometry</em>) and there seems to be little pressure for that to change any time soon.</p>

<p>On to CCCG!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102578298917323647">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-07T17:27:00Z</updated>
    <published>2019-08-07T17:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-23T04:36:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16143</id>
    <link href="https://rjlipton.wordpress.com/2019/08/06/code-it-up/" rel="alternate" type="text/html"/>
    <title>Code It Up</title>
    <summary>So you think you have a proof that P=NP Randi 2014 documentary source James Randi is a magician who has challenged paranormal claims of all kinds. Today Ken and I want to make a suggestion to those who claim they have proved P=NP. No the claim to have a proof that P=NP is not a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>So you think you have a proof that P=NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png"><img alt="" class="alignright wp-image-18" height="192" src="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png?w=144&amp;h=192" width="144"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Randi 2014 documentary <a href="https://en.wikipedia.org/wiki/An_Honest_Liar">source</a></font></td>
</tr>
</tbody>
</table>
<p>
James Randi is a magician who has challenged paranormal claims of all kinds.</p>
<p>
Today Ken and I want to make a suggestion to those who claim they have proved P=NP.<br/>
<span id="more-16143"/></p>
<p>
No the claim to have a proof that P=NP is not a paranormal claim. But such claims are related to Randi—or the Amazing Randi as he is called. We talked about him before <a href="https://rjlipton.wordpress.com/2012/02/23/an-amazing-result/">here</a>.</p>
<p>
Randi once helped run a contest to see who could find gold with their dowsing rod. He explained why he doubted one contestant: </p>
<blockquote><p><b> </b> <em> If they really could find gold, why were they dressed so poorly, and why were they so interested in winning the prize? </em>
</p></blockquote>
<p/><p>
I have the same question about those who claim that they have a proof that P=NP. Usually the proof is constructive and I agree with Randi:</p>
<blockquote><p><b> </b> <em> If they really could solve P=NP, why <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p/><p>
You get the idea.</p>
<p>
Ken adds the obvious remark that if a foreign power or intelligence agency discovered P=NP, or factoring in P, they would still keep the lean-and-hungry look. But they are not the kind we are addressing here.</p>
<p>
</p><p/><h2> Coding Helps </h2><p/>
<p/><p>
Let’s look at a claims that P=NP is resolved. Yes, such a result is unlikely—many would say impossible. But we do get claims like this:</p>
<blockquote><p><b> </b> <em> The following <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> is known to be a NP-complete problem; the following <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> is known to be a polynomial time problem. I can reduce <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> to <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> in polynomial time. </em>
</p></blockquote>
<p/><p>
Usually the reduction is the reason their proof fails. Their claims about <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal H}"/> and <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal E}"/> are usually correct, since they are in the literature. </p>
<p>
The reduction is often complicated, often poorly defined, often defined by example. Giving a precise definition for the reduction is critical. This is the reason we suggest the following: </p>
<blockquote><p><b> </b> <em> <i>Write the reduction down in code.</i> </em>
</p></blockquote>
<p>Even better, write it as a program in a real language such as Python. </p>
<p>
There are two advantages in doing this. </p>
<ul>
<li>
Writing it as a program in a real language will likely force one to define it precisely. <p/>
</li><li>
Writing it down will also allow one to run the program on examples.
</li></ul>
<p>
The later point is the key point. Even trying your method on tiny examples is useful. Even better if you can say the following we might read the proof: </p>
<blockquote><p><b> </b> <em> <i>I have tried my code on the following public set of difficult SAT problems. The code solved all in less than three minutes each.</i> </em>
</p></blockquote>
<p>This claim would greatly improve the likelihood that people might take your claims seriously. That your code worked correctly, forgetting the running time, would improve confidence. Greatly. </p>
<p>
</p><p/><h2> The Animal Farm View<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> </h2><p/>
<p/><p>
Ken worries that some NP-complete problems are more equal than others. That is some problems, even though they are NP-complete may require reductions that blow up when encoding SAT. </p>
<p>
We wrote about this <a href="https://rjlipton.wordpress.com/2012/04/22/the-travelling-salesmans-power/">before</a> regarding the “Power Index” idea of Richard Stearns and Harry Hunt III. In their <a href="http://www.cs.albany.edu/~res/powerindex.pdf">paper</a> they gave evidence that the reductions from SAT <em>to</em> many familiar NP-complete problems <em>must</em> expand the size of instances quadratically, insofar as those problems have <em>power index</em> <img alt="{0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.5}"/>. This was based on their “SAT Hypothesis” which anticipated current forms of the Exponential Time Hypothesis, which we have <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">discussed</a>.</p>
<p>
Ken ponders a related issue. Even problems with power index <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> run into the success of practical solvers. This means: </p>
<blockquote><p><b> </b> <em> Anyone citing algorithmic success as evidence toward a claim of P=NP must compete with the real-world success of algorithms that do not represent claims of P=NP. </em>
</p></blockquote>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/22/rankings-versus-ratings/">times</a> <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">discussed</a> the practical success of SAT-solvers on myriad real-world instances. </p>
<p>
This situation has become real in the argument over achieving quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>. One who claims that quantum is superior to classic must worry that that classical algorithms can improve without making P=NP. A headline example from last year was when Ewin Tang—as a high-school senior—<a href="https://arxiv.org/abs/1807.04271">found</a> a classical way to remove a plausible quantum advantage in a matrix-completion problem that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">underlies</a> recommender systems.  There are many “industrial strength” examples in this argument—see this May 2019 <a href="https://www.technologyreview.com/s/613507/the-new-benchmark-quantum-computers-must-beat-to-achieve-quantum-supremacy/">story</a> for a start.</p>
<p>
</p><p/><h2> But… </h2><p/>
<p/><p>
Ken’s insightful comments aside, the key point is still: </p>
<blockquote><p><b> </b> <em> <i>Coding up your claimed algorithm for that NP-complete problem will still enhance belief.</i> </em>
</p></blockquote>
<p>This will happen even if the algorithm only succeeds on tiny examples. Indeed, if you cannot do this then I suggest that you will have an impossible time getting anyone to listen.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How useful is this advice for the vast majority of us who are <em>not</em> claiming P=NP or the opposite?</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-06T20:45:04Z</updated>
    <published>2019-08-06T20:45:04Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claims"/>
    <category term="complexity"/>
    <category term="heuristic algorithms"/>
    <category term="James Randi"/>
    <category term="programming"/>
    <category term="quantum advantage"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-25T04:20:57Z</updated>
    </source>
  </entry>
</feed>
