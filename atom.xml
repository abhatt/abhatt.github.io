<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-08-14T21:22:12Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04686</id>
    <link href="http://arxiv.org/abs/1908.04686" rel="alternate" type="text/html"/>
    <title>Space-Efficient Construction of Compressed Suffix Trees</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prezza:Nicola.html">Nicola Prezza</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosone:Giovanna.html">Giovanna Rosone</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04686">PDF</a><br/><b>Abstract: </b>We show how to build several data structures of central importance to string
processing, taking as input the Burrows-Wheeler transform (BWT) and using small
extra working space. Let $n$ be the text length and $\sigma$ be the alphabet
size. We first provide two algorithms that enumerate all LCP values and suffix
tree intervals in $O(n\log\sigma)$ time using just $o(n\log\sigma)$ bits of
working space on top of the input BWT. Using these algorithms as building
blocks, for any parameter $0 &lt; \epsilon \leq 1$ we show how to build the PLCP
bitvector and the balanced parentheses representation of the suffix tree
topology in $O\left(n(\log\sigma + \epsilon^{-1}\cdot \log\log n)\right)$ time
using at most $n\log\sigma \cdot(\epsilon + o(1))$ bits of working space on top
of the input BWT and the output. In particular, this implies that we can build
a compressed suffix tree from the BWT using just succinct working space (i.e.
$o(n\log\sigma)$ bits) and any time in $\Theta(n\log\sigma) + \omega(n\log\log
n)$. This improves the previous most space-efficient algorithms, which worked
in $O(n)$ bits and $O(n\log n)$ time. We also consider the problem of merging
BWTs of string collections, and provide a solution running in $O(n\log\sigma)$
time and using just $o(n\log\sigma)$ bits of working space. An efficient
implementation of our LCP construction and BWT merge algorithms use (in RAM) as
few as $n$ bits on top of a packed representation of the input/output and
process data as fast as $2.92$ megabases per second.
</p></div>
    </summary>
    <updated>2019-08-14T01:21:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04673</id>
    <link href="http://arxiv.org/abs/1908.04673" rel="alternate" type="text/html"/>
    <title>Finding and counting permutations via CSPs</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Benjamin Aram Berendsohn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozma:L=aacute=szl=oacute=.html">László Kozma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04673">PDF</a><br/><b>Abstract: </b>Permutation patterns and pattern avoidance have been intensively studied in
combinatorics and computer science, going back at least to the seminal work of
Knuth on stack-sorting (1968). Perhaps the most natural algorithmic question in
this area is deciding whether a given permutation of length $n$ contains a
given pattern of length $k$.
</p>
<p>In this work we give two new algorithms for this well-studied problem, one
whose running time is $n^{k/4 + o(k)}$, and a polynomial-space algorithm whose
running time is the better of $O(1.6181^n)$ and $O(n^{k/2 + 1})$. These results
improve the earlier best bounds of $n^{0.47k + o(k)}$ and $O(1.79^n)$ due to
Ahal and Rabinovich (2000) resp. Bruner and Lackner (2012) and are the fastest
algorithms for the problem when $k \in \Omega(\log{n})$. We show that both our
new algorithms and the previous exponential-time algorithms in the literature
can be viewed through the unifying lens of constraint-satisfaction.
</p>
<p>Our algorithms can also count, within the same running time, the number of
occurrences of a pattern. We show that this result is close to optimal: solving
the counting problem in time $f(k) \cdot n^{o(k/\log{k})}$ would contradict the
exponential-time hypothesis (ETH). For some special classes of patterns we
obtain improved running times. We further prove that $3$-increasing and
$3$-decreasing permutations can, in some sense, embed arbitrary permutations of
almost linear length, which indicates that an algorithm with sub-exponential
running time is unlikely, even for patterns from these restricted classes.
</p></div>
    </summary>
    <updated>2019-08-14T01:53:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04628</id>
    <link href="http://arxiv.org/abs/1908.04628" rel="alternate" type="text/html"/>
    <title>L2P: An Algorithm for Estimating Heavy-tailed Outcomes</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xindi.html">Xindi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Varol:Onur.html">Onur Varol</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eliassi=Rad:Tina.html">Tina Eliassi-Rad</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04628">PDF</a><br/><b>Abstract: </b>Many real-world prediction tasks have outcome (a.k.a.~target or response)
variables that have characteristic heavy-tail distributions. Examples include
copies of books sold, auction prices of art pieces, etc. By learning
heavy-tailed distributions, ``big and rare'' instances (e.g., the best-sellers)
will have accurate predictions. Most existing approaches are not dedicated to
learning heavy-tailed distribution; thus, they heavily under-predict such
instances. To tackle this problem, we introduce \emph{Learning to Place}
(\texttt{L2P}), which exploits the pairwise relationships between instances to
learn from a proportionally higher number of rare instances. \texttt{L2P}
consists of two stages. In Stage 1, \texttt{L2P} learns a pairwise preference
classifier: \textit{is instance A $&gt;$ instance B?}. In Stage 2, \texttt{L2P}
learns to place a new instance into an ordinal ranking of known instances.
Based on its placement, the new instance is then assigned a value for its
outcome variable. Experiments on real data show that \texttt{L2P} outperforms
competing approaches in terms of accuracy and capability to reproduce
heavy-tailed outcome distribution. In addition, \texttt{L2P} can provide an
interpretable model with explainable outcomes by placing each predicted
instance in context with its comparable neighbors.
</p></div>
    </summary>
    <updated>2019-08-14T01:36:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04517</id>
    <link href="http://arxiv.org/abs/1908.04517" rel="alternate" type="text/html"/>
    <title>Beyond the Inverted Index</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Zhi=Hong.html">Zhi-Hong Deng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04517">PDF</a><br/><b>Abstract: </b>In this paper, a new data structure named group-list is proposed. The
group-list is as simple as the inverted index. However, the group-list divides
document identifiers in an inverted index into groups, which makes it more
efficient when it is used to perform the intersection or union operation on
document identifiers. The experimental results on a synthetic dataset show that
the group-list outperforms the inverted index.
</p></div>
    </summary>
    <updated>2019-08-14T01:52:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04512</id>
    <link href="http://arxiv.org/abs/1908.04512" rel="alternate" type="text/html"/>
    <title>Interpolated Convolutional Networks for 3D Point Cloud Understanding</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jiageng Mao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xiaogang.html">Xiaogang Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Hongsheng.html">Hongsheng Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04512">PDF</a><br/><b>Abstract: </b>Point cloud is an important type of 3D representation. However, directly
applying convolutions on point clouds is challenging due to the sparse,
irregular and unordered data structure. In this paper, we propose a novel
Interpolated Convolution operation, InterpConv, to tackle the point cloud
feature learning and understanding problem. The key idea is to utilize a set of
discrete kernel weights and interpolate point features to neighboring
kernel-weight coordinates by an interpolation function for convolution. A
normalization term is introduced to handle neighborhoods of different sparsity
levels. Our InterpConv is shown to be permutation and sparsity invariant, and
can directly handle irregular inputs. We further design Interpolated
Convolutional Neural Networks (InterpCNNs) based on InterpConv layers to handle
point cloud recognition tasks including shape classification, object part
segmentation and indoor scene semantic parsing. Experiments show that the
networks can capture both fine-grained local structures and global shape
context information effectively. The proposed approach achieves
state-of-the-art performance on public benchmarks including ModelNet40,
ShapeNet Parts and S3DIS.
</p></div>
    </summary>
    <updated>2019-08-14T01:56:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04486</id>
    <link href="http://arxiv.org/abs/1908.04486" rel="alternate" type="text/html"/>
    <title>Private Rank Aggregation under Local Differential Privacy</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Ziqi.html">Ziqi Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Gang.html">Gang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Jiqiang.html">Jiqiang Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04486">PDF</a><br/><b>Abstract: </b>In typical collective decision-making scenarios, rank aggregation aims to
combine different agents' preferences over the given alternatives into an
aggregated ranking that agrees the most with all the preferences. However,
since the aggregation procedure relies on a data curator, the privacy within
the agents' preference data could be compromised when the curator is untrusted.
All existing works that guarantee differential privacy in rank aggregation
assume that the data curator is trusted. In this paper, we first formulate and
address the problem of locally differentially private rank aggregation, in
which the agents have no trust in the data curator. We propose an effective and
efficient protocol LDP-KwikSort, with the appealing property that each agent
only needs to answer a small number of pairwise comparison queries from the
untrusted curator with controllable noise, and the aggregated ranking could
maintain an acceptable utility compared with that of the non-private protocol.
Theoretical and empirical results demonstrate that the proposed solution can
achieve the practical trade-off between the utility of aggregated ranking and
the privacy protection of agents' pairwise preferences.
</p></div>
    </summary>
    <updated>2019-08-14T01:21:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04478</id>
    <link href="http://arxiv.org/abs/1908.04478" rel="alternate" type="text/html"/>
    <title>Proceedings Third Joint Workshop on Developments in Implicit Computational complExity and Foundational &amp; Practical Aspects of Resource Analysis</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seiller:Thomas.html">Thomas Seiller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jost:Steffen.html">Steffen Jost</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04478">PDF</a><br/><b>Abstract: </b>These proceedings present the accepted regular papers and some selected
extended abstracts from the 3rd joint DICE-FOPARA workshop, which was held in
Prague, Czech Republic on April 6-7, 2019, as a part of ETAPS. The joint
workshop provides synergies by combining two complementary communities:
</p>
<p>The 10th DICE workshop explores the area of Implicit Computational Complexity
(ICC), which grew out from several proposals to use logic and formal methods to
provide languages for complexity-bounded computation (e.g. Ptime, Logspace
computation). It aims at studying the computational complexity of programs
without referring to external measuring conditions or a particular machine
model, but only by considering language restrictions or logical/computational
principles entailing complexity properties. Several approaches have been
explored for that purpose, such as restrictions on primitive recursion and
ramification, rewriting systems, linear logic, types and lambda calculus,
interpretations of functional and imperative programs.
</p>
<p>The 6th FOPARA workshop serves as a forum for presenting original research
results that are relevant to the analysis of resource (e.g. time, space,
energy) consumption by computer programs. The workshop aims to bring together
the researchers that work on foundational issues with the researchers that
focus more on practical results. Therefore, both theoretical and practical
contributions are encouraged. We also encourage papers that combine theory and
practice.
</p>
<p>This third joint DICE-FOPARA workshop at ETAPS 2019 follows the successful
experiences of co-location of DICE-FOPARA at ETAPS 2015 in London and ETAPS
2017 in Uppsala.
</p></div>
    </summary>
    <updated>2019-08-14T01:21:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04468</id>
    <link href="http://arxiv.org/abs/1908.04468" rel="alternate" type="text/html"/>
    <title>A Fast Spectral Algorithm for Mean Estimation with Sub-Gaussian Rates</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lei:Zhixian.html">Zhixian Lei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luh:Kyle.html">Kyle Luh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venkat:Prayaag.html">Prayaag Venkat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Fred.html">Fred Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04468">PDF</a><br/><b>Abstract: </b>We study the algorithmic problem of estimating the mean of heavy-tailed
random vector in $\mathbb{R}^d$, given $n$ i.i.d. samples. The goal is to
design an efficient estimator that attains the optimal sub-gaussian error
bound, only assuming that the random vector has bounded mean and covariance.
Polynomial-time solutions to this problem are known but have high runtime due
to their use of semi-definite programming (SDP). Conceptually, it remains open
whether convex relaxation is truly necessary for this problem.
</p>
<p>In this work, we show that it is possible to go beyond SDP and achieve better
computational efficiency. In particular, we provide a spectral algorithm that
achieves the optimal statistical performance and runs in time $\widetilde
O\left(n^2 d \right)$, improving upon the previous fastest runtime $\widetilde
O\left(n^{3.5}+ n^2d\right)$ by Cherapanamjeri el al. (COLT '19) and matching
the concurrent work by Depersin and Lecu\'e. Our algorithm is spectral in that
it only requires (approximate) eigenvector computations, which can be
implemented very efficiently by, for example, power iteration or the Lanczos
method.
</p>
<p>At the core of our algorithm is a novel connection between the furthest
hyperplane problem introduced by Karnin et al. (COLT '12) and a structural
lemma on heavy-tailed distributions by Lugosi and Mendelson (Ann. Stat. '19).
This allows us to iteratively reduce the estimation error at a geometric rate
using only the information derived from the top singular vector of the data
matrix, leading to a significantly faster running time.
</p></div>
    </summary>
    <updated>2019-08-14T01:56:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04452</id>
    <link href="http://arxiv.org/abs/1908.04452" rel="alternate" type="text/html"/>
    <title>Multi-objective scheduling on two dedicated processors</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kacem:Adel.html">Adel Kacem</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dammak:Abdelaziz.html">Abdelaziz Dammak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04452">PDF</a><br/><b>Abstract: </b>We study a multi-objective scheduling problem on two dedicated processors.
The aim is to minimize simultaneously the makespan, the total tardiness and the
total completion time. This NP-hard problem requires the use of well-adapted
methods. For this, we adapted genetic algorithms to multiobjective case. Three
methods are presented to solve this problem. The first is aggregative, the
second is Pareto and the third is the NSGA-II algorithm. We proposed some
adapted lower bounds for each criterion to evaluate the quality of the found
results on a large set of instances. The obtained results show the
effectiveness of the proposed algorithms.
</p></div>
    </summary>
    <updated>2019-08-14T01:36:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04409</id>
    <link href="http://arxiv.org/abs/1908.04409" rel="alternate" type="text/html"/>
    <title>Cyclic Oritatami Systems Cannot Fold Infinite Fractal Curves</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Yo=Sub.html">Yo-Sub Han</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Hwee.html">Hwee Kim</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04409">PDF</a><br/><b>Abstract: </b>RNA cotranscriptional folding is the phenomenon in which an RNA transcript
folds upon itself while being synthesized out of a gene. The oritatami system
(OS) is a computation model of this phenomenon, which lets its sequence
(transcript) of beads (abstract molecules) fold cotranscriptionally by the
interactions between beads according to the binding ruleset. The OS is an
useful computational model for predicting and simulating an RNA folding as well
as constructing a biological structure. A fractal is an infinite pattern that
is self-similar across different scales, and is an important structure in
nature. Therefore, the fractal construction using self-assembly is one of the
most important problems. We focus on the problem of generating an infinite
fractal instead of a partial finite fractal, which is much more challenging. We
use a cyclic OS, which has an infinite periodic transcript, to generate an
infinite structure. We prove a negative result that it is impossible to make a
Koch curve or a Minkowski curve, both of which are fractals, using a cyclic OS.
We then establish sufficient conditions of infinite aperiodic curves that a
cyclic OS cannot fold.
</p></div>
    </summary>
    <updated>2019-08-14T01:20:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04381</id>
    <link href="http://arxiv.org/abs/1908.04381" rel="alternate" type="text/html"/>
    <title>Efficient Contraction of Large Tensor Networks for Weighted Model Counting through Graph Decompositions</title>
    <feedworld_mtime>1565740800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Due=ntilde=as=Osorio:Leonardo.html">Leonardo Dueñas-Osorio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04381">PDF</a><br/><b>Abstract: </b>Constrained counting is a fundamental problem in artificial intelligence. A
promising new algebraic approach to constrained counting makes use of tensor
networks, following a reduction from constrained counting to the problem of
tensor-network contraction. Contracting a tensor network efficiently requires
determining an efficient order to contract the tensors inside the network,
which is itself a difficult problem.
</p>
<p>In this work, we apply graph decompositions to find contraction orders for
tensor networks. We prove that finding an efficient contraction order for a
tensor network is equivalent to the well-known problem of finding an optimal
carving decomposition. Thus memory-optimal contraction orders for planar tensor
networks can be found in cubic time. We show that tree decompositions can be
used both to find carving decompositions and to factor tensor networks with
high-rank, structured tensors.
</p>
<p>We implement these algorithms on top of state-of-the-art solvers for tree
decompositions and show empirically that the resulting weighted model counter
is quite effective and useful as part of a portfolio of counters.
</p></div>
    </summary>
    <updated>2019-08-14T01:37:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04272</id>
    <link href="http://arxiv.org/abs/1908.04272" rel="alternate" type="text/html"/>
    <title>Naturally curved quadrilateral mesh generation using an adaptive spectral element solver</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcon:Julian.html">Julian Marcon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopriva:David_A=.html">David A. Kopriva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherwin:Spencer_J=.html">Spencer J. Sherwin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peir=oacute=:Joaquim.html">Joaquim Peiró</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04272">PDF</a><br/><b>Abstract: </b>We describe an adaptive version of a method for generating valid naturally
curved quadrilateral meshes. The method uses a guiding field, derived from the
concept of a cross field, to create block decompositions of multiply connected
two dimensional domains. The a priori curved quadrilateral blocks can be
further split into a finer high-order mesh as needed. The guiding field is
computed by a Laplace equation solver using a continuous Galerkin or
discontinuous Galerkin spectral element formulation. This operation is aided by
using $p$-adaptation to achieve faster convergence of the solution with respect
to the computational cost. From the guiding field, irregular nodes and
separatrices can be accurately located. A first version of the code is
implemented in the open source spectral element framework Nektar++ and its
dedicated high order mesh generation platform NekMesh.
</p></div>
    </summary>
    <updated>2019-08-13T23:38:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04232</id>
    <link href="http://arxiv.org/abs/1908.04232" rel="alternate" type="text/html"/>
    <title>Span Programs and Quantum Space Complexity</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jeffery:Stacey.html">Stacey Jeffery</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04232">PDF</a><br/><b>Abstract: </b>While quantum computers hold the promise of significant computational
speedups, the limited size of early quantum machines motivates the study of
space-bounded quantum computation. We relate the quantum space complexity of
computing a function f with one-sided error to the logarithm of its span
program size, a classical quantity that is well-studied in attempts to prove
formula size lower bounds.
</p>
<p>In the more natural bounded error model, we show that the amount of space
needed for a unitary quantum algorithm to compute f with bounded (two-sided)
error is lower bounded by the logarithm of its approximate span program size.
Approximate span programs were introduced in the field of quantum algorithms
but not studied classically. However, the approximate span program size of a
function is a natural generalization of its span program size.
</p>
<p>While no non-trivial lower bound is known on the span program size (or
approximate span program size) of any concrete function, a number of lower
bounds are known on the monotone span program size. We show that the
approximate monotone span program size of f is a lower bound on the space
needed by quantum algorithms of a particular form, called monotone phase
estimation algorithms, to compute f. We then give the first non-trivial lower
bound on the approximate span program size of an explicit function.
</p></div>
    </summary>
    <updated>2019-08-13T23:20:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04198</id>
    <link href="http://arxiv.org/abs/1908.04198" rel="alternate" type="text/html"/>
    <title>On simplified NP-complete variants of Not-All-Equal 3-Sat and 3-Sat</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Darmann:Andreas.html">Andreas Darmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=ouml=cker:Janosch.html">Janosch Döcker</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04198">PDF</a><br/><b>Abstract: </b>We consider simplified, monotone versions of Not-All-Equal 3-Sat and 3-Sat,
variants of the famous Satisfiability Problem where each clause is made up of
exactly three distinct literals. We show that Not-All-Equal 3-Sat remains
NP-complete even if (1) each variable appears exactly four times, (2) there are
no negations in the formula, and (3) the formula is linear, i.e., each pair of
distinct clauses shares at most one variable.
</p>
<p>Concerning 3-Sat we prove several hardness results for monotone formulas with
respect to a variety of restrictions imposed on the variable appearances.
Monotone 3-Sat is the restriction of 3-Sat to monotone formulas, i.e. to
formulas in which each clause contains only unnegated variables or only negated
variables, respectively. In particular, we show that, for any $k\geq 5$,
Monotone 3-Sat is NP-complete even if each variable appears exactly $k$ times
unnegated and exactly once negated. In addition, we show that Monotone 3-Sat is
NP-complete even if each variable appears exactly three times unnegated and
three times negated, respectively. In fact, we provide a complete analysis of
Monotone 3-Sat with exactly six appearances per variable. Further, we prove
that the problem remains NP-complete when restricted to instances in which each
variable appears either exactly once unnegated and three times negated or the
other way around. Thereby, we improve on a result by Darmann et al. [DDD18]
showing NP-completeness for four appearances per variable. Our stronger result
also implies that 3-Sat remains NP-complete even if each variable appears
exactly three times unnegated and once negated, therewith complementing a
result by Berman et al. [BKS03].
</p></div>
    </summary>
    <updated>2019-08-13T23:22:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04196</id>
    <link href="http://arxiv.org/abs/1908.04196" rel="alternate" type="text/html"/>
    <title>Hyperedge Estimation using Polylogarithmic Subset Queries</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Anup.html">Anup Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bishnu:Arijit.html">Arijit Bishnu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Arijit.html">Arijit Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mishra:Gopinath.html">Gopinath Mishra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04196">PDF</a><br/><b>Abstract: </b>A hypergraph ${\cal H}$ is a \emph{set system} $(U({\cal H}),{\cal F}(H))$,
where $U({\cal H})$ denotes the set of $n$ vertices and ${\cal F}(H)$, a set of
subsets of $U({\cal H})$, denotes the set of hyperedges. A hypergraph ${\cal
H}$ is said to be $d$-uniform if every hyperedge in ${\cal H}$ consists of
exactly $d$ vertices. The cardinality of the hyperedge set is denoted as $\
|{{\cal F}({\cal H})}\ |=m({\cal H})$.
</p>
<p>We consider an oracle access to the hypergraph ${\cal H}$ of the following
form. Given $d$ (non-empty) pairwise disjoint subsets of vertices
$A_1,\ldots,A_d \subseteq U({\cal H})$ of hypergraph ${\cal H}$, the oracle,
known as the {\bf Generalized $d$-partite independent set oracle (\gpis)}~(that
was introduced in \cite{BishnuGKM018}), answers {\sc Yes} if and only if there
exists a hyperedge in ${\cal H}$ having (exactly) one vertex in each $A_i, i
\in [d]$. The \gpis{} oracle belongs to the class of oracles for subset
queries. The study of subset queries was initiated by Stockmeyer
\cite{Stockmeyer85}, and later the model was formalized by Ron and Tsur
\cite{RonT16}. Subset queries generalize the set membership queries.
</p>
<p>In this work we give an algorithm for the \hest problem using the \gpis query
oracle to obtain an estimate $\widehat{m}$ for $m({\cal H})$ satisfying $(1 -
\epsilon) \cdot m({\cal H}) \leq \widehat{m} \leq (1 + \epsilon) \cdot m({\cal
H})$. The number of queries made by our algorithm, assuming $d$ as a constant,
is polylogarithmic in the number of vertices of the hypergraph. Our work can be
seen as a natural generalization of {\sc Edge Estimation} using {\sc Bipartite
Independent Set}({\sc BIS}) oracle \cite{BeameHRRS18} and {\sc Triangle
Estimation} using {\sc Tripartite Independent Set}({\sc TIS}) oracle
\cite{Bhatta-abs-1808-00691}.
</p></div>
    </summary>
    <updated>2019-08-13T23:22:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04141</id>
    <link href="http://arxiv.org/abs/1908.04141" rel="alternate" type="text/html"/>
    <title>Shared-Memory Branch-and-Reduce for Multiterminal Cuts</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noe:Alexander.html">Alexander Noe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04141">PDF</a><br/><b>Abstract: </b>We introduce the fastest known exact algorithm~for~the multiterminal cut
problem with k terminals. In particular, we engineer existing as well as new
data reduction rules. We use the rules within a branch-and-reduce framework and
to boost the performance of an ILP formulation. Our algorithms achieve
improvements in running time of up to multiple orders of magnitudes over the
ILP formulation without data reductions, which has been the de facto standard
used by practitioners. This allows us to solve instances to optimality that are
significantly larger than was previously possible.
</p></div>
    </summary>
    <updated>2019-08-13T23:26:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04104</id>
    <link href="http://arxiv.org/abs/1908.04104" rel="alternate" type="text/html"/>
    <title>A Natural Quadratic Approach to the Generalized Graph Layering Problem</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mallach:Sven.html">Sven Mallach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04104">PDF</a><br/><b>Abstract: </b>We propose a new exact approach to the generalized graph layering problem
that is based on a particular quadratic assignment formulation. It expresses,
in a natural way, the associated layout restrictions and several possible
objectives, such as a minimum total arc length, minimum number of reversed
arcs, and minimum width, or the adaptation to a specific drawing area. Our
computational experiments show a competitive performance compared to prior
exact models.
</p></div>
    </summary>
    <updated>2019-08-13T23:30:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04083</id>
    <link href="http://arxiv.org/abs/1908.04083" rel="alternate" type="text/html"/>
    <title>An Efficient Skyline Computation Framework</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Rui.html">Rui Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Dominique.html">Dominique Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04083">PDF</a><br/><b>Abstract: </b>Skyline computation aims at looking for the set of tuples that are not worse
than any other tuples in all dimensions from a multidimensional database. In
this paper, we present SDI (Skyline on Dimension Index), a dimension indexing
conducted general framework to skyline computation. We prove that to determine
whether a tuple belongs to the skyline, it is enough to compare this tuple with
a bounded subset of skyline tuples in an arbitrary dimensional index, but not
with all existing skyline tuples. Base on SDI, we also show that any skyline
tuple can be used to stop the whole skyline computation process with outputting
the complete set of all skyline tuples. We develop an efficient algorithm
SDI-RS that significantly reduces the skyline computation time, of which the
space and time complexity can be guaranteed. Our experimental evaluation shows
that SDI-RS outperforms the baseline algorithms in general and is especially
very efficient on high-dimensional data.
</p></div>
    </summary>
    <updated>2019-08-13T23:23:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.04073</id>
    <link href="http://arxiv.org/abs/1908.04073" rel="alternate" type="text/html"/>
    <title>Link Crossing Number is NP-hard</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mesmay:Arnaud_de.html">Arnaud de Mesmay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schaefer:Marcus.html">Marcus Schaefer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sedgwick:Eric.html">Eric Sedgwick</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.04073">PDF</a><br/><b>Abstract: </b>We show that determining the crossing number of a link is NP-hard. For some
weaker notions of link equivalence, we also show NP-completeness.
</p></div>
    </summary>
    <updated>2019-08-13T23:36:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03996</id>
    <link href="http://arxiv.org/abs/1908.03996" rel="alternate" type="text/html"/>
    <title>Coded trace reconstruction in a constant number of traces</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ray.html">Ray Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spang:Bruce.html">Bruce Spang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03996">PDF</a><br/><b>Abstract: </b>The coded trace reconstruction problem asks to construct a code $C\subset
\{0,1\}^n$ such that any $x\in C$ is recoverable from independent outputs
("traces") of $x$ from a binary deletion channel (BDC). We present binary codes
of rate $1-\varepsilon$ that are efficiently recoverable from
$\exp(O_q(\log^{1/3}(1/\varepsilon)))$ (a constant independent of $n$) traces
of a $\operatorname{BDC}_q$ for any constant deletion probability $q\in(0,1)$.
We also show that, for rate $1-\varepsilon$ binary codes, $\tilde
\Omega(\log^{5/2}(1/\varepsilon))$ traces are required. The results follow from
a pair of black-box reductions that show that average-case trace reconstruction
is essentially equivalent to coded trace reconstruction. We also show that
there exist codes of rate $1-\varepsilon$ over an $O_{\varepsilon}(1)$-sized
alphabet that are recoverable from $O(\log(1/\varepsilon))$ traces, and that
this is tight.
</p></div>
    </summary>
    <updated>2019-08-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03948</id>
    <link href="http://arxiv.org/abs/1908.03948" rel="alternate" type="text/html"/>
    <title>Fully Dynamic k-Center Clustering in Doubling Metrics</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leniowski:Dariusz.html">Dariusz Leniowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svozil:Alexander.html">Alexander Svozil</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03948">PDF</a><br/><b>Abstract: </b>In the $k$-center clustering problem, we are given a set of $n$ points in a
metric space and a parameter $k \leq n$. The goal is to select $k$ designated
points, referred to as \emph{centers}, such that the maximum distance of any
point to its closest center is minimized. This notion of clustering is of
fundamental importance and has been extensively studied.
</p>
<p>We study a \emph{dynamic} variant of the $k$-center clustering problem, where
the goal is to maintain a clustering with small approximation ratio while
supporting an intermixed update sequence of insertions and deletions of points
with small update time. Moreover, the data structure should be able to support
the following queries for any given point: (1) report whether this point is a
center or (2) determine the cluster this point is assigned to.
</p>
<p>We present a deterministic dynamic algorithms for the $k$-center clustering
problem that achieves a $(2+\epsilon)$-approximation with $O(2^{O(\kappa)}
\log\Delta \log\log\Delta \cdot \epsilon^{-1} \ln \epsilon^{-1})$ update time
and $O(\log \Delta)$ query time, where $\kappa$ bounds the doubling dimension
of the metric and $\Delta$ is the aspect ratio. Our running and query times are
independent of the number of centers $k$, and are poly-logarithmic when the
metric has constant doubling dimension and the aspect ratio is bounded by a
polynomial.
</p></div>
    </summary>
    <updated>2019-08-13T23:33:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03903</id>
    <link href="http://arxiv.org/abs/1908.03903" rel="alternate" type="text/html"/>
    <title>Quantum algorithm for estimating volumes of convex bodies</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarti:Shouvanik.html">Shouvanik Chakrabarti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Childs:Andrew_M=.html">Andrew M. Childs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hung:Shih=Han.html">Shih-Han Hung</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Tongyang.html">Tongyang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chunhao.html">Chunhao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaodi.html">Xiaodi Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03903">PDF</a><br/><b>Abstract: </b>Estimating the volume of a convex body is a central problem in convex
geometry and can be viewed as a continuous version of counting. We present a
quantum algorithm that estimates the volume of an $n$-dimensional convex body
within multiplicative error $\epsilon$ using
$\tilde{O}(n^{3.5}+n^{2.5}/\epsilon)$ queries to a membership oracle and
$\tilde{O}(n^{5.5}+n^{4.5}/\epsilon)$ additional arithmetic operations. For
comparison, the best known classical algorithm uses
$\tilde{O}(n^{4}+n^{3}/\epsilon^{2})$ queries and
$\tilde{O}(n^{6}+n^{5}/\epsilon^{2})$ additional arithmetic operations. To the
best of our knowledge, this is the first quantum speedup for volume estimation.
Our algorithm is based on a refined framework for speeding up simulated
annealing algorithms that might be of independent interest. This framework
applies in the setting of "Chebyshev cooling", where the solution is expressed
as a telescoping product of ratios, each having bounded variance. We develop
several novel techniques when implementing our framework, including a theory of
continuous-space quantum walks with rigorous bounds on discretization error.
</p></div>
    </summary>
    <updated>2019-08-13T23:26:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03870</id>
    <link href="http://arxiv.org/abs/1908.03870" rel="alternate" type="text/html"/>
    <title>Graph Motif Problems Parameterized by Dual</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fertin:Guillaume.html">Guillaume Fertin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Komusiewicz:Christian.html">Christian Komusiewicz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03870">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a vertex-colored graph, where $C$ is the set of colors used
to color $V$. The Graph Motif (or GM) problem takes as input $G$, a multiset
$M$ of colors built from $C$, and asks whether there is a subset $S\subseteq V$
such that (i) $G[S]$ is connected and (ii) the multiset of colors obtained from
$S$ equals $M$. The Colorful Graph Motif (or CGM) problem is the special case
of GM in which $M$ is a set, and the List-Colored Graph Motif (or LGM) problem
is the extension of GM in which each vertex $v$ of $V$ may choose its color
from a list $\mathcal{L}(v)\subseteq C$ of colors.
</p>
<p>We study the three problems GM, CGM, and LGM, parameterized by the dual
parameter $\ell:=|V|-|M|$. For general graphs, we show that, assuming the
strong exponential time hypothesis, CGM has no $(2-\epsilon)^\ell\cdot
|V|^{\mathcal{O}(1)}$-time algorithm, which implies that a previous algorithm,
running in $\mathcal{O}(2^\ell\cdot |E|)$ time is optimal [Betzler et al.,
IEEE/ACM TCBB 2011]. We also prove that LGM is W[1]-hard with respect to $\ell$
even if we restrict ourselves to lists of at most two colors. If we constrain
the input graph to be a tree, then we show that GM can be solved in
$\mathcal{O}(3^\ell\cdot |V|)$ time but admits no polynomial-size problem
kernel, while CGM can be solved in $\mathcal{O}(\sqrt{2}^{\ell} + |V|)$ time
and admits a polynomial-size problem kernel.
</p></div>
    </summary>
    <updated>2019-08-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03865</id>
    <link href="http://arxiv.org/abs/1908.03865" rel="alternate" type="text/html"/>
    <title>Linking of three triangles in 3-space</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>E. Kogan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03865">PDF</a><br/><b>Abstract: </b>Two triples of pairwise disjoint triangles in 3-space are combinatorially
isotopic if one triple can be obtained from the other by a continuous motion
during which the triangles remain pairwise disjoint triangles. We present a
short elementary proof that the standard triple of triangles is not
combinatorially isotopic to the Borromean triple of triangles (aka Valknut).
The earlier proof involved the Massey-Rolfsen invariant. We conjecture that any
triple of pairwise disjoint triangles in 3-space is combinatorially isotopic to
one of the 5 triples listed in the paper.
</p></div>
    </summary>
    <updated>2019-08-13T23:39:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03773</id>
    <link href="http://arxiv.org/abs/1908.03773" rel="alternate" type="text/html"/>
    <title>Approximation of the Lagrange and Markov spectra</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Delecroix:Vincent.html">Vincent Delecroix</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matheus:Carlos.html">Carlos Matheus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moreira:Carlos_Gustavo.html">Carlos Gustavo Moreira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03773">PDF</a><br/><b>Abstract: </b>The (classical) Lagrange spectrum is a closed subset of the positive real
numbers defined in terms of diophantine approximation. Its structure is quite
involved. This article describes a polynomial time algorithm to approximate it
in Hausdorff distance. It also extends to approximate the Markov spectrum
related to infimum of binary quadratic forms.
</p></div>
    </summary>
    <updated>2019-08-13T23:36:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03724</id>
    <link href="http://arxiv.org/abs/1908.03724" rel="alternate" type="text/html"/>
    <title>Slide Reduction, Revisited---Filling the Gaps in SVP Approximation</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aggarwal:Divesh.html">Divesh Aggarwal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianwei.html">Jianwei Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Phong_Q=.html">Phong Q. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stephens=Davidowitz:Noah.html">Noah Stephens-Davidowitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03724">PDF</a><br/><b>Abstract: </b>We show how to generalize Gama and Nguyen's slide reduction algorithm [STOC
'08] for solving the approximate Shortest Vector Problem over lattices (SVP).
As a result, we show the fastest provably correct algorithm for
$\delta$-approximate SVP for all approximation factors $n^{1/2+\varepsilon}
\leq \delta \leq n^{O(1)}$. This is the range of approximation factors most
relevant for cryptography.
</p></div>
    </summary>
    <updated>2019-08-13T23:30:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1908.03600</id>
    <link href="http://arxiv.org/abs/1908.03600" rel="alternate" type="text/html"/>
    <title>Kernel for Kt-free edge deletion</title>
    <feedworld_mtime>1565654400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1908.03600">PDF</a><br/><b>Abstract: </b>In the $K_t$-free edge deletion problem, the input is a graph $G$ and an
integer $k$, and the goal is to decide whether there is a set of at most $k$
edges of $G$ whose removal results a graph with no clique of size $t$. In this
paper we give a kernel to this problem with $O(k^{t-1})$ vertices and edges.
</p></div>
    </summary>
    <updated>2019-08-13T23:31:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-08-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16151</id>
    <link href="https://rjlipton.wordpress.com/2019/08/11/leaps-and-bounds-practice-meets-theory/" rel="alternate" type="text/html"/>
    <title>Leaps and Bounds: Practice Meets Theory</title>
    <summary>Solving the runtime selection problem Composite from src1, src2 Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s workshop at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.” Today I will discuss their talks, which I enjoyed greatly at the workshop. The workshop’s general theme was the use of machine-learning techniques […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Solving the runtime selection problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png"><img alt="" class="alignright wp-image-16153" height="129" src="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png?w=180&amp;h=129" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite from <a href="https://www.microsoft.com/en-us/research/people/brlucier/">src1</a>, <a href="https://www.microsoft.com/en-us/research/video/sparse-stochastic-bandits/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s <a href="http://www.cs.cmu.edu/~ckingsf/AutoAlg2019/">workshop</a> at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.”</p>
<p>
Today I will discuss their talks, which I enjoyed greatly at the workshop.</p>
<p>
The workshop’s general theme was the use of machine-learning techniques to improve the tuning of algorithms. Indeed, the goal is to have the algorithm tune itself by selecting strategies from a collection of possible ones. Besides better performance with less human work, this promises better logical reliability than with hand-tuning programs and debugging. </p>
<p>
A common component of this work used in both talks is an interesting oracle model. Since oracles are familiar to many of us theorists this will give us an avenue into the talks and the <a href="https://pdfs.semanticscholar.org/0dce/10ed863423e2e9b1b77a0becfc23111578be.pdf">two</a> recent <a href="https://arxiv.org/pdf/1807.00755.pdf">papers</a> they were based on.</p>
<p>
</p><p/><h2> Runtime Oracles </h2><p/>
<p/><p>
The oracle has a nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> of shape <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/>. Think of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> as the <i>runtime</i> of the <img alt="{i^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i^{th}}"/> program on the <img alt="{j^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j^{th}}"/> input. You know <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, but must ask the oracle for information about <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/>. You may ask the oracle a question <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/>:</p>
<blockquote><p><b> </b> <em> <i>Is the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> less than or equal to <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>?</i> </em>
</p></blockquote>
<p/><p>
Here <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is a time bound. Further they assume that the oracle charges you 	</p>
<p align="center"><img alt="\displaystyle  \min(R(i,j),t). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin%28R%28i%2Cj%29%2Ct%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min(R(i,j),t). "/></p>
<p>Thus an algorithm is charged in total 	</p>
<p align="center"><img alt="\displaystyle  \sum_{t} \min(R(i,j),t), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%7D+%5Cmin%28R%28i%2Cj%29%2Ct%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{t} \min(R(i,j),t), "/></p>
<p>where the sum is over all questions <img alt="{(i,j,t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j,t)}"/> you asked. 	 The rationale is that the oracle can run a program <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> on a task <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and stop after at most <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> steps. Thus returning the minimum is realistic. Since their research is motivated by practical problems, this is a useful model for studying questions about program performance. </p>
<p>
In passing I believe the reason this oracle model is new is that theorists do not often think about running arbitrary programs. Well those in recursion type did, but those designing classic algorithms do not. </p>
<p>
</p><p/><h2> A Selection Problem </h2><p/>
<p/><p>
This model to used to study a selection problem. Assume <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is as above. The task is to find the row with the smallest row sum <img alt="{s_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_{i}}"/>: </p>
<p align="center"><img alt="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%3D+%5Csum_%7Bj%3D1%7D%5E%7BM%7D+R%28i%2Cj%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). "/></p>
<p>That is to find the program that takes the least total time on the inputs—hence the least average time.</p>
<p>
The trouble is that in the worst case this can require examining all the entries. So they introduce approximations to make the problem doable, but still useful in practice:</p>
<ol>
<li>
The rows need only be a <img alt="{(1+\epsilon)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2B%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1+\epsilon)}"/> approximation to the smallest row. <p/>
</li><li>
The entries can be assumed to be truncated by a value <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tau}"/>. That is you can assume that 	<p/>
<p align="center"><img alt="\displaystyle  R(i,j) \le \tau. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28i%2Cj%29+%5Cle+%5Ctau.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  R(i,j) \le \tau. "/></p>
</li><li>
The governing algorithm can be randomized and need only meet the performance goal with high probability.
</li></ol>
<p>
Now we can state the problem formally. It is parameterized by <img alt="{(\epsilon, \tau)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C+%5Ctau%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon, \tau)}"/>:</p>
<blockquote><p><b> </b> <em> <b>Runtime Selection Problem (RSP)</b>: Given a matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R}"/> with all entries bounded by <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\tau}"/>, find a row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/> so that 	</em></p><em>
<p align="center"><img alt="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%5Cle+%281+%2B+%5Cepsilon%29s_%7Bk%7D%2C+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, "/></p>
</em><p><em>for all <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, while minimizing the oracle charges for all questions “is <img alt="{R(i,j) \leq t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cleq+t%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(i,j) \leq t}"/>?” that are asked. </em>
</p></blockquote>
<p>The talks gave a variety of randomized algorithms that solve such problems for various parameter assumptions. </p>
<p>
</p><p/><h2> Fast and Slow </h2><p/>
<p/><p>
See their papers for details on the results. The algorithms they have are interesting not only from a theory viewpoint but also in practice. Indeed, they not only prove theorems but also give experimental timings.</p>
<p>
In order to establish some intuition, let’s look at the following simple case. Assume that all entries <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> are either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or some <img alt="{\alpha \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \gg 1}"/>. This is the “fast-or-slow” running time stipulation. As theorists we often are drawn to binary values, so this might be a good case to look at initially.</p>
<p>
The first observation is that we will always ask questions of the form 	</p>
<p align="center"><img alt="\displaystyle  (i, j, 1.0001). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28i%2C+j%2C+1.0001%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (i, j, 1.0001). "/></p>
<p>This gives us the value of the entry <img alt="{R(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j)}"/> for almost unit cost: if it is the <img alt="{R(i,j) \gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R(i,j) \gg 1}"/> case then we are only charged <img alt="{1.0001}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1.0001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1.0001}"/>. Thus, we have reduced the original problem to a classic oracle problem. There is no complicated oracle cost measure: the cost is just the number of entries we read. Well okay the cost is slightly higher, but we can make it as close as we wish.</p>
<p>
The selection problem then comes down to this: </p>
<ul>
<li>
We have a <img alt="{n \times M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \times M}"/> nonnegative matrix <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> whose entries are all either <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> or <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. <p/>
</li><li>
We must find a row sum that is within a factor of <img alt="{1+\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1+\epsilon}"/> of the smallest.
</li></ul>
<p>
I believe that the analysis of this problem should be generally known. In any event it seems clear that randomly sampling each row is a good start.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Are there other natural problems where the runtime cost oracle is useful?</p>
<p>[Edited typo]</p></font></font></div>
    </content>
    <updated>2019-08-12T02:34:46Z</updated>
    <published>2019-08-12T02:34:46Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="fast"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="Algorithms"/>
    <category term="Brendan Lucier"/>
    <category term="complexity"/>
    <category term="Csaba Szepesvari"/>
    <category term="machine learning"/>
    <category term="oracles"/>
    <category term="practice"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-14T21:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/104</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/104" rel="alternate" type="text/html"/>
    <title>TR19-104 |  Reconstruction of Depth-$4$ Multilinear Circuits | 

	Vishwas Bhargava, 

	Shubhangi Saraf, 

	Ilya Volkovich</title>
    <summary>We present a deterministic algorithm for reconstructing multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits, i.e. multilinear depth-$4$ circuits with fan-in $k$ at the top $+$ gate. For any fixed $k$, given black-box access to a polynomial $f \in \mathbb{F}[x_{1},x_{2},\ldots ,x_{n}]$ computable by a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size $s$, the algorithm runs in time quasi-poly($n,s,{|\mathbb{F}|}$) and outputs a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size quasi-poly($n,s$) that computes $f$. 

Our result solves an open problem posed in \cite{GKL12} (STOC, 2012). Indeed, prior to our work, efficient reconstruction algorithms for multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits were known only for the case of $k=2$ \cite{GKL12, Volkovich17}.</summary>
    <updated>2019-08-11T04:14:43Z</updated>
    <published>2019-08-11T04:14:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-14T21:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/103</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/103" rel="alternate" type="text/html"/>
    <title>TR19-103 |  Query-to-Communication Lifting Using Low-Discrepancy Gadgets | 

	Or Meir, 

	Sajin Koroth, 

	Arkadev Chattopadhyay, 

	Toniann Pitassi, 

	Yuval Filmus</title>
    <summary>Lifting theorems are theorems that relate the query complexity of a function $f:\left\{ 0,1 \right\}^n\to \left\{ 0,1 \right\}$ to the communication complexity of the composed function $f\circ g^n$, for some “gadget” $g:\left\{ 0,1 \right\}^b\times \left\{ 0,1 \right\}^b\to \left\{ 0,1 \right\}$. Such theorems allow transferring lower bounds from query complexity to the communication complexity, and have seen numerous applications in the recent years. In addition, such theorems can be viewed as a strong generalization of a direct-sum theorem for the gadget $g$.

We prove a new lifting theorem that works for all gadgets $g$ that have logarithmic length and exponentially-small discrepancy, for both deterministic and randomized communication complexity. Thus, we significantly increase the range of gadgets for which such lifting theorems hold.

Our result has two main motivations: First, allowing a larger variety of gadgets may support more applications. In particular, our work is the first to prove a randomized lifting theorem for logarithmic-size gadgets, thus improving some applications of the theorem. Second, our result can be seen as a strong generalization of a direct-sum theorem for functions with low discrepancy.</summary>
    <updated>2019-08-11T04:04:36Z</updated>
    <published>2019-08-11T04:04:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-14T21:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://blog.ilyaraz.org/rss/12</id>
    <link href="https://blog.ilyaraz.org/?go=all/cuckoo-hashing-for-sketching-sets/" rel="alternate" type="text/html"/>
    <title>Cuckoo hashing for sketching sets</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>Below I show a neat application of <a href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hashing</a>, which is one of my favorite (cluster of) algorithms. Amazingly, we use it to obtain a purely information-theoretic (rather than algorithmic) statement.</p>
<p>Suppose we have a finite universe $U$ of size $n$ and a $k$-element subset of it $S \subseteq U$ with $k \ll n$. How many bits do we need to encode it? The obvious answer is $\log_2 \binom{n}{k} = \Theta(k \cdot \log(n / k))$.<br/>
Can we, however, improve this bound if we allow some approximation?</p>
<p>Even if $n = 2k$, it is not difficult to show the lower bound of $k \cdot \log_2(1 / \delta)$ bits if we allow to be wrong when answering queries “does $x$ belong to $S$?” with probability at most $\delta$ (hint: $\varepsilon$-nets). Can we match this lower bound?</p>
<p>One approach that does not quite work is to hash each element of $S$ to an $l$-bit string using a sufficiently good hash function $h \colon U \to \{0, 1\}^l$, and, when checking if $x$ lies in $S$, compute $h(x)$ and check if this value is among the hashes of $S$. To see why it does not work, let us analyze it: if $x \notin S$, then the probability that $h(x)$ coincides with at least one hash of an element of $S$ is around $k \cdot 2^{-l}$. To make the latter less than $\delta$, we need to take $l = \log_2(k / \delta)$ yielding the overall bound of $k \cdot \log_2(k / \delta)$ falling short of the desired size.</p>
<p>To get the optimal size, we need to avoid using the union bound in the above argument. In order to accomplish this, let us use perfect hashing on top of the above hashing scheme! It is convenient to use a particular approach to perfect hashing called <a href="https://en.wikipedia.org/wiki/Cuckoo_hashing">Cuckoo hashing</a>. In short, there is a way to generate two simple hash functions $h_1, h_2 \in U \to [m]$ for $m = O(k)$ and place the elements of our set $S$ into $m$ bins without collisions so that for every $x \in S$, the element $x$ is placed either in $h_1(x)$ or in $h_2(x)$. Now, to encode our set $S$, we build a Cuckoo hash table for it, and then for each of the $m$ bins, we either store one bit indicating that it’s empty, or store an $l$-bit hash of an element that is placed into it. Now we can set $l = \log_2(2 / \delta)$, since we compare the hash of a query to merely two hashes, instead of $k$. This gives the overall size $m + k \cdot \log_2 (2 / \delta) = k \cdot (\log_2(1 / \delta) + O(1))$, which is optimal up to a low-order term. Of course, the encoding should include $h_1$, $h_2$ and $h$, but it turns out they can be taken to be sufficiently simple so that their size does not really matter.</p>
<p>Two remarks are in order. First, in this context people usually bring up <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a>. However, they require space, which is $1.44$ times bigger, and, arguably, they are more mysterious (if technically simple). Second, one may naturally wonder why anyone would care about distinguishing bounds like $k \cdot \log_2 (1 / \delta)$ and $k \cdot \log_2(k / \delta)$. In my opinion, there are two answers to this. First, it is just a cool application of perfect hashing (an obligatory link to <a href="https://www.smbc-comics.com/comic/2010-12-09">one of my favorite comic strips</a>). Second, compressing sets is actually important in practice and constant factors do matter, for instance when we are aiming to transfer the set over the network.</p>
<p><b>Update</b> <a href="https://cs.au.dk/~larsen/">Kasper Green Larsen</a> observed that we can combine the naive and not-quite-working solutions to obtain the optimal bound. Namely, by hashing everything to $\log_2(k / \delta)$ bits, we effectively reduce the universe size to $n’ = k / \delta$. Then, the naive encoding takes $\log_2 \binom{n’}{k} \approx H(\delta) \cdot n’ = H(\delta) \cdot k / \delta \approx<br/>
k \cdot \log_2 (1 / \delta)$ bits.</p></div>
    </summary>
    <updated>2019-08-11T01:21:23Z</updated>
    <published>2019-08-11T01:21:23Z</published>
    <source>
      <id>https://blog.ilyaraz.org/</id>
      <author>
        <name>Ilya Razenshteyn</name>
      </author>
      <link href="https://blog.ilyaraz.org/" rel="alternate" type="text/html"/>
      <link href="https://blog.ilyaraz.org/rss/" rel="self" type="application/rss+xml"/>
      <title>Lullaby of Cape Cod</title>
      <updated>2019-08-13T23:41:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/102</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/102" rel="alternate" type="text/html"/>
    <title>TR19-102 |  Testing Isomorphism in the Bounded-Degree Graph Model | 

	Oded Goldreich</title>
    <summary>We consider two versions of the problem of testing graph isomorphism in the bounded-degree graph model: A version in which one graph is fixed, and a version in which the input consists of two graphs.
We essentially determine the query complexity of these testing problems in the special case of $n$-vertex graphs with connected components of size at most $\poly(\log n)$. 
This is done by showing that these problems are computationally equivalent (up to polylogarithmic factors) to corresponding problems regarding isomorphism between sequences (over a large alphabet). 
Ignoring the dependence on the proximity parameter, our main results are: 
\begin{enumerate}
\item 
The query complexity of testing isomorphism to a fixed object (i.e., an $n$-vertex graph or an $n$-long sequence) is ${\widetilde{\Theta}(n^{1/2})$. 
\item 
The query complexity of testing isomorphism between two input objects is ${\widetilde{\Theta}}(n^{2/3})$. 
\end{enumerate}
Testing isomorphism between two sequences is shown to be related to testing that two distributions are equivalent, and this relation yields reductions in three of the four relevant cases. 
Failing to reduce the problem of testing the equivalence of two distribution to the problem of testing isomorphism between two sequences, we adapt the proof of the lower bound on the complexity of the first problem to the second problem.
This adaptation constitutes the main technical contribution of the current work. 

Determining the complexity of testing graph isomorphism (in the bounded-degree graph model), in the general case (i.e., for arbitrary bounded-degree graphs), is left open.</summary>
    <updated>2019-08-10T16:22:55Z</updated>
    <published>2019-08-10T16:22:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-08-14T21:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/10/report-from-cccg</id>
    <link href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html" rel="alternate" type="text/html"/>
    <title>Report from CCCG</title>
    <summary>After WADS, I stayed in Edmonton for CCCG. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">WADS</a>, I stayed in Edmonton for <a href="https://sites.ualberta.ca/~cccg2019/">CCCG</a>. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</p>

<p>Like WADS, CCCG had three invited speakers. In past years, two were named the Paul Erdős Memorial Lecture and the Ferran Hurtado Memorial Lecture. This year, sadly, the third one has also been named, as the Godfried Toussaint Memorial Lecture.</p>

<ul>
  <li>
    <p>The Erdős Lecture was by Vida Dujmović, who spoke on her breakthrough work with several other Barbados workshop participants showing that <a href="https://arxiv.org/abs/1904.04791">every planar graph is a subgraph of a strong product of a path graph and a bounded-pathwidth graph</a>, from which it follows that these graphs have bounded <a href="https://en.wikipedia.org/wiki/Queue_number">queue number</a>, that they can be embedded into 3d grids of linear volume, and many other nice properties. The timing of the lecture invitation to Vida was good, as the breakthrough happened after she had already agreed to speak!</p>
  </li>
  <li>
    <p>The Toussaint Lecture was by Joseph O’Rourke. Joe spoke on <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting the boundary of a polyhedron into a surface that can unfold into a simple polygon in the plane. One of the points of his talk was to rationalize some of the terminology in this area. The standard version of the problem asks for (in his new terminology) an <em>edge-unfolding</em>, a set of cuts along edges of the polyhedron, forming a spanning tree for its vertices, such that the resulting cut surface unfolds to a flat polygon. But one can also ask for an anycut-unfolding, using cuts that do not have to follow the edges. Or one can ask for an edge-unzipping or anycut-unzipping, in which the cuts must form a single (Hamiltonian) path through the vertices of the polyhedron. In this terminology <a href="http://www.openproblemgarden.org/op/d_urers_conjecture">Dürer’s conjecture</a> becomes the statement that every convex polyhedron has an edge-unfolding, and the example I recently posted of a <a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">zipless polycube</a> shows that not every polycube has an edge-unzipping. Another well-known open question in this area asks whether every polycube whose boundary forms a topological sphere has an edge-unfolding. Joe conjectured that with high probability the convex hull of many random points on a sphere does not have an anycut-unzipping.</p>
  </li>
  <li>
    <p>Mark de Berg presented the Hurtado Lecture. His topic involved subexponential algorithms for disk intersection graphs and <a href="https://en.wikipedia.org/wiki/Unit_disk_graph">unit disk graphs</a>. At STOC 2018 he had a paper on <a href="https://arxiv.org/abs/1803.10633">finding the maximum independent set in disk graphs</a> in time , matching the time for planar graphs. In planar graphs, you can use the <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">planar separator theorem</a>: for each of the  independent subsets of the separator, recurse on both sides. This turns out to work in disk graphs by replacing the usual size bound on the separator (it should have  vertices) with a decomposition into a union of cliques  with . The separators can be found analogously to classical circle-packing methods for planar separators. Each clique can contribute one vertex to any independent set from which it follows that the separator again has  independent subsets. The same idea works for other problems like dominating sets in unit disk graphs (where the unit assumption is used to get a bounded contribution from each clique), and generalizes to fat objects in higher dimensions. The time bound is optimal assuming the <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">exponential time hypothesis</a>. And in FOCS 2018 de Berg obtained similar <a href="https://arxiv.org/abs/1807.06933">ETH-tight time bounds for the Euclidean traveling salesperson problem</a> by using separators of point sets with the property that few points are very close to the separator boundary.</p>
  </li>
</ul>

<p>I can’t find links for all the contributed papers, but you can find them in the <a href="https://sites.ualberta.ca/~cccg2019/cccg2019_proceedings.pdf">complete proceedings</a>. Among them:</p>

<ul>
  <li>
    <p>In “Three-Coloring Three-Dimensional Uniform Hypergraphs”, Biniaz, Bose, Cardinal, and Payne prove that, for  points in the plane and a fixed triangle shape, one can -color the points so that every scaled and translated copy of the triangle containing six or more points has more than one color. It was already known that if you change “six or more” to “two or more” you need four colors, and if you change it to “nine or more” you need only two colors.</p>
  </li>
  <li>
    <p>Audrey St. John’s talk on “Redundant Persistent Acyclic Formations for Vision-Based Control of Distributed Multi-Agent Formations” (with Burns, Klemperer, and Solyst) was beset by technical difficulties, but from it I learned that there is a theory of directed bar-and-joint frameworks, analogous to undirected rigidity theory, called “persistence theory”, and that the <a href="https://11011110.github.io/blog/2013/12/07/kinematic-chains-and.html">pebble game</a> for testing rigidity of an undirected framework produces an orientation of the network that is persistent. She used the analogy of a flock of geese, walking in formation: each goose pays attention only to the other geese in front, but the whole formation can keep its shape as the leading goose moves arbitrarily. Her goal is to get robots to do the same thing.</p>
  </li>
  <li>
    <p>In “Chirotopes of Random Points in Space are Realizable on a Small Integer Grid”, Cardinal, Fabila-Monroy and Hidalgo-Toscano prove that, with high probability, random point sets in  can be rounded to a grid of polynomial size without changing their order type.</p>
  </li>
  <li>
    <p>We had enough folding and unfolding papers to spill out over more than one section. Among them, I particularly liked “Efficient Segment Folding is Hard” by Klute, Parada, Horiyama, Korman, Uehara and Yamanaka. The question they asked is: given disjoint line segments on a piece of paper, when can you make a sequence of simple folds (that is, for a given fold line, folding all the layers of the paper that are crossed by the line), with each fold on a line through one of the segments that misses all the other segments? It turns out to be -complete. If you do allow fold lines to pass through other segments, folding sequences can be infinite, and it’s unknown whether every set of segments has a finite sequence.</p>
  </li>
  <li>
    <p>Pilar Cano spoke on generating triangulations of point sets in an affine-invariant way (“Affine invariant triangulations” with Bose and Silveira). The main trick is to use covariance to choose a canonical affine transformation for the points, after which you can use Delaunay, minimum weight, or your favorite other triangulation algorithm. But there are necessarily some general position assumptions (as there already are for using Delaunay triangulation without the affine invariance): for points in a parallelogram, there is no affine-invariant way of choosing which diagonal to use.</p>
  </li>
</ul>

<p>The excursion was to the <a href="https://royalalbertamuseum.ca/">Royal Alberta Museum</a>, where I skipped the special exhibit on Vikings (having gone to museum exhibits on them in Copenhagen a year earlier) and instead learned much about Great Plains geology and the historical mistreatment of the <a href="https://en.wikipedia.org/wiki/M%C3%A9tis">Métis</a>, local people descending both from First Nations and Europeans. (The First Nations themselves were of course also badly mistreated, but I had more of an idea of that already.)</p>

<p>From the business meeting, we heard that the acceptance ratio was a little higher than last year, but still approximately . Two papers were withdrawn because the authors had visa issues, double the number from last year, and several others were presented by non-authors after their authors were unable to attend. One possible improvement would be to move the submission and acceptance dates earlier to provide authors more time to obtain visas. The main topic of discussion was the conference’s status as a conference: should papers at CCCG continue to count as publications (in which case why are they still limited to only six pages) or should they be considered as preliminary announcements of papers that can still be sent to other more prestigious symposia? One possible compromise involves giving authors a choice: either publish your paper in the proceedings or give up the proceedings slot but still present your work in some other way (possibly as a poster, as GD does).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102595225020207137">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-10T15:34:00Z</updated>
    <published>2019-08-10T15:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-10T23:15:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/09/university-alberta-botanic</id>
    <link href="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic.html" rel="alternate" type="text/html"/>
    <title>University of Alberta Botanic Gardens</title>
    <summary>The WADS excursion was to the University of Alberta Botanic Gardens. Here are a few photos I took there:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The WADS excursion was to the University of Alberta Botanic Gardens.
Here are a few photos I took there:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Source Fountain" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain-m.jpg" style="border-style: solid; border-color: black;" width="300"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Jilau Khana" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana-m.jpg" style="border-style: solid; border-color: black;" width="405"/></a></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi.html"><img alt="University of Alberta Botanic Gardens, Aga Khan Garden, Mahtabi" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi-m.jpg" style="border-style: solid; border-color: black;" width="390"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock.html"><img alt="University of Alberta Botanic Gardens, Wetland Walk, May's Dock" src="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock-m.jpg" style="border-style: solid; border-color: black;" width="385"/></a></td>
</tr></tbody></table></div>

<p>(<a href="https://mathstodon.xyz/@11011110/102588301669141700">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-09T11:46:00Z</updated>
    <published>2019-08-09T11:46:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-10T23:15:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17820</id>
    <link href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/" rel="alternate" type="text/html"/>
    <title>Two Important Quantum Announcements!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on … <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on Sundays 14:00-16:00. Second, I would also like to announce The 4th Advanced School in Computer Science and Engineering on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019, at IIAS HUJI.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/ghen.png"><img alt="" class="alignnone size-medium wp-image-17833" height="190" src="https://gilkalai.files.wordpress.com/2019/08/ghen.png?w=300&amp;h=190" width="300"/></a></h2>
<p><span style="color: #ff0000;">Emmy Noether (left) Grete Hermann (right)</span></p>
<h2>A quantum “Kazhdan’s seminar” at HUJI: Computation, quantization, symplectic geometry, and information.</h2>
<p>“In the fall of 2019 Dorit Aharonov, Gil Kalai, Guy Kindler and Leonid Polterovich intend to run a new one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.  The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. (See below for a full description.)”</p>
<p>The course will by on Sundays 14:00-16:00 in Ross building.</p>
<p>See also the post  <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/" rel="bookmark">Symplectic Geometry, Quantization, and Quantum Noise</a> from January 2013. (The seminar was initially planned to 2014 but some bumps in the road delayed it to 2019.)</p>
<h2>A winter school at IIAS: The Mathematics of Quantum Computation</h2>
<p><a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation</a><br/>
The 4th Advanced School in Computer Science and Engineering<br/>
Event date: December 15 – December 19, 2019</p>
<p>“We will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area. (See below for a full description.)</p>
<p>Organizers: Dorit Aharonov, Zvika Brakerski, Or Sattath, Amnon Ta-Shma,</p>
<p dir="LTR"><strong>Main (confirmed) Speakers: </strong>Sergey Bravyi, Matthias Christandl, Sandy Irani, Avishay Tal, Thomas Vidick, (1-2 additional speakers may be added later).</p>
<p dir="LTR"><strong>Additional (confirmed) lectures will be given by: </strong>Dorit Aharonov,  Zvika Brakerski,  and/ Or Sattath. (1-2 additional speakers may be added later).”</p>
<p dir="LTR">The Isreali Institute of Advanced Study hosted already a 2014 <a href="http://www.as.huji.ac.il/schools/phys31">school about quantum information</a> as part of its legendary physics series of schools, and also hosted <a href="https://gilkalai.wordpress.com/2013/04/12/qstart/">QSTART</a> in 2013.</p>
<h2>More details</h2>
<p><span id="more-17820"/></p>
<h3><strong><span style="color: #ff0000;">Kazhdan’s seminar: Computation, quantization, symplectic geometry, and information.</span></strong></h3>
<p>In the fall of 2019 Aharonov, Kalai, Kindler and Polterovich intend to run a new<br/>
one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be<br/>
highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.</p>
<p>The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. Students who attend it will be awarded two N”Z after passing an exam. The goal of the course is to initiate and lead to new connections between the seemingly unrelated areas of quantum computation and symplectic geometry.</p>
<p>The topics will include:</p>
<p>– Introduction to quantum computation, quantum universality, quantum algorithms<br/>
and quantum computational complexity classes such as BQP and Quantum NP (QMA)</p>
<p>– quantum measurement and quantum noise explained using the standard quantum computational model.</p>
<p>– questions about quantum error correction and quantum noise – fault tolerance,<br/>
quantum error correcting codes, and the breakdown of robustness when the locality of<br/>
the noise does not hold.</p>
<p>– quantum measurement/quantum information (noise and speed limit) having classical counterparts, studied from the symplectic geometry perspective.</p>
<p>– Konsevich theorem and quantization,</p>
<p>– towards a the semi classical approximation of quantum computers.</p>
<p>Examples of questions we would like to initiate research on are:</p>
<p>1) what would be a semi classical model of quantum computation, and what would be<br/>
its computational power?</p>
<p>2) what is a good notion of complexity in a symplextic geometry computational model?</p>
<p>3) What can we learn from basic symplectic geometry results (such as non squeezing)<br/>
about the limitations on quantum computation in the semi classical limit?</p>
<p>4) Can noise in quantum computation be related in any way with the semi classical limit<br/>
of quantum computing systems?</p>
<p>5) can we learn anything about the possible noise models in quantum computers,<br/>
using our knowledge from symplectic geometry?</p>
<p>Hope to see you in the course!</p>
<h3><span style="color: #ff0000;"><strong>The Mathematics of Quantum Computation -The 4th Advanced School in Computer Science and Engineering</strong></span></h3>
<p>On 15-19 December 2019, we will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area.</p>
<p>To achieve this, we will have several mini-courses, each of two or three hours, about central topics in the area.   These will include quantum algorithms, quantum error correction, quantum supremacy, delegation and verification, interactive proofs, cryptography, and Hamiltonian complexity. We will emphasize concepts, open questions, and links to mathematics. We will have daily TA sessions with hands-on exercises, to allow for a serious process of learning.</p>
<p>There will be two rounds of registration. The first deadline is 23rd of August. If there is room, there will be another deadline sometime in October; please follow <a href="http://ias.huji.ac.il/SchoolCSE4">this page</a> for further announcements.</p>
<p>Hope to see you this coming December!</p></div>
    </content>
    <updated>2019-08-09T08:58:55Z</updated>
    <published>2019-08-09T08:58:55Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Conferences"/>
    <category term="Quantum"/>
    <category term="Teaching"/>
    <category term="Quantization"/>
    <category term="Quantum computers"/>
    <category term="Quantum mechanics"/>
    <category term="Symplectic geometry"/>
    <category term="Theory of Computing"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-08-14T21:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/" rel="alternate" type="text/html"/>
    <title>Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 27, 2019)</title>
    <summary>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development. Website: https://santafe.edu/sfifellowship Email: sfifellowship@santafe.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development.</p>
<p>Website: <a href="https://santafe.edu/sfifellowship">https://santafe.edu/sfifellowship</a><br/>
Email: sfifellowship@santafe.edu</p></div>
    </content>
    <updated>2019-08-08T19:38:52Z</updated>
    <published>2019-08-08T19:38:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-14T21:21:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Chennai Mathematical Institute, Chennai, India. (apply by September 30, 2019)</title>
    <summary>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata. Website: http://www.cmi.ac.in Email: registrar@cmi.ac.in</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata.</p>
<p>Website: <a href="http://www.cmi.ac.in">http://www.cmi.ac.in</a><br/>
Email: registrar@cmi.ac.in</p></div>
    </content>
    <updated>2019-08-08T03:48:33Z</updated>
    <published>2019-08-08T03:48:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-08-14T21:21:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-337501791513204418</id>
    <link href="https://blog.computationalcomplexity.org/feeds/337501791513204418/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/337501791513204418" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html" rel="alternate" type="text/html"/>
    <title>Obstacles to improving Classical Factoring Algorithms</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In Samuel Wagstaff's excellent book The Joy of Factoring (see <a href="https://mathcs.clarku.edu/~fgreen/SIGACTReviews/bookrev/47-2.pdf">here</a> for a review) there is a discussion towards the end about why factoring algorithms have not made much progress recently. I<br/>
paraphrase it:<br/>
<br/>
<br/>
--------------------------------------------------------<br/>
<br/>
The time complexities of the fastest known algorithms can be expressed as a formula of the following form (where N is the number to be factored):<br/>
<br/>
(*)                      exp(c(ln N)^t (ln(ln N))^{1-t})<br/>
<br/>
for some constants c and for 0 &lt; t &lt; 1.  For the Quadratic Sieve (QS) and Elliptic Curve Method (ECM) t=1/2. For the Number Field Sieve (NFS) t=1/3. The reason for this shape for the time complexity is the requirement of finding one or more smooth numbers (numbers that have only small primes as factors).<br/>
<br/>
----------------------------------------------------------<br/>
<br/>
This got me thinking: Okay, there may not be a drastic improvement anytime soon but what about just improving t? Is there a mathematical reason<br/>
why an algorithm with (say) t=1/4 has not been discovered? In an earlier era I would have had to write a letter to Dr. Wagstaff to ask him. Buy an envelope, buy a  stamp, find his address, the whole nine yards (my younger readers should ask their grandparents what envelopes and stamps were). In the current era I emailed him. And got a response.<br/>
<br/>
<br/>
Samuel Wagstaff:<br/>
<br/>
The fastest known factoring algorithms find smooth numbers subject to parameter choice(s).  In all these algorithms, one parameter choice is the smoothness bound B:  a number is smooth if all its prime factors are &lt; B. The NFS has the degree of a polynomial as an additional parameter.<br/>
<br/>
One analyzes the complexity of these algorithms by estimating the total work required (to find enough smooth numbers) for an arbitrary parameter choice using Dickman's function to predict the density of smooth numbers.  Then one uses calculus to find the parameter choice(s) that minimize the total work function.  Calculus also yields the optimal values for the parameter(s).<br/>
<br/>
If you have k parameters to choose, you will get the time complexity (*) with t = 1/(1+k).  If you have no parameters (k = 0),you get (*) with t = 1, basically exponential time N^c.  With one parameter to optimize, as in CFRAC  (continued fractions algorithm) and QS, you get t = 1/2.  NFS has two parameters, so t = 1/3. ECM also has t = 1/2 because it uses only one parameter, the smoothness bound B. If you want to get t = 1/4, you have to find a third parameter to optimize.  No one has found one yet. That is the answer to your question.<br/>
<br/>
Note that some choices made in some factoring algorithms don't count as parameters.  For example, the number of polynomials used in the multiple-polynomial quadratic sieve, and the upper bound on large primes kept, don't affect t.  They affect the running time only in making c smaller.  So you have to find a third parameter that matters in order to get (*) with t = 1/4.  Or find three completely different new parameters.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-08-07T19:27:00Z</updated>
    <published>2019-08-07T19:27:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-08-14T17:01:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/08/07/report-from-wads</id>
    <link href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html" rel="alternate" type="text/html"/>
    <title>Report from WADS</title>
    <summary>I’m in Edmonton, Canada for WADS, which just finished, and CCCG, which is just about to begin.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m in Edmonton, Canada for <a href="http://wads.org/">WADS</a>, which just finished, and <a href="http://cccg.ca/">CCCG</a>, which is just about to begin.</p>

<p>The three invited talks at WADS were by Rasmus Pagh, Bob Tarjan, and me. Pagh spoke on methods for representing sets of elements by concise sketches so that the size of intersections or unions of the sets could be rapidly and accurately estimated. A famous method for this is <a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>, in which one represents a set by the  elements with the smallest values of some hash function; the size of the overlap in representations is then an accurate estimator for the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity</a> of pairs of sets. New to me were -bit variations of MinHash, in which you can get almost as accurate a representation in much less space by mapping each element of the MinHash set to  by another hash function. This works well when the Jaccard similarity is bounded away from both  and , and Pagh spoke about some recent research he and others had done on finding even more accurate methods when it is near  or near .</p>

<p>Tarjan spoke about <a href="https://arxiv.org/abs/1812.06177">parallel algorithms for connected components in graphs</a>, an old area but one in which apparently there have been frequent published mistakes. He presented a modular analysis of the algorithms in this area according to some basic operations they perform (hooking together roots of trees on components, propagating that root information downwards through the trees, flattening the trees to make the information propagate more quickly, and the like) and showed that simple combinations of these operations lead to new, simple, efficient and more importantly provably-correct algorithms.</p>

<p>My talk, “Graphs in Nature”, was about finding graph-theoretic characterizations of surface-embedded graphs arising in natural processes, and using those characterizations to find algorithms to reconstruct synthetic geometric structures of the same type from their graphs. I also gave roughly the same talk a month earlier, at the Symposium on Geometry Processing in Milan. <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-19.pdf">I’ve put my talk slides online</a> in case anyone else is interested.</p>

<p>The best paper award went to Hüseyin Acan, Sankardeep Chakraborty, Seungbum Jo and Srinivasa Rao Satti for their paper “<a href="https://arxiv.org/abs/1902.09228">Succinct Data Structures for Families of Interval Graphs</a>”. I can’t tell you much about the talk because, unfortunately, I missed it. I didn’t know it was the best paper until the business meeting that evening, so I went to the other parallel session instead.</p>

<p>I think the contributed talk from Tuesday that most stood out to me was Bryce Sandlund’s, on offline dynamic graph algorithms. This is a type of problem <a href="https://doi.org/10.1006/jagm.1994.1033">I worked on long ago for minimum spanning trees</a> in which you get as input a whole sequence of edge insertions and deletions in a graph, and must produce as output the sequence of changes to the solution to whatever you’re trying to solve. <a href="http://doi.org/10.1007/978-3-030-24766-9_40">Bryce’s new paper with Peng and Sleator</a> solves similar problems for higher-order graph connectivity. The main idea is to hierarchically decompose the update sequence into intervals, and then represent the non-dynamic part of the graph within each interval by a smaller equivalent replacement graph whose size is proportional to the interval length. At the end of his talk, Bryce hinted that he could also solve incremental problems (where the updates are given one at a time rather than all in advance, but are only insertions) using similar methods in a forthcoming paper.</p>

<p>I was inspired by Caleb Levy’s talk on <a href="https://en.wikipedia.org/wiki/Splay_tree">splay trees</a> (in which he showed that <a href="https://arxiv.org/abs/1907.06309">inserting elements in either the preorder or postorder of another binary search tree takes linear time</a>) to ask the following question: we know either by time-reversing the tree rotation operations or from the <a href="https://en.wikipedia.org/wiki/Geometry_of_binary_search_trees">geometric model of dynamic search trees</a> that any given access sequence should have the same optimal cost as its reverse. So from the <a href="https://en.wikipedia.org/wiki/Optimal_binary_search_tree">dynamic optimality conjecture</a> it should also be true that (up to constant factors) splay trees have the same performance on the reverse of any access sequence as they do on the unreversed sequence. Can this be proven?</p>

<p>From the business meeting, we learned that attendance and paper submissions were down by around 15% from the previous WADS. The acceptance rate is roughly the same, just under 50%. I suspect the smaller size is because the location is not as appealing, but it turns out to be a perfectly pleasant place to have a conference: the weather in Edmonton is pleasant this time of year (except for the thunderstorm), and there are abundant restaurants, good coffee shops, and lodging within walking distance of the conference center. WADS alternates with SWAT, which next year will be in the Faroe Islands. And then WADS 2021 (and CCCG 2021) will be in Halifax, Nova Scotia, which is both more touristy than Edmonton and easier to reach from the east coast and Europe. So I suspect the numbers will improve again.</p>

<p>WADS is moving towards a more democratically elected steering committee formed from some combination of past PC chairs and at-large elections. They have already started implementing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">SafeTOC recommendations</a> for combatting harassment and discrimination in theory conferences. And in a show of hands at the business meeting, the attendees were strongly in favor of moving towards double blind peer review for submissions. The conference is not really open access, though (its proceedings are published by Springer LNCS with special issues in Springer’s <em>Algorithmica</em> and Elsevier’s <em>Computational Geometry</em>) and there seems to be little pressure for that to change any time soon.</p>

<p>On to CCCG!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102578298917323647">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-08-07T17:27:00Z</updated>
    <published>2019-08-07T17:27:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-08-10T23:15:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16143</id>
    <link href="https://rjlipton.wordpress.com/2019/08/06/code-it-up/" rel="alternate" type="text/html"/>
    <title>Code It Up</title>
    <summary>So you think you have a proof that P=NP Randi 2014 documentary source James Randi is a magician who has challenged paranormal claims of all kinds. Today Ken and I want to make a suggestion to those who claim they have proved P=NP. No the claim to have a proof that P=NP is not a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>So you think you have a proof that P=NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png"><img alt="" class="alignright wp-image-18" height="192" src="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png?w=144&amp;h=192" width="144"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Randi 2014 documentary <a href="https://en.wikipedia.org/wiki/An_Honest_Liar">source</a></font></td>
</tr>
</tbody>
</table>
<p>
James Randi is a magician who has challenged paranormal claims of all kinds.</p>
<p>
Today Ken and I want to make a suggestion to those who claim they have proved P=NP.<br/>
<span id="more-16143"/></p>
<p>
No the claim to have a proof that P=NP is not a paranormal claim. But such claims are related to Randi—or the Amazing Randi as he is called. We talked about him before <a href="https://rjlipton.wordpress.com/2012/02/23/an-amazing-result/">here</a>.</p>
<p>
Randi once helped run a contest to see who could find gold with their dowsing rod. He explained why he doubted one contestant: </p>
<blockquote><p><b> </b> <em> If they really could find gold, why were they dressed so poorly, and why were they so interested in winning the prize? </em>
</p></blockquote>
<p/><p>
I have the same question about those who claim that they have a proof that P=NP. Usually the proof is constructive and I agree with Randi:</p>
<blockquote><p><b> </b> <em> If they really could solve P=NP, why <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p/><p>
You get the idea.</p>
<p>
Ken adds the obvious remark that if a foreign power or intelligence agency discovered P=NP, or factoring in P, they would still keep the lean-and-hungry look. But they are not the kind we are addressing here.</p>
<p>
</p><p/><h2> Coding Helps </h2><p/>
<p/><p>
Let’s look at a claims that P=NP is resolved. Yes, such a result is unlikely—many would say impossible. But we do get claims like this:</p>
<blockquote><p><b> </b> <em> The following <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> is known to be a NP-complete problem; the following <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> is known to be a polynomial time problem. I can reduce <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal H}"/> to <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\cal E}"/> in polynomial time. </em>
</p></blockquote>
<p/><p>
Usually the reduction is the reason their proof fails. Their claims about <img alt="{\cal H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal H}"/> and <img alt="{\cal E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cal E}"/> are usually correct, since they are in the literature. </p>
<p>
The reduction is often complicated, often poorly defined, often defined by example. Giving a precise definition for the reduction is critical. This is the reason we suggest the following: </p>
<blockquote><p><b> </b> <em> <i>Write the reduction down in code.</i> </em>
</p></blockquote>
<p>Even better, write it as a program in a real language such as Python. </p>
<p>
There are two advantages in doing this. </p>
<ul>
<li>
Writing it as a program in a real language will likely force one to define it precisely. <p/>
</li><li>
Writing it down will also allow one to run the program on examples.
</li></ul>
<p>
The later point is the key point. Even trying your method on tiny examples is useful. Even better if you can say the following we might read the proof: </p>
<blockquote><p><b> </b> <em> <i>I have tried my code on the following public set of difficult SAT problems. The code solved all in less than three minutes each.</i> </em>
</p></blockquote>
<p>This claim would greatly improve the likelihood that people might take your claims seriously. That your code worked correctly, forgetting the running time, would improve confidence. Greatly. </p>
<p>
</p><p/><h2> The Animal Farm View<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> </h2><p/>
<p/><p>
Ken worries that some NP-complete problems are more equal than others. That is some problems, even though they are NP-complete may require reductions that blow up when encoding SAT. </p>
<p>
We wrote about this <a href="https://rjlipton.wordpress.com/2012/04/22/the-travelling-salesmans-power/">before</a> regarding the “Power Index” idea of Richard Stearns and Harry Hunt III. In their <a href="http://www.cs.albany.edu/~res/powerindex.pdf">paper</a> they gave evidence that the reductions from SAT <em>to</em> many familiar NP-complete problems <em>must</em> expand the size of instances quadratically, insofar as those problems have <em>power index</em> <img alt="{0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.5}"/>. This was based on their “SAT Hypothesis” which anticipated current forms of the Exponential Time Hypothesis, which we have <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">discussed</a>.</p>
<p>
Ken ponders a related issue. Even problems with power index <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> run into the success of practical solvers. This means: </p>
<blockquote><p><b> </b> <em> Anyone citing algorithmic success as evidence toward a claim of P=NP must compete with the real-world success of algorithms that do not represent claims of P=NP. </em>
</p></blockquote>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/22/rankings-versus-ratings/">times</a> <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">discussed</a> the practical success of SAT-solvers on myriad real-world instances. </p>
<p>
This situation has become real in the argument over achieving quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>. One who claims that quantum is superior to classic must worry that that classical algorithms can improve without making P=NP. A headline example from last year was when Ewin Tang—as a high-school senior—<a href="https://arxiv.org/abs/1807.04271">found</a> a classical way to remove a plausible quantum advantage in a matrix-completion problem that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">underlies</a> recommender systems.  There are many “industrial strength” examples in this argument—see this May 2019 <a href="https://www.technologyreview.com/s/613507/the-new-benchmark-quantum-computers-must-beat-to-achieve-quantum-supremacy/">story</a> for a start.</p>
<p>
</p><p/><h2> But… </h2><p/>
<p/><p>
Ken’s insightful comments aside, the key point is still: </p>
<blockquote><p><b> </b> <em> <i>Coding up your claimed algorithm for that NP-complete problem will still enhance belief.</i> </em>
</p></blockquote>
<p>This will happen even if the algorithm only succeeds on tiny examples. Indeed, if you cannot do this then I suggest that you will have an impossible time getting anyone to listen.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How useful is this advice for the vast majority of us who are <em>not</em> claiming P=NP or the opposite?</p>
<p/></font></font></div>
    </content>
    <updated>2019-08-06T20:45:04Z</updated>
    <published>2019-08-06T20:45:04Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claims"/>
    <category term="complexity"/>
    <category term="heuristic algorithms"/>
    <category term="James Randi"/>
    <category term="programming"/>
    <category term="quantum advantage"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-08-14T21:20:54Z</updated>
    </source>
  </entry>
</feed>
