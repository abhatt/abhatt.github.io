<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-05-05T20:39:19Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/066</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/066" rel="alternate" type="text/html"/>
    <title>TR21-066 |  Dimension-free Bounds and Structural Results in Communication Complexity | 

	Lianna Hambardzumyan, 

	Hamed Hatami, 

	Pooya Hatami</title>
    <summary>The purpose of this article is to initiate a systematic study of dimension-free relations between basic communication and query complexity measures  and various  matrix norms.  In other words, our goal is to obtain    inequalities that bound a parameter   solely as a function of another parameter. This is in contrast to perhaps the more common framework in communication complexity  where  poly-logarithmic dependencies on the number of input bits are   tolerated. 


Dimension-free bounds are also closely related to structural results, where one seeks to describe the structure of Boolean matrices and functions that have low complexity.  We prove such  theorems for several communication and query complexity measures as well as various matrix and operator norms. In several other cases we show that such bounds do not exist. 


We propose several conjectures, and establish that, in addition to applications in complexity theory, these   problems are central to  characterization of the idempotents of the algebra of Schur multipliers, and could lead to new extensions of  Cohen's celebrated idempotent theorem regarding the Fourier algebra.</summary>
    <updated>2021-05-05T18:59:23Z</updated>
    <published>2021-05-05T18:59:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/tpdp21-cfp/</id>
    <link href="https://differentialprivacy.org/tpdp21-cfp/" rel="alternate" type="text/html"/>
    <title>Call for Papers - Workshop on the Theory and Practice of Differential Privacy (TPDP 2021)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Work on differential privacy spans a number of different research communities, including theoretical computer science, machine learning, statistics, security, law, databases, cryptography, programming languages, social sciences, and more.
Each of these communities may choose to publish their work in their own community’s venues, which could result in small groups of differential privacy researchers becoming isolated.
To alleviate these issues, we have the Workshop on the <a href="https://tpdp.journalprivacyconfidentiality.org/">Theory and Practice of Differential Privacy</a> (TPDP), which is intended to bring these subcommunities together under one roof (well, a virtual one at least for 2020 and 2021).</p>

<p>We have just posted the <a href="https://tpdp.journalprivacyconfidentiality.org/2021/TPDP2021CfP.pdf">Call for Papers</a> for <a href="https://tpdp.journalprivacyconfidentiality.org/2021/">TPDP 2021</a>, which will be a workshop affiliated with <a href="https://icml.cc/Conferences/2021/">ICML 2021</a>.
The submission deadline is Friday, May 28, 2021, Anywhere on Earth (conveniently, two days after the deadline for NeurIPS 2021).
Submissions are extended abstracts of up to four pages in length, and will undergo a lightweight review process, based mostly on relevance and interest to the differential privacy community.
The workshop is non-archival, so feel free to submit recent work at any stage of publication.
Submissions will be on <a href="https://openreview.net/group?id=ICML.cc/2021/Workshop/TPDP">OpenReview</a>, but since submitted work may be preliminary, the process will be “closed” similar to traditional review processes.
One goal of the workshop is to be inclusive and welcoming to newcomers to the differential privacy community, so please consider participating even if you are new to the field.</p>

<p>Most papers will be presented as posters at a (virtual) poster session, while a few papers will be selected for spotlight talks.
There will also be plenary talks by <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a> (Hebrew University of Jerusalem) and <a href="https://www2.math.upenn.edu/~ryrogers/">Ryan Rogers</a> (LinkedIn).
The program co-chairs are <a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a> and <a href="http://www.gautamkamath.com/">myself</a>.
Please submit your best work on differential privacy, and hope to see you there!</p>
<p align="center">
  <img src="https://differentialprivacy.org/images/Ligett.png"/>
  <img src="https://differentialprivacy.org/images/Rogers.png"/> <br/>
    <i>Invited speakers Katrina Ligett and Ryan Rogers</i>
</p></div>
    </summary>
    <updated>2021-05-05T14:00:00Z</updated>
    <published>2021-05-05T14:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-05-05T13:39:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18701</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/05/05/how-to-teach-math/" rel="alternate" type="text/html"/>
    <title>How to Teach Math?</title>
    <summary>The only way to learn mathematics is to do mathematics—Paul Halmos Angie Hodge is an Associate Professor of mathematics at Northern Arizona University. Her interests as stated on her website are focused mainly on education, mentoring, and equity in the STEM disciplines. Today I thought we would discuss the issue of teaching and learning math […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>The only way to learn mathematics is to do mathematics—Paul Halmos</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/05/how-to-teach-math/an/" rel="attachment wp-att-18704"><img alt="" class="alignright size-thumbnail wp-image-18704" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/an-150x150.jpg?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
Angie Hodge is an Associate Professor of mathematics at Northern Arizona University. Her interests as stated on her <a href="https://directory.nau.edu/person/amh952">website</a> are focused mainly on education, mentoring, and equity in the STEM disciplines. </p>
<p>
Today I thought we would discuss the issue of teaching and learning math and complexity theory.</p>
<p>
I am now retired from Georgia Tech. But I continue to be interested in how we can teach math. Dually how we can learn math. I still try to learn math—not for formal classes, nor in formal classes—but to help advance my own research. Even now I find that I need to learn some topics to help write a post or to solve a problem. </p>
<p>
On this blog with Ken I am also interested in still helping others learn. Some call that teaching. This is therefore the topic for today.</p>
<p>
</p><p/><h2> First An Issue </h2><p/>
<p/><p>
One thing that drives me nuts about learning new math is what I will call the </p>
<blockquote><p><b> </b> <em> <i>“It is too obvious to state” principle.</i> </em>
</p></blockquote>
<p>What I mean is that when you start to learn material from some corner of math you get the key definitions and the main results. What I do not always get is some totally obvious ideas. Does this make any sense?</p>
<p>
Here is an example. Consider the class of sequences that are defined by linear <a href="https://en.wikipedia.org/wiki/Recurrence_relation">recurrences</a>. That is: a recursion that defines a sequence as a linear combination of earlier terms. One of the most famous is the Fibonacci numbers: 	</p>
<p align="center"><img alt="\displaystyle  F_n = F_{n-1} + F_{n-2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F_n+%3D+F_%7Bn-1%7D+%2B+F_%7Bn-2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>And <img alt="{F_0=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF_0%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{F_1=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF_1%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
The property we are interested in is: </p>
<blockquote><p><b> </b> <em> <i>Is a product of two such sequences also of the same form?</i> </em>
</p></blockquote>
<p>This is a basic question, but it is not trivial to find the <a href="https://reader.elsevier.com/reader/sd/pii/0012365X79901869?token=C0E36B1EE6735F9AB6140E86924EB1A19F236C9507028E02CB912D21952F2438487C78DDBB68CC1541D2E9CF5754B8C1&amp;originRegion=us-east-1&amp;originCreation=20210415000540">answer</a>. </p>
<p>
</p><p/><h2> How To Teach? </h2><p/>
<p/><p>
This is an ancient question that we all probably have thought about from time to time. It is complicated by the recent issue of most classes being done via online. Hodge has some nice stuff on teaching, especially on Inquiry-Based Learning (IBL). </p>
<ul>
<li>
See her <a href="https://www.artofmathematics.org/blogs/cvonrenesse/guest-blog-by-angie-hodge">blog</a>. <p/>
</li><li>
See <a href="http://math.uchicago.edu/~boller/IBL/">this</a> for her comments on <em>Inquiry-Based Learning</em>. <p/>
</li><li>
See her thoughts on <a href="https://www.maa.org/sites/default/files/Programs/MathFest2018_IPS_Hodge2.pdf">IBL</a>.
</li></ul>
<p>
</p><p/><h2> Ken’s Similar Question </h2><p/>
<p/><p>
Ken writes: I am interested in manipulating logistic curves. Such curves not only undergird the chess rating system and the theory of standardized tests, they relate directly to the design of chess programs which I use to take my data. This decade’s neural chess-playing programs, following on from AlphaZero, express values directly in terms of the likelihood of winning, as numbers between 0 and 1, rather than traditional evaluation schemes built on counting 1.00 for a pawn, 3–3.5 for a knight or bishop, and so on. </p>
<p>
The new likelihood numbers follow a logistic curve. I especially want to convert from the evaluation numbers to them. After doing this conversion for various major chess programs, I would like to average their values as input to my predictive model. This involves taking averages of logistic curves. The curves can be generalized to the <a href="https://en.wikipedia.org/wiki/Generalised_logistic_function">form</a> named for Francis Richards: </p>
<p align="center"><img alt="\displaystyle  f(x) = A + \frac{K-A}{(C + Qe^{-Bx})^{1/\nu}} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+A+%2B+%5Cfrac%7BK-A%7D%7B%28C+%2B+Qe%5E%7B-Bx%7D%29%5E%7B1%2F%5Cnu%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>for constant parameters <img alt="{A,K,B,C,Q,\nu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CK%2CB%2CC%2CQ%2C%5Cnu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The standard family has <img alt="{A=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{K=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{C=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{\nu=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cnu%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{Q=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, with <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the central parameter determining the slope of the curve <img alt="{f(t) = \frac{1}{1+e^{-Bx}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28t%29+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-Bx%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at <img alt="{x=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We can ask the basic question about intermediate families between the standard family and the most general kind:</p>
<blockquote><p><b> </b> <em> When does a linear combination of logistic curves belong to the same family? And if it doesn’t belong, how close to a member of the family does it come? </em>
</p></blockquote>
<p/><p>
My point is that I have not been able to find an easy source for answers. This strikes me as exactly the kind of question for which sites like MathOverflow and StackExchange exist. But it is also a nice instructional exercise for training students in both the grit and adventure of mathematical research. </p>
<p>
One can also pose literally the same as Dick’s question above: how about a product of two curves <img alt="{f_1(x),f_2(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%28x%29%2Cf_2%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from the family? The product still has values that run from <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> goes from <img alt="{-\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to <img alt="{+\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. If we want the curves all to have value <img alt="{f(0) = 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%280%29+%3D+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> then we can compose the product with a square root, viz. <img alt="{f(x) = \sqrt{f_1(x) f_2(x)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+%5Csqrt%7Bf_1%28x%29+f_2%28x%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, thus taking a geometric rather than arithmetic mean. I mentioned other nuts-and-bolts problems about logistic curves in this <a href="https://rjlipton.wpcomstaging.com/2018/08/25/do-you-want-to-know-a-secret/">post</a> and its longer <a href="https://rjlipton.wpcomstaging.com/2018/09/07/sliding-scale-problems/">followup</a>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The following video shows how not to teach math: <a href="https://www.youtube.com/watch?v=vU5LoCLGMdQ&amp;t=109s">The Kettles</a> do math.</p>
<p/><p><br/>
[some format and word tweaks]</p></font></font></div>
    </content>
    <updated>2021-05-05T13:56:56Z</updated>
    <published>2021-05-05T13:56:56Z</published>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="Angie Hodge"/>
    <category term="Fibonacci sequence"/>
    <category term="IBL"/>
    <category term="learn"/>
    <category term="logistic curves"/>
    <category term="teach"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-05-05T20:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/065</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/065" rel="alternate" type="text/html"/>
    <title>TR21-065 |  One-way communication complexity and non-adaptive decision trees | 

	Nikhil Mande, 

	Swagato Sanyal</title>
    <summary>We study the relationship between various one-way communication complexity measures of a composed function with the analogous decision tree complexity of the outer function. We consider two gadgets: the AND function on 2 inputs, and the Inner Product on a constant number of inputs. Let $IP$ denote Inner Product on $2b$ bits.

1) If $f$ is a total Boolean function that depends on all of its inputs, the bounded-error one-way quantum communication complexity of $f \circ IP$ equals $\Omega(n(b-1))$.

2) If $f$ is a partial Boolean function, the deterministic one-way communication complexity of $f \circ IP$ is at least $\Omega(b \cdot D_{dt}^{\rightarrow}(f))$, where $D_{dt}^{\rightarrow}(f)$ denotes the non-adaptive decision tree complexity of $f$.

For our quantum lower bound, we show a lower bound on the VC-dimension of $f \circ IP$, and then appeal to a result of Klauck [STOC'00].
Our deterministic lower bound relies on a combinatorial result due to Frankl and Tokushige [Comb.'99].

It is known due to a result of Montanaro and Osborne [arXiv'09] that the deterministic one-way communication complexity of $f \circ XOR_2$ equals the non-adaptive parity decision tree complexity of $f$.
In contrast, we show the following with the gadget $AND_2$.

1) There exists a function for which even the randomized non-adaptive AND decision tree complexity of $f$ is exponentially large in the deterministic one-way communication complexity of $f \circ AND_2$.

2) For symmetric functions $f$, the non-adaptive AND decision tree complexity of $f$ is at most quadratic in the (even two-way) communication complexity of $f \circ AND_2$.

In view of the first point, a lower bound on non-adaptive AND decision tree complexity of $f$ does not lift to a lower bound on one-way communication complexity of $f \circ AND_2$.
The proof of the first point above uses the well-studied Odd-Max-Bit function.
For the second bullet, we first observe a connection between the one-way communication complexity of $f$ and the M\"obius sparsity of $f$, and then use a known lower bound on the M\"obius sparsity of symmetric functions. An upper bound on the non-adaptive AND decision tree complexity of symmetric functions follows implicitly from prior work on combinatorial group testing; for the sake of completeness, we include a proof of this result.</summary>
    <updated>2021-05-05T13:16:19Z</updated>
    <published>2021-05-05T13:16:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3524</id>
    <link href="https://agtb.wordpress.com/2021/05/05/netecon-2021/" rel="alternate" type="text/html"/>
    <title>NetEcon 2021</title>
    <summary>NetEcon’21, the 16th Workshop on the Economics of Networks, Systems and Computation, will take place on July 23, 2021. NetEcon’21 is a workshop of EC’21, the 22nd ACM Conference on Economics and Computation, which will be held on July 19-23, 2021, co-located with the 6th World Congress of the Game Theory Society. The aim of NetEcon […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>NetEcon’21,</strong> the 16th Workshop on the Economics of Networks, Systems and Computation, will take place on July 23, 2021. NetEcon’21 is a workshop of EC’21, the 22nd ACM Conference on Economics and Computation, which will be held on July 19-23, 2021, co-located with the 6th World Congress of the Game Theory Society. The aim of NetEcon is to foster discussions on the application of economic and game-theoretic models and principles to address challenges in the development of networks and network-based applications and services.</p>



<p>Details regarding submission rules and dates can be found at <a href="https://netecon21.gametheory.online/" rel="noreferrer noopener" target="_blank">https://netecon21.gametheory.online/</a>. A novelty compared with prior editions of the workshop is that papers that were already formatted for and submitted to EC’21 or SIGMETRICS’21 may retain this format (for submission) if submitted together with all the reviews (see submission guidelines for details).</p></div>
    </content>
    <updated>2021-05-05T01:12:21Z</updated>
    <published>2021-05-05T01:12:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-05-05T20:37:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/064</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/064" rel="alternate" type="text/html"/>
    <title>TR21-064 |  Streaming approximation resistance of every ordering CSP | 

	Santhoshini Velusamy, 

	Noah Singer, 

	Madhu Sudan</title>
    <summary>An ordering constraint satisfaction problem (OCSP) is given by a positive integer $k$ and a constraint predicate $\Pi$ mapping permutations on $\{1,\ldots,k\}$ to $\{0,1\}$. Given an instance of OCSP$(\Pi)$ on $n$ variables and $m$ constraints, the goal is to find an ordering of the $n$ variables that maximizes the number of constraints that are satisfied, where a constraint specifies a sequence of $k$ distinct variables and the constraint is satisfied by an ordering on the $n$ variables if the ordering induced on the $k$ variables in the constraint satisfies $\Pi$. Ordering constraint satisfaction problems capture natural problems including ''Maximum acyclic subgraph (MAS)'' and ''Betweenness''. 

In this work we consider the task of approximating the maximum number of satisfiable constraints in the (single-pass) streaming setting, where an instance is presented as a stream of constraints. We show that for every $\Pi$, OCSP$(\Pi)$ is approximation-resistant to $o(\sqrt{n})$-space streaming algorithms, i.e., algorithms using $o(\sqrt{n})$ space cannot distinguish streams where almost every constraint is satisfiable from streams where no ordering beats the random ordering by a noticeable amount. In the case of MAS our result shows that for every $\epsilon&gt;0$, MAS is not $1/2+\epsilon$-approximable. The previous best inapproximability result only ruled out a $3/4$ approximation.

Our results build on a recent work of Chou, Golovnev, Sudan, and Velusamy who show tight inapproximability results for some constraint satisfaction problems over arbitrary (finite) alphabets. We show that the hard instances from this earlier work have the following ''small-set expansion'' property: in every partition of the hypergraph formed by the constraints into small blocks, most of the hyperedges are incident on vertices from distinct blocks. By exploiting this combinatorial property, in combination with a natural reduction from CSPs over large finite alphabets to OCSPs, we give optimal inapproximability results for all OCSPs.</summary>
    <updated>2021-05-04T21:39:50Z</updated>
    <published>2021-05-04T21:39:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=55</id>
    <link href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – An Interview with the PC Chairs of ALT 2021</title>
    <summary>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fourth post in the series, an interview with ALT 2021 PC Chairs <a href="http://vtaly.net/">Vitaly Feldman</a> and <a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a>, written by <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a> and <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>.</p>



<hr class="wp-block-separator"/>



<p>We had the great opportunity to attend <em>The 32nd International Conference on Algorithmic Learning Theory</em>, held online between March 16-19, 2021, and co-chaired by Vitaly Feldman and Katrina Ligett. Vitaly is a research scientist at Apple AI Research and has done foundational works in machine learning and privacy-preserving data analysis. Katrina is an Associate Professor of Computer Science at the Hebrew University of Jerusalem and has done pivotal works in data privacy, algorithmic fairness, algorithmic game theory, and online algorithms. We asked for an interview with them about their experiences and perspectives as co-chairs, to which they kindly agreed. We are happy to share with the readers the excerpts of this interview.</p>



<p class="has-text-align-center"><img src="https://lh4.googleusercontent.com/7RUOfC-v06amphwIhfCYsQNH4jUg82AVsePZcbWO0D40DhSRk-Cf_wnXx9y5RI-qVYz6D-IRAxRzsQ9lWBpraofuggrTYC_sG40GehOCvSrQyZfj1khlMTVqK23NKOZueGcbK_xa" style="width: 225px;"/>           <img height="252" src="https://lh4.googleusercontent.com/lUMmpb6Bcfq3bPljS7jYaF2TFaXRks64--IeslcdR3WzqnCtUETu-ymoOSxm7ys_6eyRFb2mGmd1mCe1boNHdxii0d1_UCthAEJy_eTsWsGQsFKpsV5snZe3Nm9g-QDy0JTnzPKx" width="194"/></p>



<p><strong>How it started</strong></p>



<p>How are chairs and program committees chosen? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: The chairs are selected by the Association for Algorithmic Learning Theory (AALT) Steering Committee (<a href="http://algorithmiclearningtheory.org/alt-steering-committee/">http://algorithmiclearningtheory.org/alt-steering-committee/</a>), and the chairs then select the program committee members. Vitaly and I brainstormed potential PC member names, solicited additional suggestions, and also considered the lists of people who have served on recent ALT and COLT PCs. In building the PC, we had many considerations in mind, including coverage of research areas, and various metrics of diversity.</p>



<p><strong>The chairs’ role</strong></p>



<p>What are the different tasks a chair has? What is the most difficult task?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: At a high level, the roles of the PC chairs are to build the PC, oversee the reviewing process and create the conference program. Practically, though, there are a lot of decisions that need to be discussed, emails to be sent, and a lot of organizational aspects to tend to—configuring the reviewing platform, sending reminders, chasing down late reviews, and so on. Vitaly and I have a very, very long joint “to do” list—and luckily, it’s now almost all crossed off! We also had additional responsibilities this year because of the move to the virtual conference format, including selecting the technologies, overseeing the pre-recording process, and much more.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I think the hardest and probably the most time-consuming is making the accept/reject decisions on papers.  For a large fraction of the papers arriving at the decision requires getting a sense of the results; understanding the main points in reviews, author responses and discussion (while calibrating them to the PC members and reviewers); ensuring that each paper is properly discussed by chasing reviewers, asking questions and often soliciting additional opinions. We also needed to come up with a set of criteria for deciding on borderline cases and make sure that these criteria are applied as consistently as possible. At the end it is a rather long and iterative process that luckily for us has converged to a program we are happy with.</p>



<p>How much time do you spend doing chair tasks? How do you balance chairing a conference (a massive amount of work) with all your other commitments? Do you turn down other service items you would generally accept, etc.?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: It’s difficult to estimate the number of hours, but I think we have been meeting regularly since early June 2020, and we’re only wrapping up our work now, in late March 2021. It’s a much longer-timeframe commitment than serving as a PC member. I actually am chairing a second conference this year, FORC, and together it makes for a pretty serious load. As a result, I have been declining all other conference-related service. I also have a couple of other pretty substantial service commitments, as well, so I just don’t have bandwidth this year for additional PC and Area Chair-type roles.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s hard to tell how much time we spent in total. My rough estimate is that it’s about a month of full-time work. I also had to decline most other service commitments during that period some of which I’d normally accept. Naturally, it also slows down other work so I definitely had to lean more on my collaborators in some of the ongoing projects <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;"/></p>



<p>Can chairs bring their own personality into the conference? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: One area where the chairs enjoy freedom is in selecting the keynote and tutorial speakers. I’m biased, of course, but I think we chose very well, and all of these speakers (Joelle Pineau, Shay Moran, and Costis Daskalakis) gave excellent talks (they were recorded—check them out if you missed them)! We also were fortunate to be able to work with amazing partners who organized the mentoring workshop (Surbhi Goel, Nika Hagtalab, and Ellen Vitercik) and the Women in ML Theory event (Tosca Lechner and Ruth Urner). These aspects of the conference beyond the papers are a way for the chairs to express their priorities.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: The chairs have a lot of freedom in choosing how to run the review process, design the conference program and who else will be involved. So, inevitably, the chairs’ personalities and tastes end up being reflected in the final results. </p>



<p>Does the online conference impact the chair job? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Typically, the PC chairs build the program, and then many details of organizing and running the conference get handed off to local organization chairs. But this year, since ALT was held virtually, there were many unusual tasks that fell to the PC chairs—not just the obvious ones like choosing the technologies and format and negotiating those contracts, but smaller things like chasing down authors who failed to upload their recordings, and developing instructions for people in various roles to interact with the conference platform.</p>



<p class="has-text-color" style="color: #0000ff;">In addition, COVID times placed strains on many people, which made it more challenging to recruit PC members, and resulted in a higher than usual rate of late reviews and PC drop-outs, which of course left us scrambling.</p>



<p>What motivates you to spend time on a conference service?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: We all rely on the conference system for our personal professional advancement, and for the advancement of our field as a whole. So we all owe that system our service, of course, according to our abilities, availability, and seniority. Also, it’s fun to get this different perspective on the conference review process and on the field. And it’s an honor to be entrusted with shepherding a conference for a year and hopefully nurturing its growth.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s a mix of (1) contribution to the community I’m a member of and, perhaps, an opportunity to improve some of its processes (2) a learning experience that gives one a higher-level view of the research that is happening and people who do it (3) honor and recognition that come with the job.</p>



<p><strong>Awards </strong></p>



<p>How do you decide which papers were chosen as awards? </p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: A necessary condition for a paper to receive an award is that at least one of the PC members/reviewers assigned to the paper is excited about the results.  So we start by looking at papers with the highest scores (typically all papers that received at least one “strong accept”) and reading their reviews. This allowed us to narrow down the list to a set of 5-6 candidates. From those we selected the winners by learning more about the results and selecting those, we found the most significant and interesting for the community.</p>



<p><strong>The review process</strong></p>



<p>What are your thoughts about the current peer review process in ALT? What are the downsides and advantages? Do you have suggestions for improvement?</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: It is common that confidence in correctness of the results in a conference submission is based on higher-level sanity checks and general intuition of the reviewers. Naturally, the more interesting and important result the more likely it is to be scrutinized. At this ALT we did not run into a situation where the authors’ reputation affected our confidence in the correctness of the results. In case of concerns about correctness of an interesting result we would ask either an expert on the PC or an external expert to try to verify the result.</p>



<p class="has-luminous-vivid-orange-color has-text-color">ALT currently relies on a traditional theory conference model of reviewing and for a typical submission has several PC members who are experts in the subarea. The reviewing load is also relatively light (8 papers per PC member). So I think that the overall reviewing quality is pretty much as good as it gets in ML (and is similar to COLT). Naturally, the model is not perfect and there is still variation in the quality of individual reviews. This year many more reviewers and PC members were under unusual time pressure due to the pandemic so perhaps the variation was higher than usual.</p>



<p><strong>The future</strong></p>



<p>What are your suggestions for the next chair? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Make sure you have a good co-chair. <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;"/> Vitaly has been a great partner for this process—fun to work with, reliable, always willing to pitch in even on the less-fun tasks, and I have great respect for his technical perspective.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that diversity of perspectives and expertise is useful in several ways. Most notably, it gives the chairs a wider network of people to select the PC from. But I completely agree with Katrina, that the most important thing is the ability of co-chairs to work well together: after all, it’s a lot of work and complicated decisions that need to be made jointly. Here, I couldn’t have asked for more: Katrina is amazing both professionally and personally. Working with her was definitely the highlight of being the ALT co-chair and learned a lot from her in the process as well.</p></div>
    </content>
    <updated>2021-05-04T16:40:08Z</updated>
    <published>2021-05-04T16:40:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2021-05-05T20:39:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=559</id>
    <link href="https://tcsplus.wordpress.com/2021/05/04/tcs-talk-wednesday-may-12-santhoshini-velusamy-harvard-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 12 — Santhoshini Velusamy, Harvard University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Santhoshini Velusamy from Harvard University will speak about “Classification of the approximability of all finite Max-CSPs in the dynamic streaming setting” (abstract below). You can reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://scholar.harvard.edu/santhoshiniv/home"><strong>Santhoshini Velusamy</strong></a> from Harvard University will speak about “<em>Classification of the approximability of all finite Max-CSPs in the dynamic streaming setting</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A maximum constraint satisfaction problem, Max-CSP(F), is specified by a finite family of constraints F, where each constraint is of arity k. An instance of the problem on n variables is given by m applications of constraints from F to length-k subsequences of the n variables, and the goal is to find an assignment to the n variables that satisfies the maximum number of constraints. The class of Max-CSP(F) includes optimization problems such as Max-CUT, Max-DICUT, Max-3SAT, Max-q-Coloring, Unique Games, etc.</p>
<p>In this talk, I will present our recent dichotomy theorem on the approximability of Max-CSP(F) for every finite family F, in the single-pass dynamic streaming setting. In this setting, at each time step, a constraint is either added to or deleted from the stream. In the end, the streaming algorithm must estimate the maximum number of constraints that can be satisfied using space that is only polylogarithmic in n. No background in streaming algorithms or constraint satisfaction problems will be needed to enjoy this talk!</p>
<p>The talk will be based on <a href="https://eccc.weizmann.ac.il/report/2021/011/">this paper</a>, and <a href="https://eccc.weizmann.ac.il/report/2021/063/">this paper</a> with Chi-Ning Chou, Alexander Golovnev, and Madhu Sudan.</p></blockquote></div>
    </content>
    <updated>2021-05-04T06:48:59Z</updated>
    <published>2021-05-04T06:48:59Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-05-05T20:38:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00689</id>
    <link href="http://arxiv.org/abs/2105.00689" rel="alternate" type="text/html"/>
    <title>CSAT and CEQV for nilpotent Maltsev algebras of Fitting length &gt; 2</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kompatscher:Michael.html">Michael Kompatscher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00689">PDF</a><br/><b>Abstract: </b>The circuit satisfaction problem CSAT(A) of an algebra A is the problem of
deciding whether an equation over A (encoded by two circuits) has a solution or
not. While solving systems of equations over finite algebras is either in P or
NP-complete, no such dichotomy result is known for CSAT(A). In fact, Idziak,
Kawalek and Krzaczkowski constructed examples of nilpotent Maltsev algebras A,
for which, under the assumption of ETH and an open conjecture in circuit
theory, CSAT(A) can be solved in quasipolynomial, but not polynomial time. The
same is true for the circuit equivalence problem CEQV(A).
</p>
<p>In this paper we generalize their result to all nilpotent Maltsev algebras of
Fitting length &gt;2. This not only advances the project of classifying the
complexity of CSAT (and CEQV) for algebras from congruence modular varieties,
but we also believe that the tools we developed are of independent interest in
the study of nilpotent algebras.
</p></div>
    </summary>
    <updated>2021-05-04T22:40:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00656</id>
    <link href="http://arxiv.org/abs/2105.00656" rel="alternate" type="text/html"/>
    <title>A 3D Advancing-Front Delaunay Mesh Refinement Algorithm</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Shankar P Sastry <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00656">PDF</a><br/><b>Abstract: </b>I present a 3D advancing-front mesh refinement algorithm that generates a
constrained Delaunay mesh for any piecewise linear complex (PLC) and extend
this algorithm to produce truly Delaunay meshes for any PLC. First, as in my
recently published 2D algorithm, I split the input line segments such that the
length of the subsegments is asymptotically proportional to the local feature
size (LFS). For each facet, I refine the mesh such that the edge lengths and
the radius of the circumcircle of every triangular element are asymptotically
proportional to the LFS. Finally, I refine the volume mesh to produce a
constrained Delaunay mesh whose tetrahedral elements are well graded and have a
radius-edge ratio less than some $\omega^* &gt; 2/\sqrt{3}$ (except ``near'' small
input angles). I extend this algorithm to generate truly Delaunay meshes by
ensuring that every triangular element on a facet satisfies Gabriel's
condition, i.e., its diametral sphere is empty. On an ``apex'' vertex where
multiple facets intersect, Gabriel's condition is satisfied by a modified
split-on-a-sphere (SOS) technique. On a line where multiple facets intersect,
Gabriel's condition is satisfied by mirroring meshes near the line of
intersection. The SOS technique ensures that the triangles on a facet near the
apex vertex have angles that are proportional to the angular feature size
(AFS), a term I define in the paper. All tetrahedra (except ``near'' small
input angles) are well graded and have a radius-edge ratio less than $\omega^*
&gt; \sqrt{2}$ for a truly Delaunay mesh. The upper bounds for the radius-edge
ratio are an improvement by a factor of $\sqrt{2}$ over current
state-of-the-art algorithms.
</p></div>
    </summary>
    <updated>2021-05-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00639</id>
    <link href="http://arxiv.org/abs/2105.00639" rel="alternate" type="text/html"/>
    <title>Model Counting meets F0 Estimation</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>A. Pavan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinodchandran:N=_V=.html">N. V. Vinodchandran</a>, Arnab Bhattacharyya, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meel:Kuldeep_S=.html">Kuldeep S. Meel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00639">PDF</a><br/><b>Abstract: </b>Constraint satisfaction problems (CSP's) and data stream models are two
powerful abstractions to capture a wide variety of problems arising in
different domains of computer science. Developments in the two communities have
mostly occurred independently and with little interaction between them. In this
work, we seek to investigate whether bridging the seeming communication gap
between the two communities may pave the way to richer fundamental insights. To
this end, we focus on two foundational problems: model counting for CSP's and
computation of zeroth frequency moments ($F_0$) for data streams.
</p>
<p>Our investigations lead us to observe striking similarity in the core
techniques employed in the algorithmic frameworks that have evolved separately
for model counting and $F_0$ computation. We design a recipe for translation of
algorithms developed for $F_0$ estimation to that of model counting, resulting
in new algorithms for model counting. We then observe that algorithms in the
context of distributed streaming can be transformed to distributed algorithms
for model counting. We next turn our attention to viewing streaming from the
lens of counting and show that framing $F_0$ estimation as a special case of
#DNF counting allows us to obtain a general recipe for a rich class of
streaming problems, which had been subjected to case-specific analysis in prior
works. In particular, our view yields a state-of-the art algorithm for
multidimensional range efficient $F_0$ estimation with a simpler analysis.
</p></div>
    </summary>
    <updated>2021-05-04T22:47:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00603</id>
    <link href="http://arxiv.org/abs/2105.00603" rel="alternate" type="text/html"/>
    <title>Quantum Advantage with Shallow Circuitsunder Arbitrary Corruption</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Atsuya Hasegawa, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gall:Fran=ccedil=ois_Le.html">François Le Gall</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00603">PDF</a><br/><b>Abstract: </b>Recent works by Bravyi, Gosset and K\"onig (Science 2018), Bene Watts et al.
(STOC 2019), Coudron, Stark and Vidick (QIP 2019) and Le Gall (CCC 2019) have
shown unconditional separations between the computational powers of shallow
(i.e., small-depth) quantum and classical circuits: quantum circuits can solve
in constant depth computational problems that require logarithmic depth to
solve with classical circuits. Using quantum error correction, Bravyi, Gosset,
K\"onig and Tomamichel (Nature Physics 2020) further proved that a similar
separation still persists even if quantum circuits are subject to local
stochastic noise.
</p>
<p>We prove that this quantum advantage persists even if the quantum circuits
can be subject to arbitrary corruption: in this paper we assume that any
constant fraction of the qubits (for instance, huge blocks of qubits) may be
arbitrarily corrupted at the end of the computation. We show that even in this
model, quantum circuits can still solve in constant depth computational
problems that require logarithmic depth to solve with bounded fan-in classical
circuits. This gives another compelling evidence of the computational power of
quantum shallow circuits.
</p>
<p>In order to show our result, we consider the Graph State Sampling problem
(which was also used in prior works) on expander graphs. We exploit the
"robustness" of expander graphs against vertex corruption to show that a
subproblem hard for small-depth classical circuits can still be extracted from
the output of the corrupted quantum circuit.
</p></div>
    </summary>
    <updated>2021-05-04T22:40:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00524</id>
    <link href="http://arxiv.org/abs/2105.00524" rel="alternate" type="text/html"/>
    <title>Fast mixing via polymers for random graphs with unbounded degree</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:James.html">James Stewart</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00524">PDF</a><br/><b>Abstract: </b>The polymer model framework is a classical tool from statistical mechanics
that has recently been used to obtain approximation algorithms for spin systems
on classes of bounded-degree graphs; examples include the ferromagnetic Potts
model on expanders and on the grid. One of the key ingredients in the analysis
of polymer models is controlling the growth rate of the number of polymers,
which has been typically achieved so far by invoking the bounded-degree
assumption. Nevertheless, this assumption is often restrictive and obstructs
the applicability of the method to more general graphs. For example, sparse
random graphs typically have bounded average degree and good expansion
properties, but they include vertices with unbounded degree, and therefore are
excluded from the current polymer model framework.
</p>
<p>We develop a less restrictive framework for polymer models that relaxes the
standard bounded-degree assumption, by reworking the relevant polymer models
from the edge perspective. The edge perspective allows us to bound the growth
rate of the number of polymers in terms of the total degree of polymers, which
in turn can be related more easily to the expansion properties of the
underlying graph. To apply our methods, we consider random graphs with
unbounded degrees from a fixed degree sequence and obtain approximation
algorithms for the ferromagnetic Potts model, which is a standard benchmark for
polymer models. Our techniques also extend to more general spin systems.
</p></div>
    </summary>
    <updated>2021-05-04T22:44:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00518</id>
    <link href="http://arxiv.org/abs/2105.00518" rel="alternate" type="text/html"/>
    <title>Computing Optimal Persistent Cycles for Levelset Zigzag on Manifold-like Complexes</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00518">PDF</a><br/><b>Abstract: </b>In standard persistent homology, a persistent cycle born and dying with a
persistence interval (bar) associates the bar with a concrete topological
representative, which provides means to effectively navigate back from the
barcode to the topological space. Among the possibly many, optimal persistent
cycles bring forth further information due to having guaranteed quality.
However, topological features usually go through variations in the lifecycle of
a bar which a single persistent cycle may not capture. Hence, for persistent
homology induced from PL functions, we propose levelset persistent cycles
consisting of a sequence of cycles that depict the evolution of homological
features from birth to death. Our definition is based on levelset zigzag
persistence which involves four types of persistence intervals as opposed to
the two types in standard persistence. For each of the four types, we present a
polynomial-time algorithm computing an optimal sequence of levelset persistent
$p$-cycles for the so-called weak $(p+1)$-pseudomanifolds. Given that optimal
cycle problems for homology are NP-hard in general, our results are useful in
practice because weak pseudomanifolds do appear in applications. Our algorithms
draw upon an idea of relating optimal cycles to min-cuts in a graph that we
exploited earlier for standard persistent cycles. Note that levelset zigzag
poses non-trivial challenges for the approach because a sequence of optimal
cycles instead of a single one needs to be computed in this case.
</p></div>
    </summary>
    <updated>2021-05-04T22:52:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00443</id>
    <link href="http://arxiv.org/abs/2105.00443" rel="alternate" type="text/html"/>
    <title>Fixed Point Constructions in Tilings and Cellular Automata</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=ouml=rm=auml=:Ilkka.html">Ilkka Törmä</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00443">PDF</a><br/><b>Abstract: </b>The fixed point construction is a method for designing tile sets and cellular
automata with highly nontrivial dynamical and computational properties. It
produces an infinite hierarchy of systems where each layer simulates the next
one. The simulations are implemented entirely by computations of Turing
machines embedded in the tilings or spacetime diagrams. We present an overview
of the construction and list its applications in the literature.
</p></div>
    </summary>
    <updated>2021-05-04T22:41:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00419</id>
    <link href="http://arxiv.org/abs/2105.00419" rel="alternate" type="text/html"/>
    <title>Graph Vulnerability and Robustness: A Survey</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freitas:Scott.html">Scott Freitas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Diyi.html">Diyi Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Srijan.html">Srijan Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tong:Hanghang.html">Hanghang Tong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chau:Duen_Horng.html">Duen Horng Chau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00419">PDF</a><br/><b>Abstract: </b>The study of network robustness is a critical tool in the characterization
and sense making of complex interconnected systems such as infrastructure,
communication and social networks. While significant research has been
conducted in all of these areas, gaps in the surveying literature still exist.
Answers to key questions are currently scattered across multiple scientific
fields and numerous papers. In this survey, we distill key findings across
numerous domains and provide researchers crucial access to important
information by--(1) summarizing and comparing recent and classical graph
robustness measures; (2) exploring which robustness measures are most
applicable to different categories of networks (e.g., social, infrastructure;
(3) reviewing common network attack strategies, and summarizing which attacks
are most effective across different network topologies; and (4) extensive
discussion on selecting defense techniques to mitigate attacks across a variety
of networks. This survey guides researchers and practitioners in navigating the
expansive field of network robustness, while summarizing answers to key
questions. We conclude by highlighting current research directions and open
problems.
</p></div>
    </summary>
    <updated>2021-05-04T22:48:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00299</id>
    <link href="http://arxiv.org/abs/2105.00299" rel="alternate" type="text/html"/>
    <title>Online Domination: The Value of Getting to Know All your Neighbors</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hovhannes Harutyunyan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pankratov:Denis.html">Denis Pankratov</a>, Jesse Racicot <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00299">PDF</a><br/><b>Abstract: </b>We study the dominating set problem in an online setting. An algorithm is
required to guarantee competitiveness against an adversary that reveals the
input graph one node at a time. When a node is revealed, the algorithm learns
about the entire neighborhood of the node (including those nodes that have not
yet been revealed). Furthermore, the adversary is required to keep the revealed
portion of the graph connected at all times. We present an algorithm that
achieves 2-competitiveness on trees and prove that this competitive ratio
cannot be improved by any other algorithm. We also present algorithms that
achieve 2.5-competitiveness on cactus graphs, $(t-1)$-competitiveness on
$K_{1,t}$-free graphs, and $\Theta(\sqrt{\Delta})$ for maximum degree $\Delta$
graphs. We show that all of those competitive ratios are tight. Then, we study
several more general classes of graphs, such as threshold, bipartite planar,
and series-parallel graphs, and show that they do not admit competitive
algorithms (that is, when competitive ratio is independent of the input size).
Previously, the dominating set problem was considered in a slightly different
input model, where a vertex is revealed alongside its restricted neighborhood:
those neighbors that are among already revealed vertices. Thus, conceptually,
our results quantify the value of knowing the entire neighborhood at the time a
vertex is revealed as compared to the restricted neighborhood. For instance, it
was known in the restricted neighborhood model that 3-competitiveness is
optimal for trees, whereas knowing the neighbors allows us to improve it to
2-competitiveness.
</p></div>
    </summary>
    <updated>2021-05-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00287</id>
    <link href="http://arxiv.org/abs/2105.00287" rel="alternate" type="text/html"/>
    <title>The complexity of approximating the complex-valued Ising model on bounded degree graphs</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Herrera=Poyatos:Andr=eacute=s.html">Andrés Herrera-Poyatos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00287">PDF</a><br/><b>Abstract: </b>We study the complexity of approximating the partition function
$Z_{\mathrm{Ising}}(G; \beta)$ of the Ising model in terms of the relation
between the edge interaction~$\beta$ and a parameter~$\Delta$ which is an upper
bound on the maximum degree of the input graph~$G$. Following recent trends in
both statistical physics and algorithmic research, we allow the edge
interaction~$\beta$ to be any complex number. Many recent partition function
results focus on complex parameters, both because of physical relevance and
because of the key role of the complex case in delineating the
tractability/intractability phase transition of the approximation problem.
</p>
<p>In this work we establish both new tractability results and new
intractability results. Our tractability results show that
$Z_{\mathrm{Ising}}(-; \beta)$ has an FPTAS when $\lvert \beta - 1 \rvert /
\lvert \beta + 1 \rvert &lt; \tan(\pi / (4 \Delta - 4))$. The core of the proof is
showing that there are no inputs~$G$ that make the partition function~$0$ when
$\beta$ is in this range. Our result significantly extends the known zero-free
region of the Ising model (and hence the known approximation results).
</p>
<p>Our intractability results show that it is $\mathrm{\#P}$-hard to
multiplicatively approximate the norm and to additively approximate the
argument of $Z_{\mathrm{Ising}}(-; \beta)$ when $\lvert \beta - 1 \rvert /
\lvert \beta + 1 \rvert &gt; 1/ \sqrt{\Delta - 1}$. These are the first results to
show intractability of approximating $Z_{\mathrm{Ising}}(-, \beta)$ on bounded
degree graphs with complex~$\beta$. Moreover, we demonstrate situations in
which zeros imply hardness of approximation in the Ising model.
</p></div>
    </summary>
    <updated>2021-05-04T22:37:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00254</id>
    <link href="http://arxiv.org/abs/2105.00254" rel="alternate" type="text/html"/>
    <title>Perfect Forests in Graphs and Their Extensions</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gregory Gutin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeo:Anders.html">Anders Yeo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00254">PDF</a><br/><b>Abstract: </b>Let $G$ be a graph on $n$ vertices. For $i\in \{0,1\}$ and a connected graph
$G$, a spanning forest $F$ of $G$ is called an $i$-perfect forest if every tree
in $F$ is an induced subgraph of $G$ and exactly $i$ vertices of $F$ have even
degree (including zero). A $i$-perfect forest of $G$ is proper if it has no
vertices of degree zero. Scott (2001) showed that every connected graph with
even number of vertices contains a (proper) 0-perfect forest. We prove that one
can find a 0-perfect forest with minimum number of edges in polynomial time,
but it is NP-hard to obtain a 0-perfect forest with maximum number of edges. We
also prove that for a prescribed edge $e$ of $G,$ it is NP-hard to obtain a
0-perfect forest containing $e,$ but we can find a 0-perfect forest not
containing $e$ in polynomial time. It is easy to see that every graph with odd
number of vertices has a 1-perfect forest. It is not the case for proper
1-perfect forests. We give a characterization of when a connected graph has a
proper 1-perfect forest.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00111</id>
    <link href="http://arxiv.org/abs/2105.00111" rel="alternate" type="text/html"/>
    <title>On the Hardness of Scheduling With Non-Uniform Communication Delays</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Sami.html">Sami Davies</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Janardhan.html">Janardhan Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothvoss:Thomas.html">Thomas Rothvoss</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:Sai.html">Sai Sandeep</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tarnawski:Jakub.html">Jakub Tarnawski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yihao.html">Yihao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00111">PDF</a><br/><b>Abstract: </b>In the scheduling with non-uniform communication delay problem, the input is
a set of jobs with precedence constraints. Associated with every precedence
constraint between a pair of jobs is a communication delay, the time duration
the scheduler has to wait between the two jobs if they are scheduled on
different machines. The objective is to assign the jobs to machines to minimize
the makespan of the schedule. Despite being a fundamental problem in theory and
a consequential problem in practice, the approximability of scheduling problems
with communication delays is not very well understood. One of the top ten open
problems in scheduling theory, in the influential list by Schuurman and
Woeginger and its latest update by Bansal, asks if the problem admits a
constant factor approximation algorithm. In this paper, we answer the question
in negative by proving that there is a logarithmic hardness for the problem
under the standard complexity theory assumption that NP-complete problems do
not admit quasi-polynomial time algorithms.
</p>
<p>Our hardness result is obtained using a surprisingly simple reduction from a
problem that we call Unique Machine Precedence constraints Scheduling (UMPS).
We believe that this problem is of central importance in understanding the
hardness of many scheduling problems and conjecture that it is very hard to
approximate. Among other things, our conjecture implies a logarithmic hardness
of related machine scheduling with precedences, a long-standing open problem in
scheduling theory and approximation algorithms.
</p></div>
    </summary>
    <updated>2021-05-04T22:41:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00110</id>
    <link href="http://arxiv.org/abs/2105.00110" rel="alternate" type="text/html"/>
    <title>Triangle Centrality</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burkhardt:Paul.html">Paul Burkhardt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00110">PDF</a><br/><b>Abstract: </b>Triangle centrality is introduced for finding important vertices in a graph
based on the concentration of triangles surrounding each vertex. An important
vertex in triangle centrality is at the center of many triangles, and therefore
it may be in many triangles or none at all.
</p>
<p>We give optimal algorithms that compute triangle centrality in $O(m^{3/2})$
time and $O(m+n)$ space. Using fast matrix multiplication it takes
$n^{\omega+o(1)}$ time where $\omega$ is the matrix product exponent.
</p>
<p>On a Concurrent Read Exclusive Write (CREW) Parallel Random Access Memory
(PRAM) machine, we give a near work-optimal algorithm that takes $O(\log n)$
time using $O(m\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes
four rounds using $O(m\sqrt{m})$ communication bits, and is therefore optimal.
</p>
<p>We also give a deterministic algorithm to find the triangle neighborhood and
triangle count of each vertex in $O(m\sqrt{m})$ time and $O(m+n)$ space. It can
be also easily be computed in $O(m\bar\delta(G))$ expected time, where
$\bar\delta(G)$ is the average graph degeneracy and is related to the
arboricity. We leave it as an open problem to deterministically compute
triangle neighbors in $O(m\bar\delta(G))$ time and $O(m+n)$ space.
</p>
<p>Our empirical results demonstrate that triangle centrality uniquely
identified central vertices thirty-percent of the time in comparison to five
other well-known centrality measures, while being asymptotically faster to
compute on sparse graphs than all but the most trivial of these other measures.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00057</id>
    <link href="http://arxiv.org/abs/2105.00057" rel="alternate" type="text/html"/>
    <title>Speeding up Python-based Lagrangian Fluid-Flow Particle Simulations via Dynamic Collection Data Structures</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kehl:Christian.html">Christian Kehl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sebille:Erik_van.html">Erik van Sebille</a>, Angus Gibson <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00057">PDF</a><br/><b>Abstract: </b>Array-like collection data structures are widely established in Python's
scientific computing-ecosystem for high-performance computations. The structure
maps well to regular, gridded lattice structures that are common to
computational problems in physics and geosciences. High performance is,
however, only guaranteed for static computations with a fixed computational
domain. We show that for dynamic computations within an actively changing
computational domain, the array-like collections provided by NumPy and its
derivatives are a bottleneck for large computations. In response, we describe
the integration of naturally-dynamic collection data structures (e.g.
double-linked lists) into NumPy simulations and \textit{ctypes}-based
C-bindings. Our benchmarks verify and quantify the performance increase
attributed to the change of the collection data structure. Our application
scenario, a Lagrangian (oceanic) fluid-flow particle simulation within the
\textit{Parcels} framework, demonstrates the speed-up yield in a realistic
setting and demonstrates the novel capabilities that are facilitated by
optimised collection data structures.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00017</id>
    <link href="http://arxiv.org/abs/2105.00017" rel="alternate" type="text/html"/>
    <title>Negative 3D gadgets in origami extrusions with a supporting triangle on the back side</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doi:Mamoru.html">Mamoru Doi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00017">PDF</a><br/><b>Abstract: </b>In our previous two papers, we studied (positive) 3D gadgets in origami
extrusions which create a top face parallel to the ambient paper and two side
faces sharing a ridge with two simple outgoing pleats. Then a natural problem
comes up whether it is possible to construct a `negative' 3D gadget from any
positive one having the same net without changing the outgoing pleats, that is,
to sink the top and two side faces of any positive 3D gadget to the reverse
side without changing the outgoing pleats. Of course, simply sinking the faces
causes a tear of the paper, and thus we have to modify the crease pattern.
There are two known constructions of negative 3D gadgets before ours, but they
do not solve this problem because their outgoing pleats are different from
positive ones. In the present paper we give an affirmative solution to the
above problem. For this purpose, we present three constructions of negative 3D
gadgets with a supporting triangle on the back side, which are based on our
previous ones of positive 3D gadgets. The first two are an extension of those
presented in our previous paper, and the third is new. We prove that our first
and third constructions solve the problem. Our solutions enable us to deal with
positive and negative 3D gadgets on the same basis, so that we can construct
from an origami extrusion constructed with 3D gadgets its negative using the
same pleats if there are no interferences among the 3D gadgets. We also treat
repetition/division of negative 3D gadgets under certain conditions, which
reduces their interferences with others.
</p></div>
    </summary>
    <updated>2021-05-04T22:52:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/</id>
    <link href="https://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at UC Irvine (apply by June 4, 2021)</title>
    <summary>One Post-doctoral position is available under the guidance of Ioannis Panageas. The appointment is for one year and may be renewable if funding permits. Requirement is a Ph.D. in TCS/Theory of ML, or related field. Expertise can be demonstrated by 3 top-tier publications in venues like ICML, NeurIPS, AISTATS, STOC, FOCS, SODA, ICALP, EC. Anticipated […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One Post-doctoral position is available under the guidance of Ioannis Panageas. The appointment is for one year and may be renewable if funding permits. Requirement is a Ph.D. in TCS/Theory of ML, or related field. Expertise can be demonstrated by 3 top-tier publications in venues like ICML, NeurIPS, AISTATS, STOC, FOCS, SODA, ICALP, EC. Anticipated starting date is October 1 2021 (negotiable).</p>
<p>Website: <a href="https://recruit.ap.uci.edu/JPF06615">https://recruit.ap.uci.edu/JPF06615</a><br/>
Email: ipanagea@ics.uci.edu</p></div>
    </content>
    <updated>2021-05-03T22:59:14Z</updated>
    <published>2021-05-03T22:59:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-05-05T20:37:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/063</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/063" rel="alternate" type="text/html"/>
    <title>TR21-063 |  Approximability of all finite CSPs in the dynamic streaming setting | 

	Chi-Ning  Chou, 

	Alexander Golovnev, 

	Madhu Sudan, 

	Santhoshini Velusamy</title>
    <summary>A constraint satisfaction problem (CSP), Max-CSP$({\cal F})$, is specified by a finite set of constraints ${\cal F} \subseteq \{[q]^k \to \{0,1\}\}$ for positive integers $q$ and $k$. An instance of the problem on $n$ variables is given by $m$ applications of constraints from ${\cal F}$ to subsequences of the $n$ variables, and the goal is to find an assignment to the variables that satisfies the maximum number of constraints. In the $(\gamma,\beta)$-approximation version of the problem for parameters $0 \leq \beta &lt; \gamma \leq 1$, the goal is to distinguish instances where at least $\gamma$ fraction of the constraints can be satisfied from instances where at most $\beta$ fraction of the constraints can be satisfied. 

In this work we consider the approximability of this problem in the context of streaming algorithms and give a dichotomy result in the dynamic setting, where constraints can be inserted or deleted. Specifically,  for every family ${\cal F}$ and every $\beta &lt; \gamma$,  we show that either the approximation problem is solvable with polylogarithmic space in the dynamic setting, or not solvable with $o(\sqrt{n})$ space. We also establish tight inapproximability results for a broad subclass in the streaming insertion-only setting. Our work builds on, and significantly extends previous work by the authors who consider the special case of Boolean variables ($q=2$), singleton families ($|{\cal F}| = 1$) and where constraints may be placed on variables or their negations. Our framework extends non-trivially the previous work allowing us to appeal to richer norm estimation algorithms to get our algorithmic results. For our negative results we introduce new variants of the communication problems studied in the previous work, build new reductions for these problems, and extend the technical parts of previous works. In particular, previous works used Fourier analysis over the Boolean cube to prove their results and the results seemed particularly tailored to functions on Boolean literals (i.e., with negations). Our techniques surprisingly allow us to get to general $q$-ary CSPs without negations by appealing to the same Fourier analytic starting point over Boolean hypercubes.</summary>
    <updated>2021-05-03T20:10:43Z</updated>
    <published>2021-05-03T20:10:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7474459772601125760</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7474459772601125760/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7474459772601125760" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7474459772601125760" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html" rel="alternate" type="text/html"/>
    <title>The Mythical Man-Month, Hen-Day, and Cat-Minute (Fred Brooks Turned 90)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i> The Mythical Man-Month </i>is a great book which talks about the (obvious in retrospect) fact that putting more people on a project may slow it down. It was by Fred Brooks who turned 90 in April (he is still alive). It's a good read. I actually read it many years ago when I exchanged books with a Software Engineer I was dating- She lent me <i>The Mythical Man Month </i>which I found interesting, and I lent her <i>What is the name of this book by Smullyan </i>which she found amusing. Did this exchange of books help our relationship? We have now been married for many years, though its not clear if we can trace this to the exchange of books OR to the fact that she had KNUTH Volumes 1 and 3, and I had KNUTH Volume 2. </p><p> Fred Brooks: You have my thanks and of course Happy Birthday!</p><p>When I read The Mythical Man-Month  I was reminded of a math problem I heard as a kid: </p><p>If a hen-and-half lays an egg-and-a-half in a day-and-a-half then how many eggs can seven hen lay in seven days? </p><p>My answer: if (3/2) hens lay (3/2) eggs in (3/2) days then that's 2/3 of an egg per hen-day, so the answer is </p><p>49* 2/3 = 32 and 2/3 eggs.</p><p>It did not bother me one whit that (1) you can't have 2/3 of an egg, and (2) Just like adding more people might slow down a project, adding more hens might end up being a bad idea-- especially if they are all crowded into the same chicken-coop and hence don't feel much like laying eggs.</p><p>Who was the first person to note that adding <i>more</i> people or hens might be a bad idea? I do not know, but here is an amusing, yet realistic, article by Mark Twain on what I would call <i>The mythical</i> <i>cat-minute. </i>My advisor Harry Lewis send it to me in the midst of an email exchange about <i>The Mythical</i> <i>Man-Month.</i> He got it from a student of his, Larry Denenberg. Here it is: </p><p><br/></p><p>CATS AND RATS</p><pre>The following piece first appeared in ``The Monthly Packet'' of February
1880 and is reprinted in _The_Magic_of_Lewis_Carroll_, edited by John
Fisher, Bramhall House, 1973.


   If 6 cats kill 6 rats in 6 minutes, how many will be needed to kill
   100 rats in 50 minutes?

   This is a good example of a phenomenon that often occurs in working
   problems in double proportion; the answer looks all right at first, but,
   when we come to test it, we find that, owing to peculiar circumstances in
   the case, the solution is either impossible or else indefinite, and needing
   further data.  The 'peculiar circumstance' here is that fractional cats or
   rats are excluded from consideration, and in consequence of this the
   solution is, as we shall see, indefinite.

   The solution, by the ordinary rules of Double Proportion, is 12 cats.
   [Steps of Carroll's solution, in the notation of his time, omitted.]

   But when we come to trace the history of this sanguinary scene through all
   its horrid details, we find that at the end of 48 minutes 96 rats are dead,
   and that there remain 4 live rats and 2 minutes to kill them in: the
   question is, can this be done?

   Now there are at least *four* different ways in which the original feat,
   of 6 cats killing 6 rats in 6 minutes, may be achieved.  For the sake of
   clearness let us tabulate them:
      A.  All 6 cats are needed to kill a rat; and this they do in one minute,
          the other rats standing meekly by, waiting for their turn.
      B.  3 cats are needed to kill a rat, and they do it in 2 minutes.
      C.  2 cats are needed, and do it in 3 minutes.
      D.  Each cat kills a rat all by itself, and takes 6 minutes to do it.

   In cases A and B it is clear that the 12 cats (who are assumed to come
   quite fresh from their 48 minutes of slaughter) can finish the affair in
   the required time; but, in case C, it can only be done by supposing that 2
   cats could kill two-thirds of a rat in 2 minutes; and in case D, by
   supposing that a cat could kill one-third of a rat in two minutes.  Neither
   supposition is warranted by the data; nor could the fractional rats (even
   if endowed with equal vitality) be fairly assigned to the different cats.
   For my part, if I were a cat in case D, and did not find my claws in good
   working order, I should certainly prefer to have my one-third-rat cut off
   from the tail end.

   In cases C and D, then, it is clear that we must provide extra cat-power.
   In case C *less* than 2 extra cats would be of no use.  If 2 were supplied,
   and if they began killing their 4 rats at the beginning of the time, they
   would finish them in 12 minutes, and have 36 minutes to spare, during which
   they might weep, like Alexander, because there were not 12 more rats to
   kill.  In case D, one extra cat would suffice; it would kill its 4 rats in
   24 minutes, and have 26 minutes to spare, during which it could have killed
   another 4.  But in neither case could any use be made of the last 2
   minutes, except to half-kill rats---a barbarity we need not take into
   consideration.

   To sum up our results.  If the 6 cats kill the 6 rats by method A or B,
   the answer is 12; if by method C, 14; if by method D, 13.

   This, then, is an instance of a solution made `indefinite' by the
   circumstances of the case.  If an instance of the `impossible' be desired,
   take the following: `If a cat can kill a rat in a minute, how many would be
   needed to kill it in the thousandth part of a second?'  The *mathematical*
   answer, of course, is `60,000,' and no doubt less than this would *not*
   suffice; but would 60,000 suffice?  I doubt it very much.  I fancy that at
   least 50,000 of the cats would never even see the rat, or have any idea of
   what was going on.

   Or take this: `If a cat can kill a rat in a minute, how long would it be
   killing 60,000 rats?'  Ah, how long, indeed!  My private opinion is that
   the rats would kill the cat.
</pre><div><br/></div><p><br/></p></div>
    </content>
    <updated>2021-05-02T19:33:00Z</updated>
    <published>2021-05-02T19:33:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-05-05T08:04:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/062" rel="alternate" type="text/html"/>
    <title>TR21-062 |  Improved Hitting Set for Orbit of ROABPs | 

	Vishwas Bhargava, 

	Sumanta Ghosh</title>
    <summary>The orbit of an $n$-variate polynomial $f(\mathbf{x})$ over a field $\mathbb{F}$ is the set $\{f(A \mathbf{x} +  b)\,\mid\, A\in \mathrm{GL}({n,\mathbb{F}})\mbox{ and }\mathbf{b} \in \mathbb{F}^n\}$, and the orbit of a polynomial class is the union of orbits of all the polynomials in it. In this paper, we give improved constructions of hitting-sets for the orbit of read-once oblivious algebraic branching programs (ROABPs) and a related model. Over field with characteristic zero or greater than $d$, we construct a hitting set of size  $(ndw)^{O(w^2\log n\cdot \min\{w^2, d\log w\})}$  for the orbit of ROABPs in unknown variable order where $d$ is the individual degree and $w$ is the width of ROABPs. We also give hitting set of size $(ndw)^{O(\min\{w^2,d\log w\})}$ for the orbit of polynomials  computed by $w$-width ROABPs in any variable order. Our hitting sets improve upon the results of Saha and Thankey \cite{Saha-Thankey'21} who gave an $(ndw)^{O(d\log w)}$ size hitting set for the orbit of commutative ROABPs (a subclass of \textit{any-order} ROABPs) and $(nw)^{O(w^6\log n)}$ size hitting set for the orbit of multilinear ROABPs. Designing better hitting sets in large individual degree regime, for instance $d&gt;n$, was asked as an open problem by \cite{Saha-Thankey'21} and this work solves it in  small width setting. 

We prove some new rank concentration results by establishing \emph{low-cone concentration} for the polynomials over vector spaces, and they strengthen some previously known \emph{low-support} based rank concentrations shown in \cite{FSS14}. These new low-cone concentration results are crucial in our hitting set construction, and may be of independent interest. To the best of our knowledge, this is the first time when low-cone rank concentration has been used for designing hitting sets.</summary>
    <updated>2021-05-02T07:04:05Z</updated>
    <published>2021-05-02T07:04:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18674</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/" rel="alternate" type="text/html"/>
    <title>Test of Time</title>
    <summary>Time is the ultimate critic. What future generations think of us and our work ultimately determines our standing or lack of it— Stewart Stafford Bobby Kleinberg just reached out to those of us who post from time to time. He wanted some help in announcing a new STOC Test of Time Award. So today, Ken […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Time is the ultimate critic. What future generations think of us and our work ultimately determines our standing or lack of it— Stewart Stafford</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/bk/" rel="attachment wp-att-18676"><img alt="" class="alignright size-thumbnail wp-image-18676" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/bk-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
Bobby Kleinberg just reached out to those of us who post from time to time. He wanted some help in announcing a new STOC Test of Time Award. </p>
<p>
So today, Ken and I put this together. </p>
<p>Bobby said: </p>
<blockquote><p><b> </b> <em> As with FOCS, three awards will be given: one for papers from approximately 10 years ago, one for approximately 20 years ago, and one for approximately 30 years ago. The selection committee for this year’s award will be Joe Halpern, Mihalis Yannakakis, and Salil Vadhan. </em>
</p></blockquote>
<p/><p>
I would suggest that one of Bobby’s papers could fit this award: </p>
<p>Group-theoretic algorithms for matrix multiplication <br/>
Henry Cohn, Robert Kleinberg, Balazs Szegedy, Christopher Umans </p>
<p>
Well, I can say that without being out of order <em>here</em> because that paper was in FOCS, not STOC.</p>
<p>
</p><p/><h2> Criteria </h2><p/>
<p>
</p><li>
<i>Area</i>: Opening up a new area of research <p/>
</li><li>
<i>Proof</i>: Introducing new proof techniques <p/>
</li><li>
<i>Use</i>: Solving a problem of lasting importance <p/>
</li><li>
<i>Else</i>: Stimulating advances in other areas of computer science or in other disciplines. <p/>
<p>
Go here for details on how to <a href="https://sigact.org/prizes/stoc_tot.html">nominate</a>. By the way: Another test of Time is that the nominations are due relatively soon—May 24. So if you wish to nominate some paper please act soon. </p>
<p>
Ken notes that the first criterion could also be called <i>Leadership</i>, the second always comes with an element of <i>Surprise</i>, and the last two have aspects of <i>Applicability</i> and <i>Practicality</i>.  Adding those to my terms makes a double acronym <i>APPLAUSE</i>.</p>
<p>
</p><p/><h2> Early Early Years </h2><p/>
<p/><p>
I have been around long enough to fit the a 30++ years category, and Ken almost <a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/">ditto</a>. Here are some opinions on the early days. Those papers with<br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a><br/>
are an absolute must include—I hope you agree.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc81.html">1981</a>:</p>
<p>
Space-Bounded Probabilistic Turing Machine Complexity Classes Are Closed under Complement <br/>
<i>Use</i>.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc82.html">1982</a>:</p>
<p>
Shafi Goldwasser, Silvio Micali <br/>
Probabilistic Encryption and How to Play Mental Poker Keeping Secret All Partial Information <br/>
<i>Area</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800061">1983</a>:</p>
<p>
Miklós Ajtai, Janos Komlós, and Endre Szemerédi <br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>An <img alt="{0(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> sorting network <br/>
<i>Use</i> and <i>Proof</i>.</p>
<p>
Larry Stockmeyer <br/>
The complexity of approximate counting <br/>
<i>Use</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800057">1984</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>Les Valiant <br/>
A theory of the learnable <br/>
<i>Area</i> and <i>Else</i>.</p>
<p>
Narendra Karmarkar <br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>A new polynomial-time algorithm for linear programming <br/>
<i>Use</i> and <i>Proof</i>.</p>
<p>
Of course, these are my own opinions (with concurrence from Ken) and do not reflect those of organizations we belong to.</p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
Ken thinks that one way not to be asked here about my own papers is to mention one, so here goes:</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc80.html">1980</a></p>
<p>
Ravindran Kannan, Richard Lipton <br/>
The Orbit Problem is Decidable <br/>
<i>Proof</i>.  Ken adds: Could also be <i>Surprise</i> because we not only showed decidable but in polynomial time.  But the real test of time here may be whether (despite some technical limitations) it proves useful to the great recent interest in adjacent kinds of orbit problems in <a href="https://rjlipton.wpcomstaging.com/2018/06/06/princeton-is-invariant/">invariant</a> and <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">reachability</a> theory.</p></li></font></font></div>
    </content>
    <updated>2021-04-30T22:53:16Z</updated>
    <published>2021-04-30T22:53:16Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="award"/>
    <category term="Bobby Kleinberg"/>
    <category term="Prize"/>
    <category term="STOC"/>
    <category term="Test of Time"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-05-05T20:37:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-3713824207379370168</id>
    <link href="http://processalgebra.blogspot.com/feeds/3713824207379370168/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=3713824207379370168" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/3713824207379370168" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/3713824207379370168" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/04/polyconc-online-collaboration-to.html" rel="alternate" type="text/html"/>
    <title>PolyConc: Online collaboration to improve on a result on the equational theory of CCS modulo bisimilarity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The aim of this post is to try and start an online collaboration to improve the solution to a problem in the equational logic of processes that I posed in a <a href="https://www.brics.dk/NS/03/2/BRICS-NS-03-2.pdf" target="_blank">survey paper in 2003</a>, namely    </p><blockquote>  Can one obtain a finite axiomatisation of the parallel composition operator in bisimulation semantics by adding only one binary operator to the signature of (recursion, restriction, and relabelling free) CCS? </blockquote><p>     Valentina Castiglioni, Wan Fokkink, Anna Ingólfsdóttir, Bas Luttik and I published a partial, negative answer to the above question in a <a href="https://doi.org/10.4230/LIPIcs.CSL.2021.8" target="_blank">paper at CSL 2021</a>. (See the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">arXiv version</a> for details and for the historical context for the above question.) Our solution is based on three simplifying assumptions that are described in detail in Section 3 of the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">above-mentioned paper</a>. We'd be very interested in hearing whether any member of the research community in process algebra, universal algebra and equational logic can relax or remove any of our simplifying assumptions. In particular, one can start with assumptions 3 and 2. </p><p>We would also welcome any comments and suggestions on whether some version of that problem can be solved using existing results from equational logic and universal algebra. In particular, are there any general results guaranteeing that, under certain conditions, the reduct of a finitely based algebra is also finitely based? Or, conversely, that if some algebra is not finitely based, then so its expansion with a new operator?</p><p>To start with, add any contributions you might have as comments to this post. If ever we make substantial enough progress on the above question, anyone who has played a positive role in extending our results will be a co-author of the resulting paper. </p><p>Let PolyConc begin!<br/></p><p/></div>
    </content>
    <updated>2021-04-30T20:41:00Z</updated>
    <published>2021-04-30T20:41:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-05-05T17:04:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/30/linkage</id>
    <link href="https://11011110.github.io/blog/2021/04/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The EFF on FLoC (\(\mathbb{M}\)), Google’s plan for browsers to aggregate your browsing habits and make them public for ad-personalization. Short summary: it’s a bad idea and if you care about privacy you should switch to a non-Chrome browser. Technical summary: it’s based on k-anonymity, known as inadequate at protecting individual privacy in social networks. If you use Chrome, assume all bad guys on the web can see all your browsing.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea">The EFF on FLoC</a> (<a href="https://mathstodon.xyz/@11011110/106079326968515725">\(\mathbb{M}\)</a>), Google’s plan for browsers to aggregate your browsing habits and make them public for ad-personalization. Short summary: it’s a bad idea and if you care about privacy you should switch to a non-Chrome browser. Technical summary: it’s based on <a href="https://en.wikipedia.org/wiki/K-anonymity">k-anonymity</a>, known as <a href="https://doi.org/10.1109/CASoN.2010.139">inadequate at protecting individual privacy in social networks</a>. If you use Chrome, assume all bad guys on the web can see all your browsing.</p>
  </li>
  <li>
    <p>Relevant to my recent post on Pick’s theorem: <a href="https://www.youtube.com/watch?v=osF2JhrVHxc">Chris Staecker on the dot planimeter</a> (<a href="https://mathstodon.xyz/@11011110/106090366361151274">\(\mathbb{M}\)</a>), a device for <a href="https://en.wikipedia.org/wiki/Dot_planimeter">approximating area by counting grid points</a>.</p>
  </li>
  <li>
    <p><a href="https://www.peeta.net/">Anamorphic street art by Peeta transforms building shapes into 3d geometric abstractions</a> (<a href="https://mathstodon.xyz/@11011110/106100758800338449">\(\mathbb{M}\)</a>, <a href="https://weburbanist.com/2019/07/12/anamorphic-street-art-new-abstract-murals-by-peeta-pop-off-the-wall/">via</a>).</p>
  </li>
  <li>
    <p><a href="https://lore.kernel.org/linux-nfs/YH+zwQgBBGUJdiVK@unreal/">Students of University of Minnesota assistant professor Kangjie Lu caught allegedly deliberately sending buggy patches to Linux kernel as some kind of breaching experiment</a>, resulting in <a href="https://lore.kernel.org/linux-nfs/YH%2FfM%2FTsbmcZzwnX@kroah.com/">the whole university being banned from Linux kernel development</a> (<a href="https://mathstodon.xyz/@11011110/106104208447478044">\(\mathbb{M}\)</a>, <a href="https://lobste.rs/s/3qgyzp/they_introduce_kernel_bugs_on_purpose">via</a>). They claim to have been declared IRB-exempt but this appears to be a mistake by the IRB. See also <a href="https://cse.umn.edu/cs/statement-cse-linux-kernel-research-april-21-2021">department reaction</a> and <a href="https://www.metafilter.com/191207/How-to-get-your-University-banned-in-1-easy-step">metafilter discussion</a>.</p>
  </li>
  <li>
    <p><a href="https://mastodon.social/@joshmillard/106109652170356976">Josh Millard plays with algorithmically-generated pen-plotter art</a>; <a href="https://www.patreon.com/posts/50677186">more</a>.</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/a-pretty-puzzle/">You could prove that the number of integer solutions to \(x^2+xy+y^2=a\) is a multiple of six for positive \(a\) by finding a hidden group structure</a> (<a href="https://mathstodon.xyz/@11011110/106113101236984677">\(\mathbb{M}\)</a>). Or, you could recognize that it’s the norm of the Eisenstein integers under a small change of basis from the usual one and that they have six-fold rotational symmetry.</p>
  </li>
  <li>
    <p><a href="https://www.origamitessellations.com/2018/03/paper-engineering-from-the-bauhaus-josef-albers-to-the-modern-day/">Paper engineering from the Bauhaus</a> and <a href="https://www.origamitessellations.com/2018/04/reverse-engineering-bauhaus-paper-designs-part-two/">reverse-engineering Bauhaus paper designs</a> (<a href="https://mathstodon.xyz/@11011110/106118829181433597">\(\mathbb{M}\)</a>). These designs are more curved kirigami than origami, producing smooth-looking 3d shapes from cut sheets of flat paper.</p>
  </li>
  <li>
    <p><a href="https://www.scientificamerican.com/article/the-art-of-mathematics-in-chalk/">The art of mathematics in chalk</a> (<a href="https://mathstodon.xyz/@11011110/106124866673951925">\(\mathbb{M}\)</a>, <a href="https://whatsonmyblackboard.wordpress.com/">see also</a>). Teaser for the forthcoming book <em>Do Not Erase: Mathematicians and Their Chalkboards</em>, featuring several photographic spreads of chalkboard illustrations and formulas and their explanations. They appear to be mostly set-ups rather than captured from active research, but still pretty and interesting. <a href="https://11011110.github.io/blog/2019/09/30/linkage.html">I linked an earlier post on this in 2019</a> but with fewer photos and no explanations.</p>
  </li>
  <li>
    <p><a href="https://coq.discourse.group/t/renaming-coq/1264">The Coq theorem prover brainstorms a name change</a> (<a href="https://mathstodon.xyz/@11011110/106127971601789143">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191240/Not-every-woman-is-offended-by-this-name-but-enough-people-are">via</a>), after too many women get harrassed for saying they work on Coq.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Tetrad_(geometry_puzzle)">Tetrad puzzle</a> (<a href="https://mathstodon.xyz/@11011110/106136227486814000">\(\mathbb{M}\)</a>). It’s possible to arrange four congruent hexagons so they tile a disk with each pair sharing a length of boundary, but the known pentagons with four pairwise-touching copies leave a hole in the region they tile. Is the hole necessary?</p>
  </li>
  <li>
    <p><a href="https://github.andrewt.net/mercator-rotator/">Mercator Rotator</a> (<a href="https://mastodon.social/@andrewt/105950778379233419">\(\mathbb{M}\)</a>), a tool for drawing Mercator-projection world maps with different viewpoints than the usual one. Set the pole on a place you don’t like to see the map of a world without it.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/138752/440">Tetrahedra passing through a hole</a> (<a href="https://mathstodon.xyz/@11011110/106152970915208525">\(\mathbb{M}\)</a>). This is from eight years ago, but was active again recently. The question is: what’s the smallest-area hole in a plane through which you can push a unit tetrahedron? DPKR has a very pretty animated answer, but sadly it’s not optimal: there’s a triangular hole with smaller area \(1/\sqrt{8}\), known <a href="https://doi.org/10.1016/j.comgeo.2011.07.004">minimal for translational motion</a>. The problem for more general motion seems to be still open.</p>
  </li>
  <li>
    <p><a href="http://arxiv.org/abs/1112.4205v2">Lagarias’s survey on the Takagi Function</a> and <a href="https://www.jstor.org/stable/2324028">Mallows’ survey on Conway’s $10,000 sequence</a> (<a href="https://mathstodon.xyz/@11011110/106153079186577081">\(\mathbb{M}\)</a>, <a href="https://mathstodon.xyz/@esoterica/106152848486538030">via</a>, <a href="https://en.wikipedia.org/wiki/Blancmange_curve">see also</a>) have very similar-looking figures, but little or no overlap in references. Maybe someone knows of an explanation for the similarity?</p>
  </li>
</ul></div>
    </content>
    <updated>2021-04-30T17:00:00Z</updated>
    <published>2021-04-30T17:00:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-05-01T00:37:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8108</id>
    <link href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – Equilibrium Computation and the Foundations of Deep Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Guest post by Kush Bhatia and Cyrus Rashtchian, foreword by Gautam Kamath] Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs … <a class="more-link" href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/">Continue reading <span class="screen-reader-text">ALT Highlights – Equilibrium Computation and the Foundations of Deep Learning</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>[Guest post by Kush Bhatia and Cyrus Rashtchian, foreword by Gautam Kamath]</p>



<p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. Boaz has kindly agreed to host a post in this series. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the third post in the series, an interview with <a href="http://people.csail.mit.edu/costis/">Constantinos Daskalakis</a> and coverage of his ALT 2021 <a href="https://www.youtube.com/watch?v=GpaCWKlOMig">keynote talk</a>, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>.</p>



<hr class="wp-block-separator"/>



<p>To make a decision for ourselves, we need to think about the impact of our actions to our objectives. But, when our actions affect other people and their actions affect our objectives, we also need to consider their incentives, and choose our actions in anticipation of theirs. This increase in complexity also occurs in situations involving multiple decision-making machines (e.g., self-driving cars), automated systems (e.g., algorithmic stock trading), or living organisms (e.g., groups of cells).</p>



<p>Studying decision-making in so-called multi-agent environments has been a question of interest to mathematicians and economists for centuries. In the 1830s, Antoine Augustin Cournot developed a theory of competition to model oligopolies, inspired by observing competition in a spring water duopoly. Jumping forward to the 20th century, researchers converged that a fruitful approach to analyzing multi-agent systems is studying them at “equilibrium”, that is, in situations where the system is stable in the sense that all parties are satisfied with their actions. A fundamental concept of equilibrium, studied by John von Neumann, and later by von Neumann and Oskar Morgenstern is a collection of actions, one per agent, such that no agent has an incentive to deviate from their choice given the actions of the other agents. While a nice proposal, they could only show that such equilibrium is guaranteed to exist in situations conforming to what is called a “two-player zero-sum game”. In such games, two agents are in exact competition with each other; whatever one player wins the other loses.<sup><a href="https://windowsontheory.org/feed/#fn1">1</a></sup> In 1950, John F. Nash showed that this notion of equilibrium, named Nash equilibrium in his honor, indeed exists for most naturally occurring multi-agent problems.<sup><a href="https://windowsontheory.org/feed/#fn2">2</a></sup></p>



<p>While Nash established the existence of equilibrium, one question bothered economists and computer scientists alike: “<em>Is it possible to efficiently find the Nash equilibrium of a game</em>?”</p>



<p>Throughout the rest of the 20th century, many people proposed algorithms for computing Nash equilibrium, but none of them succeeded in showing that it can be done efficiently (i.e., in polynomial time in the size of the game). During his early graduate school days at UC Berkeley, Constantinos (a.k.a. Costis) Daskalakis obsessed over this question. Then, in 2006, Costis, along with co-authors Paul Goldberg and Christos Papadimitriou, who was also his PhD advisor, showed a surprising result: finding a Nash equilibrium is computationally intractable!</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-311" src="https://kamathematics.files.wordpress.com/2021/04/fig1-1.png?w=643"/><strong>Figure 1.</strong> Utility functions encode the value an agent gets from a particular decision. (a) In classical Economics and Game Theory literature, these trade off benefits and costs of actions. For e.g., consider an agent deciding on the quantity <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of basic material to procure while the other agent sets the price <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> per unit of this material. If we let <img alt="g(x)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the revenue from selling the product produced using <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> units of basic material, where <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a concave function of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> (capturing diminishing returns), then the overall utility of the agent choosing <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <img alt="f(x,y) = g(x) - x \cdot y" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+g%28x%29+-+x+%5Ccdot+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, an overall concave function. (b) Modern multi-agent problems involve agents choosing parameters of deep neural networks. This quickly leads to non-concave agent utilities.</figure>



<p>A central concept in analyzing multi-agent systems is the <em>utility function</em> of each interacting agent. This is  a function that captures the value that the agent derives as a function of their own action as well as those of the other agents. A common assumption is that the utility function of each agent is a concave function of their own action for any collection of actions committed by the others. Concavity often arises when agents trade off benefits and costs from their actions taking into account properties like diminishing returns and risk-aversion (see Figure 1 for an illustration). It is also crucial in guaranteeing that equilibria exist.</p>



<h3>From Game Theory and Economics to Deep Learning</h3>



<p>Recently, Costis has shifted his attention to the more general setting where the underlying utilities can be arbitrary non-concave functions of the agents’ actions. “Earlier, I was interested in the problem of equilibrium computation for its fundamental applications in Game Theory and Economics and its intimate connections to duality theory, topology and complexity theory. As Machine Learning is now moving towards multi-agent learning, studying more general setups arising from nonconcave agent utilities becomes increasingly relevant,” says Costis. He elaborates that the recent success of deep learning methods has largely been in single-agent setups and that the next frontier is to replicate this success in multi-agent settings. It is at this intersection of deep learning and multi-agent learning that non-concave utility functions arise — when actions correspond to setting the parameters of deep neural networks, agent utilities quickly become non-concave in the space of these parameters(see Figure 1).</p>



<p>The focus of Costis’ <a href="https://www.youtube.com/watch?v=GpaCWKlOMig" rel="noreferrer noopener" target="_blank">keynote talk</a>, on joint work with Stratis Skoulakis and Manolis Zampetakis [<a href="https://windowsontheory.org/feed/#DSZ21">DSZ21</a>] was on the simplest multi-agent problem: two-player zero-sum games. In these games, two players, the <em>min</em> and the <em>max</em> player, choose actions <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> respectively, which are constrained to lie in some compact and convex set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e., <img alt="(x,y) \in S" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29+%5Cin+S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The agents share some objective function <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> that <em>min</em> wants to minimize and <em>max</em> wants to maximize. Classical studies, going back to von Neumann’s celebrated work [<a href="https://windowsontheory.org/feed/#vN28">vN28</a>] focus on when this objective is a convex function of the <em>min</em> player’s action and a concave function of the <em>max</em> player’s action, the so-called “convex-concave setting”. For any function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> which is convex-concave, there exists a Nash equilibrium, i.e., a point <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying</p>



<p class="has-text-align-center" id="eq-nash"><img alt="f(x^*, y) \leq f(x^*, y^*) \leq f(x, y^*) \quad \text{for all}\; x, y \text{ such that } (x, y^*), (x^*, y) \in S.\qquad (1)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%29+%5Cleq+f%28x%5E%2A%2C+y%5E%2A%29+%5Cleq+f%28x%2C+y%5E%2A%29+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x%2C+y+%5Ctext%7B+such+that+%7D+%28x%2C+y%5E%2A%29%2C+%28x%5E%2A%2C+y%29+%5Cin+S.%5Cqquad+%281%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Thus the <em>min</em> (<em>max</em>) player has no incentive to deviate from <img alt="x^* (y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A+%28y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> as long as the other player remains fixed. The existence of such <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> follows from von Neumann’s minimax theorem and Rosen’s generalization of this theorem to the case that agents actions are jointly constrained [<a href="https://windowsontheory.org/feed/#Ros65">Ros65</a>]. However, when <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is not convex-concave, the minimax theorem fails, and we lose the existence of Nash equilibrium. For a simple example, consider <img alt="f(x,y) = (x-y)^2" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+%28x-y%29%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> over the space <img alt="S=[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Given any decision choice <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> if <img alt="x\neq y" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cneq+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the <em>min</em> player should move <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> towards <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Otherwise, if <img alt="x = y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%3D+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the <em>max</em> player wants to move away from <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Thus, no pair <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfies equation <a href="https://windowsontheory.org/feed/#eq-nash">(1)</a>.</p>



<p>Nonconvex-nonconcave utility functions naturally arise in adversarial training applications, such as Generative Adversarial Network (GAN) training, where the goal is to learn how to generate new data, such as images, from the same distribution that generated a collection of given data. Specifically, GANs are trained by trying to identify the equilibrium of a two-player zero-sum game between a generator model (the <em>min</em> player) and a discriminator model (the <em>max</em> player). Each of these models are viewed as agents, choosing parameters in deep neural networks, and the objective, capturing how close the generated distribution is to the target distribution, amounts to a nonconvex-nonconcave function of the underlying network parameters, which the <em>min</em> player aims to minimize and the <em>max</em> player aims to maximize.</p>



<p>Given that Nash equilibria may not exist when the objective is not convex-concave, what type of solutions should we target when studying two player zero-sum games with such objectives? “One property that we would like our target solutions to possess is that they are universal, i.e. they are guaranteed to exist for any objective function. We can take them to a practitioner and tell them that they are always plausible targets for their computations,” says Costis. With this in mind, Costis and his co-authors consider a relaxed equilibrium concept, called <img alt="(\epsilon, \delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibrium. This is a pair <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying</p>



<p class="has-text-align-center"><img alt="f(x^*, y^*) &lt; f(x, y^*) + \epsilon \quad \text{for all}\; x \text{ such that } \|x - x^*\| \leq \delta \text{ and } (x,y^*)\in S;" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3C+f%28x%2C+y%5E%2A%29+%2B+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x+%5Ctext%7B+such+that+%7D+%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%2Cy%5E%2A%29%5Cin+S%3B&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="f(x^*, y^*) &gt; f(x^*, y) - \epsilon \quad \text{for all}\; y \text{ such that } \|y - y^*\| \leq \delta \text{ and } (x^*,y)\in S." class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3E+f%28x%5E%2A%2C+y%29+-+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+y+%5Ctext%7B+such+that+%7D+%5C%7Cy+-+y%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%5E%2A%2Cy%29%5Cin+S.&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This relaxes Nash equilibrium: given strategy <img alt="y^*" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for the <em>max</em> player, the <em>min</em> player can improve by at most <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> by changing their action in a ball of radius <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> around <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and a symmetric condition holds for the <em>max</em> player, given strategy <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for the <em>min</em> player. One of the main insights of their paper is that such local Nash equilibria <em>are guaranteed to</em> exist as long as <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a small enough function of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s smoothness, namely whenever <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s smoothness. This non-trivial result is established via an application of Brouwer’s fixed point theorem.</p>



<h3>Can algorithms find a local Nash equilibrium?</h3>



<p>The next question, pertaining to computational complexity, is to determine whether finding an <img alt="(\epsilon, \delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibrium is algorithmically tractable in the regime of parameters (small enough <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>) where it is guaranteed to exist. As a first step, Costis and his co-authors focus on first-order algorithms, which have access to the gradient of the objective function. Examples include gradient descent and variants thereof, which have been the main computational engine behind the success of deep learning in single-agent problems. A classical result known for these methods in minimization settings is that they are efficient in computing <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-minima of non-convex, smooth objectives <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. These are points <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="f(x^*) &lt; f(x) + \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%29+%3C+f%28x%29+%2B+%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all feasible <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="\|x - x^*\| \leq \delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Namely, given query access to the gradient <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of some <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-smooth objective <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> with values normalized to <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it is possible to compute <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-minima in polynomially many, in <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="1/\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, steps and queries to <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, as long as <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In contrast to minimization, a main contribution of Costis’ work is to establish an intractability result for min-maximization, showing that the number of gradient queries for any first-order algorithm to compute <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibria must be exponential in at least one of <img alt="1/\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the dimension <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or the smoothness <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the objective.</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<blockquote class="wp-block-quote"><p>Theorem 1 (informal). First-order methods need a number of queries to <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> that is exponential in at least one of <img alt="1 /\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or the dimension to find <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibria, even when <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e. in the regime in which they are guaranteed to exist.</p></blockquote>



<p>This theorem tells us that there exist objective functions for which the min-maximization problem can be computationally intractable for any first-order algorithm. Requiring many queries is one way to say that the problem is hard in practice. Indeed, practitioners have found it notoriously hard to get the discriminator-generator neural networks to converge to good solutions for generative modelling problems using gradient-based methods.</p>



<p>From a technical perspective, this work represents a new approach for proving lower bounds in optimization. Classical lower bounds in the optimization literature, going back to Nemirovsky and Yudin [<a href="https://windowsontheory.org/feed/#NY83">NY83</a>] target the black-box setting: an algorithm is given access to an oracle which outputs some desired information about a function when presented with a query. For example, a first-order oracle outputs the gradient of a function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> at a given input. Costis shared that he and his co-authors first tried to construct a black-box lower bound for local Nash equilibria directly. However, they were unsuccessful. Any direct construction they tried ended up introducing spurious local Nash equilibria, which first-order algorithms might find in polynomial time. Their direct attempts at a lower bound failed to capture the computational hardness of the problem. They quickly realized that they needed a deeper understanding of the problem at hand, better insight on what made it harder than minimization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-310" height="331" src="https://kamathematics.files.wordpress.com/2021/04/fig2.png?w=1011" width="581"/><strong>Figure 2. </strong>(a) Black-box models work with an oracle which an algorithm queries to obtain information. White-box models provide algorithms access to functions which can compute the desired information. (b) Architecture of black-box intractability results (focus of the optimization literature): first show computational hardness results in the white-box model (focus of computational complexity); then compose those with black-box lower bounds for any problem in the class for which hardness results were established.</figure></div>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<p>That insight came when they switched to studying the complexity of the white-box version of the problem, wherein the optimization algorithm can look inside the oracle that computes <img alt="\nabla f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and possibly <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> as well. One might wonder why one would want to consider such white-box models over black-box ones if their goal is to prove intractability results for methods that have limited access to <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Indeed, proving an intractability result in the white-box model is much harder because the set of algorithms that use white-box access to the objective is strictly bigger than those using only black-box access. However, the key difference is that we are not looking for the same kind of hardness in the two models. In the black-box model, we are looking for unconditional computational hardness, that is, showing that any algorithm will require exponentially many queries to the gradient oracle. On the other hand, in the white-box model, we would like to show complexity-theoretic hardness, i.e., show that solving the problem at hand is at least as hard (or exactly as hard) as solving the hardest problems in some complexity class. Such a complexity-theoretic hardness result is conditional; it says that solving this problem will be computationally intractable as long as some computational complexity conjecture, such as P <img alt="\neq" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> NP, holds. Importantly, showing hardness (or completeness) of a problem in some complexity class typically entails a fine-grained understanding of the nature of the problem and how that enables it to encode other problems in the target complexity class.</p>
</div></div>



<p>In the white-box model, the authors show that the problem of computing local Nash equilibria is PPAD-complete. In other words, computing this local equilibrium concept in zero-sum games with nonconvex-nonconcave objectives is exactly as hard as computing Nash equilibria in general-sum games with concave agent utilities.<sup><a href="https://windowsontheory.org/feed/#fn3">3</a></sup> This result is established by exhibiting a reduction from a variant of the Sperner coloring problem,<sup><a href="https://windowsontheory.org/feed/#fn4">4</a></sup> which is a PPAD-complete problem, to a discrete nonconvex-nonconcave min-maximization problem, where the two agents choose points on a hypergrid.</p>



<h3>Unexpected challenges in high dimensions</h3>



<p>Having established this result, Costis and his coauthors presumed that the hardest part of the problem was behind them. However, another challenge awaited them. They still had to construct a continuous interpolation of their discrete function to satisfy the desired Lipschitz and smoothness properties in a computationally efficient manner. To understand the challenge with this, consider a simple two-dimensional example with two actions per agent. Suppose we are given prescribed values for <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> on all four vertices of <img alt="\{0,1\}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and our goal is to construct a continuous and smooth function on <img alt="[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which matches the prescribed function values at the corners. A simple approach is to define <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> at any point <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> using a smooth interpolation of all four corners of <img alt="\{0,1\}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This works, but does not scale to high dimensions. An approach that would scale computationally in high dimensions is to first triangulate <img alt="[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> by chopping it along its main diagonal and then interpolate the function on each triangle separately. However, this simple approach fails since the gradient of the interpolated function can be discontinuous when crossing the diagonal. “This part turned out to be more technically challenging than we had thought in high dimensions,” says Costis. He and his coauthors overcame the issue by proposing a new <em>smooth and computationally efficient interpolation</em> scheme, which they expect will have more applications in transferring hardness results from discrete problems to continuous problems.</p>



<p>To obtain Theorem 1, the authors show that one can translate their complexity-theoretic hardness in the white-box model to an unconditional intractability result in the black-box model. This follows immediately from their reduction from Sperner to local Nash equilibrium. Indeed, finding local Nash equilibria in the min-max instance at the output of their reduction provides solutions to the Sperner instance at its input. Moreover, a single query (function value or gradient value) to the min-max objective requires <img alt="O(d)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28d%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> queries to the Sperner coloring circuit in order to be computed. Finally, it is known that, with black-box queries to the Sperner coloring circuit, exponentially many queries are necessary to compute a solution [<a href="https://windowsontheory.org/feed/#HPV89">HPV89</a>, <a href="https://windowsontheory.org/feed/#Pap94">Pap94</a>]. An exponential black-box lower bound for local Nash equilibrium thus follows.</p>



<p>This proof architecture can be used more generally to prove intractability results for optimization problems involving smooth objectives. First, ignore the black-box model and focus on identifying the complexity class that captures the complexity of the problem in the white-box model. Then, focus on obtaining a hardness result for a discrete version of the problem. Once this is established, one can use the techniques presented in this work to lift this intractability from the discrete to the continuous problem. If there are black-box lower bounds for any problem residing in the complexity class for which the white-box version of the problem is hard, then these lower bounds can be composed with hardness reductions to establish lower bounds for the black-box version of the problem. As an aside, Costis mentions that it would be interesting if one could establish the lower bound of Theorem 1 in the black-box model directly, i.e., without going through the PPAD machinery.</p>



<h3>Looking forward</h3>



<p>Costis ends on an optimistic note: “While this might appear as a negative result, it really is a positive one.” Explaining further, he says that a philosophical consequence of his intractability results is that the multi-agent future of deep learning is going to have a lot of interesting “texture” — it will involve a large breadth of communities and motivate a plethora of problems at the interface of theoretical computer science, game theory, economics and machine learning. Costis envisions a change in balance in the multi-agent world: while recent successes of deep learning in single-agent problems capitalize on access to large data, unprecedented computational power, and effective inductive biases, multi-agent problems will demand much stronger inductive biases, invoking domain expertise in order to develop effective models and useful learning targets, as well as to discover algorithms that attain those targets.</p>



<p>Indeed, domain expertise has been crucial in some recent high-profile machine learning achievements in multi-agent settings: the AlphaGo agent for playing the game of Go and the Libratus agent for playing Texas Hold’em. For these, a game-theoretic understanding has been infused into the structure and training of the learning algorithm. In addition to using deep neural networks, AlphaGo uses a Monte Carlo tree search procedure to determine the best next move as well as to collect data for the training of the neural networks during self play, while Libratus uses counterfactual regret minimization to approximate the equilibrium of the game. The success of both algorithms required combining machine learning expertise with game-theoretic expertise about how to solve the games at hand.</p>



<p>More broadly, Costis urges young researchers to move beyond the classical statistical paradigm which assumes independent and identically distributed observations, and embrace learning challenges that are motivated from learning problems with state, incomplete or biased data, data with dependencies, and multi-agent learning applications. In particular, he would like to see more activity in obtaining new models and algorithms for reinforcement and multi-agent learning, better tools for high-dimensional learning problems with data bias and dependencies, as well as deeper connections to causal inference and econometrics. <em>“There is a lot of beautiful mathematics to be done and new continents to explore motivated by these challenges.”</em></p>



<h4>Acknowledgements </h4>



<p>We are thankful to Margalit Glasgow, Gautam Kamath, Praneeth Netrapalli, Arun Sai Suggala, and Manolis Zampetakis for providing valuable feedback on the blog. We would like to especially thank Costis Daskalakis for helpful conversations related to the technical and philosophical aspects of this work, and valuable comments throughout the writing of this article.</p>
</div></div>



<p><strong>Notes</strong></p>



<p id="fn1"><sup>1 </sup> As we discuss later, this existence only holds when the gains of each player are a concave function of their own actions.</p>



<p id="fn2"><sup>2</sup> This led to Nash winning the Nobel prize in Economics in 1994 with John Harsanyi and Reinhard Selten.</p>



<p id="fn3"><sup>3</sup> PPAD is the complexity class that exactly captures the complexity of computing Nash equilibria in general-sum games, computing fixed points of Lipschitz functions in convex and compact domains, and many other equilibrium and fixed point computation problems.</p>



<p id="fn4"><sup>4</sup> In Sperner, we are given white-box access to a circuit that computes colors for the vertices of some canonical simplicization of the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional simplex. Each vertex receives one of the colors in <img alt="\{1,\ldots,d+1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C%5Cldots%2Cd%2B1%5C%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and each color <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> does not appear on any vertex of the triangulation lying on facet <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the simplex. The goal is to find a simplex of the triangulation with all vertices colored differently.</p>



<p><strong>Bibliography</strong></p>



<p id="DSZ21">[DSZ21] Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis. The complexity of constrained min-max optimization. Symposium on Theory of Computing, 2021</p>



<p id="HPV89">[HPV89] Michael D Hirsch, Christos H Papadimitriou, and Stephen A Vavasis. Exponential lower bounds for finding brouwer fixed points. Journal of Complexity, 1989.</p>



<p id="NY83">[NY83] Arkadi S. Nemirovsky and David B. Yudin. Problem complexity and method efficiency in optimization. Wiley, 1983.</p>



<p id="Pap94">[Pap94] Christos H. Papadimitriou. On the complexity of the parity argument and other inefficient proofs of existence. Journal of Computer and System Sciences, 1994.</p>



<p id="Ros65">[Ros65] J. Ben Rosen. Existence and uniqueness of equilibrium points for concave n-person games. Econometrica, 1965.</p>



<p id="vN28">[vN28] John von Neumann. Zur Theorie der Gesellschaftsspiele. In Mathematische annalen, 1928.</p></div>
    </content>
    <updated>2021-04-30T14:05:03Z</updated>
    <published>2021-04-30T14:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T20:38:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=94</id>
    <link href="https://dstheory.wordpress.com/2021/04/29/thursday-may-6th-hamed-hassani-from-university-of-pennsylvania/" rel="alternate" type="text/html"/>
    <title>Thursday May 6th — Hamed Hassani  from University of Pennsylvania</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, May 6th at 11:00 AM Pacific Time (14:00 Eastern Time, 19:00 Central European Time, 18:00 UTC).  Hamed Hassani from Univeristy of Pennsylvania will speak about “Learning Robust Models: How does the Geometry of Perturbations Play a Role?” Please register here to join the<a class="more-link" href="https://dstheory.wordpress.com/2021/04/29/thursday-may-6th-hamed-hassani-from-university-of-pennsylvania/">Continue reading <span class="screen-reader-text">"Thursday May 6th — Hamed Hassani  from University of Pennsylvania"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-justify">The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, May 6</strong>th at <strong>11:00 AM Pacific Time</strong> (14:00 Eastern Time, 19:00 Central European Time, 18:00 UTC).  <strong><a href="https://www.seas.upenn.edu/~hassani/index.html" rel="noreferrer noopener" target="_blank">Hamed Hassani</a></strong> from<strong> Univeristy of Pennsylvania</strong> will speak about “Learning Robust Models: How does the Geometry of Perturbations Play a Role?”</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: In this talk, we will focus on the emerging field of (adversarially) robust machine learning. The talk will be self-contained and no particular background on robust learning will be needed. Recent progress in this field has been accelerated by the observation that despite unprecedented performance on clean data, modern learning models remain fragile to seemingly innocuous changes such as small, norm-bounded additive perturbations.  Moreover, recent work in this field has looked beyond norm-bounded perturbations and has revealed that various other types of distributional shifts in the data can significantly degrade performance.  However, in general our understanding of such shifts is in its infancy and several key questions remain unaddressed.</p>



<p class="has-text-align-justify">The goal of this talk is to explain why robust learning paradigms have to be designed — and sometimes rethought — based on the geometry of the input perturbations.  We will cover a wide range of perturbation geometries from simple norm-bounded perturbations, to sparse, natural, and more general distribution shifts.  As we will show, the geometry of the perturbations necessitates fundamental modifications to the learning procedure as well as the architecture in order to ensure robustness. In the first part of the talk, we will discuss our recent theoretical results on robust learning with respect to various geometries, along with fundamental tradeoffs between robustness and accuracy, phase transitions, etc.  The remaining portion of the talk will be about developing practical robust training algorithms and evaluating the resulting (robust) deep networks against state-of-the-art methods on naturally-varying, real-world datasets.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-04-29T21:14:05Z</updated>
    <published>2021-04-29T21:14:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-05-05T20:39:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/061" rel="alternate" type="text/html"/>
    <title>TR21-061 |  Reflections on Proof Complexity and Counting Principles | 

	Noah Fleming, 

	Toniann Pitassi</title>
    <summary>This paper surveys the development of propositional proof complexity and the seminal contributions of Alasdair Urquhart. We focus on the central role of counting principles, and in particular Tseitin's graph tautologies, to most of the key advances in lower bounds in proof complexity. We reflect on a couple of key ideas that Urquhart pioneered: (i) graph expansion as a tool for distinguishing between easy and hard principles, and (ii) ``reductive" lower bound arguments, proving via a simulation theorem that an optimal proof cannot bypass the obvious (inefficient) one.</summary>
    <updated>2021-04-29T20:10:17Z</updated>
    <published>2021-04-29T20:10:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/28/how-good-greed</id>
    <link href="https://11011110.github.io/blog/2021/04/28/how-good-greed.html" rel="alternate" type="text/html"/>
    <title>How good is greed for the no-three-in-line problem?</title>
    <summary>The 37th European Workshop on Computational Geometry (EuroCG 2021) was earlier this month, but its book of abstracts remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the Canadian Conference on Computational Geometry performs much the same role, but does publish a proceedings; its submission deadline is rapidly approaching.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://eurocg21.spbu.ru/">37th European Workshop on Computational Geometry (EuroCG 2021)</a> was earlier this month, but its <a href="http://eurocg21.spbu.ru/wp-content/uploads/2021/04/proceedings.pdf">book of abstracts</a> remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the <a href="http://cccg.ca/">Canadian Conference on Computational Geometry</a> performs much the same role, but does publish a proceedings; its <a href="https://projects.cs.dal.ca/cccg2021/the-call-for-papers-is-out/">submission deadline</a> is rapidly approaching.</p>

<p>Anyway, one of the EuroCG not-really-a-published-paper things is mine: “Geometric dominating sets – A minimum version of the no-three-in-line problem”, with Oswin Aichholzer and Eva-Maria Hainzl. As the title suggests, it’s related to the <a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">no-three-in-line problem</a>, in which one must place as many points as possible in a grid so that no three are collinear. I’ve written about the same problem here <a href="https://11011110.github.io/blog/2018/11/10/random-no-three.html">several</a> <a href="https://11011110.github.io/blog/2018/11/12/gurobi-vs-no.html">times</a> <a href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html">already</a>. On an \(n\times n\) grid, there’s an easy upper bound of \(2n\) on the number of points, but it’s widely conjectured that the actual number is a smaller linear function of \(n\). It was a big step forward when Erdős showed that \(n\bigl(1-o(1)\bigr)\) points can be placed, and this was later improved to \(\tfrac{3}{2}n\bigl(1-o(1)\bigr)\).</p>

<p>These big no-three-in-line sets are constructed algebraically, but what if we try something simpler, a greedy algorithm that just adds points one by one (in a random or systematic order) until getting stuck? This question was already asked in the 1970s by Martin Gardner, and studied by several other authors since. But it is, if anything, even more frustratingly unknown than the no-three-in-line problem itself. We don’t know whether, in general, it’s possible to get stuck with fewer points than the maximum solution to the no-three-in-line problem, or even whether it’s possible to get stuck with fewer than \(2n\) points for infinitely many values of \(n\). For some values of \(n\) we do know smaller stuck solutions, though: for instance, here’s one with \(28\) points on a \(36\times 36\) grid.</p>

<p style="text-align: center;"><img alt="A 28-point greedy solution to the no-three-in-line problem on a 36x36 grid" src="https://11011110.github.io/blog/assets/2021/greedy-no3-36x36.svg"/></p>

<p>It was known that greedy solutions always have \(\Omega(\sqrt{n})\) points, and one of our main results is to improve this bound to \(\Omega(n^{2/3})\). The known \(\Omega(\sqrt{n})\) lower bound is easy to see: A single line through two selected points can cover at most \(n\) other grid points, so you need \(n\) lines to cover the whole grid, and you need \(\Omega(\sqrt{n})\) points to determine this many lines. With fewer points, there won’t be enough lines through your points to cover the whole grid, and your greedy solution won’t be stuck. Our new \(\Omega(n^{2/3})\) bound looks more carefully at the tradeoff between numbers of lines and numbers of points per line. It can be divided into two cases:</p>

<ul>
  <li>
    <p>Suppose, first, that the selected point set has the property that, for any selected point \(p\), the lines through \(p\) cover fewer than \(n^{4/3}\) grid points. Because each selected point covers few grid points, we need to select many points to cover the whole grid: at least \(\Omega(n^{2/3})\) points.</p>
  </li>
  <li>
    <p>Suppose on the other hand that the lines through some point \(p\) cover at least  \(n^{4/3}\) grid points. Parameterize these lines by the \(L_\infty\) distance to the closest grid point (regardless of whether that point is one of the selected ones). Then there are \(O(k)\) lines with parameter \(k\), each of which covers \(O(n/k)\) grid points. Summing over small values of \(k\) shows that, even if we use lines that cover as many grid points as possible, we need  \(\Omega(n^{2/3})\) lines through \(p\) to cover this many grid points. Each of these lines is determined by another selected point, so we need \(\Omega(n^{2/3})\) selected points.</p>
  </li>
</ul>

<p>The actual proof in the paper takes into account that not all the grid points near \(p\) are the nearest on their line, and does the summation over small values of \(k\) more carefully, to get more precise constant factors in the bounds. Our paper also includes another variation of the problem in which we allow our selected points to be collinear but require the lines through them to cover all unselected points. There, we can make a little progress: we show that \(n\) points, or in some cases slightly fewer than \(n\) points, are sufficient. The same \(\Omega(n^{2/3})\) lower bound is still valid for this case, but there’s still a big gap between the lower bound and the upper bound.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106146843522019241">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-04-28T18:23:00Z</updated>
    <published>2021-04-28T18:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-05-01T00:37:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18647</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/" rel="alternate" type="text/html"/>
    <title>Congrats to the New Members</title>
    <summary>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off no matter what they say—Barbara McClintock David Oxtoby is the president of AAAS. He just announced the 2021 new members. See the press release. Today I thought I would explain which choices are correct […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> no matter what they say—Barbara McClintock</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/oxtobycropped/" rel="attachment wp-att-18671"><img alt="" class="alignright size-full wp-image-18671" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/oxtobyCropped.png?resize=121%2C150&amp;ssl=1" width="121"/></a></p>
<p>
David Oxtoby is the president of <a href="https://www.amacad.org/new-members-2021">AAAS</a>. He just announced the 2021 new members. See the <a href="https://www.amacad.org/news/2021-member-announcement">press release</a>.</p>
<p>
Today I thought I would explain which choices are correct and which are <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/>
<span id="more-18647"/></p>
<p>
Just kidding. Of course they all are terrific choices. Here are some choices in previous years—going back a little while: </p>
<blockquote><p><b> </b> <em> The new class joins Academy members elected before them, including Benjamin Franklin (elected 1781) and Alexander Hamilton (1791) in the eighteenth century; Ralph Waldo Emerson (1864), Maria Mitchell (1848), and Charles Darwin (1874) in the nineteenth; Albert Einstein (1924), Robert Frost (1931), Margaret Mead (1948), Groucho Marx (1951), Milton Friedman (1959), Martin Luther King, Jr. (1966), and Anthony Fauci (1991) in the twentieth. </em>
</p></blockquote>
<p>
</p><p/><h2> Computer Science </h2><p/>
<p/><p>
Here they are with some fun facts.</p>
<p>
<a href="https://en.wikipedia.org/wiki/Demis_Hassabis">Demis Hassabis</a> (International Honorary Member), DeepMind <br/>
Child chess prodigy: at the age of 13 had an Elo rating of 2300.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/dh/" rel="attachment wp-att-18657"><img alt="" class="aligncenter size-thumbnail wp-image-18657" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/dh-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Charles_Lee_Isbell_Jr.">Charles Isbell</a>, Georgia Institute of Technology <br/>
Started the Black History Database. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ci/" rel="attachment wp-att-18659"><img alt="" class="aligncenter size-thumbnail wp-image-18659" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ci-150x150.jpg?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Fei-Fei_Li">Fei-Fei Li</a>, Stanford University <br/>
Helped create ImageNet. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/fl/" rel="attachment wp-att-18660"><img alt="" class="aligncenter size-thumbnail wp-image-18660" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/fl-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://www.linkedin.com/in/murielmedard/">Muriel Medard</a>, Massachusetts Institute of Technology <br/>
Co-founded multiple companies. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/mm-3/" rel="attachment wp-att-18661"><img alt="" class="aligncenter size-thumbnail wp-image-18661" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/mm-1-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Stefan_Savage">Stefan Savage</a>, University of California, San Diego <br/>
Uses cool names for projects: Jetset, Trufflehunter, <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ss/" rel="attachment wp-att-18666"><img alt="" class="aligncenter size-thumbnail wp-image-18666" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ss-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Margo_Seltzer">Margo Seltzer</a>, University of British Columbia <br/>
Very busy: see her <a href="https://www.seltzer.com/margo/calendar/">calendar</a> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ms-2/" rel="attachment wp-att-18663"><img alt="" class="aligncenter size-thumbnail wp-image-18663" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ms-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Daniel_Spielman">Daniel Spielman</a>, Yale University <br/>
Once held a professorship named for “Hank the Deuce” or “HF2”. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ds/" rel="attachment wp-att-18664"><img alt="" class="aligncenter size-thumbnail wp-image-18664" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ds-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
[re-aligned photo at top]</p>
<p/><h2> Mathematics </h2><p/>
<p/><p>
<a href="https://en.wikipedia.org/wiki/Yakov_Eliashberg">Yakov Eliashberg</a>, Stanford University <br/>
<a href="https://en.wikipedia.org/wiki/Benson_Farb">Benson Farb</a>, University of Chicago <br/>
<a href="https://www.math.nyu.edu/faculty/masmoudi/">Nader Masmoudi</a>, New York University <br/>
<a href="https://en.wikipedia.org/wiki/Kavita_Ramanan">Kavita Ramanan</a>, Brown University <br/>
<a href="https://en.wikipedia.org/wiki/Scott_D._Sheffield">Scott Sheffield</a>, Massachusetts Institute of Technology <br/>
<a href="https://en.wikipedia.org/wiki/Karen_E._Smith">Karen Smith</a>, University of Michigan <br/>
<a href="https://en.wikipedia.org/wiki/Amie_Wilkinson">Amie Wilkinson</a>, University of Chicago </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you have better fun facts on the winners? Let us know if you do.</p>
<p/></font></font></div>
    </content>
    <updated>2021-04-28T16:20:07Z</updated>
    <published>2021-04-28T16:20:07Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="AAAS"/>
    <category term="Awards"/>
    <category term="congrats"/>
    <category term="new members"/>
    <category term="who"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-05-05T20:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8105</id>
    <link href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/" rel="alternate" type="text/html"/>
    <title>Google Research Workshop on Deep Learning Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz] Please join us for a virtual Google workshop on “Conceptual Understanding of Deep Learning”  When: May 17th 9am-4pm. Where: Live over Youtube, Goal: How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological … <a class="more-link" href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/">Continue reading <span class="screen-reader-text">Google Research Workshop on Deep Learning Theory</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz]</em><br/></p>



<p>Please join us for a virtual Google workshop on “<a href="https://sites.google.com/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">Conceptual Understanding of Deep Learning</a>” </p>



<p>When: May 17th 9am-4pm. Where: <a href="https://www.youtube.com/watch?v=g5DGBWjiULQ" rel="noreferrer noopener" target="_blank">Live over Youtube</a>,</p>



<p><strong>Goal: </strong>How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.</p>



<p>The speakers and panelists include Turing award winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou (<a href="https://sites.google.com/corp/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">full-details</a>).   </p>



<p><strong>Panel Discussion: </strong>There will also be a panel discussion on the fundamental question of “Is there a mathematical model for the Mind?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”<br/><br/>Twitter:<a href="https://twitter.com/search?q=%23ConceptualDLWorkshop&amp;src=recent_search_click" rel="noreferrer noopener" target="_blank"> #ConceptualDLWorkshop</a>. Please help advertise on mailing-lists/blog-posts and <a href="https://twitter.com/rinapy/status/1384311169519788032" rel="noreferrer noopener" target="_blank">Retweet</a>.<br/>Hope to see you there!</p>



<p>Rina Panigrahy<br/>(<a href="http://theory.stanford.edu/~rinap" rel="noreferrer noopener" target="_blank">http://theory.stanford.edu/~rinap</a>)</p></div>
    </content>
    <updated>2021-04-27T18:55:31Z</updated>
    <published>2021-04-27T18:55:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T20:38:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/alt-highlights/</id>
    <link href="https://differentialprivacy.org/alt-highlights/" rel="alternate" type="text/html"/>
    <title>ALT Highlights - An Equivalence between Private Learning and Online Learning (ALT '21 Tutorial)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! 
To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. 
Given the topic of this post, we felt <a href="https://differentialprivacy.org/">DifferentialPrivacy.org</a> was a great fit.
This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. 
All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>

<p>The second post is coverage of <a href="http://www.cs.technion.ac.il/~shaymrn">Shay Moran</a>’s <a href="https://www.youtube.com/watch?v=wk910Aj559A">tutorial</a>, by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>.</p>

<hr/>

<p>The tutorial at ALT was given by <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, an assistant professor at the Technion in Haifa.
His <a href="https://www.youtube.com/watch?v=wk910Aj559A">talk</a> focused on recent results showing a deep connection between two important areas in learning theory: online learning and differentially private learning. 
While online learning is a well-established area that has been studied since the invention of the Perceptron algorithm in 1954, differential privacy (DP) - introduced in the seminal work of Dwork, McSherry, Nissim, and Smith in 2006 <a href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405"><strong>[DMNS06]</strong></a> - has received increasing attention in recent years from both theoretical and applied research communities along with industry and the government. 
This recent interest in differential privacy comes from a need to protect the privacy rights of the individuals, while still allowing one to derive useful conclusions from the dataset.
Shay, in a sequence of papers with co-authors Noga Alon, Mark Bun, Roi Livni, and Maryanthe Malliaris, revealed a surprising qualitative connection between these two models of learning: a concept class can be learned in an online fashion if and only if this concept class can be learned in an offline fashion by a differentially private algorithm.</p>

<p>The main objectives of this tutorial were to give an in-depth foray into this recent work, and present an opportunity to young researchers to identify interesting research problems at the intersection of these two fields. This line of work (<a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>, <a href="https://arxiv.org/abs/2003.00563"><strong>[BLM20]</strong></a>) - which has been primarily featured in general CS Theory conferences, including recently winning a best paper award at FOCS -  introduced several new techniques which could be of use to the machine learning theory community. The first part of this article focuses on the technical challenges of characterizing DP learnability and the solutions used in Shay’s work, which originate from combinatorics and model theory. In the rest of this article, we highlight some of the exciting open directions Shay sees more broadly in learning theory.</p>

<h2 id="background-pac-learning-online-learning-and-dp-pac-learning">Background: PAC Learning, Online Learning, and DP PAC Learning</h2>

<p>We begin by reviewing the classical setting of PAC learning. 
The goal of PAC learning is to learn some function from a <em>concept class</em> \(\mathcal{H} \), a set of functions from some domain \( \mathcal{X} \) to \( \{0, 1\} \). 
<img align="right" src="https://differentialprivacy.org/images/PACLearning.png" style="width: 300px; height: 300px;"/> 
In the realizable setting of PAC learning, which we will focus on here, the learner is presented with \( n \) labeled training samples \( \{(x_i, y_i)\}_{i=1}^{n} \) where \( x_i \in \mathcal{X} \) and \( y_i = h(x_i) \) for some function \( h \in \mathcal{H} \). While the learner knows the concept class \( \mathcal{H} \), the function \( h \) is unknown, and after seeing the \( n \) samples, the learner algorithm \( A \) must output some function \( \hat{h}: \mathcal{X} \rightarrow \{0, 1\} \). A concept class is <em>PAC-learnable</em> if there exists an algorithm \( A \) such that for any distribution over samples, as the number of labeled training samples goes to infinity, the probability that \( \hat{h} \) incorrectly labels a new random sample goes to 0. We will say that \( A \) is a <em>proper</em> learner if \( A \) outputs a function in \(\mathcal{H}\), while \( A \) is <em>improper</em> if it may output a function outside of \( \mathcal{H} \). More quantitative measures of learnability concern the exact number of samples \( n \) needed for the learner to correctly predict future labels with nontrivial probability.</p>

<p>DP PAC learning imposes an additional restriction on PAC learning: the learner must output a function which does not reveal too much about any one sample in the input. Formally, we say an algorithm \( A \) is \( (\varepsilon, \delta) \)-DP if for any two neighboring inputs \( X = (X_1, \cdots,  X_i, \cdots, X_n) \) and \( X’ = (X_1, \cdots, X_i’,\cdots, X_n) \) which differ at exactly one sample, for any set \( S \), \( \Pr[A(X) \in S] \leq e^\varepsilon Pr[A(X’) \in S] + \delta \) . A concept class is <em>DP PAC learnable</em> if it can be PAC-learned by a \( (0.1, o(1/n)) \)-DP algorithm \( A \). That is, changing any one training sample \( (x_i, y_i) \) should not affect the distribution over concepts output by \( A \) by too much.</p>

<p>Online learning considers a setting where the samples arrive one-by-one, and the learner must make predictions as this process unfolds. <img align="right" src="https://differentialprivacy.org/images/OnlineLearning.png" style="width: 300px; height: 300px;"/>Formally, in realizable online learning, at each round \( i = 1,\dots,T \), the learner is presented with a sample \( x_i\). The learner must predict the label, and then the true label \( y_i \) is revealed to the learner. The sequence of examples \( x_i \) and the labels \( y_i \) may be chosen adversarially, but they must be consistent with some function \( h \in \mathcal{H} \). The goal of the learner is to minimize the total number of mistakes made by round \( T \), also called the <em>mistake bound</em>. If there is a learner such that at \( T \rightarrow \infty \), the number of mistakes is \( o(T) \), we say that the class of functions \( \mathcal{H} \) is <em>online learnable</em>. Because of the adversarial nature of the examples, online learning is well known to be much harder than PAC learning, and is possible precisely when the <em>Littlestone Dimension</em> of the concept class is finite. Figure 1 below illustrates the definition of the Littlestone Dimension. One important PAC-learnable concept class which is not online learnable is the infinite class of thresholds on \( \mathbb{R} \): The set of functions \(\{h_t\}_{t \in \mathbb{R}} \) where \( h_t(x) = \textbf{1}(x &gt; t) \).</p>

<p><img alt="Figure 1: Littlestone Dimension" src="https://differentialprivacy.org/images/LD.png" title="Figure 1: Littlestone Dimension"/></p>

<p><strong>Figure 1</strong>: The Littlestone dimension is the maximum depth of a tree shattered by \( \mathcal{H} \), where each node may contain a unique element from \(\mathcal{X}\). The tree is shattered if each leaf can be labeled by a function in \(\mathcal{H} \) that labels each element on the path to the root according to the value of the edge entering it. In this figure, we show how the set of thresholds on \( [0, 1] \) shatters this tree of depth 3.</p>

<p>It’s worth taking a moment to understand intuitively why learning thresholds might be hard for both an online learner and a DP learner. In an online setting, suppose the adversary chooses the next example to be any value of \( x \) in between all previously 0-labeled examples and all 1-labeled examples. Then no matter what label \( A \) chooses, the adversary can say \( A \) was incorrect. In a DP setting, a simple proper learner that outputs a threshold that makes no errors on the training data will reveal too much information about the samples at the boundary of 0-labeled samples and 1-labeled samples.</p>

<h2 id="a-challenging-question">A Challenging Question</h2>

<p>The journey to characterizing DP PAC learnability started soon after the introduction of DP, in <a href="https://arxiv.org/abs/0803.0924"><strong>[KLNRS08]</strong></a>, where the concept of DP PAC learning was introduced. This work primarily considered the more stringent <em>pure</em> DP-learning, where \( \delta = 0\). This work established that any finite concept class could be learned privately by applying the <em>exponential mechanism</em> (a standard technique in DP) to the empirical error of each candidate concept. Using the exponential mechanism, the learner could output each function \( h \in \mathcal{H}\) with probability proportional to \( \exp(- \varepsilon(\# \text{ of errors h on the training data})) \). This was sufficiently private because the empirical error is not too sensitive to a change of one training sample. Later works <a href="https://arxiv.org/abs/1402.2224"><strong>[BNS14]</strong></a> combinatorially characterized the complexity of pure DP PAC learning in terms of a measure called <em>representation dimension</em>, showing that in some cases where PAC learning was possible, pure DP PAC learning was not. <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> further yielded lower bounds on the limits of proper DP PAC learning.<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">1</a></sup><br/>
Both pure and proper DP learning though are significantly more stringent than improper DP learning, and proving lower bounds against an improper DP learner posed a serious challenge. Even the following simple-sounding question was unsolved:</p>

<blockquote>
  <p>Can an improper DP algorithm learn the infinite class of thresholds over [0, 1]? (*)</p>
</blockquote>

<p>This question stands at the center of Shay’s work, which unfolded while Shay was residing at the Institute for Advanced Study (IAS) at Princeton from 2017 to 2019.<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2" rel="footnote">2</a></sup> At the time, Shay was working on understanding the expressivity of limited mutual-information algorithms, that is, algorithms which expose little information about the total input. “If we were to have directly worked on this problem, I believe we wouldn’t have solved it,” Shay says. Instead, they came from the angle of mutual-information, a concept qualitatively similar to DP, but armed with a rich toolkit from 70 years of information theory. One of Shay’s prior works with Raef Bassily, Ido Nachum, Jonathan Shafer, and Amir Yehudayof established lower bounds on the mutual information of any proper algorithm that learns thresholds <a href="https://arxiv.org/abs/1710.05233"><strong>[BMNSY18]</strong></a>, though this didn’t yet address the challenge presented by improper learners.</p>

<p>Unlike most lower bounds in theoretical computer science, proving hardness of learning the infinite class of thresholds on the line against an improper DP algorithm would require coming up with algorithm-specific distributions over samples. That is, instead of showing that one distribution over samples would be impossible to learn for all algorithms — in the way the a uniform distribution over the set in \(\mathcal{X}\) shattered by the concept class is hard to PAC-learn for any algorithm — they would have to come up with a distribution on \(\mathcal{X}\) specific to each candidate learning algorithm. Indeed, if the distribution was known to the learner, it was possible to devise a DP algorithm using the exponential mechanism (again!) which could learn any PAC-learnable concept class. Similar to the case of finite concept classes, here we can apply the exponential mechanism to some finite set of representative functions forming a cover of the concept class.</p>

<h2 id="uncovering-a-solution">Uncovering a Solution</h2>

<p>At the IAS, Shay met his initial team to tackle this obstacle: Noga Alon, a combinatorialist, Roi Livni, a learning theorist, and Maryanthe Malliaris, a model theorist. Shay and Maryanthe would walk together from IAS to their combinatorics class at Princeton taught by Noga and discuss mathematics. While Marayathe studied the abstract mathematical field of model theory, Shay and Maryanthe soon noticed a connection between model theory and machine learning: the Littlestone dimension. “There is applied math, then pure math, and then model theory is way over there,” Shay elaborates. “If theoretical machine learning is between applied math and pure math, model theory is on the other extreme.” This surprising interdisciplinary connection led them to use a result from model theory: a concept class had finite Littlestone Dimension precisely when the concept class had finite threshold dimension (formally, the maximum number of threshold functions that could be embedded in the class). This meant that answering (*) negatively was enough to show that DP PAC learning was as hard as online learning.</p>

<p>The idea for showing a lower bound for improper DP learning of thresholds came from Ramsey Theory, a famous area in combinatorics. Ramsey theory guarantees the existence of structured subsets among large, but arbitrary, combinatorial objects. A toy example of Ramsey Theory is that in any graph on 6 or more nodes, there must be a group of 3 nodes which form either a clique or an independent set. In the case of DP learning thresholds, the learning algorithm \( A \) is the arbitrary (and unstructured) combinatorial object. Ramsey Theory guarantees that for any PAC learner \( A \), there exists some large subset \( \mathcal{X}’ \) of the domain \(\mathcal{X}=[0, 1]\) on which \( A \) is close to behaving “normally”. The next step is to show that behaving normally contradicts differentially privacy. We’ll dig more technically into this argument in the next couple paragraphs. Note that we invent a couple definitions for the sake of exposition (“proper-normal” and “improper-normal”) that don’t appear in <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> or <a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>.</p>

<p>Let’s start by seeing how a simpler version of this argument from <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> works to show that proper DP algorithms cannot learn thresholds. Recall that in a proper algorithm, after seeing \( n \) labeled samples, \( A \) must output a threshold. To be a PAC learner, if exactly half of the \( n \) samples are labeled \( 1 \) (which we will call a <em>balanced</em> sample), \( A \) must output a threshold between the smallest and largest sample with constant probability. Indeed, otherwise the empirical error of \( A \) will be too large to even hope to generalize. This implies that for a balanced list of samples \( S = [(x_1, 0), \ldots ,(x_{n/2}, 0), (x_{n/2+1}, 1), \ldots ,(x_n, 1)] \) (ordered by \(x\)-value), there must exist an integer \( k \in [n] \) for which with probability \( \Omega(1/n) \), \(A \) outputs a threshold in between 
\( x_k \) and \( x_{k+1} \). We’ll say that \( A \) is <em>\(k\)-proper-normal</em> on a set \( \mathcal{X}’ \) if for any balanced sample \( S \) of \( n \) points in \( \mathcal{X}’ \), \( A \) outputs a threshold in between the \(k\)th and \(k+1\)th ordered samples with probability \( \Omega(1/n) \). For example, the naive algorithm that always outputs a threshold between the 0-labeled samples and 1-labeled samples is \(n/2\)-normal on the entire domain \([0, 1]\). Ramsey theory guarantees that there is an arbitrary large subset of the domain \([0, 1]\) on which \(A \) is \(k\)-proper-normal for some \(k\). (See Figure 2).</p>

<p><img alt="Figure 2: Ramsey's Theorem" src="https://differentialprivacy.org/images/RamseyTheorem.png" title="Figure 2: Ramsey's Theorem"/>
<strong>Figure 2</strong>: Ramsey’s Theorem guarantees a large subset \( \mathcal{X}’ \) on which \( A \) is \( k \)-proper-normal for some \( k \).</p>

<p>The second part of the argument shows that being \( k \)-proper-normal on a large set is in direct conflict with differential privacy. We show this argument in Figure 3 by constructing a set of \( n \) samples \( S^* \) on which \( A \) must output a threshold in many distinct regions with substantial probability.</p>

<p><img alt="Figure 3: A Hard Distribution" src="https://differentialprivacy.org/images/DP_Construction.png" title="Figure 2: Ramsey's Theorem"/></p>

<p><strong>Figure 3:</strong> A distribution showing the conflict between \(A \) being DP and \(k\)-proper normal. By DP, the behaviour of \(A\) on \(S^* \) must be similar to its behaviour on \(S_i\) for \(i = 1 \ldots \Omega(n).\) Namely, since \(S^* \) and \( S_i \) differ by at most two points, \( A(S^*) \) must output a threshold in \( I_i \) with probability \( p \geq (q - 2\delta)e^{-(2\varepsilon)} \) for each \( i \), where \( q \) is a lower bound on the probability that \( A(S_i) \) outputs a threshold in \( I_i \). Because \( A \) is \(k\)-proper-normal, \( q &gt; c/n \), so \( p = \Omega(1/n) \). This yields a contradiction for \( m &gt;1/p \) because \( A \) cannot simultaneously output a threshold in two of the intervals \( I_i \).</p>

<p>For the case of improper algorithms, Shay and his coauthors considered an alternative notion of normality, which we will term <em>improper-normal</em>. Recall that in this case the output \( A(S) \) of the learner on a sample \( S \) is <em>any function</em> from \( [0, 1] \) to \( \{0, 1\} \) and not necessarly a threshold. We’ll say that \( A \) is \(k\)-improper-normal on a set \( \mathcal{X}’ \) if for any balanced sample \( S = [(x_1, 0), \ldots, (x_{n/2}, 0), (x_{n/2 +1}, 1), \ldots,  (x_n, 1)] \) of \( n \) points in \( \mathcal{X}’, \Pr[A(S)(w) = 1] - \Pr[A(S)(v) = 1] &gt; \Omega(1/n) \) for any \( w \in (x_{k - 1}, x_k) \) and \( v \in  (x_k, x_{k + 1}) \) in \( \mathcal{X}’ \setminus \{x_1, … x_n\} \). To PAC learn, A must be \(k\)-improper-normal for some \(k\) on any set of \(n + 1\) points. Applying the same Ramsey Theorem to a graph with colored hyperedges of size \(n + 1\) shows that there must exist an arbitrarily large set \( \mathcal{X}’ \) on which \( A \) is \(k\)-improper normal for some \( k \). A similar (but more nuanced) argument as before shows that a learner cannot be simultaneously private and \(k\)-improper-normal on some distribution over \( \mathcal{X}’ \).</p>

<p>For the last piece of the puzzle, showing the upper bound converse, Mark Bun, an expert in differential privacy at Princeton at the time, joined in. Beginning in the fall of 2019, Mark, Shay, and Roi worked out an upper bound that showed that any class with finite Littlestone dimension could be learned privately. Their technique introduced a new notion of stability, called <em>global stability</em>, which is a property of algorithms that frequently output the same hypothesis. Given a globally stable PAC learner \( A \), to obtain a DP PAC learner, one can run \( A \) many times and produce a histogram of the output hypotheses, add noise to this histogram for the sake of privacy, and then select the most frequent output hypothesis. The construction for the globally stable learner uses the Standard Optimal Algorithm for online learning as a black box - though the reduction is very computationally intensive and results in a sample complexity depending exponentially on the Littlestone Dimension. This reduction was improved in <a href="https://arxiv.org/abs/2012.03893"><strong>[GGKM20]</strong></a>, where the authors gave a reduction requiring only polynomially many samples in the Littlestone dimension.</p>

<h2 id="outlook">Outlook</h2>

<p>Shay mentions that these results are only a first step towards understanding differentially private PAC learning. This work establishes a deep connection between online learning and DP learning, qualitatively showing that these two problems have similar underlying complexity. Recent works <a href="https://arxiv.org/abs/1905.11311"><strong>[GHM19]</strong></a> have gone a step further and established polynomial time reductions from DP learning to online learning under certain conditions. At the same time, Bun <a href="https://arxiv.org/abs/2007.05665"><strong>[B20]</strong></a> demonstrates a computational gap between the two problems: they exhibit a concept class which is DP PAC learnable in polynomial time, but no algorithm can learn it online in polynomial time and sample complexity.</p>

<p>An interesting question here is whether a polynomial time online learning algorithm implies a polynomial time DP learning algorithm? With regards to sample complexity, tighter quantitative bounds relating the sample complexity of DP learning to the Threshold dimension and the Littlestone Dimension, along with constructive reductions from DP learning to online learning are wide open. An interesting conjecture, also highlighted in the talk, is whether DP PAC learning and PAC learning are actually equivalent up to a \(log*\) factor of the Littlestone dimension? Solving this would mean that for most natural function classes, one need not pay a very high price for private learning as compared to PAC learning.</p>

<p>From a more practical perspective, studying such qualitative equivalences can lay the groundwork allowing one to use the vast existing knowledge in the field of online learning to design better algorithms for DP learning, and vice versa. Despite its abstractness, Shay believes this result still has significance for engineers: “If they want to do something differentially privately, if they already have a good online learning algorithm for this, maybe they can modify it,” Shay says. “It gives some kind of inspiration.”</p>

<p>From a broader perspective, Shay believes that discovering clean, beautiful mathematical models that are more realistic than the PAC learning model and understanding the price one pays for privacy in those models are important directions for future research. One model, highlighted in the tutorial by Shay is that of <em>Universal Learning</em>, introduced in a recent work <a href="https://arxiv.org/abs/2011.04483"><strong>[BHMVY21]</strong></a> with Olivier Bousquet, Steve Hanneke, Ramon van Handel and Amir Yehudayoff. This model considers a learning task with a fixed distribution of samples and studies the hardness of the problem as the number of samples \( n \to \infty \). This setup better captures the practical aspects of modern machine learning and overcomes the limitations of the PAC model, which studies worst-case distributions for each sample size.</p>

<p>And how should one go about identifying such better mathematical models? “Pick the simplest problem that you don’t know how to solve and see where that leads you”, says Shay. One should begin by trying to understand the deficiencies of existing learning models, by identifying simple examples which go beyond these existing models. For example, Livni and Moran <a href="https://arxiv.org/abs/2006.13508"><strong>[LM20]</strong></a> exhibit the limitations of PAC-Bayes framework through a simple 1D linear classification problem. Fixing such limitations can often lead one to discover better learning models.</p>

<hr/>
<p><em>Thanks to Gautam Kamath, Shay Moran, and Keziah Naggita for helpful conversations and comments.</em></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>For a more complete background on the progress in DP PAC learning, we refer the reader to the excellent survey blog post <a href="https://differentialprivacy.org/private-pac/">here</a>. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>At the time, Shay was additionally affiliated with Princeton University and Google Brain. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2021-04-26T16:00:00Z</updated>
    <published>2021-04-26T16:00:00Z</published>
    <author>
      <name>Margalit Glasgow</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-05-05T13:39:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9152128988613149804</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9152128988613149804/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html" rel="alternate" type="text/html"/>
    <title>Ferrer's Diagrams can be used to prove X theorems about partitions. What is X?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>1978: I took an excellent  ugrad course in combinatorics from James C Frauenthal (he sometimes wrote his name as the biniomial cofficient (J choose F))  and he covered Ferrer's diagrams. They are a nice way to prove equalities about types of partitions.   See <a href="https://www.britannica.com/science/combinatorics/The-Ferrer-diagram">here</a> for a definition and a few examples. I have this (possibly false) memory that there were LOTS of partition theorems proven nicely with Ferrer's diagrams.</p><p>Fast forward to 2021:</p><p>2021: My TA Emily  needs a topic to cover in Honors Discrete Math. I have this memory that there were LOTS of theorems about partitions proven with Ferrer's diagrams. We look at many websites on Ferrer diagrams  and  find only TWO examples:</p><p>The numb of partitions of n into k parts is the numb of partitions of n into parts the largest of which is k.</p><p><br/></p><p>The numb of partitions of n into \le k parts is the numb of partitions of n into parts the largest of which is \le k</p><p>We DO find many theorems about partitions such as this corollary to the Rogers-Ramanujan theorem:</p><p>The numb of partitions of n such that adjacent parts differ by at least 2 is the numb of partitions of n such that each partition is either \equiv 1 mod 5 or \equiv 4 mod 5.</p><p>This is a HARD theorem and there is no Ferrer-diagram or other elementary proof. </p><p>SO, I have one MEMORY but the reality seems different. Possibilities:</p><p>1) My memory is wrong. There really are only 2 examples (or some very small number).</p><p>2) There are other examples but I can't find them on the web. I HOPE this is true--- if someone knows of other ways to use Ferrer diagrams to get partition results, please comment. </p><p><br/></p></div>
    </content>
    <updated>2021-04-26T02:01:00Z</updated>
    <published>2021-04-26T02:01:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-05-05T08:04:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5481</id>
    <link href="https://www.scottaaronson.com/blog/?p=5481" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5481#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5481" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The easiest exercise in the moral philosophy book</title>
    <summary xml:lang="en-US">Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit. Assuming we’d do that, he argued that we do […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit.  Assuming we’d do that, he argued that we do in fact face an ethically equivalent choice; if we don’t donate most of our income to save children in the Third World, then we need to answer for why, as surely as the person who walked past the kid thrashing in the water.</p>



<p>In this post, I don’t want to take a position on Singer’s difficult but important hypothetical.  I merely want to say: suppose that to save the child, you didn’t even have to jump in the water.  Suppose you just had to toss a life preserver, one you weren’t using.  Or suppose you just had to assure the child that it was OK to grab your life raft that was already in the water.</p>



<p>That, it seems, is the situation that the US and other rich countries will increasingly face with covid vaccines.  What’s happening in India right now looks on track to become a humanitarian tragedy, if it isn’t already.  Even if, as Indian friends tell me, this was a staggering failure of the Modi government, people shouldn’t pay for it with their lives.  And we in the US now have tens of millions of vaccine doses sitting in warehouses unused, for regulatory and vaccine hesitancy reasons—stupidly, but we do.  We’re past the time, in my opinion, when it’s morally obligatory either to use the doses or to give them away.  Anyone in a position to manufacture more vaccines for distribution to poor countries, should also immediately get the intellectual property rights to do so.</p>



<p>I was glad to read, just this weekend, that the US is finally starting to move in the right direction.  I hope it moves faster.</p>



<p>And I’m sorry that this brief post doesn’t contain any information or insight that you can’t find elsewhere.  It just made me feel better to write it, is all.</p></div>
    </content>
    <updated>2021-04-25T20:04:49Z</updated>
    <published>2021-04-25T20:04:49Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-04-25T20:04:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/060" rel="alternate" type="text/html"/>
    <title>TR21-060 |  Optimal Error Resilience of Adaptive Message Exchange | 

	Raghuvansh Saxena, 

	Klim Efremenko, 

	Gillat Kol</title>
    <summary>We study the error resilience of the message exchange task: Two parties, each holding a private input, want to exchange their inputs. However, the channel connecting them is governed by an adversary that may corrupt a constant fraction of the transmissions. What is the maximum fraction of corruptions that still allows the parties to exchange their inputs? 

For the non-adaptive channel, where the parties must agree in advance on the order in which they communicate, the maximum error resilience was shown to be $\frac{1}{4}$ (see Braverman and Rao, STOC 2011).
The problem was also studied over the adaptive channel, where the order in which the parties communicate may not be predetermined (Ghaffari, Haeupler, and Sudan, STOC 2014; Efremenko, Kol, and Saxena, STOC 2020). These works show that the adaptive channel admits much richer set of protocols but leave open the question of finding its maximum error resilience.

In this work, we show that the maximum error resilience of a protocol for message exchange over the adaptive channel is $\frac{5}{16}$, thereby settling the above question. Our result requires improving both the known upper bounds and the known lower bounds for the problem.</summary>
    <updated>2021-04-25T13:09:50Z</updated>
    <published>2021-04-25T13:09:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T20:37:37Z</updated>
    </source>
  </entry>
</feed>
