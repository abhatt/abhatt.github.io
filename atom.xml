<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-09-19T00:22:13Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=367</id>
    <link href="https://tcsplus.wordpress.com/2019/09/18/tcs-talk-wednesday-september-25-mark-sellke-stanford/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 25 — Mark Sellke, Stanford</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, September 25th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Mark Sellke from Stanford will speak about “Chasing Convex Bodies” (abstract below). Please make sure you reserve a spot for your group to join us live by signing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, September 25th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Mark Sellke</strong> from Stanford will speak about “<em>Chasing Convex Bodies</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: I will explain our recent understanding of the chasing convex bodies problem posed by Friedman and Linial in 1991. In this problem, an online player receives a request sequence <img alt="K_1,\dots,K_T" class="latex" src="https://s0.wp.com/latex.php?latex=K_1%2C%5Cdots%2CK_T&amp;bg=fff&amp;fg=444444&amp;s=0" title="K_1,\dots,K_T"/> of convex sets in <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> dimensional space and moves his position online into each requested set. The player’s movement cost is the length of the resulting path. Chasing convex bodies asks if there an online algorithm with cost competitive against the offline optimal path. This is both an challenging metrical task system and (equivalent to) a competitive analysis view on online convex optimization.</p>
<p>This problem was open for <img alt="d&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=d%3E2&amp;bg=fff&amp;fg=444444&amp;s=0" title="d&gt;2"/> until last year but has recently been solved twice. The first solution gives a <img alt="2^{O(d)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28d%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="2^{O(d)}"/> competitive algorithm while the second gives a nearly optimal <img alt="\min(d,\sqrt(d\log(T)))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin%28d%2C%5Csqrt%28d%5Clog%28T%29%29%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\min(d,\sqrt(d\log(T)))"/> competitive algorithm for <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> requests. The latter result is based on the Steiner point, which is the exact optimal solution to a related geometric problem called Lipschitz selection and dates from 1840. In the talk, I will briefly outline the first solution and fully explain the second.</p>
<p>Partially based on joint works with Sébastien Bubeck, Bo’az Klartag, Yin Tat Lee, and Yuanzhi Li.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2019-09-18T19:57:34Z</updated>
    <published>2019-09-18T19:57:34Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-09-19T00:21:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7551</id>
    <link href="https://windowsontheory.org/2019/09/18/swiss-tcs-winter-school-guest-post-by-david-steurer/" rel="alternate" type="text/html"/>
    <title>Swiss TCS winter school (guest post by David Steurer)</title>
    <summary>[Guest post by David Steurer – seems like a great opportunity! –Boaz] The Swiss Winter School on Lower Bounds and Communication Complexity (10-14 February 2020, https://theory.epfl.ch/WinterSchool2020/ ) is the first in a series of annual winter schools in Theoretical Computer Science jointly organized by EPFL and ETH Zurich. The goal of the school is to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by David Steurer – seems like a great opportunity! –Boaz]</em></p>



<p>The <a href="https://theory.epfl.ch/WinterSchool2020/">Swiss Winter School on Lower Bounds and Communication Complexity</a> (10-14 February 2020, <a href="https://theory.epfl.ch/WinterSchool2020/" rel="nofollow">https://theory.epfl.ch/WinterSchool2020/</a> ) is the first in a series of annual winter schools in Theoretical Computer Science jointly organized by EPFL and ETH Zurich. The goal of the school is to educate top international theory PhD students about exciting recent developments in the field. The winter school will be held in Zinal, a mountain village in the Swiss Alps that has a long tradition of hosting academic workshops and that allows for nice excursions and stimulating discussions in a relaxed atmosphere.</p>



<p>This year’s installment features an exciting trinity of speakers: Kasper Green Larsen (Data Structure Lower Bounds), Raghu Meka (Communication Complexity) and Amir Shpilka (Algebraic complexity). </p>



<p>The application deadline is November 15th 2019, and acceptance notifications will be sent by December 1st 2019. The application form is available at <a href="https://theory.epfl.ch/WinterSchool2020/" rel="nofollow">https://theory.epfl.ch/WinterSchool2020/</a>. Attendance of the winter school is free of charge and includes room and board (shared rooms).</p>



<p>Organizers: Michael Kapralov (EPFL),  David Steurer  (ETH) ,   Ola Svennson (EPFL) </p></div>
    </content>
    <updated>2019-09-18T12:36:54Z</updated>
    <published>2019-09-18T12:36:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-09-19T00:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07919</id>
    <link href="http://arxiv.org/abs/1909.07919" rel="alternate" type="text/html"/>
    <title>Combinatorial Algorithms for Edge-Disjoint $T$-Paths and Integer Free Multiflow</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iwata:Satoru.html">Satoru Iwata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yokoi:Yu.html">Yu Yokoi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07919">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a multigraph with a set $T\subseteq V$ of terminals. A path
in $G$ is called a $T$-path if its ends are distinct vertices in $T$ and no
internal vertices belong to $T$. In 1978, Mader showed a characterization of
the maximum number of edge-disjoint $T$-paths. The original proof was not
constructive, and hence it did not suggest an efficient algorithm.
</p>
<p>In this paper, we provide a combinatorial, deterministic algorithm for
finding the maximum number of edge-disjoint $T$-paths. The algorithm adopts an
augmenting path approach. More specifically, we introduce a novel concept of
augmenting walks in auxiliary labeled graphs to capture a possible augmentation
of the number of edge-disjoint $T$-paths. To design a search procedure for an
augmenting walk, we introduce blossoms analogously to the matching algorithm of
Edmonds (1965), while it is neither a special case nor a generalization of the
present problem. When the search procedure terminates without finding an
augmenting walk, the algorithm provides a certificate for the optimality of the
current edge-disjoint $T$-paths. Thus the correctness argument of the algorithm
serves as an alternative direct proof of Mader's theorem on edge-disjoint
$T$-paths. The algorithm runs in $O(|V|\cdot |E|^2)$ time, which is much faster
than the best known deterministic algorithm based on a reduction to the linear
matroid parity problem.
</p>
<p>We also present a strongly polynomial algorithm for solving the integer free
multiflow problem, which asks for a nonnegative integer combination of
$T$-paths maximizing the sum of the coefficients subject to capacity
constraints on the edges.
</p></div>
    </summary>
    <updated>2019-09-18T23:28:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07854</id>
    <link href="http://arxiv.org/abs/1909.07854" rel="alternate" type="text/html"/>
    <title>Dynamic coloring for Bipartite and General Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kashyop:Manas_Jyoti.html">Manas Jyoti Kashyop</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanaswamy:N=_S=.html">N. S. Narayanaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nasre:Meghana.html">Meghana Nasre</a>, Sai Mohith Potluri <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07854">PDF</a><br/><b>Abstract: </b>We consider the dynamic coloring problem on bipartite and general graphs in
the incremental as well as fully-dynamic settings. In this work, we are
interested in the following parameters : the update time and query time, the
number of colors used, and the number of vertex recolorings per update. Our
results reveal the following trade-off for a bipartite graph with $n$ vertices:
</p>
<p>In the fully dynamic setting, if we restrict the number of colors to $2$ then
the maximum of update and query time is at least $\log n$. In the incremental
setting, using $2$ colors we achieve the maximum of update and query time to be
$O(\alpha(n))$, where $\alpha(n)$ is the inverse Ackermann function.
</p>
<p>We show that by allowing more than two colors we can reduce the query time to
$O(1)$ without changing the update time. Our incremental algorithm uses $1+2
\log{n}$ colors.
</p>
<p>To the best of our knowledge, there are no known theoretical guarantees for
dynamic coloring specific to bipartite graphs. For general graphs we provide a
deterministic fully-dynamic algorithm with constant number of recolorings per
update.
</p>
<p>We use $\Delta+1$ colors and achieve $O(\sqrt{m})$ worst case update time
with at most one recoloring per update. Here $\Delta$ is the maximum degree of
a vertex and $m$ denotes the maximum number of edges throughout the update
sequence.
</p>
<p>For graphs of arboricity bounded by $\gamma$ we maintain a $\Delta+1$
coloring with at most one recoloring per update, an amortized update time of
$O(\gamma + \log{n})$, and an $O(1)$ query time.
</p></div>
    </summary>
    <updated>2019-09-18T23:24:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07816</id>
    <link href="http://arxiv.org/abs/1909.07816" rel="alternate" type="text/html"/>
    <title>The Computational Complexity of Fire Emblem Series and similar Tactical Role-Playing Games</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jiawei.html">Jiawei Gao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07816">PDF</a><br/><b>Abstract: </b>Fire Emblem (FE) is a popular turn-based tactical role-playing game (TRPG)
series on the Nintendo gaming consoles. This paper studies the computational
complexity of FE, and proves that: 1. General FE is PSPACE-complete. 2.
Poly-round FE is NP-complete, even when the map is cycle-free. Poly-round FE is
to decide whether the player can win the game in a certain number of rounds
that is polynomial to the map size. A map is called cycle-free if its
corresponding planar graph is cycle-free. These hardness results also hold for
other similar TRPG series, such as Final Fantasy Tactics, Tactics Ogre and
Disgaea.
</p></div>
    </summary>
    <updated>2019-09-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07780</id>
    <link href="http://arxiv.org/abs/1909.07780" rel="alternate" type="text/html"/>
    <title>Preprocessing and Cutting Planes with Conflict Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brito:Samuel_S=.html">Samuel S. Brito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Haroldo_G=.html">Haroldo G. Santos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07780">PDF</a><br/><b>Abstract: </b>This paper addresses the implementation of conflict graph-based routines into
the COIN-OR Branch-and-Cut (CBC) solver, including: $(i)$ a conflict graph
infrastructure with an improved version of a state-of-the-art conflict
detection algorithm to quickly build conflict graphs; this version detects
additional conflicts and has the same worst-case complexity of the original
algorithm; $(ii)$ a preprocessing routine based on a clique-strengthening
scheme that can both reduce the number of nonzeros in the constraint matrix and
also produce stronger formulations; $(iii)$ a clique cut separator capable of
obtaining dual bounds at the root node that are $26\%$ stronger than the ones
provided by the equivalent cut generator of a state-of-the-art commercial
solver, $467\%$ stronger than those attained by the clique cut separator of the
GLPK solver and $500\%$ stronger than the dual bounds obtained by the clique
separation routine of the COIN-OR Cut Generation Library; $(iv)$ an odd-cycle
cut separator with a lifting module to produce valid odd-wheel inequalities.
This new version of CBC obtained an average gap closed that is $26\%$ better
than the previous one and solved $27\%$ more instances.
</p></div>
    </summary>
    <updated>2019-09-18T23:21:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07703</id>
    <link href="http://arxiv.org/abs/1909.07703" rel="alternate" type="text/html"/>
    <title>Multi-robot persistent surveillance with connectivity constraints</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scherer:J=uuml=rgen.html">Jürgen Scherer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rinner:Bernhard.html">Bernhard Rinner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07703">PDF</a><br/><b>Abstract: </b>Mobile robots, especially unmanned aerial vehicles (UAVs), are of increasing
interest for surveillance and disaster response scenarios. We consider the
problem of multi-robot persistent surveillance with connectivity constraints
where robots have to visit sensing locations periodically and maintain a
multi-hop connection to a base station. We formally define several problem
instances closely related to multi-robot persistent surveillance with
connectivity constraints, i.e., connectivity-constrained multi-robot persistent
surveillance (CMPS), connectivity-constrained multi-robot reachability (CMR),
and connectivity-constrained multi-robot reachability with relay dropping
(CMRD), and show that they are all NP-hard on general graph. We introduce three
heuristics with different planning horizons for convex grid graphs and combine
these with a tree traversal approach which can be applied to a partitioning of
non-convex grid graphs (CMPS with tree traversal, CMPSTT). In simulation
studies we show that a short horizon greedy approach, which requires parameters
to be optimized beforehand, can outperform a full horizon approach, which
requires a tour through all sensing locations, if the number of robots is
larger than the minimum number of robots required to reach all sensing
locations. The minimum number required is the number of robots necessary for
building a chain to the farthest sensing location from the base station.
Furthermore, we show that partitioning the area and applying the tree traversal
approach can achieve a performance similar to the unpartitioned case up to a
certain number of robots but requires less optimization time.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07647</id>
    <link href="http://arxiv.org/abs/1909.07647" rel="alternate" type="text/html"/>
    <title>A heuristic use of dynamic programming to upperbound treewidth</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Hisao.html">Hisao Tamaki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07647">PDF</a><br/><b>Abstract: </b>For a graph $G$, let $\Omega(G)$ denote the set of all potential maximal
cliques of $G$. For each subset $\Omega$ of $\Omega(G)$, let $\tw(G, \Omega)$
denote the smallest $k$ such that there is a tree-decomposition of $G$ of width
$k$ whose bags all belong to $\Omega$. Bouchitt\'{e} and Todinca observed in
2001 that $\tw(G, \Omega(G))$ is exactly the treewidth of $G$ and developed a
dynamic programming algorithm to compute it. Indeed, their algorithm can
readily be applied to an arbitrary non-empty subset $\Omega$ of $\Omega(G)$ and
computes $\tw(G, \Omega)$, or reports that it is undefined, in time
$|\Omega||V(G)|^{O(1)}$. This efficient tool for computing $\tw(G, \Omega)$
allows us to conceive of an iterative improvement procedure for treewidth upper
bounds which maintains, as the current solution, a set of potential maximal
cliques rather than a tree-decomposition.
</p>
<p>We design and implement an algorithm along this approach. Experiments show
that our algorithm vastly outperforms previously implemented heuristic
algorithms for treewidth.
</p></div>
    </summary>
    <updated>2019-09-18T23:25:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07633</id>
    <link href="http://arxiv.org/abs/1909.07633" rel="alternate" type="text/html"/>
    <title>Communication-Efficient Weighted Sampling and Quantile Summary for GBDT</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Ziyue.html">Ziyue Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Ke.html">Ke Yi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07633">PDF</a><br/><b>Abstract: </b>Gradient boosting decision tree (GBDT) is a powerful and widely-used machine
learning model, which has achieved state-of-the-art performance in many
academic areas and production environment. However, communication overhead is
the main bottleneck in distributed training which can handle the massive data
nowadays. In this paper, we propose two novel communication-efficient methods
over distributed dataset to mitigate this problem, a weighted sampling approach
by which we can estimate the information gain over a small subset efficiently,
and distributed protocols for weighted quantile problem used in approximate
tree learning.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07557</id>
    <link href="http://arxiv.org/abs/1909.07557" rel="alternate" type="text/html"/>
    <title>Object Reachability via Swaps under Strict and Weak Preferences</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Sen.html">Sen Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07557">PDF</a><br/><b>Abstract: </b>The \textsc{Housing Market} problem is a widely studied resource allocation
problem. In this problem, each agent can only receive a single object and has
preferences over all objects. Starting from an initial endowment, we want to
reach a certain assignment via a sequence of rational trades. We first consider
whether an object is reachable for a given agent under a social network, where
a trade between two agents is allowed if they are neighbors in the network and
no participant has a deficit from the trade. Assume that the preferences of the
agents are strict (no tie among objects is allowed). This problem is
polynomially solvable in a star-network and NP-complete in a tree-network. It
is left as a challenging open problem whether the problem is polynomially
solvable when the network is a path. We answer this open problem positively by
giving a polynomial-time algorithm. Then we show that when the preferences of
the agents are weak (ties among objects are allowed), the problem becomes
NP-hard even when the network is a path. In addition, we consider the
computational complexity of finding different optimal assignments for the
problem under the network being a path or a star.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07538</id>
    <link href="http://arxiv.org/abs/1909.07538" rel="alternate" type="text/html"/>
    <title>Generalized Dictionary Matching under Substring Consistent Equivalence Relations</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07538">PDF</a><br/><b>Abstract: </b>Given a set of patterns called a dictionary and a text, the dictionary
matching problem is a task to find all occurrence positions of all patterns in
the text. The dictionary matching problem can be solved efficiently by using
the Aho-Corasick algorithm. Recently, Matsuoka et al. [TCS, 2016] proposed a
generalization of pattern matching problem under substring consistent
equivalence relations and presented a generalization of the Knuth-Morris-Pratt
algorithm to solve this problem. An equivalence relation $\approx$ is a
substring consistent equivalence relation (SCER) if for two strings $X,Y$, $X
\approx Y$ implies $|X| = |Y|$ and $X[i:j] \approx Y[i:j]$ for all $1 \le i \le
j \le |X|$. In this paper, we propose a generalization of the dictionary
matching problem and present a generalization of the Aho-Corasick algorithm for
the dictionary matching under SCER. We present an algorithm that constructs
SCER automata and an algorithm that performs dictionary matching under SCER by
using the automata. Moreover, we show the time and space complexity of our
algorithms with respect to the size of input strings.
</p></div>
    </summary>
    <updated>2019-09-18T23:26:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07515</id>
    <link href="http://arxiv.org/abs/1909.07515" rel="alternate" type="text/html"/>
    <title>Multiplicative Rank-1 Approximation using Length-Squared Sampling</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07515">PDF</a><br/><b>Abstract: </b>We show that the span of $\Omega(\frac{1}{\varepsilon^4})$ rows of any matrix
$A \subset \mathbb{R}^{n \times d}$ sampled according to the length-squared
distribution contains a rank-$1$ matrix $\tilde{A}$ such that $||A -
\tilde{A}||_F^2 \leq (1 + \varepsilon) \cdot ||A - \pi_1(A)||_F^2$, where
$\pi_1(A)$ denotes the best rank-$1$ approximation of $A$ under the Frobenius
norm. Length-squared sampling has previously been used in the context of
rank-$k$ approximation. However, the approximation obtained was additive in
nature. We obtain a multiplicative approximation albeit only for rank-$1$
approximation.
</p></div>
    </summary>
    <updated>2019-09-18T23:26:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07511</id>
    <link href="http://arxiv.org/abs/1909.07511" rel="alternate" type="text/html"/>
    <title>Streaming PTAS for Constrained k-Means</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Dishant.html">Dishant Goyal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07511">PDF</a><br/><b>Abstract: </b>We generalise the results of Bhattacharya et al. (Journal of Computing
Systems, 62(1):93-115, 2018) for the list-$k$-means problem defined as -- for a
(unknown) partition $X_1, ..., X_k$ of the dataset $X \subseteq \mathbb{R}^d$,
find a list of $k$-center sets (each element in the list is a set of $k$
centers) such that at least one of $k$-center sets $\{c_1, ..., c_k\}$ in the
list gives an $(1+\varepsilon)$-approximation with respect to the cost function
$\min_{\textrm{permutation } \pi} \left[ \sum_{i=1}^{k} \sum_{x \in X_i} ||x -
c_{\pi(i)}||^2 \right]$. The list-$k$-means problem is important for the
constrained $k$-means problem since algorithms for the former can be converted
to PTAS for various versions of the latter. Following are the consequences of
our generalisations:
</p>
<p>- Streaming algorithm: Our $D^2$-sampling based algorithm running in a single
iteration allows us to design a 2-pass, logspace streaming algorithm for the
list-$k$-means problem. This can be converted to a 4-pass, logspace streaming
PTAS for various constrained versions of the $k$-means problem. To the best of
our knowledge, these are the first constant pass, logspace streaming PTASs for
constrained versions of the $k$-means problem.
</p>
<p>- Faster PTAS under stability: Our generalisation is also useful in $k$-means
clustering scenarios where finding good centers becomes easy once good centers
for a few "bad" clusters have been chosen. One such scenario is clustering
under stability where the number of such bad clusters is a constant. Using the
above idea, we significantly improve the running time of the known algorithm
from $O(dn^3) (k \log{n})^{poly(\frac{1}{\beta}, \frac{1}{\varepsilon})}$ to $O
\left(dn^3 k^{\tilde{O}_{\beta \varepsilon}(\frac{1}{\beta \varepsilon})}
\right)$.
</p></div>
    </summary>
    <updated>2019-09-18T23:25:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07498</id>
    <link href="http://arxiv.org/abs/1909.07498" rel="alternate" type="text/html"/>
    <title>Vanishing-Error Approximate Degree and QMA Complexity</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07498">PDF</a><br/><b>Abstract: </b>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is
the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)|
\leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate
degree of the element distinctness function, the surjectivity function, and the
permutation testing problem, showing they are $\Theta(n^{2/3}
\log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and
$\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these
bounds were known only for constant $\epsilon.$
</p>
<p>We also derive a connection between vanishing-error approximate degree and
quantum Merlin--Arthur (QMA) query complexity. We use this connection to show
that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This
improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson
(Quantum Information &amp; Computation, 2012), and comes somewhat close to matching
a known upper bound of $O(n^{1/3})$.
</p></div>
    </summary>
    <updated>2019-09-18T23:21:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07446</id>
    <link href="http://arxiv.org/abs/1909.07446" rel="alternate" type="text/html"/>
    <title>Three-in-a-Tree in Near Linear Time</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kai-Yuan Lai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Hsueh=I.html">Hsueh-I Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07446">PDF</a><br/><b>Abstract: </b>The three-in-a-tree problem is to determine if a simple undirected graph
contains an induced subgraph which is a tree connecting three given vertices.
Based on a beautiful characterization that is proved in more than twenty pages,
Chudnovsky and Seymour [Com-binatorica 2010] gave the previously only known
polynomial-time algorithm, running in $O(mn^2)$ time, to solve the
three-in-a-tree problem on an $n$-vertex $m$-edge graph. Their three-in-a-tree
algorithm has become a critical subroutine in several state-of-the-art graph
recognition and detection algorithms.
</p>
<p>In this paper we solve the three-in-a-tree problem in $\tilde{O}(m)$ time,
leading to improved algorithms for recognizing perfect graphs and detecting
thetas, pyramids, beetles, and odd and even holes. Our result is based on a new
and more constructive characterization than that of Chudnovsky and Seymour. Our
new characterization is stronger than the original, and our proof implies a new
simpler proof for the original characterization. The improved characterization
gains the first factor $n$ in speed. The remaining improvement is based on
dynamic graph algorithms.
</p></div>
    </summary>
    <updated>2019-09-18T23:22:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07420</id>
    <link href="http://arxiv.org/abs/1909.07420" rel="alternate" type="text/html"/>
    <title>Regular Partitions and Their Use in Structural Pattern Recognition</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fiorucci:Marco.html">Marco Fiorucci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07420">PDF</a><br/><b>Abstract: </b>Recent years are characterized by an unprecedented quantity of available
network data which are produced at an astonishing rate by an heterogeneous
variety of interconnected sensors and devices. This high-throughput generation
calls for the development of new effective methods to store, retrieve,
understand and process massive network data. In this thesis, we tackle this
challenge by introducing a framework to summarize large graphs based on
Szemer\'edi's Regularity Remma (RL), which roughly states that any sufficiently
large graph can almost entirely be partitioned into a bounded number of
random-like bipartite graphs. The partition resulting from the RL gives rise to
a summary, which inherits many of the essential structural properties of the
original graph. We first extend an heuristic version of the RL to improve its
efficiency and its robustness. We use the proposed algorithm to address
graph-based clustering and image segmentation tasks. In the second part of the
thesis, we introduce a new heuristic algorithm which is characterized by an
improvement of the summary quality both in terms of reconstruction error and of
noise filtering. We use the proposed heuristic to address the graph search
problem defined under a similarity measure. Finally, we study the linkage among
the regularity lemma, the stochastic block model and the minimum description
length. This study provide us a principled way to develop a graph decomposition
algorithm based on stochastic block model which is fitted using likelihood
maximization.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07413</id>
    <link href="http://arxiv.org/abs/1909.07413" rel="alternate" type="text/html"/>
    <title>On Decoding Cohen-Haeupler-Schulman Tree Codes</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Anand_Kumar.html">Anand Kumar Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weidner:Matthew.html">Matthew Weidner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07413">PDF</a><br/><b>Abstract: </b>Tree codes, introduced by Schulman, are combinatorial structures essential to
coding for interactive communication. An infinite family of tree codes with
both rate and distance bounded by positive constants is called asymptotically
good. Rate being constant is equivalent to the alphabet size being constant.
Schulman proved that there are asymptotically good tree code families using the
Lovasz local lemma, yet their explicit construction remains an outstanding open
problem. In a major breakthrough, Cohen, Haeupler and Schulman constructed
explicit tree code families with constant distance, but over an alphabet
polylogarithmic in the length. Our main result is a randomized polynomial time
decoding algorithm for these codes making novel use of the polynomial method.
The number of errors corrected scales roughly as the block length to the
three-fourths power, falling short of the constant fraction error correction
guaranteed by the constant distance. We further present number theoretic
variants of Cohen-Haeupler-Schulman codes, all correcting a constant fraction
of errors with polylogarithmic alphabet size. Towards efficiently correcting
close to a constant fraction of errors, we propose a speculative convex
optimization approach inspired by compressed sensing.
</p></div>
    </summary>
    <updated>2019-09-18T23:20:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.09527</id>
    <link href="http://arxiv.org/abs/1901.09527" rel="alternate" type="text/html"/>
    <title>Envy-free Matchings in Bipartite Graphs and their Applications to Fair Division</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aigner=Horev:Elad.html">Elad Aigner-Horev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Segal=Halevi:Erel.html">Erel Segal-Halevi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.09527">PDF</a><br/><b>Abstract: </b>A matching in a bipartite graph $G:=(X + Y,E)$ is said to be envy-free if no
unmatched vertex in $X$ is adjacent to a mathced vertex in $Y$. Every perfect
matching is envy-free, but envy-free matchings may exist even when perfect
matchings do not.
</p>
<p>We provide a polynomial-time algorithm for finding an envy-free matching of
maximum cardinality. For edge-weighted bipartite graphs, we provide a
polynomial-time algorithm for finding a maximum-cardinality envy-free matching
of minimum weight.
</p>
<p>We show how envy-free matchings can be used in various fair division problems
with either continuous resources (``cakes'') or discrete ones. In particular,
we show a symmetric algorithm for proportional cake-cutting, and an algorithm
for $1$-out-of-$(2n-2)$ maximin-share allocation of discrete objects among $n$
agents.
</p></div>
    </summary>
    <updated>2019-09-18T23:24:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/125</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/125" rel="alternate" type="text/html"/>
    <title>TR19-125 |  Hardness Amplification of Optimization Problems 	 | 

	Elazar Goldenberg, 

	Karthik  C. S.</title>
    <summary>In this paper, we prove a general hardness amplification scheme for optimization problems based on the technique of direct products.
  
We say that an optimization problem $\Pi$ is direct product feasible if it is possible to efficiently aggregate any $k$ instances of $\Pi$ and form one large instance of $\Pi$ such that given an optimal feasible solution to the larger instance, we can efficiently find optimal feasible solutions to all the $k$ smaller instances. Given a direct product feasible optimization problem $\Pi$, our hardness amplification theorem may be informally stated as follows:
  
If there is a distribution $\mathcal{D}$ over instances of $\Pi$ of size $n$ such that every randomized algorithm running in time $t(n)$ fails to solve $\Pi$ on $\frac{1}{\alpha(n)}$ fraction of inputs sampled from $\mathcal{D}$, then, assuming some relationships on $\alpha(n)$ and $t(n)$, there is a distribution $\mathcal{D}'$ over instances of $\Pi$ of size $O(n\cdot \alpha(n))$ such that every randomized algorithm running in time $\frac{t(n)}{poly(\alpha(n))}$ fails to solve $\Pi$ on $\frac{99}{100}$ fraction of inputs sampled from $\mathcal{D}'$.
  
As a consequence of the above theorem, we show hardness amplification of problems in various classes such as NP-hard problems like Max-Clique, Knapsack, and Max-SAT, problems in P such as Longest Common Subsequence, Edit Distance, Matrix Multiplication, and even problems in TFNP such as Factoring and computing Nash equilibrium.</summary>
    <updated>2019-09-17T23:59:55Z</updated>
    <published>2019-09-17T23:59:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/124</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/124" rel="alternate" type="text/html"/>
    <title>TR19-124 |  Testing Odd Direct Sums Using High Dimensional Expanders | 

	Roy Gotlib, 

	Tali Kaufman</title>
    <summary>In this work, using methods from high dimensional expansion, we show that the property of $k$-direct-sum is testable for odd values of $k$ . Previous work of Kaufman and Lubotzky could inherently deal only with the case that $k$ is even, using a reduction to linearity testing.
Interestingly, our work is the first to combine the topological notion of high dimensional expansion (called co-systolic expansion) with the combinatorial/spectral notion of high dimensional expansion (called colorful expansion) to obtain the result.

The classical $k$-direct-sum problem applies to the complete complex; Namely it considers a function defined over all $k$-subsets of some $n$ sized universe. Our result here applies to any collection of $k$-subsets of an $n$-universe, assuming this collection of subsets forms a high dimensional expander.</summary>
    <updated>2019-09-17T00:04:22Z</updated>
    <published>2019-09-17T00:04:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/123</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/123" rel="alternate" type="text/html"/>
    <title>TR19-123 |  On the Hardness of Robust Classification | 

	Pascale Gourdeau, 

	Varun Kanade, 

	Marta Kwiatkowska, 

	James Worrell</title>
    <summary>It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show moreover that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\omega(\log n)$ input bits. However if the adversary is restricted to perturbing $O(\log n)$ bits, then the class of monotone conjunctions can be robustly learned with respect to a general class of distributions (that includes the uniform distribution). Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on another computational model (e.g. the statistical query model) nor on any hardness assumption other than the existence of a hard learning problem in the PAC framework.</summary>
    <updated>2019-09-17T00:00:40Z</updated>
    <published>2019-09-17T00:00:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/122</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/122" rel="alternate" type="text/html"/>
    <title>TR19-122 |  LDPC Codes Achieve List-Decoding Capacity | 

	Jonathan Mosheiff, 

	Nicolas Resch, 

	Noga Ron-Zewi, 

	Shashwat Silas, 

	Mary Wootters</title>
    <summary>We show that Gallager's ensemble of Low-Density Parity Check (LDPC) codes achieve list-decoding capacity. These are the first graph-based codes shown to have this property. Previously, the only codes known to achieve list-decoding capacity were completely random codes, random linear codes, and codes constructed by algebraic (rather than combinatorial) techniques. This result opens up a potential avenue towards truly linear-time list-decodable codes which achieve list-decoding capacity.

Our result on list decoding follows from a much more general result: any local property satisfied with high probability by a random linear code is also satisfied with high probability by a random LDPC code from Gallager's distribution. Local properties are properties characterized by the exclusion of small sets of codewords, and include list-decoding, list-recovery and average-radius list-decoding. Along the way, we give a characterization of sets of codewords that are likely to appear in a random linear code, which may be of independent interest.</summary>
    <updated>2019-09-16T23:58:26Z</updated>
    <published>2019-09-16T23:58:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/121</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/121" rel="alternate" type="text/html"/>
    <title>TR19-121 |  Vanishing-Error Approximate Degree and QMA Complexity | 

	Justin Thaler, 

	Alexander A. Sherstov</title>
    <summary>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)| \leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate degree of the element distinctness function, the surjectivity function, and the permutation testing problem, showing they are $\Theta(n^{2/3} \log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and  $\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these bounds were known only for constant $\epsilon.$ 

We also derive a connection between vanishing-error approximate degree and quantum Merlin--Arthur (QMA) query complexity. We use this connection to show that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson (Quantum Information &amp; Computation, 2012), and comes somewhat close to matching a known upper bound of $O(n^{1/3})$.</summary>
    <updated>2019-09-16T23:55:59Z</updated>
    <published>2019-09-16T23:55:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16239</id>
    <link href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/" rel="alternate" type="text/html"/>
    <title>Separating Words: Decoding a Paper</title>
    <summary>A clever trick on combining automata John Robson has worked on various problems including what is still the best result on separating words—the topic we discussed the other day. Ken first knew him for his proof than checkers is -complete and similar hardness results for chess and Go. Today I want to talk about his […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A clever trick on combining automata</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/unknown-128/" rel="attachment wp-att-16242"><img alt="" class="alignright  wp-image-16242" src="https://rjlipton.files.wordpress.com/2019/09/unknown-2.jpeg?w=190" width="190"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
John Robson has worked on various problems including what is still the best result on separating words—the topic we discussed the other <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">day</a>. Ken first knew him for his <a href="https://epubs.siam.org/doi/10.1137/0213018">proof</a> than <img alt="{N \times N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N \times N}"/> checkers is <img alt="{\mathsf{EXPTIME}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BEXPTIME%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{EXPTIME}}"/>-complete and similar hardness results for chess and Go.</p>
<p>
Today I want to talk about his theorem that any two words can be separated by an automaton with relataivley few states.</p>
<p>
In his famous paper from 1989, he proved an upper bound on the <i>Separating Word Problem</i>. This is the question: Given two strings <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, how many states does a deterministic automaton need to be able to accept <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and reject <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>? His theorem is:</p>
<blockquote><p><b>Theorem 1 (Robson’s Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{O(n^{0.4}\log^{0.6} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B0.4%7D%5Clog%5E%7B0.6%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{0.4}\log^{0.6} n)}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
The story of his result is involved. For starters, it is still the best upper bound after almost three decades. Impressive. Another issue is that a web search does not quickly, at least for for me, find a PDF of the original paper. I tried to find it and could not. More recent papers on the separating word problem reference his 1989 paper, but they do not explain how he proves it. </p>
<p>
Recall the problem of separating words is: Given two distinct words of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, is there a deterministic finite automaton that accepts one and rejects the other? And the machine has as few states as possible. Thus his theorem shows that roughly the number of states grows at most like the square root of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. </p>
<p>
I did finally track the paper down. The trouble for me is the paper is encrypted. Well not exactly, but the version I did find is a poor copy of the original. Here is an example to show what I mean:</p>
<p/><p/>
<p>&lt;/tr</p><table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/r/" rel="attachment wp-att-16248"><img alt="" class="aligncenter size-medium wp-image-16248" height="137" src="https://rjlipton.files.wordpress.com/2019/09/r.png?w=300&amp;h=137" width="300"/></a>
</td>

</tr><tr>
<td class="caption alignright"><font size="-2">[ An Example ]</font>
</td>
</tr>
</tbody></table>
<p>
So the task of decoding the proof is a challenge. A challenge, but a rewarding one.</p>
<p>
</p><p/><h2> A Cool Trick </h2><p/>
<p/><p>
Robson’s proof uses two insights. The first is he uses some basic <a href="http://www.stringology.org">string-ology</a>. That is he uses some basic facts about strings. For example he uses that a non-periodic string cannot overlap itself too much.</p>
<p>
He also uses a clever trick on how to simulate two deterministic machines for the price of one. This in general is not possible, and is related to deep questions about automata that we have discussed before <a href="https://rjlipton.wordpress.com/2012/11/08/the-power-of-guessing/">here</a>. Robson shows that it can be done in a special but important case.</p>
<p>
Let me explain. Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a string. We can easily design an automaton that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> if and only if <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. The machine will have order the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> states. So far quite simple. </p>
<p>
Now suppose that we have a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and wish to find a particular occurrence of the pattern <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. We assume that there are <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. The task is to construct an automaton that accepts at the end of the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Robson shows that this can be done by a automaton that has order 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) + |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) + |\alpha| "/></p>
<p>Here <img alt="{|\alpha|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Calpha%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\alpha|}"/> is the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>.</p>
<p>
This is a simple, clever, and quite useful observation. Clever indeed. The obvious automaton that can do this would seem to require a cartesian product of two machines. This would imply that it would require 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) \times |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%5Ctimes+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) \times |\alpha| "/></p>
<p>number of states: Note the times operator <img alt="{\times}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctimes%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\times}"/> rather than addition. Thus Robson’s trick is a huge improvement.</p>
<p>
Here is how he does this.</p>
<p>
</p><p/><h2> His Trick </h2><p/>
<p/><p>
Robson’s uses a clever trick in his proof of the main lemma. Let’s work through an example with the string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. The goal is to see if there is a copy of this string starting at a position that is a multiple of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>.</p>
<p>
The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to find the correct string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/> as input. If it does, then it reaches the accepting state <img alt="{(3,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,Y)}"/>. If while doing this it gets a wrong input, then it switches to states that have stopped looking for the input <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. After seeing three inputs the machine reaches <img alt="{(3,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,N)}"/> and then moves back to the start state. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/rfig/" rel="attachment wp-att-16249"><img alt="" class="aligncenter  wp-image-16249" src="https://rjlipton.files.wordpress.com/2019/09/rfig.png?w=500" width="500"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ The automaton  ]</font>
</td>
</tr>
</tbody></table>
<p/><h2> The Lemmas </h2><p/>
<p>We will now outline the proof in some detail.</p>
<p>
</p><p/><h3> Hashing </h3><p/>
<p/><p>
The first lemma is a simple fact about hashing.</p>
<blockquote><p><b>Lemma 2</b> <em> Suppose <img alt="{1 \le r \le m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+r+%5Cle+m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \le r \le m}"/> and 	</em></p><em>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Then all but <img alt="{{O}(m \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m+%5Clog+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(m \log n)}"/> primes satisfy 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+%5Ctext%7B+if+and+only+if+%7D+i+%3Dr.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Consider the quantity <img alt="{|k_{r} - k_{i}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Ck_%7Br%7D+-+k_%7Bi%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|k_{r} - k_{i}|}"/> for <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> not equal to <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. Call a prime <i>bad</i> if it divides this quantity. This quantity can be divisible by at most <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> primes. So there are at most <img alt="{{O}(m\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{O}(m\log n)}"/> bad primes in total. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Strings </h3><p/>
<p/><p>
We need some definitions about strings. Let <img alt="{| \alpha |}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Calpha+%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{| \alpha |}"/> be the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Also let <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> be the number of occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the <i>period</i> <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> provided 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+p}, "/></p>
<p>for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> so that <img alt="{i+p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i+p}"/> is defined. A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is <i>periodic</i> provided it has a period <img alt="{p&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;0}"/> that is less than half its length. Note, the shorter the period the more the string is really “periodic”: for example, the string 	</p>
<p align="center"><img alt="\displaystyle  10101010101010 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10101010101010+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10101010101010 "/></p>
<p>is more “periodic” than 	</p>
<p align="center"><img alt="\displaystyle  10000001000000. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10000001000000.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10000001000000. "/></p>
<blockquote><p><b>Lemma 3</b> <em> For any string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u}"/> either <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u0}"/> or <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u1}"/> is not periodic. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Suppose that <img alt="{\beta=u\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3Du%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta=u\sigma}"/> is periodic with period <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> where <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sigma}"/> is a single character. Let the length of <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> equal <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. So by definition, <img alt="{1 \le p \le l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+p+%5Cle+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le p \le l/2}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  \beta_{i} = \beta_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bi%7D+%3D+%5Cbeta_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{i} = \beta_{i+p}, "/></p>
<p>for <img alt="{1 \le i \le l-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+i+%5Cle+l-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le i \le l-p}"/>. So it follows that 	</p>
<p align="center"><img alt="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bl-p%7D+%3D+%5Cbeta_%7Bl%7D+%3D+%5Csigma.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. "/></p>
<p>This shows that <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> cannot both be periodic, since 	</p>
<p align="center"><img alt="\displaystyle  1 \le l-p \le l/2 &lt; l. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+l-p+%5Cle+l%2F2+%3C+l.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le l-p \le l/2 &lt; l. "/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 4</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not a periodic string. Then the number of copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is upper bounded by <img alt="{{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(M)}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \frac{|S|}{|\alpha|}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5Cfrac%7B%7CS%7C%7D%7B%7C%5Calpha%7C%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \frac{|S|}{|\alpha|}. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The claim follows once we prove that no two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> can overlap more than <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/> where <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/> is the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. This will immediately imply the lemma.</p>
<p>
If <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has two copies in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> that overlap then clearly 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+d}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bd%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+d}, "/></p>
<p>for some <img alt="{d&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d&gt;0}"/> and all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> in the range <img alt="{1,\dots,l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C%5Cdots%2Cl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,\dots,l-d}"/>. This says that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the period <img alt="{l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l-d}"/>. Since <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not periodic it follows that <img alt="{d &gt; l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%3E+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d &gt; l/2}"/>. This implies that the overlap of the two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> are at most length <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/>. Thus we have shown that they cannot overlap too much. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Main Lemma </h3><p/>
<p/><p>
Say an automaton <i>finds</i> the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> provided it enters a special state after scanning the last bit of this occurrence.</p>
<blockquote><p><b>Lemma 5</b> <em> Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> be a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string.Then, there is an automaton with at most <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> states that can find the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \#(S,\alpha) + |\alpha|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \#(S,\alpha) + |\alpha|. "/></p>
</em><p><em/>
</p></blockquote>
<p>Here <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> allows factors that are fixed powers of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. This lemma is the main insight of Robson and will be proved later.</p>
<p>
</p><p/><h2> The Main Theorem </h2><p/>
<p/><p>
The following is a slightly weaker version of Robson’s theorem. I am still confused a bit about his stronger theorem, to be honest. </p>
<blockquote><p><b>Theorem 6 (Robson’s Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Since <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> are distinct we can assume that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> starts with the prefix <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> starts with the prefix <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> for some string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/>. If the length of <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is less than order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> the theorem is trivial. Just construct an automaton that accepts <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and rejects <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/>.</p>
<p>
So we can assume that <img alt="{u = w\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+w%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u = w\alpha}"/> for some strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> where the latter is order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> in length. By lemma we can assume that <img alt="{\alpha1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha1}"/> is not periodic. So by lemma we get that 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha1%29+%3D+%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). "/></p>
<p>Then by lemma we are done. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Proof of Main Lemma </h2><p/>
<p/><p>
<em>Proof:</em>  Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> have length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. Also let <img alt="{\#(S,\alpha) = m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29+%3D+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha) = m}"/>. By the overlap lemma it follows that <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bounded by <img alt="{\widetilde{O}(|S|/|\alpha|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%7CS%7C%2F%7C%5Calpha%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(|S|/|\alpha|)}"/>. </p>
<p>
Let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> occur at locations 	</p>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Suppose that we are to construct a machine that finds the <img alt="{r^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. By the hashing lemma there is a prime <img alt="{p=\widetilde{O}(m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3D%5Cwidetilde%7BO%7D%28m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p=\widetilde{O}(m)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p "/></p>
<p>if and only if <img alt="{i=r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3Dr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=r}"/>. Note we can also assume that <img alt="{p &gt; l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3E+l%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p &gt; l}"/>. </p>
<p>
Let’s argue the special case where <img alt="{k_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_{r}}"/> is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> modulo <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. If it is congruent to another value the same argument can be used. This follows by having the machine initially skip a fixed amount of the input and then do the same as in the congruent to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> case.</p>
<p>
The automaton has states <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> and <img alt="{(i,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,N)}"/> for <img alt="{i=0,\dots,p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3D0%2C%5Cdots%2Cp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=0,\dots,p}"/>. The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to get to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>. The transitions include: 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CY%29+%5Cunderset%7B%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CY%29+%5Cunderset%7B%5Calpha_%7B3%7D%7D%7B%5Crightarrow%7D+%5Ccdots+%5Cunderset%7B%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CY%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). "/></p>
<p>This means that the machine keeps checking the input to see if it is scanning a copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. If it gets all the way to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>, then it stops.</p>
<p>
Further transitions are: 	</p>
<p align="center"><img alt="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%281%2CN%29+%5Crightarrow+%282%2CN%29+%5Crightarrow+%5Ccdots+%5Crightarrow+%28p%2CN%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), "/></p>
<p>and 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CN%29%2C+%281%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CN%29%2C+%5Cdots%2C+%28l-1%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CN%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). "/></p>
<p>The second group means that if a wrong input happens, then <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> moves to <img alt="{(i+1,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2B1%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i+1,N)}"/>. Finally, the state <img alt="{(p,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28p%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(p,N)}"/> resets and starts the search again by going to the start state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> with an epsilon move.</p>
<p>
Clearly this has the required number of states and it operates correctly. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The open problem is: Can the SWP be solved with a better bound? The lower bound is still order <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. So the gap is exponential. </p></font></font></div>
    </content>
    <updated>2019-09-16T21:26:18Z</updated>
    <published>2019-09-16T21:26:18Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="automaton"/>
    <category term="deterministic"/>
    <category term="separating words"/>
    <category term="strings"/>
    <category term="trick"/>
    <category term="words"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-09-19T00:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18035</id>
    <link href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/" rel="alternate" type="text/html"/>
    <title>Alef’s corner: Bicycles and the Art of  Planar Random Maps</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The artist behind Alef’s corner has a few mathematical designs and here are two new ones. (See Alef’s  website offering over 100 T-shirt designs.)   which was used for the official T-shirt for Jean-François Le Gall’s birthday conference. See also … <a href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The artist behind <a href="https://gilkalai.wordpress.com/?s=alef">Alef’s corner</a> has a few mathematical designs and here are two new ones. (See Alef’s  <a href="https://tembelone.com/?fbclid=IwAR27VIu9gIgfgTWSYu88Xz1H9GneVoZsLZb1sw6jQ6IiE9w7cFo0jlISUas">website offering over 100 T-shirt designs</a>.)</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/legal.png"><img alt="" class="alignnone size-full wp-image-18040" height="529" src="https://gilkalai.files.wordpress.com/2019/09/legal.png?w=640&amp;h=529" width="640"/></a></p>
<p>which was used for the official T-shirt for Jean-François Le Gall’s <a href="https://www.math.u-psud.fr/~jf60/">birthday conference</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg"><img alt="" class="alignnone size-full wp-image-18041" src="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/curien.png"><img alt="" class="alignnone size-full wp-image-18036" src="https://gilkalai.files.wordpress.com/2019/09/curien.png?w=640"/></a></p>
<p>See also <a href="https://www.quantamagazine.org/random-surfaces-hide-an-intricate-order-20190702/">this quanta magazine article</a> by Kevin Hartness.</p></div>
    </content>
    <updated>2019-09-16T21:23:03Z</updated>
    <published>2019-09-16T21:23:03Z</published>
    <category term="Art"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Probability"/>
    <category term="Alef's corner"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-09-19T00:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6037506695705789893</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6037506695705789893/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html" rel="alternate" type="text/html"/>
    <title>this paper from 2015 cracks Diffie-Hellman. What to tell the students?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am teaching cryptography this semester for the second time (I taught it in Fall 2019) and will soon tell the students about the paper from 2015:<br/>
<a href="https://weakdh.org/imperfect-forward-secrecy.pdf">Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice</a>. There are 14 authors.<br/>
<br/>
The upshot is that as Diffie-Hellman was implemented in 2015, many cases were crackable. In summary (and probably too simple):<br/>
<br/>
DH in a 512-bit group can be cracked by the authors<br/>
<br/>
DH in a 1024-bit group they speculate can be cracked with nation-state resources. <br/>
<br/>
<br/>
<br/>
Is this a big deal? If YES then what is being done, and if NOT then why not?<br/>
<br/>
I have come up with some statements that I DO NOT KNOW if they are true, but I am ASKING you, to shed some light on the BIG DEAL or NO BIG DEAL question. (Note- Idea for a game show: BIG DEAL or NO BIG DEAL where contestants are asked if a news story is a BIG DEAL or not.)<br/>
<br/>
So, please comment on the following question:<br/>
<br/>
1) Since 2015 the people who use DH have upped their game and are now using bigger parameters. (I doubt this is true)<br/>
<br/>
2) DH is mostly not used on things that hackers are not interested in, so this is not a big deal.<br/>
<br/>
3) The expertise required to crack DH via this paper is rather difficult, so hackers don't have the skills.<br/>
<br/>
4) This paper is not a problem for a bad reason: Hackers don't need to  use the number field sieve DL algorithm when all they need to do is (1) guess that the pin numer is 1234 or the year the user was born (or close to it), (2) put on a uniform from Geek-Squad or some such organization and claim they are here to help, (3) exploit a known security flaw that the company has not bothered fixing.  <br/>
<br/>
5) The 14 authors have mysteriously disappeared. (I doubt this is true.)<br/>
<br/>
<br/>
(Misc: My spell checker thinks that Diffie and crackable are not words, but Hellman is.)</div>
    </content>
    <updated>2019-09-16T13:10:00Z</updated>
    <published>2019-09-16T13:10:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-18T23:54:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/" rel="alternate" type="text/html"/>
    <title>faculty at University of Sydney (apply by November 15, 2019)</title>
    <summary>Multiple continuing positions in the School Computer Science at the University of Sydney Website: https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1 Email: joachim.gudmundsson@sydney.edu.au</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple continuing positions in the School Computer Science at the University of Sydney</p>
<p>Website: <a href="https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1">https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1</a><br/>
Email: joachim.gudmundsson@sydney.edu.au</p></div>
    </content>
    <updated>2019-09-16T11:34:31Z</updated>
    <published>2019-09-16T11:34:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-19T00:20:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/09/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/09/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Lee Bollinger, president of Columbia University: “No, I won’t start spying on my foreign-born students” ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.washingtonpost.com/opinions/no-i-wont-start-spying-on-my-foreign-born-students/2019/08/29/01c80e84-c9b2-11e9-a1fe-ca46e8d573c0_story.html">Lee Bollinger, president of Columbia University: “No, I won’t start spying on my foreign-born students”</a> (<a href="https://mathstodon.xyz/@11011110/102718751083310854"/>).</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/08/30/update-on-the-safe-toc-initiative-guest-post-by-sandy-irani/">Update on the Safe ToC initiative</a> (<a href="https://mathstodon.xyz/@11011110/102725927728134229"/>). Sandy Irani describes progress in combatting harassment and discrimination at theoretical computer science conferences, and calls for volunteer advocates to serve as contact points at conferences.</p>
  </li>
  <li>
    <p><a href="http://isohedral.ca/escher-like-spiral-tilings/">Escher-like spiral tilings, by Craig Kaplan</a> (<a href="https://mathstodon.xyz/@11011110/102732614495435403"/>, <a href="https://news.ycombinator.com/item?id=20854644">via</a>). Sadly with no angels, devils, fish, or geese, but maybe some talented artist will take up that challenge.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00263">How to peel self-intersecting onions</a> (<a href="https://mathstodon.xyz/@jeffgerickson/102734672335961160"/>). Gabriel Nivasch extends the <a href="https://11011110.github.io/blog/2017/10/11/peeling-vs-shortening.html">conjectured equivalence</a> between <a href="https://en.wikipedia.org/wiki/Convex_layers">convex layers</a> and the <a href="https://en.wikipedia.org/wiki/Curve-shortening_flow#Related_flows">affine curve-shortening flow</a> to non-convex and self-intersecting curves. The generalized onion-peeling process alternates between steps that jump over grid points and steps that shrink curves to the shortest curve that passes between the same grid points. See also Gabriel’s animations of this process for <a href="https://mathstodon.xyz/@gnivasch/102741204463574303">grid points</a> and for <a href="https://mathstodon.xyz/@gnivasch/102753301344471044">random points</a>.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00917">New stick number bounds from random sampling of confined polygons</a> (<a href="https://mathstodon.xyz/@shonk/102742716819892997"/>). Tom Eddy and Clayton Shonkwiler do knot theory on large numbers of random 3d polygons, in the process finding polygonal representations of many knots with fewer segments than were known before.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/2019/09/42-is-the-answer-to-the-question-what-is-80538738812075974%c2%b3-80435758145817515%c2%b3-12602123297335631%c2%b3/">42 is the answer</a>. The question is: What is ?</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1177/2378023118823946">Who Counts as a Notable Sociologist on Wikipedia? Gender, Race, and the “Professor Test”</a> (<a href="https://mathstodon.xyz/@11011110/102755324164533099"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-08-30/Recent_research">via</a>). After authors Adams, Brückner, and Naslund factored out seniority and impact of sociologists, white men remained more likely than others to have Wikipedia articles. Surprisingly to me, the disparity happens at article creation, not deletion. So we should create more articles about women! Or be less quick to create them on borderline-notable men…</p>
  </li>
  <li>
    <p><a href="https://www.flickr.com/photos/132410114@N04/24230683269/">Permutations in the real world: 12784563</a> (<a href="https://mathstodon.xyz/@11011110/102763393307640430"/>). Actually I have sentimental reasons to prefer 15426378, but I couldn’t find a nice photo of that one.</p>
  </li>
  <li>
    <p><a href="https://simon.lc/the-history-of-tetris-randomizers">The history of Tetris randomizers</a> (<a href="https://mathstodon.xyz/@11011110/102766825773116819"/>, <a href="https://www.metafilter.com/182935/let-piece-I-J-L-TMathfloorMathrandom-4">via</a>). Truly uniformly random distributions tend to be more clustered than people expect (having runs of the same piece or of mostly the same piece). So later versions took measures to make the piece distribution less random and more non-clustered.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1908.07097">An  lower bound for random universal sets for planar graphs</a> (<a href="https://mathstodon.xyz/@11011110/102771230722757397"/>). Random subsets of a square act like grids in lots of ways. Here’s one, from the linked preprint: to draw all -vertex planar graphs with chosen points as vertices, you need either a grid or a random point set of  points. The reason is that drawings of the nested triangles graph contain a sequence of  points (corners of bounding boxes of triangles) that’s monotone in both coordinate directions, and smaller random sets (or grids) don’t have such sequences.</p>
  </li>
  <li>
    <p><a href="https://codepen.io/collection/eErLu/">CSS polyhedra</a> (<a href="https://mathstodon.xyz/web/statuses/102775320989084287"/>). Visualizations of 3d rotating polyhedra, coded entirely in html/css and embeddable in other web pages.</p>
  </li>
  <li>
    <p><a href="https://www.maths.ox.ac.uk/node/30217">Random minimum spanning trees</a> (<a href="https://mathstodon.xyz/@11011110/102786143581334329"/>). Did you know that in random graphs with edge probability  (just below the appearance of the giant component) there are lots of components of size  that all look nearly the same as uniformly random spanning trees of a complete graph? And that the minimum spanning tree of a randomly-weighted complete graph, instead, looks like one of these components with a lot of others all glued onto it? Christina Goldschmidt describes her work in this area.</p>
  </li>
  <li>
    <p><a href="https://www.gwern.net/Turing-complete">A big list of unlikely or surprising Turing-complete systems</a> (<a href="https://mathstodon.xyz/@11011110/102789724968251958"/>, <a href="https://www.metafilter.com/183095/On-having-sufficient-complexity-to-allow-for-arbitrary-computation">via</a>). My favorite: <a href="https://github.com/tom-p-reichel/svg-is-turing-complete">SVG is Turing-complete</a> because it can be used to (slowly) simulate Rule 110 (and one hopes also simulate the weird boundary conditions needed to make Rule 110 Turing complete).</p>
  </li>
  <li>
    <p><a href="https://www.english.cam.ac.uk/cmt/?p=5751">Milton’s hand-annotated volume of Shakespeare’s plays discovered sitting on a library shelf in Philly</a> (<a href="https://mathstodon.xyz/@11011110/102791968928048975"/>, <a href="https://www.metafilter.com/183100/Miltons-Shakespeare">via</a>).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Vojt%C4%9Bch_Jarn%C3%ADk">Vojtěch Jarník, now a good article on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/102798710399112671"/>). I teach his algorithm for minimum spanning trees in my classes, but lately in my research I’ve been citing him more for his work on the number of integer grid points on convex curves. He also did important work on Diophantine approximation and nowhere-differentiable functions.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-09-15T17:51:00Z</updated>
    <published>2019-09-15T17:51:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-09-16T01:18:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/15/assistant-associate-professor-theory-at-university-of-massachusetts-amherst-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/15/assistant-associate-professor-theory-at-university-of-massachusetts-amherst-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Assistant/Associate Professor – Theory at University of Massachusetts, Amherst (apply by December 1, 2019)</title>
    <summary>An opening is available for an Assistant or Associate Professor in Theoretical Computer Science. Exceptional candidates at other ranks may be considered. As a campus with a continually growing diverse student body, we encourage applications from women, people of color, members of the LGBTQ community, and individuals with a commitment to mentoring individuals from underrepresented […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An opening is available for an Assistant or Associate Professor in Theoretical Computer Science. Exceptional candidates at other ranks may be considered. As a campus with a continually growing diverse student body, we encourage applications from women, people of color, members of the LGBTQ community, and individuals with a commitment to mentoring individuals from underrepresented groups in CS.</p>
<p>Website: <a href="http://careers.umass.edu/amherst/en-us/job/502778/assistantassociate-professortheory">http://careers.umass.edu/amherst/en-us/job/502778/assistantassociate-professortheory</a><br/>
Email: facrec@cs.umass.edu</p></div>
    </content>
    <updated>2019-09-15T16:28:12Z</updated>
    <published>2019-09-15T16:28:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-19T00:20:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/120</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/120" rel="alternate" type="text/html"/>
    <title>TR19-120 |  Toward Better Depth Lower Bounds: Two Results on the Multiplexor Relation | 

	Or Meir</title>
    <summary>One of the major open problems in complexity theory is proving super-logarithmic
lower bounds on the depth of circuits (i.e., $\mathbf{P}\not\subseteq\mathbf{NC}^1$). Karchmer, Raz, and Wigderson (Computational Complexity 5, 3/4) suggested to approach this problem by proving that depth complexity behaves "as expected" with respect to the composition of functions $f \diamond g$. They showed that the validity of this conjecture would imply that $\mathbf{P}\not\subseteq\mathbf{NC}^1$.

As a way to realize this program, Edmonds et. al. (Computational Complexity 10, 3) suggested to study the "multiplexor relation" $MUX$,  which is a simplification of functions. In this note, we present two results regarding this relation:

- The multiplexor relation is "complete" for the approach of Karchmer et. al.
in the following sense: if we could prove (a variant of) their conjecture
for the composition $f \diamond MUX$ for every function $f$, then this would
imply $\mathbf{P}\not\subseteq\mathbf{NC}^1$.

- A simpler proof of a lower bound for the multiplexor relation due
to Edmonds et. al. Our proof has the additional benefit of fitting
better with the machinery used in previous works on the subject.</summary>
    <updated>2019-09-15T14:52:07Z</updated>
    <published>2019-09-15T14:52:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/119</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/119" rel="alternate" type="text/html"/>
    <title>TR19-119 |  On Hitting-Set Generators for Polynomials that Vanish Rarely | 

	Dean Doron, 

	Amnon Ta-Shma, 

	Roei Tell</title>
    <summary>We study the following question: Is it easier to construct a hitting-set generator  for polynomials $p:\mathbb{F}^n\rightarrow\mathbb{F}$ of degree $d$ if we are guaranteed that the polynomial vanishes on at most an $\epsilon&gt;0$ fraction of its inputs? We will specifically be interested in tiny values of $\epsilon\ll d/|\mathbb{F}|$. This question was first asked by Goldreich and Wigderson (STOC 2014), who studied a specific setting geared for an application, and another specific setting was later studied by the third author (CCC 2017). 

In this work our main interest is a *systematic study of the problem itself*, in its general form, and we prove results that significantly extend and improve the two previously-known results. Our contributions are of two types:

1. Over fields of size $2\le|\mathbb{F}|\le poly(n)$, we show that the seed length of any hitting-set generator for polynomials of degree $d\le n^{.49}$ that vanish on at most $\epsilon=|\mathbb{F}|^{-t}$ of their inputs is at least $\Omega\left((d/t)\cdot\log(n)\right)$.

2. Over $\mathbb{F}_2$, we show that there exists a (non-explicit) hitting-set generator for polynomials of degree $d\le n^{.99}$ that vanish on at most $\epsilon=|\mathbb{F}|^{-t}$ of their inputs with seed length $O\left((d-t)\cdot\log(n)\right)$. We also show a polynomial-time computable hitting-set generator with seed length $O\left( (d-t)\cdot\left(2^{d-t}+\log(n)\right) \right)$.

In addition, we prove that the problem we study is closely related to the following question: ``Does there exist a small set $S\subseteq\mathbb{F}^n$ whose degree-$d$ closure is very large?'', where the degree-$d$ closure of $S$ is the variety induced by the set of degree-$d$ polynomials that vanish on $S$. We then use our lower bounds on hitting-sets for polynomials that vanish rarely to deduce lower bounds for this question.</summary>
    <updated>2019-09-15T14:51:52Z</updated>
    <published>2019-09-15T14:51:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/118</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/118" rel="alternate" type="text/html"/>
    <title>TR19-118 |  Hardness Magnification for all Sparse NP Languages | 

	Lijie Chen, 

	Ce Jin, 

	Ryan Williams</title>
    <summary>In the Minimum Circuit Size Problem (MCSP[s(m)]), we ask if there is a circuit of size s(m) computing a given truth-table of length n = 2^m. Recently, a surprising phenomenon termed as hardness magnification by [Oliveira and Santhanam, FOCS 2018] was discovered for MCSP[s(m)] and the related problem MKtP of computing time-bounded Kolmogorov complexity. In [Oliveira and Santhanam, FOCS 2018], [Oliveira, Pich, and Santhanam, CCC 2019], and [McKay, Murray, and Williams, STOC 2019], it was shown that minor (n^{1+eps}-style) lower bounds for MCSP[2^o(m)] or MKtP[2^o(m)] would imply breakthrough circuit lower bounds such as NP is not in P/poly, NP is not in NC^1, or EXP is not in P/poly.
		
We consider the question: What is so special about MCSP and MKtP? Why do they admit this striking phenomenon? One simple property is that all variants of MCSP (and MKtP) considered in prior work are sparse languages. For example, MCSP[s(m)] has 2^{O(s(m))} yes-instances of length n=2^m, so MCSP[2^o(m)] is 2^{n^o(1)}-sparse. 
		
We show that there is a hardness magnification phenomenon for all equally-sparse NP languages. Formally, suppose there is an eps &gt; 0 and a language L in NP which is 2^{n^o(1)}-sparse, and L is not in Circuit[n^{1+eps}]. Then NP does not have n^k-size circuits for all k. We prove analogous theorems for De Morgan formulas, B_2-formulas, branching programs, AC^0[6] and TC^0 circuits, and more: improving the state of the art in NP lower bounds against any of these models by an eps factor in the exponent would already imply NP lower bounds for all fixed polynomials. In fact, in our proofs it is not necessary to prove a (say) n^{1+eps} circuit size lower bound for L: one only has to prove a lower bound against n^{1+eps}-time n^eps-space deterministic algorithms with n^eps advice bits. Such lower bounds are well-known for non-sparse problems.        
		
Building on our techniques, we also show interesting new hardness magnifications for search-MCSP and search-MKtP (where one must output small circuits or short representations of strings), showing consequences such as Parity-P (or PP, PSPACE, and EXP) is not contained in P/poly (or NC^1, AC^0[6], or branching programs of polynomial size). For instance, if there is an eps &gt; 0 such that search-MCSP[2^{beta m}] does not have De Morgan formulas of size n^{3+eps} for all constants beta &gt; 0, then Parity-P is not in NC^1.</summary>
    <updated>2019-09-15T14:51:37Z</updated>
    <published>2019-09-15T14:51:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=667</id>
    <link href="https://emanueleviola.wordpress.com/2019/09/12/those-who-sold-their-town-to-the-marijuana-industry-now-worry-about-vaping/" rel="alternate" type="text/html"/>
    <title>Those who sold their town to the marijuana industry now worry about vaping</title>
    <summary>Below is a statement from the same administration which rigged elections to sell their town to the marijuana industry.  The latter spent more than $300,000 to win the rigged election, see expense report, a figure that does not include money spent on attorneys to lobby the administration.  In less than a month Newton residents will […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Below is a statement from the same administration which <a href="https://emanueleviola.wordpress.com/tag/marijuana/">rigged elections to sell their town to the marijuana industry</a>.  The latter spent more than $300,000 to win the rigged election, see <a href="http://www.newtonma.gov/civicax/filebank/documents/95997">expense report</a>, a figure that does not include money spent on attorneys to lobby the administration.  In less than a month Newton residents will have their chance to hold the administration accountable.</div>
<div/>
<div>————————————</div>
<div/>
<div><strong>A multi-state outbreak of severe pulmonary disease associated with e-cigarette and marijuana vaping devices has struck.  […] Some contained nicotine and others contained marijuana or related substances.</strong></div>
<div/>
<div><strong>Newton Health and Human Services strongly urges residents to consider not using any e-cigarette or vaping products at this time.</strong></div></div>
    </content>
    <updated>2019-09-12T13:57:53Z</updated>
    <published>2019-09-12T13:57:53Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-09-19T00:21:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=363</id>
    <link href="https://tcsplus.wordpress.com/2019/09/11/the-fall-season-of-tcs-is-upon-us/" rel="alternate" type="text/html"/>
    <title>The Fall season of TCS+ is upon us!</title>
    <summary>With the summer winding down, the Fall ’19 season of TCS+ is coming fast! We’re excited to bring to you, over the next few months, great speakers and amazing results, right into the comfort of your home institution (or home home, for that matter). As a teaser, here are the first three talks of the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>With the summer winding down, the Fall ’19 season of TCS+ is coming fast! We’re excited to bring to you, over the next few months, great speakers and amazing results, right into the comfort of your home institution (or home <em>home</em>, for that matter).</p>
<p>As a teaser, here are the first three talks of the season:</p>
<ul>
<li>
<ul>
<li><a href="http://web.stanford.edu/~msellke/main" rel="noopener" target="_blank">Mark Sellke</a> (Stanford) will tell us, on September 25th, about his recent work on <em>Chasing Convex Bodies.</em><em><br/>
</em></li>
<li><a href="https://cseweb.ucsd.edu/~slovett/" rel="noopener" target="_blank">Shachar Lovett</a> (UCSD) will on October 9th present his new results on the Sunflower Lemma.</li>
<li><a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> (Emory University) will talk on October 22nd <em>(note: a Tuesday)</em> about his recent proof of the Sensitivity Conjecture.</li>
</ul>
</li>
</ul>
<p>Stay tuned for those, and the following!</p></div>
    </content>
    <updated>2019-09-11T19:44:19Z</updated>
    <published>2019-09-11T19:44:19Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-09-19T00:21:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/117</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/117" rel="alternate" type="text/html"/>
    <title>TR19-117 |  Locally Testable Non-Malleable Codes | 

	Silas Richelson, 

	Sourya Roy</title>
    <summary>In this work we adapt the notion of non-malleability for codes or Dziembowski, Pietrzak and Wichs (ICS 2010) to locally testable codes. Roughly speaking, a locally testable code is non-malleable if any tampered codeword which passes the local test with good probability is close to a valid codeword which either encodes the original, or an unrelated message.
We instantiate our definition by proving that a Reed-Muller-type code is non-malleable in the following sense: any adversary who independently tampers the coordinates of the code so that the tampered code passes the test with good probability, is tampering the underlying polynomial according to an affine transformation.
To the best of our knowledge, prior to this work, polynomial codes were not known to possess any non-malleability guarantees. Our analysis builds on the sampler-based decoding techniques common to several recent works.</summary>
    <updated>2019-09-10T12:26:11Z</updated>
    <published>2019-09-10T12:26:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-4980143336209093039</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/4980143336209093039/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=4980143336209093039" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4980143336209093039" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4980143336209093039" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/09/a-new-analysis-of-adaptive-data-analysis.html" rel="alternate" type="text/html"/>
    <title>A New Analysis of "Adaptive Data Analysis"</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div style="text-align: center;"><i>This is a blog post about our new paper, which you can read here: </i><a href="https://arxiv.org/abs/1909.03577">https://arxiv.org/abs/1909.03577</a> </div><div style="text-align: center;"><br/></div>The most basic statistical estimation task is estimating the expected value of some predicate $q$ over a distribution $\mathcal{P}$: $\mathrm{E}_{x \sim \mathcal{P}}[q(x)]$, which I'll just write as $q(\mathcal{P})$. Think about estimating the mean of some feature in your data, or the error rate of a classifier that you have just trained.  There's a really obvious way to come up with a good estimate if you've got a dataset $S \sim \mathcal{P}^n$ of $n$ points that were sampled i.i.d. from the distribution: just use the empirical mean $a = \frac{1}{n}\sum_{i=1}^n q(S_i)$! In fact, this is a great way to estimate the values of a really large number of predicates, so long as they were chosen <i>non-adaptively</i>: that is, so long as you came up with all of the predicates you wanted to estimate before you estimated any of the answers. This phenomenon is, for example, what classical generalization theorems in machine learning rely on: the empirical error of a set of classifiers in some model class will be a good estimate of their actual, out-of-sample error, so long as your dataset is at least as large as the logarithm of your model class.<br/><div><br/></div><div>But this guarantee breaks down if the predicates that you want to estimate are chosen in sequence, adaptively. For example, suppose you are trying to fit a machine learning model to data. If you train your first model, estimate its error, and then as a result of the estimate tweak your model and estimate its error again, you are engaging in exactly this kind of adaptivity. If you repeat this many times (as you might when you are tuning hyper-parameters in your model) you could quickly get yourself into big trouble. Of course there is a simple way around this problem: just don't re-use your data. The most naive baseline that gives statistically valid answers is called "data splitting". If you want to test k models in sequence, just randomly partition your data into k equal sized parts, and test each model on a fresh part. The holdout method is just the special case of k = 2.  But this "naive" method doesn't make efficient use of data: its data requirements grow <i>linearly</i> with the number of models you want to estimate. </div><div><br/></div><div>It turns out its possible to do better by perturbing the empirical means with a little bit of noise before you use them: this is what we (Dwork, Feldman, Hardt, Pitassi, Reingold, and Roth --- DFHPRR) showed back in 2014 in <a href="https://arxiv.org/abs/1411.2664">this paper</a>, which helped kick off a small subfield known as "adaptive data analysis". In a nutshell, we proved a "transfer theorem" that says the following: if your statistical estimator is simultaneously <i>differentially private</i> and <i>sample accurate</i> --- meaning that with high probability it provides estimates that are close to the empirical means, then it will also be accurate out of sample. When paired with a simple differentially private mechanism for answering queries --- just perturbing their answers with Gaussian noise --- this gave a significant asymptotic improvement in data efficiency over the naive baseline! You can see how well it does in this figure (click to enlarge it): </div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s1600/DFHPRRonly.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="205" src="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s320/DFHPRRonly.png" width="320"/></a></div><div style="text-align: left;">Well... Hmm. In this figure, we are plotting how many adaptively chosen queries can be answered accurately as a function of dataset size. By "accurately" we have arbitrarily chosen to mean: answers that have confidence intervals of width 0.1 and uniform coverage probability 95%. On the x axis, we've plotted the dataset size n, ranging from 100,000 to about 12 million. And we've plotted two methods: the "naive" sample splitting baseline, and using the sophisticated Gaussian perturbation technique, as analyzed by the bound we proved in the "DFHPRR" paper. (Actually --- a numerically optimized variant of that bound!) You can see the problem. Even with a dataset size in the tens of millions, the sophisticated method does substantially worse than the naive method! You can extrapolate from the curve that the DFHPRR bound will <i>eventually</i> beat the naive bound, but it would require a truly enormous dataset. When I try extending the plot out that far my optimizer runs into numeric instability issues. </div><div style="text-align: left;"><br/></div><div style="text-align: left;">There has been improvement since then. In particular, DFHPRR didn't even obtain the best bound asymptotically. It is folklore that differentially private estimates generalize in expectation: the trickier part is to show that they enjoy <i>high probability</i> generalization bounds. This is what we showed in a sub-optimal way in DFHPRR. In 2015, a <a href="https://arxiv.org/abs/1511.02513">beautiful paper</a> by Bassily, Nissim, Steinke, Smith, Stemmer, and Ullman (BNSSSU) introduced the amazing "monitor technique" to obtain the asymptotically optimal high probability bound. An upshot of the bound was that the Gaussian mechanism can be used to answer roughly $k = n^2$ queries --- a quadratic improvement over the naive sample splitting mechanism! You can read about this technique in the lecture notes of the <a href="https://adaptivedataanalysis.com/">adaptive data analysis class</a> Adam Smith and I taught a few years back.  Lets see how it does (click to enlarge):</div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s1600/DFHPRRandBNSSSU.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="206" src="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s320/DFHPRRandBNSSSU.png" width="320"/></a></div><div style="text-align: left;">Substantially better! Now we're plotting n from 100,000 up to about only 1.7 million. At this scale, the DFHPRR bound appears to be constant (at essentially 0), whereas the BNSSSU bound clearly exhibits quadratic behavior. It even beats the baseline --- by a little bit, so long as your dataset has somewhat more than a million entries... I should add that what we're plotting here is again a numerically optimized variant of the BNSSSU bound, not the closed-form version from their paper. So maybe not yet a practical technique. The problem is that the monitor argument --- while brilliant --- seems unavoidably to lead to large constant overhead.  </div><div style="text-align: left;"><br/></div><div style="text-align: left;">Which brings us to our new work (this is joint work with Christopher Jung, Katrina Ligett, Seth Neel, Saeed Sharifi-Malvajerdi, and Moshe Shenfeld). We give a brand new proof of the transfer theorem. It is elementary, and in particular, obtains high probability generalization bounds directly from high probability sample-accuracy bounds, avoiding the need for the monitor argument. I think the proof is the most interesting part --- its simple and (I think) illuminating --- but an upshot is that we get <i>substantially</i> better bounds, even though the improvement is just in the constants (the existing BNSSSU bound is known to be asymptotically tight). Here's the plot with our bound included --- the x-axis is the same, but note the substantially scaled-up y axis (click to enlarge): </div><div style="text-align: left;"><br/></div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s1600/allthree.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s320/allthree.png" width="320"/></a></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><br/><b><u>Proof Sketch</u></b><br/>Ok: on to the proof. Here is the trick. In actuality, the dataset S is first sampled from $\mathcal{P}^n$, and then some data analyst interacts with a differentially private statistical estimator, resulting in some transcript $\pi$ of query answer pairs. But now imagine that <i>after the interaction is complete</i>, S is <i>resampled</i> from $Q_\pi = (\mathcal{P}^n)|\pi$, the posterior distribution on datasets conditioned on $\pi$. If you reflect on this for a moment, you'll notice that this resampling experiment doesn't change the joint distribution on dataset transcript pairs $(S,\pi)$ at all. So if the mechanism promised high probability sample accuracy bounds, it still promises them in this resampling experiment. But lets think about what that means: the mechanism can <i>first commit</i> to some set of answers $a_i$, and promise that with high probability, <i>after</i> S is resampled from $Q_\pi$, $|a_i - \frac{1}{n}\sum_{j=1}^n q_i(S_j)|$ is small. But under the resampling experiment, it is quite likely that the empirical value of the query $\frac{1}{n}\sum_{j=1}^n q_i(S_j)$ will end up being close to its expectation over the posterior: $q_i(Q_{\pi}) = \mathrm{E}_{S \sim Q_{\pi}}[\frac{1}{n}\sum_{j=1}^n q_i(S_j)]$. So the only way that a mechanism can promise high probability sample accuracy is if it actually promises high probability posterior accuracy: i.e. with high probability, for every query $q_i$ that was asked and answered, we must have that $|a_i - q_i(Q_\pi)|$ is small.<br/><br/>That part of the argument was generic --- it didn't use differential privacy at all! But it serves to focus attention on these posterior distributions $Q_\pi$ that our statistical estimator induces. And it turns out its not hard to see that the expected value of queries on posteriors induced by differentially private mechanisms have to be close to their true answers. For $(\epsilon,0)$-differential privacy, it follows almost immediately from the definition. Here is the derivation. Pick your favorite query $q$ and your favorite transcript $\pi$, and write $S_j \sim S$ to denote a uniformly randomly selected element of a dataset $S$:</div><div style="text-align: left;">$$q (Q_\pi) =  \sum_{x} q (x) \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x | \pi]= \sum_{x} q (x) \cdot \frac{\Pr [\pi | S_j = x ] \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x]}{\Pr[\pi]}$$<br/>$$\leq \sum_{x} q (x) \cdot \frac{e^\epsilon \Pr [\pi] \cdot \Pr_{S_j \sim \mathcal{P}} [S_j = x]}{\Pr[\pi]}<br/>= e^\epsilon \cdot q (\mathcal{P})$$<br/><br/>Here, the inequality follows from the definition of differential privacy, which controls the effect that fixing a single element of the dataset to any value $(S_j = x)$ can have on the probability of any transcript: it can increase it multiplicatively by a factor of at most $e^\epsilon$. </div><div style="text-align: left;"><br/>And thats it: So we must have that (with probability 1!), $|q(Q_\pi) - q(\mathcal{P})| \leq e^\epsilon-1 \approx \epsilon$. The transfer theorem then follows from the triangle inequality. We get a high probability bound for free, with no need for any heavy machinery.<br/><br/>The argument is just a little more delicate in the case of $(\epsilon,\delta)$-differential privacy, and can be extended beyond linear queries --- but I think this gives the basic idea. The details are in <a href="https://arxiv.org/abs/1909.03577">our new "JLNRSS" paper</a>. Incidentally, once nice thing about having many different proofs of the same theorem is that you can start to see some commonalities. One seems to be: it takes six authors to prove a transfer theorem!</div><div style="text-align: left;"><br/></div><div style="text-align: left;"><br/></div></div>
    </content>
    <updated>2019-09-10T10:40:00Z</updated>
    <published>2019-09-10T10:40:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-09-12T10:29:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4301</id>
    <link href="https://www.scottaaronson.com/blog/?p=4301" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4301#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4301" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Paul Bernays Lectures</title>
    <summary xml:lang="en-US">Last week, I had the honor of giving the annual Paul Bernays Lectures at ETH Zürich. My opening line: “as I look at the list of previous Bernays Lecturers—many of them Nobel physics laureates, Fields Medalists, etc.—I think to myself, how badly did you have to screw up this year in order to end up […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last week, I had the honor of giving the annual <a href="https://gess.ethz.ch/en/news-and-events/paul-bernays-lectures.html">Paul Bernays Lectures</a> at ETH Zürich.  My opening line: “as I look at the list of previous Bernays Lecturers—many of them Nobel physics laureates, Fields Medalists, etc.—I think to myself, how badly did you have to screw up this year in order to end up with me?”</p>



<p><a href="https://en.wikipedia.org/wiki/Paul_Bernays">Paul Bernays</a> was the primary assistant to David Hilbert, before Bernays (being Jewish by birth) was forced out of Göttingen by the Nazis in 1933.  He spent most of the rest of his career at ETH.  He’s perhaps best known for the <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Bernays%E2%80%93G%C3%B6del_set_theory">von Neumann-Bernays-Gödel set theory</a>, and for writing (in a volume by “Hilbert and Bernays,” but actually just Bernays) arguably the first full proof of Gödel’s <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems#Second_incompleteness_theorem">Second Incompleteness Theorem</a>.</p>



<p>Anyway, the idea of the Paul Bernays Lectures is to rotate between Bernays’s different interests in his long, distinguished career—interests that included math, philosophy, logic, and the foundations of physics.  I mentioned that, if there’s any benefit to carting me out to Switzerland for these lectures, it’s that quantum computing theory combines <em>all</em> of these interests.  And this happens to be the moment in history right before we start finding out, directly from experiments, whether quantum computers can indeed solve certain special problems much faster.</p>



<p>The general theme for my three lectures was “Quantum Computing and the Fundamental Limits of Computation.”  The attendance was a few hundred.  My idea was to take the audience from Church and Turing in the 1930s, all the way to the quantum computational supremacy experiments that Google and others are doing now—as part of a single narrative.</p>



<p>If you’re interested, streaming video of the lectures is available as of today (though I haven’t watched it—let me know if the quality is OK!), as well as of course my slides.  Here you go:</p>



<p><strong>Lecture 1: The Church-Turing Thesis and Physics (<a href="https://video.ethz.ch/speakers/bernays/2019/7b11b50e-f813-4d26-95e0-616cc350708c.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays1.ppt">PowerPoint slides</a>)</strong> <strong>(with an intro in German by Giovanni Sommaruga, who knew Bernays, and a second intro in English by Renato Renner, who appeared on this blog <a href="https://www.scottaaronson.com/blog/?p=3975">here</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Is nature computable?  What should we even mean in formulating such a question?  For generations, the identification of “computable” with “computable by a Turing machine” has been seen as either an arbitrary mathematical definition, or a philosophical or psychological claim.  The rise of quantum computing and information, however, has brought a fruitful new way to look at the Church-Turing Thesis: namely, as a falsifiable empirical claim about the physical universe.  This talk seeks to examine the computability of the laws of physics from a modern standpoint—one that fully incorporates the insights of quantum mechanics, quantum field theory, quantum gravity, and cosmology.  We’ll critically assess ‘hypercomputing’ proposals involving (for example) relativistic time dilation, black holes, closed timelike curves, and exotic cosmologies, and will make a 21st-century case for the physical Church-Turing Thesis.</p></blockquote>



<p><strong>Lecture 2: The Limits of Efficient Computation (<a href="https://video.ethz.ch/speakers/bernays/2019/5564a353-d71b-46d4-bfc0-fa907de5de25.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays2.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Computer scientists care about what’s computable not only in principle, but within the resource constraints of the physical universe.  Closely related, which types of problems are solvable using a number of steps that scales reasonably (say, polynomially) with the problem size?  This lecture will examine whether the notorious NP-complete problems, like the Traveling Salesman Problem, are efficiently solvable using the resources of the physical world.  We’ll start with P=?NP problem of classical computer science—its meaning, history, and current status.  We’ll then discuss quantum computers: how they work, how they can sometimes yield exponential speedups over classical computers, and why many believe that not even they will do so for the NP-complete problems.  Finally, we’ll critically assess proposals that would use exotic physics to go even beyond quantum computers, in terms of what they would render computable in polynomial time. </p></blockquote>



<p><strong>Lecture 3: The Quest for Quantum Computational Supremacy (<a href="https://video.ethz.ch/speakers/bernays/2019/2a08c4a0-67e1-4e1f-8019-3e557fcb4cde.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays3.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Can useful quantum computers be built in our world?  This talk will discuss the current status of the large efforts currently underway at Google, IBM, and many other places to build noisy quantum devices, with 50-100 qubits, that can clearly outperform classical computers at least on some specialized tasks — a milestone that’s been given the unfortunate name of “quantum supremacy.”  We’ll survey recent theoretical work (on BosonSampling, random circuit sampling, and more) that aims to tell us: which problems should we give these devices, that we’re as confident as possible are hard for classical computers?  And how should we check whether the devices indeed solved them?  We’ll end by discussing a new protocol, for generating certified random bits, that can be implemented almost as soon as quantum supremacy itself is achieved, and which might therefore become the first application of quantum computing to be realized.</p></blockquote>



<p>Finally, thanks so much to Giovanni Sommaruga and everyone else at ETH for arranging a fantastic visit.</p></div>
    </content>
    <updated>2019-09-09T22:21:31Z</updated>
    <published>2019-09-09T22:21:31Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-09-10T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/116</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/116" rel="alternate" type="text/html"/>
    <title>TR19-116 |  $d$-to-$1$ Hardness of Coloring $4$-colorable Graphs with $O(1)$ colors | 

	Venkatesan Guruswami, 

	Sai Sandeep</title>
    <summary>The $d$-to-$1$ conjecture of Khot asserts that it is hard to satisfy an $\epsilon$ fraction of constraints of a satisfiable $d$-to-$1$ Label Cover instance, for arbitrarily small $\epsilon &gt; 0$. We prove that the $d$-to-$1$ conjecture for any fixed $d$ implies the hardness of coloring a $4$-colorable graph with $C$ colors for arbitrarily large integers $C$. Earlier, this implication was only known under the $2$-to-$1$ conjecture, which is the strongest in the family of $d$-to-$1$ conjectures.</summary>
    <updated>2019-09-09T20:29:16Z</updated>
    <published>2019-09-09T20:29:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T00:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>QuICS Hartree Postdoctoral Fellowship at University of Maryland (apply by December 1, 2019)</title>
    <summary>The Joint Center for Quantum Information and Computer Science seeks exceptional candidates for QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. QuICS postdocs will interact with leading computer scientists and physicists at the University of Maryland and the National Institute of Standards and Technology. Website: https://academicjobsonline.org/ajo/jobs/14493 Email: quics-coordinator@umiacs.umd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Joint Center for Quantum Information and Computer Science seeks exceptional candidates for QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. QuICS postdocs will interact with leading computer scientists and physicists at the University of Maryland and the National Institute of Standards and Technology.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/14493">https://academicjobsonline.org/ajo/jobs/14493</a><br/>
Email: quics-coordinator@umiacs.umd.edu</p></div>
    </content>
    <updated>2019-09-09T16:53:54Z</updated>
    <published>2019-09-09T16:53:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-19T00:20:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5655789602676044507</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5655789602676044507/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5655789602676044507" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5655789602676044507" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html" rel="alternate" type="text/html"/>
    <title>Are there any natural problems complete for NP INTER TALLY? NP INTER SPARSE?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
Recall:<br/>
<br/>
A is a <i>tally set</i> if A ⊆ 1<sup>*</sup>. <br/>
<br/>
<br/>
A is a <i>sparse set</i> if there is a polynomial p such that the number of strings of length n is ≤ p(n). <br/>
<br/>
<br/>
If there exists a sparse set A that is NP-hard under m-reductions (even btt-reductions) then P=NP. (See <a href="https://blog.computationalcomplexity.org/2006/04/favorite-theorems-small-sets.html">this post</a>.)<br/>
<br/>
If there exists a sparse set A that is NP-hard under T-reductions then PH collapses. (See <a href="https://blog.computationalcomplexity.org/2006/11/favorite-theorems-nonuniform.html">this post</a>.)<br/>
<br/>
Okay then!<br/>
<br/>
I have sometimes had a tally set or a sparse set that is in NP and I think that its not in P. I would like to prove, or at least conjecture, that it's NP-complete. But alas, I cannot since then P=NP. (Clarification: If my set is NP-complete then P=NP. I do not mean that the very act of conjecturing it would make P=NP. That would be an awesome superpower.)<br/>
<br/>
So what to do?  <br/>
<br/>
A is <i>NPSPARSE-complete </i> if A is in NP, A is sparse, and for all B that are in NP and sparse, B ≤<sub>m</sub> A.<br/>
<br/>
Similar for NPTALLY and one can also look at other types of reductions.<br/>
<br/>
So, can I show that my set is NPSPARSE-complete? Are there any NPSPARSE-complete sets? Are there NATURAL ones? (Natural is a slippery notion- see this <a href="https://blog.computationalcomplexity.org/2004/03/unnatural-post.html">post by Lance</a>.)<br/>
<br/>
Here is what I was able to find out (if more is known then please leave comments with pointers.)<br/>
<br/>
1) It was observed by <a href="https://lance.fortnow.com/papers/files/npsparse.pdf">Bhurman, Fenner, Fortnow, van Velkebeek</a> that the following set is NPTALLY-complete:<br/>
<br/>
Let M<sub>1</sub>, M<sub>2</sub>, ... be a standard list of NP-machines. Let<br/>
<br/>
A = { 1<sup>(i,n,t)</sup> : M<sub>i</sub>(1<sup>n</sup>) accepts on some path within t steps }'<br/>
<br/>
The set involves Turing Machines so its not quite what I want.<br/>
<br/>
<br/>
2) <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/messnertoran.pdf">Messner and Toran</a> show that, under an unlikely assumption about proof systems there exists an NPSPARSE-complete set. The set involves Turing Machines. Plus it uses an unlikely assumption. Interesting, but not quite what I want.<br/>
<br/>
<br/>
3) Buhrman, Fenner, Fortnow, van Melkebeek also showed that there are relativized worlds where there are no NPSPARSE sets (this was their main result). Interesting but not quite what I want.  <br/>
<br/>
4) If A is NE-complete then the tally version: { 1<sup>x</sup> : x is in A } is likely NPTALLY-complete. This may help me get what I want.<br/>
<br/>
Okay then!<br/>
<br/>
Are there any other sets that are NPTALLY-complete. NPSPARSE-complete? The obnoxious answer is to take finite variants of A.  What I really want a set of such problems so that we can proof other problems NPTALLY-complete or NPSPARSE-complete with the ease we now prove problems NP-complete.<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-09-09T14:55:00Z</updated>
    <published>2019-09-09T14:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-18T23:54:58Z</updated>
    </source>
  </entry>
</feed>
