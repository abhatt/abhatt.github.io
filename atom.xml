<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-04-29T12:38:19Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22570</id>
    <link href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/" rel="alternate" type="text/html"/>
    <title>Joshua Hinman proved Bárány’s conjecture on face numbers of polytopes, and Lei Xue proved a lower bound conjecture by Grünbaum.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Joshua Hinman proved Bárány’s conjecture. One of my first posts on this blog was a 2008 post Five Open Problems Regarding Convex Polytopes, now 14 years later, I can tell you about the first problem on the list to get solved. … <a href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h3>Joshua Hinman proved Bárány’s conjecture.</h3>
<p>One of my first posts on this blog was a 2008 post <a href="https://gilkalai.wordpress.com/2008/05/07/five-open-problems-regarding-convex-polytopes/" rel="bookmark">Five Open Problems Regarding Convex Polytopes</a>, now 14 years later, I can tell you about the first problem on the list to get solved.</p>
<p>Imre Bárány posed in the late 1990s the following question:</p>
<p>For a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>-dimensional polytope <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> and every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>, <img alt="0 \le k \le d-1" class="latex" src="https://s0.wp.com/latex.php?latex=0+%5Cle+k+%5Cle+d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>,  is it true that <img alt="f_k(P) \ge \min (f_0(P),f_{d-1}(P))" class="latex" src="https://s0.wp.com/latex.php?latex=f_k%28P%29+%5Cge+%5Cmin+%28f_0%28P%29%2Cf_%7Bd-1%7D%28P%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>?</p>
<p>Now, Joshua Hinman settled the problem! In his paper <a href="https://arxiv.org/abs/2204.02568">A Positive Answer to Bárány’s Question on Face Numbers of Polytopes</a> he actually proved even stronger linear relations. The abstract of Joshua’s paper starts with the very true assertion: “Despite a full characterization of the face vectors of simple and simplicial polytopes, the face numbers of general polytopes are poorly understood.” He moved on to describe his new inequalities:</p>
<pre><img alt="\frac{f_k(P)}{f_0(P)} \geq \frac{1}{2}\biggl[{\lceil \frac{d}{2} \rceil \choose k} + {\lfloor \frac{d}{2} \rfloor \choose k}\biggr], \qquad \frac{f_k(P)}{f_{d-1}(P)} \geq \frac{1}{2}\biggl[{\lceil \frac{d}{2} \rceil \choose d-k-1} + {\lfloor \frac{d}{2} \rfloor \choose d-k-1}\biggr]." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bf_k%28P%29%7D%7Bf_0%28P%29%7D+%5Cgeq+%5Cfrac%7B1%7D%7B2%7D%5Cbiggl%5B%7B%5Clceil+%5Cfrac%7Bd%7D%7B2%7D+%5Crceil+%5Cchoose+k%7D+%2B+%7B%5Clfloor+%5Cfrac%7Bd%7D%7B2%7D+%5Crfloor+%5Cchoose+k%7D%5Cbiggr%5D%2C+%5Cqquad+%5Cfrac%7Bf_k%28P%29%7D%7Bf_%7Bd-1%7D%28P%29%7D+%5Cgeq+%5Cfrac%7B1%7D%7B2%7D%5Cbiggl%5B%7B%5Clceil+%5Cfrac%7Bd%7D%7B2%7D+%5Crceil+%5Cchoose+d-k-1%7D+%2B+%7B%5Clfloor+%5Cfrac%7Bd%7D%7B2%7D+%5Crfloor+%5Cchoose+d-k-1%7D%5Cbiggr%5D.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></pre>
<h3>Lei Xue proved Grünbaum’s conjecture</h3>
<p>In her 2020 paper: <a href="https://arxiv.org/abs/2004.08429">A Proof of Grünbaum’s Lower Bound Conjecture for general polytopes</a>, Lei Xue proved a lower bound conjecture of Grünbaum: In 1967, Grünbaum conjectured that any <em><span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">d</span></span></span></span></em>-dimensional polytope with <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6">d</span><span class="mo" id="MathJax-Span-7">+</span><span class="mi" id="MathJax-Span-8">s</span><span class="mo" id="MathJax-Span-9">≤</span><span class="mn" id="MathJax-Span-10">2</span><span class="mi" id="MathJax-Span-11">d</span></span></span></span></em> vertices has at least</p>
<pre><img alt="\phi_k(d+s,d) = {d+1 \choose k+1 }+{d \choose k+1 }-{d+1-s \choose k+1 }" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi_k%28d%2Bs%2Cd%29+%3D+%7Bd%2B1+%5Cchoose+k%2B1+%7D%2B%7Bd+%5Cchoose+k%2B1+%7D-%7Bd%2B1-s+%5Cchoose+k%2B1+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></pre>
<p><em><span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-86"><span class="mrow" id="MathJax-Span-87"><span class="mi" id="MathJax-Span-88">k</span></span></span></span></em>-faces. Lei Xue proved this conjecture and also characterized the cases in which equality holds.</p>
<p><strong>Congratulations to Lei Xue and to Joshua Hinman.<br/></strong><strong><br/></strong></p>
<p/>
<p> </p>


<p/></div>
    </content>
    <updated>2022-04-29T07:11:24Z</updated>
    <published>2022-04-29T07:11:24Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Branko Grunbaum"/>
    <category term="Imre B&#xE1;r&#xE1;ny"/>
    <category term="Joshua Hinman"/>
    <category term="Lei Xue"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-04-29T12:37:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/04/28/may-4-ideal-cs-colloquium-seminar-by-chandra-chekuri-uiuc/</id>
    <link href="https://cstheory-events.org/2022/04/28/may-4-ideal-cs-colloquium-seminar-by-chandra-chekuri-uiuc/" rel="alternate" type="text/html"/>
    <title>May 4: IDEAL/CS Colloquium Seminar by Chandra Chekuri (UIUC)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 4, 2022 MUDD LIBRARY ROOM 3514 https://www.ideal.northwestern.edu/events/ May 4: IDEAL Seminar by Chandra Chekuri (UIUC) FRIDAY / IDEAL/CS Colloquium May 4, 2022 / 12:00 pm CDT (Chicago Time) in Mudd Library Room 3514 “Densest Subgraph: Supermodularity, Iterative Peeling, and Flow” Chandra Chekuri, University of Illinois Urbana-Champaign Zoom: https://www.ideal.northwestern.edu/special-quarters/spring-2022/workshops/zoom-link Panopto: https://www.ideal.northwestern.edu/special-quarters/spring-2022/workshops/panopto-05-04-22 Abstract: The densest subgraph … <a class="more-link" href="https://cstheory-events.org/2022/04/28/may-4-ideal-cs-colloquium-seminar-by-chandra-chekuri-uiuc/">Continue reading <span class="screen-reader-text">May 4: IDEAL/CS Colloquium Seminar by Chandra Chekuri (UIUC)</span></a></div>
    </summary>
    <updated>2022-04-28T23:04:18Z</updated>
    <published>2022-04-28T23:04:18Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-04-29T08:38:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=619</id>
    <link href="https://tcsplus.wordpress.com/2022/04/28/tcs-talk-wednesday-may-4-vera-traub-eth-zurich/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 4 — Vera Traub, ETH Zürich</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Vera Traub from ETH Zürich will speak about “Approximation Algorithms for Connectivity Augmentation Problems” (abstract below). You can reserve a spot as an individual or a group to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://people.math.ethz.ch/~vtraub/"><strong>Vera Traub</strong></a> from ETH Zürich will speak about “<em>Approximation Algorithms for Connectivity Augmentation Problems</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Augmentation problems are a fundamental class of network design problems. They ask about the cheapest way to increase the (edge-)connectivity of a graph by adding edges among a given set of options. One of the most elementary and intensely studied augmentation problems is the (Weighted) Tree Augmentation Problem. Here, a spanning tree has to be augmented into a 2-edge-connected graph.</p>
<p>Classic techniques for network design yield 2-approximation algorithms for a wide class of augmentation problems. For the Unweighted Tree Augmentation Problem, better-than-2 approximations are known for more than 20 years. However, only recently the first better-than-2 approximations have been found for the more general Unweighted Connectivity Augmentation Problem and Weighted Tree Augmentation Problem. In this talk we will discuss these recent advances.</p></blockquote></div>
    </content>
    <updated>2022-04-28T10:39:45Z</updated>
    <published>2022-04-28T10:39:45Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-04-29T12:37:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.13087</id>
    <link href="http://arxiv.org/abs/2204.13087" rel="alternate" type="text/html"/>
    <title>Faster online calibration without randomization: interval forecasts and the power of two choices</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Chirag.html">Chirag Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramdas:Aaditya.html">Aaditya Ramdas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.13087">PDF</a><br/><b>Abstract: </b>We study the problem of making calibrated probabilistic forecasts for a
binary sequence generated by an adversarial nature. Following the seminal paper
of Foster and Vohra (1998), nature is often modeled as an adaptive adversary
who sees all activity of the forecaster except the randomization that the
forecaster may deploy. A number of papers have proposed randomized forecasting
strategies that achieve an $\epsilon$-calibration error rate of
$O(1/\sqrt{T})$, which we prove is tight in general. On the other hand, it is
well known that it is not possible to be calibrated without randomization, or
if nature also sees the forecaster's randomization; in both cases the
calibration error could be $\Omega(1)$. Inspired by the equally seminal works
on the "power of two choices" and imprecise probability theory, we study a
small variant of the standard online calibration problem. The adversary gives
the forecaster the option of making two nearby probabilistic forecasts, or
equivalently an interval forecast of small width, and the endpoint closest to
the revealed outcome is used to judge calibration. This power of two choices,
or imprecise forecast, accords the forecaster with significant power -- we show
that a faster $\epsilon$-calibration rate of $O(1/T)$ can be achieved even
without deploying any randomization.
</p></div>
    </summary>
    <updated>2022-04-28T22:41:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.13019</id>
    <link href="http://arxiv.org/abs/2204.13019" rel="alternate" type="text/html"/>
    <title>Fair and Efficient Allocation with Quotas</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Siddhartha.html">Siddhartha Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eichhorn:Matthew.html">Matthew Eichhorn</a>, David Kempe <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.13019">PDF</a><br/><b>Abstract: </b>In many settings, such as the rationing of medical care and supplies,
university admissions, and the assignment of public housing, the decision of
who receives an allocation can be justified by various normative criteria
(ethical, financial, legal, etc.). These criteria can influence priorities and
restrict the number of units available to particular demographics. We consider
a setting wherein a set of identical items must be distributed among
unit-demand applicants. The items are divided across a set of categories (each
with an allocation quota), and each category has a priority ordering over its
eligible applicants. Building on previous work, we define a set of natural
desiderata for allocations. We use techniques from linear and integer
programming to give a polynomial-time procedure for finding Pareto efficient
allocations satisfying these desiderata. The clean formulation of our algorithm
allows us to more easily derive known results in this space and provides the
flexibility to consider alternate objectives and enforce various notions of
equity between categories.
</p></div>
    </summary>
    <updated>2022-04-28T22:44:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12856</id>
    <link href="http://arxiv.org/abs/2204.12856" rel="alternate" type="text/html"/>
    <title>Insight into Voting Problem Complexity Using Randomized Classes</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fitzsimmons:Zack.html">Zack Fitzsimmons</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hemaspaandra:Edith.html">Edith Hemaspaandra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12856">PDF</a><br/><b>Abstract: </b>The first step in classifying the complexity of an NP problem is typically
showing the problem in P or NP-complete. This has been a successful first step
for many problems, including voting problems. However, in this paper we show
that this may not always be the best first step. We consider the problem of
constructive control by replacing voters (CCRV) introduced by Loreggia et al.
(2015) for the scoring rule First-Last, which is defined by $\langle 1, 0,
\dots, 0, -1\rangle$. We show that this problem is equivalent to Exact Perfect
Bipartite Matching (EPBM), and so CCRV for First-Last can be determined in
random polynomial time. So on the one hand, if CCRV for First-Last is
NP-complete then RP = NP, which is extremely unlikely. On the other hand,
showing that CCRV for First-Last is in P would also show that EPBM is in P,
which would solve a well-studied 40-year-old open problem.
</p>
<p>Considering RP as an option for classifying problems can also help classify
problems that until now had escaped classification. For example, the sole open
problem in the comprehensive table from Erd\'{e}lyi et al. (2021) is CCRV for
2-Approval. We show that this problem is in RP, and thus easy since it is
widely assumed that P = RP.
</p></div>
    </summary>
    <updated>2022-04-28T22:40:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12801</id>
    <link href="http://arxiv.org/abs/2204.12801" rel="alternate" type="text/html"/>
    <title>Speeding Hirschberg Algorithm for Sequence Alignment</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Llorens:David.html">David Llorens</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vilar:Juan_Miguel.html">Juan Miguel Vilar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12801">PDF</a><br/><b>Abstract: </b>The use of Hirschberg algorithm reduces the spatial cost of recovering the
Longest Common Subsequence to linear space. The same technique can be applied
to similar problems like Sequence Alignment. However, the price to pay is a
duplication of temporal cost. We present here a technique to reduce this time
overhead to a negligible amount.
</p></div>
    </summary>
    <updated>2022-04-28T22:45:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12780</id>
    <link href="http://arxiv.org/abs/2204.12780" rel="alternate" type="text/html"/>
    <title>A Branch-and-Price Approach to a Variant of the Cognitive Radio Resource Allocation Problem</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Falsafain:Hossein.html">Hossein Falsafain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heidarpour:Mohammad_Reza.html">Mohammad Reza Heidarpour</a>, Soroush Vahidi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12780">PDF</a><br/><b>Abstract: </b>Radio-frequency portion of the electromagnetic spectrum is a scarce resource.
Cognitive radio technology has emerged as a promising solution to overcome the
spectrum scarcity bottleneck. Through this technology, secondary users (SUs)
sense the spectrum opportunities free from primary users (PUs), and
opportunistically take advantage of these (temporarily) idle portions, known as
spectrum holes. In this correspondence, we consider a variant of the cognitive
radio resource allocation problem posed by Martinovic et al. in 2017. The
distinguishing feature of this version of the problem is that each SU, due to
its hardware limitations, imposes the requirement that the to-be-aggregated
spectrum holes cannot be arbitrarily far from each other. We call this
restriction as the Maximal Aggregation Range (MAR) constraint, and refer to
this variant of the problem as the MAR-constrained hole assignment problem. The
problem can be formalized as an NP-hard combinatorial optimization problem. We
propose a novel binary integer linear programming (ILP) formulation to the
problem. The number of constraints in this formulation is the number of
spectrum holes plus the number of SUs. On the other hand, the number of binary
decision variables in the formulation can be prohibitively large, as for each
legitimate spectrum allocation to each SU, one variable is needed. We propose a
branch-and-price (B&amp;P) framework to tackle this challenge. This framework is in
fact a branch-and-bound procedure in which at each node of the search tree, we
utilize the so-called (delayed) column generation technique for solving the LP
relaxation of the corresponding subproblem. As evidenced by the numerical
results, the LP relaxation bounds are very tight. This allows for a very
effective pruning of the search space. Compared to the previously suggested
formulations, the proposed technique can require much less computational
effort.
</p></div>
    </summary>
    <updated>2022-04-28T22:42:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12721</id>
    <link href="http://arxiv.org/abs/2204.12721" rel="alternate" type="text/html"/>
    <title>Regularized Box-Simplex Games and Dynamic Decremental Bipartite Matching</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jambulapati:Arun.html">Arun Jambulapati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yujia.html">Yujia Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Kevin.html">Kevin Tian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12721">PDF</a><br/><b>Abstract: </b>Box-simplex games are a family of bilinear minimax objectives which
encapsulate graph-structured problems such as maximum flow [She17], optimal
transport [JST19], and bipartite matching [AJJ+22]. We develop efficient
near-linear time, high-accuracy solvers for regularized variants of these
games. Beyond the immediate applications of such solvers for computing Sinkhorn
distances, a prominent tool in machine learning, we show that these solvers can
be used to obtain improved running times for maintaining a (fractional)
$\epsilon$-approximate maximum matching in a dynamic decremental bipartite
graph against an adaptive adversary. We give a generic framework which reduces
this dynamic matching problem to solving regularized graph-structured
optimization problems to high accuracy. Through our reduction framework, our
regularized box-simplex game solver implies a new algorithm for dynamic
decremental bipartite matching in total time $\tilde{O}(m \cdot
\epsilon^{-3})$, from an initial graph with $m$ edges and $n$ nodes. We further
show how to use recent advances in flow optimization [CKL+22] to improve our
runtime to $m^{1 + o(1)} \cdot \epsilon^{-2}$, thereby demonstrating the
versatility of our reduction-based approach. These results improve upon the
previous best runtime of $\tilde{O}(m \cdot \epsilon^{-4})$ [BGS20] and
illustrate the utility of using regularized optimization problem solvers for
designing dynamic algorithms.
</p></div>
    </summary>
    <updated>2022-04-28T22:42:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12640</id>
    <link href="http://arxiv.org/abs/2204.12640" rel="alternate" type="text/html"/>
    <title>Optimal Closeness Testing of Discrete Distributions Made (Complex) Simple</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yucheng.html">Yucheng Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12640">PDF</a><br/><b>Abstract: </b>In this note, we revisit the recent work of Diakonikolas, Gouleakis, Kane,
Peebles, and Price (2021), and provide an alternative proof of their main
result. Our argument does not rely on any specific property of Poisson random
variables (such as stability and divisibility) nor on any "clever trick," but
instead on an identity relating the expectation of the absolute value of any
random variable to the integral of its characteristic function:
</p>
<p>\[
</p>
<p>\mathbb{E}[|X|] = \frac{2}{\pi}\int_0^\infty \frac{1-\Re(\mathbb{E}[e^{i
tX}])}{t^2}\, dt
</p>
<p>\]
</p>
<p>Our argument, while not devoid of technical aspects, is arguably conceptually
simpler and more general; and we hope this technique can find additional
applications in distribution testing.
</p></div>
    </summary>
    <updated>2022-04-28T22:45:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12614</id>
    <link href="http://arxiv.org/abs/2204.12614" rel="alternate" type="text/html"/>
    <title>MaxSAT with Absolute Value Functions: A Parameterized Perspective</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannach:Max.html">Max Bannach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fleischmann:Pamela.html">Pamela Fleischmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skambath:Malte.html">Malte Skambath</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12614">PDF</a><br/><b>Abstract: </b>The natural generalization of the Boolean satisfiability problem to
optimization problems is the task of determining the maximum number of clauses
that can simultaneously be satisfied in a propositional formula in conjunctive
normal form. In the weighted maximum satisfiability problem each clause has a
positive weight and one seeks an assignment of maximum weight. The literature
almost solely considers the case of positive weights. While the general case of
the problem is only restricted slightly by this constraint, many special cases
become trivial in the absence of negative weights. In this work we study the
problem with negative weights and observe that the problem becomes
computationally harder - which we formalize from a parameterized perspective in
the sense that various variations of the problem become W[1]-hard if negative
weights are present.
</p>
<p>Allowing negative weights also introduces new variants of the problem:
Instead of maximizing the sum of weights of satisfied clauses, we can maximize
the absolute value of that sum. This turns out to be surprisingly expressive
even restricted to monotone formulas in disjunctive normal form with at most
two literals per clause. In contrast to the versions without the absolute
value, however, we prove that these variants are fixed-parameter tractable. As
technical contribution we present a kernelization for an auxiliary problem on
hypergraphs in which we seek, given an edge-weighted hypergraph, an induced
subgraph that maximizes the absolute value of the sum of edge-weights.
</p></div>
    </summary>
    <updated>2022-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12609</id>
    <link href="http://arxiv.org/abs/2204.12609" rel="alternate" type="text/html"/>
    <title>A 3-Approximation Algorithm for a Particular Case of the Hamiltonian p-Median Problem</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pereira:Dilson_Lucas.html">Dilson Lucas Pereira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soares:Michel_Wan_Der_Maas.html">Michel Wan Der Maas Soares</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12609">PDF</a><br/><b>Abstract: </b>Given a weighted graph $G$ with $n$ vertices and $m$ edges, and a positive
integer $p$, the Hamiltonian $p$-median problem consists in finding $p$ cycles
of minimum total weight such that each vertex of $G$ is in exactly one cycle.
We introduce an $O(n^6)$ 3-approximation algorithm for the particular case in
which $p \leq \lceil \frac{n-2\lceil \frac{n}{5} \rceil}{3} \rceil$. An
approximation ratio of 2 might be obtained depending on the number of
components in the optimal 2-factor of $G$. We present computational experiments
comparing the approximation algorithm to an exact algorithm from the
literature. In practice much better ratios are obtained. For large values of
$p$, the exact algorithm is outperformed by our approximation algorithm.
</p></div>
    </summary>
    <updated>2022-04-28T22:44:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2204.12051</id>
    <link href="http://arxiv.org/abs/2204.12051" rel="alternate" type="text/html"/>
    <title>Complexity of quantum circuits via sensitivity, magic, and coherence</title>
    <feedworld_mtime>1651104000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bu:Kaifeng.html">Kaifeng Bu</a>, Roy J. Garcia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaffe:Arthur.html">Arthur Jaffe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koh:Dax_Enshan.html">Dax Enshan Koh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Lu.html">Lu Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2204.12051">PDF</a><br/><b>Abstract: </b>Quantum circuit complexity-a measure of the minimum number of gates needed to
implement a given unitary transformation-is a fundamental concept in quantum
computation, with widespread applications ranging from determining the running
time of quantum algorithms to understanding the physics of black holes. In this
work, we study the complexity of quantum circuits using the notions of
sensitivity, average sensitivity (also called influence), magic, and coherence.
We characterize the set of unitaries with vanishing sensitivity and show that
it coincides with the family of matchgates. Since matchgates are tractable
quantum circuits, we have proved that sensitivity is necessary for a quantum
speedup. As magic is another measure to quantify quantum advantage, it is
interesting to understand the relation between magic and sensitivity. We do
this by introducing a quantum version of the Fourier entropy-influence
relation. Our results are pivotal for understanding the role of sensitivity,
magic, and coherence in quantum computation.
</p></div>
    </summary>
    <updated>2022-04-28T22:37:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6405</id>
    <link href="https://scottaaronson.blog/?p=6405" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6405#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6405" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My first-ever attempt to create a meme!</title>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" src="https://www.scottaaronson.com/4thinkers.jpg"/></figure></div>
    </content>
    <updated>2022-04-27T23:41:25Z</updated>
    <published>2022-04-27T23:41:25Z</published>
    <category scheme="https://scottaaronson.blog" term="Embarrassing Myself"/>
    <category scheme="https://scottaaronson.blog" term="Metaphysical Spouting"/>
    <category scheme="https://scottaaronson.blog" term="Procrastination"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-04-27T23:41:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/060" rel="alternate" type="text/html"/>
    <title>TR22-060 |  How much randomness is needed to convert MA protocols to AM protocols? | 

	Nikolay Vereshchagin</title>
    <summary>The Merlin-Arthur  class of languages MA is included into Arthur-Merlin  class AM, and into PP. For a  standard transformation of a given MA protocol with  Arthur's message (= random string) of length $a$ and Merlin's message of length $m$ to a PP machine, the latter needs  $O(ma)$ random bits. The same holds for simulating MA protocols by AM protocols: in the resulting AM protocol the length of Arthur's message (= random string) is $O(ma)$. And the same holds for simulating heuristic MA protocols by  heuristic  AM protocols as well. In the paper  [A. Knop, Circuit Lower Bounds for Average-Case MA, CSR 2015] it was conjectured that, in the transformation of heuristic MA protocols to heuristic AM protocols, $O(ma)$ can be replaced by a polynomial of $a$ only. A similar question can be asked for normal MA and AM protocols, and for the simulation of MA protocols by PP machines. In the present paper we show that, relative to an oracle,  both latter questions answer in the negative and Knop's conjecture is false. Moreover,  the same is true for simulation of MA protocols by AM protocols in which the  error probability is not bounded away from 1/2, the so called PP$\cdot$NP protocols. The latter protocols generalize both AM protocols and  PP machines.</summary>
    <updated>2022-04-27T16:52:27Z</updated>
    <published>2022-04-27T16:52:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8309</id>
    <link href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/" rel="alternate" type="text/html"/>
    <title>A personal FAQ on the math education controversies</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I was a contact person for the open letter on K-12 math education, and am in strong support of the recent letter on the role of data science in math education (and would encourage readers that are faculty members in California to sign it). Since I tend to see the same questions and objections arise … <a class="more-link" href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/">Continue reading <span class="screen-reader-text">A personal FAQ on the math education controversies</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was a contact person for the <a href="https://windowsontheory.org/2021/12/03/an-alarming-trend-in-k-12-math-education/">open letter on K-12 math education</a>, and am in strong support of the <a href="https://scottaaronson.blog/?p=6389">recent letter on the role of data science in math education</a> (and would encourage readers that are faculty members in California to sign it). Since I tend to see the same questions and objections arise time and again, I thought it would be useful to write my responses to these. The following is my own opinions only, and does not reflect the views of any other contact person or signer of these letters. I also apologize in advance for the lack of links and references below. However, if you ask questions in the comments, I’d be happy to give more sources.</p>



<p><strong>Q: The status quo in US math education is terrible and doesn’t work for many children, especially students of color and low income students. Aren’t these letter writers just trying to protect a flawed system that worked well for them?</strong></p>



<p><strong>A: </strong>The US math education system is very complex, but I agree that it is largely failing a large chunk of our students. But that doesn’t mean that any change will necessarily be for the better. Just because a system is bad, doesn’t mean you can’t make it worse. We have a responsibility to “first do no harm” when we experiment on millions of children of our largest state, and the proposed changes are not based on any solid evidence, and in my opinion (and the opinion of many other experts) will make things worse. Indeed, there is no shortage of experiments in mathematics education that yielded no or even negative progress in terms of equity.</p>



<p>Also, not all change needs to be curricular change. The inequalities in the system were not created because of the math curriculum, and will not be fixed by it. Many top-performing countries use a fairly traditional math curriculum, some strongly influenced by the Soviet system.  The inequalities in the US arise from huge disparities in the resources at school, and a highly unequal society at large. I personally think that improving education is much more about support for students, resources, tutoring, teacher training, etc, than whether we teach logarithms using method X or method Y.</p>



<p><strong>Q:</strong> <strong>Shouldn’t CS and STEM faculty stay out of this debate, and leave it to the math education faculty that are the true subject matter experts?</strong></p>



<p><strong>A:</strong> The education system has many stakeholders, including students, parents, teachers, citizens, employers, and post-secondary educators, and they all should be heard. STEM careers and other quantitative fields are the fastest growing in opportunities and student interest in college. As such, one of the goals (though not the only one) of K-12 math education is to prepare students to have the option to major in STEM in college, if that is what they want to do. STEM faculty are the best equipped to <a href="https://mathematics.stanford.edu/news/submission-ca-math-framework-revision">say what is needed</a> for success in their field, and what they see is the impact of K-12 preparation. Math Ed and STEM faculty can and should be working together on the  K-12 curriculum. </p>



<p><strong>Q: But not all students will go to STEM in college. Shouldn’t the K-12 math education system also offer something for the students that are not interested in STEM?</strong></p>



<p><strong>A: </strong>I agree that not all students will go to STEM and that (for example) not all high-school students should be forced to take calculus. However, if we are offering an option that is designed for students that are not interested in STEM then we should be honest about it. At the moment high-school data science courses are marketed as a way to “have your cake and eat it too” – courses that are on one hand easier than algebra and calculus and on the other hand give just as good or maybe even better preparation for a career in tech or data science. This is misinformation, and the students most likely to fall for it are the ones with the least resources. In addition, the type of thinking developed by rigorous math courses can benefit students throughout their lives and careers, regardless of the path they take.</p>



<p><strong>Q: Isn’t equity more important than giving students opportunities to advance in math? Shouldn’t mathematical education policy be focused on the kids that are struggling the most and facing most challenges, in particular students of color?</strong></p>



<p><strong>A: </strong>I personally think equity and expanding access to mathematical education is absolutely crucial. This is why I was and am involved in initiatives including <a href="https://www.addiscoder.com/">AddisCoder</a>, <a href="https://jamcoders.org.jm/">JamCoders</a>, <a href="https://womenintheory.wordpress.com/">Women In Theory</a>, and <a href="https://boazbk.github.io/tcs-summerschool/">New Horizons in TCS</a>. But true equity is about actually educating students more, not about moving the goalposts and claiming success. This is doubly true in the context of the US education system. There will be many routes open to well-resourced students to bypass any limitations of the public system. These include private tutoring, courses such as Russian School of Math, Art of Problem Solving, or simply opting out of the public system altogether. Also, due to local control, wealthier districts are likely to opt out of any reforms that they perceive (correctly) as giving worse preparation for post-secondary success. </p>



<p>Hence changes such as the CMF will disproportionately harm low-income students and students of color, and make it less likely for them to succeed in STEM. Not coincidentally, many educators, researchers, and practitioners of color have signed both letters, while the CMF itself has no Black authors. There are efforts that actually do work to decrease educational gaps: these include Bob Moses’ <a href="https://www.nytimes.com/2001/01/07/education/algebra-project-bob-moses-empowers-students.html">Algebra Project</a>, Adrian Mims’ (contact person for one of the letters) <a href="https://thecalculusproject.org/">Calculus Project</a>,  <a href="https://www.theescalanteprogram.org/">Jaime Escalante</a>  (from “stand and deliver”) math program, and the <a href="https://www.aeaweb.org/articles?id=10.1257/app.3.3.158">Harlem Children’s Zone</a>. Notably, none of these projects involve lowering the bar. </p>



<p><strong>Q: Maybe the problem is with the STEM college curriculum as well? For example, why do students need calculus for a computer science degree when hardly any software engineer uses it? If colleges would make their curriculum more practically oriented then we wouldn’t need to teach high-school kids this hard math.</strong></p>



<p><strong>A:</strong> There is a narrow answer and a deeper answer to this question. The narrow answer is that the goal of K-12 education is to prepare students for success in the world as it exists now. If you want to fight these battles at the higher education level, then you should fight them and win them, and only later change the K-12 education to fit the new college curricula.</p>



<p>However, there is a deeper answer why university education has always been about more than just giving students the minimal vocational skills. We believe that our mission is not just to give students some tools that they’ll use in the first job out of school, but broader ways of thinking that will help them keep up with new developments throughout their careers. Computer Science is a great example of this. Fifteen years ago, most computer scientists didn’t need to know much about algebra, probability or calculus, but these days deep learning is fast expanding to every area of CS. The time between an academic paper to a real-world product is getting shorter and shorter, and one skill a computer scientist needs these days is the ability to read a complex technical text and not be afraid of learning new math. Foundational courses such as college calculus and linear algebra (which themselves build on high-school Algebra II and  pre-calculus) are crucial for this skill.</p>



<p><strong>Q: Aren’t you devaluing data science and saying it’s less important than Algebra or Calculus?</strong></p>



<p><strong>A: </strong>Absolutely not. I think literacy with data is an essential skill for any citizen in our modern society, and strongly support it being taught for every K-12 student. This does not mean that it can or should replace the basic math foundational skills. Data science can and be included in variety of courses, ranging from the computational and natural sciences to the social sciences and even humanities. (For example see the courses satisfying Harvard’s <a href="https://oue.fas.harvard.edu/quantitative-reasoning-data">quantitative reasoning with data requirement</a>.)</p>



<p>“Data science” is an evolving field and at the moment not very well defined, and as such there are data science courses of vastly different types. A high-school course or module in data proficiency can be extremely beneficial for students, but without prerequisites such as algebra, probability, and programming, there is a severe limit to the depth that it can go to. For students who will not go into STEM or data science, such a data literacy course would be highly recommended. Students who will take a deeper course later on are better served by foundational courses such as Algebra, Pre-calculus, and Calculus. </p>



<p>By the way, there is nothing about data science that makes it inherently easier than algebra or calculus. While (univariate) calculus is ultimately about functions you can draw on a paper and reason intuitively about their graphs, issues of correlations vs causation are highly subtle, and even experts could get it wrong. The skills and rigorous modes of thinking developed in courses such as Algebra II and beyond are required to develop a true understanding of data science. </p>



<p>There is another reason why a prerequisite-free data literacy course should not be considered as part of the math curriculum, which was eloquently put by <a href="https://blog.mathed.page/2019/10/14/freakonomics-radio-on-math-curriculum/">Henri Picciotto</a> (see also <a href="https://blog.mathed.page/2021/12/14/yet-more-on-the-california-framework-part-1/">this</a>): <em>“in math we should not teach black-box formulas and software packages that students cannot possibly understand thoroughly. We have been moving towards teaching math for understanding at all levels. There is no reason to use data analysis as an excuse to backtrack. Let science and social studies teachers use standard deviation, correlation coefficient, regression, confidence interval, and the like without understanding the underlying assumptions and the reasoning and calculations that lead to those. Math teachers should not. “</em></p>



<p><strong>Q: Isn’t the CMF an evidence-based proposal that is backed by a huge number of citations?</strong></p>



<p><strong>A:</strong> The short answer to this question is “No”. The medium answer is that the CMF contains many citations but often the research cited is <a href="https://notepad.michaelpershan.com/more-youcubed-research-that-is-difficult-to-explain/">sloppy</a>, or is cited incorrectly. (For example, they make plenty of <a href="https://docs.google.com/document/d/1WO4gCR0fCHtlN8uN5lRztAsdqEGuRgKE/edit#bookmark=id.d8y5jr2fqobx" rel="noreferrer noopener" target="_blank">unsupported</a> <a href="https://docs.google.com/document/d/1WO4gCR0fCHtlN8uN5lRztAsdqEGuRgKE/edit#bookmark=id.biqb9dlec448" rel="noreferrer noopener" target="_blank">claims</a> on neuroscience ,whereas essentially all neuroscientists agree that our understanding of the brain is nowhere near the level that it could be used to guide curriculum development.) The long answer is out of scope for this blog post, but here are some links to analyses done by other people. I will update this blog as more are put out (this is a 900 page document after all), but some people that wrote about this include <a href="https://notepad.michaelpershan.com/what-is-happening-in-california-with-math-right-now/">Michael Pershan</a> and <a href="https://twitter.com/BethKellySF/status/1516875836573454338?s=20&amp;t=ewWPTA0FYdJBpJNDzeTjDw">Beth Kelly</a> (see also <a href="https://twitter.com/BethKellySF/status/1518991575526699008?s=20&amp;t=ewWPTA0FYdJBpJNDzeTjDw">this</a>). Brian Conrad has been working on fuller analysis of the CMF, and I will update this post (as well as <a href="https://twitter.com/boazbaraktcs">tweet</a> about it) as parts of it become available.</p></div>
    </content>
    <updated>2022-04-27T15:37:13Z</updated>
    <published>2022-04-27T15:37:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-04-29T12:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/059" rel="alternate" type="text/html"/>
    <title>TR22-059 |  Diameter versus Certificate Complexity of Boolean Functions | 

	Siddhesh Chaubal, 

	Anna Gal</title>
    <summary>In this paper, we introduce a measure of Boolean functions we call diameter, that captures the relationship between certificate complexity and several other measures of Boolean functions. Our measure can be viewed as a variation on alternating number, but while alternating number can be exponentially larger than certificate complexity, we show that diameter is always upper bounded by certificate complexity. We argue that estimating diameter may help to get improved bounds on certificate complexity in terms of sensitivity, and other measures.

Previous results due to Lin and Zhang  imply that $s(f) \ge \Omega(n^{1/3})$ for transitive functions with constant alternating number. We improve and extend this bound and prove that $s(f) \ge \sqrt{n}$ for transitive functions with constant alternating number, as well as for transitive functions with constant diameter. We also show that $bs(f) \ge \Omega(n^{3/7})$ for transitive functions under the weaker condition that the ``minimum'' diameter is constant.

Furthermore, we prove that the log-rank conjecture holds for functions of the form $f(x \oplus y)$ for functions $f$ with diameter bounded above by a polynomial of the logarithm of the Fourier sparsity of the function $f$.</summary>
    <updated>2022-04-27T03:46:54Z</updated>
    <published>2022-04-27T03:46:54Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6389</id>
    <link href="https://scottaaronson.blog/?p=6389" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6389#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6389" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">An update on the campaign to defend serious math education in California</title>
    <summary xml:lang="en-US">Update (April 27): Boaz Barak—Harvard CS professor, longtime friend-of-the-blog, and coauthor of my previous guest post on this topic—has just written an awesome FAQ, providing his personal answers to the most common questions about what I called our “campaign to defend serious math education.” It directly addresses several issues that have already come up in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Update (April 27):</strong> Boaz Barak—Harvard CS professor, longtime friend-of-the-blog, and coauthor of my previous guest post on this topic—has just written an <a href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/">awesome FAQ</a>, providing his personal answers to the most common questions about what I called our “campaign to defend serious math education.”  It directly addresses several issues that have already come up in the comments.  Check it out!</p>



<hr class="wp-block-separator"/>



<p>As you might remember, last December I hosted a <a href="https://scottaaronson.blog/?p=6146">guest post</a> about the “California Mathematics Framework” (CMF), which was set to cause radical changes to precollege math in California—e.g., eliminating 8th-grade algebra and making it nearly impossible to take AP Calculus.  I linked to an <a href="https://sites.google.com/view/k12mathmatters/home">open letter</a> setting out my and my colleagues’ concerns about the CMF.  That letter went on to receive more than 1700 signatures from STEM experts in industry and academia from around the US, including recipients of the Nobel Prize, Fields Medal, and Turing Award, as well as a lot of support from college-level instructors in California. </p>



<p>Following widespread pushback, a <a href="https://www.cde.ca.gov/ci/ma/cf/">new version of the CMF</a> appeared in mid-March.  I and others are gratified that the new version significantly softens the opposition to acceleration in high school math and to calculus as a central part of mathematics.  Nonetheless, we’re still concerned that the new version promotes a narrative about data science that’s a recipe for cutting kids off from any chance at earning a 4-year college degree in STEM fields (including, ironically, in data science itself).</p>



<p>To that end, some of my Californian colleagues have <a href="https://sites.google.com/view/mathindatamatters/home"><strong>issued a new statement today</strong></a> on behalf of academic staff at 4-year colleges in California, aimed at clearing away the fog on how mathematics is related to data science.  I strongly encourage my readers on the academic staff at 4-year colleges in California to sign this commonsense statement, which has already been signed by over 250 people (including, notably, at least 50 from Stanford, home of two CMF authors).</p>



<p>As a public service announcement, I’d also like to bring to wider awareness <a href="https://www.law.cornell.edu/regulations/california/5-CCR-Sec-18533">Section 18533 of the California Education Code</a>, for submitting written statements to the California State Board of Education (SBE) about errors, objections, and concerns in curricular frameworks such as the CMF.  </p>



<p>The SBE is scheduled to vote on the CMF in mid-July, and their remaining meeting before then is on May 18-19 according to <a href="https://www.cde.ca.gov/be/ag/st/index.asp">this site</a>, so it is really at the May meeting that concerns need to be aired.  Section 18533 requires submissions to be written (yes, snail mail) and postmarked at least 10 days before the SBE meeting.  So to make your voice heard by the SBE, please send your written concern by certified mail (for tracking, but <em>not</em> requiring signature for delivery), no later than Friday May 6, to State Board of Education, c/o Executive Secretary of the State Board of Education, 1430 N Street, Room 5111, Sacramento, CA 95814, complemented by an email submission to <a href="mailto:sbe@cde.ca.gov" rel="noreferrer noopener" target="_blank">sbe@cde.ca.gov</a> and <a href="mailto:mathframework@cde.ca.gov" rel="noreferrer noopener" target="_blank">mathframework@cde.ca.gov</a>.</p></div>
    </content>
    <updated>2022-04-26T17:02:02Z</updated>
    <published>2022-04-26T17:02:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-04-27T23:41:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/058" rel="alternate" type="text/html"/>
    <title>TR22-058 |  Separations in Proof Complexity and TFNP | 

	Mika Göös, 

	Alexandros Hollender, 

	Siddhartha Jain, 

	Gilbert Maystre, 

	William Pires, 

	Robert Robere, 

	Ran Tao</title>
    <summary>It is well-known that Resolution proofs can be efficiently simulated by Sherali-Adams (SA) proofs. We show, however, that any such simulation needs to exploit huge coefficients: Resolution cannot be efficiently simulated by SA when the coefficients are written in unary. We also show that Reversible Resolution (a variant of MaxSAT Resolution) cannot be efficiently simulated by Nullstellensatz (NS).

These results can be interpreted in the language of total NP search problems. We show that PPADS, PPAD, SOPL are captured by unary-SA, unary-NS, and Reversible Resolution, respectively. Consequently, relative to an oracle, PLS $\not\subseteq$ PPADS and SOPL $\not\subseteq$ PPA.</summary>
    <updated>2022-04-26T15:47:44Z</updated>
    <published>2022-04-26T15:47:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/057" rel="alternate" type="text/html"/>
    <title>TR22-057 |  When Arthur has Neither Random Coins nor Time to Spare: Superfast Derandomization of Proof Systems | 

	Lijie Chen, 

	Roei Tell</title>
    <summary>What is the actual cost of derandomization? And can we get it for free? These questions were recently raised by Doron et. al (FOCS 2020) and have been attracting considerable interest. In this work we extend the study of these questions to the setting of *derandomizing interactive proofs systems*. 

First, we show conditional derandomization of $\mathcal{MA}$ and of $\mathcal{AM}$ with *optimal runtime overhead*, where optimality is under the  $\#NSETH$ assumption. Specifically, denote by $\mathcal{AM}\mathcal{TIME}^{[\rightleftharpoons c]}[T]$ a protocol with $c$ turns of interaction in which the verifier runs in polynomial time $T$. We prove that for every $\epsilon&gt;0$ there exists $\delta&gt;0$ such that:

1. $\mathcal{MATIME}[T]\subseteq \mathcal{NTIME}[T^{2+\epsilon}]$, and

2. $\mathcal{AM}\mathcal{TIME}^{[\rightleftharpoons c]}[T] \subseteq \mathcal{NTIME}[n\cdot T^{\lceil c/2 \rceil+\epsilon}]$,

where $(1)$ follows if there is a property $\Pi$ of Boolean functions that can be recognized from a $2^n$-length truth-table in $\mathcal{NTIME}[2^{(2+\epsilon/3)\cdot n}]$ such that functions with $\Pi$ are hard for $(\mathcal{N}\cap co\mathcal{N})\mathcal{TIME}[2^{(2-\delta)\cdot n}]/2^{(1-\delta)\cdot n}$; and $(2)$ follows if for every $k\ge1$ there is a $\Pi$ that can be recognized from a $2^n$-length truth-table in $\mathcal{NTIME}[2^{(k+\epsilon/3)\cdot n}]$ such that functions with $\Pi$ are hard for $\mathcal{MAMTIME}[2^{(1-\delta)\cdot k n}]/2^{(1-\delta)\cdot n}$.

To obtain faster derandomization, we introduce the notion of a *deterministic effective argument system*: This is a deterministic verifier $V$ such that correct claims $x\in L$ can be proved to $V$ (i.e., there is a proof $\pi$ such that $V(x,\pi)=1$), and for every probabilistic polynomial-time adversary $\tilde{P}$, the probability that $\tilde{P}$ finds an incorrect claim $x\notin L$ and a misleading proof $\pi$ such that $V(x,\pi)=1$ is negligible.

Under strong hardness assumptions, we prove that *any constant-round proof system can be compiled into a deterministic effective argument system, with essentially no time overhead*. As one corollary, under the foregoing hardness assumptions, for every $\epsilon&gt;0$ there is a deterministic verifier $V$ that gets as input an $n$-bit formula of size $2^{o(n)}$, runs in time $2^{\epsilon \cdot n}$, and satisfies the following: For every formula $\Phi$ there is a proof $\pi$ such that $V(\Phi,\pi)$ prints the number of satisfying assignments for $\Phi$; and for every adversary $\tilde{P}$ running in time $2^{O(n)}$, the probability that $\tilde{P}$ finds $\Phi$ and $\pi$ such that $V(\Phi,\pi)$ prints an incorrect count is $2^{-\omega(n)}$.</summary>
    <updated>2022-04-25T07:50:36Z</updated>
    <published>2022-04-25T07:50:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-889555349371097512</id>
    <link href="http://blog.computationalcomplexity.org/feeds/889555349371097512/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-problem-was-solved-before-i.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/889555349371097512" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/889555349371097512" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-problem-was-solved-before-i.html" rel="alternate" type="text/html"/>
    <title>The Roeder Problem was Solved Before I Posed it (how we missed it)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This is a joint post with David and Tomas Harris.)</p><p><br/></p><p>In my an earlier post (see <a href="https://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html">here</a>) I discussed the MATH behind a problem that I worked on, with David and Tomas Harris, that we later found out had already been solved. In this post we discuss HOW this happened. </p><p>Recall that Bill Gasarch read a column of Oliver Roeder (see <a href="https://fivethirtyeight.com/features/pick-a-number-any-number/">here</a>) on Nate Silvers' blog where he challenged his readers to the following:</p><p>Find the longest sequence using numbers from {1,...,100} such that every number is either a factor or multiple of the previous number. (A later column (see <a href="https://fivethirtyeight.com/features/is-this-bathroom-occupied/">here</a> ) revealed the answer to be 77 via a computer search, which we note is not a human-readable proof.)</p><p>Bill wrote a blog post (see <a href="https://blog.computationalcomplexity.org/2017/09/a-problem-i-thought-was-interesting-now.html">here</a>) and an open problems column (see <a href="https://www.cs.umd.edu/~gasarch/open/nate.pdf">here</a> ) asking about the general case of {1,...,n}. Before doing this Bill DID try to check the literature to see what was known, but he didn't check very hard since this was not going to be a published paper. Also, he vaguely thought that if it was a known problem then one of his readers would tell him.</p><p>QUESTION: Is it appropriate to blog on things that you have not done a search of the literature on?</p><p>ANSWER: Yes, but you should SAY SO in the blog post.</p><p>As measured by comments, the post did not generate much interest- 10 comments. 2 were me (Gasarch) responding to comments.</p><p>David (who has a PhD from UMCP under Aravind Srinivasan) asked Bill to find a HS project for his son Tomas. Bill gave Tomas the sequence problem (as he called it) to look at- perhaps write a program to find what happens for {1,...,n} for small n, perhaps find human-readable proofs of weaker bound, for small n or for n=100.</p><p>David got interested in the MATH behind the problem so the project became three projects: Tomas would look at the programing aspects and the human-readable aspects, David would look at the Math, and Bill would...  hmmm, not clear what Bill would do, but he did write up a great deal of it and cleaned up some of the proofs.</p><p>David showed</p><p>Omega( n/( (log n)^{1.68} )  LE  L(n)  LE  O( n/( (log n)^{0.79} ). </p><p>Tomas and Bill obtained a human-readable proof that L(100) LE 83. (Comments on my blog sketched a proof that L(100) LE 83, and someone else that L(100) LE 80). See my previous post (<a href="https://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html">here</a>) for more on the known numbers for L. </p><p>At that point David did a brief literature search; however, he didn't know what to look for.</p><p>BILL still thought of this as a HS project so he didn't think much about a paper coming out of it, or if it was original. So he didn't do the due diligence of seeing what was already known.</p><p>David and Tomas were busy working on it, so they only did a few cursory checks of the literature.</p><div><div><br/></div><div>With the two results above,  we had a paper! David then looked much more carefully at the literature. He DID find some earlier papers -- he did a Google search for Roeder's puzzle, which mentioned another mathematician, who was quoted in a blog by another mathematician, who eventually mentioned Pomerance's old paper on the topic. Once he found a reference to an actual math paper it was easy to use Google Scholar to find forward/backward citations and find the current state of the art.</div><div><br/></div><div>His email had subject title</div><div><br/></div><div>                        SHUT IT ALL DOWN!!!</div><div><br/></div><div>Which made Bill think it involved a nuclear reactor undergoing The China Syndrome rather than just telling us that other people did had better and earlier results. </div><div><br/></div><div><p class="MsoNormal">In 1995 Gerald Tenenbaum showed, in a paper written in French,  that there exists a,b such that </p><p class="MsoNormal">                               n/(log n)^a LE L(n) LE n/(log n)^b (see <a href="http://www.numdam.org/item/ASENS_1995_4_28_2_115_0/">here</a>). </p><p class="MsoNormal">More recently, in 2021, Saias showed, in a paper written in French, that </p><p class="MsoNormal">                                      L(n) GE (0.3 - o(1)) n/log n (see <a href="https://arxiv.org/abs/2107.03855">here</a>). </p></div><div><br/></div><div>SO, why didn't Bill, David, Tomas find that it was already known until late in the process:</div><div><br/></div><div>1) They didn't know the right search term: <i>Divisor Graph</i></div><div><br/></div><div>2) The literature was in French so the right search term is <i>graphe divisoriel</i></div><div><br/></div><div>3) The transition from FUN HS PROJECT to SERIOUS MATH PAPER was somewhat abrupt and caught Bill by surprise.</div><div><br/></div><div>Was this a disappointment?</div><div><br/></div><div>1) We all learned some math from it, so that was nice.</div><div><br/></div><div>2) We were in a position to read and understand the paper since we knew all of the difficulties --- however, it was in French which I do not read. David reads some, Tomas does not read French.  I prefer to be scooped in English, but even then  I might not be able to read up on the problem since  math is... hard. When did math get so hard? see my blog on that <a href="https://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html">here</a>. When did CS theory get so hard? See my blog on that <a href="https://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html">here</a>.)</div><div><br/></div><div>Could this happen again?</div><div><br/></div><div>1) Yes. Language barriers are hard to overcome. Though this is rare nowadays--- not much serious mathematics seems to be done outside English. French mathematicians seem to like to keep their language alive, although they probably know English as well. There may be a few other countries (China, perhaps), where English language skills are not advanced and researchers are cut off from the English literature.</div><div><br/></div><div>2) Yes. I've heard of cases where many people discovered the same theorem but were unaware of each others results since they were in different fields.</div><div><br/></div><div>3) Is it easier or harder to reprove a theorem now then it was X years ago?</div><div><br/></div></div><div>We have better search tools, but we also have more to search. </div><div><br/></div></div>
    </content>
    <updated>2022-04-25T01:19:00Z</updated>
    <published>2022-04-25T01:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-04-28T12:21:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6387</id>
    <link href="https://scottaaronson.blog/?p=6387" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6387#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6387" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On form versus meaning</title>
    <summary xml:lang="en-US">There is a fundamental difference between form and meaning. Form is the physical structure of something, while meaning is the interpretation or concept that is attached to that form. For example, the form of a chair is its physical structure – four legs, a seat, and a back. The meaning of a chair is that […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>There is a fundamental difference between form and meaning. Form is the physical structure of something, while meaning is the interpretation or concept that is attached to that form. For example, the form of a chair is its physical structure – four legs, a seat, and a back. The meaning of a chair is that it is something you can sit on.</p>



<p>This distinction is important when considering whether or not an AI system can be trained to learn semantic meaning. AI systems are capable of learning and understanding the form of data, but they are not able to attach meaning to that data. In other words, AI systems can learn to identify patterns, but they cannot understand the concepts behind those patterns.</p>



<p>For example, an AI system might be able to learn that a certain type of data is typically associated with the concept of “chair.” However, the AI system would not be able to understand what a chair is or why it is used. In this way, we can see that an AI system trained on form can never learn semantic meaning.</p>



<p>–GPT3, when I gave it the prompt “Write an essay proving that an AI system trained on form can never learn semantic meaning” <img alt="&#x1F603;" height="16" src="https://static.xx.fbcdn.net/images/emoji.php/v9/taa/1.5/16/1f603.png" width="16"/></p></div>
    </content>
    <updated>2022-04-24T21:34:19Z</updated>
    <published>2022-04-24T21:34:19Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="Procrastination"/>
    <category scheme="https://scottaaronson.blog" term="Rage Against Doofosity"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-04-27T23:41:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/056" rel="alternate" type="text/html"/>
    <title>TR22-056 |  Optimal Coding Theorems in Time-Bounded Kolmogorov Complexity | 

	Zhenjian Lu, 

	Igor Carboni Oliveira, 

	Marius Zimand</title>
    <summary>The classical coding theorem in Kolmogorov complexity states that if an $n$-bit string $x$ is sampled with probability $\delta$ by an algorithm with prefix-free domain then K$(x) \leq \log(1/\delta) + O(1)$. In a recent work, Lu and Oliveira [LO21] established an unconditional time-bounded version of this result, by showing that if $x$ can be efficiently sampled with probability $\delta$ then rKt$(x) = O(\log(1/\delta)) + O(\log n)$, where rKt denotes the randomized analogue of Levin's Kt complexity. Unfortunately, this result is often insufficient when transferring applications of the classical coding theorem to the time-bounded setting, as it  achieves a  $O(\log(1/\delta))$ bound instead of the information-theoretic optimal $\log(1/\delta)$.

Motivated by this discrepancy, we investigate optimal coding theorems in the time-bounded setting. Our main contributions can be summarised as follows.

Efficient coding theorem for rKt with a factor of $2$. Addressing a question from [LO21], we show that if $x$ can be efficiently sampled with probability at least $\delta$ then rKt$(x) \le (2 + o(1)) \cdot \log(1/\delta) + O\!\left(\log n\right)$. As in previous work, our coding theorem is efficient in the sense that it provides a polynomial-time probabilistic algorithm that, when given $x$, the code of the sampler, and $\delta$,  it outputs, with  probability $\ge 0.99$, a probabilistic representation of $x$ that certifies this rKt complexity bound.

Optimality under a cryptographic assumption. Under a hypothesis about the security of cryptographic pseudorandom generators, we show that no efficient coding theorem can achieve a bound of the form rKt$(x) \leq (2 - o(1)) \cdot \log(1/\delta) +$ poly$(\log n)$. Under a weaker assumption, we exhibit a gap between efficient coding theorems and existential coding theorems with near-optimal parameters.

Optimal coding theorem for pK$^t$ and unconditional Antunes-Fortnow. We consider pK$^t$ complexity [GKLO22], a variant of rKt where the randomness is public and the time bound is fixed. We observe the existence of an optimal coding theorem for pK$^t$, and employ this result to establish an unconditional version of a theorem of Antunes and Fortnow [AF09] which characterizes the worst-case running times of languages that are in average polynomial-time over all P-samplable distributions.</summary>
    <updated>2022-04-24T20:25:42Z</updated>
    <published>2022-04-24T20:25:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/055</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/055" rel="alternate" type="text/html"/>
    <title>TR22-055 |  Simple Hard Instances for Low-Depth Algebraic Proofs | 

	Nashlen Govindasamy, 

	Tuomas Hakoniemi, 

	Iddo  Tzameret</title>
    <summary>We prove super-polynomial lower bounds on the size of propositional proof systems operating with constant-depth algebraic circuits over fields of zero characteristic. Specifically, we show that the subset-sum variant $\sum_{i,j,k,l\in[n]} z_{ijkl}x_ix_jx_kx_l-\beta = 0$, for Boolean variables, does not have polynomial-size IPS refutations where the refutations are multilinear and written as constant-depth circuits.

Andrews and Forbes (STOC’22) established recently a constant-depth IPS lower bound, but their hard instance does not have itself small constant-depth circuits, while our instance is computable already with small depth-2 circuits. 

Our argument relies on extending the recent breakthrough lower bounds against constant-depth algebraic circuits by Limaye, Srinivasan and Tavenas (FOCS’21) to the functional lower bound framework of Forbes, Shpilka, Tzameret and Wigderson (ToC’21), and may be of independent interest. Specifically, we construct a polynomial $f$ computable with small-size constant-depth circuits, such that the multilinear polynomial computing $1/f$ over Boolean values and its appropriate set-multilinear projection are hard for constant-depth circuits.</summary>
    <updated>2022-04-24T20:24:46Z</updated>
    <published>2022-04-24T20:24:46Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/054</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/054" rel="alternate" type="text/html"/>
    <title>TR22-054 |  A Lower Bound for $k$-DNF Resolution on Random CNF Formulas via Expansion | 

	Anastasia Sofronova, 

	Dmitry Sokolov</title>
    <summary>Random $\Delta$-CNF formulas are one of the few candidates that are expected to be hard to refute in any proof system. One of the frontiers in the direction of proving lower bounds on these formulas is the $k$-DNF Resolution proof system (aka $\mathrm{Res}(k)$). Assume we sample $m$ clauses over $n$ variables. There are two known lower bounds.
1. Segerlind, Buss, Impagliazzo showed an exponential lower bound for any constant $k$, $\Delta = \mathcal{O}(k^2)$ in case $m = \mathcal{O}(n^{7 / 6})$.
2. Alekhnovich showed lower bound for $k = \mathcal{O}(\sqrt{\frac{\log n}{\log\log n}})$, any $\Delta \ge 3$ in case $m = \mathcal{O}(n)$.


Both of these papers used the same technique: the so-called small restriction switching lemma. However, they used different properties of the dependency graph of the random formula. In this paper we present a new technique with the same flavour though based on a different complexity measure that we call closure covering. We use only the expansion of the dependency graph of the formula. This technique allows us to unify and improve both of these bounds simultaneously. In particular, as a corollary we show:
1) an exponential lower bound for any constant $k$, $\Delta = \mathcal{O}(1)$ in case $m = \mathrm{poly}(n)$;
2) an exponential lower bound for $k = \mathcal{O}(\sqrt{\log n})$, $\Delta = \mathcal{O}(1)$ in case $m = \mathcal{O}(n)$.

It is the first lower bound that works for clause density $\frac{m}{n} &gt; n^{1 / 6}$ (density can even be superpolynomial for random $\log n$-CNF).</summary>
    <updated>2022-04-24T19:14:00Z</updated>
    <published>2022-04-24T19:14:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/053</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/053" rel="alternate" type="text/html"/>
    <title>TR22-053 |  On the Complexity of Algebraic Numbers, and the Bit-Complexity of Straight-Line Programs | 

	Eric Allender, 

	Nikhil Balaji, 

	Samir Datta, 

	Rameshwar Pratap</title>
    <summary>We investigate the complexity of languages that correspond to algebraic real numbers, and we present improved upper bounds on the complexity of these languages.  Our key technical contribution is the presentation of improved uniform TC^0 circuits
for division, matrix powering, and related problems, where the improvement is in terms of "majority depth" (initially studied by Maciel and Therien). As a corollary, we obtain improved bounds on the complexity of certain problems involving arithmetic circuits, which are known to lie in the counting hierarchy, and we answer a question posed by Yap.</summary>
    <updated>2022-04-23T22:56:11Z</updated>
    <published>2022-04-23T22:56:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6362</id>
    <link href="https://scottaaronson.blog/?p=6362" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6362#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6362" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Back</title>
    <summary xml:lang="en-US">Thanks to everyone who asked whether I’m OK! Yeah, I’ve been living, loving, learning, teaching, worrying, procrastinating, just not blogging. Last week, Takashi Yamakawa and Mark Zhandry posted a preprint to the arXiv, “Verifiable Quantum Advantage without Structure,” that represents some of the most exciting progress in quantum complexity theory in years. I wish I’d […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Thanks to everyone who asked whether I’m OK!  Yeah, I’ve been living, loving, learning, teaching, worrying, procrastinating, just not blogging.</p>



<hr class="wp-block-separator"/>



<p>Last week, Takashi Yamakawa and Mark Zhandry posted a preprint to the arXiv, <a href="https://arxiv.org/abs/2204.02063">“Verifiable Quantum Advantage without Structure,”</a> that represents some of the most exciting progress in quantum complexity theory in years.  I wish I’d thought of it.  tl;dr they show that relative to a random oracle (!), there’s an NP search problem that quantum computers can solve exponentially faster than classical ones.  And yet this is 100% consistent with the Aaronson-Ambainis Conjecture!</p>



<hr class="wp-block-separator"/>



<p>A student brought my attention to <a href="https://deduckproject.github.io/quantle/">Quantle</a>, a variant of Wordle where you need to guess a true equation involving 1-qubit quantum states and unitary transformations.  It’s really well-done!  Possibly the best quantum game I’ve seen.</p>



<hr class="wp-block-separator"/>



<p>Last month, Microsoft <a href="https://www.microsoft.com/en-us/research/blog/microsoft-has-demonstrated-the-underlying-physics-required-to-create-a-new-kind-of-qubit/">announced on the web</a> that it had achieved an experimental breakthrough in topological quantum computing: not <em>quite</em> the creation of a topological qubit, but some of the underlying physics required for that.  This followed their needing to <a href="https://www.nature.com/articles/d41586-021-00612-z">retract</a> their previous claim of such a breakthrough, due to the criticisms of Sergey Frolov and others.  One imagines that they would’ve taken far greater care this time around.  Unfortunately, a research paper doesn’t seem to be available yet.  Anyone with further details is welcome to chime in.</p>



<hr class="wp-block-separator"/>



<p>Woohoo!  Maximum flow, maximum bipartite matching, matrix scaling, and isotonic regression on posets (among many others)—all algorithmic problems that I was familiar with way back in the 1990s—are now solvable in nearly-linear time, thanks to a <a href="https://arxiv.org/abs/2203.00671">breakthrough by Chen et al.</a>!  Many undergraduate algorithms courses will need to be updated.</p>



<hr class="wp-block-separator"/>



<p>For those interested, Steve Hsu <a href="https://infoproc.blogspot.com/2022/04/scott-aaronson-quantum-computing.html">recorded a podcast with me</a> where I talk about quantum complexity theory.</p></div>
    </content>
    <updated>2022-04-23T22:47:09Z</updated>
    <published>2022-04-23T22:47:09Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Complexity"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-04-27T23:41:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19926</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/04/22/a-paradox/" rel="alternate" type="text/html"/>
    <title>A Paradox</title>
    <summary>If you can’t solve a problem, it’s because you’re playing by the rules—Paul Arden Dietrich Braess is a professor of mathematics at Ruhr University in Bochum, Germany. He is famous for the discovery of a paradox. When he was doing research on traffic modeling in 1968, he discovered that the flow in a road network […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you can’t solve a problem, it’s because you’re playing by the rules—Paul Arden</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2022/04/22/a-paradox/db/" rel="attachment wp-att-19928"><img alt="" class="alignright wp-image-19928" height="165" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/04/db.jpg?resize=220%2C165&amp;ssl=1" width="220"/></a></p>
<p>
Dietrich Braess is a professor of mathematics at Ruhr University in Bochum, Germany.  He is famous for the discovery of a paradox. When he was doing research on traffic modeling in 1968, he discovered that the flow in a road network could be <i>hindered</i> by <i>adding</i> a new road.</p>
<p>
Today we note a connection between him and the new ACM Athena Award winner, Éva Tardos, whom we congratulate.</p>
<p>
The paradox has a paradox riding on it.  The original is about the game theory of elective actions by drivers individually trying to optimize their routes. Yet it shows up in purely physical dynamics.  Consider the following <a href="http://www.davros.org/science/roadparadox.html">network</a> of springs and strings:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/04/22/a-paradox/par/" rel="attachment wp-att-19929"><img alt="" class="aligncenter wp-image-19929" height="192" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/04/par.png?resize=100%2C192&amp;ssl=1" width="100"/></a></p>
<p>
Quoting Clive Feathers, who <a href="http://www.davros.org/">studies</a> Britain’s railways and the London Underground:</p>
<blockquote><p><b> </b> <em> If all the strings are taut, then each of them will be carrying one-third of the weight of the block. So if the purple string is cut, the remaining strings will carry more of the weight and the block will drop down a bit as the springs take up the load, right?</em></p><em>
<p>
Wrong!</p>
</em><p><em>
As shown, each string has a tension of 4N, so the springs will each be under a tension of 8N and will stretch accordingly. Now, when the purple string is cut the remaining strings have a tension of 6N, and so does each spring. So there is less tension in the springs, and they will contract accordingly, making the block rise. </em>
</p></blockquote>
<p>
</p><p/><h2> The Braess Paradox </h2><p/>
<p/><p>
Who cares about springs and strings? Indeed. </p>
<p>
The point is that this paradox arises in problems we study in CS. It is named now as <a href="https://en.wikipedia.org/wiki/Braess's_paradox">Braess’s Paradox</a>. Springs and strings can be changed to edges. Edges in turn relate to networks of many kinds; the following figure comes from a <a href="https://iopscience.iop.org/article/10.1088/1367-2630/aad490">paper</a> on power grids:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/04/22/a-paradox/smile/" rel="attachment wp-att-19931"><img alt="" class="aligncenter wp-image-19931" height="282" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/04/smile.jpg?resize=500%2C282&amp;ssl=1" width="500"/></a></p>
<p>
The original paradox is that adding one or more roads to a road network can slow down overall traffic flow through it. The new road initially makes its use locally optimal for everyone until a saturation point <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is reached. The limit on choices before and after using the new road, however, also makes the <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> usage increase the cost of the previously optimal strategies. This evolves a worse configuration for everyone that is not locally improvable. </p>
<p>
The flip side is that a clog-prone network can sometimes be improved by removing certain parts of it. This paradox has been used to explain instances of improved traffic flow when existing major roads are closed. Here are two examples:</p>
<ul>
<li>
<a href="https://resources.mpi-inf.mpg.de/departments/d1/teaching/ws12/ct/Braess-paradox.pdf">In Stuttgart, Germany</a> after investments into the road network in 1969, the traffic situation did not improve until a section of newly-built road was closed for traffic again.<p/>
<p/></li><li>
<a href="https://www.nytimes.com/1990/12/25/health/what-if-they-closed-42d-street-and-nobody-noticed.html">ON Earth Day</a> this year (1990), New York City’s Transportation Commissioner decided to close 42d Street, which as every New Yorker knows is always congested. “Many predicted it would be doomsday,” said the Commissioner, Lucius J. Riccio. “You didn’t need to be a rocket scientist or have a sophisticated computer queuing model to see that this could have been a major problem.”<p/>
<p>
But to everyone’s surprise, Earth Day generated no historic traffic jam. Traffic flow actually improved when 42d Street was closed.</p>
</li></ul>
<p>
</p><p/><h2> Today’s News and the Paradox </h2><p/>
<p/><p>
This started as a post on Éva Tardos, who is a professor at Cornell University. She just was named the 2022-2023 ACM <a href="https://awards.acm.org/athena">Athena Lecturer</a>:</p>
<blockquote><p><b> </b> <em> This award celebrates women researchers who have made fundamental contributions to Computer Science. Each year ACM honors a preeminent woman computer scientist as the Athena Lecturer. The recipient gives an invited talk at a major ACM conference of her choice. </em>
</p></blockquote>
<p/><p>
What is the connection between Tardos as Athena Lecturer and the Braess Paradox? Indeed, the citation notes her contributions to algorithmic game theory. These are game-theory situations in her purview.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/04/22/a-paradox/et-3/" rel="attachment wp-att-19933"><img alt="" class="aligncenter wp-image-19933" height="200" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/04/et.jpg?resize=300%2C200&amp;ssl=1" width="300"/></a></p>
<p>
She has many papers that bound approximations to optimal solutions. Often the answers are likely to be hard to solve exactly—they are NP-complete for example. But she has some wonderful papers that study questions where paradoxes apply regardless of whether <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is true.</p>
<p>
One is the <a href="http://www.timroughgarden.org/papers/mcbp.pdf">paper</a> by Henry Lin, Tim Roughgarden, Eva Tardos, and Asher Walkover, and is titled, “Stronger Bounds On Braess’s Paradox And The Maximum Latency Of Selfish Routing.” It addresses the flip-side paradox: how much can the performance of a network be improved by removing one edge? One might expect that removing an edge might be less likely to improve the smallest networks, as well as less impactful on larger networks, so that the highest improvement would come in some mid-size example. In fact, they show that Braess’s original example of four nodes and five edges has the highest improvement. </p>
<p>
They also show that the problem of finding the maximum improvement possible within a sub-network of a large network is <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-hard to approximate, even sub-exponentially. We wonder how this connects to an earlier <a href="https://mathweb.ucsd.edu/~fan/wp/braess_rsa.pdf">paper</a> by Fan Chung, Stephen Young, and Wenbo Zhao showing that expander graphs tend to have many subgraphs exhibiting the Braess paradox. This is surprising because expanders by-and-large promote free network flows.</p>
<p/><p>
We add that Tardos is just the third Athena Lecturer from the theory area since the first award in 2006: Shafi Goldwasser in 2008 and Nancy Lynch in 2012. Congrats, Éva. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I did not know about the Braess Paradox before reading about her award; Ken thinks he saw it a decade or so ago. Previously my favorite result of Tardos was in the <a href="https://www.cs.cornell.edu/~eva/Gap.Between.Monotone.NonMonotone.Circuit.Complexity.is.Exponential.pdf">paper</a>, “The Gap Between Monotone And Non-Monotone Circuit Complexity Is Exponential.” Now not so clear.</p>
<p>
What is your favorite of her results?</p>
<p/></font></font></div>
    </content>
    <updated>2022-04-22T04:48:21Z</updated>
    <published>2022-04-22T04:48:21Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="ACM"/>
    <category term="approximation"/>
    <category term="Athena Award"/>
    <category term="Dietrich Braess"/>
    <category term="Eva Tardos"/>
    <category term="graphs"/>
    <category term="networks"/>
    <category term="paradox"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-04-29T12:37:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/missingness/</id>
    <link href="https://gradientscience.org/missingness/" rel="alternate" type="text/html"/>
    <title>Missingness Bias in Model Debugging</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><!-- <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> -->
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->









<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script> -->
<!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->


<!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
<!-- chart.js -->


<p><a class="bbutton" href="https://arxiv.org/abs/2204.08945" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/missingness" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Code
</a>
<br/></p>

<p><i>
“Missingness”, or the absence of features from an input, is a concept that is fundamental to many model debugging tools. In our <a href="https://arxiv.org/abs/2204.08945">latest paper</a>, we examine the challenges of implementing missingness in computer vision. In particular, we demonstrate how current approximations of missingness introduce biases into the debugging process of computer vision models. We then show how a natural implementation of missingness based on VITs can mitigate these biases and lead to more reliable model debugging.
</i></p>

<p>Deep learning models can learn powerful features. However, these learned features can be unintuitive or spurious. Indeed, recent studies have pointed out that ML models often leverage unexpected—and, in fact, undesirable—associations. These include image pathology detection models that rely on <a href="https://cerre.eu/wp-content/uploads/2020/07/ai_explainability_whitepaper_google.pdf">pen marks made by radiologist</a> and image classifiers that focus too much on <a href="https://arxiv.org/abs/2006.09994">backgrounds</a> or on <a href="https://arxiv.org/abs/1811.12231">texture</a>. Such prediction mechanisms can cause models to fail in downstream tasks or new environments.</p>

<p>How can we detect model failures caused by relying on such brittle or undesirable associations? Answering this question is a major goal of model debugging. Work in this context brought forth techniques that allow, for example, surfacing <a href="https://arxiv.org/abs/1704.05796">human aligned</a> <a href="https://gradientscience.org/glm_saga/">concepts</a>, <a href="https://gradientscience.org/3db/">probing specific types of bias a model uses</a>, or highlighting features that were <a href="https://arxiv.org/abs/1904.07451">important for a</a> <a href="https://arxiv.org/abs/1602.04938">specific prediction</a>.</p>

<p>A common theme in many of these debugging methods is to study model behavior on so-called counterfactual inputs, i.e., inputs with and without specific features. For example, consider the image of a dog being held by its owner below. By removing the owner from the image, we can study how much our model’s prediction depends on the presence of a human. In a similar vein, we can remove parts of the dog (head, body, paws) to identify which ones among them are most critical for correctly classifying the image. This concept of “the absence of a feature” from the input is sometimes referred to as <a href="https://distill.pub/2020/attribution-baselines/">missingness</a>.</p>

<p><img alt="Woman-Dog Example" src="https://gradientscience.org/assets/missingness/woman_dog_example.png" style="width: 100%;"/></p>
<div class="footnote">
        By removing parts of the image, we can study how much our model depends on a given input feature (such as the human, or the dog's snout).  
</div>

<p>Indeed, this primitive of missingness is used quite a lot in model debugging techniques. For example, widely-used methods such as <a href="https://arxiv.org/abs/1602.04938">LIME</a> and <a href="https://arxiv.org/abs/1703.01365">integrated gradients</a> leverage it. It also has been applied to <a href="https://arxiv.org/abs/1802.07623">radiology images</a> to understand the regions of the scan that are important for diagnoses, or to <a href="https://arxiv.org/abs/2110.04301">flag spurious correlations</a>. Finally, in natural language processing, model designers often remove words <a href="https://arxiv.org/abs/2010.12487">to understand their impact on the output</a>.</p>

<p><img alt="Example of LIME" src="https://gradientscience.org/assets/missingness/main_lime.png" style="width: 100%;"/></p>
<div class="footnote">
LIME, a popular model debugging method, relies on the  missingness primitive to generate model explanations. The method first generates a set of ablations by randomly removing parts of the image. These ablations are then used to generate a model explanation, typically obtained by fitting a sparse linear model to them. 
</div>

<h2 id="challenges-of-implementing-missingness-in-computer-vision">Challenges of implementing missingness in computer vision</h2>

<p>Missingness is a rather intuitive notion: we simply would like the model to predict as if the corresponding part of the input didn’t exist. Also, in a domain such as NLP implementing this primitive is fairly straightforward: we simply drop the corresponding words from the sentence. However, in the context of computer vision, its proper implementation turns out to be much more challenging. This is because images are spatially contiguous objects: it is unclear how to leave a “hole” in the image.</p>

<p>Researchers thus have come up with all kinds of ways to “fill” such hole, i.e., approximating missingness by replacing the region with other pixels. This involves <a href="https://arxiv.org/pdf/1703.01365.pdf">blacking out the pixels</a>, replacing them with <a href="https://arxiv.org/pdf/1706.03825.pdf">random noise</a>, or <a href="https://arxiv.org/pdf/1704.03296.pdf">blurring the corresponding image region</a>. However, these approaches, even though very natural, turn out to have unintended effects. For example, researchers found that <a href="https://distill.pub/2020/attribution-baselines/">saliency maps generated with integrated gradients are quite sensitive to the chosen baseline color of the filling</a>, and thus can change significantly based on the (arbitrary) choice of that missingness approximation.</p>

<p><img alt="Woman-Dog Example" src="https://gradientscience.org/assets/missingness/various_approx_original.png" style="width: 100%;"/></p>
<div class="footnote">
    Practitioners often approximate missingness in computer vision by replacing the removed region with other types of pixels. Examples include blacking out, using the mean pixel color, filling with random noise, or blurring the image.
</div>

<!-- What impact do missingness approximations have—especially with respect to model debugging? In our [recent work][arxiv], we systematically investigate how approximations like blacking out pixels can create bias, where the model uses masked out regions to make predictions rather than ignoring them. Moreover, we find that this _missingness bias_ can hinder our ability to debug models. We then show how transformer-based architectures can enable a more natural implementation of missingness, allowing us to mitigate this bias and thus improve model debugging.  -->

<h2 id="missingness-approximations-can-create-bias">Missingness approximations can create bias</h2>

<p>So, what impact do such missingness approximations actually have on the resulting model predictions? In our <a href="https://arxiv.org/abs/2204.08945">recent work</a>, we systematically investigate the bias that these approximations can imbue. Specifically, <i>we find that models end up using masked out regions to make predictions rather than simply ignoring them.</i></p>

<p>For example, take a look below at the image of a spider from ImageNet, where we have removed various regions from the image by blacking out the corresponding pixels.</p>

<div id="bias_examples_widget" style="overflow: auto; text-align: center;"/>
<div class="footnote">
    Various regions of an image are removed by blacking out pixels. Regardless of what regions from the image are masked, a ResNet-50 outputs a wrong class. 
</div>

<p>It turns out that irrespective of what subregions of the image are removed, a standard CNN (e.g., ResNet-50) outputs incorrect classes, even when most of the foreground object is not obscured. In fact, taking a closer look at the randomly masked images, we find that the model seems to be relying on the masking pattern itself to make the prediction (e.g., predicting class “crossword”).</p>

<p>To analyze this bias more quantitatively, we measure how missingness approximations impact the output class distribution of a Resnet-50 classifier (over the whole dataset).  Specifically, we iteratively black out parts of ImageNet images, and keep track of how the probability of predicting any one class changes. Before blacking out any pixels, the model predicts a roughly equal number of each class on the ImageNet test set (which is what one would expect given that this test set is class balanced). However, when we apply missingness approximations, this distribution skews heavily toward classes such as maze, crossword puzzle, and carton.</p>

<div id="anno"> 
    <canvas height="15%" id="resnet_bar_chart" width="30%"/>
</div>
<div class="footnote">
    We measure the shift in output class distribution after applying a (blacking out) missingness approximations. As patches are increasingly blacked out, the ResNet-50 classifier's predictions skew from a uniform distribution toward a few specific classes such as maze, crossword puzzle, and carton.
</div>

<p>Our <a href="https://arxiv.org/abs/2204.08945">paper</a> investigates this missingness bias in more depth by exploring different approximations, datasets, mask sizes, etc.</p>

<h2 id="missingness-bias-in-model-debugging-a-case-study-on-lime">Missingness bias in model debugging: A case study on LIME</h2>
<p>As we mentioned earlier, missingness primitive is often used by model debugging techniques—how does the above-mentioned bias impact them? To answer this question, we focus on a popular feature attribution method: local interpretable model-agnostic explanations, or <a href="https://arxiv.org/abs/1602.04938">LIME</a>.</p>

<div id="lime_examples_widget" style="overflow: auto; text-align: center;"/>
<div class="footnote">
    Examples of generated LIME explanations represented as a heat map. High-intensity regions contribute more to the prediction of the model than low-intensity ones. On the right, the top 20 image regions identified by the LIME explanation are masked in black.
</div>

<p>The image above depicts an example LIME explanation generated for a ResNet-50 classifier. Specifically, for a given image, LIME generates a heatmap highlighting the regions of the image based on how much they impact prediction (according to LIME). While sometimes LIME highlights the foreground object (which is what one would expect), in most cases it also highlights rather irrelevant regions scattered all over the image. Why is this the case?</p>

<p>Although we can’t say for sure, we suspect that this behavior is caused in large part by the fact that the underlying ResNet-50 classifier relies on masked regions in the image to make predictions, and this tricks it into believing that these regions are important. In <a href="https://arxiv.org/abs/2204.08945">our paper</a>, we perform a more detailed quantitative analysis of the missingness bias in LIME explanations, and find that it indeed makes them more inconsistent and, during evaluation, indistinguishable from random explanations.</p>

<h2 id="a-more-natural-implementation-of-missingness">A more natural implementation of missingness</h2>
<p>What is the right way to represent missing pixels then? Ideally, since replacing pixels with other pixels can lead to missingness bias, we would like to be able to remove these regions altogether. But what about the need of having the images be represented by contiguous inputs?</p>

<p>Certainly, convolutional neural networks (CNNs) require such spatial contiguity because convolutions slide filters across the image. But do we even need to use CNNs? Not really!</p>

<p>How about we turn to a different architecture:  <a href="https://arxiv.org/abs/2010.11929">vision transformers</a> (ViTs)? Unlike CNNs, ViTs do not use convolutions and operate instead on sets of patches that correspond to positionally encoded regions of the image. Specifically, a ViT has two stages when processing an input image:</p>

<ul>
  <li><strong>Tokenization</strong>: split the image into square patches, and positionally encode these patches into tokens.</li>
  <li><strong>Self-attention</strong>: pass the set of tokens through several self-attention layers.</li>
</ul>

<p>After tokenization, the self-attention layers operate on the set of tokens rather than the entire image. Thus, ViTs enables a far more natural implementation of missingness: <i>we can simply drop the tokens that encode the region we want to remove!</i></p>

<p><img alt="Woman-Dog Example" src="https://gradientscience.org/assets/missingness/vit_dropping.png" style="width: 100%;"/></p>
<div class="footnote">
    ViTs split the image into a set of tokens, where each token represents a patch in the image. In order to implement missingness, we can simply drop the tokens corresponding to the regions we would like to remove.
</div>

<h2 id="mitigating-missingness-bias-through-vits">Mitigating missingness bias through ViTs</h2>

<p>As we now demonstrate,  using this more natural implementation of missingness turns out to substantially mitigate the missingness bias that we saw earlier. Indeed, recall that, with a ResNet-50, blacking out pixels biased the model toward specific classes (such as crossword). But, a similarly sized ViT-small (ViT-S) architecture is able to side-step this bias (when we implement token dropping), maintaining a correct (or at least related) prediction.</p>

<div id="bias_examples_widget2" style="overflow: auto; text-align: center;"/>
<div class="footnote">
   When we remove image regions by dropping tokens with a ViT-S classifier, the model maintains its original prediction or, at least, predicts a related class.
</div>

<p>This difference is even more striking when we examine the output class distribution corresponding to removal of image regions: while for our ResNet-50 classifier we have seen this distribution being skewed toward certain classes, for the ViT classifier, this distribution remains close to uniform.</p>

<div id="anno"> 
    <canvas height="15%" id="vit_bar_chart" width="30%"/>
</div>
<div class="footnote">
The shift in output class distribution after dropping tokens using a ViT architecture. In contrast to the ResNet-50 classifier, ViT largely maintains its original uniform class distribution.
</div>

<h2 id="improving-model-debugging-with-vits">Improving model debugging with ViTs</h2>

<p>So, we have seen that ViTs allow us to mitigate missingness bias. Can we thus use ViTs to improve model debugging too? We return to our case study of LIME. As we demonstrated earlier, LIME relies on a notion of missingness, and is thus vulnerable to missingness bias when using approximations like blacking out pixels. What happens when we use ViTs and token dropping instead?</p>

<div id="lime_examples_widget2" style="overflow: auto; text-align: center;"/>
<div class="footnote">
Examples of generated LIME explanations for a ResNet (blacking out pixels) and a ViT (dropping tokens). 
</div>

<p>The figure above displays examples of the LIME explanations generated for a ResNet classifier and for a ViT classifier (dropping tokens). Qualitatively, one can see that the explanations for the ViT seem more aligned with human intuition, highlighting the main object instead of regions in the background. We confirm these observations with a more quantitative analysis in <a href="https://arxiv.org/abs/2204.08945">our paper</a>.</p>

<h2 id="conclusion">Conclusion</h2>
<p>In this post, we studied how missingness approximations can lead to biases and, in turn, impact the model debugging techniques that leverage them. We also demonstrated how transformer-based architectures can enable a seamless implementation of missingness that allows us to side-step missingness bias and lead to more reliable model debugging.</p>

<!-- <br><br><br><br> -->
<!-- <div id="anno"> 
  <canvas id="resnet_bar_chart" width="100%" height="35%"></canvas>
  </div>
  <div class="footnote"> Some Caption
</div>

<div id="anno"> 
  <canvas id="vit_bar_chart" width="100%" height="35%"></canvas>
  </div>
  <div class="footnote"> Some Caption
</div> -->

<!-- <div id="anno"> 
  <canvas id="entropy_plot" width="100%" height="35%"></canvas>
  </div>
  <div class="footnote"> Some Caption
</div> -->

<!-- <div id="anno"> 
  <canvas id="resnet_50_lime" width="100%" height="35%"></canvas>
  </div>
  <div class="footnote"> Some Caption
</div>


<div id="anno"> 
  <canvas id="vit_lime" width="100%" height="35%"></canvas>
  </div>
  <div class="footnote"> Some Caption
</div> --></div>
    </summary>
    <updated>2022-04-20T00:00:00Z</updated>
    <published>2022-04-20T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-04-28T22:46:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/04/19/ideal-workshop-on-clustering/</id>
    <link href="https://cstheory-events.org/2022/04/19/ideal-workshop-on-clustering/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Clustering</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">April 22-23, 2022 Northwestern University &amp; Online https://www.ideal.northwestern.edu/events/clustering/ We are inviting you to attend the IDEAL Workshop on Clustering. The workshop will take place at Northwestern University on Friday, April 22, and Saturday, April 23. It will be in a hybrid format. If you are interested in participating in the workshop (in-person or remotely), please … <a class="more-link" href="https://cstheory-events.org/2022/04/19/ideal-workshop-on-clustering/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Clustering</span></a></div>
    </summary>
    <updated>2022-04-19T15:37:34Z</updated>
    <published>2022-04-19T15:37:34Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-04-29T12:37:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/04/18/postdoc-at-university-of-texas-at-san-antonio-apply-by-april-30-2022/</id>
    <link href="https://cstheory-jobs.org/2022/04/18/postdoc-at-university-of-texas-at-san-antonio-apply-by-april-30-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Texas at San Antonio (apply by April 30, 2022)</title>
    <summary>Applicants with background in one of the following fields are invited to apply: discrete and convex geometry, algebraic algorithms, convex optimization, randomized numerical analysis, average case complexity theory. One year research only position. Please send your CV, a letter on your technical background and research interests, and two references for recommendation letters to Alperen Ergur. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applicants with background in one of the following fields are invited to apply: discrete and convex geometry, algebraic algorithms, convex optimization, randomized numerical analysis, average case complexity theory. One year research only position. Please send your CV, a letter on your technical background and research interests, and two references for recommendation letters to Alperen Ergur.</p>
<p>Website: <a href="http://alpergur.xyz">http://alpergur.xyz</a><br/>
Email: alperen.ergur@utsa.edu</p></div>
    </content>
    <updated>2022-04-18T20:10:11Z</updated>
    <published>2022-04-18T20:10:11Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-04-29T12:37:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/052</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/052" rel="alternate" type="text/html"/>
    <title>TR22-052 |  Verifying The Unseen: Interactive Proofs for Label-Invariant Distribution Properties | 

	Tal Herman, 

	Guy Rothblum</title>
    <summary>Given i.i.d. samples from an unknown distribution over a large domain $[N]$, approximating several basic quantities, including the distribution's support size, its entropy, and its distance from the uniform distribution, requires $\Theta(N / \log N)$ samples [Valiant and Valiant, STOC 2011].

Suppose, however, that we can interact with a powerful but untrusted prover, who knows the entire distribution (or a good approximation of it). Can we use such a prover to approximate (or rather, to approximately {\em verify}) such statistical quantities more efficiently? We show that this is indeed the case: the support size, the entropy, and the distance from the uniform distribution, can all be approximately verified via a 2-message interactive proof, where the communication complexity, the verifier's running time, and the sample complexity are $\widetilde{O}({\sqrt{N}})$. For all these quantities, the sample complexity is tight up to $\polylog N$ factors (for any interactive proof, regardless of its communication complexity or verification time).

More generally, we give a tolerant interactive proof system with the above sample and communication complexities for verifying a distribution's proximity to any label-invariant property (any property that is invariant to re-labeling of the elements in the distribution's support). The verifier's running time in this more general protocol is also $\widetilde{O}({\sqrt{N}})$, under a mild assumption about the complexity of deciding, given a compact representation of a distribution, whether it is in the property or far from it.</summary>
    <updated>2022-04-18T18:36:21Z</updated>
    <published>2022-04-18T18:36:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/051</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/051" rel="alternate" type="text/html"/>
    <title>TR22-051 |  Low Degree Testing over the Reals | 

	Noah Fleming, 

	Vipul Arora, 

	Arnab Bhattacharyya, 

	Esty Kelman, 

	Yuichi Yoshida</title>
    <summary>We study the problem of testing whether a function $f: \mathbb{R}^n \to \mathbb{R}$ is a polynomial of degree at most $d$ in the distribution-free testing model. Here, the distance between functions is measured with respect to an unknown distribution $\mathcal{D}$ over $\mathbb{R}^n$ from which we can draw samples. In contrast to previous work, we do not assume that $\mathcal{D}$ has finite support. 
    
We design a tester that given query access to $f$, and sample access to $\mathcal{D}$, makes $(d/\varepsilon)^{O(1)}$ many queries to $f$, accepts with probability $1$ if $f$ is a polynomial of degree $d$, and rejects with probability at least $2/3$ if every degree-$d$ polynomial $P$ disagrees with $f$ on a set of mass at least $\varepsilon$ with respect to $\mathcal{D}$. Our result also holds under mild assumptions when we receive only a polynomial number of bits of precision for each query to $f$, or when $f$ can only be queried on rational points representable using a logarithmic number of bits. Along the way, we prove a new stability theorem for multivariate polynomials that may be of independent interest.</summary>
    <updated>2022-04-18T18:34:56Z</updated>
    <published>2022-04-18T18:34:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-04-29T12:37:16Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8738724093968037845</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8738724093968037845/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/1-week-long-summer-school-for-ugrads.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8738724093968037845" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8738724093968037845" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/1-week-long-summer-school-for-ugrads.html" rel="alternate" type="text/html"/>
    <title>1-week long Summer School for Ugrads Interested in Theory, and my comments on it</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Recently a grad student in CS at UMCP emailed me the following email he got,  thinking (correctly) that I should forward it to interested ugrads. </p><p>-------------------------------------------------------</p><p>Are you interested in theoretical computer science including topics like algorithms, cryptography, machine learning, and others? If so, please consider applying to the New Horizons in Theoretical Computer Science week-long online summer school! The school will contain several mini-courses from top researchers in the field. The course is free of charge,and we welcome applications from undergraduates majoring in computer science or related fields. We particularly encourage applications from students that are members of groups that are currently under-represented in theoretical computer science.</p><p>Students from previous years have shared with us that the mini-lectures, online group activities, and interactions with other students and the friendly TAs were extraordinarily engaging and fun.</p><p>For full consideration, please complete the application (it’s short and easy!) by April 25, 2022. The summer school will take place online from June 6 to June 10.</p><p>Please see our website for details: see <a href="https://tcs-summerschool.ttic.edu/">here</a> </p><p>Any questions can be directed to summer-school-admin-2022@ttic.edu.</p><p>--------------------------------------------------------------------------</p><p>A few points about this</p><p>1) I emailed them asking `why do people need to apply if its online and free?'</p><p>I had one answer in mind, but they gave me another one</p><p><i>Their Answer: </i>They want to have SMALL online activities in groups. If they had X students and want groups of size g then if X is large, X/g may be too large. </p><p><i>My Answer</i>: If people REGISTER for something they are more likely to actually show up. (I know of a conference that got MORE people going once they had registation, and even MORE when they began charging for it.) </p><p>2) I emailed them asking if the talks will, at some later point, be on line. They will be. I then realized that there are already LOTS of theory talks online that I have not gotten around to watching, and perhaps never will. Even so, the talks on line may well benefit people who goto the summer school if they want to look back and something. </p><p>3) Online conferences PROS and CONS:</p><p>PROS: Free (or very low cost), no hassle getting airfare and hotel, and if talks are recorded then you can see them later (that applies to in-person as well). </p><p>CONS: Less committed to going to it. Can go in a half-ass way. For example, you can go and then in the middle of a talk go do your laundry. Being FORCED to be in a ROOM with the SPEAKER may be good. Also, of course, no informal conversations in the hallways.  Also, less serendipity. </p><p>I want to say <i>It would to be good to see talks outside of my area </i>however, this may only be true for easy talks, perhaps talks in a new field, OR talks that are just barely outside my area so I have some context. </p><p>4) I was surprised I didn't get the email directly since I have more contact with ugrads (and I have this blog) then the grad student who alerted me to it. However, I have learned that information gets to people in random ways so perhaps not to surprising. </p></div>
    </content>
    <updated>2022-04-18T13:54:00Z</updated>
    <published>2022-04-18T13:54:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-04-28T12:21:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>As Robert Fathauer points out (\(\mathbb{M}\)), the US “Star Ribbon” postage stamp depicts a star-shaped Möbius strip. If you slice the depicted ribbon lengthwise into two linked rings, its central white portion and outer red and blue portions, the inner part is again a Möbius strip while the outer part becomes doubly twisted and twice as long, with red on one side and blue on the other.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://twitter.com/RobFathauerArt/status/1494044593486131200">As Robert Fathauer points out</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108064413451021876">\(\mathbb{M}\)</a>),</span> the <a href="https://www.nmc.edu/about/nmc-stories/success-stories/viscomm-grad-designs-stamp.html">US “Star Ribbon” postage stamp</a> depicts a star-shaped Möbius strip. If you slice the depicted ribbon lengthwise into two linked rings, its central white portion and outer red and blue portions, the inner part is again a Möbius strip while the outer part becomes doubly twisted and twice as long, with red on one side and blue on the other.</p>
  </li>
  <li>
    <p>When its Japanese-American students were released from the concentration camps at the end of World War II, the University of Southern California refused to readmit them or even allow them to transfer their credits elsewhere <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108069391491491798">\(\mathbb{M}\)</a>).</span> Now, 80 years after the students were taken to the camps, <a href="https://www.latimes.com/california/story/2022-04-02/usc-offers-posthumous-degrees-japanese-students">USC is giving them posthumous honorary degrees</a>.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/father-son-team-solves-geometry-problem-with-infinite-folds-20220404/">Erik and Marty Demaine profiled for their work on squishing polyhedral surfaces flat</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108074681771364763">\(\mathbb{M}\)</a>),</span> in <em>Quanta</em>.</p>
  </li>
  <li>
    <p><a href="https://www.npr.org/2022/04/01/1090279187/russia-wikipedia-fine">Russian government threatens to fine Wikipedia for not sticking to Russian propaganda in its reporting of the invasion of Ukraine</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108082233497808371">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=30899708">via</a>, <a href="https://boingboing.net/2022/04/05/putins-government-threatens-to-fine-wikipedia-for-publishing-unreliable-socially-significant-information.html">see also</a>). Laughable, but the likely outcome appears to be that Wikipedia becomes blocked within Russia (as there is no possibility of complying with these demands) and Russia deepens its self-imposed isolation from civilized society.</p>
  </li>
  <li>
    <p>Longstanding but still-active theoretical CS blog “Gödel’s Lost Letter and P=NP” makes a <a href="https://rjlipton.wpcomstaging.com/2022/04/05/blogs-that-are-current/">roundup of other still-active math and theoretical CS blogs</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108089353162729425">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://www.acm.org/articles/bulletins/2022/april/50-years-backfile">ACM makes its early publications, from 1951 to 2000, open access</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108091645356237331">\(\mathbb{M}\)</a>).</span> It’s not everything I’d want, but it’s a start…</p>
  </li>
  <li>
    <p>You’re probably aware that Twitter has gradually joined Facebook and Instagram in deliberately walling itself off from the open web and making itself close-to-unusable by those of us without accounts. Manuel Grabowski writes that <a href="https://annoying.technology/posts/e6901c0ea272f57d/">it’s also becoming significantly less usable even by those with accounts</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108100999866052164">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=30949048">via</a>).</p>
  </li>
  <li>
    <p>I’m sad to hear that <a href="https://algo.rwth-aachen.de/">algorithmist Gerhard Woeginger died recently, only aged 57</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108106575959194943">\(\mathbb{M}\)</a>).</span> Much of his early work was in computational geometry (how we became coauthors), and I’ve posted on other papers of his, but some of my favorites include:</p>

    <ul>
      <li>
        <p>Surveys on exact algorithms for hard problems, in <a href="https://doi.org/10.1007/3-540-36478-1_17"><em>Combinatorial Optimization — Eureka, You Shrink!</em></a> and <a href="https://doi.org/10.1016/j.dam.2007.03.023"><em>Disc. Appl. Math.</em> 2007</a>.</p>
      </li>
      <li>
        <p>Arranging lines with given numbers of crossings, in <a href="https://doi.org/10.1016/j.tcs.2004.04.006"><em>Theor. Comput. Sci.</em> 2004</a>.</p>
      </li>
      <li>
        <p>On river-crossing puzzles, in <a href="https://doi.org/10.1137/080736661"><em>SIAM J. Disc. Math.</em> 2010</a>.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/108106319690622089">Christian Lawson-Perfect finds his perfect love match</a>: someone who agrees on the best method of stacking eggs. Which raises “Kepler’s egg-packing problem”: what is that  method, in an egg box of bounded width?</p>

    <p style="text-align: center;"><img alt="Eggs stacked in an egg box" src="https://www.ics.uci.edu/~eppstein/pix/kepleregg/Kepler-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p>It’s the long-overdue Python2 apocalypse! <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108114873951435174">\(\mathbb{M}\)</a>).</span>  I upgraded my laptop to MacOS 12.3.1 and somehow the upgrade nuked any old python2 executables I might have had in my path, so from now on everything has to be python3. Fortunately any of my old python2 scripts that I’ve tried to use so far have been very easy to fix (most complicated issue: installing Pillow to replace PIL). But I suspect that if I ever want to update and rebuild my old PyObjC-based apps, the changes will be more substantial.</p>
  </li>
  <li>
    <p><a href="https://thehighergeometer.wordpress.com/2022/04/12/its-a-messy-job-but-someone-had-to-do-it-fixing-all-the-links/">David Roberts on fixing all the old broken links from StackExchange to the “Front for the Mathematics arXiv”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108125670540879313">\(\mathbb{M}\)</a>),</span> a user interface veneer for arXiv that used to be available from UC Davis and has since gone away. You would think it would be a small matter of parsing the arXiv id in the link and replacing it with a current arXiv url for the same id, but…</p>
  </li>
  <li>
    <p><a href="https://www.science.org/content/article/russian-website-peddles-authorships-linked-reputable-journals">You may have seen <em>Science</em> on cracking a Russian pay-for-coauthorship ring</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108129289678280113">\(\mathbb{M}\)</a>).</span> As the <a href="https://arxiv.org/abs/2112.13322">associated preprint arXiv:2112.13322</a> details, many reputable publishers had their journals caught up in publications of this ring. But it also points to suspicious patterns in MDPI journals, where several people from one country were both coauthors and editors of ring papers, and coauthorship slots were advertised as reserved for those editors.</p>
  </li>
  <li>
    <p>Zugzwang describes a situation where moving first is a disadvantage, especially in games where it might usually be an advantage <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108136997760810042">\(\mathbb{M}\)</a>).</span> <em>Quanta</em> outlines <a href="https://www.quantamagazine.org/zugzwang-in-chess-math-and-pizzas-20220222/">four zugzwang puzzles in games ranging from chess to pizza-division</a>. <a href="https://www.quantamagazine.org/the-secrets-of-zugzwang-in-chess-math-and-pizzas-20220408/">Solutions</a>.</p>
  </li>
  <li>
    <p><a href="https://www.acm.org/media-center/2022/april/allen-award-2021">The ACM has given Carla Brodley their inaugural ACM Frances E. Allen Award for Outstanding Mentoring</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108139193039016625">\(\mathbb{M}\)</a>),</span> citing her work to improve the representation of women among students and faculty in her work as dean of computer science at Northeastern University, her founding of the Center for Inclusive Computing, which helps other institutions make similar improvements, and her leadership on the Computing Research Association Committee on Widening Participation.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-04-15T18:42:00Z</updated>
    <published>2022-04-15T18:42:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-04-28T00:25:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/04/15/amsi-austms-workshop-on-bridging-maths-and-computer-science/</id>
    <link href="https://cstheory-events.org/2022/04/15/amsi-austms-workshop-on-bridging-maths-and-computer-science/" rel="alternate" type="text/html"/>
    <title>AMSI–AustMS Workshop on Bridging Maths and Computer Science</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 31 – June 3, 2022 Sydney, Australia https://sites.google.com/view/2022-workshop-bridgingmathstcs/ This 4-day workshop will bring together Australian and Australasian researchers in mathematics and theoretical computer science, in view of fostering exchanges and collaborations. Specifically, the workshop will focus on two themes, “Computational Complexity and Cryptography” and “Graph Theory and Combinatorics,” from the point of view of … <a class="more-link" href="https://cstheory-events.org/2022/04/15/amsi-austms-workshop-on-bridging-maths-and-computer-science/">Continue reading <span class="screen-reader-text">AMSI–AustMS Workshop on Bridging Maths and Computer Science</span></a></div>
    </summary>
    <updated>2022-04-15T07:11:05Z</updated>
    <published>2022-04-15T07:11:05Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-04-29T12:37:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/04/15/ideal-workshop-on-clustering-friday-saturday-april-22-23-2022-840-am-400-pm-central-time-in-mudd-library-3514/</id>
    <link href="https://cstheory-events.org/2022/04/15/ideal-workshop-on-clustering-friday-saturday-april-22-23-2022-840-am-400-pm-central-time-in-mudd-library-3514/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on “Clustering” -Friday &amp; Saturday, April 22-23, 2022, 8:40 am-4:00 pm Central Time in Mudd Library 3514</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">April 22-23, 2022 Mudd Library 3514 https://www.ideal.northwestern.edu/events/clustering/ IDEAL Workshop on Clustering. The workshop will take place at Northwestern University on Friday, April 22, and Saturday, April 23, 8:40 am- 4:00 pm CST (Chicago Time) in MUDD 3514. It will be in a hybrid format. If you are interested in participating in the workshop (in-person or … <a class="more-link" href="https://cstheory-events.org/2022/04/15/ideal-workshop-on-clustering-friday-saturday-april-22-23-2022-840-am-400-pm-central-time-in-mudd-library-3514/">Continue reading <span class="screen-reader-text">IDEAL Workshop on “Clustering” -Friday &amp; Saturday, April 22-23, 2022, 8:40 am-4:00 pm Central Time in Mudd Library 3514</span></a></div>
    </summary>
    <updated>2022-04-15T07:10:42Z</updated>
    <published>2022-04-15T07:10:42Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-04-29T12:37:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=126</id>
    <link href="https://dstheory.wordpress.com/2022/04/14/wednesday-april-20th-2022-gabriel-peyre-from-cnrs-and-ens/" rel="alternate" type="text/html"/>
    <title>Wednesday April 20th 2022 — Gabriel Peyré from CNRS and ENS</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk of this year will take place on Wednesday, March 20th at 12:00 PM Pacific Time (15:00 Eastern Time, 21:00 Central European Time, 19:00 UTC). Gabriel Peyré from CNRS and Ecole Normale Supérieure will speak about “Scaling Optimal Transport for High dimensional Learning.” Please register here to join<a class="more-link" href="https://dstheory.wordpress.com/2022/04/14/wednesday-april-20th-2022-gabriel-peyre-from-cnrs-and-ens/">Continue reading <span class="screen-reader-text">"Wednesday April 20th 2022 — Gabriel Peyré from CNRS and ENS"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk of this year will take place on <strong>Wednesday, March 20th</strong> at <strong>12:00 PM Pacific Time</strong> (15:00 Eastern Time, 21:00 Central European Time, 19:00 UTC). <a href="http://www.gpeyre.com/">Gabriel Peyré</a> from<strong> CNRS and Ecole Normale Supérieure</strong> will speak about “Scaling Optimal Transport for High dimensional Learning.<em>”</em></p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p><strong>Abstract</strong>:  Optimal transport (OT) has recently gained lot of interest in machine learning. It is a natural tool to compare in a geometrically faithful way probability distributions. It finds applications in both supervised learning (using geometric loss functions) and unsupervised learning (to perform generative model fitting). OT is however plagued by the curse of dimensionality, since it might require a number of samples which grows exponentially with the dimension. In this talk, I will explain how to leverage entropic regularization methods to define computationally efficient loss functions, approximating OT with a better sample complexity. More information and references can be found on <a href="https://optimaltransport.github.io/">the website of our book</a> “Computational Optimal Transport.”</p>



<p> The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2022-04-14T13:31:09Z</updated>
    <published>2022-04-14T13:31:09Z</published>
    <category term="Announcement"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2022-04-29T12:38:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=616</id>
    <link href="https://tcsplus.wordpress.com/2022/04/14/tcs-talk-wednesday-april-20-rasmus-kyng-eth-zurich/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 20 — Rasmus Kyng, ETH Zürich</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Rasmus Kyng from ETH Zürich will speak about “Almost-Linear Time Algorithms for Maximum Flow and More” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="http://rasmuskyng.com/"><strong>Rasmus Kyng</strong></a> from ETH Zürich will speak about “<em>Almost-Linear Time Algorithms for Maximum Flow and More</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We give the first almost-linear time algorithm for computing exact maximum flows and minimum-cost flows on directed graphs. By well-known reductions, this implies almost-linear time algorithms for several problems including bipartite matching, optimal transport, and undirected vertex connectivity.</p>
<p>Our algorithm uses a new Interior Point Method (IPM) that builds the optimal flow as a sequence of an almost-linear number of approximate undirected minimum-ratio cycles, each of which is computed and processed very efficiently using a new dynamic data structure.</p>
<p>Our framework extends to give an almost-linear time algorithm for computing flows that minimize general edge-separable convex functions to high accuracy. This gives the first almost-linear time algorithm for several problems including entropy-regularized optimal transport, matrix scaling, p-norm flows, and Isotonic regression.</p>
<p>Joint work with Li Chen, Yang Liu, Richard Peng, Maximilian Probst Gutenberg, and Sushant Sachdeva.</p></blockquote></div>
    </content>
    <updated>2022-04-14T12:46:59Z</updated>
    <published>2022-04-14T12:46:59Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-04-29T12:37:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6339126729709498263</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6339126729709498263/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6339126729709498263" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6339126729709498263" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html" rel="alternate" type="text/html"/>
    <title>The Roeder Seq Problems was Solved Before I Posed it (Math)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>  (Joint Post by Bill Gasarch, David Harris, and Tomas
Harris) </p><p class="MsoNormal"/>

<p class="MsoNormal"> </p>

<p class="MsoNormal">The divisor graph D(n) is an undirected graph with</p>

<p class="MsoNormal">vertex set V={1,...,n}$ and</p>

<p class="MsoNormal">edge set E={(a,b) :  a  divides  b 
or  b  divides  a }</p>

<p class="MsoNormal">We denote the length of the longest simple path in D(n) by
L(n).</p>

<p class="MsoNormal">EXAMPLE: if n=10 then one long-ish sequence is</p>

<p class="MsoNormal">1,8,4,2,6,3,9</p>

<p class="MsoNormal">so L(10) GE 7. I leave it to the reader to do better OR to
show its optimal. </p>

<p class="MsoNormal"> </p>

<p class="MsoNormal">In 2017 Oliver Roeder asked for L(100) (see <a href="https://fivethirtyeight.com/features/pick-a-number-any-number/">here</a>)
In a later post Roeder reported that Anders Kaseorg claimed L(100)=77
(see  <a href="https://fivethirtyeight.com/features/is-this-bathroom-occupied/">here</a>).
Anders gave a sequence and claimed that, by a computer search, this was
optimal. The column also claims that other people also claimed 77 and nobody
got a sequence of length 78, so the answer probably is 77 (it is now known that
it IS 77).  Roeder also mentions the case of n=1000 for which Kaseorg
showed L(1000) GE 418. No nontrivial lower bounds are known. </p>

<p class="MsoNormal">In 2019 I (Gasarch) asked about asymptotic results for
L(n)  (see my blog post <a href="https://blog.computationalcomplexity.org/2017/09/a-problem-i-thought-was-interesting-now.html">here</a> and
my open problems column <a href="https://www.cs.umd.edu/~gasarch/open/nate.pdf">here</a>.)
I began working on it with David and Tomas Harris. David proved that </p>

<p class="MsoNormal">Omega( n/( (log n)^{1.68} )  LE  L(n) 
LE  O( n/( (log n)^{0.79} ).</p>

<p class="MsoNormal">We also studied human-readable proofs that L(100) LE X for
some reasonable X, though getting a human-readable proof for X=77 seemed
impossible. We did get L(100) LE 83, in a human-readable proof. (Some
commenters on my post to sketched a proof  that L(100) LE 83 and another
that L(100) LE 80 as well.) </p>

<p class="MsoNormal"> But it turned out that this problem had already been
studied, predating Roeder's column. (This blog post is all about the math, bout
the math, no treble.  My next post will be about how we didn't know the
literature until our paper was close to being finished.) </p>

<p class="MsoNormal">In 1982 Pomerance showed L(n)  LE o(n) (see <a href="https://math.dartmouth.edu/~carlp/divisorgraph.pdf">here</a>).
Pollington had earlier shown </p>

<p class="MsoNormal">               
                     
    L(n) GE ne^{polylog(n)};</p>

<p class="MsoNormal">however, the paper is not online and hence is lost to
history forever. (If you can find an online copy please email me the pointer
and I will edit this post.) </p>

<p class="MsoNormal">In 1995 Gerald Tenenbaum showed, in a paper written in
French,  that there exists a,b such that </p>

<p class="MsoNormal">               
               n/(log n)^a LE L(n) LE
n/(log n)^b (see <a href="http://www.numdam.org/item/ASENS_1995_4_28_2_115_0/">here</a>). </p>

<p class="MsoNormal">More recently, in 2021, Saias showed, in a paper written in
French, that </p>

<p class="MsoNormal">               
                     
L(n) GE (0.3 - o(1)) n/log n (see <a href="https://arxiv.org/abs/2107.03855">here</a>). </p><p class="MsoNormal">(ADDED LATER:  I got a very angry email telling me that the paper was in English and that I am a moron. It turns out that the abstract is in English but the paper is in French, hence the person who send the letter only read the abstract which explains their mistake.) </p>

<p class="MsoNormal">He conjectures that L(n)  SIM cn/log n where c is
likely in the interval [3,7]. (Apparently, no other information is known about
the relevant constant factors in the estimates.)</p>

<p class="MsoNormal">Interestingly, the work of Tenenbaum and Saias also
demonstrates why the study of L(n)  is not an idle problem in recreational
mathematics. The upper bounds come from results on certain density conditions
for prime factorization of random integers. That is, given an integer x chosen
uniformly at random from the range {1,..., n} with prime factorization p1 GE p2
GE ... one wants to show that, with high probability, the primes pi are close
to each other in a certain sense. Most recent results on L(n) have been tied
closely with improved asymptotic estimates for deep number theory problems.</p>

<p class="MsoNormal">Determining the value of L(100) (i.e., Roeder's problem) was
mentioned in Saias's paper. He claims that L(100) = 77 was discovered by Arnaud
Chadozeau, who himself has written a number of papers on other properties of
D(n). Since this paper was in 2021 it was after Roeder's column; however, we
believe that the different discoveries of L(100) are independent. The recent
work around Roeder's column appears to be done independently from the extensive
French-language literature on the topic.</p>

<p class="MsoNormal">The following problems are  likely still open:</p>

<p class="MsoNormal"> </p>

<p class="MsoNormal">a) Find L(n) exactly for as many n as you can.  This
would clearly need a computer program.</p>

<p class="MsoNormal">A listing of L(n) for n = 1 ... 200, computed by Rob Pratt
and Nathan McNew,</p>

<p class="MsoNormal">appears as OEIS #A337125. This also includes additional
references.</p>

<p class="MsoNormal"> </p>

<p class="MsoNormal">b) Find human-readable proofs for upper bounds on L(n)
(likely not exact) for as many</p>

<p class="MsoNormal">n as you can.</p>

<p class="MsoNormal">  </p><p class="MsoNormal"/>

<p class="MsoNormal">ADDED LATER: Gaétan Berthe emailed me </p>

<p class="MsoNormal">-----------------------------------------------------------------</p><p class="MsoNormal"/>

<p class="MsoNormal">I'm the author of the last comment on your article about
Roeder Sequence , as your curious about the subject I can share what we've done
with my friend Paul Revenant those last few years for fun.</p><p class="MsoNormal">
<br/>
It all started with a competition between our classmates (see <a href="https://perso.ens-lyon.fr/gaetan.berthe/challenge.php">here</a> though note that its in French) for the 100 and 1000 cases, after a few months Paul using a MIP solver gurobi
was able to found a solution of size 666, and last year by studying the
structure of the 666 solution we were able, with the help of gurobi again, to
prove that there was no 667 solution either.<br/>
<br/>
Paul then achieve to find very probable value of the sequence for 1 to 1000 (we
didn't automatize the proof of 666 but it should be doable). On my side I tried
to look for good solutions for the 10000 case, again using gurobi and the structure
that appeared in the solution of size 666. The structure enable to cut the
problem in two subpart, so the search goes faster I was able to find a solution
of size 5505.<br/>
<br/>
So I would say that the two mains reasons we're able to prove optimality for high
numbers as 1000 are:<br/>
<br/>
- MIP solver such as gurobi are very powerful tools.<br/>
<br/>
- The longest path in the divisor graph are highly structured.<br/>
<br/>
I joined our informal proof of the 666 case (the solution at the end), what is
interesting is to understand how the solution is composed of different blocks
depending of the prime decomposition of the elements. I joined lower bound from
1 to 1000 computed by Paul, that are very likely to be optimal.</p>

<p class="MsoNormal">---------------------------------------------------------------------------------------------------------</p>

<p class="MsoNormal">He also emailed me</p><p class="MsoNormal"/>

<p class="MsoNormal">1)  a list of the numbers I call L(n) for n=1 to 1000.
These have not been refereed though I think they are correct. The list is <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/1-1000.txt">here</a></p><p class="MsoNormal"/>

<p class="MsoNormal">AND</p>

<p class="MsoNormal">2)  a PROOF that L(1000)\le 666 (and they HAVE a
sequence of length 666, so L(1000)=666).</p>

<p class="MsoNormal">Again, not refereed, but you can read the proof
yourself <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/proof1000.pdf">here</a> WARNING- the proof is in ENGLISH, so you cannot use it to improve your
mathematical French. </p></div>
    </content>
    <updated>2022-04-11T22:37:00Z</updated>
    <published>2022-04-11T22:37:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-04-28T12:21:13Z</updated>
    </source>
  </entry>
</feed>
