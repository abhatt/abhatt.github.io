<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-31T04:22:00Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15618</id>
    <link href="http://arxiv.org/abs/2007.15618" rel="alternate" type="text/html"/>
    <title>Outlier Robust Mean Estimation with Subgaussian Rates via Stability</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pensia:Ankit.html">Ankit Pensia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15618">PDF</a><br/><b>Abstract: </b>We study the problem of outlier robust high-dimensional mean estimation under
a finite covariance assumption, and more broadly under finite low-degree moment
assumptions. We consider a standard stability condition from the recent robust
statistics literature and prove that, except with exponentially small failure
probability, there exists a large fraction of the inliers satisfying this
condition. As a corollary, it follows that a number of recently developed
algorithms for robust mean estimation, including iterative filtering and
non-convex gradient descent, give optimal error estimators with
(near-)subgaussian rates. Previous analyses of these algorithms gave
significantly suboptimal rates. As a corollary of our approach, we obtain the
first computationally efficient algorithm with subgaussian rate for
outlier-robust mean estimation in the strong contamination model under a finite
covariance assumption.
</p></div>
    </summary>
    <updated>2020-07-31T01:37:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15589</id>
    <link href="http://arxiv.org/abs/2007.15589" rel="alternate" type="text/html"/>
    <title>Efficient Tensor Decomposition</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vijayaraghavan:Aravindan.html">Aravindan Vijayaraghavan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15589">PDF</a><br/><b>Abstract: </b>This chapter studies the problem of decomposing a tensor into a sum of
constituent rank one tensors. While tensor decompositions are very useful in
designing learning algorithms and data analysis, they are NP-hard in the
worst-case. We will see how to design efficient algorithms with provable
guarantees under mild assumptions, and using beyond worst-case frameworks like
smoothed analysis.
</p></div>
    </summary>
    <updated>2020-07-31T01:31:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15551</id>
    <link href="http://arxiv.org/abs/2007.15551" rel="alternate" type="text/html"/>
    <title>Quantitative Distortion Analysis of Flattening Applied to the Scroll from En-Gedi</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Clifford Seth Parker, William Brent Seales, Pnina Shor <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15551">PDF</a><br/><b>Abstract: </b>Non-invasive volumetric imaging can now capture the internal structure and
detailed evidence of ink-based writing from within the confines of damaged and
deteriorated manuscripts that cannot be physically opened. As demonstrated
recently on the En-Gedi scroll, our "virtual unwrapping" software pipeline
enables the recovery of substantial ink-based text from damaged artifacts at a
quality high enough for serious critical textual analysis. However, the quality
of the resulting images is defined by the subjective evaluation of scholars,
and a choice of specific algorithms and parameters must be available at each
stage in the pipeline in order to maximize the output quality.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15385</id>
    <link href="http://arxiv.org/abs/2007.15385" rel="alternate" type="text/html"/>
    <title>A Novel Point Inclusion Test for Convex Polygons Based on Voronoi Tessellations</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rahman Salim Zengin, Volkan Sezer Istanbul Technical University) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15385">PDF</a><br/><b>Abstract: </b>The point inclusion tests for polygons, in other words the point in polygon
(PIP) algorithms are fundamental tools for many scientific fields related to
computational geometry and they have been studied for a long time. PIP
algorithms get direct or indirect geometric definition of a polygonal entity
and validate its containment of a given point. The PIP algorithms which are
working directly on the geometric entities derive linear boundary definitions
for the edges of the polygon. Moreover, almost all direct test methods rely on
the two point form of the line equation to partition the space into
half-spaces. Voronoi tessellations use an alternate approach for half-space
partitioning. Instead of line equation, distance comparison between generator
points is used to accomplish the same task. Voronoi tessellations consist of
convex polygons which are defined between generator points. Therefore, Voronoi
tessellations have become an inspiration for us to develop a new approach of
PIP testing specialized for convex polygons. Essential equations to the
conversion of a convex polygon to a voronoi polygon are derived along this
paper. As a reference, a very standard convex PIP testing algorithm, the sign
of offset, is selected for comparison. For generalization of the comparisons
the ray crossing algorithm is used as another reference. All algorithms are
implemented as vector and matrix operations without any branching. This enabled
us to benefit from the CPU optimizations of the underlying linear algebra
libraries. All algorithms are tested for three different polygon sizes and
varying point batch sizes. Overall, our proposed algorithm has performed better
with varying margin between 10% to 23% comparing to the reference methods.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15362</id>
    <link href="http://arxiv.org/abs/2007.15362" rel="alternate" type="text/html"/>
    <title>Synchronized Planarity with Applications to Constrained Planarity Problems</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bl=auml=sius:Thomas.html">Thomas Bläsius</a>, Simon D. Fink, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15362">PDF</a><br/><b>Abstract: </b>We introduce the problem Synchronized Planarity. Roughly speaking, its input
is a loop-free multi-graph together with synchronization constraints that,
e.g., match pairs of vertices of equal degree by providing a bijection between
their edges. Synchronized Planarity then asks whether the graph admits a
crossing-free embedding into the plane such that the orders of edges around
synchronized vertices are consistent. We show, on the one hand, that
Synchronized Planarity can be solved in quadratic time, and, on the other hand,
that it serves as a powerful modeling language that lets us easily formulate
several constrained planarity problems as instances of Synchronized Planarity.
In particular, this lets us solve Clustered Planarity in quadratic time, where
the most efficient previously known algorithm has an upper bound of
$O(n^{16})$.
</p></div>
    </summary>
    <updated>2020-07-31T01:33:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15334</id>
    <link href="http://arxiv.org/abs/2007.15334" rel="alternate" type="text/html"/>
    <title>Many Order Types on Integer Grids of Polynomial Size</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scheucher:Manfred.html">Manfred Scheucher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15334">PDF</a><br/><b>Abstract: </b>Two point configurations $\{p_1,\ldots,p_n\}$ and $\{q_1,\ldots,q_n\}$ are of
the same order type if, for every $i,j,k$, the triples $(p_i,p_j,p_k)$ and
$(q_i,q_j,q_k)$ have the same orientation. In the 1980's, Goodman, Pollack and
Sturmfels showed that (i) the number of order types on $n$ points is of order
$4^{n+o(n)}$, (ii) all order types can be realized with double-exponential
integer coordinates, and that (iii) certain order types indeed require
double-exponential integer coordinates. In 2018, Caraballo, D\'iaz-B\'a{\~n}ez,
Fabila-Monroy, Hidalgo-Toscano, Lea{\~n}os, Montejano showed that $n^{3n-o(n)}$
order types can be realized on an integer grid of polynomial size. In this
article, we show that $n^{4n-o(n)}$ order types can be realized on an integer
grid of polynomial size, which is essentially best-possible.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15306</id>
    <link href="http://arxiv.org/abs/2007.15306" rel="alternate" type="text/html"/>
    <title>Phase Transitions of the k-Majority Dynamics in a Biased Communication Model</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cruciani:Emilio.html">Emilio Cruciani</a>, Hlafo Alfie Mimun, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quattropani:Matteo.html">Matteo Quattropani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rizzo:Sara.html">Sara Rizzo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15306">PDF</a><br/><b>Abstract: </b>Consider a graph where each of the $n$ nodes is in one of two possible
states. Herein, we analyze the synchronous $k$-Majority dynamics, where nodes
sample $k$ neighbors uniformly at random with replacement and adopt the
majority state among the nodes in the sample (potential ties are broken
uniformly at random). This class of dynamics generalizes other well-known
dynamics, e.g., Voter and $3$-Majority, which have been studied in the
literature as distributed algorithms for consensus.
</p>
<p>We consider a biased communication model: whenever nodes sample a neighbor
they see state $\sigma$ with some probability $p$, regardless of the state of
the sampled node, and its true state with probability $1-p$. Differently from
previous works where specific graph topologies are considered, our analysis
only requires the graphs to be sufficiently dense, i.e., to have minimum degree
$\omega(\log n)$, without any further topological assumption.
</p>
<p>In this setting we prove two phase transition phenomena, both occurring with
high probability, depending on the bias $p$ and on the initial unbalance toward
state $\sigma$. More in detail, we prove that for every $k\geq 3$ there exists
a $p_k^\star$ such that if $p&gt;p_k^\star$ the process reaches in $O(1)$ rounds a
$\sigma$-almost-consensus, i.e., a configuration where a fraction $1-o(1)$ of
the volume is in state $\sigma$. On the other hand, if $p&lt;p_k^\star$, we look
at random initial configurations in which every node is in state $\sigma$ with
probability $1-q$ independently of the others. We prove that there exists a
constant $q_{p,k}^\star$ such that if $q &lt; q_{p,k}^\star$ then a
$\sigma$-almost-consensus is still reached in $O(1)$ rounds, while, if $q &gt;
q_{p,k}^\star$, the process spends $n^{\omega(1)}$ rounds in a metastable phase
where the fraction of volume in state $\sigma$ is around a constant value
depending only on $p$ and $k$.
</p></div>
    </summary>
    <updated>2020-07-31T01:31:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15251</id>
    <link href="http://arxiv.org/abs/2007.15251" rel="alternate" type="text/html"/>
    <title>Local Conflict Coloring Revisited: Linial for Lists</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tonoyan:Tigran.html">Tigran Tonoyan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15251">PDF</a><br/><b>Abstract: </b>Linial's famous color reduction algorithm reduces a given $m$-coloring of a
graph with maximum degree $\Delta$ to a $O(\Delta^2\log m)$-coloring, in a
single round in the LOCAL model. We show a similar result when nodes are
restricted to choose their color from a list of allowed colors: given an
$m$-coloring in a directed graph of maximum outdegree $\beta$, if every node
has a list of size $\Omega(\beta^2 (\log \beta+\log\log m + \log \log
|\mathcal{C}|))$ from a color space $\mathcal{C}$ then they can select a color
in two rounds in the LOCAL model. Moreover, the communication of a node
essentially consists of sending its list to the neighbors. This is obtained as
part of a framework that also contains Linial's color reduction (with an
alternative proof) as a special case. Our result also leads to a defective list
coloring algorithm. As a corollary, we improve the state-of-the-art truly local
$(deg+1)$-list coloring algorithm from Barenboim et al. [PODC'18] by slightly
reducing the runtime to $O(\sqrt{\Delta\log\Delta})+\log^* n$ and significantly
reducing the message size (from huge to roughly $\Delta$). Our techniques are
inspired by the local conflict coloring framework of Fraigniaud et al.
[FOCS'16].
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15220</id>
    <link href="http://arxiv.org/abs/2007.15220" rel="alternate" type="text/html"/>
    <title>The Complexity of Adversarially Robust Proper Learning of Halfspaces with Agnostic Noise</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15220">PDF</a><br/><b>Abstract: </b>We study the computational complexity of adversarially robust proper learning
of halfspaces in the distribution-independent agnostic PAC model, with a focus
on $L_p$ perturbations. We give a computationally efficient learning algorithm
and a nearly matching computational hardness result for this problem. An
interesting implication of our findings is that the $L_{\infty}$ perturbations
case is provably computationally harder than the case $2 \leq p &lt; \infty$.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15219</id>
    <link href="http://arxiv.org/abs/2007.15219" rel="alternate" type="text/html"/>
    <title>AMM: Adaptive Multilinear Meshes</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhatia:Harsh.html">Harsh Bhatia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoang:Duong.html">Duong Hoang</a>, Garrett Morrison, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Usher:Will.html">Will Usher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pascucci:Valerio.html">Valerio Pascucci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bremer:Peer=Timo.html">Peer-Timo Bremer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindstrom:Peter.html">Peter Lindstrom</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15219">PDF</a><br/><b>Abstract: </b>We present Adaptive Multilinear Meshes (AMM), a new framework that
significantly reduces the memory footprint compared to existing data
structures. AMM uses a hierarchy of cuboidal cells to create continuous,
piecewise multilinear representation of uniformly sampled data. Furthermore,
AMM can selectively relax or enforce constraints on conformity, continuity, and
coverage, creating a highly adaptive and flexible representation to support a
wide range of use cases. AMM supports incremental updates in both spatial
resolution and numerical precision establishing the first practical data
structure that can seamlessly explore the tradeoff between resolution and
precision. We use tensor products of linear B-spline wavelets to create an
adaptive representation and illustrate the advantages of our framework. AMM
provides a simple interface for evaluating the function defined on the adaptive
mesh, efficiently traversing the mesh, and manipulating the mesh, including
incremental, partial updates. Our framework is easy to adopt for standard
visualization and analysis tasks. As an example, we provide a VTK interface,
through efficient on-demand conversion, which can be used directly by
corresponding tools, such as VisIt, disseminating the advantages of faster
processing and a smaller memory footprint to a wider audience. We demonstrate
the advantages of our approach for simplifying scalar-valued data for commonly
used visualization and analysis tasks using incremental construction, according
to mixed resolution and precision data streams.
</p></div>
    </summary>
    <updated>2020-07-31T01:24:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15203</id>
    <link href="http://arxiv.org/abs/2007.15203" rel="alternate" type="text/html"/>
    <title>Algorithmic Stability in Fair Allocation of Indivisible Goods Among Two Agents</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Menon:Vijay.html">Vijay Menon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larson:Kate.html">Kate Larson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15203">PDF</a><br/><b>Abstract: </b>We propose a notion of algorithmic stability for scenarios where cardinal
preferences are elicited. Informally, our definition captures the idea that an
agent should not experience a large change in their utility as long as they
make "small" or "innocuous" mistakes while reporting their preferences. We
study this notion in the context of fair and efficient allocations of
indivisible goods among two agents, and show that it is impossible to achieve
exact stability along with even a weak notion of fairness and even approximate
efficiency. As a result, we propose two relaxations to stability, namely,
approximate-stability and weak-approximate-stability, and show how existing
algorithms in the fair division literature that guarantee fair and efficient
outcomes perform poorly with respect to these relaxations. This leads us to the
explore the possibility of designing new algorithms that are more stable.
Towards this end we present a general characterization result for pairwise
maximin share allocations, and in turn use it to design an algorithm that is
approximately-stable and guarantees a pairwise maximin share and Pareto optimal
allocation for two agents. Finally, we present a simple framework that can be
used to modify existing fair and efficient algorithms in order to ensure that
they also achieve weak-approximate-stability.
</p></div>
    </summary>
    <updated>2020-07-31T01:30:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15192</id>
    <link href="http://arxiv.org/abs/2007.15192" rel="alternate" type="text/html"/>
    <title>Branch-and-Bound Solves Random Binary Packing IPs in Polytime</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Santanu_S=.html">Santanu S. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dubey:Yatharth.html">Yatharth Dubey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molinaro:Marco.html">Marco Molinaro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15192">PDF</a><br/><b>Abstract: </b>Branch-and-bound is the workhorse of all state-of-the-art mixed integer
linear programming (MILP) solvers. These implementations of branch-and-bound
typically use variable branching, that is, the child nodes are obtained by
fixing some variable to an integer value v in one node and to v + 1 in the
other node. Even though modern MILP solvers are able to solve very large-scale
instances efficiently, relatively little attention has been given to
understanding why the underlying branch-and-bound algorithm performs so well.
In this paper our goal is to theoretically analyze the performance of the
standard variable branching based branch-and-bound algorithm. In order to avoid
the exponential worst-case lower bounds, we follow the common idea of
considering random instances. More precisely, we consider random packing
integer programs where the entries of the coefficient matrix and the objective
function are randomly sampled. Our main result is that with good probability
branch-and-bound with variable branching explores only a polynomial number of
nodes to solve these instances, for a fixed number of constraints. To the best
of our knowledge this is the first known such result for a standard version of
branch-and-bound. We believe that this result provides a compelling indication
of why branch-and-bound with variable branching works so well in practice.
</p></div>
    </summary>
    <updated>2020-07-31T01:28:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15154</id>
    <link href="http://arxiv.org/abs/2007.15154" rel="alternate" type="text/html"/>
    <title>Approximate Ridesharing of Personal Vehicles Problem</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Qian=Ping.html">Qian-Ping Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Jiajian_Leo.html">Jiajian Leo Liang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Guochuan.html">Guochuan Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15154">PDF</a><br/><b>Abstract: </b>The ridesharing problem is that given a set of trips, each trip consists of
an individual, a vehicle of the individual and some requirements, select a
subset of trips and use the vehicles of selected trips to deliver all
individuals to their destinations satisfying the requirements. Requirements of
trips are specified by parameters including source, destination, vehicle
capacity, preferred paths of a driver, detour distance and number of stops a
driver is willing to make, and time constraints. We analyze the relations
between the time complexity and parameters for two optimization problems:
minimizing the number of selected vehicles and minimizing total travel distance
of the vehicles. We consider the following conditions: (1) all trips have the
same source or same destination, (2) no detour is allowed, (3) each participant
has one preferred path, (4) no limit on the number of stops, and (5) all trips
have the same departure and same arrival time. It is known that both
minimization problems are NP-hard if one of Conditions (1), (2) and (3) is not
satisfied. We prove that both problems are NP-hard and further show that it is
NP-hard to approximate both problems within a constant factor if Conditions (4)
or (5) is not satisfied. We give $\frac{K+2}{2}$-approximation algorithms for
minimizing the number of selected vehicles when condition (4) is not satisfied,
where $K$ is the largest capacity of all vehicles.
</p></div>
    </summary>
    <updated>2020-07-31T01:29:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15133</id>
    <link href="http://arxiv.org/abs/2007.15133" rel="alternate" type="text/html"/>
    <title>Algebraic 3D Graphic Statics: Constrained Areas</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akbarzadeh:Masoud.html">Masoud Akbarzadeh</a>, Marton Hablicsek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15133">PDF</a><br/><b>Abstract: </b>This research provides algorithms and numerical methods to geometrically
control the magnitude of the internal and external forces in the reciprocal
diagrams of 3D/Polyhedral Graphic statics (3DGS). In 3DGS, the form of the
structure and its equilibrium of forces is represented by two polyhedral
diagrams that are geometrically and topologically related. The areas of the
faces of the force diagram represent the magnitude of the internal and external
forces in the system. For the first time, the methods of this research allow
the user to control and constrain the areas and edge lengths of the faces of
general polyhedrons that can be convex, self-intersecting, or concave. As a
result, a designer can explicitly control the force magnitudes in the force
diagram and explore the equilibrium of a variety of compression and
tension-combined funicular structural forms. In this method, a quadratic
formulation is used to compute the area of a single face based on its edge
lengths. The approach is applied to manipulating the face geometry with a
predefined area and the edge lengths. Subsequently, the geometry of the
polyhedron is updated with newly changed faces. This approach is a multi-step
algorithm where each step includes computing the geometry of a single face and
updating the polyhedral geometry. One of the unique results of this framework
is the construction of the zero-area, self-intersecting faces, where the sum of
the signed areas of a self-intersecting face is zero, representing a member
with zero force in the form diagram. The methodology of this research can
clarify the equilibrium of some systems that could not be previously justified
using reciprocal polyhedral diagrams. Therefore, it generalizes the principle
of the equilibrium of polyhedral frames and opens a completely new horizon in
the design of highly-sophisticated funicular polyhedral structures beyond
compression-only systems.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15125</id>
    <link href="http://arxiv.org/abs/2007.15125" rel="alternate" type="text/html"/>
    <title>Two's Company, Three's a Crowd: Consensus-Halving for a Constant Number of Agents</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deligkas:Argyrios.html">Argyrios Deligkas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filos=Ratsikas:Aris.html">Aris Filos-Ratsikas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hollender:Alexandros.html">Alexandros Hollender</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15125">PDF</a><br/><b>Abstract: </b>We consider the $\varepsilon$-Consensus-Halving problem, in which a set of
heterogeneous agents aim at dividing a continuous resource into two (not
necessarily contiguous) portions that all of them simultaneously consider to be
of approximately the same value (up to $\varepsilon$). This problem was
recently shown to be PPA-complete, for $n$ agents and $n$ cuts, even for very
simple valuation functions. In a quest to understand the root of the complexity
of the problem, we consider the setting where there is only a constant number
of agents, and we consider both the computational complexity and the query
complexity of the problem.
</p>
<p>For agents with monotone valuation functions, we show a dichotomy: for two
agents the problem is polynomial-time solvable, whereas for three or more
agents it becomes PPA-complete. Similarly, we show that for two monotone agents
the problem can be solved with polynomially-many queries, whereas for three or
more agents, we provide exponential query complexity lower bounds. These
results are enabled via an interesting connection to a monotone Borsuk-Ulam
problem, which may be of independent interest. For agents with general
valuations, we show that the problem is PPA-complete and admits exponential
query complexity lower bounds, even for two agents.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15102</id>
    <link href="http://arxiv.org/abs/2007.15102" rel="alternate" type="text/html"/>
    <title>Book Embeddings of Graph Products</title>
    <feedworld_mtime>1596153600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pupyrev:Sergey.html">Sergey Pupyrev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15102">PDF</a><br/><b>Abstract: </b>A $k$-stack layout (also called a $k$-page book embedding) of a graph
consists of a total order of the vertices, and a partition of the edges into
$k$ sets of non-crossing edges with respect to the vertex order. The stack
number (book thickness, page number) of a graph is the minimum $k$ such that it
admits a $k$-stack layout. A $k$-queue layout is defined similarly, except that
no two edges in a single set may be nested.
</p>
<p>It was recently proved that graphs of various non-minor-closed classes are
subgraphs of the strong product of a path and a graph with bounded treewidth.
Motivated by this decomposition result, we explore stack layouts of graph
products. We show that the stack number is bounded for the strong product of a
path and (i) a graph of bounded pathwidth or (ii) a bipartite graph of bounded
treewidth and bounded degree. The results are obtained via a novel concept of
simultaneous stack-queue layouts, which may be of independent interest.
</p></div>
    </summary>
    <updated>2020-07-31T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-31T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14898</id>
    <link href="http://arxiv.org/abs/2007.14898" rel="alternate" type="text/html"/>
    <title>Deterministic Distributed Expander Decomposition and Routing with Applications in Distributed Derandomization</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14898">PDF</a><br/><b>Abstract: </b>There is a recent exciting line of work in distributed graph algorithms in
the $\mathsf{CONGEST}$ model that exploit expanders. All these algorithms so
far are based on two tools: expander decomposition and expander routing. An
$(\epsilon,\phi)$-expander decomposition removes $\epsilon$-fraction of the
edges so that the remaining connected components have conductance at least
$\phi$, i.e., they are $\phi$-expanders, and expander routing allows each
vertex $v$ in a $\phi$-expander to very quickly exchange $\text{deg}(v)$
messages with any other vertices, not just its local neighbors.
</p>
<p>In this paper, we give the first efficient deterministic distributed
algorithms for both tools. We show that an $(\epsilon,\phi)$-expander
decomposition can be deterministically computed in $\text{poly}(\epsilon^{-1})
n^{o(1)}$ rounds for $\phi = \text{poly}(\epsilon) n^{-o(1)}$, and that
expander routing can be performed deterministically in
$\text{poly}(\phi^{-1})n^{o(1)}$ rounds. Both results match previous bounds of
randomized algorithms by [Chang and Saranurak, PODC 2019] and [Ghaffari, Kuhn,
and Su, PODC 2017] up to subpolynomial factors.
</p>
<p>Consequently, we derandomize existing distributed algorithms that exploit
expanders. We show that a minimum spanning tree on $n^{o(1)}$-expanders can be
constructed deterministically in $n^{o(1)}$ rounds, and triangle detection and
enumeration on general graphs can be solved deterministically in $O(n^{0.58})$
and $n^{2/3 + o(1)}$ rounds, respectively.
</p>
<p>We also give the first polylogarithmic-round randomized algorithm for
constructing an $(\epsilon,\phi)$-expander decomposition in
$\text{poly}(\epsilon^{-1}, \log n)$ rounds for $\phi = 1 /
\text{poly}(\epsilon^{-1}, \log n)$. The previous algorithm by [Chang and
Saranurak, PODC 2019] needs $n^{\Omega(1)}$ rounds for any $\phi\ge
1/\text{poly}\log n$.
</p></div>
    </summary>
    <updated>2020-07-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14775</id>
    <link href="http://arxiv.org/abs/2007.14775" rel="alternate" type="text/html"/>
    <title>Intersectional Affirmative Action Policies for Top-k Candidates Selection</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Giorgio Barnabo', <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Castillo:Carlos.html">Carlos Castillo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathioudakis:Michael.html">Michael Mathioudakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Celis:Sergio.html">Sergio Celis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14775">PDF</a><br/><b>Abstract: </b>We study the problem of selecting the top-k candidates from a pool of
applicants, where each candidate is associated with a score indicating his/her
aptitude. Depending on the specific scenario, such as job search or college
admissions, these scores may be the results of standardized tests or other
predictors of future performance and utility. We consider a situation in which
some groups of candidates experience historical and present disadvantage that
makes their chances of being accepted much lower than other groups. In these
circumstances, we wish to apply an affirmative action policy to reduce
acceptance rate disparities, while avoiding any large decrease in the aptitude
of the candidates that are eventually selected. Our algorithmic design is
motivated by the frequently observed phenomenon that discrimination
disproportionately affects individuals who simultaneously belong to multiple
disadvantaged groups, defined along intersecting dimensions such as gender,
race, sexual orientation, socio-economic status, and disability. In short, our
algorithm's objective is to simultaneously: select candidates with high
utility, and level up the representation of disadvantaged intersectional
classes. This naturally involves trade-offs and is computationally challenging
due to the the combinatorial explosion of potential subgroups as more
attributes are considered. We propose two algorithms to solve this problem,
analyze them, and evaluate them experimentally using a dataset of university
application scores and admissions to bachelor degrees in an OECD country. Our
conclusion is that it is possible to significantly reduce disparities in
admission rates affecting intersectional classes with a small loss in terms of
selected candidate aptitude. To the best of our knowledge, we are the first to
study fairness constraints with regards to intersectional classes in the
context of top-k selection.
</p></div>
    </summary>
    <updated>2020-07-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14766</id>
    <link href="http://arxiv.org/abs/2007.14766" rel="alternate" type="text/html"/>
    <title>A Progressive Approach to Scalar Field Topology</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vidal:Jules.html">Jules Vidal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guillou:Pierre.html">Pierre Guillou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierny:Julien.html">Julien Tierny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14766">PDF</a><br/><b>Abstract: </b>This paper introduces progressive algorithms for the topological analysis of
scalar data. Our approach is based on a hierarchical representation of the
input data and the fast identification of topologically invariant vertices, for
which we show that no computation is required as they are introduced in the
hierarchy. This enables the definition of efficient coarse-to-fine topological
algorithms, which leverage fast update mechanisms for ordinary vertices and
avoid computation for the topologically invariant ones. We instantiate our
approach with two examples of topological algorithms (critical point extraction
and persistence diagram computation), which generate exploitable outputs upon
interruption requests and which progressively refine them otherwise.
Experiments on real-life datasets illustrate that our progressive strategy, in
addition to the continuous visual feedback it provides, even improves run time
performances with regard to non-progressive algorithms and we describe further
accelerations with shared-memory parallelism. We illustrate the utility of our
approach in (i) batch-mode and (ii) interactive setups, where it respectively
enables (i) the control of the execution time of complete topological pipelines
as well as (ii) previews of the topological features found in a dataset, with
progressive updates delivered within interactive times.
</p></div>
    </summary>
    <updated>2020-07-30T23:30:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14569</id>
    <link href="http://arxiv.org/abs/2007.14569" rel="alternate" type="text/html"/>
    <title>Space- and Computationally-Efficient Set Reconciliation via Parity Bitmap Sketch (PBS)</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gong:Long.html">Long Gong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Ziheng.html">Ziheng Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Liang.html">Liang Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jun.html">Jun Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ogihara:Mitsunori.html">Mitsunori Ogihara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Tong.html">Tong Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14569">PDF</a><br/><b>Abstract: </b>Set reconciliation is a fundamental algorithmic problem that arises in many
networking, system, and database applications. In this problem, two large sets
A and B of objects (bitcoins, files, records, etc.) are stored respectively at
two different network-connected hosts, which we name Alice and Bob
respectively. Alice and Bob communicate with each other to learn $A\Delta B$,
the difference between A and B, and as a result the reconciled set $A\bigcup
B$.
</p>
<p>Current set reconciliation schemes are based on either Invertible Bloom
Filters (IBF) or Error-Correction Codes (ECC). The former has a low
computational complexity of O(d), where d is the cardinality of $A\Delta B$,
but has a high communication overhead that is several times larger than the
theoretical minimum. The latter has a low communication overhead close to the
theoretical minimum, but has a much higher computational complexity of
$O(d^2)$. In this work, we propose Parity Bitmap Sketch (PBS), an ECC- based
set reconciliation scheme that gets the better of both worlds: PBS has both a
low computational complexity of O(d) just like IBF-based solutions and a low
communication overhead of roughly twice the theoretical minimum. A separate
contribution of this work is a novel rigorous analytical framework that can be
used for the precise calculation of various performance metrics and for the
near-optimal parameter tuning of PBS.
</p></div>
    </summary>
    <updated>2020-07-30T23:21:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14539</id>
    <link href="http://arxiv.org/abs/2007.14539" rel="alternate" type="text/html"/>
    <title>Truncated Linear Regression in High Dimensions</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Daskalakis:Constantinos.html">Constantinos Daskalakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohatgi:Dhruv.html">Dhruv Rohatgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zampetakis:Manolis.html">Manolis Zampetakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14539">PDF</a><br/><b>Abstract: </b>As in standard linear regression, in truncated linear regression, we are
given access to observations $(A_i, y_i)_i$ whose dependent variable equals
$y_i= A_i^{\rm T} \cdot x^* + \eta_i$, where $x^*$ is some fixed unknown vector
of interest and $\eta_i$ is independent noise; except we are only given an
observation if its dependent variable $y_i$ lies in some "truncation set" $S
\subset \mathbb{R}$. The goal is to recover $x^*$ under some favorable
conditions on the $A_i$'s and the noise distribution. We prove that there
exists a computationally and statistically efficient method for recovering
$k$-sparse $n$-dimensional vectors $x^*$ from $m$ truncated samples, which
attains an optimal $\ell_2$ reconstruction error of $O(\sqrt{(k \log n)/m})$.
As a corollary, our guarantees imply a computationally efficient and
information-theoretically optimal algorithm for compressed sensing with
truncation, which may arise from measurement saturation effects. Our result
follows from a statistical and computational analysis of the Stochastic
Gradient Descent (SGD) algorithm for solving a natural adaptation of the LASSO
optimization problem that accommodates truncation. This generalizes the works
of both: (1) [Daskalakis et al. 2018], where no regularization is needed due to
the low-dimensionality of the data, and (2) [Wainright 2009], where the
objective function is simple due to the absence of truncation. In order to deal
with both truncation and high-dimensionality at the same time, we develop new
techniques that not only generalize the existing ones but we believe are of
independent interest.
</p></div>
    </summary>
    <updated>2020-07-30T23:28:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14525</id>
    <link href="http://arxiv.org/abs/2007.14525" rel="alternate" type="text/html"/>
    <title>Acutely Triangulated, Stacked, and Very Ununfoldable Polyhedra</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Martin_L=.html">Martin L. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14525">PDF</a><br/><b>Abstract: </b>We present new examples of topologically convex edge-ununfoldable polyhedra,
i.e., polyhedra that are combinatorially equivalent to convex polyhedra, yet
cannot be cut along their edges and unfolded into one planar piece without
overlap. One family of examples is acutely triangulated, i.e., every face is an
acute triangle. Another family of examples is stacked, i.e., the result of
face-to-face gluings of tetrahedra. Both families achieve another natural
property, which we call very ununfoldable: for every $k$, there is an example
such that every nonoverlapping multipiece edge unfolding has at least $k$
pieces.
</p></div>
    </summary>
    <updated>2020-07-30T23:30:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14514</id>
    <link href="http://arxiv.org/abs/2007.14514" rel="alternate" type="text/html"/>
    <title>Computing Weighted Subset Transversals in $H$-Free Graphs</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brettell:Nick.html">Nick Brettell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Johnson:Matthew.html">Matthew Johnson</a>, Daniel Paulusma <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14514">PDF</a><br/><b>Abstract: </b>For the Odd Cycle Transversal problem, the task is to find a small set $S$ of
vertices in a graph that intersects every cycle of odd length. The
generalization Subset Odd Cycle Transversal requires that $S$ only intersects
those odd cycles that include a vertex of a distinguished subset $T$ of the
vertex set. If we are also given weights for the vertices of the graph, we can
ask instead that $S$ has small weight: this is the problem Weighted Subset Odd
Cycle Transversal. We prove an almost-complete complexity dichotomy for this
problem when the input is restricted to graphs that do not contain a graph~$H$
as an induced subgraph. In particular, we show that for $(3P_1+P_2)$-free
graphs (where $P_r$ is the path on $r$ vertices) there is a polynomial-time
algorithm, but the problem is NP-complete for $5P_1$-free graphs, that is,
graphs of independence number~$4$. Thus we obtain a dichotomy with respect to
the independence number; this is an analogue of the dichotomy for Weighted
Subset Feedback Vertex Set recently obtained by Papadopoulos and Tzimas. In
contrast, Subset Feedback Vertex Set and Subset Odd Cycle Transversal have a
polynomial-time algorithm for any graph class with bounded independence number.
We also generalize the polynomial-time result of Papadopoulos and Tzimas for
Weighted Subset Feedback Vertex Set on $4P_1$-free graphs to $(3P_1+P_2)$-free
graphs. As a consequence, we show that the complexity for both of the weighted
subset transversal problems restricted to $H$-free graphs remains open for just
three particular graphs~$H$.
</p></div>
    </summary>
    <updated>2020-07-30T23:26:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.14502</id>
    <link href="http://arxiv.org/abs/2007.14502" rel="alternate" type="text/html"/>
    <title>A polynomial-time algorithm to determine (almost) Hamiltonicity of dense regular graphs</title>
    <feedworld_mtime>1596067200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Viresh.html">Viresh Patel</a>, Fabian Stroh <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14502">PDF</a><br/><b>Abstract: </b>We give a polynomial-time algorithm for detecting very long cycles in dense
regular graphs. Specifically, we show that, given $\alpha \in (0,1)$, there
exists a $c=c(\alpha)$ such that the following holds: there is a
polynomial-time algorithm that, given a $D$-regular graph $G$ on $n$ vertices
with $D\geq \alpha n$, determines whether $G$ contains a cycle on at least $n -
c$ vertices. The problem becomes NP-complete if we drop either the density or
the regularity condition. The algorithm combines tools from extremal graph
theory and spectral partitioning as well as some further algorithmic
ingredients.
</p></div>
    </summary>
    <updated>2020-07-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings</id>
    <link href="https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings.html" rel="alternate" type="text/html"/>
    <title>Polyhedra with convex unfoldings</title>
    <summary>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (arXiv:2007.14525). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I already posted a video for the paper so see that for more information.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (<a href="https://arxiv.org/abs/2007.14525">arXiv:2007.14525</a>). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">already posted a video for the paper</a> so see that for more information.</p>

<p>Instead, I thought I’d go into a little more detail about a throwaway remark in the video and the paper (one that I already got an email query about). It says that <a href="https://en.wikipedia.org/wiki/Ideal_polyhedron">ideal hyperbolic polyhedra</a> can always be unfolded (into the hyperbolic plane). These polyhedra are the hyperbolic convex hulls of finitely many limit points of the hyperbolic space; their faces are ideal polygons, glued together along entire hyperbolic lines. More strongly, if you cut an ideal polyhedron along any spanning tree of its vertices and edges, the result always unfolds into a convex ideal hyperbolic polygon. Here, for instance, is a net for an ideal cube:</p>

<p style="text-align: center;"><img alt="Net for an ideal cube" src="https://11011110.github.io/blog/assets/2020/ideal-cube-net.svg"/></p>

<p>I don’t know of a previous reference for this result, and the paper and video state it without proof (because it’s an introductory remark and not the topic of the paper), but it’s easy to prove a stronger statement by induction: any collection of ideal hyperbolic polygons (like the faces of an ideal polyhedron), when connected edge-to-edge in a complex with the connectivity of a tree (like the faces of any convex polyhedron when you cut it along a spanning tree), unfolds to an ideal convex polygon. As a base case, when you have one polygon in your collection, it unfolds to itself. When you have more than one, find a leaf polygon of the tree structure, remove it, and unfold the rest into a convex ideal polygon. Now add back the leaf. It needs to be connected to the rest of the complex along a hyperbolic line, which (by the induction hypothesis that the rest unfolds convexly) has the rest of the complex on one side and an empty hyperbolic halfplane on the other side. Any convex ideal polygon can be placed within this halfplane so that the side on which it should be glued matches up with the boundary line of the halfplane, with enough freedom to match up the points along this line that should be matched up.</p>

<p>This caused me to wonder: which Euclidean convex polyhedra have the same property, that cutting them along any spanning tree leads to a convex unfolding? The answer is: not very many. By <a href="https://en.wikipedia.org/wiki/Descartes%27_theorem_on_total_angular_defect">Descartes’ theorem on total angular defect</a>, the angular defects at the vertices of a convex polyhedron add up to . If a polyhedron is to have all spanning trees produce a (weakly) convex unfolding, then each vertex has to have angular defect at least , because otherwise cutting along a spanning tree that has a leaf at that vertex will make an unfolding that is non-convex at that vertex. And this is the only thing that can go wrong, because if all angular defects are at least  then the unfolding will be convex at each of its vertices and cannot self-overlap.</p>

<p>So to answer the question about Euclidean polyhedra with all unfoldings convex, we need only look for ways to partition the total angular defect of  among some set of vertices so that each one gets at least . If we know the defects of all the vertices and the distances between vertices, then by <a href="https://en.wikipedia.org/wiki/Alexandrov%27s_uniqueness_theorem">Alexandrov’s uniqueness theorem</a> the shape of the polyhedron will be determined. Since we’re using Alexandrov, we should also consider a <a href="https://en.wikipedia.org/wiki/Dihedron">dihedron</a> (two mirror-image convex faces glued at their edges) to be a special case of a polyhedron. This leaves, as the only cases:</p>

<ul>
  <li>
    <p>A triangular dihedron based on a right or acute triangle.</p>
  </li>
  <li>
    <p>A rectangular dihedron.</p>
  </li>
  <li>
    <p>A tetrahedron with angular defect exactly  at each vertex.</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="Convex unfoldings of dihedra and a disphenoid" src="https://11011110.github.io/blog/assets/2020/convex-unfoldings.svg"/></p>

<p>The unfoldings of the dihedra have two copies of their face, mirrored across a joining edge. The tetrahedra with all-convex unfoldings are exactly the <a href="https://en.wikipedia.org/wiki/Disphenoid">disphenoids</a>, the tetrahedra whose four faces are congruent. They unfold either to a copy of the same face shape,
expanded by a factor of two in each dimension and creased into four copies along its <a href="https://en.wikipedia.org/wiki/Medial_triangle">medial triangle</a>, or a parallelogram, creased to form a strip of four congruent triangles. Their unfoldings were discussed by Jin Akiyama in his paper “Tile-makers and semi-tile-makers” (<em>American Mathematical Monthly</em> 2007, <a href="https://doi.org/10.1080/00029890.2007.11920450">doi:10.1080/00029890.2007.11920450</a>, <a href="https://www.jstor.org/stable/27642275">jstor:27642275</a>), as part of a broader investigation of polyhedra whose every unfolding tiles the plane.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104601177683049272">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-29T22:18:00Z</updated>
    <published>2020-07-29T22:18:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-30T05:36:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/" rel="alternate" type="text/html"/>
    <title>Junior Fellowship / Andvanced Fellowship at ETH Institute for Theoretical Studies in Zurich (apply by September 23, 2020)</title>
    <summary>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years. Website: https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html Email: nominations@eth-its.ethz.ch</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years.</p>
<p>Website: <a href="https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html">https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html</a><br/>
Email: nominations@eth-its.ethz.ch</p></div>
    </content>
    <updated>2020-07-29T14:52:31Z</updated>
    <published>2020-07-29T14:52:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-31T04:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/114</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/114" rel="alternate" type="text/html"/>
    <title>TR20-114 |  Disjointness through the Lens of Vapnik–Chervonenkis Dimension: Sparsity and Beyond | 

	Anup Bhattacharya, 

	Sourav Chakraborty, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</title>
    <summary>The disjointness problem - where Alice and Bob are given two subsets of $\{1, \dots, n\}$ and they have to check if their sets intersect - is a central problem in the world of communication complexity. While both deterministic and randomized communication complexities for this problem are known to be $\Theta(n)$, it is also known that if the sets are assumed to be drawn from some restricted set systems then the communication complexity can be much lower. In this work, we explore how communication complexity measures change with respect to the complexity of the underlying set system. The complexity measure for the set system that we use in this work is the Vapnik–Chervonenkis (VC) dimension. More precisely, on any set system with VC dimension bounded by $d$, we analyze how large can the deterministic and randomized communication complexities be, as a function of $d$ and $n$.  The $d$-sparse set disjointness problem, where the sets have size at most $d$, is one such set system with VC dimension $d$. The deterministic and the randomized communication complexities of the $d$-sparse set disjointness problem have been well studied and is known to be $\Theta \left( d \log \left({n}/{d}\right)\right)$ and $\Theta(d)$, respectively, in the multi-round communication setting. In this paper, we address the question of whether the randomized communication complexity is always upper bounded by a function of the VC dimension of the set system, and does there always exist a gap between the deterministic and randomized communication complexity for set systems with small VC dimension. 

In this paper, we construct two natural set systems of VC dimension $d$, motivated from geometry. Using these set systems we show that the deterministic and randomized communication complexity can be $\widetilde{\Theta}\left(d\log \left( n/d \right)\right)$ for set systems of VC dimension $d$ and this matches the deterministic upper bound for all set systems of VC dimension $d$. We also study the deterministic and randomized communication complexities of the set intersection problem when sets belong to a set system of bounded VC dimension. We show that there exists set systems of VC dimension $d$ such that both deterministic and randomized (one-way and multi-round) complexities for the set intersection problem can be as high as $\Theta\left( d\log \left( n/d \right) \right)$, and this is tight among all set systems of VC dimension $d$.</summary>
    <updated>2020-07-29T14:15:30Z</updated>
    <published>2020-07-29T14:15:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-31T04:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/113</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/113" rel="alternate" type="text/html"/>
    <title>TR20-113 |  Relaxed Locally Correctable Codes with Nearly-Linear Block Length and Constant Query Complexity | 

	Tom Gur, 

	Igor Shinkar, 

	Alessandro Chiesa</title>
    <summary>Locally correctable codes (LCCs) are error correcting codes C : \Sigma^k \to \Sigma^n which admit local algorithms that correct any individual symbol of a corrupted codeword via a minuscule number of queries. This notion is stronger than that of locally decodable codes (LDCs), where the goal is to only recover individual symbols of the message. One of the central problems in algorithmic coding theory is to construct O(1)-query LCCs and LDCs with minimal block length. Alas, state-of-the-art of such codes requires super-polynomial block length to admit O(1)-query algorithms for local correction and decoding, despite much attention during the last two decades.

This lack of progress prompted the study of relaxed LCCs and LDCs, which allow the correction algorithm to abort (but not err) on a small fraction of the locations. This relaxation turned out to allow constant-query correcting and decoding algorithms for codes with polynomial block length. Focusing on local correction, Gur, Ramnarayan, and Rothblum (ITCS~2018) showed that there exist O(1)-query relaxed LCCs that achieve nearly-quartic block length n = k^{4+\alpha}, for an arbitrarily small constant \alpha&gt;0.

We construct an O(1)-query relaxed LCC with nearly-linear block length n = k^{1+\alpha}, for an arbitrarily small constant \alpha&gt;0. This significantly narrows the gap between the lower bound which states that there are no O(1)-query relaxed LCCs with block length n = k^{1+o(1)}. In particular, our construction matches the parameters achieved by Ben-Sasson et al. (SIAM J. Comput. 2006), who constructed relaxed LDCs with the same parameters. This resolves an open problem raised by Gur, Ramnarayan, and Rothblum (ITCS 2018).</summary>
    <updated>2020-07-27T20:27:01Z</updated>
    <published>2020-07-27T20:27:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-31T04:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/112</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/112" rel="alternate" type="text/html"/>
    <title>TR20-112 |  Simulating DQBF Preprocessing Techniques with Resolution Asymmetric Tautologies | 

	Joshua Blinkhorn</title>
    <summary>Dependency quantified Boolean formulas (DQBF) describe an NEXPTIME-complete generalisation of QBF, which in turn generalises SAT. QRAT is a recently proposed proof system for quantified Boolean formulas (QBF), which simulates the full suite of QBF preprocessing techniques and thus forms a uniform proof checking format for solver verification.

In this work, we study QRAT in the more general DQBF context, obtaining a sound and complete refutational DQBF proof system that we call DQRAT. We show that DQRAT can simulate the full suite of dedicated DQBF preprocessing techniques, except those relying on defined variables, which we cover with the introduction of a new form of prefix modification. Our work enables generalisations of further QBF preprocessing techniques (e.g. blocked literal elimination) that were not previously considered for DQBF.</summary>
    <updated>2020-07-27T19:18:09Z</updated>
    <published>2020-07-27T19:18:09Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-31T04:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17349</id>
    <link href="https://rjlipton.wordpress.com/2020/07/27/a-brilliant-book-on-combinatorics/" rel="alternate" type="text/html"/>
    <title>A Brilliant Book on Combinatorics</title>
    <summary>And Razborov’s brilliant proof method Stasys Jukna is the author of the book Extremal Combinatorics With Applications in Computer Science. Today we talk about Jukna’s book on extremal combinatorics. The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And Razborov’s brilliant proof method</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/07/jukna1.png"><img alt="" class="alignright size-full wp-image-17351" src="https://rjlipton.files.wordpress.com/2020/07/jukna1.png?w=600"/></a></p>
<p>
Stasys Jukna is the author of the <a href="https://www.google.com/books/edition/Extremal_Combinatorics/NV3Y8vjWo8kC?hl=en&amp;gbpv=1">book</a> <em>Extremal Combinatorics With Applications in Computer Science</em>. </p>
<p>
Today we talk about Jukna’s book on extremal combinatorics.</p>
<p>
The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we might highlight one tiny part—the part on monotone circuit lower bounds. Here goes. All below is based directly on his discussion. Any errors or misguided comments are ours.</p>
<p>
</p><p/><h2> Monotone Boolean Functions </h2><p/>
<p/><p>
Fix an input size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and consider some property of subsets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Let <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> exactly when <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has the property. We can think of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as a Boolean function. You believe that this property is hard to compute—how do you go about proving that? </p>
<p>
In general we have no tools, but if the property is monotone, then there are some powerful methods. Recall <em>monotone</em> means that if <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> then any set <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> so that <img alt="{S \subset T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \subset T}"/> still has the property. For example, <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/> could be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> includes at least half of the elements of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. It cannot be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has an even number of elements. Another example is when <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is given in <em>disjunctive normal form</em> (DNF), </p>
<p align="center"><img alt="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+T_1+%5Cvee+T_2+%5Cvee+%5Ccdots+T_m%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, "/></p>
<p>where each <b>term</b> <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is a conjunction of variables. Each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> can be regarded as a subset of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \supseteq T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csupseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \supseteq T_k}"/> for some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. Every monotone function also has a <em>conjunctive normal form</em> (CNF) </p>
<p align="center"><img alt="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+C_f+%3D+C_1+%5Cwedge+C_2+%5Cwedge+%5Ccdots+%5Cwedge+C_%5Cell%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, "/></p>
<p>where each <b>clause</b> <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> is a disjunction of variables. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \cap C_k \neq \emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+C_k+%5Cneq+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \cap C_k \neq \emptyset}"/> for <em>all</em> <img alt="{k.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k.}"/> The problem is that the numbers <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> of terms and <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> of clauses involved may be huge. The clauses may have different sizes. Given a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, we write <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> for the conjunction of clauses of size exactly <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> and <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> for the rest. We similarly write <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> for DNFs <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>.</p>
<p>
The lower bound methods are on the size of a monotone circuit for <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/>. That is the circuit can only use gates <img alt="{AND}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAND%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AND}"/> and <img alt="{OR}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BOR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{OR}"/>, but no other types of gates, especially not <img alt="{NOT}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BNOT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{NOT}"/> gates. Of course, if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has no small monotone circuits, then it has no small DNF or CNF formulas either. </p>
<p>
The neat fact on which the lower-bound technique builds is that if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> <b>does</b> have small monotone circuits, then we can “wrap” it between a CNF and a DNF in various customizable ways:</p>
<blockquote><p><b>Theorem 1 (informal)</b> <em><a name="informal"/> For every <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> with small monotone circuits and <img alt="{r,s &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s &gt; 0}"/> we can find a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> and a DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of maximum term size <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r}"/> such that </em></p><em>
<p align="center"><img alt="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cleq+f+%5Cleq+D+%5Cqquad%5Ctext%7Band+also%7D%5Cqquad+D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. "/></p>
</em><p><em>Moreover, <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D^r}"/> are small. </em>
</p></blockquote>
<p/><p>
We have said “wrap” not “sandwich” because although <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the “upper slice,” the part of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> with smaller terms—but there could be many of them—wraps around to be under the corresponding part of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. This fact will enable us to throw away the smaller clauses and terms. How small is “small”? We will say later. We are trying to solve problems of exposition by keeping a high-level view at the start. </p>
<p>
</p><p/><h2> Exposition Problems </h2><p/>
<p/><p>
Tim Gowers has written an <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.8986&amp;rep=rep1&amp;type=pdf">article</a> about the lower method for monotone functions. The method is due to Alexander Razborov in his seminal 1985 <a href="http://people.cs.uchicago.edu/~razborov/files/clique.pdf">paper</a> and extended by Noga Alon and Ravi Boppana in their <a href="https://core.ac.uk/download/pdf/191378189.pdf">paper</a> right afterward, and by Benjamin Rossman in his 2009 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5526&amp;rep=rep1&amp;type=pdf">paper</a>, to name a few. </p>
<p>
Gowers says right away that the original papers on this method are clear and well written. But he believes that there is need for more exposition. The method is so important that it must be made easy for all to understand. He says his article is an attempt to solve an <i>open exposition problem</i>. The notion of an exposition problem is due to Timothy Chow who <a href="https://arxiv.org/pdf/0712.1320.pdf">wrote</a>:</p>
<blockquote><p><b> </b> <em> All mathematicians are familiar with the concept of an open research problem. I propose the less familiar concept of an open exposition problem. </em>
</p></blockquote>
<p/><p>
Chow raised this issue with respect to the forcing method in set theory due to Paul Cohen. A modest suggestion: Read Chow on forcing, a great exposition; read Gowers on the monotone lower bound method, another great one. Both are much better than anything we can do. But we will put our own spin on the lower bound method. And hope to add to the quest to solve the exposition problem. </p>
<p/><h2> The Method—High Level </h2><p/>
<p/><p>
Suppose that <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is a monotone boolean circuit that has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs and computes <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> at the last gate. The method is called the <i>approximation method</i> because the idea is that it builds two other boolean functions <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/>: for all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{\{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^{n}}"/>: </p>
<p align="center"><img alt="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Blower%7D%28x%29+%5Cle+f%28x%29+%5Cle+%5Cmathsf%7Bupper%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). "/></p>
<p>This follows a tradition in math that we often replace a complex function, <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>, with simpler upper and lower bounds. Standard stuff. </p>
<p>
Usually the point is that the approximators are not only easier to understand but also simpler in some objective sense. For example, Christophe Chesneau and Yogesh Bagul give a nice short <a href="https://hal.archives-ouvertes.fr/hal-01934571/document">compendium</a> of approximating formulas involving trigonometric functions by formulas without them, including that for all <img alt="{0&lt;x&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cx%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;x&lt;1}"/>, </p>
<p align="center"><img alt="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexp%28-bx%5E%7B2%7D%29+%3C+%5Csin%28x%29%2Fx+%3C+%5Cexp%28-x%5E%7B2%7D%2F6%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), "/></p>
<p>with <img alt="{b \approx 0.172604}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Capprox+0.172604%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \approx 0.172604}"/>. If you have to reason about the behavior of <img alt="{\sin(x)/x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csin%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sin(x)/x}"/>, it is nice to have these upper and lower bounds. Note that the upper bound kind-of wraps around because it is the same kind of function as the lower bound.</p>
<p>
What gives the monotone method a special twist is that <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/> are not necessarily simple in the sense of being small.  Rather, they <em>make simple errors</em>—ones that can be corrected with small effort. The correction process yields <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r.}"/>  Isolating what is small, however, requires us to trade an “AND” of two inequalities for an “OR” of two economical ones. We know that at least one of the latter inequalities must be true. We arrange that either one gives us the kind of lower bound we seek. </p>
<p>
</p><p/><h2> Some More Detail </h2><p/>
<p/><p>
Here is how the trade happens. From Theorem <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> we have: </p>
<p align="center"><img alt="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cwedge+C%5E%7B%3Cs%7D+%5Cleq+f+%5Cleq+D%5E%7B%3Cr%7D+%5Cvee+D%5Er%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, "/></p>
<p>where: <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> are small, and while <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> might be big, we have <img alt="{D^{&lt;r} \leq C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r} \leq C^{&lt;s}}"/>. The trick is to ask:</p>
<blockquote><p><b> </b> <em> Is <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> empty—that is, is it the trivial <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> function? </em>
</p></blockquote>
<p>
</p><ul>
<li>
If <em>yes</em>, then it goes away on the left-hand side. We get: <p/>
<p align="center"><img alt="\displaystyle  C^s \leq f. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cleq+f.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \leq f. "/></p>
<p>Since <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> is small, this is something we want. We got a small lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that holds for <b>all</b> arguments <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. </p>
</li><li>
If <em>no</em>, then it has a nontrivial clause corresponding to a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s-1}"/>. This is where the wraparound comes in. We have: <p/>
<p align="center"><img alt="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D+%5Cleq+E%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, "/></p>
<p>since we chose at least one clause. Substituting on the right-hand side thus gives us: </p>
<p align="center"><img alt="\displaystyle  f \leq E \vee D^r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cleq+E+%5Cvee+D%5Er.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \leq E \vee D^r. "/></p>
<p>Now <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> is small, since it is just one clause, and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> is small. We got a small upper bound rather than lower bound, but the fact that it has a restricted form and holds for <b>all</b> cases we can input to <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> will give us a lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>.
</p></li></ul>
<p>
Finally we are ready to state the theorem, which quantifies “small.” To follow Jukna, we now need to replace “<img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>” by “<img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r+1}"/>” and “<img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>” by “<img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.” But the essence is the same.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="tsimple"/> If <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has a monotone Boolean circuit of size <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>, then for any <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s}"/> such that <img alt="{1 \leq r,s \leq n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+r%2Cs+%5Cleq+n-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \leq r,s \leq n-1}"/>, we can build a conjunction <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of at most <img alt="{t \cdot r^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+r%5E%7Bs%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot r^{s+1}}"/> clauses of size exactly <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s+1}"/>, a disjunction <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of at most <img alt="{t \cdot s^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+s%5E%7Br%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot s^{r+1}}"/> terms of size exactly <img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r+1}"/>, and a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> such that either <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C \leq f}"/> or <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. </em>
</p></blockquote>
<p/><p>
Rather than re-prove this, we will continue the discussion with a concrete example. An exposition trick is: give examples before the general case and then abstract. Our example will involve graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>—so the variables have the form <img alt="{x_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j}}"/>, where <img alt="{x_{i,j} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 1}"/> means there is an edge between vertex <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and vertex <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/>, <img alt="{x_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 0}"/> otherwise. Putting <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> as the number of vertices, the number of possible edges is <img alt="{n = \binom{m}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%5Cbinom%7Bm%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = \binom{m}{2}}"/>. We think of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> as a set of edges, so <img alt="{G \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \subseteq [n]}"/>.</p>
<p>
</p><p/><h2> Checking for Triangles </h2><p/>
<p/><p>
Let <img alt="{f(G)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)=1}"/> hold precisely when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> has a triangle. This is clearly a monotone property. Our goal is to use the lower and upper bounds to prove that the monotone complexity of <img alt="{f(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)}"/> is almost of order <img alt="{m^{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m^{3}}"/>. A side note is that the general complexity is much less via <img alt="{m \times m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times m}"/> matrix products. </p>
<p>
The first beauty of using the method is that <em>you</em> get to choose the parameters <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> with a goal <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in mind. The <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> must be in <img alt="{[1,n-1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B1%2Cn-1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[1,n-1]}"/>. The value of <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> will be a lower bound on the size of any monotone boolean circuit for <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. The parameters <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r,s}"/> are bounds on the clause and term size of the DNF and the CNF. You can select them any way you wish. But of course choose them wisely.</p>
<p>
In this case we know that <img alt="{r=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r=1}"/> is a right choice. We will say what <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> is later but we will have <img alt="{s=(\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%3D%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s=(\log n)^{O(1)}}"/>. Once you pick them, the CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> and DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> (and small set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/>, a set of <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log n)}"/> edges in this case) are chosen for you. You have no control over the sets <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> that make up the terms of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> and the sets <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> that correspond to the clauses of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Well you do know something about them. Here is what you do know about how many sets there are and how big the sets are:</p>
<ol>
<li>
For <img alt="{k=1,\dots,t \cdot s^{r+1} = ts^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%2C%5Cdots%2Ct+%5Ccdot+s%5E%7Br%2B1%7D+%3D+ts%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1,\dots,t \cdot s^{r+1} = ts^2}"/>, each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is of size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. <p/>
</li><li>
For <img alt="{\ell=1,\dots, t \cdot r^{s+1} = t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%3D1%2C%5Cdots%2C+t+%5Ccdot+r%5E%7Bs%2B1%7D+%3D+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell=1,\dots, t \cdot r^{s+1} = t}"/>, each <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> is of size <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.
</li></ol>
<p>The goal in either case is to force <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> to be large. We’ve numbered the right-hand case first.</p>
<ol>
<li>
Case <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> that <b>do</b> have a triangle—and nothing else. Because <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> includes at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> edges, hence touches at most <img alt="{2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s}"/> vertices, and <img alt="{2s \ll m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s+%5Cll+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s \ll m}"/>, we can focus on triangles among the <img alt="{m' = m - 2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%27+%3D+m+-+2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m' = m - 2s}"/> untouched vertices. There are <img alt="{T = \binom{m'}{3} = \Theta(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5Cbinom%7Bm%27%7D%7B3%7D+%3D+%5CTheta%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \binom{m'}{3} = \Theta(m^3)}"/> such triangles, hence <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> to consider.<p/>
<p>
Since these graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> have no edges in <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> but make <img alt="{f(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 1}"/>, there must be some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> such that <img alt="{T_k(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k(G) = 1}"/>. Since <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, this means <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has two edges of the triangle. Now the point is:</p>
<blockquote><p><b> </b> <em> For each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/>, there is at most <b>one</b> triangle that <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/> can be two edges of. </em>
</p></blockquote>
<p/><p>
Hence there must be at least as many terms as possible triangles. This means: </p>
<p align="center"><img alt="\displaystyle  ts^2 \geq \binom{m'}{3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++ts%5E2+%5Cgeq+%5Cbinom%7Bm%27%7D%7B3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  ts^2 \geq \binom{m'}{3}. "/></p>
<p>Because <img alt="{s = (\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs+%3D+%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s = (\log n)^{O(1)}}"/>, we finally get <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/>, where the tilde means to ignore factors of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>.</p>
<p/></li><li>
Case <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> such that <img alt="{f(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 0}"/> but <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is chock full of as many edges as one can have without creating a triangle. Such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> include complete bipartite graphs. There are <img alt="{2^{m-1} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm-1%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m-1} - 1}"/> such graph inputs, as can be realized from how any binary string <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> except <img alt="{0^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^m}"/> and <img alt="{1^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1^m}"/> encodes such a graph—and only its bit-complement <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> encodes the same labeled graph.<p/>
<p>
In order to keep <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/> we need <img alt="{C(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(G) = 0}"/> for all such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>, so we need (at least) one clause <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> to <em>fail</em> on <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. This means that all vertices touched by the edges in <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> must be in the same partition. The more vertices touched, the fewer strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> have all <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s (or all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>s) in the corresponding positions, which means the fewer graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> “covered” by that clause. We want to know how many clauses we need to cover all these graphs, hence we try to minimize the number of vertices touched by each clause. That number is at least <img alt="{s' = \lceil \sqrt{2s}\rceil}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3D+%5Clceil+%5Csqrt%7B2s%7D%5Crceil%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' = \lceil \sqrt{2s}\rceil}"/>. The number of graphs we cover is at most <img alt="{2^{m - s'} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm+-+s%27%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m - s'} - 1}"/> (the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> excludes the empty graph). Thus the number <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> of clauses we need satisfies </p>
<p align="center"><img alt="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%5Cgeq+%5Cfrac%7B2%5E%7Bm-1%7D+-+1%7D%7B2%5E%7Bm+-+s%27%7D+-+1%7D+%5Cgeq+2%5E%7Bs%27+-+1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. "/></p>
<p>By taking <img alt="{s' &gt; 4.5\log^2 m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3E+4.5%5Clog%5E2+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' &gt; 4.5\log^2 m}"/> we can make <img alt="{t \geq m^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Cgeq+m%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t \geq m^3}"/> in this case. We can actually get bigger functions with bigger <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, but this balances against case 1 where <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/> was the best we could do, so that is our lower bound.
</p></li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in understanding the approximation method? Can you work out the concretely optimum choice of <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the triangle example?</p>
<p>
Would you prefer not changing <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a>? Then we would have worded the triangle example with “<img alt="{r = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 2}"/>” rather than “<img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/>.” The former is a little more suggestive of the idea of having two edges of a triangle. Doing so, however, could make notation in the proof of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a> somewhat messier. Another possibility was keeping Jukna’s usage throughout, so that the earlier version <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> of the theorem would say <img alt="{D^{\leq r} \leq C^{\leq s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%5Cleq+r%7D+%5Cleq+C%5E%7B%5Cleq+s%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{\leq r} \leq C^{\leq s}}"/> with <img alt="{C^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7Bs%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{s+1}}"/> and <img alt="{D^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7Br%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{r+1}}"/> being small. We try to solve “exposition problems” in every post but feel a dilemma here. Comments might help us on a followup post. </p>
<p/></font></font></div>
    </content>
    <updated>2020-07-27T06:39:13Z</updated>
    <published>2020-07-27T06:39:13Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="Alexander Razborov"/>
    <category term="approximation"/>
    <category term="Boolean functions"/>
    <category term="circuits"/>
    <category term="complexity"/>
    <category term="exposition problems"/>
    <category term="lower bounds"/>
    <category term="monotone"/>
    <category term="Stasys Jukna"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-31T04:20:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3389282706697250678</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3389282706697250678/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html" rel="alternate" type="text/html"/>
    <title>Do computers make us more safe or less safe?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Norbert Weiner wrote a paper <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/moral.pdf">Some Moral and Technical Consequences of Automation</a> in 1960. It warns of the dangers of computers in two ways:<br/>
<br/>
1) If a chess program is only trained against expert chess players then it might get confused if its opponent makes a bad move. This is not dangerous. But imagine a nuclear missle system that assumes the opponent is rational. If the opponent is not rational then it might launch and have an accidental nuclear war. So <i>there must be a human component </i>so that this won't happen.<br/>
<br/>
I offer a story and a counter narrative. In the 5th season, 23rd episode of the TV show Castle,<br/>
title <i>The Human Factor </i>a character had the following story to tell:<br/>
<i><br/>
The drone on its own was going to bomb a car. But the human noticed that there were red roses on the car, so it was a wedding couple, not a terrorist. If a human had not been involved the drone may have killed an innocent just married couple!</i><br/>
<br/>
This scene bothered me. It could EASILY be the other way around: the human wants to bomb and the drone (which has better vision) notices the roses. Or there may be many other ways that a computer could be BETTER than a human. I am not saying that a completely automated system is better, I am saying that its not obvious which way to go.  Both in some combination? What combination? Who has the final say? And in the drone scenario there may not be time for a human to consider the options.<br/>
<br/>
2) The Sorcerer's apprentice scenario. In The Sorcerer's Apprentice segment of the (original) movie Fantasia, Mickey mouse tells a broom to get him a glass of water. The broom keeps bringing him water and Mickey almost drowns. Computers may take orders to literally and not stop. I wonder if  automated stock-trading and automated auctions may have this problem. Is there a case known where this really did cause a problem?<div><br/></div><div>So what do you think?</div><div><br/></div><div>NOW- do computers (or, more generally technology) make us more safe or less safe?</div><div><br/></div><div>FUTURE- same question.</div></div>
    </content>
    <updated>2020-07-27T03:18:00Z</updated>
    <published>2020-07-27T03:18:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-28T12:46:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/07/27/discrete-fragility/</id>
    <link href="http://benjamin-recht.github.io/2020/07/27/discrete-fragility/" rel="alternate" type="text/html"/>
    <title>Digital Witnesses</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Doyle derived his LQG counterexample in the time before the ubiquity of numerical computing. This meant that numerical examples did not carry the rhetorical weight of algebraic closed form instances. The need for clean, persuasive formulae also meant that controllers were idealized in continuous time. Continuous-time optimal control often produced policies that couldn’t be implemented because of the limits of physical reality: no system can act instantaneously with arbitrary power. These issues of infeasibility were <a href="https://ieeexplore.ieee.org/document/1099822/">certainly noted in the literature</a> during the hey day of optimal control, but continuous time models still often made it difficult to pinpoint these issues.</p>

<p>Discrete-time models don’t share many of these issues. In discrete time, we explicitly encode the sequential, computational nature of decision and control. Discrete-time formulae are unfortunately less elegant than their continuous-time counterparts, but, as I hope to show here, they are often more revealing. Indeed, constructing examples where discrete-time optimal control leads to fragile solutions seems to be surprisingly easy.</p>

<p>Here, I’ll highlight a few examples where relatively innocuous problem formulations lead to very fragile control policies. The examples are weirdly simple and almost comical to a point. But anyone who has played with discrete-time optimal control may have stumbled into similar control policies and had to step back and think about why.</p>

<p>Let’s revisit the discrete-time LQR problem:</p>



<p>We again assume $x_t$ is observed perfectly without noise. While such perfect state information is not realistic, even ideal state feedback ends up being fragile in discrete time. $w_t$ is assumed to be stochastic, but I don’t think much changes if we move to a more adversarial setting. Here, we need the decision variable $u_t$ to be <em>causal</em>. It must be a function of only the values $x_s$ and $u_s$ with $s\leq t$. For stochastic disturbances, the optimal $u$ can always be found by dynamic programming.</p>

<p>Consider the following innocuous dynamics:</p>



<p>This system is a simple, two-state shift register. I’ll write the state out with indexed components $x=[x^{(1)},x^{(2)}]^\top$. New states enter through the control $B$ into the second state. The first state, $x^{(1)}$ is simply whatever was in the second register at the previous time step. The open loop dynamics of this system are as stable as you could imagine. Both eigenvalues of $A$ are zero.</p>

<p>Let’s say our control objective aims to try to keep the two states equal to each other. We can model this with the quadratic cost:</p>



<p>I assume $R=0$ here for simplicity, as the formulae are particularly nice for this case. But, as I will discuss in a moment, the situation is not improved simply by having $R$ be positive. For the disturbance, assume that $w_t$ is zero mean, has bounded second moment, $\Sigma_t = \mathbb{E}[w_t w_t^\top]$, and is uncorrelated with $x_t$ and $u_t$.</p>

<p>The cost is asking to minimize</p>



<p>When $w_t=0$, $x_t^{(1)}+x_t^{(2)} = x_{t-1}^{(2)}+u_{t-1}$, so it seems like our best bet is to just set $u_{t}=x_t^{(2)}$. This turns out to be the optimal action, and you can prove this directly using standard dynamic programming computations. What this means is that the closed loop dynamics of the system are</p>



<p>This closed-loop system is <em>marginally stable</em>, meaning that while signals don’t blow up, some states will persist forever and not converge to $0$. Indeed, the state-transition matrix here has eigenvalues $0$ and $1$. The $1$ corresponds the state where the two components are equal, and such a state can persist forever.</p>

<p>If we learned an incorrect model of the dynamics, how would that influence the closed loop behavior? The simplest scenario is that we identified $B$ from some preliminary experiments. We can immediately see that if the true $B_\star=\alpha B $, then the closed loop dynamics are</p>



<p>This system is unstable for any $\alpha&gt;1$. That is, the system is arbitrarily sensitive to misidentification of the dynamics. Note that this lack of robustness has nothing to do with the noise sequence. The structure of the cost is what drives the system to fragility.</p>

<p>If $R&gt;0$, you will get a slightly different policy. Again, using elementary dynamic programming shows that the optimal control is $u_t=\beta_t(R) x_t^{(2)}$ for some $\beta_t(R) \in (1/2,1)$. The closed loop system will be a bit more stable, but this comes at the price of reduced performance. And, at best, the gain margin of this system approaches $2$ as $R$ goes to infinity. You can also check that if you add $\epsilon$ times the identity to $Q$, you again get a control policy proportional to $x_t^{(2)}$.</p>

<p>This behavior can occur in even simpler systems. Consider the one-state linear system</p>



<p>The open loop system is again as stable as it gets. Now let’s aim to minimize $\Vert x-u \Vert$. It doesn’t matter what norm you choose here or whether you treat the noise as stochastic or worst case with respect to $w$, the optimal control is going to be $u_t = x_t/b$. Once again, the closed loop system has a pole at $1$ and is arbitrary fragile to misspecification of $b$.</p>

<p>I could continue to construct nasty examples, but I hope these examples are sufficiently illustrative. They are certainly contrived and pathological, and it’s not at all clear that they reflect any optimal control problem you might have been hoping to solve. However, both examples involve systems that are robust and stable in open loop. It’s only when we close the feedback loop that we end up in a dangerous situation. That simple optimal control problems give some profoundly fragile solutions should be a clear warning: <em>You can’t just optimize and hope to be robust.</em> You have to consider uncertainty as a first class citizen when designing feedback systems.</p>

<p>In some sense, the core contribution of robust control is in raising awareness of fundamental tradeoffs in the design of feedback systems. Optimal control promises that you can roughly identify a system, model uncertainty as noise, solve an optimization problem,  and then ship your policy. Hopefully, the examples in the last two posts have shown why this particular approach is fraught with danger.</p>

<p>If failure of a feedback system has any consequences, then a more holistic robust approach is <em>necessary</em>. We have to work with experts at different levels of the engineering pipeline, worry about unmodeled behaviors, and understand hard limits and practical tradeoffs. That is, engineering has to be more concerned with <em>design</em> than with <em>optimization.</em></p>

<p>There are all sorts of questions that a robust, systems level engineering effort might ask. Where should you put that extra sensor? Which parts of the system are likely to create issues? Is it possible to avoid performance disruptions when updating a single component in a legacy system? These questions are important in all aspects of system engineering, and developing accessible tools for addressing them in machine learning systems remains a daunting but essential challenge.</p>

<p>I am emphatically not saying that the design of feedback systems is hopeless. It’s easy to walk away with the impression “Ben’s examples are pathologies and unlike what I see in practice” or the pessimistic feeling of “shoot, all of this ML stuff is hopeless, I’m going to go work on something tractable like vaccine development.” I’m not saying that engineering robust machine learning systems is hopeless. I’m just saying that our community has to work better to incorporate multiple levels of uncertainty in its thinking. What are the fundamental tradeoffs between performance and robustness in machine learning? What do we even want to be robust to? In the next post I want to describe some of these robustness tradeoffs without using the language of optimization, probing if that provides some possible paths forward.</p></div>
    </summary>
    <updated>2020-07-27T00:00:00Z</updated>
    <published>2020-07-27T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-31T00:01:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/" rel="alternate" type="text/html"/>
    <title>Private Set Intersection #2</title>
    <summary>In the first post on Private Set Intersection, I presented the problem of Private Set Intersection, its applications and the simple protocol of [KMRS14], that allows Alice and Bob to learn the intersection of their sets with the aid of an untrusted third party Steve who is assumed to not...</summary>
    <updated>2020-07-26T23:00:00Z</updated>
    <published>2020-07-26T23:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-31T00:01:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/111</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/111" rel="alternate" type="text/html"/>
    <title>TR20-111 |  Lifting: As Easy As 1,2,3 | 

	Ian Mertz, 

	Toniann Pitassi</title>
    <summary>Query-to-communication lifting theorems translate lower bounds on query complexity to lower bounds for the corresponding communication model. In this paper, we give a simplified proof of deterministic lifting (in both the tree-like and dag-like settings). Whereas previous proofs used sophisticated Fourier analytic techniques, our proof uses elementary counting together with the sunflower lemma.</summary>
    <updated>2020-07-25T05:05:34Z</updated>
    <published>2020-07-25T05:05:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-31T04:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8081773524220393104</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8081773524220393104/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8081773524220393104" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8081773524220393104" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html" rel="alternate" type="text/html"/>
    <title>Virtual Complexity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The <a href="https://computationalcomplexity.org/Archive/2020/fullsite/">Complexity Complexity Conference</a>, the conference that shares its name and URL with this blog, originally scheduled for Saarbrücken will be held virtually next week. Registration is free for non-authors. <a href="https://www.youtube.com/channel/UCXgNLnzWOP4bM2-xfHDHUrw">Talks</a> are already posted. Looking forward to seeing you at the business meeting and the social.<br/>
<div>
<br/></div>
<div>
<div>
Award winners have already been announced: The Best Student Paper Award goes to Rahul Ilango for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12583/">Connecting Perebor Conjectures: Towards a Search to Decision Reduction for Minimizing Formulas</a> and the Best Paper Award goes to Daniel Dadush and Samarth Tiwari for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12586/">On the Complexity of Branching Proofs</a>.</div>
</div>
<div>
<br/></div>
<div>
Virtual conferences give an opportunity for far more people to attend since you don't have the expense and time needed to go to Germany. On the other hand it's hard to dedicate time for a conference when you aren't there. I missed STOC which would have been walking distance from where I live but I did attend parts of the <a href="http://ec20.sigecom.org/">Economics and Computation</a> conference which was supposed to be in Budapest. EC made great use of <a href="http://gather.town/">gather.town</a> where you can wander around virtual rooms bumping into and talking to people. I caught up with a few people there. Complexity plans to use gather for its social meeting next week. Looking forward to the virtual beer.</div></div>
    </content>
    <updated>2020-07-24T16:21:00Z</updated>
    <published>2020-07-24T16:21:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-28T12:46:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19859</id>
    <link href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/" rel="alternate" type="text/html"/>
    <title>Noam Lifshitz: A new hypercontractivity inequality — The proof!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a guest post kindly contributed by Noam Lifshitz. Here is a pdf version.  This post is a continuation of the post  To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new … <a href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is a guest post kindly contributed by Noam Lifshitz</em>. <em>Here is a <a href="https://gilkalai.files.wordpress.com/2020/07/proof-of-hypercontractivity.pdf">pdf version</a>.  This post is a continuation of the post  </em><a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="bookmark">To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</a>, <em>and it gives the proof of the new hypercontractive inequality. We plan a third post where various applications will be mentioned.</em></p>
<p>Before we get to the post I want to mention that there are a lot of activities on the web. I may devote a special post to links and discussion (and contributing links in the comment section is very welcome.) but meanwhile a few links:  1) <a href="https://simons.berkeley.edu/events/boolean">Advances in Boolean Function Analysis Lecture Series</a> (thanks to Avishay Tal and Prasad Raghavendra for letting me know); 2) <a href="https://math216.wordpress.com/agittoc-2020/">Online course in Foundations of Algebraic Geometry</a> Given by Ravi Vakil from Stanford. You can take the course at varying levels of involvement. (Thanks to Tami Ziegler for telling me) A very very interesting way of online teaching. 3) <a href="https://researchseminars.org/">A site with online mathematical lectures.</a></p>
<h2><img alt="Bonami" class="alignnone size-full wp-image-19984" height="480" src="https://gilkalai.files.wordpress.com/2020/07/bonami.jpg?w=640&amp;h=480" width="640"/></h2>
<p><span style="color: #ff0000;">Aline Bonami with Szilard Revesz and me (2006). Aline Bonami first proved the 2-point hypercontractive inequality which is very useful in the analysis of Boolean functions. (Leonard Gross proved it independently a few years later and William Beckner found important applications to harmonic analysis.)</span></p>
<h2>Proof of the new hypercontractivity inequality</h2>
<p>Our aim is to prove the hypercontractivity theorem for global functions. The proof here is taken from a joint paper with David Ellis and Guy Kindler that’ll soon be out on the Arxiv.</p>
<h3><strong>Theorem 1:</strong></h3>
<p><img alt="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, "/></p>
<p>Here we use the notations given in the <a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/">last blog post</a>. Let us first get a feel for our hypercontractivity theorem by proving the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case. Here the RHS is <img alt="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}"/></p>
<h3>1. Proof of the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case</h3>
<p>We will prove the following slightly stronger version of Theorem 1 for the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case.</p>
<p><strong>Proposition 2:</strong></p>
<p>Let <img alt="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5Crightarrow%5Cmathbb%7BC%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}"/> Let <img alt="{\rho\le\frac{1}{10}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}.}"/> Then<br/>
<img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. "/></p>
<p style="text-align: left;"><strong>Proof</strong>: Let us write <img alt="{L\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L\left[f\right]}"/> for <img alt="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B1%7D%5Cleft%5Bf%5Cright%5D%3Df-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}"/> Rearranging, we have<br/>
<img alt="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2BL%5Cleft%5Bf%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. "/><br/>
The noise operator in the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case is by definition equal to <img alt="{\rho Id+\left(1-\rho\right)\mathbb{E},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho+Id%2B%5Cleft%281-%5Crho%5Cright%29%5Cmathbb%7BE%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho Id+\left(1-\rho\right)\mathbb{E},}"/> where <img alt="{\mathbb{E}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{E}}"/> is the expectation over <img alt="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}"/> operator, and <img alt="{Id}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BId%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Id}"/> is the identity operator. Hence,<br/>
<img alt="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Crho+L%5Bf%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. "/></p>
<p>Now when expanding the 4-norm of the function <img alt="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}"/>, we obtain</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\left|\mathbb{E}\left[f\right]\right|^{4}"/><br/>
<img alt="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B6%5Crho%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CLf%5C%7C_%7B2%7D%5E%7B2%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+"/><br/>
<img alt="\displaystyle&#xA0; +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%2B4%5Crho%5E%7B3%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+"/><br/>
<img alt="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B+%5Crho%5E%7B4%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4},"/></p>
<p>where we used the fact that the expectation of <img alt="{L\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L\left[f\right]}"/> is 0. When looking at the right hand side of the global hypercontractivity theorem, we see most of the above terms except for the one involving the third norm of the Laplacian. Indeed we have</p>
<p style="text-align: center;"><img alt="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+RHS+%3D%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}"/><br/>
<img alt="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}"/><br/>
<img alt="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B2%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}"/><br/>
<img alt="\displaystyle +\|L\left[f\right]\|_{2}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +\|L\left[f\right]\|_{2}^{4}"/><br/>
<img alt="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%5C%7C%7D%7D_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}."/></p>
<p>Hence we see that the only term in the left hand side that doesn’t appear with a greater coefficient in the left hand side is the term <img alt="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}"/> and by AM-GM we have</p>
<p style="text-align: center;"><img alt="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}"/> <img alt="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B3%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]"/><br/>
<img alt="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cle%5Cmathbb%7BE%7D%5Cleft%5B%5Cfrac%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%2B%5Cleft%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%7D%7D%5Cright%7C%5E%7B4%7D%7D%7B2%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]"/><br/>
<img alt="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cfrac%7B1%7D%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%2B%5Cfrac%7B1%7D%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, "/></p>
<p>which allows us to upper bound the only term appearing in the left hand side but not in the right hand side by corresponding terms that do appear in the right hand side. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<h3>2. Tensorisation lemma</h3>
<p>Next we are going to prove a theorem that doesn’t seem to fit to our setting, but we’re going to fit it in by force. Let <img alt="{X,Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,Y}"/> be finite sets. Let us write <img alt="{\mathcal{F}\left(X\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\right)}"/> for the linear space of complex valued functions on <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. The space <img alt="{\mathcal{F}\left(X\times Y\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\times Y\right)}"/> can be identified with the space <img alt="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Cotimes%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}"/> where a pair of function <img alt="{f\otimes g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\otimes g}"/> is identified with the function<br/>
<img alt="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28x%2Cy%5Cright%29%5Cmapsto+f%5Cleft%28x%5Cright%29g%5Cleft%28y%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) "/><br/>
in <img alt="{\mathcal{F}\left(X\times Y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}\left(X\times Y\right).}"/></p>
<p>Given two operators <img alt="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Cright%29%2CA_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}"/>, the operator <img alt="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Ctimes+X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Ctimes+Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}"/> is the unique operator sending <img alt="{f\otimes g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\otimes g}"/> to <img alt="{A_{1}f\otimes A_{2}g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7Df%5Cotimes+A_%7B2%7Dg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}f\otimes A_{2}g}"/>. We write <img alt="{A^{\otimes n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^{\otimes n}}"/> for <img alt="{A\otimes\cdots\otimes A.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes%5Ccdots%5Cotimes+A.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes\cdots\otimes A.}"/> The operator <img alt="{A_{1}\otimes A_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}}"/> can also be defined more explictly in terms of its values on functions. The operator <img alt="{A_{1}\otimes A_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes A_{2}}"/> can be understood more explicitly by noting that it is the composition of the operators <img alt="{A_{1}\otimes I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}\otimes I}"/> and <img alt="{I\otimes A_{2}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%5Cotimes+A_%7B2%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I\otimes A_{2}.}"/> Now the operator <img alt="{A\otimes I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes I}"/> is given by <img alt="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+If%5Cleft%28x%2Cy%5Cright%29%3DAf_%7By%7D%5Cleft%28x%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}"/> where <img alt="{f_{y}\left(x\right)=f\left(x,y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%5Cleft%28x%5Cright%29%3Df%5Cleft%28x%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}\left(x\right)=f\left(x,y\right).}"/></p>
<p><strong>Lemma 3:</strong> Let <img alt="{X,Y,Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%2CZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,Y,Z}"/> be measure spaces with finite underlying sets. Let <img alt="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2CB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Z%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}"/> be operators satisfying</p>
<p style="text-align: center;"><img alt="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CAf%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} "/></p>
<p>for all functions <img alt="{f\in\mathcal{F}\left(X\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in\mathcal{F}\left(X\right).}"/><br/>
Then</p>
<p style="text-align: center;"><img alt="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CA%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} "/></p>
<p>for all <img alt="{f\in\mathcal{F}\left(X^{n}\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5E%7Bn%7D%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in\mathcal{F}\left(X^{n}\right).}"/></p>
<p>Here the spaces <img alt="{X^{n},Y^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%5E%7Bn%7D%2CY%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X^{n},Y^{n},}"/> and <img alt="{Z^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z^{n}}"/> are equipped with the product measure, where the measure of an atom is the product of the measures of its coordiates.</p>
<p><strong>Proof:</strong> For each <img alt="{y\in X,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%5Cin+X%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y\in X,}"/> let <img alt="{g_{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_{y}}"/> be given by <img alt="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%3A%3DA%5E%7B%5Cotimes%5Cleft%28n-1%5Cright%29%7Df%5Cleft%28%5Ccdot%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}"/> As mentioned <img alt="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7Df%5Cleft%28x%2Cy%5Cright%29%3DAg_%7By%7D%5Cleft%28x%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}"/> Hence by hypothesis, we have</p>
<p style="text-align: center;"><img alt="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathrm%7BA%7D%5E%7B%5Cotimes+n%7Df%5Cright%7C%5E%7B4%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]"/> <img alt="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CAg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}"/><br/>
<img alt="\displaystyle&#xA0; \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CBg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}"/><br/>
<img alt="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5C%7CA%5E%7B%5Cotimes+n-1%7D%5Cotimes+B%5C%7C_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}."/> We may now repeat the same process on each of the other coordinates to replace the <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>s by <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>s one by one. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<h3>3. The main idea: Fourifying the 2-norms.</h3>
<p>The strategy of our proof is to take the theorem</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, "/></p>
<p>which we established in the <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=1}"/> case for <img alt="{\rho\le\frac{1}{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}}"/>, and to turn it into an essentially equivalent statement about 4-norms. We will then get a tensorised statement for general <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, which we will be able to convert back into our hypercontractivity theorem for global functions. Our idea is to encode our function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as a function <img alt="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5Ccolon%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}"/> satisfying</p>
<p style="text-align: center;"><img alt="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} "/></p>
<p>and</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%3D%5C%7Cf%5C%7C_%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. "/></p>
<p>The benefit of working with <img alt="{\mathrm{En}f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}f}"/> rather than <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is that in <img alt="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}"/> one may move between 4-norms and 2-norms by appealing to the hypercontractivity theorem there, which gives</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Ccirc%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D%5Cle%5C%7C%5Cmathrm%7BE%7Dnf%5C%7C_%7B2%7D%5Cle%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} "/></p>
<p>at the cost of some noise.</p>
<p>To define <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> we use Fourier analysis of Abelian groups. Let us briefly recall it. For simplicity let us assume that <img alt="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}"/> where <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is a prime. Let <img alt="{\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\omega}"/> be a <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>th root of unity. For any <img alt="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}"/> we have a character <img alt="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}"/> given by <img alt="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Cleft%28x%5Cright%29%3D%5Comega%5E%7B%5Cleft%5Clangle+%5Cgamma%2Cx%5Cright%5Crangle+%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}"/> The <img alt="{\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}}"/> are an orthonormal basis of <img alt="{\left(\mathbb{Z}/p\right)^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left(\mathbb{Z}/p\right)^{n}}"/> and we write <img alt="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3D%5Csum%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}"/>, where <img alt="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B%5Cgamma%7D%5Cright%5Crangle+.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}"/> Note that <img alt="{\chi_{0}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{0}}"/> is the constant function, and so we have</p>
<p style="text-align: center;"><img alt="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat%7Bf%7D%5Cleft%280%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B0%7D%5Cright%5Crangle+%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], "/></p>
<p>which gives</p>
<p style="text-align: center;"><img alt="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum%5Chat%7Bf%7D%5Cleft%28i%5Cright%29%5Cchi_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. "/></p>
<p>Our mission will first be to convert the <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>-norm of a function <img alt="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}"/> to the <img alt="{4-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4-}"/>norm of a different function.</p>
<p>We define an encoding operator <img alt="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}"/> by setting</p>
<p style="text-align: center;"><img alt="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%5Cmapsto%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum_%7Bi%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cp-1%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28i%5Cright%29x_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. "/></p>
<p>We have</p>
<p style="text-align: center;"><img alt="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7Cf%5C%7C_%7B2%7D%5E%7B2%7D%3D%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%5E%7B2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, "/></p>
<p>as the <img alt="{\chi_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{i}}"/> are orthonormal and so are the <img alt="{x_{i}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}.}"/> Moreover, <img alt="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D%3D%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}"/> by the Fourier formula for <img alt="{\mathrm{T}_{\rho}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}.}"/> Since <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>-norms are always smaller than 4-norms on probability spaces, we’ve got the following corollary of Proposition 2.</p>
<p><strong>Lemma 4.</strong> For all <img alt="{\rho\le\frac{1}{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}}"/> and all <img alt="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}"/> we have</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. "/></p>
<p>We now reach the final little trick. We define a measure space <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> whose underlying set is <img alt="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Csqcup%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7B%5Cleft%5C%7B+p-1%5Cright%5C%7D+%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}"/> and where the measure is given by <img alt="{\mu\left(i\right)=\frac{1}{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28i%5Cright%29%3D%5Cfrac%7B1%7D%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu\left(i\right)=\frac{1}{p}}"/> for <img alt="{i\in\mathbb{Z}/p\mathbb{Z}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5Cin%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i\in\mathbb{Z}/p\mathbb{Z}}"/> and <img alt="{\mu\left(x\right)=\frac{1}{2}^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28x%5Cright%29%3D%5Cfrac%7B1%7D%7B2%7D%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu\left(x\right)=\frac{1}{2}^{p-1}}"/> for <img alt="{x\in\left\{ -1,1\right\} ^{p-1}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left\{ -1,1\right\} ^{p-1}.}"/> We let <img alt="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}"/> be given by <img alt="{Bf=\mathrm{En}f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BBf%3D%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Bf=\mathrm{En}f}"/> on <img alt="{\left\{ -1,1\right\} ^{p-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} ^{p-1}}"/> and letting it be <img alt="{f-\mathbb{E}\left[f\right]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f-\mathbb{E}\left[f\right]}"/> on <img alt="{\mathbb{Z}/p\mathbb{Z}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}.}"/> This way Lemma 4 takes the form <img alt="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}"/></p>
<h3>4. Tensorised operators</h3>
<p>The operator <img alt="{\mathrm{T}_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}}"/> on <img alt="{\mathbb{Z}/p\mathbb{Z}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p\mathbb{Z}^{n}}"/> satisfies <img alt="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}"/> where the latter <img alt="{\mathrm{T}_{\rho}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}}"/> refers to the noise operator on <img alt="{\mathbb{Z}/p.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{Z}/p.}"/> The characters <img alt="{\chi_{\gamma}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}}"/> satisfy <img alt="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%3D%5Cbigotimes%5Cchi_%7B%5Cgamma_%7Bi%7D%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}"/> and so we have the Fourier formula</p>
<p style="text-align: center;"><img alt="\displaystyle \mathrm{T}_{\rho}f&#xA0; =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%C2%A0+%3D%5Csum_%7B%5Cgamma%7D%5Crho%5E%7B%5C%23%5Cleft%5C%7B+i%3A%5Cgamma_%7Bi%7D%5Cne0%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \mathrm{T}_{\rho}f&#xA0; =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. "/></p>
<p>We also have</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Cbigotimes_%7Bi%5Cin+S%7D%5Cleft%28f%5Cmapsto+f-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%29%5Cotimes%5Cbigotimes_%7Bi%5Cnotin+S%7DId%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, "/></p>
<p>and so</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Csum_%7B%5Cgamma%3A%5Cgamma_%7Bi%7D%5Cne0%5Ctext%7B+for+all+%7Di%5Cin+S%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. "/></p>
<p>This will allow us to conclude that</p>
<p style="text-align: center;"><img alt="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7DT_%7B%5Crho%7DL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. "/></p>
<p>We will also encounter the operator <img alt="{\mathrm{En}^{\otimes n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}^{\otimes n},}"/> which by abusing notation we also call <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> encodes</p>
<p style="text-align: center;"><img alt="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Csum_%7B%5Cgamma%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} "/></p>
<p>as the function <img alt="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7B%5Cgamma%7D%5Cwidehat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cprod_%7Bi%3D1%7D%5E%7Bn%7Dx_%7Bpi%2B%5Cgamma_%7Bi%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}"/> on <img alt="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}"/><br/>
Now finally we can get to the understanding of the operator <img alt="{B^{\otimes n}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%5E%7B%5Cotimes+n%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B^{\otimes n}.}"/> The space <img alt="{Y^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y^{n}}"/> is the disjoint union of <img alt="{2^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n}}"/> spaces of the form</p>
<p style="text-align: center;"><img alt="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. "/></p>
<p>By definition of the tensor product, for <img alt="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}"/> is the function</p>
<p style="text-align: center;"><img alt="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+B%5E%7Bn%7Df%5Cleft%28x%2Cy%5Cright%29%3D%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cleft%28y%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). "/></p>
<h3>5. Finishing the proof</h3>
<p><strong>Proof:</strong> Lemmas 3 and 4 yield:</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\|B^{\otimes n}f\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}&#xA0; \le\|B^{\otimes n}f\|_{4}^{4}"/> <img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4},"/></p>
<p>for any <img alt="{\rho\le\frac{1}{10}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\le\frac{1}{10}.}"/> We now have</p>
<p style="text-align: center;"><img alt="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B%5Crho%7D%7B%5Csqrt%7B3%7D%7D%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}"/> <img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%28%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%29%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Cleft%28%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4},"/><br/>
<img alt="\displaystyle&#xA0; \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle&#xA0; \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}"/><br/>
<img alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}."/></p>
<p>The first equality follows from the formula <img alt="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathrm%7BT%7D_%7B%5Crho%7DL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}"/> and the fact that <img alt="{\mathrm{T_{\rho}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT_%7B%5Crho%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T_{\rho}}}"/> commutes with the encoding. The inequality used hypercontractivity on the discrete cube. The last equality follows from the fact that the <img alt="{\mathrm{En}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{En}}"/> operator preserves 2-norms. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-07-24T15:21:49Z</updated>
    <published>2020-07-24T15:21:49Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Guest blogger"/>
    <category term="Noam Lifshitz"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-07-31T04:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7779</id>
    <link href="https://windowsontheory.org/2020/07/24/ryan-odonnels-tcs-toolkit-and-other-resources/" rel="alternate" type="text/html"/>
    <title>Ryan O’Donnell’s “TCS Toolkit” and other resources</title>
    <summary>When I was in grad school a common advice for beginning grad students was to leaf through the (paper) STOC or FOCS proceedings to see papers that you are interested in. This is still a decent advice (and requires less physical strength these days 🙂 ) but papers are not always the best source for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>When I was in grad school a common advice for beginning grad students was to leaf through the (paper) STOC or FOCS proceedings to see papers that you are interested in. This is still a decent advice (and requires less physical strength these days <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> ) but papers are not always the best source for people starting out. More often than we’d like to, the author of the 10th paper on a topic writes it to the audience of people that read (in fact probably wrote) the previous 9 papers.</p>



<p>Talks often do a better job of giving an overview of the field, and one great resource is the <a href="https://simons.berkeley.edu/videos">videos</a> from the Simons Institute. If you want to get more in-depth information about a particular topic, it’s hard to beat the extended surveys in <a href="https://www.nowpublishers.com/TCS">Foundations and Trends in TCS</a>, as well as the related areas such as <a href="https://www.nowpublishers.com/MAL">Machine Learning</a> and <a href="https://www.nowpublishers.com/CIT">Information Theory</a>. </p>



<p>But if you are not yet sure what topic you’re interested in, or perhaps not even sure if you want to go to grad school, but you just know that you are interested in theory, there is now a new great resource. As I learned from <a href="https://twitter.com/BooleanAnalysis/status/1286658578049359873">Twitter</a>, Ryan O’Donnell has just finished his <a href="https://www.diderot.one/course/28/">TCS Toolkit course</a>. All 99(!) lectures are on <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube</a>.</p>



<p>The topics are the following (these links are to the handwritten notes, for the lecture videos see <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube channel</a>):</p>



<p><a href="https://www.diderot.one/course/28/chapters/1824/">1.   Course Overview, and How to TCS</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1881/">2.   Basic Asymptotics</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1889/">3.   Factorials and Binomial Coefficients</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1923/">4.   Central Limit Theorem</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1956/">5.   Chernoff Bounds</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1973/">6.   Computational Models</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1981/">7.   Fast Multiplication with the DFT</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1990/">8.   Analysis of Boolean Functions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2003/">9.   Quantum Computation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2037/">10.   Fields and Polynomials</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2038/">11.   Error-Correcting Codes</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2064/">12.   Derandomization</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2065/">13.   Spectral Graph Theory I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2094/">14.   Spectral Graph Theory II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2099/">15.   Spectral Graph Theory III</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2101/">15.1.   Cheeger’s Inequality (Spectral Graph Theory bonus)</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2112/">16.   Expander Graphs</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2149/">17.   Linear Programming I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2162/">18.   Linear Programming II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2173/">19.   The Ellipsoid Algorithm</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2190/">20.   CSPs and Approximation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2197/">21.   LP Hierarchies and Proof Systems</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2209/">22.   Treewidth</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2227/">23.   Communication Complexity</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2250/">24.   Information Theory</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2251/">25.   Cryptography</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2290/">26.   Hardness Assumptions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2291/">27.   The PCP Theorem</a></p>



<p>p.s. For giving a high level taste of theory to beginning undergraduates, a great resource is Aaronson’s <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing since Democritus</a> or <a href="https://www.math.ias.edu/avi/book">Wigderson’s Math and Computation</a> if they’re more math inclined. </p></div>
    </content>
    <updated>2020-07-24T14:34:02Z</updated>
    <published>2020-07-24T14:34:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-31T04:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4916</id>
    <link href="https://www.scottaaronson.com/blog/?p=4916" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4916#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4916" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Busy Beaver Frontier</title>
    <summary xml:lang="en-US">Update (July 27): I now have a substantially revised and expanded version, which incorporates (among other things) the extensive feedback that I got from this blog post. There are new philosophical remarks, some lovely new open problems, and an even-faster-growing (!) integer sequence. Check it out! A life that was all covid, cancellations, and Trump, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (July 27):</span></strong> I now have a <a href="https://www.scottaaronson.com/papers/bb.pdf">substantially revised and expanded version</a>, which incorporates (among other things) the extensive feedback that I got from this blog post.  There are new philosophical remarks, some lovely new open problems, and an <em>even-faster-growing</em> (!) integer sequence.  Check it out!</p>



<p/><hr/><p/>



<p>A life that was all covid, cancellations, and Trump, all desperate rearguard defense of the beleaguered ideals of the Enlightenment, would hardly be worth living.  So it was an exquisite delight, these past two weeks, to forget current events and write an <a href="https://www.scottaaronson.com/papers/bb.pdf">18-page survey article</a> about the <a href="https://en.wikipedia.org/wiki/Busy_beaver">Busy Beaver function</a>: the staggeringly quickly-growing function that probably encodes a huge portion of all interesting mathematical truth in its first hundred values, if only we could know those values or exploit them if we did.</p>



<p>Without further ado, here’s the title, abstract, and link:</p>



<blockquote class="wp-block-quote"><p><a href="https://www.scottaaronson.com/papers/bb.pdf"><strong>The Busy Beaver Frontier</strong></a><br/>by Scott Aaronson</p><p>The Busy Beaver function, with its incomprehensibly rapid growth, has captivated generations of computer scientists, mathematicians, and hobbyists.  In this survey, I offer a personal view of the BB function 58 years after its introduction, emphasizing lesser-known insights, recent progress, and especially favorite open problems.  Examples of such problems include: when does the BB function first exceed the Ackermann function?  Is the value of BB(20) independent of set theory?  Can we prove that BB(n+1)&gt;2<sup>BB(n)</sup> for large enough n?  Given BB(n), how many advice bits are needed to compute BB(n+1)?  Do all Busy Beavers halt on all inputs, not just the 0 input?  Is it decidable whether BB(n) is even or odd?</p></blockquote>



<p>The article is slated to appear soon in <em>SIGACT News</em>.  I’m grateful to Bill Gasarch for suggesting it—even with everything else going on, this was a commission I felt I couldn’t turn down!</p>



<p>Besides Bill, I’m grateful to the various Busy Beaver experts who answered my inquiries, to Marijn Heule and Andy Drucker for suggesting some of the open problems, to Marijn for creating a figure, and to Lily, my 7-year-old daughter, for raising the question about the first value of n at which the Busy Beaver function exceeds the Ackermann function.  (Yes, Lily’s covid homeschooling has included multiple lessons on very large positive integers.)</p>



<p>There are still a few days until I have to deliver the final version. So if you spot anything wrong or in need of improvement, don’t hesitate to leave a comment or send an email.  Thanks in advance!</p>



<p>Of course Busy Beaver has been an obsession that I’ve returned to many times in my life: for example, in that <a href="https://www.scottaaronson.com/writings/bignumbers.html">Who Can Name the Bigger Number?</a> essay that I wrote way back when I was 18, in <em><a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a></em>, in my <a href="https://www.scottaaronson.com/blog/?p=3445">public lecture at Festivaletteratura</a>, and in my <a href="https://www.scottaaronson.com/blog/?p=2725">2016 paper with Adam Yedidia</a> that showed that the values of all Busy Beaver numbers beyond the 7910<sup>th</sup> are independent of the axioms of set theory (Stefan O’Rear has since shown that independence starts at the 748<sup>th</sup> value or sooner).  This survey, however, represents the first time I’ve tried to take stock of BusyBeaverology <em>as a research topic</em>—collecting in one place all the lesser-known theorems and empirical observations and open problems that I found the most striking, in the hope of inspiring not just contemplation or wonderment but actual progress.</p>



<p>Within the last few months, the world of <em>deep mathematics that you can actually explain to a child</em> lost two of its greatest giants: <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Conway</a> (who died of covid, and who I <a href="https://www.scottaaronson.com/blog/?p=4732">eulogized here</a>) and <a href="https://en.wikipedia.org/wiki/Ronald_Graham">Ron Graham</a>.  One thing I found poignant, and that I didn’t know before I started writing, is that Conway and Graham <em>both</em> play significant roles in the story of the Busy Beaver function.  Conway, because most of the best known candidates for Busy Beaver Turing machines turn out, when you analyze them, to be testing variants of the notorious <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz Conjecture</a>—and Conway is the one who proved, in 1972, that the set of “Collatz-like questions” is Turing-undecidable.  And Graham because of <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a> from <a href="https://en.wikipedia.org/wiki/Ramsey_theory">Ramsey theory</a>—a candidate for the biggest number that’s ever played a role in mathematical research—and because of the <a href="https://googology.wikia.org/wiki/User_blog:Wythagoras/The_nineteenth_Busy_Beaver_number_is_greater_than_Graham%27s_Number!">discovery</a>, four years ago, that the 18<sup>th</sup> Busy Beaver number exceeds Graham’s number.</p>



<p>(“Just how big is Graham’s number?  So big that the <em>17<sup>th</sup> Busy Beaver number</em> is not yet known to exceed it!”)</p>



<p>Anyway, I tried to make the survey pretty accessible, while still providing enough technical content to sink one’s two overgrown front teeth into (don’t worry, there are no such puns in the piece itself).  I hope you like reading it at least 1/BB(10) as much as I liked writing it.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (July 24):</span></strong> Longtime commenter Joshua Zelinsky gently reminded me that one of the main questions discussed in the survey—namely, whether we can prove BB(n+1)&gt;2<sup>BB(n)</sup> for all large enough n—was <a href="https://www.scottaaronson.com/blog/?p=1385#comment-73298">first brought to my attention</a> by him, Joshua, in a 2013 Ask-Me-Anything session on this blog!  I apologize to Joshua for the major oversight, which has now been corrected.  On the positive side, we just got a powerful demonstration <em>both</em> of the intellectual benefits of blogging, and of the benefits of sharing paper drafts on one’s blog before sending them to the editor!</p></div>
    </content>
    <updated>2020-07-23T06:42:48Z</updated>
    <published>2020-07-23T06:42:48Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-27T09:36:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/23/tenure-track-or-tenured-faculty-positions-at-center-on-frontiers-of-computing-studies-peking-university-apply-by-september-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/23/tenure-track-or-tenured-faculty-positions-at-center-on-frontiers-of-computing-studies-peking-university-apply-by-september-30-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track or Tenured Faculty Positions at Center on Frontiers of Computing Studies, Peking University (apply by September 30, 2020)</title>
    <summary>The Center on Frontiers of Computing Studies (CFCS), Peking University (PKU), China, is a university new initiative co-founded by Professors John Hopcroft and Wen Gao. We are seeking applicants from all areas of Computer Science, spanning theoretical foundations, systems, software, and applications, with special interests in artificial intelligence and machine learning. Website: https://cfcs.pku.edu.cn/english/people/joinus/236979.htm Email: cfcs_recruiting@pku.edu.cn</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Center on Frontiers of Computing Studies (CFCS), Peking University (PKU), China, is a university new initiative co-founded by Professors John Hopcroft and Wen Gao.</p>
<p>We are seeking applicants from all areas of Computer Science, spanning theoretical foundations, systems, software, and applications, with special interests in artificial intelligence and machine learning.</p>
<p>Website: <a href="https://cfcs.pku.edu.cn/english/people/joinus/236979.htm">https://cfcs.pku.edu.cn/english/people/joinus/236979.htm</a><br/>
Email: cfcs_recruiting@pku.edu.cn</p></div>
    </content>
    <updated>2020-07-23T02:00:39Z</updated>
    <published>2020-07-23T02:00:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-31T04:20:56Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/22/three-cccg-videos</id>
    <link href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html" rel="alternate" type="text/html"/>
    <title>Three CCCG videos</title>
    <summary>Three new ten-minute research talk videos by me are now up on YouTube as part of the collection of videos to be presented in the 2020 Canadian Conference on Computational Geometry. The pdf conference program has links to all the videos. The conference includes an opportunity to interact with the speakers online, on the August 5–7 dates of the actual conference, with free registration at the CCCG web site.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Three new ten-minute research talk videos by me are now up on YouTube as part of the collection of videos to be presented in the 2020 Canadian Conference on Computational Geometry. The <a href="http://vga.usask.ca/cccg2020/program.pdf">pdf conference program</a> has links to all the videos. The conference includes an opportunity to interact with the speakers online, on the August 5–7 dates of the actual conference, with free registration at <a href="http://vga.usask.ca/cccg2020/">the CCCG web site</a>.</p>

<p>My three videos are on <a href="https://11011110.github.io/blog/2020/07/16/comparing-multi-sport.html">dynamic products of ranks, discussed in my previous post</a>, polyhedra that are difficult to unfold, and mathematics inspired by <a href="https://en.wikipedia.org/wiki/Lusona">the sona drawings of southwest Africa</a>. For your convenience here they are more directly:</p>

<div style="text-align: center;">

<p> </p>

<p> </p>

<p> </p>
</div>

<p>(Apologies for the weird aspect ratio. I should probably aim for a more standard 16x9 format in future.)</p>

<p>I also have a fourth CCCG paper, on unfolding orthogonal polyhedra, with a video produced by Joe O’Rourke. I posted about its preprint version, “<a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">Some polycubes have no edge-unzipping</a>”, a year ago. Here’s Joe’s talk:</p>

<div style="text-align: center;">
<p> </p>

</div></div>
    </content>
    <updated>2020-07-22T14:48:00Z</updated>
    <published>2020-07-22T14:48:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-30T05:36:42Z</updated>
    </source>
  </entry>
</feed>
