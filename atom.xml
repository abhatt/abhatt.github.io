<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-06-28T23:36:15Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17489</id>
    <link href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/" rel="alternate" type="text/html"/>
    <title>Another sensation – Annika Heckel: Non-concentration of the chromatic number of a random graph</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Annika Heckel Sorry for the long period of non blogging. There are a lot of things to report and  various other plans for posts and I hope to come back to it soon. But it is nice to break the … <a href="https://gilkalai.wordpress.com/2019/06/28/another-sensation-annika-heckel-non-concentration-of-the-chromatic-number-of-a-random-graph/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/06/annika-1.png"><img alt="" class="alignnone size-full wp-image-17490" src="https://gilkalai.files.wordpress.com/2019/06/annika-1.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Annika Heckel</strong></span></p>
<p>Sorry for the long period of non blogging. There are a lot of things to report and  various other plans for posts and I hope to come back to it soon. But it is nice to break the silence with another sensational result by Annika Heckel. I first heard about it some time ago and Noam Lifshitz just informed be that the<a href="https://arxiv.org/abs/1906.11808"> paper is on the arXive</a>!</p>
<h2><a href="https://arxiv.org/abs/1906.11808">Non-concentration of the chromatic number of a random graph</a></h2>
<p>And here is the <strong>abstract:</strong> We show that the chromatic number of $latex <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span class="mi" id="MathJax-Span-4">G(</span><span class="texatom" id="MathJax-Span-5"><span class="mrow" id="MathJax-Span-6"><span class="mi" id="MathJax-Span-7">n</span><span class="mo" id="MathJax-Span-8">,</span><span class="mfrac" id="MathJax-Span-9"><span class="mn" id="MathJax-Span-10">1/</span><span class="mn" id="MathJax-Span-11">2)$</span></span></span></span></span></span></span></span> is not concentrated on fewer than <img alt="n^{1/4-\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2F4-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1/4-\epsilon}"/>  consecutive values. This addresses a longstanding question raised by Erdős and several other authors.</p>
<p>The Introduction tells the history of the problem very nicely.</p></div>
    </content>
    <updated>2019-06-28T10:37:04Z</updated>
    <published>2019-06-28T10:37:04Z</published>
    <category term="Combinatorics"/>
    <category term="Annika Heckel"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-06-28T23:34:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11811</id>
    <link href="http://arxiv.org/abs/1906.11811" rel="alternate" type="text/html"/>
    <title>Faster and Better Nested Dissection Orders for Customizable Contraction Hierarchies</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Lars Gottesbüren, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamann:Michael.html">Michael Hamann</a>, Tim Niklas Uhl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Dorothea.html">Dorothea Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11811">PDF</a><br/><b>Abstract: </b>Graph partitioning has many applications. We consider the acceleration of
shortest path queries in road networks using Customizable Contraction
Hierarchies (CCH). It is based on computing a nested dissection order by
recursively dividing the road network into parts. Recently, with FlowCutter and
Inertial Flow, two flow-based graph bipartitioning algorithms have been
proposed for road networks. While FlowCutter achieves high-quality results and
thus fast query times, it is rather slow. Inertial Flow is particularly fast
due to the use of geographical information while still achieving acceptable
quality. We combine the techniques of both algorithms to achieve more than six
times faster preprocessing times than FlowCutter and even slightly better
quality. We show that using 16 cores of a shared-memory machine, this
preprocessing needs four minutes on the Europe road network.
</p></div>
    </summary>
    <updated>2019-06-28T23:28:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11750</id>
    <link href="http://arxiv.org/abs/1906.11750" rel="alternate" type="text/html"/>
    <title>A Constant-Factor Approximation Algorithm for Online Coverage Path Planning with Energy Constraint</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dutta:Ayan.html">Ayan Dutta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Gokarna.html">Gokarna Sharma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11750">PDF</a><br/><b>Abstract: </b>In this paper, we study the problem of coverage planning by a mobile robot
with a limited energy budget. The objective of the robot is to cover every
point in the environment while minimizing the traveled path length. The
environment is initially unknown to the robot. Therefore, it needs to avoid the
obstacles in the environment on-the-fly during the exploration. As the robot
has a specific energy budget, it might not be able to cover the complete
environment in one traversal. Instead, it will need to visit a static charging
station periodically in order to recharge its energy. To solve the stated
problem, we propose a budgeted depth-first search (DFS)-based exploration
strategy that helps the robot to cover any unknown planar environment while
bounding the maximum path length to a constant-factor of the shortest-possible
path length. Our $O(1)$-approximation guarantee advances the state-of-the-art
of log-approximation for this problem. Simulation results show that our
proposed algorithm outperforms the current state-of-the-art algorithm both in
terms of the traveled path length and run time in all the tested environments
with concave and convex obstacles.
</p></div>
    </summary>
    <updated>2019-06-28T23:22:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11700</id>
    <link href="http://arxiv.org/abs/1906.11700" rel="alternate" type="text/html"/>
    <title>Efficient algorithms for modifying and sampling from a categorical distribution</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Daniel.html">Daniel Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11700">PDF</a><br/><b>Abstract: </b>Probabilistic programming languages and other machine learning applications
often require samples to be generated from a categorical distribution where the
probability of each one of $n$ categories is specified as a parameter. If the
parameters are hyper-parameters then they need to be modified, however, current
implementations of categorical distributions take $\mathcal{O}(n)$ time to
modify a parameter. If $n$ is large and the parameters are being frequently
modified, this can become prohibitive. Here we present the insight that a
Huffman tree is an efficient data structure for representing categorical
distributions and present algorithms to generate samples as well as add, delete
and modify categories in $\mathcal{O}(\log(n))$ time. We demonstrate that the
time to sample from the distribution remains, in practice, within a few percent
of the theoretical optimal value. The same algorithm may also be useful in the
context of adaptive Huffman coding where computational efficiency is important.
</p></div>
    </summary>
    <updated>2019-06-28T23:24:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11524</id>
    <link href="http://arxiv.org/abs/1906.11524" rel="alternate" type="text/html"/>
    <title>Improved Distributed Approximation to Maximum Independent Set</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khoury:Seri.html">Seri Khoury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schild:Aaron.html">Aaron Schild</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwartzman:Gregory.html">Gregory Schwartzman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11524">PDF</a><br/><b>Abstract: </b>We present improved results for approximating Maximum Independent Set
($\MaxIS$) in the standard LOCAL and CONGEST models of distributed computing.
Let $n$ and $\Delta$ be the number of nodes and maximum degree in the input
graph, respectively. Bar-Yehuda et al. [PODC 2017] showed that there is an
algorithm in the CONGEST model that finds a $\Delta$-approximation to $\MaxIS$
in $O(\MIS(n,\Delta)\log W)$ rounds, where $\MIS(n,\Delta)$ is the running time
for finding a \emph{maximal} independent set, and $W$ is the maximum weight of
a node in the network. Whether their algorithm is randomized or deterministic
depends on the $\MIS$ algorithm that they use as a black-box. Our results: (1)
A deterministic $O(\MIS(n,\Delta))$ rounds algorithm for
$O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (2) A randomized
$2^{O(\sqrt{\log \log n})}$ rounds algorithm that finds, with high probability,
an $O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (3) An
$\Omega(\log^*n)$ lower bound for any randomized algorithm that finds an
independent set of size $\Omega(n/\Delta)$ that succeeds with probability at
least $1-1/\log n$, even for the LOCAL model. This hardness result applies for
graphs of maximum degree $\Delta=O(n/\log^*n)$. One might wonder whether the
same hardness result applies for low degree graphs. We rule out this
possibility with our next result. (4) An $O(1)$ rounds algorithm that finds an
independent set of size $\Omega(n/\Delta)$ in graphs with maximum degree
$\Delta\leq n/\log n$, with high probability. Due to a lower bound of
$\Omega(\sqrt{\log n/\log \log n})$ that was given by Kuhn, Moscibroda and
Wattenhofer [JACM, 2016] on the number of rounds for finding a maximal
independent set ($\MIS$) in the LOCAL model, even for randomized algorithms,
our second result implies that finding an $O(\Delta)$-approximation to $\MaxIS$
is strictly easier than $\MIS$.
</p></div>
    </summary>
    <updated>2019-06-28T23:24:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11447</id>
    <link href="http://arxiv.org/abs/1906.11447" rel="alternate" type="text/html"/>
    <title>Improved Upper Bounds on the Growth Constants of Polyominoes and Polycubes</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barequet:Gill.html">Gill Barequet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shalah:Mira.html">Mira Shalah</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11447">PDF</a><br/><b>Abstract: </b>A $d$-dimensional polycube is a facet-connected set of cells (cubes) on the
$d$-dimensional cubical lattice~$\mathbb{Z}^d$. Let~$A_d(n)$ denote the number
of $d$-dimensional polycubes (distinct up to translations) with~$n$ cubes,
and~$\lambda_d$ denote the limit of the ratio~$A_d(n{+}1)/A_d(n)$ as~$n \to
\infty$. The exact value of~$\lambda_d$ is still unknown rigorously for any
dimension~$d \geq 2$; the asymptotics of~$\lambda_d$, as~$d \to \infty$, also
remained elusive as of today. In this paper, we revisit and extend the approach
presented by Klarner and Rivest in~1973 to bound $A_2(n)$ from above. Our
contributions are: Using available computing power, we prove that~$\lambda_2
\leq 4.5252$. This is the first improvement of the upper bound on~$\lambda_2$
in almost half a century; We prove that~$\lambda_d \leq (2d-2)e+o(1)$ for any
value of~$d \geq 2$, using a novel construction of a rational generating
function which dominates that of the sequence~$\left(A_d(n)\right)$; For $d=3$,
this provides a subtantial improvement of the upper bound on~$\lambda_3$
from~12.2071 to~9.8073;%~10.016; However, we implement an iterative process in
three dimensions, which improves further the upper bound
on~$\lambda_3$to~$9.3835$;
</p></div>
    </summary>
    <updated>2019-06-28T23:32:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11423</id>
    <link href="http://arxiv.org/abs/1906.11423" rel="alternate" type="text/html"/>
    <title>Vector Programming Using Generative Recursion</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moraz=aacute=n:Marco_T=.html">Marco T. Morazán</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11423">PDF</a><br/><b>Abstract: </b>Vector programming is an important topic in many Introduction to Computer
Science courses. Despite the importance of vectors, learning vector programming
is a source of frustration for many students. Much of the frustration is rooted
in discovering the source of bugs that are manifested as out-of-bounds
indexing. The problem is that such bugs are, sometimes, rooted in incorrectly
computing an index. Other times, however, these errors are rooted in mistaken
reasoning about how to correctly process a vector. Unfortunately, either way,
all too often beginners are left adrift to resolve indexing errors on their
own. This article extends the work done on vector programming using vector
intervals and structural recursion to using generative recursion. As for
problems solved using structural recursion, vector intervals provide beginners
with a useful framework for designing code that properly indexes vectors. This
article presents the methodology and concrete examples that others may use to
build their own CS1 modules involving vector programming using any programming
language.
</p></div>
    </summary>
    <updated>2019-06-28T23:24:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11385</id>
    <link href="http://arxiv.org/abs/1906.11385" rel="alternate" type="text/html"/>
    <title>A Tight Analysis of Greedy Yields Subexponential Time Approximation for Uniform Decision Tree</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ray.html">Ray Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Percy.html">Percy Liang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mussmann:Stephen.html">Stephen Mussmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11385">PDF</a><br/><b>Abstract: </b>Decision Tree is a classic formulation of active learning: given $n$
hypotheses with nonnegative weights summing to 1 and a set of tests that each
partition the hypotheses, output a decision tree using the provided tests that
uniquely identifies each hypothesis and has minimum (weighted) average depth.
Previous works showed that the greedy algorithm achieves a $O(\log n)$
approximation ratio for this problem and it is NP-hard beat a $O(\log n)$
approximation, settling the complexity of the problem. However, for Uniform
Decision Tree, i.e. Decision Tree with uniform weights, the story is more
subtle. The greedy algorithm's $O(\log n)$ approximation ratio is the best
known, but the largest approximation ratio known to be NP-hard is
$4-\varepsilon$. We prove that the greedy algorithm gives a $O(\frac{\log
n}{\log C_{OPT}})$ approximation for Uniform Decision Tree, where $C_{OPT}$ is
the cost of the optimal tree and show this is best possible for the greedy
algorithm. As a corollary, this resolves a conjecture of Kosaraju, Przytycka,
and Borgstrom. Our results also hold for instances of Decision Tree whose
weights are not too far from uniform. Leveraging this result, we exhibit a
subexponential algorithm that yields an $O(1/\alpha)$ approximation to Uniform
Decision Tree in time $2^{O(n^\alpha)}$. As a corollary, achieving any
super-constant approximation ratio on Uniform Decision Tree is not NP-hard,
assuming the Exponential Time Hypothesis. This work therefore adds
approximating Uniform Decision Tree to a small list of natural problems that
have subexponential algorithms but no known polynomial time algorithms. Like
the greedy algorithm, our subexponential algorithm gives similar guarantees
even for slightly nonuniform weights.
</p></div>
    </summary>
    <updated>2019-06-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11366</id>
    <link href="http://arxiv.org/abs/1906.11366" rel="alternate" type="text/html"/>
    <title>Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Yihe.html">Yihe Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hopkins:Samuel_B=.html">Samuel B. Hopkins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11366">PDF</a><br/><b>Abstract: </b>We study two problems in high-dimensional robust statistics: \emph{robust
mean estimation} and \emph{outlier detection}. In robust mean estimation the
goal is to estimate the mean $\mu$ of a distribution on $\mathbb{R}^d$ given
$n$ independent samples, an $\varepsilon$-fraction of which have been corrupted
by a malicious adversary. In outlier detection the goal is to assign an
\emph{outlier score} to each element of a data set such that elements more
likely to be outliers are assigned higher scores. Our algorithms for both
problems are based on a new outlier scoring method we call QUE-scoring based on
\emph{quantum entropy regularization}. For robust mean estimation, this yields
the first algorithm with optimal error rates and nearly-linear running time
$\widetilde{O}(nd)$ in all parameters, improving on the previous fastest
running time $\widetilde{O}(\min(nd/\varepsilon^6, nd^2))$. For outlier
detection, we evaluate the performance of QUE-scoring via extensive experiments
on synthetic and real data, and demonstrate that it often performs better than
previously proposed algorithms. Code for these experiments is available at
https://github.com/twistedcubic/que-outlier-detection .
</p></div>
    </summary>
    <updated>2019-06-28T23:22:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11337</id>
    <link href="http://arxiv.org/abs/1906.11337" rel="alternate" type="text/html"/>
    <title>Voronoi Cells in Metric Algebraic Geometry of Plane Curves</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Madeline Brandt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Madeleine.html">Madeleine Weinstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11337">PDF</a><br/><b>Abstract: </b>Voronoi cells of varieties encode many features of their metric geometry. We
prove that each Voronoi or Delaunay cell of a plane curve appears as the limit
of a sequence of cells obtained from point samples of the curve. We then use
this result to study metric features of plane curves, including the medial
axis, curvature, evolute, bottlenecks, and reach. In each case, we provide
algebraic equations defining the object and, where possible, give formulas for
the degrees of these algebraic varieties. We then show how to identify the
desired metric feature from Voronoi or Delaunay cells, and therefore how to
approximate it by a finite point sample from the variety.
</p></div>
    </summary>
    <updated>2019-06-28T23:32:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.11327</id>
    <link href="http://arxiv.org/abs/1906.11327" rel="alternate" type="text/html"/>
    <title>The Adversarial Robustness of Sampling</title>
    <feedworld_mtime>1561680000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yogev:Eylon.html">Eylon Yogev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.11327">PDF</a><br/><b>Abstract: </b>Random sampling is a fundamental primitive in modern algorithms, statistics,
and machine learning, used as a generic method to obtain a small yet
"representative" subset of the data. In this work, we investigate the
robustness of sampling against adaptive adversarial attacks in a streaming
setting: An adversary sends a stream of elements from a universe $U$ to a
sampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with the
goal of making the sample "very unrepresentative" of the underlying data
stream. The adversary is fully adaptive in the sense that it knows the exact
content of the sample at any given point along the stream, and can choose which
element to send next accordingly, in an online manner.
</p>
<p>Well-known results in the static setting indicate that if the full stream is
chosen in advance (non-adaptively), then a random sample of size $\Omega(d /
\varepsilon^2)$ is an $\varepsilon$-approximation of the full data with good
probability, where $d$ is the VC-dimension of the underlying set system
$(U,R)$. Does this sample size suffice for robustness against an adaptive
adversary? The simplistic answer is \emph{negative}: We demonstrate a set
system where a constant sample size (corresponding to VC-dimension $1$)
suffices in the static setting, yet an adaptive adversary can make the sample
very unrepresentative, as long as the sample size is (strongly) sublinear in
the stream length, using a simple and easy-to-implement attack.
</p>
<p>However, this attack is "theoretical only", requiring the set system size to
(essentially) be exponential in the stream length. This is not a coincidence:
We show that to make Bernoulli or reservoir sampling robust against adaptive
adversaries, the modification required is solely to replace the VC-dimension
term $d$ in the sample size with the cardinality term $\log |R|$. This nearly
matches the bound imposed by the attack.
</p></div>
    </summary>
    <updated>2019-06-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5703612485495687112</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5703612485495687112/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5703612485495687112" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5703612485495687112" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html" rel="alternate" type="text/html"/>
    <title>FCRC 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-1zksIfUU-7U/XRToEil7J7I/AAAAAAABpiI/nR4seqK1l08FfLoalQyM2OzdK3iZTwL2ACKgBGAs/s1600/MVIMG_20190626_112006_1.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" height="240" src="https://1.bp.blogspot.com/-1zksIfUU-7U/XRToEil7J7I/AAAAAAABpiI/nR4seqK1l08FfLoalQyM2OzdK3iZTwL2ACKgBGAs/s320/MVIMG_20190626_112006_1.jpg" width="320"/></a></td></tr>
<tr><td class="tr-caption" style="text-align: center;">Georgia Tech FCRC Participants</td></tr>
</tbody></table>
I'm heading home from the <a href="https://fcrc.acm.org/">2019 ACM Federated Computing Research Conference</a> in Phoenix, a collection of computer science meetings including <a href="http://acm-stoc.org/stoc2019/">STOC</a>, <a href="http://learningtheory.org/colt2019/">COLT</a> and <a href="http://www.sigecom.org/ec19/">EC</a>.<br/>
<br/>
Geoff Hinton and Yann LeCun gave their Turing award lectures, their co-winner Yoshua Bengio not in attendance. Hinton talked about how machine learning triumphed over symbolic AI. LeCun argued that under uncertainty, one should learn the distribution instead of just the average. If you want more, just <a href="https://fcrc.acm.org/turing-lecture-at-fcrc-2019">watch it yourself</a>.<br/>
<div style="text-align: left;">
<br/></div>
<div style="text-align: left;">
To get to the STOC lectures you go up and down escalators and pass through ISCA (Computer Architecture) and PLDI (Programming Languages). It's like you are going up the computing stack until you reach algorithms and complexity. </div>
<div style="text-align: left;">
<br/>
The conference center was just two blocks from Chase Field so we could take in a Diamondbacks baseball game. They opened the roof because the temperature dropped into the double digits. Last night, Paul McCartney played at an arena just a block from the conference center, but instead I hung out at an Uber reception for the EC conference.<br/>
<br/></div>
<div style="text-align: left;">
Let me mention a best paper awardee, <a href="https://doi.org/10.1145/3313276.3316369">The Reachability Problem for Petri Nets is Not Elementary</a> by Wojciech Czerwinski, Slawomir Lasota, Ranko Lazic, Jerome Leroux and Filip Mazowiecki. In a Petri net you have a list of vectors of integers and an initial and final vector. You start with the initial vector and can add any of the other vectors nondeterministically as often as you like as long as no coordinate goes negative. Can you get to the final vector? This problem was known to be computable in "Ackermannian" time and EXPSPACE-hard. This paper shows the problem is not elementary, i.e. not solvable in running time a tower of 2's to the n. A <a href="https://arxiv.org/abs/1903.08575">recent result</a> shows Petri Nets reachability is primitive recursive for fixed dimensions.<br/>
<br/>
Avi Wigderson gave the Knuth Prize lecture exploring deep connections between mathematics and algorithms. Hopefully the video will be online soon.<br/>
<br/>
STOC next year in Chicago, EC as part of the Game Theory Congress in Budapest. </div></div>
    </content>
    <updated>2019-06-27T20:34:00Z</updated>
    <published>2019-06-27T20:34:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-28T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/06/27/student-combinatorics-day-at-bar-ilan-university-israel/</id>
    <link href="https://cstheory-events.org/2019/06/27/student-combinatorics-day-at-bar-ilan-university-israel/" rel="alternate" type="text/html"/>
    <title>Student Combinatorics Day at Bar Ilan University (Israel)</title>
    <summary>July 7, 2019 Bar Ilan University, Israel https://sites.google.com/a/math.biu.ac.il/student-combinatorics-day/ A one-day workshop in Combinatorics composed of a keynote talk of Noga Alon on list coloring and of 15 short talks by graduate students and postdocs.</summary>
    <updated>2019-06-27T16:35:25Z</updated>
    <published>2019-06-27T16:35:25Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-06-28T23:35:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/090" rel="alternate" type="text/html"/>
    <title>TR19-090 |  Quasilinear time list-decodable codes for space bounded channels | 

	Ronen Shaltiel</title>
    <summary>We consider codes for space bounded channels. This is a model for communication under noise that was studied by Guruswami and Smith (J. ACM 2016) and lies between the Shannon (random) and Hamming (adversarial) models. In this model, a channel is a space bounded procedure that reads the codeword in one pass, and modifies at most a $p$ fraction of the bits of the codeword.

Guruswami and Smith, and later work by Shaltiel and Silbak (RANDOM 2016), gave constructions of list-decodable codes with rate approaching $1-H(p)$ against channels with space $s=c \log n$, with encoding/decoding time $\poly(2^s)=\poly(n^c)$.

In this paper we show that for every constant $0 \le p 0$, there are codes with rate $R \ge 1-H(p)-\epsilon$, list size $\poly(1/\epsilon)$, and furthermore:
\begin{itemize}
\item Our codes can handle channels with space $s=n^{\Omega(1)}$, which is much larger than $O(\log n)$ achieved by previous work.
\item We give encoding and decoding algorithms that run in time $n \cdot \polylog(n)$. Previous work achieved large and unspecified $\poly(n)$ time (even for space $s=1 \cdot \log n$ channels).
\item We can handle space bounded channels that read the codeword in any order, whereas previous work considered channels that read the codeword in the standard order.
\end{itemize}
Our construction builds on the machinery of Guruswami and Smith (with some key modifications) replacing some nonconstructive codes and pseudorandom objects (that are found in exponential time by brute force) with efficient explicit constructions.
For this purpose we exploit recent results of Haramaty, Lee and Viola (SICOMP 2018) on pseudorandom properties of ``$t$-wise independence + low weight noise'' which we quantitatively improve using techniques by Forbes and Kelly (FOCS 2018).

To make use of such distributions, we give new explicit constructions of binary linear codes that have dual distance of $n^{\Omega(1)}$, and are also polynomial time list-decodable from relative distance $\half-\epsilon$, with list size $\poly(1/\epsilon)$. To the best of our knowledge, no such construction was previously known.

Somewhat surprisingly, we show that Reed-Solomon codes with dimension $k&lt;\sqrt{n}$, have this property if interpreted as binary codes (in some specific interpretation) which we term: ``Raw Reed-Solomon Codes''. A key idea is viewing Reed-Solomon codes as ``bundles'' of certain dual-BCH codewords.</summary>
    <updated>2019-06-27T11:33:00Z</updated>
    <published>2019-06-27T11:33:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-06-28T23:34:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1278</id>
    <link href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/" rel="alternate" type="text/html"/>
    <title>Edit-a-thon update</title>
    <summary>This event was a great success! Thank you to all of the participants for contributing your time. Please keep up the momentum and continue to edit the pages you made a start on. Please continue to record your progress on the list of topics. Special thanks to Aviad Rubinstein and Yuval Filmus for offering expert […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://thmatters.wordpress.com/2019/06/11/wikipedia-edit-a-thon-at-stoc19/">This event</a> was a great success! Thank you to all of the participants for contributing your time. Please keep up the momentum and continue to edit the pages you made a start on. Please continue to record your progress on the <a href="https://docs.google.com/spreadsheets/d/1zVUdxKk9nqR5Itwc37v26aRHMqgV9qI8XexssoFq_CE/edit?usp=sharing">list of topics</a>. Special thanks to Aviad Rubinstein and Yuval Filmus for offering expert advice at the event.</p>
<p>We plan to organize this event again at future STOCs, and hope many more people can participate. Even an hour of your time can have a huge impact on the community!</p>
<p><img alt="20190625_212644" class="  wp-image-1279 aligncenter" height="352" src="https://thmatters.files.wordpress.com/2019/06/20190625_212644.jpg?w=470&amp;h=352" width="470"/></p></div>
    </content>
    <updated>2019-06-26T15:54:42Z</updated>
    <published>2019-06-26T15:54:42Z</published>
    <category term="Uncategorized"/>
    <category term="workshops"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-06-28T23:34:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=645</id>
    <link href="https://emanueleviola.wordpress.com/2019/06/25/we-knew-the-best-threshold-circuit-lower-bounds-long-ago/" rel="alternate" type="text/html"/>
    <title>We knew the best threshold-circuit lower bounds long ago</title>
    <summary>For more than 20 years we’ve had lower bounds for threshold circuits of depth [IPS97], for a fixed . There have been several “explanations” for the lack of progress [AK10]. Recently Chen and Tell have given a better explanation showing that you can’t even improve the result to a better without proving “the whole thing.” […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>     <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->                 <!-- html,xhtml,-css,NoFonts -->     </p>
<p style="text-align: justify;">For more than 20 years we’ve had <img alt="n^{1+c^{-d}}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Bc%5E%7B-d%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+c^{-d}}"/> lower bounds for threshold circuits of depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XImpagliazzoPS97">IPS97</a>]</span>, for a fixed <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. There have been several “explanations” for the lack of progress <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAllenderK10">AK10</a>]</span>. Recently <a href="https://www.google.com/url%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26cad%3Drja%26uact%3D8%26ved%3D2ahUKEwiVrqqOgoXjAhWF1FkKHUgiBjcQFjAAegQIAhAC%26url%3Dhttps%3A%2F%2Feccc.weizmann.ac.il%2Freport%2F2018%2F199%2Fdownload%26usg%3DAOvVaw342o4eSvZMdt_vhMYa7kwk">Chen and Tell</a> have given a better explanation showing that you can’t even improve the result to a better <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> without proving “the whole thing.” </p>
<p style="text-align: justify;">   Say you have a finite group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and you want to compute the <em>iterated product</em> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> elements. </p>
<p style="text-align: justify;">   <b>Warm-up <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAllenderK10">AK10</a>]</span>.</b>. </p>
<p style="text-align: justify;">   Suppose you can compute this with circuits of size <img alt="s(n)=n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Dn%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=n^{10}"/> and depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. Now we show how you can trade size for depth. Put a complete tree with fan-in <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> on top of the group product, where each node computes the product of its children (this is correct by associativity, in general this works for a monoid). This tree needs depth <img alt="\log _{f}n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+_%7Bf%7Dn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log _{f}n"/>. If you stick your circuit of size <img alt="s(n)" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)"/> and depth <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> at each node, the depth of the overall circuit would be obviously <img alt="O(\log _{f}n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+_%7Bf%7Dn%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log _{f}n)"/> and the overall size would be dominated by the input layer which is <img alt="s(f)\cdot n/f&lt;s(f)\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=s%28f%29%5Ccdot+n%2Ff%3Cs%28f%29%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(f)\cdot n/f&lt;s(f)\cdot n"/>. If you are aiming for overall depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, you need <img alt="f=n^{O(1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dn%5E%7BO%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=n^{O(1/d)}"/>. This gives size <img alt="n^{1+O(1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2BO%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+O(1/d)}"/>. </p>
<p style="text-align: justify;">   Hence we have shown that proving bounds <img alt="n^{1+\omega (1/d)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Comega+%281%2Fd%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\omega (1/d)}"/> for some depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> suffices to prove <img alt="n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{10}"/> lower bounds for depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. </p>
<p style="text-align: justify;">   <b>Chen and Tell.</b>. </p>
<p style="text-align: justify;">   The above is not the most efficient way to build a tree! I am writing this post following their paper to understand what they do. As they say, the idea is quite simple. While above the size will be dominated by the input layer, we want to balance things so that every layer has roughly the same contribution. </p>
<p style="text-align: justify;">   Let’s say we are aiming for size <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> and let’s see what depth we can get. Let’s say now the size is <img alt="s(n)=n^{k}" class="latex" src="https://s0.wp.com/latex.php?latex=s%28n%29%3Dn%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s(n)=n^{k}"/>. Let us denote by <img alt="n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}"/> the number of nodes at level <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> with <img alt="i=0" class="latex" src="https://s0.wp.com/latex.php?latex=i%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i=0"/> being the root. The fan-in at level <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> is <img alt="(n^{1+\epsilon }/n_{i})^{1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(n^{1+\epsilon }/n_{i})^{1/k}"/> so that the cost is <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> as desired. We have the recursion <img alt="n_{i+1}=n_{i}\cdot (n^{1+\epsilon }/n_{i})^{1/k}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%2B1%7D%3Dn_%7Bi%7D%5Ccdot+%28n%5E%7B1%2B%5Cepsilon+%7D%2Fn_%7Bi%7D%29%5E%7B1%2Fk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i+1}=n_{i}\cdot (n^{1+\epsilon }/n_{i})^{1/k}"/>. </p>
<p style="text-align: justify;">   The solution to this recursion is <img alt="n_{i}=n^{(1+\epsilon )(1-(1-1/k)^{i})}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%281-1%2Fk%29%5E%7Bi%7D%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}=n^{(1+\epsilon )(1-(1-1/k)^{i})}"/>, see below. </p>
<p style="text-align: justify;">   So that’s it. We need to get to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> nodes. So if you set <img alt="i=O(k\log (1/\epsilon ))" class="latex" src="https://s0.wp.com/latex.php?latex=i%3DO%28k%5Clog+%281%2F%5Cepsilon+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i=O(k\log (1/\epsilon ))"/> you get say <img alt="n_{i}=n^{(1+\epsilon )(1-\epsilon ^{2})}&gt;n" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D%3Dn%5E%7B%281%2B%5Cepsilon+%29%281-%5Cepsilon+%5E%7B2%7D%29%7D%3En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}=n^{(1+\epsilon )(1-\epsilon ^{2})}&gt;n"/>. Going back to <img alt="k=10" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=10"/>, we have exhibited circuits of size <img alt="n^{1+\epsilon }" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2B%5Cepsilon+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{1+\epsilon }"/> and depth just <img alt="O(\log 1/\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+1%2F%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log 1/\epsilon )"/>. So proving stronger bounds than this would rule out circuits of size <img alt="n^{10}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B10%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^{10}"/> and depth <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="10"/>. </p>
<p style="text-align: justify;">   <b>Added later: About the recurrence</b>. </p>
<p style="text-align: justify;">   Letting <img alt="a_{i}:=\log _{n}n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D%3A%3D%5Clog+_%7Bn%7Dn_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{i}:=\log _{n}n_{i}"/> we have the following recurrence for the exponents of <img alt="n_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=n_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n_{i}"/>. </p>
<p style="text-align: justify;">
</p><div style="text-align: center;"> <img alt="\begin{aligned} a_{0} &amp; =0\\ a_{i+1} &amp; =a_{i}(1-1/k)+(1+\epsilon )/k=:a_{i}b+c. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B0%7D+%26+%3D0%5C%5C+a_%7Bi%2B1%7D+%26+%3Da_%7Bi%7D%281-1%2Fk%29%2B%281%2B%5Cepsilon+%29%2Fk%3D%3Aa_%7Bi%7Db%2Bc.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{0} &amp; =0\\ a_{i+1} &amp; =a_{i}(1-1/k)+(1+\epsilon )/k=:a_{i}b+c. \end{aligned}"/> </div>
<p/>
<p style="text-align: justify;">   This gives </p>
<div style="text-align: center;"> <img alt="\begin{aligned} a_{i}=c\sum _{j\le i}b{}^{j}=c\frac {1-b^{i+1}}{1-b}=(1+\epsilon )(1-b^{i+1}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7Bi%7D%3Dc%5Csum+_%7Bj%5Cle+i%7Db%7B%7D%5E%7Bj%7D%3Dc%5Cfrac+%7B1-b%5E%7Bi%2B1%7D%7D%7B1-b%7D%3D%281%2B%5Cepsilon+%29%281-b%5E%7Bi%2B1%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{i}=c\sum _{j\le i}b{}^{j}=c\frac {1-b^{i+1}}{1-b}=(1+\epsilon )(1-b^{i+1}). \end{aligned}"/> </div>
<p/>
<p style="text-align: justify;">   If it was <img alt="a'_{i+1}=a'_{i}+(1+\epsilon )/k" class="latex" src="https://s0.wp.com/latex.php?latex=a%27_%7Bi%2B1%7D%3Da%27_%7Bi%7D%2B%281%2B%5Cepsilon+%29%2Fk&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a'_{i+1}=a'_{i}+(1+\epsilon )/k"/> obviously <img alt="a'_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=a%27_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a'_{k}"/> would already be <img alt="1+\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2B%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+\epsilon "/>. Instead for <img alt="a_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{i}"/> we need to get to <img alt="k\log (1/\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Clog+%281%2F%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\log (1/\epsilon )"/>. </p>
<p style="text-align: justify;">   <b>My two cents.</b>. </p>
<p style="text-align: justify;">   I am not sure I need more evidence that making progress on long-standing bounds in complexity theory is hard, but I do find it interesting to prove these links; we have quite a few by now! The fact that we have been stuck forever just short of proving “the whole thing” makes me think that these long-sought bounds may in fact be false. Would love to be proved wrong, but it’s 2019, this connection is proved by balancing a tree better, and you feel confident that P <img alt="\ne " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cne+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ne "/> NP?    </p>
<h3 class="likesectionHead"><a id="x1-1000"/>References</h3>
<p style="text-align: justify;">
</p><div class="thebibliography">
<p class="bibitem"><span class="biblabel">  [AK10]<span class="bibsp">   </span></span><a id="XAllenderK10"/>Eric Allender and Michal Koucký.  Amplifying lower bounds by         means of self-reducibility. J. of the ACM, 57(3), 2010.         </p>
<p class="bibitem"><span class="biblabel">  [IPS97]<span class="bibsp">   </span></span><a id="XImpagliazzoPS97"/>Russell Impagliazzo, Ramamohan Paturi, and Michael E. Saks.         Size-depth  tradeoffs  for  threshold  circuits.    SIAM  J.  Comput.,         26(3):693–707, 1997. </p>
<p/></div></div>
    </content>
    <updated>2019-06-25T18:02:17Z</updated>
    <published>2019-06-25T18:02:17Z</published>
    <category term="Uncategorized"/>
    <category term="lower bounds"/>
    <category term="review"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-06-28T23:35:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1503</id>
    <link href="https://theorydish.blog/2019/06/24/on-the-importance-of-disciplinary-pride-for-multidisciplinary-collaboration/" rel="alternate" type="text/html"/>
    <title>On the Importance of Disciplinary Pride for Multidisciplinary Collaboration</title>
    <summary>    On the Importance of Disciplinary Pride for Multidisciplinary Collaboration I am a big fan of collaborations, even if they come with their own challenges. I always got further and enjoyed research much more because of my collaborators. I’m forever indebted to so many colleagues and dear, dear friends. Each and every one of them was better than me in some ways. To contribute, I had to remember my own strengths and bring them to the table. The premise of this post is that the same holds for collaboration between fields. It should be read as a call for theoreticians to bring the tools and the powerful way of thinking of TOC into collaborations. We shouldn’t be blind to the limitation of our field but obsessing on those limitations is misguided and would only limit our impact. Instead we should bring our best and trust on the other disciplines we collaborate with to do the same (allowing each to complement and compensate for the other). The context in which these thoughts came to my mind is Algorithmic Fairness. In this and other areas on the interface between society and computing, true collaboration is vital. Not surprisingly, attending multidisciplinary programs [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p> </p>
<p>On the Importance of Disciplinary Pride for Multidisciplinary Collaboration</p>
<p>I am a big fan of collaborations, even if they <a href="https://windowsontheory.org/2014/07/01/collaboration-competition-and-competition-within-collaboration/">come with their own challenges</a>. I always got further and enjoyed research much more because of my collaborators. I’m forever indebted to so many colleagues and dear, dear friends. Each and every one of them was better than me in some ways. To contribute, I had to remember my own strengths and bring them to the table. The premise of this post is that the same holds for collaboration between fields. It should be read as a call for theoreticians to bring the tools and the powerful way of thinking of TOC into collaborations. We shouldn’t be blind to the limitation of our field but obsessing on those limitations is misguided and would only limit our impact. Instead we should bring our best and trust on the other disciplines we collaborate with to do the same (allowing each to complement and compensate for the other).</p>
<p>The context in which these thoughts came to my mind is Algorithmic Fairness. In this and other areas on the interface between society and computing, true <a href="https://theorydish.blog/2018/11/01/simons-cluster-on-algorithmic-fairness/">collaboration is vital</a>. Not surprisingly, attending multidisciplinary programs on Algorithm Fairness, is a major part of my professional activities these days. And I love it – I get to learn so much from people and disciplines that have been thinking about fairness for many decades and centuries. In addition, the Humanities are simply splendid. Multidisciplinary collaborations come with even more challenges than other collaborations: the language, tools and perspectives are different. But for exactly the same reasons they can be even more rewarding. Nevertheless, my fear and the reason for this post is that my less experienced TOC colleagues might come out from those interdisciplinary meetings frustrated and might lose confidence in what TOC can contribute. It feels to me that <a href="http://www.wisdom.weizmann.ac.il/~oded/PDF/toc-sp2.pdf">old lessons</a> about the value of TOC need to be learned again. There is a lot to be proud of, and holding to this pride would in fact make us better collaborators not worse.</p>
<p>In the context of Algorithmic Fairness, we should definitely acknowledge (as we often do) that science exists within political structures, that algorithms are not objective and that mathematical definitions cannot replace social norms as expressed by policy makers. But let’s not take these as excuses for inaction and let’s not withdraw to the role of spectators. In this era of algorithms, other disciplines need us just as much as we need them .</p>
<p> </p></div>
    </content>
    <updated>2019-06-24T16:43:23Z</updated>
    <published>2019-06-24T16:43:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2019-06-28T23:35:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8803689043688761239</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8803689043688761239/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/are-you-smarter-than-5th-grade-amoeba.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8803689043688761239" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8803689043688761239" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/are-you-smarter-than-5th-grade-amoeba.html" rel="alternate" type="text/html"/>
    <title>Are you smarter than a 5th grade amoeba?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(title of this blog is due to Henry Baker who posted an article about this elsewhere)<br/>
<br/>
Amoeba finds approx solution to TSP in linear time:<a href="https://phys.org/news/2018-12-amoeba-approximate-solutions-np-hard-problem.html">here</a>.<br/>
<br/>
Over the years we have seen models of computation that claim to solve NPC or other hard problems quickly. I ask non-rhetorically and with and open mind how they have panned out.<br/>
<br/>
In no particular order:<br/>
<br/>
1) Parallelism. For solving problems faster YES. For speeding up how to solve NPC problems I think YES. For making P=NP somehow NO.  Even so, parallel computers have been a definite practical success.<br/>
<br/>
2) Quantum Computing. Will they factor large numbers anytime soon? Ever? Should we view the effort to build them as an awesome and insightful Physics experiment? Are there any problems that they are NOW doing faster? Is Quantum Crypto (I know, not the same thing) actually used? Will other things of interest come out of the study of quantum computing? It already has, see <a href="https://theoryofcomputing.org/articles/gs002/gs002.pdf">here</a>.<br/>
<br/>
3) DNA computing. Did that lead to practical solutions to NPC problems? I do not think it did. Did that lead to interesting math? Interesting biology? Interesting science?  I do not know.<br/>
<br/>
4) Autistic  computing for finding primes: see <a href="https://blog.computationalcomplexity.org/2009/09/possibly-recruits-for-polymath-primes.html">here</a>. Oliver Sacks, the neurologist ,claimed that two autistic twin brothers could generate large primes quickly. This story was never put to a rigorous test and may not be quite right.<br/>
<br/>
5) Amoeba computing: Too early to tell. The article seems to say it succeeded on 8 cities<br/>
<br/>
The problem with all of these non-standard models of computing is SCALE.  And the more powerful classic computers get, the harder it is for these nonstandard models to compete.<br/>
<br/>
Are these models interesting even if they don't end up getting us fast algorithms? They can be:<br/>
<br/>
1) Do they lead to mathematics of interest? (Quantum- Yes, Parallelism- Yes)<br/>
<br/>
2) Did they inspire algorithms for classical computers? (Quantum- Yes)<br/>
<br/>
3) Do they give insight into other fields? (Quantum for Physics yes, DNA-computing for bio-??)<br/>
<br/>
4) Have they ACTUALLY sped up  up computations in meaningful ways for problems we care about (Parallelism  has)<br/>
<br/>
If  you know of any result which I missed<br/>
<br/>
 (e.g.,<br/>
<br/>
 Amoeba-computing giving insight into evolution,<br/>
<br/>
Autistic computing being used by the NSA to find primes,<br/>
<br/>
 DNA computing  leading to interesting mathematics)<br/>
<br/>
 then leave polite comments!<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-06-24T05:03:00Z</updated>
    <published>2019-06-24T05:03:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-28T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16034</id>
    <link href="https://rjlipton.wordpress.com/2019/06/23/computer-science-gender-gap/" rel="alternate" type="text/html"/>
    <title>Computer Science Gender Gap</title>
    <summary>NY Times article on the paper LinkedIn source Lucy Lu Wang is the lead author of a paper released this Friday on gender parity in computer science. The paper is from the Allen Institute for Artificial Intelligence. The authors are Wang, Gabriel Stanovsky, Luca Weihs, and Oren Etzioni. We will call them WSWE for short. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>NY Times article on the paper</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/23/computer-science-gender-gap/unknown-123/" rel="attachment wp-att-16036"><img alt="" class="alignright size-full wp-image-16036" src="https://rjlipton.files.wordpress.com/2019/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LinkedIn <a href="https://www.linkedin.com/in/lucylw/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Lucy Lu Wang is the lead author of a paper released this Friday on gender parity in computer science. The <a href="https://arxiv.org/pdf/1906.07883.pdf">paper</a> is from the Allen Institute for Artificial Intelligence. The authors are Wang, Gabriel Stanovsky, Luca Weihs, and Oren Etzioni.  We will call them WSWE for short. </p>
<p>
Today we will discuss some of the issues this study raises.</p>
<p>
The paper was highlighted by the New York Times in an <a href="https://www.nytimes.com/2019/06/21/technology/gender-gap-tech-computer-science.html">article</a> titled, “The Gender Gap in Computer Science Research Won’t Close for 100 Years.”  The news article begins with an equally sobering statement of this conclusion:</p>
<blockquote><p><b> </b> <em>Women will not reach parity with men in writing published computer science research in this century if current trends hold, according to a study released on Friday. </em>
</p></blockquote>
<p/><p>
We are for gender-neutral opportunities and have always promoted this—see our earlier discussions <a href="https://rjlipton.wordpress.com/2010/03/23/its-ada-lovelace-day/">here</a> and <a href="https://rjlipton.wordpress.com/2016/10/29/absolute-firsts/">here</a>. We are for doing a better job in supporting women in computer science. The study by WSWE is an important paper that helps frame the problem. Quoting them:</p>
<blockquote><p><b> </b> <em> The field has made more of an effort to reach a more balanced gender status. But the data seems to show that even with all the progress, we are still not making the change fast enough. </em>
</p></blockquote>
<p/><p>
I suggest that you might wish to read the paper. Unfortunately there are many papers with similar conclusions—see <a href="https://aclweb.org/anthology/D18-1301">this</a> by Natalie Schluter, for example. </p>
<p>
</p><p/><h2> Main Points </h2><p/>
<p/><p>
Here are some points of the paper by WSWE:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>There is a measurable gap</i>. No one would, I believe, doubt this. But it is important to see that it is measurable. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The gap is shrinking, but slowly</i>. Again this seems correct, but whether it is shrinking in all relevant measures of publication weight is still an issue.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>The predictions</i>. Perhaps it will not be closed for over a century. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>Modern technology allows such a study</i>. This is one aspect that we can all applaud. WSWE used automated tools that allowed this study to search millions of papers.</p>
<p>
</p><p/><h2> Issues </h2><p/>
<p>
WSWE filtered a corpus of <b>2.87 million</b> papers tagged as in computer science.  The volume constrained their approaches to handling several basic issues.</p>
<p/><p><br/>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> How to tell the gender of an author?  They use first names and try to detect gender from that alone. This is not easy.  Not only can differently-gendered names in different nations or language groups have the same Romanized form, many names apply to both genders within those groups.  The names Taylor and Kelley are perfect examples pf the latter. </p>
<p>
WSWE used a statistical weighing method. So “Taylor,” for example, would be weighted as 55 percent female, 45 percent male.  The weightings come from a large database called <i>Gender API</i> compiled from government and social agencies not directly related to computer science. </p>
<p/><p><br/>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> Another issue concerns the prediction part of their paper. They attempt to extrapolate and guess when there will be parity between female and male authorship. </p>
<p>
As all predictions this is not easy. It is my main complaint with this and other papers on the gender-gap issue. They predict that parity will not be reached until 2167, in 168 years. An earlier <a href="https://www.computerworld.com.au/article/640548/gender-parity-computer-science-could-take-280-years/">study</a> puts the parity point at 280 years away.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I believe that a major issue is hiring by computer science departments and other institutions. A major CS department just hired <img alt="{N&gt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%3E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N&gt;1}"/> assistant professors, of which <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> were male. This is a problem. </p>
<p>
Should studies on the gender gap count all papers? Perhaps they should weight the papers by some citation indices. Are women writing more impactful papers? What percent of papers by gender have citations rate above X?—you get the idea. </p>
<p>
Finally I wonder if parity is the right goal? <b>How about aiming for more women papers than men</b>? Why not?</p>
<p/><p><br/>
[various formatting and word edits]</p></font></font></div>
    </content>
    <updated>2019-06-23T22:33:38Z</updated>
    <published>2019-06-23T22:33:38Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="gender gap"/>
    <category term="gender parity"/>
    <category term="parity"/>
    <category term="study"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-28T23:34:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=203</id>
    <link href="https://minimizingregret.wordpress.com/2019/06/23/lecture-notes-optimization-for-ml/" rel="alternate" type="text/html"/>
    <title>Lecture notes: optimization for ML</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Spring semester is over, yay! To celebrate summer, I’ve compiled lecture notes from the graduate course COS 598D, a.k.a. “optimization for machine learning“. The course is an aftermath of a few lectures and summer school tutorials given in various locations, in which  lectures goal of the course was to present the most useful methods and … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/06/23/lecture-notes-optimization-for-ml/">Continue reading <span class="screen-reader-text">Lecture notes: optimization for ML</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Spring semester is over, yay! To celebrate summer, I’ve compiled lecture notes from the graduate course COS 598D, a.k.a. “<a href="https://sites.google.com/view/optimization4machinelearning/home">optimization for machine learning</a>“.</p>
<p>The course is an aftermath of a few lectures and summer school tutorials given in various locations, in which  lectures goal of the course was to present the most useful methods and ideas in a rigorous-but-not-tedious way:</p>
<ul>
<li>Suitable for a mathematically-prepared undergraduate student, and/or researcher beginning their endeavor into machine learning.</li>
<li>Focus on the important: we start with stochastic gradient descent for training deep neural networks.</li>
<li>Bring out the main ideas: i.e. projection-free methods, second-order optimization, the three main acceleration techniques, qualitatively discuss the advantages and applicability of each.</li>
<li>*short* proofs, that everyone can follow and extend in their future research. I prefer being off by a constant/log factor from the best known bound with a more insightful proof.</li>
<li>Not loose track of the goal: generalization/regret, rather than final accuracy. This means we talked about online learning, generalization and precision issues in ML.</li>
</ul>
<p>The most recent version can be downloaded here:<br/>
<a href="https://drive.google.com/open?id=1GIDnw7T-NT4Do3eC0B5kYJlzwOs6nzIO" title="OPTtutorial">OPTtutorial</a></p>
<p>This is still work in progress, please feel free to send me typos/corrections, as well as other topics you’d like to see (on my todos already: lower bounds, quasi-convexity, and the homotopy method).</p>
<p>Note: zero-order/bandit optimization is an obvious topic that’s not address. The reason is purely subjective – it appears as a chapter in <a href="http://ocobook.cs.princeton.edu/">this textbook</a> (that also started as lecture notes!).</p>
<p> </p></div>
    </content>
    <updated>2019-06-23T21:49:40Z</updated>
    <published>2019-06-23T21:49:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-06-28T23:35:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/06/23/postdoc-at-uc-san-diego-apply-by-august-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/06/23/postdoc-at-uc-san-diego-apply-by-august-1-2019/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by August 1, 2019)</title>
    <summary>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD. Expected start date is October 1, 2019. As this is very late in the season, please apply online […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for strong theory candidates working in the areas of machine learning, optimization, high dimensional statistics, privacy, fairness, and broadly interpreted data science. The postdoc is part of the Data Science fellows program at UCSD.</p>
<p>Expected start date is October 1, 2019. As this is very late in the season, please apply online in the website and ALSO email Shachar.</p>
<p>Website: <a href="http://dsfellows.ucsd.edu/">http://dsfellows.ucsd.edu/</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2019-06-23T20:34:36Z</updated>
    <published>2019-06-23T20:34:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-06-28T23:34:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/06/23/phd-scholarship-in-computer-science-at-european-university-cyprus-apply-by-june-28-2019/</id>
    <link href="https://cstheory-jobs.org/2019/06/23/phd-scholarship-in-computer-science-at-european-university-cyprus-apply-by-june-28-2019/" rel="alternate" type="text/html"/>
    <title>PhD Scholarship in Computer Science at European University Cyprus (apply by June 28, 2019)</title>
    <summary>The Department of Computer Science and Eng. jointly with the Astrophysics and HPC Group of European University Cyprus announce one scholarship for the Ph.D. Program of Computing/Computer Science. The topics are: • Parallel Algorithms and HPC • Graph Theory and Applications • Big Data Applications on Astrophysics Opportunities for extra funding are also available. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science and Eng. jointly with the Astrophysics and HPC Group of European University Cyprus announce one scholarship for the Ph.D. Program of Computing/Computer Science. The topics are: •	Parallel Algorithms and HPC<br/>
•	Graph Theory and Applications<br/>
•	Big Data Applications on Astrophysics<br/>
Opportunities for extra funding are also available.</p>
<p>Website: <a href="http://ahpc.euc.ac.cy/call-of-phd-positions-2/">http://ahpc.euc.ac.cy/call-of-phd-positions-2/</a><br/>
Email: A.Efstathiou@euc.ac.cy</p></div>
    </content>
    <updated>2019-06-23T20:34:36Z</updated>
    <published>2019-06-23T20:34:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-06-28T23:34:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/089</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/089" rel="alternate" type="text/html"/>
    <title>TR19-089 |  Exponential separation between shallow quantum circuits and unbounded fan-in shallow classical circuits | 

	Adam Bene Watts, 

	Robin Kothari, 

	Luke Schaeffer, 

	Avishay Tal</title>
    <summary>Recently, Bravyi, Gosset, and König (Science, 2018) exhibited a search problem called the 2D Hidden Linear Function (2D HLF) problem that can be solved exactly by a constant-depth quantum circuit using bounded fan-in gates (or QNC^0 circuits), but cannot be solved by any constant-depth classical circuit using bounded fan-in AND, OR, and NOT gates (or NC^0 circuits). In other words, they exhibited a search problem in QNC^0 that is not in NC^0.

We strengthen their result by proving that the 2D HLF problem is not contained in AC^0, the class of classical, polynomial-size, constant-depth circuits over the gate set of unbounded fan-in AND and OR gates, and NOT gates. We also supplement this worst-case lower bound with an average-case result: There exists a simple distribution under which any AC^0 circuit (even of nearly exponential size) has exponentially small correlation with the 2D HLF problem. Our results are shown by constructing a new problem in QNC^0, which we call the Relaxed Parity Halving Problem, which is easier to work with. We prove our AC^0 lower bounds for this problem, and then show that it reduces to the 2D HLF problem.

As a step towards even stronger lower bounds, we present a search problem that we call the Parity Bending Problem, which is in QNC^0/qpoly (QNC^0 circuits that are allowed to start with a quantum state of their choice that is independent of the input), but is not even in AC^0[2] (the class AC^0 with unbounded fan-in XOR gates).

All the quantum circuits in our paper are simple, and the main difficulty lies in proving the classical lower bounds. For this we employ a host of techniques, including a refinement of H{\aa}stad's switching lemmas for multi-output circuits that may be of independent interest, the Razborov-Smolensky AC^0[2] lower bound, Vazirani's XOR lemma, and lower bounds for non-local games.</summary>
    <updated>2019-06-23T04:09:25Z</updated>
    <published>2019-06-23T04:09:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-06-28T23:34:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://blog.ilyaraz.org/rss/11</id>
    <link href="https://blog.ilyaraz.org/?go=all/stoc-2019-workshop-data-science-through-a-geometric-lens/" rel="alternate" type="text/html"/>
    <title>STOC 2019 workshop “Data Science through a Geometric Lens”</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>I would like to bring up a <a href="http://acm-stoc.org/stoc2019/">STOC 2019</a> workshop <a href="http://madscience.ucsd.edu/dsgl.html">Data Science through a Geometric Lens</a> (co-organized with <a href="https://cseweb.ucsd.edu/~dasgupta/">Sanjoy Dasgupta</a> and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashchtian</a>). It will happen on Sunday at 9am. We have a stellar line-up of speakers:</p>
<ul>
<li><a href="http://www.cs.cmu.edu/~dwoodruf/">David Woodruff</a></li>
<li><a href="http://sgunasekar.github.io/">Suriya Gunasekar</a></li>
<li><a href="https://voices.uchicago.edu/willett/">Rebecca Willett</a></li>
<li><a href="https://www.stat.washington.edu/person/hanyu-zhang">Hanyu Zhang</a></li>
<li><a href="http://www.columbia.edu/~skk2175/">Samory Kpotufe</a></li>
<li><a href="http://www.cs.cmu.edu/~ninamf/">Nina Balcan</a></li>
</ul>
<p>Some of the topics are a bit unusual for the STOC audience, and we hope you will be inspired by fresh ideas. Please do attend and bring your friends!</p></div>
    </summary>
    <updated>2019-06-23T03:12:56Z</updated>
    <published>2019-06-23T03:12:56Z</published>
    <source>
      <id>https://blog.ilyaraz.org/</id>
      <author>
        <name>Ilya Razenshteyn</name>
      </author>
      <link href="https://blog.ilyaraz.org/" rel="alternate" type="text/html"/>
      <link href="https://blog.ilyaraz.org/rss/" rel="self" type="application/rss+xml"/>
      <title>Lullaby of Cape Cod</title>
      <updated>2019-06-28T23:36:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/21/report-from-socg</id>
    <link href="https://11011110.github.io/blog/2019/06/21/report-from-socg.html" rel="alternate" type="text/html"/>
    <title>Report from SoCG</title>
    <summary>As I mentioned in my previous post, I just finished attending the Symposium on Computational Geometry in Portland. The conference proceedings are open access through LIPIcs.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As I mentioned in <a href="https://11011110.github.io/blog/2019/06/20/portland-street-art.html">my previous post</a>, I just finished attending the Symposium on Computational Geometry in Portland. The <a href="http://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16108">conference proceedings are open access through LIPIcs</a>.</p>

<p>The conference started on Tuesday (after some earlier social activities) with the best paper talk by Arnaud de Mesmay, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.27">Almost tight lower bounds for hard cutting problems in embedded graphs</a>” (with V. Cohen-Addad, É. Colin de Verdière, and D. Marx) proving that, to find the shortest set of cuts to slice a genus- surface into a disk, the exponent must depend linearly on  (assuming the exponential time hypothesis).</p>

<p>Several of the contributed talks from throughout the conference particularly caught my attention:</p>

<ul>
  <li>
    <p>Shay Moran’s paper with A. Yehudayoff, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.51">On weak -nets and the Radon number</a>” concerned abstract convexity spaces where the convex sets are any set family closed under intersection. A space has Radon number  if every  points can be partitioned into two subsets whose convex hulls (smallest containing convex sets) intersect, and a point in the intersection is called a Radon point. Having bounded Radon number turns out to be equivalent to having weak -nets, subsets of points that (for a given measure on the space) intersect every large convex set.</p>
  </li>
  <li>
    <p>Mitchell Jones’ “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.41">Journey to the center of the point set</a>” (with Sariel Har-Peled) improved an old paper of mine on using Radon points to find points of high <a href="https://en.wikipedia.org/wiki/Centerpoint_(geometry)">Tukey depth</a> in high-dimensional point sets in time polynomial in the dimension, improving both the polynomial and the depth of the resulting points.</p>
  </li>
  <li>
    <p>Sariel Har-Peled spoke on his work with Timothy Chan, “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.23">Smallest -enclosing rectangle revisited</a>”. As well as shaving logs from the time bounds for finding rectangles that enclose a given number of points and minimize their area or perimeter, they found a general reduction from problems on  points to  problems on  points, allowing one to turn factors of  in the time bounds into factors of . Previously such reductions were only known for -point subset problems where the optimal solution lies among the  nearest neighbors of some input point, true for rectangle perimeter but not rectangle area.</p>
  </li>
  <li>
    <p>Timothy Chan’s “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.20">Computing Shapley values in the plane</a>” concerns an interesting combination of game theory and computational geometry. The <a href="https://en.wikipedia.org/wiki/Shapley_value">Shapley value</a> is a method for assigning credit when multiple people collaborate to produce some value (given as input a function from subsets of people to the value of a subset). It can be defined by adding contributors one-by-one in a random order and setting each contributor’s Shapley value to the expected increase in value when that contributor is added. It sums to the total value and is the unique function with this property that obeys several other natural and desirable axioms for credit assignment. For arbitrary functions from subsets of  contributors to subset values, it takes time  to compute, but Timothy described polynomial time algorithms for cases when the value function has some geometric meaning, such as when it measures the area of the convex hull of a subset of  points. There’s probably a lot more to be done in the same direction.</p>
  </li>
  <li>
    <p>Patrick Schnider’s “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.56">Ham-Sandwich cuts and center transversals in subspaces</a>” has some partial results towards a conjectured generalization of the <a href="https://en.wikipedia.org/wiki/Ham_sandwich_theorem">ham sandwich theorem</a>: given  probability distributions in -dimensional Euclidean space, it should be possible to find  hyperplanes whose checkerboard partition of space simultaneously bisects all of the distributions.</p>
  </li>
  <li>
    <p>Jie Xue spoke on “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.60">Near-optimal algorithms for shortest paths in weighted unit-disk graphs</a>” (with Haitao Wang). Here “weighted” means that overlapping unit disks are connected by an edge whose length is the Euclidean distance between their centers. Previous methods obtained near-linear algorithms by using bichromatic closest pair data structures to simulate Dijkstra’s algorithm. Instead, Wang and Xue use a related relaxation algorithm that partitions the plane into a grid and at each step relaxes all edges between certain pairs of grid squares, using data structures for additively weighted nearest neighbors. By avoiding the overhead of closest pairs they shave several logs from the runtime.</p>
  </li>
  <li>
    <p>Arnaud de Mesmay spoke again towards the end of the conference on “<a href="https://doi.org/10.4230/LIPIcs.SoCG.2019.49">The unbearable hardness of unknotting</a>”, with Yo’av Rieck, Eric Sedgwick, and Martin Tancer. They used a reduction from 3-satisfiability, with <a href="https://en.wikipedia.org/wiki/Hopf_link">Hopf links</a> for variables and <a href="https://en.wikipedia.org/wiki/Borromean_rings">Borromean links</a> for clauses (connected to each other by ribbons), to prove that it’s NP-complete to find an unlinked subset of a link with a maximum number of components. By a second level of replacement that doubles the strands of each link, they also showed that it’s NP-complete to find the minimum number of crossing changes or of Reidemeister moves to unlink a link or to unknot a knot.</p>
  </li>
</ul>

<p>On Tuesday afternoon I went to the workshop on open problems. After the obligatory open problem session, we debated whether we should collect problems on <a href="https://cs.smith.edu/~jorourke/TOPP/">The Open Problems Project</a>, <a href="http://www.openproblemgarden.org/">The Open Problem Garden</a>, or some new system that, since it doesn’t exist, can be more perfect than anything that does. Then I switched to the Young Researcher’s Forum (unfortunately missing the open problem implementation challenge); at the YRF, my student Daniel Frishberg spoke about <a href="https://arxiv.org/abs/1902.06875">our work on using nearest neighbor chains to speed up greedy algorithms</a>.</p>

<p>The invited talks on Wednesday and Friday were by Sanjoy Dasgupta and Bruce Donald, respectively. Dasgupta spoke on using concepts from geometric data structures to interpret the neural structure of the olfactory system in fruit flies (and hopefully, eventually, vice versa: to use our understanding of neural structures to develop new data structures). For instance, the first three layers of neurons in this system appear to implement an “expand-and-sparsify” data structure that represents low-dimensional normalized vectors by randomly mapping them to much higher dimensional vectors and then listing as a set a smaller number of high-value coordinates. This appears to be closely analogous to known methods for <a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">locality-sensitive hashing</a>.  Donald spoke on using geometric methods to represent and infer the shapes of proteins, and to design proteins with desired shapes and functions.</p>

<p>Wednesday evening was the conference banquet, at the famed <a href="https://en.wikipedia.org/wiki/Crystal_Ballroom_(Portland,_Oregon)">Crystal Ballroom</a>, conveniently located near Powell’s Books. Matthew Dickerson showed up (after many years absence from SoCG) and brought some musical family members for a live concert.</p>

<p style="text-align: center;"><img alt="Marquee for Michael Dickerson and Shaky Situation" src="http://www.ics.uci.edu/~eppstein/pix/portland/ShakySituation-m.jpg" style="border-style: solid; border-color: black;"/></p>

<p>On Thursday afternoon I stopped by the workshop on algebraic methods where I had the pleasure of seing Josh Zahl give his talk on a whiteboard instead of using prepared slides. It was on methods for proving bounds on the number of incidences among geometric objects by combining naive bounds based on forbidden complete bipartite subgraphs of the incidence graphs, cuttings of space into smaller regions within which one applies these naive bounds, and cuttings of the objects into pieces in order to make the forbidden subgraphs smaller.</p>

<p>The conference business meeting was also Thursday, and ran very smoothly.
Next year SoCG will be in Zurich; the year after that, in Buffalo. We now have an officially incorporated society, <a href="http://www.computational-geometry.org/society/index.html">The Society for Computational Geometry</a>, so that we can maintain buffer funds for the conference from one year to the next; it will be supported by an increase of $30-$35 in non-student registration fees. And the attendees voted overwhelmingly in favor of both <a href="https://www.ics.uci.edu/~irani/safetoc.html">the SafeTOC anti-harassment guidelines</a> and ensuring and better advertising the availability of childcare at future conferences.</p>

<p>The conference was dedicated to the memory of <a href="https://en.wikipedia.org/wiki/Richard_M._Pollack">Ricky Pollack</a>, but it also included a celebration on Friday of a living computational geometer: <a href="https://en.wikipedia.org/wiki/John_Hershberger">John Hershberger</a>, who led the effort to bring SoCG to Oregon, and turned 60 just before the conference began. Happy birthday, John!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102313609521577006">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-06-21T22:09:00Z</updated>
    <published>2019-06-21T22:09:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-22T05:38:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1373</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/06/20/optimal-bound-for-stochastic-bandits-with-corruption/" rel="alternate" type="text/html"/>
    <title>Optimal bound for stochastic bandits with corruption</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Guest post by Mark Sellke. In the comments of the previous blog post we asked if the new viewpoint on best of both worlds can be used to get clean “interpolation” results. The context is as follows: in a STOC … <a href="https://blogs.princeton.edu/imabandit/2019/06/20/optimal-bound-for-stochastic-bandits-with-corruption/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Guest post by <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>.</em></p>
<p>In the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/#comments">comments</a> of the previous blog post we asked if the new viewpoint on best of both worlds can be used to get clean “interpolation” results. The context is as follows: in a <a class="liinternal" href="https://arxiv.org/abs/1803.09353">STOC 2018 paper</a> followed by a <a class="liinternal" href="https://arxiv.org/abs/1902.08647">COLT 2019 paper</a>, the following corruption model was discussed: stochastic bandits, except for <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> rounds which are adversarial. The state of the art bounds were of the form: optimal (or almost optimal) stochastic term plus <img alt="K C" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-189063850ed2dd251e3453bcdf72bb1f_l3.png?resize=30%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="30"/>, and it was mentioned as an open problem whether <img alt="KC" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a11b6676b92ebe2d33985ebf5d9107fe_l3.png?resize=30%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="30"/> could be improved to <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> (there is a lower bound showing that <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> is necessary — when <img alt="C = O(\sqrt{T})" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-7a63a8eb07aa9c2f39df62272d6a867e_l3.png?resize=92%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="92"/>). As was discussed in the comment section, it seemed that indeed this clean best of both worlds approach should certainly shed light on the corruption model. It turns out that this is indeed the case, and a one-line calculation resolves positively the open problem from the COLT paper. The formal result is as follows (recall the notation/definitions from <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">the previous blog post</a>):</p>
<blockquote><p><strong>Lemma:</strong> Consider a strategy whose regret with respect to the optimal action <img alt="i^*" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9af0b76a90462b68c1d83fca9cc6604d_l3.png?resize=12%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is upper bounded by</p>
<p class="ql-center-displayed-equation" style="line-height: 56px;"><span class="ql-right-eqno"> (1) </span><span class="ql-left-eqno">   </span><img alt="\begin{equation*} c \sum_{t=1}^T \sum_{i \neq i^*} \sqrt{\frac{x_{i,t}}{t}} \,. \end{equation*}" class="ql-img-displayed-equation " height="56" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2ed2f41c6df060684cac5f6b54464432_l3.png?resize=122%2C56&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="122"/></p>
<p>Then in the <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/>-corruption stochastic bandit model one has that the regret is bounded by:</p>
<p class="ql-center-displayed-equation" style="line-height: 50px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ C + 2 c \sqrt{K C} + c^2 \sum_{i \neq i^*} \frac{\log(T)}{\Delta_i} \]" class="ql-img-displayed-equation " height="50" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c48324ec76e014154981894b80b05577_l3.png?resize=219%2C50&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="219"/></p>
<p> </p></blockquote>
<p>Note that by the previous blog post we know strategies that satisfy (1) with <img alt="c=10" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ac5b38b4377a6b37c2b5319ca167d4c1_l3.png?resize=49%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/> (see Lemma 2 in the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">previous post</a>).</p>
<p><em>Proof: In equation (1) let us apply Jensen over the corrupt rounds, this yields a term <img alt="c \sqrt{K C}" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aec148c42036e82bad7bbc28ce4df79f_l3.png?resize=53%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/>. For the non-corrupt rounds, let us use that</em></p>
<p class="ql-center-displayed-equation" style="line-height: 45px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ c \sqrt{\frac{x_{i,t}}{t}} \leq \frac{1}{2} \left( \Delta_i x_{i,t} + \frac{c^2}{t \Delta_i} \right) \]" class="ql-img-displayed-equation " height="45" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-85bba8f5ccf6308ab72f723bb5aa19b6_l3.png?resize=213%2C45&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="213"/></p>
<p>The sum of the second term on the right hand side is upper bounded by <img alt="c^2 \sum_{i \neq i^*} \frac{\log(T)}{2 \Delta_i}" class="ql-img-inline-formula " height="28" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b9e1680c083d81bc4a40e096a27bda7b_l3.png?resize=109%2C28&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="109"/>. On the other hand the sum (over non-corrupt rounds) of the first term is equal to <img alt="1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c652ece8cc629e4e659c41eeed4d410_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> of the regret over the non-corrupt rounds, which is certainly smaller than <img alt="1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c652ece8cc629e4e659c41eeed4d410_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> of the total regret plus <img alt="C" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eda88fce4ab12a676aa4baf036291115_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/>. Thus we obtain (denoting <img alt="R" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-dfd80738ac64385be5b381ea59d7fe55_l3.png?resize=14%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="14"/> for the total regret):</p>
<p class="ql-center-displayed-equation" style="line-height: 50px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ R \leq c \sqrt{K C} + c^2 \sum_{i \neq i^*} \frac{\log(T)}{2 \Delta_i} + \frac{C}{2} + \frac{R}{2} \]" class="ql-img-displayed-equation " height="50" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-936baa25f1189bd3993ce4dba58242c5_l3.png?resize=290%2C50&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="290"/></p>
<p>which concludes the proof.</p>
<p> </p></div>
    </content>
    <updated>2019-06-20T18:43:39Z</updated>
    <published>2019-06-20T18:43:39Z</published>
    <category term="Machine learning"/>
    <category term="Optimization"/>
    <category term="Theoretical Computer Science"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-06-28T23:35:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=34</id>
    <link href="https://kamathematics.wordpress.com/2019/06/20/theory-and-practice-of-differential-privacy-2019/" rel="alternate" type="text/html"/>
    <title>Theory and Practice of Differential Privacy 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">While I’m a relative newcomer to differential privacy (my first paper on it was only in 2017), I’ve found the community to be a pleasure to interact with: paradoxically, simultaneously tight-knit yet highly welcoming to newcomers. I partially credit this culture to the number of workshops and programs which bring people together, including, but not … <a class="more-link" href="https://kamathematics.wordpress.com/2019/06/20/theory-and-practice-of-differential-privacy-2019/">Continue reading<span class="screen-reader-text"> "Theory and Practice of Differential Privacy 2019"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While I’m a relative newcomer to differential privacy (my <a href="https://arxiv.org/abs/1703.10127">first paper</a> on it was only in 2017), I’ve found the community to be a pleasure to interact with: paradoxically, simultaneously tight-knit yet highly welcoming to newcomers. I partially credit this culture to the number of workshops and programs which bring people together, including, but not limited to, <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5189">a BIRS workshop</a>, <a href="https://privacytools.seas.harvard.edu/">the Privacy Tools project at Harvard</a>, <a href="https://simons.berkeley.edu/programs/privacy2019">a semester at the Simons Institute</a>, <a href="https://shonan.nii.ac.jp/seminars/164/">the forthcoming Shonan workshop</a>, and <a href="https://tpdp.cse.buffalo.edu/">the Theory and Practice of Differential Privacy (TPDP) Workshop</a>.</p>



<p>I’m writing this post to draw attention to the imminent deadline of <a href="https://tpdp.cse.buffalo.edu/2019/">TPDP 2019</a>, co-located with CCS 2019 in London. I’ll spare you the full details (click the link for more information), but most pressing is the deadline tomorrow, June 21, 2019, anywhere on Earth (let me know if this presents hardship for you, and I can pass concerns on to the chair). Essentially anything related to the theory or practice of differential privacy is welcome. Submissions are limited to four pages in length and are lightly refereed, based on originality, relevance, interest, and clarity. There are no published proceedings, and previously published results are welcome. If you’ve been looking to get to know the community, consider either submitting or attending the workshop! </p></div>
    </content>
    <updated>2019-06-20T18:05:19Z</updated>
    <published>2019-06-20T18:05:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2019-06-28T23:36:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/20/portland-street-art</id>
    <link href="https://11011110.github.io/blog/2019/06/20/portland-street-art.html" rel="alternate" type="text/html"/>
    <title>Portland street art</title>
    <summary>I’ve been in Portland, Oregon this week for Computational Geometry Week. Here are a few photos of local street art, the first set I’ve taken with my new Pixel 3 XL cellphone (I neglected to bring an actual camera for this trip):</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve been in Portland, Oregon this week for <a href="http://eecs.oregonstate.edu/socg19/">Computational Geometry Week</a>. Here are a few photos of local street art, the first set I’ve taken with my new Pixel 3 XL cellphone
(I neglected to bring an actual camera for this trip):</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/portland/Clay-2nd-1.html"><img alt="Portland Oregon Street art: Clay &amp; 2nd" src="http://www.ics.uci.edu/~eppstein/pix/portland/Clay-2nd-1-m.jpg" style="border-style: solid; border-color: black;" width="400"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/portland/Clay-2nd-2.html"><img alt="Portland Oregon Street art: Clay &amp; 2nd" src="http://www.ics.uci.edu/~eppstein/pix/portland/Clay-2nd-2-m.jpg" style="border-style: solid; border-color: black;" width="382"/></a></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/portland/Hall-5th-2.html"><img alt="Portland Oregon Street art: Hall &amp; 5th" src="http://www.ics.uci.edu/~eppstein/pix/portland/Hall-5th-2-m.jpg" style="border-style: solid; border-color: black;" width="335"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/portland/College-4th.html"><img alt="Portland Oregon Street art: College &amp; 4th" src="http://www.ics.uci.edu/~eppstein/pix/portland/College-4th-m.jpg" style="border-style: solid; border-color: black;" width="382"/></a></td>
</tr></tbody></table></div>

<p><a href="http://www.ics.uci.edu/~eppstein/pix/portland/index.html">Here are the rest of my photos</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102306697775168322">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-06-20T17:04:00Z</updated>
    <published>2019-06-20T17:04:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-22T05:38:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4207</id>
    <link href="https://www.scottaaronson.com/blog/?p=4207" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4207#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4207" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quanta of Solace</title>
    <summary xml:lang="en-US">In Quanta magazine, Kevin Hartnett has a recent article entitled A New Law to Describe Quantum Computing’s Rise? The article discusses “Neven’s Law”—a conjecture, by Hartmut Neven (head of Google’s quantum computing effort), that the number of integrated qubits is now increasing exponentially with time, so that the difficulty of simulating a state-of-the-art QC on […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <em>Quanta</em> magazine, Kevin Hartnett has a recent article entitled <a href="https://www.quantamagazine.org/does-nevens-law-describe-quantum-computings-rise-20190618/">A New Law to Describe Quantum Computing’s Rise?</a>  The article discusses “Neven’s Law”—a conjecture, by Hartmut Neven (head of Google’s quantum computing effort), that the number of integrated qubits is now increasing exponentially with time, so that the difficulty of simulating a state-of-the-art QC on a fixed classical computer is increasing <em>doubly</em> exponentially with time.  (Jonathan Dowling tells me that he expressed the same thought years ago.)</p>



<p>Near the end, the <em>Quanta</em> piece quotes some UT Austin professor whose surname starts with a bunch of A’s as follows:</p>



<blockquote class="wp-block-quote"><p>“I think the undeniable reality of this progress puts the ball firmly in the court of those who believe scalable quantum computing can’t work.   They’re the ones who need to articulate where and why the progress will stop.”</p></blockquote>



<p>The quote is perfectly accurate, but in context, it might give the impression that I’m endorsing Neven’s Law.  In reality, I’m reluctant to fit a polynomial or an exponential or any other curve through a set of numbers that so far hasn’t exceeded about 50.  I say only that, regardless of what anyone believes is the ultimate rate of progress in QC, what’s already happened today puts the ball firmly in the skeptics’ court.</p>



<p>Also in <em>Quanta</em>, Anil Ananthaswamy has a new article out on <a href="https://www.quantamagazine.org/how-to-turn-a-quantum-computer-into-the-ultimate-randomness-generator-20190619/">How to Turn a Quantum Computer Into the Ultimate Randomness Generator</a>.  This piece covers two schemes for using a quantum computer to generate “certified random bits”—that is, bits you can <em>prove</em> are random to a faraway skeptic.  one due to me, the other due to <a href="https://arxiv.org/abs/1804.00640">Brakerski et al</a>.  The article cites my <a href="https://arxiv.org/abs/1612.05903">paper with Lijie Chen</a>, which shows that under suitable computational assumptions, the outputs in my protocol are hard to spoof using a classical computer.  The randomness aspect will be addressed in a paper that I’m currently writing; for now, see <a href="https://www.scottaaronson.com/talks/certrand2.ppt">these slides</a>.</p>



<p>As long as I’m linking to interesting recent <em>Quanta</em> articles, Erica Klarreich has <a href="https://www.quantamagazine.org/mathematician-disproves-hedetniemis-graph-theory-conjecture-20190617/">A 53-Year-Old Network Coloring Conjecture is Disproved</a>.  Briefly, <a href="https://en.wikipedia.org/wiki/Hedetniemi%27s_conjecture">Hedetniemi’s Conjecture</a> stated that, given any two finite, undirected graphs G and H, the chromatic number of the tensor product G⊗H is just the minimum of the chromatic numbers of G and H themselves.  This reasonable-sounding conjecture has now been <a href="https://arxiv.org/abs/1905.02167">falsified</a> by Yaroslav Shitov.  For more, see also <a href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/">this post by Gil Kalai</a>—who appears here <em>not</em> in his capacity as a quantum computing skeptic.</p>



<p>In interesting math news beyond <em>Quanta</em> magazine, the Berkeley alumni magazine has a piece about the crucial, neglected topic of <a href="https://alumni.berkeley.edu/california-magazine/just-in/2019-06-14/chalk-market-where-mathematicians-go-get-good-stuff">mathematicians’ love for Hagoromo-brand chalk</a> (hat tip: Peter Woit).  I can personally vouch for this.  When I moved to UT Austin three years ago, most offices in CS had whiteboards, but I deliberately chose one with a blackboard.  I figured that chalk has its problems—it breaks, the dust gets all over—but I could live with them, much more than I could live with the Fundamental Whiteboard Difficulty, of all the available markers always being dry whenever you want to explain anything.  With the Hagoromo brand, though, you pretty much get all the benefits of chalk with none of the downsides, so it just strictly dominates whiteboards.</p>



<p>Jan Kulveit asked me to advertise the <a href="https://espr-camp.org/">European Summer Program on Rationality</a> (ESPR), which will take place this August 13-23, and which is aimed at students ages 16-19.  I’ve <a href="https://www.scottaaronson.com/blog/?p=2410">lectured</a> both at ESPR and at a similar summer program that ESPR was modeled after (called SPARC)—and while I was never there as a student, it looked to me like a phenomenal experience.   So if you’re a 16-to-19-year-old who reads this blog, please consider applying!</p>



<p>I’m now at the end of my annual family trip to Tel Aviv, returning to the Eastern US tonight, and then on to <a href="http://acm-stoc.org/stoc2019/stocprogram.html">STOC’2019</a> at the <a href="https://fcrc.acm.org/">ACM Federated Computing Research Conference</a> in Phoenix (which I can blog about if anyone wants me to).  It was a good trip, although marred by my two-year-old son Daniel falling onto sun-heated metal and suffering a second-degree burn on his leg, and then by the doctor botching the treatment.  Fortunately Daniel’s now healing nicely.  For future reference, whenever bandaging a burn wound, <em>be sure</em> to apply lots of Vaseline to prevent the bandage from drying out, and also to change the bandage daily.  Accept no fancy-sounding substitute.</p></div>
    </content>
    <updated>2019-06-20T15:54:37Z</updated>
    <published>2019-06-20T15:54:37Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-06-21T17:58:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7528</id>
    <link href="https://windowsontheory.org/2019/06/20/tcs-women-at-stoc-guest-post-by-virginia-williams/" rel="alternate" type="text/html"/>
    <title>TCS Women at STOC (guest post by Virginia Williams)</title>
    <summary>[Guest post by Virgi Vassilevska Williams on the TCS women program at STOC. In particular the TCS Women Spotlight workshop has a great program and is open to all. –Boaz] Dear all, The TCS Women 2019 program is finalized: https://sigact.org/tcswomen/tcs-women-2019/. Here are some details: On June 23rd, we have our TCS Women Spotlight workshop from 2 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><em>[Guest post by Virgi Vassilevska Williams on the TCS women program at STOC. In particular the TCS Women Spotlight workshop has a great program and is open to all. –Boaz]</em></div>
<div/>
<div>Dear all,</div>
<div/>
<div>The TCS Women 2019 program is finalized: <a href="https://sigact.org/tcswomen/tcs-women-2019/" rel="noopener" target="_blank">https://sigact.org/tcswomen/tcs-women-2019/</a>. Here are some details:</div>
<div/>
<div>On June 23rd, we have our TCS Women Spotlight workshop from 2 pm to 5 pm. This will feature an inspirational talk by Ronitt Rubinfeld (MIT &amp; Tel Aviv University)–“Comedy of Errors”, and rising stars talks by Naama Ben-David (CMU), Debarati Das (Charles University), Andrea Lincoln (MIT) and Oxana <span style="color: #000000;">Poburinnaya (Boston University). The workshop is open to all and we would love to see you all there.</span></div>
<div><span style="color: #000000;"> </span></div>
<div><span style="color: #000000;">On June 24th, we have the TCS Women lunch and panel of distinguished researchers from academia and industries. This year’s panelists include Shuchi Chawla (University of Wisconsin), Julia Chuzhoy (TTIC), Edith Cohen (Google), Faith Ellen (University of Toronto), Rachel Lin (University of Washington) and Nutan Limaye (Indian Institute of Technology, Mumbai). The event is open to all women participants of FCRC.</span></div>
<div><span style="color: #000000;"> </span></div>
<div><span style="color: #000000;">In addition to these, there will be a TCS Women poster session held jointly with the STOC poster session on June 24th. Fourteen women researchers will be presenting posters on their research. More information is available on our website. All are welcome. </span></div>
<div><span style="color: #000000;"> </span></div>
<div><span style="color: #000000;">We are providing travel scholarships to more than forty women students this year to attend STOC and FCRC. We secured funding from the NSF, Akamai, Amazon, Google and Microsoft. Thank you!<br/>
</span></div>
<div><span style="color: #000000;"> </span></div>
<div><span style="color: #000000;">Looking forward to seeing you soon!</span></div>
<div><span style="color: #000000;"> </span></div>
<div><span style="color: #000000;">Best wishes,</span></div>
<div><span style="color: #000000;">The TCS Women organizers</span></div></div>
    </content>
    <updated>2019-06-20T14:33:12Z</updated>
    <published>2019-06-20T14:33:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-06-28T23:34:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8718880846893877693</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8718880846893877693/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/the-urbanrural-collegiality-divide.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8718880846893877693" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8718880846893877693" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/the-urbanrural-collegiality-divide.html" rel="alternate" type="text/html"/>
    <title>The Urban/Rural Collegiality Divide</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
Just a reminder that Grigory Yaroslavtsev has <a href="http://grigory.us/blog/theory-jobs-2019/">taken over</a> the <a href="https://docs.google.com/spreadsheets/d/1Oegc0quwv2PqoR_pzZlUIrPw4rFsZ4FKoKkUvmLBTHM/edit?usp=sharing">Theory Jobs Spreadsheet</a>. Check out who is moving where and let everyone know where you will continue your research career.</div>
<div>
<br/></div>
In 1999 when I considered leaving the University of Chicago for NEC Research I had a conversation with Bob Zimmer, then VP of Research and current U of C President. Zimmer said it was a shame I didn't live in Hyde Park, the Chicago South Side neighborhood where the university resides, and thus not fully connected with the school. At the time I didn't fully understand his point and did leave for NEC, only to return in 2003 and leave again in 2008. I never did live in Hyde Park.<br/>
<div>
<br/></div>
<div>
Recently I served on a review committee for a computer science department in a rural college town. You couldn't help but notice the great collegiality among the faculty. Someone told me their theory that you generally get more faculty collegiality in rural versus urban locations. Why?</div>
<div>
<br/></div>
<div>
In urban locations faculty tend to live further from campus, to get bigger homes and better schools, and face more traffic. They are likely to have more connections with people unconnected with the university. There are more consulting opportunities in large cities, a larger variety of coffee houses to hang out in and better connected airports make leaving town easier. Particularly in computer science, where you can do most of your research remotely, faculty will find themselves less likely to come in every day and you lose those constant informal connections with the rest of the faculty. </div>
<div>
<br/></div>
<div>
This is a recent phenomenon, even going back to when I was a young faculty you needed to come to the office for access to research papers, better computers to write papers, good printers. Interactions with students and colleagues is always better in person but in the past the methods of electronic communication proved more limiting.</div>
<div>
<br/></div>
<div>
The University of Chicago helped create and promote its own neighborhood and ran a very strong private school with reduced tuition for faculty children. Maybe my life would have been different had I immersed myself in that lifestyle. </div>
<div>
<br/></div>
<div>
Or maybe we should go the other extreme. If we can find great ways to do on-line meetings and teaching, why do we need the physical university at all?</div></div>
    </content>
    <updated>2019-06-20T13:18:00Z</updated>
    <published>2019-06-20T13:18:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-28T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16021</id>
    <link href="https://rjlipton.wordpress.com/2019/06/19/diophantine-equations/" rel="alternate" type="text/html"/>
    <title>Diophantine Equations</title>
    <summary>Complexity of solving polynomial equations [ Jeff ] Jeff Lagarias is a mathematician or a professor at the University of Michigan. Today I wish to discuss Diophantine equations. Note, the “or” is a poor joke: For mathematicians is true also when both and are true. Jeff has a paper titled Complexity of Diophantine Equations and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Complexity of solving polynomial equations</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/19/diophantine-equations/jeff/" rel="attachment wp-att-16022"><img alt="" class="alignright  wp-image-16022" src="https://rjlipton.files.wordpress.com/2019/06/jeff.jpg?w=240" width="240"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Jeff ]</font></td>
</tr>
</tbody>
</table>
<p>
Jeff Lagarias is a mathematician <b>or</b> a professor at the University of Michigan.</p>
<p>
Today I wish to discuss Diophantine equations.</p>
<p>
Note, the “or” is a poor joke: For mathematicians <img alt="{A \text{ or } B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Ctext%7B+or+%7D+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \text{ or } B}"/> is true also when both <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> are true.</p>
<p>
Jeff has a paper titled <i>Complexity of Diophantine Equations</i> and related <a href="http://www.math.lsa.umich.edu/~lagarias/TALK-SLIDES/dioph-cplx-icerm2011aug.pdf">talk</a> version. It is a nice review of some of the issues around Diophantine equations. </p>
<p>
He has worked on number theory, on complexity theory, and on many other <a href="https://rjlipton.wordpress.com/2013/09/05/eulers-constants/">problems</a>. Some are applied and some theoretical. He with Peter Shor solved an open problem years ago that was first stated by Ott-Heinrich Keller in 1930. Our friends at Wikipedia <a href="https://en.wikipedia.org/wiki/Keller%27s_conjecture">state</a>: </p>
<blockquote><p><b> </b> <em> In geometry, Keller’s conjecture is the conjecture that in any tiling of Euclidean space by identical hypercubes there are two cubes that meet face to face. </em>
</p></blockquote>
<p>For dimensions ten or more it is now proved to be false thanks to Jeff and Peter. I am amazed by such geometric results, since I have no geometric intuition. Ten dimensions is way beyond me—although curiously I am okay in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> dimensions. Strange? Jeff has a relevant <a href="https://www.azquotes.com/quote/765002">quote</a>:</p>
<blockquote><p>Every dimension is special.</p></blockquote>
<p>
</p><p/><h2> Complexity of Diophantine Equations </h2><p/>
<p/><p>
Recall the main problem is to find solutions to equations usually restricted to be integers or rationals. This restriction makes the problems hard as in <em>open</em>, and hard as in <em>computationally difficult</em>. </p>
<p>
</p><p/><h3>  Factoring-Hard </h3><p/>
<p>Jeff mentions the following hardness result in his talk: Solving in nonnegative integers for <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/> 	</p>
<p align="center"><img alt="\displaystyle  (x+2)(y+2) = N, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x%2B2%29%28y%2B2%29+%3D+N%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (x+2)(y+2) = N, "/></p>
<p>is as hard as integer factoring. This follows since <img alt="{x+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x+2}"/> and <img alt="{y+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y+2}"/> must be non-trivial factors of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>. Note this relies on the fact that <img alt="{x+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x+2}"/> and <img alt="{y+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y+2}"/> are both greater than or equal to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>.</p>
<p>
We can delete “nonnegative” in the above by the following simple idea. Suppose that <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> has two factors that are both congruent to <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> modulo <img alt="{8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8}"/>. If not, then we can still factor, but I believe the idea is clearer without adding extra complications. Then solve in integers 	</p>
<p align="center"><img alt="\displaystyle  (8x + 3)(8y+3) = N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%288x+%2B+3%29%288y%2B3%29+%3D+N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (8x + 3)(8y+3) = N. "/></p>
<p>By assumption on <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> there is a solution of this equation. Moreover suppose that <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/> are some solution. The key is that <img alt="{8x + 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8x+%2B+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8x + 3}"/> cannot be <img alt="{\pm 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm 1}"/> and <img alt="{8y+3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8y%2B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8y+3}"/> also cannot be <img alt="{\pm 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm 1}"/>. Then it follows that each is also not equal to <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> in absolute value. Thus 	</p>
<p align="center"><img alt="\displaystyle  1 &lt; |8x+3| &lt; N, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%3C+%7C8x%2B3%7C+%3C+N%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 &lt; |8x+3| &lt; N, "/></p>
<p>and we have factored <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>.</p>
<p>
</p><p/><h3>  NP-hard </h3><p/>
<p/><p>
Jeff points out that it is unlikely that Diophantine problems are going to be classified by the NP-hard machinery. He says </p>
<blockquote><p><b> </b> <em> <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> shows the (possible) mismatch of “natural” Diophantine problems with the P versus NP question. </em>
</p></blockquote>
<p>Factoring is one of those in between problems that could be in P, but most believe that it could not be NP-hard.</p>
<p>
</p><p/><h2> Rational Case </h2><p/>
<p/><p>
The problem of deciding whether a polynomial has a <i>rational</i> root is still open. That is given a polynomial with integer coefficients, does the equation 	</p>
<p align="center"><img alt="\displaystyle  F(x,y,z,\dots)= 0, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%2Cy%2Cz%2C%5Cdots%29%3D+0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(x,y,z,\dots)= 0, "/></p>
<p>have a rational solution <img alt="{x,y,z,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z,\dots}"/>? Of course the famous Hilbert’s Tenth problem asks for integer solutions of polynomials and is undecidable. The rational case is open. We have discussed it before <a href="https://rjlipton.wordpress.com/2010/08/07/hilberts-tenth-over-the-rationals/">here</a>. See <a href="https://sites.math.washington.edu/~morrow/336_16/2016papers/peter%20gc.pdf">this</a> for a survey. </p>
<p>
I had tried to see if we could at least prove the following: The decision problem over the rationals is at NP-hard. I thought for a while that I could show that solving equations over the rationals is at least NP-hard. My idea was to try to replace <img alt="(x+2)(y+2)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2B2%29%28y%2B2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x+2)(y+2)"/> by a equation that works over the rationals. The attempt failed. I was also unable to find a reference for such a result either. So perhaps it is open.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is it undecidable to determine whether a polynomial has a root over the rationals? Can we at least get that it is factoring hard?</p>
<p/></font></font></div>
    </content>
    <updated>2019-06-19T22:32:53Z</updated>
    <published>2019-06-19T22:32:53Z</published>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="equations"/>
    <category term="Hilbert Tenth"/>
    <category term="NP"/>
    <category term="NP-hard"/>
    <category term="open problem"/>
    <category term="polynomial"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-28T23:34:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=359</id>
    <link href="https://tcsplus.wordpress.com/2019/06/19/the-spring-season-is-behind-us/" rel="alternate" type="text/html"/>
    <title>The Spring season of TCS+ is behind us!</title>
    <summary>With John Wright‘s talk last week, the Spring ’19 season of TCS+ concluded. Thanks to all our followers who tuned in, everyone who suggested a talk or spread the word, and, of course, thanks to all our speakers! For those who missed a talk, or would like to watch them again in the comfort of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>With <a href="https://tcsplus.wordpress.com/2019/06/06/tcs-talk-wednesday-june-12th-john-wright-mit/">John Wright</a>‘s talk last week, the Spring ’19 season of TCS+ concluded. Thanks to all our followers who tuned in, everyone who <a href="https://sites.google.com/site/plustcs/suggest">suggested a talk</a> or spread the word, and, of course, thanks to <a href="https://sites.google.com/site/plustcs/past-talks">all our speakers</a>!</p>
<p>For those who missed a talk, or would like to watch them again in the comfort of your home, institution, or on the seaside: all past talks are now uploaded and available, along with the speakers’ slides.</p>
<ul>
<li>
<ul>
<li>Ran Canetti (Boston University and Tel Aviv University) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190206rancanettibostonuniversityandtelavivuniversity">Fully Bideniable Interactive Encryption</a></em></li>
<li>Sepehr Assadi (Princeton) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190220sepehrassadiprincetonuniversity">A Simple Sublinear-Time Algorithm for Counting Arbitrary Subgraphs via Edge Sampling</a></em></li>
<li>Shayan Oveis Gharan (University of Washington) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190306shayanoveisgharanuniversityofwashington">Strongly log concave polynomials, high dimensional simplicial complexes, and an FPRAS for counting Bases of Matroids </a></em></li>
<li>Aleksandar Nikolov (University of Toronto) on <em><a href="https://sites.google.com/site/plustcs/past-talks/03202019aleksandarnikolovuniversityoftoronto">Sticky Brownian Rounding and its Applications to Constraint Satisfaction Problems</a><br/>
</em></li>
<li>Richard Peng (Georgia Tech) on <em><a href="https://sites.google.com/site/plustcs/past-talks/04032019richardpenggeorgiatech">Fully Dynamic Spectral Vertex Sparsifiers and Applications</a><br/>
</em></li>
<li>Thatchaphol Saranurak (TTIC) on <em><a href="https://sites.google.com/site/plustcs/past-talks/04172019thatchapholsaranurakttic">Breaking Quadratic Time for Small Vertex Connectivity</a><br/>
</em></li>
<li>Chris Peikert (University of Michigan) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190501chrispeikertuniversityofmichigan">Noninteractive Zero Knowledge for NP from Learning With Errors</a><br/>
</em></li>
<li>Ewin Tang (University of Washington) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190515ewintanguniversityofwashington">Quantum-inspired classical linear algebra algorithms: why and how?</a><br/>
</em></li>
<li>Lior Kamma (Aarhus University) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190529liorkammaaarhusuniversity">Lower Bounds for Multiplication via Network Coding</a><br/>
</em></li>
<li>John Wright (MIT) on <em><a href="https://sites.google.com/site/plustcs/past-talks/20190612johnwrightmit">NEEXP in MIP*</a><br/>
</em></li>
</ul>
</li>
</ul>
<p>Have a great summer, and see you in the Fall!</p></div>
    </content>
    <updated>2019-06-19T18:07:07Z</updated>
    <published>2019-06-19T18:07:07Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-06-28T23:35:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2592965474602859939</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2592965474602859939/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/why-does-nevalina-prize-now-abacus-got.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2592965474602859939" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2592965474602859939" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/why-does-nevalina-prize-now-abacus-got.html" rel="alternate" type="text/html"/>
    <title>Why does the Nevalina Prize (now Abacus) got to Algorithms/Complexity people</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In my post about the Nevanlinna prize  name change (see <a href="https://blog.computationalcomplexity.org/2019/06/imus-non-controversial-changing-name-of.html">here</a>) one of my readers raised a different question about the prize:<br/>
<br/>
BEGIN QUOTE<br/>
<br/>
<div style="text-align: start;">
<br/></div>
<span>So there's one of my main questions about the prize answered (or at least resolved). The second remains. The IMU's website(which still refers to the Nevanlinna Prize) says that it is awarded "for outstanding contributions in Mathematical Aspects of Information Sciences including:"</span><br/>
<br/>
<span>1)All mathematical aspects of computer science, including complexity theory, logic of programming languages, analysis of algorithms, cryptography, computer vision, pattern recognition, information processing and modelling of intelligence.</span><br/>
<br/>
<span>2)Scientific computing and numerical analysis. Computational aspects of optimization and control theory. Computer algebra.</span><br/>
<br/>
<span>Correct me if I'm wrong, but it seems that the recognized work of the ten winners of the award all fits into two or three of the possible research areas for which the prize may be rewarded. Why do people think that this is the case?</span><br/>
<br/>
<br/>
<div style="text-align: justify;">
<span><span style="background-color: #ccff99; font-size: 14px;">END QUOTE</span></span></div>
<div style="text-align: justify;">
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span></div>
<div style="text-align: justify;">
<span><span style="background-color: #ccff99; font-size: 14px;">First off, lets see if this is true. Here is a list of all the winners:</span></span></div>
<div style="text-align: justify;">
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span></div>
<div style="text-align: justify;">
<span><span style="background-color: #ccff99; font-size: 14px;">Tarjan, Valiant, Razborov, Wigderson, Shor, Sudan, Kleinberg, Spielman, Khot, Daskalakis </span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">Yup, they all seem to be in Algorithms or Complexity.</span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">Speculation as to why:</span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">1) Algorithms and Complexity have problems with short descriptions that can easily be understood: Tarjan proved Planarity was in O(n) time. Valiant defined Sharp-P and showed the Permanent was Sharp-P complete. Hence it is easy to see what they have done. In many of the fields listed, while people have done great work, it may be harder to tell since the questions are not as clean.  If my way to do Vision is better than your way to do Vision, that may be hard to prove. And the proof  may need to be non-rigorous.</span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">2) If someone does great work in (for example) Logic of Programming Languages, it may not be recognized until she is past 40 years old. </span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">3) This one I am less sure of (frankly I'm not that sure of any of these and invite polite commentary): areas that are more practical may take longer to build and get to work.</span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">But there is still a problem with this. Numerical Analysis and Cryptography would seem to not have these problems. </span></span><br/>
<span><span style="background-color: #ccff99; font-size: 14px;"><br/></span></span>
<span><span style="background-color: #ccff99; font-size: 14px;">I invite the reader to speculate</span></span></div></div>
    </content>
    <updated>2019-06-18T00:59:00Z</updated>
    <published>2019-06-18T00:59:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-28T22:56:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/06/18/robustness-in-learning-and-statistics-past-and-future/</id>
    <link href="https://cstheory-events.org/2019/06/18/robustness-in-learning-and-statistics-past-and-future/" rel="alternate" type="text/html"/>
    <title>Robustness in Learning and Statistics: Past and Future</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">August 12-15, 2019 UC San Diego http://cseweb.ucsd.edu/~slovett/workshops/robust-statistics-2019/ Registration deadline: July 31, 2019 Robust statistics and related topics offer ways to stress test estimators to the assumptions they are making. It offers insights into what makes some estimators behave well in the face of model misspecification, while others do not. In this summer school, we will … <a class="more-link" href="https://cstheory-events.org/2019/06/18/robustness-in-learning-and-statistics-past-and-future/">Continue reading <span class="screen-reader-text">Robustness in Learning and Statistics: Past and Future</span></a></div>
    </summary>
    <updated>2019-06-18T00:13:18Z</updated>
    <published>2019-06-18T00:13:18Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-06-28T23:35:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=23</id>
    <link href="https://kamathematics.wordpress.com/2019/06/17/hello-world/" rel="alternate" type="text/html"/>
    <title>Hello World!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Welcome to my blog! My name is Gautam Kamath, and I just started as an assistant professor in computer science at the University of Waterloo (for more info, see About). This blog will, broadly speaking, be about topics relevant to those interested in the the theory of computer science, statistics, and machine learning. Posts will … <a class="more-link" href="https://kamathematics.wordpress.com/2019/06/17/hello-world/">Continue reading<span class="screen-reader-text"> "Hello World!"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to my blog! My name is Gautam Kamath, and I just started as an assistant professor in computer science at the University of Waterloo (for more info, see <a href="https://kamathematics.wordpress.com/about/">About</a>).</p>



<p>This blog will, broadly speaking, be about topics relevant to those interested in the the theory of computer science, statistics, and machine learning. Posts will range from technical, to informational, to meta (read: basically whatever I want to write about, but I’ll do my best to keep it topical). Stay tuned!</p>



<p>The unofficial theme song of this blog is <a href="https://www.youtube.com/watch?v=8Ir-zFC9nFE">“Mathematics” by Mos Def</a>.</p></div>
    </content>
    <updated>2019-06-17T23:42:13Z</updated>
    <published>2019-06-17T23:42:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2019-06-28T23:36:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/06/17/3rd-school-on-foundations-of-programming-and-software-systems/</id>
    <link href="https://cstheory-events.org/2019/06/17/3rd-school-on-foundations-of-programming-and-software-systems/" rel="alternate" type="text/html"/>
    <title>3rd School on Foundations of Programming and Software Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 10-15, 2019 Warsaw, Poland https://www.mimuw.edu.pl/~fopss19/ The Summer School on Foundations of Programming and Software Systems (FoPSS) was jointly created by EATCS, ETAPS, ACM SIGLOG and ACM SIGPLAN. It was first organised in 2017. The goal is to introduce the participants to various aspects of computation theory and programming languages. The school, spread over a … <a class="more-link" href="https://cstheory-events.org/2019/06/17/3rd-school-on-foundations-of-programming-and-software-systems/">Continue reading <span class="screen-reader-text">3rd School on Foundations of Programming and Software Systems</span></a></div>
    </summary>
    <updated>2019-06-17T12:23:27Z</updated>
    <published>2019-06-17T12:23:27Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-06-28T23:35:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16001</id>
    <link href="https://rjlipton.wordpress.com/2019/06/17/contraction-and-explosion/" rel="alternate" type="text/html"/>
    <title>Contraction and Explosion</title>
    <summary>Different ways of recursing on graphs Bletchley Park 2017 source William Tutte was a British combinatorialist and codebreaker. He worked in a different group at Bletchley Park from that of Alan Turing. He supplied several key insights and algorithms for breaking the Lorenz cipher machine. His algorithms were implemented alongside Turing’s on Colossus code-breaking computers. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Different ways of recursing on graphs</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<img alt="TutteBletchley" class="alignright wp-image-16003" height="200" src="https://rjlipton.files.wordpress.com/2019/06/tuttebletchley.jpg?w=120&amp;h=200" width="120"/>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Bletchley Park 2017 <a href="https://bletchleypark.org.uk/news/codebreaker-bill-tutte-to-be-celebrated-in-centenary-exhibition">source</a></font></td>
</tr>
</tbody>
</table>
<p>
William Tutte was a British combinatorialist and codebreaker. He worked in a different group at Bletchley Park from that of Alan Turing. He supplied several key insights and algorithms for breaking the Lorenz cipher <a href="https://en.wikipedia.org/wiki/Lorenz_cipher">machine</a>. His algorithms were implemented alongside Turing’s on <a href="https://en.wikipedia.org/wiki/Colossus_computer">Colossus</a> code-breaking computers.</p>
<p>
Today we discuss graph recursions discovered by Tutte and Hassler Whitney.</p>
<p>
Tutte wrote a doctoral thesis after the war on graph theory and its generalization into <em>matroid theory</em>. We will follow the same arc in this and a followup post. He joined the faculty of the universities of Toronto and then Waterloo, where he was active long beyond his retirement. </p>
<p>
For more on Tutte and his work, see this <a href="https://theconversation.com/remembering-bill-tutte-another-brilliant-codebreaker-from-world-war-ii-77556">article</a> and <a href="http://thelaborastory.com/stories/william-thomas-tutte/">lecture</a> by Graham Farr, who is a professor at Monash University and a longtime friend of Ken’s from their Oxford days. We covered some of Tutte’s other work <a href="https://rjlipton.wordpress.com/2010/06/02/the-tensor-trick-and-tuttles-flow-conjectures/">here</a>.</p>
<p/><h2> Deletion and Contraction </h2><p/>
<p/><p>
The two most basic recursion operations are <em>deleting</em> and <em>contracting</em> a chosen edge <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> in a given graph <img alt="{G = (V,E)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%3D+%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G = (V,E)}"/>:</p>
<p><img alt="deletion_contraction" class="aligncenter wp-image-16004" height="118" src="https://rjlipton.files.wordpress.com/2019/06/deletion_contraction.png?w=400&amp;h=118" width="400"/></p>
<p>
These operations produce graphs denoted by <img alt="{G \setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \setminus e}"/> and <img alt="{G/e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%2Fe%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G/e}"/>, respectively. A motive for them harks back to Gustav Kirchhoff’s counting of spanning trees:</p>
<ul>
<li>
A spanning tree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> avoids using edge <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> if and only if it is a spanning tree of the graph <img alt="{G \setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \setminus e}"/> with <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> deleted.<p/>
</li><li>
A spanning tree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> uses edge <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> if and only if the rest of it is a spanning tree of the graph <img alt="{G/e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%2Fe%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G/e}"/> after contracting <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/>.
</li></ul>
<p>
Well, this is not how Kirchhoff counted trees. Counting via the recursion would take exponential time. Our whole object will be telling which cases of the recursions can be computed more directly.</p>
<p>Note that contracting one edge of the triangle graph <img alt="{C_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_3}"/> produces a <em>multi-</em>graph <img alt="{C_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_2}"/> with one double-edge. Then contracting one edge of <img alt="{C_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_2}"/> yields the loop graph <img alt="{C_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_1}"/>.</p>
<p/><p><br/>
<img alt="triangle" class="aligncenter wp-image-16005" height="73" src="https://rjlipton.files.wordpress.com/2019/06/triangle.png?w=250&amp;h=73" width="250"/></p>
<p/><p><br/>
Thus contraction yields non-simple undirected graphs, but the logic of counting their spanning trees remains valid.</p>
<p>
The order of edges does not matter as long as one avoids disconnecting the graph, and the base case is a tree (ignoring any loops) which contributes <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>.</p>
<p/><h2> Tutte’s Polynomial </h2><p/>
<p/><p>
A similar recursion counts colorings <img alt="{c: V \rightarrow \{1,...,k\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3A+V+%5Crightarrow+%5C%7B1%2C...%2Ck%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c: V \rightarrow \{1,...,k\}}"/> that are <em>proper</em>, meaning that for each edge <img alt="{e = (u,v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = (u,v)}"/>, <img alt="{c(u) \neq c(v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%28u%29+%5Cneq+c%28v%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c(u) \neq c(v)}"/>.</p>
<ul>
<li>
A proper coloring <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> of <img alt="{G \setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \setminus e}"/> makes <img alt="{c(u) \neq c(v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%28u%29+%5Cneq+c%28v%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c(u) \neq c(v)}"/> iff it is a proper coloring of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>.<p/>
</li><li>
A proper coloring <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> of <img alt="{G \setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \setminus e}"/> makes <img alt="{c(u) = c(v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%28u%29+%3D+c%28v%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c(u) = c(v)}"/> iff it induces a proper coloring of <img alt="{G/e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%2Fe%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G/e}"/>.
</li></ul>
<p>
This leads to the recursive definition of the <em>chromatic polynomial</em>:</p>
<p align="center"><img alt="\displaystyle    P_G(x) = P_{G\setminus e}(x) - P_{G/e}(x).   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++P_G%28x%29+%3D+P_%7BG%5Csetminus+e%7D%28x%29+-+P_%7BG%2Fe%7D%28x%29.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    P_G(x) = P_{G\setminus e}(x) - P_{G/e}(x).   "/></p>
<p>
The base cases are that an isolated vertex contributes <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, whereas an isolated loop contributes <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> since its single edge is never properly colored. The final rule is that <img alt="{P_G(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_G%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_G(x)}"/> is always the product of <img alt="{P_H(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_H%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_H(x)}"/> over all connected components <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Then <img alt="{P_G(k)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_G%28k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_G(k)}"/> counts the number of proper <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>-colorings.</p>
<p>
This is like the recursion for coutning spanning terees except for the minus sign. Tutte’s brilliant insight, which was anticipated by Whitney in less symbolic form, was that the features can be combined by using two variables <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>. Call an edge a <a href="https://en.wikipedia.org/wiki/Bridge_(graph_theory)">bridge</a> if it is not part of any cycle. If <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> is not a bridge, the recursion is</p>
<p align="center"><img alt="\displaystyle    T_G(x,y) = T_{G \setminus e}(x,y) + T_{G/e}(x,y).   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++T_G%28x%2Cy%29+%3D+T_%7BG+%5Csetminus+e%7D%28x%2Cy%29+%2B+T_%7BG%2Fe%7D%28x%2Cy%29.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    T_G(x,y) = T_{G \setminus e}(x,y) + T_{G/e}(x,y).   "/></p>
<p>
The base case is now a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> with some number <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> of bridges and some number <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> of loops, which gives <img alt="{T_G(x,y) = x^k y^\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%28x%2Cy%29+%3D+x%5Ek+y%5E%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(x,y) = x^k y^\ell}"/>. An important feature is that all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex trees have the same Tutte polynomial <img alt="{x^{n-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Bn-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{n-1}}"/>, since there are <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> edges and they are all bridges. The following are just some of the beautiful <a href="https://en.wikipedia.org/wiki/Tutte_polynomial#Specialisations">rules</a> that <img alt="{T_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G}"/> follows. Let <img alt="{c = c_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+c_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c = c_G}"/> stand for the number of connected components of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>.</p>
<ul>
<li>
<img alt="{T_G(1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(1,1)}"/> counts the number of spanning trees forests. This counts the number of spanning trees if <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is connected.<p/>
</li><li>
<img alt="{T_G(1-x,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%281-x%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(1-x,0)}"/>, when multiplied by <img alt="{(-1)^{n-c} x^c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5E%7Bn-c%7D+x%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^{n-c} x^c}"/>, yields the chromatic polynomial.<p/>
</li><li>
<img alt="{T_G(1,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%281%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(1,2)}"/> counts the number of spanning subgraphs.<p/>
</li><li>
<img alt="{T_G(2,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%282%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(2,2)}"/> is just <img alt="{2^{|E|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%7CE%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{|E|}}"/>.<p/>
</li><li>
<img alt="{T_G(x,\frac{1}{x})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_G%28x%2C%5Cfrac%7B1%7D%7Bx%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_G(x,\frac{1}{x})}"/> gives the <a href="https://en.wikipedia.org/wiki/Jones_polynomial">Jones polynomial</a> of a knot related to <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>.
</li></ul>
<p>
There are many further relations. The Jones polynomial has many applications including in quantum physics.</p>
<p/><h2> Contraction With a Twist </h2><p/>
<p>
Recall our definition of the “amplitude” <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/> of an undirected <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> from the “Net-Zero Graphs” <a href="https://rjlipton.wordpress.com/2019/06/10/net-zero-graphs/">post</a>:</p>
<p align="center"><img alt="\displaystyle    a(G) = \frac{c_0 - c_1}{2^n},   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28G%29+%3D+%5Cfrac%7Bc_0+-+c_1%7D%7B2%5En%7D%2C+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(G) = \frac{c_0 - c_1}{2^n},   "/></p>
<p>
where <img alt="{c_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_0}"/> is the number of black-and-white 2-colorings that make an even number of edges have both nodes colored black, and <img alt="{c_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1}"/> for an odd number. </p>
<p>
There does not seem to be a simple recursion for <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/> from <img alt="{G \setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \setminus e}"/> and <img alt="{G/e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%2Fe%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G/e}"/>. We can, however, obtain one by using another kind of contraction that adds a loop at the combined vertex:</p>
<p><img alt="inchworm_contraction" class="aligncenter wp-image-16006" height="128" src="https://rjlipton.files.wordpress.com/2019/06/inchworm_contraction.png?w=250&amp;h=128" width="250"/></p>
<p>
We denote this by <img alt="{G/\!/e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%2F%5C%21%2Fe%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G/\!/e}"/>. We have not found a simple reference for this. We obtain the following recursive formula:</p>
<p align="center"><img alt="\displaystyle    a(G) = a(G\backslash e) + \frac{1}{2}a(G/\!/e) - \frac{1}{2}a(G/e).   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28G%29+%3D+a%28G%5Cbackslash+e%29+%2B+%5Cfrac%7B1%7D%7B2%7Da%28G%2F%5C%21%2Fe%29+-+%5Cfrac%7B1%7D%7B2%7Da%28G%2Fe%29.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(G) = a(G\backslash e) + \frac{1}{2}a(G/\!/e) - \frac{1}{2}a(G/e).   "/></p>
<p>
This recursion allows <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> to be a bridge, so the base cases are <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> for an isolated vertex and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> for a loop. More generally, the basis is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> for a node with an even number of loops, <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> for odd. Here is an example for the ‘star graph’ <img alt="{S_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_4}"/> on 4 vertices:</p>
<p/><p><br/>
<img alt="starGraph" class="aligncenter wp-image-16007" height="294" src="https://rjlipton.files.wordpress.com/2019/06/stargraph.png?w=520&amp;h=294" width="520"/></p>
<p/><p><br/>
The diagram would need another layer to get down to (products of) base cases, which we have shortcut by putting values of <img alt="{a(H)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28H%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(H)}"/> for each graph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> at a leaf. Adding the products over all branches gives <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/>. For the star graph,</p>
<p align="center"><img alt="\displaystyle    a(S_4) = \frac{1}{2} + \frac{1}{4} - \frac{1}{4} + \frac{1}{4} + \frac{1}{8} - \frac{1}{8} - \frac{1}{4} - \frac{1}{8} + \frac{1}{8} = \frac{1}{2}.   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28S_4%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B4%7D+-+%5Cfrac%7B1%7D%7B4%7D+%2B+%5Cfrac%7B1%7D%7B4%7D+%2B+%5Cfrac%7B1%7D%7B8%7D+-+%5Cfrac%7B1%7D%7B8%7D+-+%5Cfrac%7B1%7D%7B4%7D+-+%5Cfrac%7B1%7D%7B8%7D+%2B+%5Cfrac%7B1%7D%7B8%7D+%3D+%5Cfrac%7B1%7D%7B2%7D.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(S_4) = \frac{1}{2} + \frac{1}{4} - \frac{1}{4} + \frac{1}{4} + \frac{1}{8} - \frac{1}{8} - \frac{1}{4} - \frac{1}{8} + \frac{1}{8} = \frac{1}{2}.   "/></p>
<p/><p><br/>
Clearly this brute-force recursion grows as <img alt="{3^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3^n}"/>. This is slower than the order-<img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> time of using the coloring definition directly, but what all this underscores is how singular it is to be able to compute <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/> in polynomial time, indeed <img alt="{O(n^\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^\omega)}"/> time. The search for a more-efficient recursion, one that might apply to <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-hard quantities, leads us to consider a more-drastic operation on edges.</p>
<p/><h2> Exploding Edges </h2><p/>
<p>
The new recursion operation is well illustrated by this figure:</p>
<p/><p><br/>
<img alt="explosionSolo" class="aligncenter wp-image-16008" height="203" src="https://rjlipton.files.wordpress.com/2019/06/explosionsolo.png?w=300&amp;h=203" width="300"/></p>
<p/><p><br/>
Two vertices disappear, not just one. Not only does the edge <img alt="{e = (u,v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = (u,v)}"/> disappear, but any other edge incident to <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> or <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> from a vertex <img alt="{w \neq u,v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw+%5Cneq+u%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w \neq u,v}"/> gets “recoiled” into a loop at <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/>. We denote this operation by <img alt="{G \backslash\!\backslash e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Cbackslash%5C%21%5Cbackslash+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \backslash\!\backslash e}"/> to connote that <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> is not just deleted but “exploded.” </p>
<p>
Properly speaking, we need to specify what happens if there are other edges between <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> or loops at <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> or <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/>. In an upcoming post we will see that those become <em>circles</em> in a <em>graphical polymatroid</em> which generalizes the notion of a graph. For now, however, it suffices to let <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> be the total number of vaporized edges, including <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/>. Then we obtain a two-term recursive formula:</p>
<p><a name="expl"/></p><a name="expl">
<p align="center"><img alt="\displaystyle    a(G) = a(G \backslash e) + \frac{(-1)^r}{2} a(G\backslash \!\backslash e).   \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28G%29+%3D+a%28G+%5Cbackslash+e%29+%2B+%5Cfrac%7B%28-1%29%5Er%7D%7B2%7D+a%28G%5Cbackslash+%5C%21%5Cbackslash+e%29.+++%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(G) = a(G \backslash e) + \frac{(-1)^r}{2} a(G\backslash \!\backslash e).   \ \ \ \ \ (1)"/></p>
</a><p><a name="expl"/></p>
<p>
The base cases for isolated vertices are the same as before, but explosion also needs a base case for pure emptiness. This contributes <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. In the following example diagram, for the path graph <img alt="{P_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_4}"/> on four nodes, we denote such base cases by `w’ for “wisp”:</p>
<p><img alt="P3explosion" class="aligncenter wp-image-16009" height="291" src="https://rjlipton.files.wordpress.com/2019/06/p3explosion.png?w=450&amp;h=291" width="450"/></p>
<p>
Note again the rule that when the recursion disconnects the graph, the component values multiply together. Thus the value is</p>
<p align="center"><img alt="\displaystyle    a(P_4) = (1 - \frac{1}{2})(1 - \frac{1}{2}) - 0 = \frac{1}{4}.   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28P_4%29+%3D+%281+-+%5Cfrac%7B1%7D%7B2%7D%29%281+-+%5Cfrac%7B1%7D%7B2%7D%29+-+0+%3D+%5Cfrac%7B1%7D%7B4%7D.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(P_4) = (1 - \frac{1}{2})(1 - \frac{1}{2}) - 0 = \frac{1}{4}.   "/></p>
<p>
This is different from the amplitude <img alt="{\frac{1}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2}}"/> of the star graph. What this means is that <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/> does not obey the rules of the Tutte polynomial, which is the same for both of these 4-vertex trees. </p>
<p>
To prove the recursion equation (<a href="https://rjlipton.wordpress.com/feed/#expl">1</a>), for <img alt="{e = (u,v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = (u,v)}"/>, note that every coloring has the same odd/even parity of black-black edges for <img alt="{G\setminus e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%5Csetminus+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G\setminus e}"/> as for <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> except those that color both <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> black. Let <img alt="{c_0^{uv}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_0%5E%7Buv%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_0^{uv}}"/> denote the colorings among the latter that make an even number of black-black edges (including <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/>) overall, <img alt="{c_1^{uv}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%5E%7Buv%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1^{uv}}"/> for an odd number. Then</p>
<p align="center"><img alt="\displaystyle    a(G) = a(G \setminus e) + \frac{2}{2^n}(c_1^{uv} - c_0^{uv}).   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++a%28G%29+%3D+a%28G+%5Csetminus+e%29+%2B+%5Cfrac%7B2%7D%7B2%5En%7D%28c_1%5E%7Buv%7D+-+c_0%5E%7Buv%7D%29.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    a(G) = a(G \setminus e) + \frac{2}{2^n}(c_1^{uv} - c_0^{uv}).   "/></p>
<p>
Now if there are no other edges between or loops at <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> and <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/>, then <img alt="{c_1^{uv}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%5E%7Buv%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1^{uv}}"/> is the same as the number of colorings of <img alt="{G \backslash\!\backslash e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Cbackslash%5C%21%5Cbackslash+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \backslash\!\backslash e}"/> that make an even number of black-black edges, and <img alt="{c_0^{uv}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_0%5E%7Buv%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_0^{uv}}"/> becomes the odd case in <img alt="{G \backslash\!\backslash e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Cbackslash%5C%21%5Cbackslash+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \backslash\!\backslash e}"/> again because we subtracted <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/>. Considering the sign change from other <img alt="{(u,v)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(u,v)}"/> edges or loops and <img alt="{\frac{2}{2^n} = \frac{1/2}{2^{n-2}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%7D%7B2%5En%7D+%3D+%5Cfrac%7B1%2F2%7D%7B2%5E%7Bn-2%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{2}{2^n} = \frac{1/2}{2^{n-2}}}"/> yields equation (<a href="https://rjlipton.wordpress.com/feed/#expl">1</a>).  It is also possible to “explode” a loop, and our readers may enjoy figuring out how to define it.</p>
<p/><h2> The Amplitude Polynomial </h2><p/>
<p/><p>
We can expand on this by defining a polynomial <img alt="{Q_G(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_G%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_G(x)}"/> such that <img alt="{a(G) = Q_G(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29+%3D+Q_G%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G) = Q_G(1)}"/>. The base cases are <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for an isolated vertex but still <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> for a “wisp” and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> for a loop. The basis extends to give <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for an isolated node with an even number of loops and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> for odd. Another way to put it is that two edges with the same endpoints, or two loops at the same node, can be removed. The above diagram shows that for the path graph <img alt="{P_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_4}"/>,</p>
<p align="center"><img alt="\displaystyle    Q_{P_4}(x) = (x^2 - \frac{1}{2})^2 = x^4 - x^2 + \frac{1}{4}.   " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++++Q_%7BP_4%7D%28x%29+%3D+%28x%5E2+-+%5Cfrac%7B1%7D%7B2%7D%29%5E2+%3D+x%5E4+-+x%5E2+%2B+%5Cfrac%7B1%7D%7B4%7D.+++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle    Q_{P_4}(x) = (x^2 - \frac{1}{2})^2 = x^4 - x^2 + \frac{1}{4}.   "/></p>
<p>
Whereas, the recursion for the star graph—noting that the “star” <img alt="{S_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_2}"/> on two nodes is just a single edge—gives:</p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}    Q_{S_4}(x) &amp;=&amp; xQ_{S_3}(x) - \frac{1}{2}0\\   &amp;=&amp; x^2 Q_{S_2}(x) - \frac{1}{2}0 - \frac{1}{2}0\\   &amp;=&amp; x^4 - x^2 \frac{1}{2}(1\!\cdot\! 1) - \frac{1}{2}0 - \frac{1}{2}0 = x^4 - \frac{1}{2}x^2.   \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++++Q_%7BS_4%7D%28x%29+%26%3D%26+xQ_%7BS_3%7D%28x%29+-+%5Cfrac%7B1%7D%7B2%7D0%5C%5C+++%26%3D%26+x%5E2+Q_%7BS_2%7D%28x%29+-+%5Cfrac%7B1%7D%7B2%7D0+-+%5Cfrac%7B1%7D%7B2%7D0%5C%5C+++%26%3D%26+x%5E4+-+x%5E2+%5Cfrac%7B1%7D%7B2%7D%281%5C%21%5Ccdot%5C%21+1%29+-+%5Cfrac%7B1%7D%7B2%7D0+-+%5Cfrac%7B1%7D%7B2%7D0+%3D+x%5E4+-+%5Cfrac%7B1%7D%7B2%7Dx%5E2.+++%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}    Q_{S_4}(x) &amp;=&amp; xQ_{S_3}(x) - \frac{1}{2}0\\   &amp;=&amp; x^2 Q_{S_2}(x) - \frac{1}{2}0 - \frac{1}{2}0\\   &amp;=&amp; x^4 - x^2 \frac{1}{2}(1\!\cdot\! 1) - \frac{1}{2}0 - \frac{1}{2}0 = x^4 - \frac{1}{2}x^2.   \end{array} "/></p>
<p>
This is not the same polynomial as <img alt="{Q_{P_4}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_%7BP_4%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_{P_4}(x)}"/>, again implying that <img alt="{Q_G(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_G%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_G(x)}"/> is not a specialization of the Tutte polynomial. We will show in the last post in this series that <img alt="{Q_G(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_G%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_G(x)}"/> does specialize the polynomial <img alt="{S_G(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_G%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_G(x,y)}"/> introduced in this 1993 <a href="http://homepages.mcs.vuw.ac.nz/~whittle/pubs/Tutte_invariants_of_2-polymatroids.pdf">paper</a> titled, “A Characterization of Tutte Invariants of 2-Polymatroids” and covered further in this 2006 <a href="https://www.researchgate.net/publication/49399603_Evaluating_the_Rank_Generating_Function_of_a_Graphic_2-Polymatroid">paper</a>.</p>
<p/><h2> Open Problems </h2><p/>
<p>
What other rules does our “amplitude polynomial” follow?  We will explore this in the mentioned upcoming post.  What other quantities can it be made to count?</p>
<p>
What we called “explosion” is in fact attested as the natural form of <em>contraction</em> for the <b>polymatroids</b> considered in these papers. What further uses might “explosion” have in graph theory apart from polymatroids?</p></font></font></div>
    </content>
    <updated>2019-06-17T08:27:09Z</updated>
    <published>2019-06-17T08:27:09Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="algebra"/>
    <category term="graph theory"/>
    <category term="graphs"/>
    <category term="polynomials"/>
    <category term="quantum"/>
    <category term="Tutte polynomial"/>
    <category term="William Tutte"/>
    <author>
      <name>Chaowen Guan and K.W. Regan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-28T23:34:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/06/16/modeconnectivity/</id>
    <link href="http://offconvex.github.io/2019/06/16/modeconnectivity/" rel="alternate" type="text/html"/>
    <title>Landscape Connectivity of Low Cost Solutions for Multilayer Nets</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A big mystery about deep learning is how, in a highly nonconvex loss landscape, gradient descent often finds near-optimal solutions —those with training cost almost zero— even starting from a random initialization. This conjures an image of a landscape filled with deep pits.  Gradient descent started at a random point falls easily to the bottom of the nearest pit. In this mental image the pits are disconnected from each other, so there is no way to go from the bottom of one pit to bottom of another without going through regions of high cost.</p>

<p>The current post is about our <a href="https://arxiv.org/abs/1906.06247">new paper with Rohith Kuditipudi, Xiang Wang, Holden Lee, Yi Zhang, Wei Hu, Zhiyuan Li and Sanjeev Arora</a> which provides a mathematical explanation of  the following surprising phenomenon reported last year.</p>

<blockquote>
  <p><strong>Mode connectivity</strong> (<a href="https://arxiv.org/abs/1611.01540">Freeman and Bruna, 2016</a>, <a href="https://papers.nips.cc/paper/8095-loss-surfaces-mode-connectivity-and-fast-ensembling-of-dnns.pdf">Garipov et al. 2018</a>, <a href="https://arxiv.org/abs/1803.00885">Draxler et al. 2018</a>) All pairs of low-cost solutions found via gradient descent  can actually be connected by simple paths in the parameter space, such that every point on the path is another solution of almost the same cost. In fact the low-cost path connecting two near-optima  can be <em>piecewise linear</em> with two line-segments, or a Bezier curve.</p>
</blockquote>

<p>See Figure 1 below from <a href="https://papers.nips.cc/paper/8095-loss-surfaces-mode-connectivity-and-fast-ensembling-of-dnns.pdf">Garipov et al. 2018</a> for an illustration. Solutions A and B have low cost but the line connecting them goes through solutions with high cost. But we can find C of low cost such that paths AC and CB only pass through low-cost region.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/modes.PNG" style="width: 300px;"/>
<br/>
<b>Figure 1</b> Mode Connectivity. Warm colors represent low loss. 
</div>

<p>Using a very simple example let us see that this phenomenon is highly counterintuitive. Suppose we’re talking about 2-layer nets with linear activations and a real-valued output. Let the two nets $\theta_A$ and 
$\theta_B$  with zero loss be
<br/>
respectively where $x, U_1, U_2 \in \Re^n$
and matrices $W_1, W_2$ are $n\times n$. Then the straight line connecting them in parameter space corresponds to nets of the type $(\alpha U_1 + (1-\alpha)U_2)^\top(\alpha W_1 + (1-\alpha)W_2)$ which can be rewritten as</p>
<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/hybridnet.jpg" style="width: 650px;"/> 
</div>

<p>Note that the middle terms correspond to putting the top layer of one net on top of the bottom of the other, which in general is a nonsensical net (reminiscent of a <em>centaur</em>, a mythical half-man half-beast) that in general would be expected to have high loss.</p>

<p>Originally we figured mode connectivity would not be mathematically understood for a long time, because of the seeming difficulty of proving any mathematical theorems  about, say, $50$-layer nets trained on ImageNet data, and in particular dealing with such “centaur-like” nets in the interpolation.</p>

<p>Several authors (<a href="https://arxiv.org/abs/1611.01540">Freeman and Bruna, 2016</a>, <a href="https://arxiv.org/abs/1802.06384">Venturi et al. 2018</a>, <a href="https://arxiv.org/abs/1803.00909">Liang et al. 2018</a>, <a href="https://arxiv.org/abs/1809.10749">Nguyen et al. 2018</a>, <a href="https://arxiv.org/abs/1901.07417">Nguyen et al. 2019</a>) did try to explain the phenomenon of mode connectivity in simple settings (the first of these demonstrated mode connectivity empirically for multi-layer nets). But these explanations only work for very unrealistic 2-layer nets (or multi-layer nets with special structure) which are highly redundant e.g., the number of neurons may have to be larger than the number of training samples.</p>

<p>Our paper starts by clarifying an important point: redundancy with respect to a ground truth neural network is  insufficient for mode connectivity, which we show via a simple counterexample sketched below.</p>

<p>Thus to explain mode connectivity for multilayer nets we  will need to leverage some stronger property of <em>typical</em> solutions discovered via gradient-based training, as we will see below.</p>

<h2 id="mode-connectivity-need-not-hold-for-2-layer-overparametrized-nets">Mode Connectivity need not hold for 2-layer overparametrized nets</h2>

<p>We show that the strongest version of mode connectivity (every two minimizers are connected) does not hold even for a simple two-layer setting, where $f(x) = W_2\sigma(W_1x)$, even where the net is vastly overparametrized than it needs to be for the dataset in question.</p>

<blockquote>
  <p><strong>Theorem</strong> For any $h&gt;1$ there exists a data set which is perfectly fitted by  a ground truth neural network with $2$ layers and only $2$ hidden neurons, but if we desire to train neural network with $h$ hidden units on this dataset then the set of global minimizers are not connected.</p>
</blockquote>

<h2 id="stability-properties-of-typical-nets">Stability properties of typical nets</h2>

<p>Since mode connectivity has been found to hold for a range of architectures and datasets, any explanation probably should only rely upon properties that <em>generically</em> seem to hold for deep net standard training. Our explanation relies upon properties that were discovered in recent years in the effort to understand the generalization properties of deep nets.  These properties say that the output of the final net is stable to various kinds of added noise.
The properties imply that the loss function does not change much when the net parameters are perturbed; this is informally described as the net being a <em>flat minimum</em> (<a href="https://www.cs.toronto.edu/~hinton/absps/colt93.html">Hinton and Van Camp 1993</a>).</p>

<p>Our explanation of mode connectivity will involve the following two properties.</p>

<h3 id="noise-stability-and-dropout-stability">Noise stability and Dropout Stability</h3>

<p><em>Dropout</em> was introduced by <a href="https://arxiv.org/abs/1207.0580">Hinton et al. 2012</a>: during gradient-based training, one  zeroes out the output of $50\%$ of the nodes, and doubles the output of the remaining nodes. The gradient used in the next update is computed for this net. While dropout may not be as popular these days, it can be added to any existing net training without loss of generality. We’ll say a net is “$\epsilon$-dropout stable” if applying dropout to $50\%$ of the nodes increases its loss by at most $\epsilon$. Note that unlike dropout training where nodes are <em>randomly</em> dropped out, in our definition a network is dropout stable as long as there <em>exists</em> a way of dropping out $50\%$ of the nodes that does not increase its loss by too much.</p>

<blockquote>
  <p><strong>Theorem 1:</strong> If two trained multilayer ReLU nets with the same architecture  are $\epsilon$-dropout stable, then they can be connected in the loss landscape via a piece-wise linear path in which the number of linear segments is linear in the number of layers, and the loss of every point on the path is at most $\epsilon$ higher than the loss of the two end points.</p>
</blockquote>

<p><em>Noise stability</em> was discovered by <a href="https://arxiv.org/abs/1802.05296">Arora et al. ICML18</a>; this   was described in a <a href="http://www.offconvex.org/2018/02/17/generalization2/">previous blog post</a>. They found that trained nets are very stable to noise injection: if one adds a fairly large Gaussian noise vector to the output of a layer, then this has only a small effect on the output of higher layers. In other words, the network <em>rejects</em> the injected noise. That paper showed that noise stability can be used to prove that the net is compressible. Thus noise stability is indeed a form of redundancy in the net.</p>

<p>In the new paper we show that a minor variant of the noise stability property (which we empirically find to still hold in trained nets) implies dropout stability. More importantly, solutions satisfying this property can be connected using a piecewise linear path with at most $10$ segments.</p>

<blockquote>
  <p><strong>Theorem 2:</strong> If two trained multilayer ReLU nets with the same architecture are $\epsilon$-noise stable, then they can be connected in the loss landscape via a piece-wise linear path with at most 10 segments, and the loss of every point on the path is at most $\epsilon$ higher than the loss of the two end points.</p>
</blockquote>

<h2 id="proving-mode-connectivity-for-dropout-stable-nets">Proving mode connectivity for dropout-stable nets</h2>
<p>We exhibit the main ideas by proving mode connectivity for  fully connected nets that are dropout-stable, meaning training loss is stable to dropping out $50\%$ of the nodes.</p>

<p>Let $W_1,W_2,…,W_p$ be the weight matrices of the neural network, so the function that is computed by the network is $f(x) = W_p\sigma(\cdots \sigma(W_2(\sigma(W_1x)))\cdots)$. Here $\sigma$ is the ReLU activation (our result in this section works for any activations). We use $\theta = (W_1,W_2,…,W_p)\in \Theta$ to denote the parameters for the neural network. Given a set of data points $(x_i,y_i)~i=1,2,…,n$, the empirical loss $L$ is just an average of the losses for the individual samples $L(\theta) = \frac{1}{n}\sum_{i=1}^n l(y_i, f_\theta(x_i))$. The function $l(y, \hat{y})$ is a loss function that is convex in the second parameter (popular loss functions such as cross-entropy or mean-squared-error are all in this category).</p>

<p>Using this notation, Theorem 1 can be restated as:</p>

<blockquote>
  <p><strong>Theorem 1 (restated)</strong> Let $\theta_A$ and $\theta_B$ be two solutions that are both $\epsilon$-dropout stable, then there exists a path $\pi:[0,1]\to \Theta$ such that $\pi(0) = \theta_A$, $\pi(1) = \theta_B$ and for any $t\in(0,1)$ the loss $L(\pi(t)) \le \max{L(\theta_A), L(\theta_B)} + \epsilon$.</p>
</blockquote>

<p>To prove this theorem, the major step is to connect a network with its dropout version where half of the neurons are not used (see next part). Then intuitively it is not too difficult to connect two dropout versions as they both have a large number of inactive neurons.</p>

<p>As we discussed before, directly interpolating between two networks may not work as it give rise to <em>centaur-like</em> networks.  A key idea in this simpler theorem is that each linear segment in the path involves varying the parameters of only one layer, which allows careful control of this issue. (Proof of Theorem 2 is more complicated because the number of layers in the net are allowed to exceed the number of path segments.)</p>

<p>As a simple example, we show how to connect a 3-layer neural network with its dropout version. (The same idea can be easily extended to more layers by a simple induction on number of layers.) Assume without loss of generality that we are going to dropout the second half of neurons for both hidden layers. For the weight matrices $W_3, W_2, W_1$, we will write them in block form: $W_3$ is a $1\times 2$ block matrix $W_3 = [L_3, R_3]$, $W_2$ is a $2\times 2$ block matrix $W_2 = \left[L_2, C_2; D_2, R_2 \right]$, and $W_1$ is a $2\times 1$ block matrix $W_1 = \left[L_1; B_1\right]$ (here ; represents the end of a row). The dropout stable property implies that the networks with weights $(W_3, W_2, W_1)$, $(2[L_3, 0], W_2, W_1)$, $([2L_3, 0], [2L_2, 0; 0, 0], W_1)$ all have low loss (these weights correspond to the cases of no dropout, dropout only applied to the top hidden layer and dropout applied to both hidden layers). Note that the final set of weights $([2L_3, 0], [2L_2, 0; 0, 0], W_1)$ is equivalent to $([2L_3, 0], [2L_2, 0; 0, 0], [L_1; 0])$ as the output from the $B_1$ part of $W_1$ has no connections. The path we construct is illustrated in Figure 2 below:
As a simple example, we show how to connect a 3-layer neural network with its dropout version. (The same idea can be easily extended to more layers by a simple induction on number of layers.) Assume without loss of generality that we are going to dropout the second half of neurons for both hidden layers. For the weight matrices $W_3, W_2, W_1$, we will write them in block form: $W_3$ is a $1\times 2$ block matrix $W_3 = [L_3, R_3]$, $W_2$ is a $2\times 2$ block matrix $W_2 = \left[L_2, C_2; D_2, R_2 \right]$, and $W_1$ is a $2\times 1$ block matrix $W_1 = \left[L_1; B_1\right]$ (here ; represents the end of a row). The dropout stable property implies that the networks with weights $(W_3, W_2, W_1)$, $(2[L_3, 0], W_2, W_1)$, $([2L_3, 0], [2L_2, 0; 0, 0], W_1)$ all have low loss (these weights correspond to the cases of no dropout, dropout only applied to the top hidden layer and dropout applied to both hidden layers). Note that the final set of weights $([2L_3, 0], [2L_2, 0; 0, 0], W_1)$ is equivalent to $([2L_3, 0], [2L_2, 0; 0, 0], [L_1; 0])$ as the output from the $B_1$ part of $W_1$ has no connections. The path we construct is illustrated in Figure 2 below:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/path.png" style="width: 400px;"/> <br/>
<b>Figure 2</b> Path from a 3-layer neural network to its dropout version.
</div>

<p>We use two types of steps to construct the path: (a) Since the loss function is convex in the weight of the top layer, we can interpolate between two different networks that only differ in top layer weights; (b) if a set of neurons already has 0 output weights, then we can set its input weights arbitrarily.</p>

<p>Figure 2 shows how to alternate between these two types of steps to connect a 3-layer network to its dropout version. The red color highlights weights that have changed. In the case of type (a) steps, the red color only appears in the top layer weights; in the case of type (b) steps, the 0 matrices highlighted by the green color are the 0 output weights, where because of these 0 matrices setting the red blocks to any matrix will not change the output of the neural network.</p>

<p>The crux of this construction appears in steps (3) and (4). When we are going from (2) to (3), we changed the bottom rows of $W_2$ from $[D_2, R_2]$ to $[2L_2, 0]$. This is a type (b) step, and because currently the top-level weight is $[2L_3, 0]$, changing the bottom row of $W_2$ has no effect on the output of the neural network. However, making this change allows us to do the interpolation between (3) and (4), as now the two networks only differ in the top layer weights. The loss is bounded because the weights in (3) are equivalent to $(2[L_3, 0], W_2, W_1)$ (weights with dropout applied to top hidden layer), and the weights in (4) are equivalent to $([2L_3, 0], [2L_2, 0; 0, 0], W_1)$ (weights with dropout applied to both hidden layers). The same procedure can be repeated if the network has more layers.</p>

<p>The number of line segments in the path is linear in the number of layers. As mentioned, the paper also gives stronger results assuming noise stability, where we can actually consruct a path with constant number of line segments.</p>

<h2 id="conclusions">Conclusions</h2>

<p>Our results are a first-cut explanation for how mode connectivity can arise in realistic deep nets. Our methods do not answer all mysteries about mode connectivity. In particular, in many cases (especially when the number of parameters is not as large) the solutions found in practice are not as robust as we require in our theorems (either in terms of dropout stability or noise stability), yet empirically it is still possible to find simple paths connecting the solutions. Are there other properties satisfied by these solutions that allow them to be connected? Also, our results can be extended to convolutional neural networks via <em>channel-wise dropout</em>, where one randomly turn off half of the channels (this was considered before in <a href="https://arxiv.org/abs/1411.4280">Thompson et al. 2015</a>,<a href="https://arxiv.org/abs/1812.03965">Keshari et al.2018</a>). While it is possible to train networks that are robust to channel-wise dropout, standard networks or even the ones trained with standard dropout do not satisfy this property.</p>

<p>It would also be interesting to utilize the insights into the landscape given by our explanation to design better training algorithms.</p></div>
    </summary>
    <updated>2019-06-16T22:00:00Z</updated>
    <published>2019-06-16T22:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-06-28T23:35:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/088</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/088" rel="alternate" type="text/html"/>
    <title>TR19-088 |  On the Complexity of Estimating the Effective Support Size | 

	Oded Goldreich</title>
    <summary>Loosely speaking, the effective support size of a distribution is the size of the support of a distribution that is close to it (in totally variation distance). 
We study the complexity of estimating the effective support size of an unknown distribution when given samples of the distributions as well as an evaluation oracle (which returns the probability that the queried element appears in the distribution).
In this context, we present several algorithms that exhibit a trade-off between the quality of the approximation and the complexity of obtaining it, and leave open the question of their optimality.</summary>
    <updated>2019-06-16T15:33:01Z</updated>
    <published>2019-06-16T15:33:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-06-28T23:34:01Z</updated>
    </source>
  </entry>
</feed>
