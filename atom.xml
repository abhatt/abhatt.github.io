<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-17T21:22:09Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-6952358197668395658</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/6952358197668395658/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=6952358197668395658" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/algorithms-with-predictions-survey-and.html" rel="alternate" type="text/html"/>
    <title>Algorithms with Predictions:  Survey and Workshop</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There's a whole new, interesting theory trend  -- Algorithms with Predictions.  The idea, spurred by advances in machine learning, is that you assume you have predictor that tells you something about your input.  For example, in caching, you might have a prediction of when the item you are currently accessing will be next accessed.  Of course, machine learning predictions aren't perfect.  Still, you'd like to use this prediction to improve your caching algorithm, but from the theory side, we'd like provable statements.  For example, you could say, if my prediction is THIS good (e.g., the error is bounded under some metric), then my caching performance will correspondingly be at least THIS good (e.g., performance bounded in some way).<br/><br/>If you haven't seen the burgeoning spread of this line of work and are interested, you're in luck.  First, Sergei Vassilvitskii and I have written a <a href="https://arxiv.org/abs/2006.09123">brief survey that's now on the arxiv</a>.  We had written it for a collection Tim Roughgarden is organizing on Beyond Worst-Case Analysis (that we thought we be out by now, and should be out from the publisher soon-ish), but we've gone ahead and put a version on the arxiv to make it available.  The area is moving fast, so there are already many new results --  we hope to update the "survey" with new material as the area grows.<br/><br/>Second, one of the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">STOC'20 Workshops will be on Algorithms with Predictions</a>.  It will be on Friday from 1-4pm, with speakers Tim Roughgarden, Edith Cohen,  Ravi Kumar, and me.  I'll be talking about some of my recent work  (in submission) on queues with predictions, and partitioned learned Bloom filters.  (Arxiv papers are <a href="https://arxiv.org/abs/1902.00732">here</a>, <a href="https://arxiv.org/abs/1905.12155">here</a>, and <a href="https://arxiv.org/abs/2006.03176">here</a>, but maybe you want to see the talk first.)  I'll also do a blog post on partitioned learned Bloom filters in the near future.</div>
    </content>
    <updated>2020-06-17T17:52:00Z</updated>
    <published>2020-06-17T17:52:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-17T17:53:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2271116647104476479</id>
    <link href="http://processalgebra.blogspot.com/feeds/2271116647104476479/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2271116647104476479" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/logic-mentoring-workshop-2020.html" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_k"><a href="https://www2.csc.liv.ac.uk/~lehtinen/">Karoliina Lehtinen</a> asked me to encourage young researchers of all ages to attend this year's edition of the Logic Mentoring Workshop. (See <a href="https://lmw.mpi-sws.org/">here</a> for information.) The <a href="https://lmw.mpi-sws.org/speakers.html">set of speakers</a> is top class, registration is  free and I am sure that attending the event would be beneficial  to  many. Spread the news!<br/><br/>FWIW, I gave a talk at the <a href="https://lics.siglog.org/lics17/lmw.html">2017 edition</a> of the event and thoroughly enjoyed it. Even though the event is targeted at students, from senior undergraduates to graduates, I feel that I always learn something new from attending this kind of workshops/talks. </div></div>
    </content>
    <updated>2020-06-17T16:10:00Z</updated>
    <published>2020-06-17T16:10:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-17T16:10:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09352</id>
    <link href="http://arxiv.org/abs/2006.09352" rel="alternate" type="text/html"/>
    <title>A One-Pass Private Sketch for Most Machine Learning Tasks</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coleman:Benjamin.html">Benjamin Coleman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shrivastava:Anshumali.html">Anshumali Shrivastava</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09352">PDF</a><br/><b>Abstract: </b>Differential privacy (DP) is a compelling privacy definition that explains
the privacy-utility tradeoff via formal, provable guarantees. Inspired by
recent progress toward general-purpose data release algorithms, we propose a
private sketch, or small summary of the dataset, that supports a multitude of
machine learning tasks including regression, classification, density
estimation, near-neighbor search, and more. Our sketch consists of randomized
contingency tables that are indexed with locality-sensitive hashing and
constructed with an efficient one-pass algorithm. We prove competitive error
bounds for DP kernel density estimation. Existing methods for DP kernel density
estimation scale poorly, often exponentially slower with an increase in
dimensions. In contrast, our sketch can quickly run on large, high-dimensional
datasets in a single pass. Exhaustive experiments show that our generic sketch
delivers a similar privacy-utility tradeoff when compared to existing DP
methods at a fraction of the computation cost. We expect that our sketch will
enable differential privacy in distributed, large-scale machine learning
settings.
</p></div>
    </summary>
    <updated>2020-06-17T04:48:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09327</id>
    <link href="http://arxiv.org/abs/2006.09327" rel="alternate" type="text/html"/>
    <title>A Note on Monotone Submodular Maximization with Cardinality Constraint</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Wenxin.html">Wenxin Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09327">PDF</a><br/><b>Abstract: </b>We show that for the cardinality constrained monotone submodular maximization
problem, there exists a $(1-1/e-\varepsilon)$-approximate deterministic
algorithm with linear query complexity, which performs $O(n/\varepsilon)$
queries in total.
</p></div>
    </summary>
    <updated>2020-06-17T04:48:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09221</id>
    <link href="http://arxiv.org/abs/2006.09221" rel="alternate" type="text/html"/>
    <title>Testing systems of real quadratic equations for approximate solutions</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexander Barvinok <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09221">PDF</a><br/><b>Abstract: </b>Consider systems of equations $q_i(x)=0$, where $q_i: {\Bbb R}^n
\longrightarrow {\Bbb R}$, $i=1, \ldots, m$, are quadratic forms. We want to be
able to tell efficiently systems with many non-trivial solutions or near
solutions $x \ne 0$ from systems that are far from having a solution. For that,
we pick a penalty function $F: {\Bbb R} \longrightarrow [0, 1]$ with $F(0)=1$
and $F(y) &lt; 1$ for $y \ne 0$ and compute the expectation of $F(q_1(x)) \cdots
F(q_m(x))$ for a random $x$ sampled from the standard Gaussian measure in
${\Bbb R}^n$. We choose $F(y)=y^{-2}\sin^2 y$ and show that the expectation can
be approximated within relative error $0&lt; \epsilon &lt; 1$ in quasi-polynomial
time $(m+n)^{O(\ln (m+n)-\ln \epsilon)}$, provided each form $q_i$ depends on
not more than $r$ real variables, has common variables with at most $r-1$ other
forms and satisfies $|q_i(x)| \leq \gamma \|x\|^2/r$, where $\gamma &gt;0$ is an
absolute constant.
</p></div>
    </summary>
    <updated>2020-06-17T04:48:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09197</id>
    <link href="http://arxiv.org/abs/2006.09197" rel="alternate" type="text/html"/>
    <title>Dense Non-Rigid Structure from Motion: A Manifold Viewpoint</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Suryansh.html">Suryansh Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gool:Luc_Van.html">Luc Van Gool</a>, Carlos E. P. de Oliveira, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cherian:Anoop.html">Anoop Cherian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dai:Yuchao.html">Yuchao Dai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Hongdong.html">Hongdong Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09197">PDF</a><br/><b>Abstract: </b>Non-Rigid Structure-from-Motion (NRSfM) problem aims to recover 3D geometry
of a deforming object from its 2D feature correspondences across multiple
frames. Classical approaches to this problem assume a small number of feature
points and, ignore the local non-linearities of the shape deformation, and
therefore, struggles to reliably model non-linear deformations. Furthermore,
available dense NRSfM algorithms are often hurdled by scalability,
computations, noisy measurements and, restricted to model just global
deformation. In this paper, we propose algorithms that can overcome these
limitations with the previous methods and, at the same time, can recover a
reliable dense 3D structure of a non-rigid object with higher accuracy.
Assuming that a deforming shape is composed of a union of local linear subspace
and, span a global low-rank space over multiple frames enables us to
efficiently model complex non-rigid deformations. To that end, each local
linear subspace is represented using Grassmannians and, the global 3D shape
across multiple frames is represented using a low-rank representation. We show
that our approach significantly improves accuracy, scalability, and robustness
against noise. Also, our representation naturally allows for simultaneous
reconstruction and clustering framework which in general is observed to be more
suitable for NRSfM problems. Our method currently achieves leading performance
on the standard benchmark datasets.
</p></div>
    </summary>
    <updated>2020-06-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09167</id>
    <link href="http://arxiv.org/abs/2006.09167" rel="alternate" type="text/html"/>
    <title>Heterogeneous Parallelization and Acceleration of Molecular Dynamics Simulations in GROMACS</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/P=aacute=ll:Szil=aacute=rd.html">Szilárd Páll</a>, Artem Zhmurov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bauer:Paul.html">Paul Bauer</a>, Mark Abraham, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lundborg:Magnus.html">Magnus Lundborg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gray:Alan.html">Alan Gray</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hess:Berk.html">Berk Hess</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindahl:Erik.html">Erik Lindahl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09167">PDF</a><br/><b>Abstract: </b>The introduction of accelerator devices such as graphics processing units
(GPUs) has had profound impact on molecular dynamics simulations and has
enabled order-of-magnitude performance advances using commodity hardware. To
fully reap these benefits, it has been necessary to reformulate some of the
most fundamental algorithms, including the Verlet list, pair searching and
cut-offs. Here, we present the heterogeneous parallelization and acceleration
design of molecular dynamics implemented in the GROMACS codebase over the last
decade. The setup involves a general cluster-based approach to pair lists and
non-bonded pair interactions that utilizes both GPUs and CPU SIMD acceleration
efficiently, including the ability to load-balance tasks between CPUs and GPUs.
The algorithm work efficiency is tuned for each type of hardware, and to use
accelerators more efficiently we introduce dual pair lists with rolling pruning
updates. Combined with new direct GPU-GPU communication as well as GPU
integration, this enables excellent performance from single GPU simulations
through strong scaling across multiple GPUs and efficient multi-node
parallelization.
</p></div>
    </summary>
    <updated>2020-06-17T04:47:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09123</id>
    <link href="http://arxiv.org/abs/2006.09123" rel="alternate" type="text/html"/>
    <title>Algorithms with Predictions</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vassilvitskii:Sergei.html">Sergei Vassilvitskii</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09123">PDF</a><br/><b>Abstract: </b>We introduce algorithms that use predictions from machine learning applied to
the input to circumvent worst-case analysis. We aim for algorithms that have
near optimal performance when these predictions are good, but recover the
prediction-less worst case behavior when the predictions have large errors.
</p></div>
    </summary>
    <updated>2020-06-17T04:49:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.09085</id>
    <link href="http://arxiv.org/abs/2006.09085" rel="alternate" type="text/html"/>
    <title>MCRapper: Monte-Carlo Rademacher Averages for Poset Families and Approximate Pattern Mining</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pellegrina:Leonardo.html">Leonardo Pellegrina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cousins:Cyrus.html">Cyrus Cousins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vandin:Fabio.html">Fabio Vandin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Riondato:Matteo.html">Matteo Riondato</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.09085">PDF</a><br/><b>Abstract: </b>We present MCRapper, an algorithm for efficient computation of Monte-Carlo
Empirical Rademacher Averages (MCERA) for families of functions exhibiting
poset (e.g., lattice) structure, such as those that arise in many pattern
mining tasks. The MCERA allows us to compute upper bounds to the maximum
deviation of sample means from their expectations, thus it can be used to find
both statistically-significant functions (i.e., patterns) when the available
data is seen as a sample from an unknown distribution, and approximations of
collections of high-expectation functions (e.g., frequent patterns) when the
available data is a small sample from a large dataset. This feature is a strong
improvement over previously proposed solutions that could only achieve one of
the two. MCRapper uses upper bounds to the discrepancy of the functions to
efficiently explore and prune the search space, a technique borrowed from
pattern mining itself. To show the practical use of MCRapper, we employ it to
develop an algorithm TFP-R for the task of True Frequent Pattern (TFP) mining.
TFP-R gives guarantees on the probability of including any false positives
(precision) and exhibits higher statistical power (recall) than existing
methods offering the same guarantees. We evaluate MCRapper and TFP-R and show
that they outperform the state-of-the-art for their respective tasks.
</p></div>
    </summary>
    <updated>2020-06-17T04:48:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08958</id>
    <link href="http://arxiv.org/abs/2006.08958" rel="alternate" type="text/html"/>
    <title>On the Hardness of Problems Involving Negator Relationships in an Artificial Hormone System</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hutter:Eric.html">Eric Hutter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pacher:Mathias.html">Mathias Pacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brinkschulte:Uwe.html">Uwe Brinkschulte</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08958">PDF</a><br/><b>Abstract: </b>The Artificial Hormone System (AHS) is a self-organizing middleware to
allocate tasks in a distributed system. We extended it by so-called negator
hormones to enable conditional task structures. However, this extension
increases the computational complexity of seemingly simple decision problems in
the system: In [1] and [2], we defined the problems Negator-Path and
Negator-Sat and proved their NP-completeness. In this supplementary report to
these papers, we show examples of Negator-Path and Negator-Sat, introduce the
novel problem Negator-Stability and explain why all of these problems involving
negators are hard to solve algorithmically.
</p></div>
    </summary>
    <updated>2020-06-17T04:45:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08949</id>
    <link href="http://arxiv.org/abs/2006.08949" rel="alternate" type="text/html"/>
    <title>Utility-Based Graph Summarization: New and Improved</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiabadi:Mahdi.html">Mahdi Hajiabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Jasbir.html">Jasbir Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srinivasan:Venkatesh.html">Venkatesh Srinivasan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomo:Alex.html">Alex Thomo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08949">PDF</a><br/><b>Abstract: </b>A fundamental challenge in graph mining is the ever-increasing size of
datasets. Graph summarization aims to find a compact representation resulting
in faster algorithms and reduced storage needs. The flip side of graph
summarization is the loss of utility which diminishes its usability. The key
questions we address in this paper are: (1)How to summarize a graph without any
loss of utility? (2)How to summarize a graph with some loss of utility but
above a user-specified threshold? (3)How to query graph summaries without graph
reconstruction?} We also aim at making graph summarization available for the
masses by efficiently handling web-scale graphs using only a consumer-grade
machine. Previous works suffer from conceptual limitations and lack of
scalability. In this work, we make three key contributions. First, we present a
utility-driven graph summarization method, based on a clique and independent
set decomposition, that produces significant compression with zero loss of
utility. The compression provided is significantly better than state-of-the-art
in lossless graph summarization, while the runtime is two orders of magnitude
lower. Second, we present a highly scalable algorithm for the lossy case, which
foregoes the expensive iterative process that hampers previous work. Our
algorithm achieves this by combining a memory reduction technique and a novel
binary-search approach. In contrast to the competition, we are able to handle
web-scale graphs in a single machine without a performance impediment as the
utility threshold (and size of summary) decreases. Third, we show that our
graph summaries can be used as-is to answer several important classes of
queries, such as triangle enumeration, Pagerank, and shortest paths. This is in
contrast to other works that incrementally reconstruct the original graph for
answering queries, thus incurring additional time costs.
</p></div>
    </summary>
    <updated>2020-06-17T04:46:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08926</id>
    <link href="http://arxiv.org/abs/2006.08926" rel="alternate" type="text/html"/>
    <title>Computing Igusa's local zeta function of univariates in deterministic polynomial-time</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08926">PDF</a><br/><b>Abstract: </b>Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that
counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$,
for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$
is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of
this fact for a univariate polynomial $f$. Our proof is constructive as it
gives a closed-form expression for the number of roots $N_{k}(f)$.
</p>
<p>Our proof, when combined with the recent root-counting algorithm of (Dwivedi,
Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$)
time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only
in the case when $f$ completely splits over $\mathbb{Q}_p$; it required the
rational roots to use the concept of generating function of a tree
(Z\'u\~niga-Galindo, J.Int.Seq., 2003).
</p></div>
    </summary>
    <updated>2020-06-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08886</id>
    <link href="http://arxiv.org/abs/2006.08886" rel="alternate" type="text/html"/>
    <title>Distinct distances in the complex plane</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheffer:Adam.html">Adam Sheffer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zahl:Joshua.html">Joshua Zahl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08886">PDF</a><br/><b>Abstract: </b>We prove that if $P$ is a set of $n$ points in $\mathbb{C}^2$, then either
the points in $P$ determine $\Omega(n^{1-\epsilon})$ complex distances, or $P$
is contained in a line with slope $\pm i$. If the latter occurs then each pair
of points in $P$ have complex distance 0.
</p></div>
    </summary>
    <updated>2020-06-17T04:56:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08731</id>
    <link href="http://arxiv.org/abs/2006.08731" rel="alternate" type="text/html"/>
    <title>Exact and Metaheuristic Approaches for the Production Leveling Problem</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Johannes Vass, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lackner:Marie=Louise.html">Marie-Louise Lackner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musliu:Nysret.html">Nysret Musliu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08731">PDF</a><br/><b>Abstract: </b>In this paper we introduce a new problem in the field of production planning
which we call the Production Leveling Problem. The task is to assign orders to
production periods such that the load in each period and on each production
resource is balanced, capacity limits are not exceeded and the orders'
priorities are taken into account. Production Leveling is an important
intermediate step between long-term planning and the final scheduling of orders
within a production period, as it is responsible for selecting good subsets of
orders to be scheduled within each period.
</p>
<p>A formal model of the problem is proposed and NP-hardness is shown by
reduction from Bin Backing. As an exact method for solving moderately sized
instances we introduce a MIP formulation. For solving large problem instances,
metaheuristic local search is investigated. A greedy heuristic and two
neighborhood structures for local search are proposed, in order to apply them
using Variable Neighborhood Descent and Simulated Annealing. Regarding exact
techniques, the main question of research is, up to which size instances are
solvable within a fixed amount of time. For the metaheuristic approaches the
aim is to show that they produce near-optimal solutions for smaller instances,
but also scale well to very large instances.
</p>
<p>A set of realistic problem instances from an industrial partner is
contributed to the literature, as well as random instance generators. The
experimental evaluation conveys that the proposed MIP model works well for
instances with up to 250 orders. Out of the investigated metaheuristic
approaches, Simulated Annealing achieves the best results. It is shown to
produce solutions with less than 3% average optimality gap on small instances
and to scale well up to thousands of orders and dozens of periods and products.
The presented metaheuristic methods are already being used in the industry.
</p></div>
    </summary>
    <updated>2020-06-17T04:46:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.08668</id>
    <link href="http://arxiv.org/abs/2006.08668" rel="alternate" type="text/html"/>
    <title>Algorithmic Aspects of Temporal Betweenness</title>
    <feedworld_mtime>1592352000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sebastian Buß, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, Maciej Rymar <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.08668">PDF</a><br/><b>Abstract: </b>The betweenness centrality of a graph vertex measures how often this vertex
is visited on shortest paths between other vertices of the graph. In the
analysis of many real-world graphs or networks, betweenness centrality of a
vertex is used as an indicator for its relative importance in the network. In
particular, it is among the most popular tools in social network analysis. In
recent years, a growing number of real-world networks is modeled as temporal
graphs, where we have a fixed set of vertices and there is a finite discrete
set of time steps and every edge might be present only at some time steps.
While shortest paths are straightforward to define in static graphs, temporal
paths can be considered "optimal" with respect to many different criteria,
including length, arrival time, and overall travel time (shortest, foremost,
and fastest paths). This leads to different concepts of temporal betweenness
centrality and we provide a systematic study of temporal betweenness variants
based on various concepts of optimal temporal paths. Computing the betweenness
centrality for vertices in a graph is closely related to counting the number of
optimal paths between vertex pairs. We show that counting foremost and fastest
paths is computationally intractable (#P-hard) and hence the computation of the
corresponding temporal betweenness values is intractable as well. For shortest
paths and two selected special cases of foremost paths, we devise
polynomial-time algorithms for temporal betweenness computation. Moreover, we
also explore the distinction between strict (ascending time labels) and
non-strict (non-descending time labels) time labels in temporal paths. In our
experiments with established real-world temporal networks, we demonstrate the
practical effectiveness of our algorithms, compare the various betweenness
concepts, and derive recommendations on their practical use.
</p></div>
    </summary>
    <updated>2020-06-17T04:52:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17204</id>
    <link href="https://rjlipton.wordpress.com/2020/06/16/pnp/" rel="alternate" type="text/html"/>
    <title>P&lt;NP</title>
    <summary>Some thoughts on P versus NP Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the third of Mehlhorn’s eighty-eight listed students. Today I wish to discuss a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some thoughts on P versus NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17188" rel="attachment wp-att-17188"><img alt="" class="alignright size-full wp-image-17188" src="https://rjlipton.files.wordpress.com/2020/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=35475&amp;fChrono=1">third</a> of Mehlhorn’s eighty-eight listed students.</p>
<p>
Today I wish to discuss a new paper by Blum.</p>
<p>
No, it does not solve the P versus NP problem. The title of his paper is: <i>On the Approximation Method and the P versus NP Problem</i>. Its is available <a href="https://arxiv.org/pdf/1708.03486.pdf">here</a>.</p>
<p>
Blum. like most complexity theorists, believes that P is weaker than NP. This is usually stated as P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP. The staff at GLL have the idea that we should state this as 	</p>
<p align="center"><img alt="\displaystyle  P &lt; NP. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3C+NP.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P &lt; NP. "/></p>
<p>This is clearer, more to the point, and logically what P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP actually says. We will soon have T-shirts, mugs, and other stuff available in our web store at https:donotgotothisaddressplease.com. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/16/pnp/mug2-2/" rel="attachment wp-att-17207"><img alt="" class="aligncenter size-medium wp-image-17207" height="257" src="https://rjlipton.files.wordpress.com/2020/06/mug2-1.png?w=300&amp;h=257" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Three Years Ago </h2><p/>
<p/><p>
In 2017 Blum released a <a href="https://arxiv.org/abs/1708.03486">paper</a> that tried to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. It caused a sensation—it was discussed on the complexity blogs such as <a href="https://lucatrevisan.wordpress.com/2017/08/15/on-norbert-blums-claimed-proof-that-p-does-not-equal-np/">In theory</a> and <a href="https://www.scottaaronson.com/blog/?p=3409">Shtetl-Optimized</a>. And also at <a href="https://rjlipton.wordpress.com/2017/08/17/on-the-edge-of-eclipses-and-pnp/">GLL</a>. Blum’s paper got thousands of Twitter mentions. Unfortunately he had to retract it, since it is wrong: He said: </p>
<blockquote><p><b> </b> <em> The proof is wrong. I shall elaborate precisely what the mistake is. For doing this, I need some time. I shall put the explanation on my homepage </em>
</p></blockquote>
<p>Look at <a href="https://johncarlosbaez.wordpress.com/2017/08/15/norbert-blum-on-p-versus-np/">here</a> for more comments that were made after his paper was released. </p>
<p>
He did, months later in 2017, post a two-page retraction<br/>
<a href="http://theory.cs.uni-bonn.de/blum/PvsNP/mistake.pdf">here</a>. His original paper’s abstract: </p>
<blockquote><p><b> </b> <em> Berg and Ulfberg and Amano and Maruoka have used CNF-DNF-approximators to prove exponential lower bounds for the monotone network complexity of the clique function and of Andreev’s function. We show that these approximators can be used to prove the same lower bound for their non-monotone network complexity. This implies P not equal NP. </em>
</p></blockquote>
<p>This approach is what we will discuss.</p>
<p>
</p><p/><h2> Today </h2><p/>
<p/><p>
Blum’s new paper does not claim to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, but gives his thoughts on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I think he has earned our attention. It must have been difficult to go from thinking you have solved <i>the problem</i> to retracting your paper. I have thought, privately, that I had solved some neat problems. Only later to discover that I was wrong. I cannot imagine how tough it was to do this in public. </p>
<p>
</p><p/><h2> The Idea </h2><p/>
<p/><p>
Blum’s work on proving lower bounds began with his dissertation under Mehlhorn, which included a 1985 <a href="https://www.sciencedirect.com/science/article/pii/0304397585900301">paper</a> on monotone network complexity for convolutions. Earlier in 1984 Blum <a href="https://reader.elsevier.com/reader/sd/pii/0304397583900294? which was improved token=1F67F05B416D89618750BC409200E17D536C46207555E1A9FD524B2592630E400FC2C597EA81F7190D2A747A4B82F28B">proved</a> a lower bound of order <img alt="{3n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n}"/>. This stood for thirty years until in 2015 Magnus Find, Alexander Golovnev, Edward Hirsch, and Alexander Kulikov <a href="https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=919494">improved</a> it to order <img alt="{3.011n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3.011n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3.011n}"/>. A long way from super-polynomial lower bounds. See also a <a href="https://simons.berkeley.edu/sites/default/files/docs/3815/20151001gateelimination.pdf">talk</a> about this work. </p>
<p>
Blum’s new paper discusses an old approach to prove boolean circuit lower bounds. The methods he used in 1984 and those improved in 2015 do not seem to be on track to prove even non-linear circuit lower bounds. </p>
<p>
Let’s look at his comments at a high level. See his paper for details. </p>
<p>
Suppose that one has a boolean function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> that is monotone: recall this means that if <img alt="{f(x)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=1}"/>, then changing some input <img alt="{x_{k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{k}}"/> from <img alt="{0 \rightarrow 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \rightarrow 1}"/> does not change the value of <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. Then it is always possible to compute <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> without using any negations: only and/or operations are needed. Sometimes one can prove that the number of such operations is super-linear, sometimes even super-polynomial. Even bounds in this restricted model can be deep.</p>
<p>
The idea that has tempted Blum and many other complexity theorists is: Can we extend the proofs for lower bounds without negations to ones with negations? One problem is there is a function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> so that the following are true: </p>
<ol>
<li>
The function is monotone; <p/>
</li><li>
The function can be computed in polynomial time; <p/>
</li><li>
Any monotone circuit for computing the function requires exponential size
</li></ol>
<p>This is the famous <a href="https://en.wikipedia.org/wiki/Tardos_function">Tardos function</a> due to Éva Tardos. The existence of this function sunk Blum’s original paper. And it makes life hard for this general program—this is an instance of what our previous <a href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/">post</a> meant by a proof attempt running up against a fundamental law. Negations can help tremendously in computing a function. </p>
<p>
</p><p/><h2> Blum’s Paper </h2><p/>
<p/><p>
In his new <a href="https://arxiv.org/pdf/1708.03486.pdf">paper</a> he surveys boolean complexity ideas—especially those linked to monotone complexity. He begins by trying to argue that the largeness feature of the <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">natural proofs</a> barrier, which applies to combinatorial properties defined via sub-additive circuit complexity measures, does not constrain approximation complexity measures of the kind he envisions. He then proceeds to define <em>CNF-DNF approximators</em> and further what he calls <em>sunflower approximators</em>. He does enough development to highlight a missing piece of information about monomial representations of <em>non-</em>approximated pieces of the Boolean function one is trying to prove hard. He concludes that without this information, his methods cannot even prove super-<em>linear</em> size lower bounds on general circuits.</p>
<p>
He ends with this assessment: </p>
<blockquote><p><b> </b> <em> How to proceed the work with respect to the P versus NP problem? Currently, I am convinced that we are far away to prove a super-polynomial lower bound for the non-monotone complexity of any explicit Boolean function. On the other hand, the strongest barrier towards proving P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP could be that it holds P = NP. To ensure that the whole time spent for working on the P versus NP problem is not used to prove an impossible theorem, I would switch to the try to develop a polynomial algorithm for the solution of an NP-complete problem. </em>
</p></blockquote>
<p/><p>
Note, we have changed his P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. Ken and I agree with him on trying to work both on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP and P=NP. However, see our comments below. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I applaud Blum for thinking about P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. We need people to be fearless if it is ever going to be solved. However, I personally believe that his approach may be wrong:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> I am not as sure as he is that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I do think that P=NP is possible, especially if algorithms are allowed to be <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">galactic</a>. Recall these are algorithms that run in polynomial time, but in polynomials of astronomical degree.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Also I am not sure if the boolean approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP is the right one. Suppose there is a <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> so that SAT has boolean circuits of size <img alt="{n^{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{C}}"/> where 	</p>
<p align="center"><img alt="\displaystyle  C = 2^{2^{2^{10000}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%3D+2%5E%7B2%5E%7B2%5E%7B10000%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C = 2^{2^{2^{10000}}}. "/></p>
<p>It still could be the case that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, since there may be no uniform algorithm for SAT.</p>
<p>
Restating the last point: I believe we should try to prove what is needed, and not any more. The approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP based on boolean circuit complexity is trying to prove too much. A proof that SAT has super-polynomial circuits does imply more than P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. A proof that SAT cannot be solved in time <img alt="o(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(n\log n)"/> on a multitape Turing machine would imply much less than P &lt; NP, yet still be a breakthrough</p>
<p>
Be cheap, prove the least possible. </p>
<p/></font></font></div>
    </content>
    <updated>2020-06-16T20:40:41Z</updated>
    <published>2020-06-16T20:40:41Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-17T21:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/092" rel="alternate" type="text/html"/>
    <title>TR20-092 |  Computing Igusa&amp;#39;s local zeta function of univariates in deterministic polynomial-time | 

	Ashish Dwivedi, 

	Nitin Saxena</title>
    <summary>Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$. 

Our proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\mathbb{Q_p}$; it required the rational roots to use the concept of generating function of a tree (Zuniga-Galindo, J.Int.Seq., 2003).</summary>
    <updated>2020-06-16T08:32:14Z</updated>
    <published>2020-06-16T08:32:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc positions in TCS at University of Copenhagen (apply by July 6, 2020)</title>
    <summary>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See https://employment.ku.dk/faculty/?show=151975 for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk. Website: https://employment.ku.dk/faculty/?show=151975 Email: jn@di.ku.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a><br/>
Email: jn@di.ku.dk</p></div>
    </content>
    <updated>2020-06-15T21:51:22Z</updated>
    <published>2020-06-15T21:51:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-17T21:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Graduata data structures online (), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/261/">Graduata data structures online</a> (<a href="https://mathstodon.xyz/@11011110/104266993520726615"/>), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2020/06/02/list-100-times-law-enforceme.html">Freedom of the press under attack: 100+ times law enforcement violently assaulted journalists in US at George Floyd protests</a> (<a href="https://mathstodon.xyz/@11011110/104276714124643888"/>). Of course this is only a small piece of an enormous pattern of awfulness by the current administration, law enforcement, and the prison-industrial complex, but it’s a piece that I think is important to document.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/06/01/four-commercial-publishers-filed-a-complaint-about-the-internet-archives-lending-of-digitized-books/">Four book publishing corporations claim that what libraries always have done (lending out copies of books they have purchased as physical objects) is illegal, because computer, and are suing the Internet Archive over it</a> (<a href="https://mathstodon.xyz/@11011110/104283895750093044"/>, <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">via</a>, <a href="https://torrentfreak.com/publishers-sue-the-internet-archive-over-its-open-library-declare-it-a-pirate-site-200601/">via2</a>). One of them, Wiley, is also a major publisher of academic works. Perhaps that should give some of us pause in which journals we send our papers to and referee for.</p>
  </li>
  <li>
    <p><a href="https://observablehq.com/@otaviocv/moire-patterns-from-random-dots">Moiré patterns from random dots</a> (<a href="https://mathstodon.xyz/@11011110/104290097720006041"/>). Overlaying the same random dot pattern on a translated and rotated copy of itself shows concentric dots around the center of rotation, illustrating <a href="https://en.wikipedia.org/wiki/Chasles%27_theorem_(kinematics)">Chasles’ theorem</a> that every rigid transformation of the plane is a translation or rotation. The effect seems to have first been observed by Leon Glass in “<a href="https://doi.org/10.1038/223578a0">Moiré patterns from random dots</a>” (<em>Nature</em>, 1969).</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/978-3-030-48966-3_3">“The Micro-world of Cographs”, Alecu, Lozin, and de Werra, <em>IWOCA</em> 2020</a> (<a href="https://mathstodon.xyz/@11011110/104295850760016598"/>). <a href="https://en.wikipedia.org/wiki/Cograph">Cographs</a> have a simple structure, but there’s still an interesting hierarchy of subclasses of graphs within them restricting different parameters of graph complexity to be bounded. A typical result: Every cograph with large h-index must contain a large complete graph, balanced bipartite graph, or forest of many high-degree stars.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/technology/2020/jun/01/cutting-edge-japanese-paper-art-inspires-a-non-slip-shoe">Japanese scientists use kirigami to design a shoe sole with pop-up non-slip spikes</a>.</p>
  </li>
  <li>
    <p><a href="https://mamot.fr/@starifi/104246098809527372">Ombre et lumière</a>. Artwork in which random-looking blocks on a wall create a recognizable shadow in side-light.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/a/362569/440">Brian Hopkins answers his own 9-year-old question on the history of  Fibonacci numbers and compositions</a> (<a href="https://mathstodon.xyz/@11011110/104312192948087479"/>). The ancient Indians knew that compositions (ordered partitions of integers) into ’s and ’s are counted by Fibonacci numbers. For instance, there five ways of forming  as an ordered sum of ’s and ’s:     . Cayley knew that the compositions with all parts bigger than  have Fibonacci counts. But who first knew that compositions with all parts odd are also counted by Fibonacci? Hopkins suggests: de Morgan, 1846.</p>
  </li>
  <li>
    <p>Despite new US covid cases being more or less the same level (or worse) as the start of the lockdown in March, <a href="https://www.chronicle.com/article/Faculty-Want-a-Say-in-Whether/248951">some universities are telling their students that it’s safe to return to normal and at the same time telling their faculty that unless they’re close to retirement age and have additional medical conditions, they must teach face to face</a> (<a href="https://mathstodon.xyz/@11011110/104318055800990449"/>).</p>
  </li>
  <li>
    <p><a href="https://drericsilverman.wordpress.com/games/">A nice page of recent writings about abstract strategy games, mostly connection games</a> (<a href="https://mathstodon.xyz/@jsiehler/104241019767261031"/>).</p>
  </li>
  <li>
    <p><a href="https://news.mit.edu/2020/guided-by-open-access-principles-mit-ends-elsevier-negotiations-0611">MIT gives up on trying to get an equitable subscription deal from Elsevier, ends negotiations</a> (<a href="https://mathstodon.xyz/@11011110/104326335350221116"/>, <a href="https://news.ycombinator.com/item?id=23489068">via</a>).</p>
  </li>
  <li>
    <p><em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16150">The Proceedings of the 17th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2020)</a></em> (<a href="https://mathstodon.xyz/@11011110/104334978432657954"/>), newly published open-access through LIPIcs. Sadly, the conference will be online rather than in the Faroe Islands as originally planned. <em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16149">The Proceedings of the 36th International Symposium on Computational Geometry (SoCG 2020)</a></em> is also now out.</p>
  </li>
  <li>
    <p><a href="https://www.win.tue.nl/~kbuchin/proj/ruler/art/">Illuminate</a> (<a href="https://mathstodon.xyz/@11011110/104340239573347579"/>). An online puzzle based on the art gallery theorem, part of the media exposition of this year’s Symposium on Computational Geometry. See also the <a href="https://doi.org/10.4230/LIPIcs.SoCG.2020.80">theoretical writeup</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/book/10.1007/978-1-84800-070-4">Skiena’s <em>Algorithm Design Manual</em></a> (<a href="https://mathstodon.xyz/@11011110/104349420443124730"/>, <a href="https://news.ycombinator.com/item?id=23529759">via</a>, <a href="https://news.ycombinator.com/item?id=23055340">via2</a>, <a href="https://www.metafilter.com/187489/Free-Textbooks">see also</a>), one of 500 Springer textbooks still available for free download from the publisher.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-15T17:54:00Z</updated>
    <published>2020-06-15T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3523309889572389823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3523309889572389823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html" rel="alternate" type="text/html"/>
    <title>Presentations of Diffie-Helman leave out how to find g</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first taught Diffie Helman I read the following<br/>
1) Alice and Bob agree on p a prime and g a generator<br/>
2) Alice picks a, sends g^a to Bob, Bob picks b, sends g^b to Alice<br/>
3) Alice computes (g^b)^a and Bob computes (g^a)^b so they both have g^{ab}<br/>
<br/>
I knew how to find a prime- pick a number of length n (perhaps make sure the last digit is not even) and test for primality, if not then try again, you'll get one soon enough. I did not know how to find g. I had thought you<i> first </i>find p, and<i> then</i> given p you find g. I then figured out that you make actually pick  p to be a  <i>safe prime</i>, so q=(p-1)/2 is a prime, and then just pick random g and test them via computing  g^2  and g^q: if neither is 1 then g is a generator. You will find a generator soon enough.<br/>
<br/>
That was all fine. But how come my source didn't <i>say </i>how to find g.?You need to know that to run the algorithm. That was years ago. Then I wondered how common it is for an explanation to not say how to find g. So I Googled ``Diffie-Helman'' I only record those that had some technical content to them, and were not about other DH such as Elliptic Curves.<br/>
<br/>
0) <a href="http://www.cs.jhu.edu/~rubin/courses/sp03/papers/diffie.hellman.pdf">The Original DH paper</a> Page 34:<i> alpha is a fixed primitive element of GF(alpha)</i>. No mention of how to find either the prime q or the prim root alpha.<br/>
<br/>
1) <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Wikiepdia</a>: ... <i>protocol uses the mult group of integers mod p, where p is a prime and g is a prim</i> <i>root mod p</i>. NO mention of how they find p or g.<br/>
<br/>
2) <a href="https://mathworld.wolfram.com/Diffie-HellmanProtocol.html">Wolfram's MathWorld</a>:<i> They agree on two prime numbers g and p, where p is large and g is a prim root mod p. In practice it is good to choose p such that (p-1)/2 is also prime. </i>They mention (p-1)/2 but not for the reason I give. (There are algorithms for Discrete Log that do well if (p-1)/2 has many factors.)<br/>
<br/>
3) <a href="https://www.comparitech.com/blog/information-security/diffie-hellman-key-exchange/">Comparatech</a>: <i>Alice and Bob start out by deciding two numbers p and g.</i> No mention of how to find p or g.<br/>
<br/>
4) <a href="https://searchsecurity.techtarget.com/definition/Diffie-Hellman-key-exchange">Searchsecurity</a> Won't bother quoting, but more of the same, no mention of how to find p or g.<br/>
<br/>
5) <a href="https://doubleoctopus.com/security-wiki/encryption-and-cryptography/diffie-hellman-algorithm/">The Secret Security Wiki</a> <i>Alice and Bob agree on p and g</i>.<br/>
<br/>
6) <a href="https://www.sciencedirect.com/topics/computer-science/diffie-hellman">Science Direct</a> More of the same.<br/>
<br/>
7) <a href="https://www.math.ucla.edu/~baker/40/handouts/rev_DH/node1.html">Notes from a UCLA Crypto Course</a> YEAH! They say how to find g.<br/>
<br/>
8) <a href="https://brilliant.org/wiki/diffie-hellman-protocol/">Brilliant (yes that really is the name of this site)</a> Brilliant? Not brilliant enough to realize you need to say how to find p and g.<br/>
<br/>
9) <a href="https://wiki.openssl.org/index.php/Diffie_Hellman">OpenSSL</a> Hard to tell. Their intuitive explanation leaves it out, but they have details below and code that might have it.<br/>
<br/>
<br/>
I looked at a few more but it was the same story.<br/>
<br/>
This is NOT a RANT or even a complaint, but its a question:<br/>
<br/>
<b>Why do so few expositions of DH mention how to find p,g? You really need to do that if you really want to DO DH.</b><br/>
<b><br/></b>
Speculation<br/>
<br/>
1) Some of the above are for the laymen and hence can not get into that. But some are not.<br/>
<br/>
2) Some of them are for advanced audiences who would know how to do it. Even so, how to find the generator really needs to be mentioned.<br/>
<br/>
3) Goldilocks: Some papers are for the layman who would not notice the gap, and some papers are for the expert who can fill in the gap themselves, so no paper in between. I do not believe that.<br/>
<br/>
4) The oddest of the above is that the original paper did not say how to find g.<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-15T15:17:00Z</updated>
    <published>2020-06-15T15:17:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-17T15:54:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs</id>
    <link href="https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs.html" rel="alternate" type="text/html"/>
    <title>Infinite threshold graphs, four different ways</title>
    <summary>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</p>

<p style="text-align: center;"><img alt="Threshold graph" src="https://11011110.github.io/blog/assets/2020/threshold.svg"/></p>

<p>As an example of this phenomenon, consider the <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, one of the simplest classes of finite graphs. An example is shown above. These can be defined in multiple equivalent ways:</p>

<ul>
  <li>
    <p>The finite threshold graphs are the graphs that can be built up by repeatedly adding either a universal vertex or an isolated vertex to a smaller graph. In the example, the vertices have been added in left-to-right order, with isolated vertices depicted in yellow and universal vertices in blue. This can be formalized in a way that extends to infinite graphs by saying that they are the graphs in which every nonempty induced subgraph contains either a universal vertex or an isolated vertex. Let’s call these graphs the “inductive threshold graphs”.</p>
  </li>
  <li>
    <p>We can also construct graphs in the reverse ordering, by repeatedly adding a vertex whose neighbors form a clique and whose non-neighbors form an independent set. More concisely, the vertex is both simplicial and cosimplicial. The example above can be constructed in this way by adding the vertices in right-to-left order, with the blue neighbors of each added vertex forming a clique and the yellow neighbors forming an independent set. This can be formalized in a way that extends to infinite graphs by requiring that every induced subgraph has a vertex that is simplicial and cosimplicial. Let’s call a graph with this property a “coinductive threshold graph”.</p>
  </li>
  <li>
    <p>The finite threshold graphs are the -free finite graphs, meaning that no four vertices form an induced subgraph that is a path, cycle, or perfect matching.</p>
  </li>
  <li>
    <p>The finite threshold graphs get their name from the following property: they are the graphs that we can generate by assigning weights in the interval  to the vertices and connecting two vertices by an edge whenever their sum of weights is at least one. Let’s call a graph with this property a “real threshold graph”.</p>
  </li>
</ul>

<p>All four of these properties are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>: if a graph has the property, so do all its induced subgraphs. Because the three forbidden subgraphs , , and  have no universal or isolated vertex, have no simplicial and cosimplicial vertex, and have no valid weight assignment, the inductive threshold graphs, coinductive threshold graphs, and real threshold graphs are all subclasses of the -free graphs.</p>

<p>If a graph is -free, we can define a relation  on its vertices by saying that  if there is no vertex  with  forming an induced path or complement of a path. It follows from the nonexistence of the forbidden subgraphs that this is a total preorder, that every vertex  is universal or isolated among the vertices , and that every vertex  is simplicial and cosimplicial among the vertices . In the example above, two vertices are in the same equivalence class of the ordering if they are in a contiguous block of vertices with the same color, and otherwise their ordering according to  is the same as their left-to-right ordering. Because every finite total preorder has a minimal and a maximal element, every finite -free graph is an inductive threshold graph and a coinductive threshold graph.</p>

<p>However, these properties differ for infinite graphs. In an infinite inductive threshold graph, the total preorder must obey the <a href="https://en.wikipedia.org/wiki/Ascending_chain_condition">ascending chain condition</a> that there be no strictly-increasing infinite sequence of vertices, for the subgraph induced by the vertices of such a sequence would have no isolated or universal vertex. Conversely, if the order does obey the ascending chain condition, one could find an isolated or universal vertex in any subgraph by starting from an arbitrary vertex and repeatedly moving upwards in the order until getting stuck. So the inductive threshold graphs are exactly the ones whose order obeys the ascending chain condition. Similarly, the coinductive threshold graphs are exactly the ones whose order obeys the descending chain condition. But it is easy to construct orders that violate one or both of these conditions. A graph can only be a real threshold graph if the total order on the equivalence classes of its preorder can be embedded into , and again this is not true of all total orders.</p>

<p>One consequence of this difference between classes of infinite graphs is the construction of natural statements in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> that are true for all finite graphs but untrue for some infinite graphs. For instance, the statements that a -free graph has an isolated or universal vertex, and that a -free graph has a simplicial and cosimplicial vertex, are both true of all finite graphs, but untrue of some infinite graphs.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104345188939710302">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-14T15:50:00Z</updated>
    <published>2020-06-14T15:50:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/091" rel="alternate" type="text/html"/>
    <title>TR20-091 |  Randomized polynomial-time equivalence between determinant and trace-IMM equivalence tests | 

	Janaky Murthy, 

	vineet nair, 

	Chandan Saha</title>
    <summary>Equivalence testing for a polynomial family $\{g_m\}_{m \in \mathbb{N}}$ over a field F is the following problem: Given black-box access to an $n$-variate polynomial $f(\mathbb{x})$, where $n$ is the number of variables in $g_m$ for some $m \in \mathbb{N}$, check if there exists an $A \in \text{GL}(n,\text{F})$ such that $f(\mathbb{x}) = g_m(A\mathbb{x})$. If yes, then output such an $A$. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the family of iterated matrix multiplication polynomials. Two popular variants of the iterated matrix multiplication polynomial are: IMM$_{w,d}$ (the $(1,1)$ entry of the product of $d$ many $w\times w$  symbolic matrices) and Tr-IMM$_{w,d}$ (the trace of the product of $d$ many $w\times w$ symbolic matrices). The families - Det, IMM and Tr-IMM - are VBP-complete under $p$-projections, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). 

The above result may appear a bit surprising as the complexity of equivalence testing for IMM and that for Det are quite different over rationals: a randomized polynomial-time equivalence testing for IMM over rationals is known [Kayal,Nair,Saha,Tavenas 2019], whereas [Garg,Gupta,Kayal,Saha 2019] showed that equivalence testing for Det over rationals is integer factoring hard (under randomized reductions and assuming GRH). To our knowledge, the complexity of equivalence testing for Tr-IMM was not known before this work. We show that, despite the syntactic similarity between IMM and Tr-IMM, equivalence testing for Tr-IMM and that for Det are randomized polynomial-time Turing reducible to each other over any field of characteristic zero or sufficiently large. The result is obtained by connecting the two problems via another well-studied problem in computer algebra, namely the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 

1.Testing equivalence of polynomials to Tr-IMM$_{w,d}$, for $d\geq 3$ and $w\geq 2$, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det$_w$, the determinant of the $w \times w$ matrix of formal variables. (Here, $d$ need not be a constant.)

2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors $\{$Tr-IMM$_{w,3}\}_{w \in \mathbb{N}}$.

These results, in conjunction with the randomized poly-time reduction (shown in [GGKS19]) from determinant equivalence testing to FMAI, imply that the four problems - FMAI, equivalence testing for Tr-IMM and for Det, and the $3$-tensor isomorphism problem for the family of matrix multiplication tensors - are randomized poly-time equivalent under Turing reductions.</summary>
    <updated>2020-06-14T13:41:43Z</updated>
    <published>2020-06-14T13:41:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17191</id>
    <link href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/" rel="alternate" type="text/html"/>
    <title>Proof Checking: Not Line by Line</title>
    <summary>Proofs and perpetual motion machines Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Proofs and perpetual motion machines</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/06/picture.png"><img alt="" class="alignright  wp-image-17193" height="150" src="https://rjlipton.files.wordpress.com/2020/06/picture.png?w=200&amp;h=150" width="200"/></a></p>
<p>
Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical and impractical <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">inventions</a>: musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.</p>
<p>
Today I wish to discuss proofs and perpetual motion machines.</p>
<p>
You might ask: <i>What do proofs and perpetual motion machines have in common?</i> Proofs refer to math proofs that claim to solve open problems like P <img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP. Ken and I get such claims all time. I take a look at them, not because I think they are likely to be correct. Rather because I am interested in understanding how people think. </p>
<p>
I started to work on discussing such proofs when I realized that such “proofs” are related to claims about perpetual motion machines. Let’s see how.</p>
<p>
</p><p/><h2> Perpetual Motion Machines </h2><p/>
<p/><p>
A perpetual motion <a href="https://en.wikipedia.org/wiki/Perpetual_motion">machine</a> is a machine that operates indefinitely without an energy source. This kind of machine is impossible, as da Vinci knew already:</p>
<blockquote><p><b> </b> <em> Oh ye seekers after perpetual motion, how many vain chimeras have you pursued? Go and take your place with the alchemists. <br/>
—da Vinci, 1494 </em>
</p></blockquote>
<p/><p>
I like this statement about applying for US patents on such machines: </p>
<blockquote><p><b> </b> <em> Proposals for such inoperable machines have become so common that the United States Patent and Trademark Office (USPTO) has made an official policy of refusing to grant patents for perpetual motion machines without a working model. </em>
</p></blockquote>
<p/><p>
Here is a classic attempt at perpetual motion: The motion goes on “forever” since the right side floats up and the left side falls down. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/float.png"><img alt="" class="aligncenter size-full wp-image-17194" src="https://rjlipton.files.wordpress.com/2020/06/float.png?w=600"/></a></p>
<p>
The analogy of proofs and to perpetual motion machines is: The debunking such a machine is not done by looking carefully at each gear and lever to see why the machine fails to work. Rather is done like this: </p>
<blockquote><p><b> </b> <em> Your machine violates the fundamental laws of thermodynamics and is thus impossible. </em>
</p></blockquote>
<p>Candidate machines are not studied to find the exact flaw in their design. The force of fundamental laws allows a sweeping, simple, and powerful argument against them. There are similar ideas in checking a proof. Let’s take a look at them.</p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Claims are made about proofs of open problems all the time. Often these are made for solutions to famous open problems, like P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP or the Riemann Hypothesis (RH).</p>
<p>
Math proofs are used to try to get to the <i>truth</i>. As we said <a href="https://rjlipton.wordpress.com/2019/04/24/why-check-a-proof/">before</a> proofs are only as good as the assumptions made and the rules invoked. The beauty of the proof concept is that arguments can be checked, even long and complex ones. If the assumptions and the rules are correct, then no matter how strange the conclusion is, it must be true.</p>
<p>
For <a href="https://math.stackexchange.com/questions/2949/which-one-result-in-mathematics-has-surprised-you-the-most">example</a>:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The Riemann rearrangement <a href="https://en.wikipedia.org/wiki/Ri emann_series_theorem#Statement_of_the_theorem">theorem</a>. A sum 	</p>
<p align="center"><img alt="\displaystyle  a_{1} + a_{2} + a_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_%7B1%7D+%2B+a_%7B2%7D+%2B+a_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a_{1} + a_{2} + a_{3} + \dots "/></p>
<p>that is conditionally convergent can be reordered to yield any number. Thus there is series 	</p>
<p align="center"><img alt="\displaystyle  b_{1} + b_{2} + b_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b_%7B1%7D+%2B+b_%7B2%7D+%2B+b_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b_{1} + b_{2} + b_{3} + \dots "/></p>
<p>that sums conditionally to your favorite number <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> and yet the <img alt="{b_{1},b_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B1%7D%2Cb_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{1},b_{2},\dots}"/> is just a arrangement of the <img alt="{a_{1},a_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B1%7D%2Ca_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{1},a_{2},\dots}"/>. This says that addition is not commutative for infinite series.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Cover the largest triangle by two <a href="https://www2.stetson.edu/~efriedma/squcotri/">unit squares</a>: what is the best? The following shows that it is unexpected: </p>
<p/><p/>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/cover.png"><img alt="" class="aligncenter size-full wp-image-17195" src="https://rjlipton.files.wordpress.com/2020/06/cover.png?w=600"/></a></p>
<p/><p><br/>
The point of a proof is that it is a series of small steps. If each step is correct, then the whole is correct. But in practice proofs are often checked in other ways.</p>
<p>
</p><p/><h2> Checking Proofs </h2><p/>
<p/><p>
The starting point for my thoughts—joined here with Ken’s—are these two issues:</p>
<ol>
<li>
A proof that <em>only</em> has many small steps but no global picture is hard to motivate. <p/>
</li><li>
A proof with complex logic at the high level is hard to understand.
</li></ol>
<p>
Note that a deep, hard theorem can still have straightforward logic. A famous <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis#Littlewood's_theorem">theorem</a> of Littlewood has for its proof the structure:</p>
<ul>
<li>
Case the RH is false: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> <p/>
</li><li>
Case the RH is true: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>
</li></ul>
<p>
The RH-false case takes under a page. The benefit with this logic is that one gets to assume RH for the rest. The strategy for the famous proof by Andrew Wiles of Fermat’s Last Theorem (FLT)—incorporating the all-important fix by Richard Taylor—has this structure:</p>
<ul>
<li>
If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. <p/>
</li><li>
If not-<img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. <p/>
</li><li>
<img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> implies FLT. <p/>
</li><li>
<img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/> implies FLT.
</li></ul>
<p>
Wiles had done the last step long before but had put aside since he didn’t know how to get <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. The key was framing <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that it enabled bridged the gap in his originally-announced proof while its negation enabled the older proof.</p>
<p>
Thus what we should seek are proofs with simple logic at the high level that breaks into cases or into sequential sub-goals so that the proof is a chain or relatively few of those goals. </p>
<p>
</p><p/><h2> Shapes and Barriers </h2><p/>
<p/><p>
This makes Ken and I think again about an old <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.7682">paper</a> by Juris Hartmanis with his students Richard Chang, Desh Ranjan, and Pankaj Rohatgi in the May 1990 <em>Bulletin of the EATCS</em> titled, “On IP=PSPACE and Theorems With Narrow Proofs.” Ken’s <a href="https://rjlipton.wordpress.com/2015/05/17/the-shapes-of-computations/">post</a> on it included this nice diagram of what the paper calls “shapes of proofs”:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png"><img alt="" class="aligncenter  wp-image-17197" height="252" src="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png?w=400&amp;h=252" width="400"/></a></p>
<p/><p><br/>
Ken’s thought now is that this taxonomy needs to be augmented with a proof shape corresponding to certain classes believed to be properly below polynomial time—classes within the <a href="https://en.wikipedia.org/wiki/NC_(complexity)">NC</a> hierarchy. Those proofs branch at the top into manageable-size subcases, and/or have a limited number of sequential stages, where each stage may be wide but is shallow in its chains of dependencies. Call this shape a “macro-tree.”</p>
<p>
The difference between the macro-tree shape and the sequential shapes pictured above is neatly captured by Ashley Ahlin on a <a href="http://www.math.wichita.edu/~pparker/classes/thms.htm">page</a> about “Reading Theorems”:</p>
<blockquote><p><b> </b> <em> Note that, in some ways, the easiest way to read a proof is to check that each step follows from the previous ones. This is a bit like following a game of chess by checking to see that each move was legal, or like running a spell-checker on an essay. It’s important, and necessary, but it’s not really the point. … The problem with this is that you are unlikely to remember anything about how to prove the theorem, if you’ve only read in this manner. Once you’re read a theorem and its proof, you can go back and ask some questions to help synthesize your understanding. </em>
</p></blockquote>
<p/><p>
The other high-level structure that a proof needs to make evident—before seeing it is reasonable to expend the effort to check it—is shaped by <em>barriers</em>. We have <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">touched</a> on <a href="https://rjlipton.wordpress.com/2013/03/13/no-go-theorems/">this</a> topic <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">several</a> <a href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/">times</a> but maybe have not stated it full on for P versus NP. A recent <a href="http://theory.stanford.edu/~liyang/teaching/projects/formal-barriers-to-proving-P-ne-NP.pdf">essay</a> for a course led by Li-Yang Tan at Stanford does so in just a few pages. A proof should state up front how it works around barriers, and this alone makes its strategy easier to follow.</p>
<p>
The idea of barriers extends outside P versus NP, of course. Peter Scholze seems to be invoking it in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709&amp;cpage=1#comment-235940">comment</a> two months ago in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">post</a> by Peter Woit in April on the status of Shinichi Mochizuki’s claimed proof of the ABC conjecture:</p>
<blockquote><p><b> </b> <em> I may have not expressed this clearly enough in my manuscript with Stix, but there is just no way that anything like what Mochizuki does can work. … The reason it cannot work is a[nother] theorem of Mochizuki himself. … If the above claims [which are negated by the theorem] would have been true, I would see how Mochizuki’s strategy might have a nonzero chance of succeeding. … </em>
</p></blockquote>
<p/><p>
Thus what Ken and I conclude is that in order for a proof to be checkable <em>chunk by chunk</em>—not line by line—it needs to have:</p>
<ol>
<li>
A top-level decomposition into a relatively small number of components and stages—like legs in a sailing race—and <p/>
</li><li>
A demonstration of how the stages navigate around known barriers.
</li></ol>
<p>
Lack of a clear plan in the first already says the proof attempt cannot avoid being snagged on a barrier, as surely as natural laws prevent building a perpetual-motion machine.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in ascertaining what shape a proof that resolves the P versus NP problem must have?</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-14T01:33:31Z</updated>
    <published>2020-06-14T01:33:31Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="barriers"/>
    <category term="Leonardo da Vinci"/>
    <category term="perpetual motion"/>
    <category term="proof checking"/>
    <category term="shapes of proofs"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-17T21:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3504</id>
    <link href="https://agtb.wordpress.com/2020/06/14/submitting-papers-to-jet/" rel="alternate" type="text/html"/>
    <title>Suggestions for computer scientists submitting papers to JET</title>
    <summary>Guest post by Tilman Borgers (JET Lead Editor), Marciano Siniscalchi (JET Editor), and Jason Hartline (JET Associate Editor): The Journal of Economic Theory (JET) would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Guest post by <a href="http://www-personal.umich.edu/~tborgers/">Tilman Borgers</a> (JET Lead Editor), <a href="https://faculty.wcas.northwestern.edu/~msi661/">Marciano Siniscalchi</a> (JET Editor), and <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a> (JET Associate Editor):</i></p>
<p>The <a href="https://www.journals.elsevier.com/journal-of-economic-theory">Journal of Economic Theory (JET)</a> would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of topics than other theory journals. JET is also the first field journal of the economic theory community, having been founded more than 50 years ago. Many publications in JET in those 50 years have changed not just the direction of economic theory, but also the direction of economics overall.</p>
<p>The convergence of research interests of computer scientists and economic theorists has been a remarkable development, and JET would like to do more to help facilitate the exchange of ideas across fields. Therefore, we compile here some suggestions for computer scientists who are interested in submitting their work to JET.</p>
<p>The basic standard for a publication in JET is that the paper should be original, make a substantial contribution, and be of interest to a broad group of readers, and this group should include economic theorists. Of course, editors make subjective, and fallible, judgments when assessing whether a paper meets these criteria. Typically, the substantive contribution is a contribution to economic theory, i.e. to our understanding of models of markets, strategic games, mechanisms, etc. Papers may be computer-science centric in its contributions, but then these contributions should be on a topic of interest to economists. For example, new algorithmic results related to game theory or mechanism design may be of interest to JET, if it is the editors’ judgment that these algorithms will be of interest to economists. On the other hand, results on more applied computational problems, such as faster algorithms for winner determination in auctions, or for clearing prediction markets, may be out of scope for JET.</p>
<p>In terms of style, successful JET submissions include an introduction that is accessible to a broad theory audience, and that explains the motivation for the work, overviews the main results, and explains some key intuitions. The introduction, or a separate literature review section, should precisely situate the work relative to the most closely related research. The main body of the paper should explain the model rigorously, and state the results precisely. Proofs which are not very long, and which provide insight, are typically included in the main body of the paper, whereas other proofs are moved to an appendix. It is often useful to paraphrase results in words after stating them formally, and to give explanations of intuitions as well as explanations of proof structures. We encourage authors to make their work as simple as is possible without losing the main message.</p>
<p>There is no length limit per se, but published papers have rarely more than 40 pages, including appendix and references, in print. We value conciseness, and focus on a main theme throughout the paper. Minor results can be left out. On the other hand, we do provide authors with the space needed to be precise and clear.</p>
<p>One general recommendation for computer science authors in preparing manuscripts for economics journals is to have an economist colleague look over the paper before submitting.  This is a good way to identify inaccurate assumptions about readers’ knowledge, or omitted relationships to the prior literature in economics.  Such advice can also help better motivate the results of the paper from an economic perspective.</p>
<p>To be publishable, if an earlier version of a paper was published as an extended abstract in conference proceedings, then the journal version must make additional contributions beyond the conference version.  This additional contribution may include important conceptual aspects of economic interest that were omitted from the original extended abstract, proofs that were omitted from the extended abstract, and additional results that did not appear in the extended abstract. Authors should explain the differences between the conference version and the journal version in a cover letter. Papers that have previously appeared as one or two page abstracts in a conference volume do not need to distinguish themselves.  Mentioning these appearances in a cover letter would useful, however.</p></div>
    </content>
    <updated>2020-06-14T00:53:10Z</updated>
    <published>2020-06-14T00:53:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-17T21:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/theory-jobs-2020</id>
    <link href="http://grigory.github.io/blog/theory-jobs-2020/" rel="alternate" type="text/html"/>
    <title xml:lang="en">Theory Jobs 2020</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><p>It’s been an unusually challenging year for both sides of the TCS job market with some unexpected obstacles and delays. Apologies for putting up the spreadsheet later than usual and congrats to both sides in each converged process!</p>

<p><a href="https://docs.google.com/spreadsheets/d/1kzq4xVyU1k5CUTrV0yjIgzqlcv8agZqN_jiVlbYJb9g/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory jobs this year. 
I put in a biased pseudorandom seed, please help populate and share!
Rules for the spreadsheet have been copied from previous years (with one substantial suggestion regarding senior hires based on one of my friends’ recommendation, see below) and all edits to the document are anonymized. Please, post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>People should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are absolutely sure have been offered and accepted. This is not the place for speculation and rumors. <b>New:</b> Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
 <li>You are welcome to add yourself, or people your department has hired. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2020/">Theory Jobs 2020</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on June 14, 2020.</p></div>
    </content>
    <updated>2020-06-14T00:00:00Z</updated>
    <published>2020-06-14T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2020-06-15T04:23:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/" rel="alternate" type="text/html"/>
    <title>PhD Positions at International Max Planck Research School on Trustworthy Computing (apply by June 30, 2020)</title>
    <summary>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de">https://www.imprs-trust.mpg.de</a><br/>
Email: imprs@mpi-klsb.mpg.de</p></div>
    </content>
    <updated>2020-06-12T19:45:16Z</updated>
    <published>2020-06-12T19:45:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-17T21:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/</id>
    <link href="https://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <summary>July 6, 2020 Online http://lmw.mpi-sws.org/index.html The Logic Mentoring Workshop (LMW) will introduce young researchers to the technical and practical aspects of a career in logic research. It is targeted at students, from senior undergraduates to graduates, and will include talks and a panel session from leaders in the subject.</summary>
    <updated>2020-06-12T18:31:23Z</updated>
    <published>2020-06-12T18:31:23Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-06-17T21:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3496</id>
    <link href="https://agtb.wordpress.com/2020/06/12/virtual-ec-2020/" rel="alternate" type="text/html"/>
    <title>Virtual EC 2020</title>
    <summary>EC 2020 will be held virtually with events from June 15 to July 22 (details of virtual format).  Participation by members of related fields is strongly encouraged.   Since 1999 the ACM Special Interest Group on Economics and Computation (SIGecom) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>EC 2020 will be held virtually with events from June 15 to July 22 (<a href="http://ec20.sigecom.org/participation/covid/">details of virtual format</a>).  Participation by members of related fields is strongly encouraged.  </p>



<p>Since 1999 the ACM Special Interest Group on Economics and Computation (<a href="http://sigecom.org/">SIGecom</a>) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface of economics and computation. The 21st ACM Conference on Economics and Computation (<a href="http://ec20.sigecom.org/">Virtual EC 2020</a>) will feature invited speakers, a highlight of papers from other conferences and journals, a technical program of submitted paper presentations and posters, workshops, and tutorials.  </p>



<p>Registration is mandatory (<a href="http://ec20.sigecom.org/participation/registration/">register here</a>) but complimentary with SIGecom membership of $10 ($5 for students).  Details on joining EC events will be emailed to registered participants.</p>



<p>An overview of the schedule:</p>



<p><strong>June 15 – 19:</strong> <a href="http://ec20.sigecom.org/program/mentoring-workshop">Mentoring Workshop</a> and <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Live Tutorial Pre-recording Sessions</a>.<br/>
<strong>June 22 – July 3:</strong> <a href="http://ec20.sigecom.org/program/pre-recording/">Live EC Paper Pre-recording Plenary Sessions</a>.<br/>
<strong>July 13:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Tutorial Watch Parties</a>, Business Meeting, and <a href="http://ec20.sigecom.org/call-for-contributions-acm/posters/">Poster Session</a><br/>
<strong>July 14 – 16:</strong> <a href="http://ec20.sigecom.org/program/main/">EC Conference</a> (Paper Watch Parties, Paper Poster Sessions, and Plenaries).<br/>
<strong>July 17 – 22:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Workshops</a>.</p>



<p>Areas of interest include, but are not limited to:</p>



<p><strong>Design of economic mechanisms:</strong> algorithmic mechanism design; market design; matching; auctions; revenue maximization; pricing; fair division; computational social choice; privacy and ethics.</p>



<p><strong>Game theory:</strong> equilibrium computation; price of anarchy; learning in games.</p>



<p><strong>Information elicitation and generation:</strong> prediction markets; recommender, reputation and trust systems; social learning; data markets.</p>



<p><strong>Behavioral models:</strong> behavioral game theory and bounded rationality; decision theory; computational social science; agent-based modeling.</p>



<p><strong>Online systems:</strong> online advertising; electronic commerce; economics of cloud computing; social networks; crowdsourcing; ridesharing and transportation; labor markets; cryptocurrencies; industrial organization.</p>



<p><strong>Methodological developments:</strong> machine learning; econometrics; data mining.</p></div>
    </content>
    <updated>2020-06-12T16:09:54Z</updated>
    <published>2020-06-12T16:09:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-17T21:20:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=771</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/12/cifellows2020-in-theoretical-computer-science-and-computational-complexity-theory/" rel="alternate" type="text/html"/>
    <title>CIFellows2020 in Theoretical Computer Science and Computational Complexity Theory</title>
    <summary>This post is to advertise the CIFellow program 2020, and my availability. People who are looking for a postdoctoral position in theoretical computer science please consider getting in touch with me. The deadline for the application is in 5 days, and if possible complete part of it by today.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is to advertise the <a href="https://cifellows2020.org/">CIFellow program 2020</a>, and my availability.  People who are looking for a postdoctoral position in theoretical computer science please consider getting in touch with me.  The deadline for the application is in 5 days, and if possible complete part of it by today.</p></div>
    </content>
    <updated>2020-06-12T12:44:04Z</updated>
    <published>2020-06-12T12:44:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-06-17T21:21:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-06-12-optimal-optimistic-responsiveness/</id>
    <link href="https://decentralizedthoughts.github.io/2020-06-12-optimal-optimistic-responsiveness/" rel="alternate" type="text/html"/>
    <title>On the Optimality of Optimistic Responsiveness</title>
    <summary>Synchronous consensus protocols tolerating Byzantine failures depend on the maximum network delay $\Delta$ for their safety and progress. The delay, $\Delta$ is usually much larger than actual network delay $\delta$ since $\Delta$ is a pessimistic value. While synchronous protocols tolerating more than one-third will have executions with at least a...</summary>
    <updated>2020-06-12T08:10:00Z</updated>
    <published>2020-06-12T08:10:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-06-17T05:25:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4845</id>
    <link href="https://www.scottaaronson.com/blog/?p=4845" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4845#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4845" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Book Review: “Will He Go?”</title>
    <summary xml:lang="en-US">Will He Go?, by legal scholar Lawrence Douglas, is, at 120 pages, a slim volume focused on a single question: what happens if the 2020 US election delivers a narrow or disputed result favoring Biden, and Trump refuses to concede? This question will, of course, either be answered or rendered irrelevant in half a year. […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.amazon.com/Will-He-Go-Election-Meltdown/dp/1538751887">Will He Go?</a>, by legal scholar Lawrence Douglas, is, at 120 pages, a slim volume focused on a single question: <em>what happens if the 2020 US election delivers a narrow or disputed result favoring Biden, and Trump refuses to concede?</em>  This question will, of course, either be answered or rendered irrelevant in half a year.  And yet, in my estimation, there’s at least a 15% probability that <em>Will He Go?</em> will enter the ranks of the most important and prescient books ever written.  You should read it right now (or at least read <a href="https://www.vox.com/policy-and-politics/2020/6/3/21257133/trump-2020-election-meltdown-lawrence-douglas">this Vox interview</a>), if you want to think through the contours of a civilizational Singularity that seems at least as plausible to me as the AI Singularity, but whose fixed date of November 3, 2020 we’re now hurtling toward.</p>



<p>In one of the defining memes of the past few years, a sign in a bookstore reads “Dear customers: post-apocalyptic fiction has been moved to the Current Affairs section.”  I was reminded of that as Douglas dryly lays out his horror scenario: imagine, hypothetically, that a President of the United States gets elected on a platform of racism and lies, with welcomed assistance from a foreign adversary.  Suppose that his every outrage only endears him further to his millions of followers.  Suppose that, as this president’s deepest (and perhaps only) principle, he never backs down, never apologizes, never acknowledges any inconvenient fact, and never accepts the legitimacy of any contest that he loses—and <em>this is perfectly rational for him, </em>as he’s been richly rewarded for this strategy his entire life.  Suppose that, during the final presidential debate, he pointedly refuses to promise to respect the election outcome if he loses—a first in American history.  And suppose that, after eking out a narrow win in the Electoral College, he then turns around and <em>disputes the election anyway</em> (!)—claiming, ludicrously, that he would’ve won the popular vote too, if not for millions of fraudulent voters.  Suppose that, for their own sordid reasons, Republican majorities in the Senate and Supreme Court enable this president’s chaotic rule, block his impeachment, and acquiesce to his daily cruelties and lies.</p>



<p>Then what happens in the <em>next</em> election?</p>



<p>Taking the existing catastrophe as given, Douglas asks: is America’s Constitutional machinery up to a challenge that it’s never yet faced, of a president who accepts democracy itself as legitimate only when he wins?  Douglas concludes that it isn’t—and this is the book’s terrifying and non-obvious part.  There are no checks or balances in the Constitution that will magically ensure a smooth transition of power.  On the contrary, the design flaws of our antiquated system make a meltdown <em>more</em> likely.</p>



<p>OK, but then why hasn’t America’s Reactor of Democracy exploded yet (or at least, not since the Civil War)?  Douglas spends a lot of time on historical parallels, including the Tilden-Hayes election of 1876 and the Bush-Gore election of 2000.  In each case, he finds, collapse was averted not because of mythical safeguards in our rickety, Rube-Goldberg system, but <em>only</em> because the relevant people (e.g., Samuel Tilden, Al Gore) stood down, having internalized the norm that the national good required them to.  But that’s precisely what Trump has telegraphed that he’ll never do.</p>



<p>The class of scenario that most worries Douglas runs as follows: just like last time, the election comes down to a few swing states, such as Pennsylvania, Wisconsin, and Michigan.  Crucially, right now all three of those states have Democratic governors and Republican-controlled legislatures … and <em>there’s no clear law about which of the two (the governor or the legislature) gets to certify election results and send them to Congress!</em>  So suppose Trump has a slight edge on election night, Fox News calls the race for him, but then an avalanche of absentee or provisional ballots shift things in Biden’s favor over the following week.  Can you imagine Trump or his supporters accepting the latter?</p>



<p>Or suppose that, on election day, Russian hackers cut off electricity or voter registration databases in Philadelphia or Detroit, via computer systems that <em>we know they already broke into and that remain exposed (!)</em>.  Hundreds of thousands are unable to vote; the Democratic governor orders a revote; the Republican legislature tries to preempt that by sending the original tally to Congress.</p>



<p>The final authority over election results rests with Congress.  The trouble is, the Senate is currently under Republican control and the House under Democratic control—and once again, <em>the Constitution and federal law provide no clear guidance on how to resolve a deadlock between the two on presidential succession (!!)</em>.  So what if Michigan or Pennsylvania or Wisconsin sends two separate sets of election results, and (predictably) the House accepts one and the Senate accepts the other?  And what if there’s no resolution by noon EST on January 20, 2021?  Then by law, the Speaker of the House, currently Nancy Pelosi, becomes acting president.  Can you imagine Trump willingly vacating the Oval Office if that comes to pass?</p>



<p>Douglas seems to have finished writing <em>Will He Go?</em> just as the coronavirus shut down the planet; he includes some comments about how that will massively exacerbate the above problems.  Election officials expect a historic number of absentee ballots, from people—disproportionately urban—who will (reasonably) consider it unsafe to wait in line for hours in a room packed with hundreds of strangers.  Alas, Trump has already told his followers that voting by mail is a scam to be fiercely opposed, never mind that he uses it himself.  Worse yet, the laws governing mail-in ballots—the signature, the postmark, the deadline for receipt—are byzantine, open to interpretation, and wildly different from county to county.  So again: imagine if mail-in ballots overturn what looked like a Trump win on election night.  The 2000 Florida recount battle was tea and cookies by comparison.</p>



<p>Douglas doesn’t mention, because it happened too recently, the nationwide Black Lives Matter protests (and in rarer cases, vandalism and looting) set off by the horrific murder of George Floyd, and the often shockingly militarized response.  But assuming the protests continue through the fall, they’ll of course give the Trumpists even more pretexts to meddle with the election, in the name of imposing “order.”</p>



<p>This is not a sound statistical methodology, but if I imagine a <em>gong</em> every time the US inches perceptibly closer to collapse—<em>gong</em> when Trump got elected, <em>gong</em> when covid made landfall and the states were abandoned to fight each other over medical supplies, <em>gong</em> when George Floyd was murdered and staid, conformist liberals suddenly became anarchists demanding the complete abolition of all police—well, the <em>gong</em>s seem to be getting more frequent!  Almost as if they were building toward a <em>gong</em>ularity that was, I dunno, sometime around November!</p>



<p>Douglas never mentions the prospect of a second Civil War until literally the book’s last sentence, but it’s the undercurrent of everything he writes—particularly given Trump’s frequent glorifications of violence, and his heavily armed base.  Having spent his career studying American jurisprudence, Douglas is willing to guide our imaginations all the way to the precipice but not over it.  Part of me still finds the possibility of going over unthinkable—although wasn’t the <em>first</em> Civil War similarly unthinkable until shortly before it happened?</p>



<p>If there <em>is</em> to be a Chernobyl-like meltdown of the Founding Fathers’ machine, at least it would retrospectively make sense of a lot that’s confused me in the past few years.  As I’m far from the only one to notice, “my” side, the left, has seemed less and less interested in debate and discussion, and more and more eager to denounce, ban, shame, and no-platform.  As just one example, out of hundreds that would serve, last week a 28-year-old analyst named David Shor was <a href="https://nymag.com/intelligencer/2020/06/case-for-liberalism-tom-cotton-new-york-times-james-bennet.html">fired from his job</a> for <em>politely tweeting about an <a href="http://omarwasow.com/APSR_protests3_1.pdf">academic paper</a> offering evidence that peaceful protests are effective at winning public support for progressive, antiracist causes, while violence is ineffective</em>.  Hopefully <em>I</em> won’t now be fired for mentioning this!</p>



<p>Of course every cause has its extremists, but the puzzle is that I <em>know</em> plenty of people who will eagerly join whatever is the shaming or firing campaign du jour.  And many of those people strike me as friendly, insightful, honest, balanced, wise—at least when the topic is apolitical, as (alas) less and less seems to be these days.</p>



<p>Thought experiment: two protesters meet on a street, carrying huge signs that say “BLACK LIVES MATTER” and “ALL LIVES MATTER” respectively.  Can you imagine the following conversation ensuing: “Ah, my good fellow, it looks like you and I are allies, sharing deeply compatible moral messages with the world … one of us merely focused more on a special case, and the other on its generalization!  Shall we sit in the park to discuss our joint strategy?”</p>



<p>I guess it takes an Aspbergery STEM nerd even to <em>ask</em> why that never happens.  To spell it out: both sides are deploying English words, not for what they explicitly assert, but as markers of tribal affiliation, of <em>which side they’re on</em>.</p>



<p>It’s much the same with “Believe Women.”  “Believe <em>all</em> women, <em>always</em>?” asks our hapless STEM nerd.  “Women are goddesses who never lie?  Feminism is no longer the radical notion that women are people?”  “No, you sexist asshat,” replies the normie.  “It means listen to women, empathize with women, believe women, be on their side, be on <em>our</em> side.  What about that is so f-ing hard to understand?”</p>



<p>Or consider the slogans now conquering the world: “abolish the police” and “defund the police.”  “You mean <em>fundamentally reform</em> the police, right?” asks the STEM nerd.  “Eliminate qualified immunity, bust the unions that protect abusive cops, get rid of military gear, provide de-escalation training, stop treating homelessness and drug abuse as law enforcement problems, and all those other no-brainers?  But not, like, literally end all law enforcement, leave the 911 calls unanswered as machete-wielding rapists run free, and let gangsters and warlords fill the vacuum?”</p>



<p>“No, abolish the police means <em>abolish the police</em>,” reply the activists sternly.  “You refuse to listen.  You’re not our ally.”</p>



<p>Imagine a ragtag guerilla army encamped in the jungle, surrounded by a brutal occupying force and facing impossible odds, constantly on the alert for turncoats and spies and fair-weather friends in its midst.  Would it surprise you if these guerillas had a macabre initiation ritual for new recruits: say, slicing off the tips of recruits’ fingers?</p>



<p>Now suppose you reckoned that truth and justice were at least 3/4 on the guerillas’ side, and so decided to join them.  At your initiation, would you ask the guerillas if they’d analyzed whether finger-slicing <em>actually</em> leads to greater effectiveness in battle?  Or, as you swore the oath of eternal allegiance to the cause, with one hand on your heart and the other on your Kalashnikov, would you add: “… <em>assuming</em> that we continue to represent Enlightenment values like science, free speech, and intellectual charity”?</p>



<p>When the Nazis invaded the Soviet Union in 1941, it suddenly became reasonable to take the side of the bloodthirsty Stalin.  And it would’ve been <em>praiseworthy</em> for a Russian to say: “I now pledge my life to fighting for the Soviet government—even if, likely as not, that government will thank me afterward by sending me to the gulag for an invented crime.”</p>



<p>Five years ago, thousands of woke activists shamed me for writing about my teenage experiences on this blog, a few even calling for an end to my career.  Especially if those activists emerge victorious from a turbulent 2020—<em>as I hope they will</em>—I expect that they’ll come for me again.  (Well, if they get around to it.  I’m nowhere near the top of their list.)</p>



<p>And yet, if Lawrence Douglas’s scenario comes to pass—if, for example, the 2020 election leaves Trump barricaded in the White House with his loyalists, while a duly elected government waits in limbo—then I pledge to render whatever assistance I can, and even risk my life if needed, for the same side that the woke activists will be on.</p>



<p>I’d rather not, though.  As Douglas points out, the more overwhelming we can make Trump’s electoral defeat, the less chance that it ever comes to this.</p></div>
    </content>
    <updated>2020-06-11T21:41:10Z</updated>
    <published>2020-06-11T21:41:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-12T02:14:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/10/postdoc-at-technion-apply-by-september-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/10/postdoc-at-technion-apply-by-september-30-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion (apply by September 30, 2020)</title>
    <summary>Postdoctoral positions in distributed computing are available in the research group of Keren Censor-Hillel at the Technion. Candidates with a strong publication record in closely related areas are welcome to apply (deadline is flexible). To apply, send to Mrs. Hila Mizrahi: (1) a CV, (2) a 1-2 page research statement, (3) the contact details of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Postdoctoral positions in distributed computing are available in the research group of Keren Censor-Hillel at the Technion. Candidates with a strong publication record in closely related areas are welcome to apply (deadline is flexible). To apply, send to Mrs. Hila Mizrahi: (1) a CV, (2) a 1-2 page research statement, (3) the contact details of 3 references, and (4) an expected graduation date.</p>
<p>Website: <a href="https://ckeren.net.technion.ac.il/">https://ckeren.net.technion.ac.il/</a><br/>
Email: hilamiz@cs.technion.ac.il</p></div>
    </content>
    <updated>2020-06-10T12:22:37Z</updated>
    <published>2020-06-10T12:22:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-17T21:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/090" rel="alternate" type="text/html"/>
    <title>TR20-090 |  Tight Quantum Time-Space Tradeoffs for Function Inversion | 

	Kai-Min Chung, 

	Siyao  Guo, 

	Qipeng Liu, 

	Luowen Qian</title>
    <summary>In function inversion, we are given a function $f: [N] \mapsto [N]$, and want to prepare some advice of size $S$, such that we can efficiently invert any image in time $T$. This is a well studied problem with profound connections to cryptography, data structures, communication complexity, and circuit lower bounds. Investigation of this problem in the quantum setting was initiated by Nayebi, Aaronson, Belovs, and Trevisan (2015), who proved a lower bound of $ST^2 = \tilde\Omega(N)$ for random permutations against classical advice, leaving open an intriguing possibility that Grover's search can be sped up to time $\tilde O(\sqrt{N/S})$. Recent works by Hhan, Xagawa, and Yamakawa (2019), and Chung, Liao, and Qian (2019) extended the argument for random functions and quantum advice, but the lower bound remains $ST^2 = \tilde\Omega(N)$. 

In this work, we prove that even with quantum advice, $ST + T^2 = \tilde\Omega(N)$ is required for an algorithm to invert random functions. This demonstrates that Grover's search is optimal for $S = \tilde O(\sqrt{N})$, ruling out any substantial speed-up for Grover's search even with quantum advice. Further improvements to our bounds would imply a breakthrough in circuit lower bounds, as shown by Corrigan-Gibbs and Kogan (2019).

To prove this result, we develop a general framework for establishing quantum time-space lower bounds. We further demonstrate the power of our framework by proving the following results. 

* Yao's box problem: We prove a tight quantum time-space lower bound for classical advice. For quantum advice, we prove a first time-space lower bound using shadow tomography. These results resolve two open problems posted by Nayebi, Aaronson, Belovs, and Trevisan (2015). 

* Salted cryptography: We show that “salting generically provably defeats preprocessing,” a result shown by Coretti, Dodis, Guo, and Steinberger (2018), also holds in the quantum setting. In particular, we prove quantum time-space lower bounds for a wide class of salted cryptographic primitives in the quantum random oracle model. This yields a first quantum time-space lower bound for salted collision-finding, which in turn implies that ${PWPP}^{O} \not\subseteq {FBQP}^{O}{/qpoly}$ relative to a random oracle $O$.</summary>
    <updated>2020-06-10T06:43:41Z</updated>
    <published>2020-06-10T06:43:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/089</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/089" rel="alternate" type="text/html"/>
    <title>TR20-089 |  Lower Bounds on  the Time/Memory Tradeoff of Function Inversion | 

	Dror Chawin, 

	Iftach Haitner, 

	Noam Mazor</title>
    <summary>We study time/memory tradeoffs of function inversion: an algorithm, i.e., an inverter, equipped with an $s$-bit advice for a randomly chosen function $f\colon [n] \mapsto [n]$ and using $q$ oracle queries to $f$, tries to invert a randomly chosen output $y$ of $f$ (i.e., to find $x$ such that $f(x)=y$). Much progress was done regarding adaptive function inversion - the inverter is allowed to make adaptive oracle queries. Hellman [IEEE transactions on Information Theory '80] presented an adaptive inverter that inverts with high probability a random $f$. Fiat and Naor [SICOMP '00] proved that for any $s,q$ with $s^2 q = n^2$ (ignoring low-order terms), an $s$-advice, $q$-query variant of Hellman's algorithm inverts a constant fraction of the image points of any function. Yao [STOC '90] proved a lower bound of $sq\ge n$ for  this problem. Closing the gap between the above lower and upper bounds is a long-standing open question.

Very little is known for the non-adaptive variant of the question - the inverter chooses its queries in advance. The only known upper bounds, i.e., inverters, are the trivial ones (with $s+q= n$), and the only lower bound is the above bound of Yao. In a recent work, Corrigan-Gibbs and Kogan [TCC '19] partially justified the difficulty of finding lower bounds on non-adaptive inverters, showing that a lower bound on the time/memory tradeoff of non-adaptive inverters implies a lower bound on low-depth Boolean circuits. Bounds that for a strong enough choice of parameters, are notoriously hard to prove.

We make progress on the above intriguing question, both for the adaptive and the non-adaptive case, proving the following lower bounds on restricted families of inverters:

	- Linear-advice (adaptive inverter): If the advice string is a linear function of $f$ (e.g., $A\times f$, viewing $f$ as  a vector in $[n]^n$), then $s+q \in \Omega(n)$.
	
	- Affine non-adaptive decoders: If the non-adaptive inverter has an affine decoder - it outputs a linear function, determined by the advice string and the element to invert, of the query answers - then $s \in \Omega(n)$ (regardless of $q$).
	
	- Affine non-adaptive decision trees: If the non-adaptive inversion algorithm is a $d$-depth affine decision tree - it outputs the evaluation of a decision tree whose nodes compute a linear function of the answers to the queries - and $q \le cn$ for some universal $c&gt;0$, then $s\in \Omega(n/d \log n)$.</summary>
    <updated>2020-06-09T13:19:02Z</updated>
    <published>2020-06-09T13:19:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/088</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/088" rel="alternate" type="text/html"/>
    <title>TR20-088 |  Eliminating Intermediate Measurements in Space-Bounded Quantum Computation | 

	Bill Fefferman, 

	Zachary Remscrim</title>
    <summary>A foundational result in the theory of quantum computation known as the ``principle of safe storage'' shows that it is always possible to take a quantum circuit and produce an equivalent circuit that makes all measurements at the end of the computation.  While this procedure is time efficient, meaning that it does not introduce a large overhead in the number of gates, it uses extra ancillary qubits and so is not generally space efficient.  It is quite natural to ask whether it is possible to defer measurements to the end of a quantum computation without increasing the number of ancillary qubits.
		
		We give an affirmative answer to this question by exhibiting a procedure to eliminate all intermediate measurements that is simultaneously space-efficient and time-efficient. A key component of our approach, which may be of independent interest, involves showing that the well-conditioned versions of many standard linear-algebraic problems may be solved by a quantum computer in less space than seems possible by a classical computer.</summary>
    <updated>2020-06-08T21:24:06Z</updated>
    <published>2020-06-08T21:24:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/087</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/087" rel="alternate" type="text/html"/>
    <title>TR20-087 |  Quantum Logspace Algorithm for Powering Matrices with Bounded Norm | 

	Uma Girish, 

	Ran Raz, 

	Wei Zhan</title>
    <summary>We give a quantum logspace algorithm for powering contraction matrices, that is, matrices with spectral norm at most 1. The algorithm gets as an input an arbitrary $n\times n$ contraction matrix $A$, and a parameter $T \leq poly(n)$ and outputs the entries of $A^T$, up to (arbitrary) polynomially small additive error. The algorithm applies only unitary operators, without intermediate measurements. We show various implications and applications of this result:

First, we use this algorithm to show that the class of quantum logspace algorithms with only quantum memory and with intermediate measurements is equivalent to the class of quantum logspace algorithms with only quantum memory without intermediate measurements. This shows that the deferred-measurement principle, a fundamental principle of quantum computing, applies also for quantum logspace algorithms (without classical memory). More generally, we give a quantum algorithm with space $O(S + \log T)$ that takes as an input the description of a quantum algorithm with quantum space $S$ and time $T$, with intermediate measurements (without classical memory), and simulates it unitarily with polynomially small error, without intermediate measurements.

Since unitary transformations are reversible (while measurements are irreversible) an interesting aspect of this result is that it shows that any quantum logspace algorithm (without classical memory) can be simulated by a reversible quantum logspace algorithm. This proves a quantum analogue of the result of Lange, McKenzie and Tapp that deterministic logspace is equal to reversible logspace.

Finally, we use our results to show non-trivial classical simulations of quantum logspace learning algorithms.</summary>
    <updated>2020-06-08T18:51:13Z</updated>
    <published>2020-06-08T18:51:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-17T21:20:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9046421052819875987</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9046421052819875987/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9046421052819875987" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9046421052819875987" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html" rel="alternate" type="text/html"/>
    <title>The Committee for the Adv. of TCS- workshop coming up SOON!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"/><br/>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><span>(Posted by request from Jelani Nelson.)</span></span></div>
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The Committee for the Advancement of Theoretical Computer Science (CATCS)</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>is organizing a Visioning workshop.  The primary objective of the workshop</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>is for TCS participants to brainstorm directions and talking points for TCS</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>program managers at funding agencies to advocate for theory funding.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>There was some question of whether or not it would run this summer, but</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>YES, it is going to run.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>If you are interested then reply (at the link below) by June 15.</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>This is SOON so click that link SOON.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The time commitment is 4-5 hours during the week of July 20-July 24 for</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>most participants, or roughly 10 hours for those who are willing to</span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>volunteer to be group leaders.</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span>The link to sign up is:</span></div>
<br/><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<span><a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/</a></span></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<br/></div>
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;">
<br/></div>
</span></div>
    </content>
    <updated>2020-06-08T15:03:00Z</updated>
    <published>2020-06-08T15:03:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-17T15:54:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4392</id>
    <link href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/" rel="alternate" type="text/html"/>
    <title>“Visioning” workshop call for participation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In 2008, the Committee for the Advancement of Theoretical Computer Science convened a workshop to brainstorm directions and talking points for TCS program managers at funding agencies to advocate for theory funding. The event was quite productive and successful. A … <a href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 2008, the <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science</a> convened a workshop to brainstorm directions and talking points for TCS<br/>
program managers at funding agencies to advocate for theory funding. The event was quite productive and successful. </p>
<p>A second such workshop is going to be held, online, in the third week of July. Applications to participate are due on June 15, a week from today. Organizers expect that participants will have to devote about four hours of their time to the workshop, and those who volunteer to be team leads will have a time commitment of about ten hours.</p>
<p>More information <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">at this link</a></p></div>
    </content>
    <updated>2020-06-08T09:38:07Z</updated>
    <published>2020-06-08T09:38:07Z</published>
    <category term="theory"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-06-17T21:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1343</id>
    <link href="https://ptreview.sublinear.info/?p=1343" rel="alternate" type="text/html"/>
    <title>Welcome Akash Kumar!</title>
    <summary>Let’s welcome our latest editor, Akash Kumar. Akash will be taking the place of Gautam Kamath, who has decided to pass the torch on. Let’s also thank Gautam for all the help with PTReview.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let’s welcome our latest editor, Akash Kumar. Akash will be taking the place of Gautam Kamath, who has decided to pass the torch on. Let’s also thank Gautam for all the help with PTReview.</p></div>
    </content>
    <updated>2020-06-08T03:29:36Z</updated>
    <published>2020-06-08T03:29:36Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-06-17T05:24:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1315</id>
    <link href="https://ptreview.sublinear.info/?p=1315" rel="alternate" type="text/html"/>
    <title>News for May 2020</title>
    <summary>Last month saw activity across a diverse collection of topics in sublinear algorithms. In particular, we had the following five six papers. (Sorry, I missed one) One-Sided Error Testing of Monomials and Affine Subspaces by Oded Goldreich and Dana Ron (ECCC). This work focuses on one-sided testing of two kinds of problems (and their variants): […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last month saw activity across a diverse collection of topics in sublinear algorithms. In particular, we had the following <s>five</s> six papers. <em>(Sorry, I missed one)</em> </p>



<p><strong>One-Sided Error Testing of Monomials and Affine Subspaces</strong> by Oded Goldreich and Dana Ron (<a href="https://eccc.weizmann.ac.il/report/2020/068/">ECCC</a>). This work focuses on one-sided testing of two kinds of problems (and their variants): <br/><span class="has-inline-color has-blue-color">1.</span> Testing Monomials: Suppose you are given a function \(f \colon \{0,1\}^n \to \{0,1\}\). Is \(f = \wedge_{i \in I} x_i\) (that is, is \(f\) a monotone monomial). <br/><span class="has-inline-color has-blue-color">2.</span> Testing Affine Subspaces: Consider the task of testing whether a \(f \colon \mathcal{F}^n \to \{0,1\}\) is the indicator of an \((n-k)\)-dimensional affine space for some \(k\) (where \(\mathcal{F}\) is a finite field).<br/></p>



<p>The paper shows that the general problem — the one in which the arity of the monomial (resp the co-dimension of the subspace) is not specified has one-sided query complexity \(\widetilde{O}(1/\varepsilon)\). The same holds for testing whether the arity of the monomial is at most \(k\) (resp the co-dimension of the subspace is at most \(k\)). Finally, the exact problem which seeks to test whether the arity of the monomial is exactly \(k\) (resp the co-dimension of the space is exactly \(k\)) has query complexity \(\Omega(\log n)\). For two sided testers however, size oblivious testers are known for this problem. Thus, like the authors remark, two-sided error is inherent in the case of the exact version of the problem.</p>



<p/>



<p><strong>Sampling Arbitrary Subgraphs Exactly Uniformly in Sublinear Time</strong> by Hendrik Fichtenberger, Mingze Gao, Pan Peng (<a href="https://arxiv.org/abs/2005.01861v2">arXiv</a>). Readers of PT Review are no strangers to the problem of counting cliques in sublinear time (with a certain query model). Building on tools from [1], in [2], Eden-Ron-Seshadhri gave the first algorithms for counting number of copies \(K_r\) in a graph \(G\) to within a \((1 \pm \varepsilon)\) multiplicative factor. En route to this result, they also gave a procedure to sample cliques incident to some special set \(S \subseteq V(G)\). The query model in [2] allowed the following queries: a u.a.r vertex query, degree query, \(i^{th}\) neighbor query and a pair query which answers whether a pair \((u,v)\) forms an edge. The work under consideration shows a result which I personally find remarkable: given the additional ability to get a u.a.r edge sample, we can do the following. For any graph \(H\) we can obtain a uniformly random subgraph isomorphic to \(H\) in \(G\). Let that sink in: this work shows that you can sample \(H\) <em>exactly uniformly</em> from the graph \(G\).  </p>



<p><strong>Finding Planted Cliques in Sublinear Time</strong> by Jay Mardia, Hilal Asi, Kabir Aladin Chandrasekher (<a href="https://arxiv.org/abs/2004.12002">arXiv</a>). Planted Clique is a time honored problem in average case complexity. This classic problem asks the following: You are given a \(G \sim \mathcal{G}(n, 1/2)\). Suppose I select a subset of \(k\) vertices in this graph and put a clique on the subgraph they induce. In principle it is possible to recover the clique I planted if \(k &gt; (2 + \varepsilon) \log n\). But it seems you get polynomial time algorithms only when \(k \geq \Omega(\sqrt n)\) even after you throw SDPs at the problem. Moreover, so far, the algorithms which recover the planted \(k\)-clique were known to take \(\widetilde{O}(n^2)\) time. This work shows that you actually get algorithms which take time \(\widetilde{O}(n^{3/2})\) if \(k \geq \Omega(\sqrt{n \log n})\). The key idea is to first obtain a “core” part of the clique of size \(O(\log n)\) in time \(\widetilde{O}(n^2/k)\). This is followed up with a clique completion routine where you mark all vertices connected to the entire core as being potentially in the clique. The paper also shows a conditional lower bound result which shows that given query access to adjacency matrix of the graph, a natural family of non-adaptive algorithms cannot recover a planted \(k\) clique in time \(o\left(\frac{n}{k}\right)^3\) (for \(k \geq \widetilde{\Omega}(\sqrt n))\).</p>



<p><strong>A robust multi-dimensional sparse Fourier transform in the continuous setting</strong> by Yaonan Jin, Daogao Liu and Zhao Song (<a href="https://arxiv.org/abs/2005.06156">arXiv</a>).  Suppose you are given an unknown signal whose Fourier Spectrum is k-sparse (that is, there are at most k dominant Fourier Coefficients and all the others are zero or close to zero). Significant research effort has been devoted to learn these signals leading to works which study this problem for multi-dimensional discrete setting and in the one-dimensional continuous case. The \(d\)-dimensional continuous case \((d = \Theta(1))\) was largely unexplored. This work makes progress on this frontier by making some natural assumptions on the unknown signal. In particular, the paper assumes that the frequencies — which are vectors \(f_i’s \in R^d\) — are well separated and satisfy \(\|f_i – f_j\|_2 \leq \eta\) and that all \({f_i}_{i \in [k]} \subseteq [-F, F]^d\) sit inside a bounded box.<br/>The authors assume sample access to the signal in the sense that at any desired timestep \(\tau\), the algorithm can sample the signal’s value. With this setup, the authors show that all the dominant frequencies can be recovered with a \(O_d(k \cdot \log(F/\eta))\) samples by considering a relatively small time horizon.</p>



<p><strong>Extrapolating the profile of a finite population</strong> by Soham Jana, Yury Polyanskiy, Yihong Wu (<a href="https://arxiv.org/abs/2005.10561">arXiv</a>). Consider the following setup. You are given a universe \(k\) balls. Ball come in up to \(k\) different colors. Say you \(\theta_j\) balls in color \(j\) for each \(j \in [k]\). One of the fundamental problems in statistics considers taking samples \(m\) balls from the universe and attempts estimating “population profile” (that is, the number of balls in each color). Historically, it is known that unless an overwhelming majority of the universe has been seen, one cannot estimate the empirical distribution of colors. This paper shows that in the sublinear regime, with \(m \geq \omega(k/\log k)\), it is possible to consistently estimate the population profile in total variation. And once you have a handle on the empirical distribution of the population, you can go ahead and learn lots of interesting label invariant properties of your universe (things like entropy, number of distinct elements etc). </p>



<p/>



<p><em>(Edit added later)</em></p>



<p><strong>Testing Positive Semi-Definiteness via Random Submatrices</strong> by Ainesh Bakshi, Nadiia Chepurko, Rajesh Jayaram (<a href="https://arxiv.org/abs/2005.06441">arXiv</a>). Suppose I give you a PSD matrix \(A \in R^{n \times n}\). You know that all of its principle submatrices are also PSD. What if \(A\) was \(\varepsilon\)-far from the PSD cone (in a sense I will define soon)? What can you say about the eigenvalues of principle submatrices of \(A\) now? In this paper, the authors tackle precisely this question. The paper defines a matrix \(A\) to be \(\varepsilon\)-far in \(\ell_2^2\) distance from the PSD Cone if you have that \(\min_{B \geq 0: B \in R^{n \times n}}\|A – B\|_F^2 \geq \varepsilon n^2\). You are allowed to randomly sample a bunch of principle submatrices (of order roughly \(O(1/\varepsilon)\) by \(O(1/\varepsilon)\) and check if they are PSD. Armed with this setup, the paper gives a non-adaptive one sided tester for this problem which makes \(\widetilde{O}(1/\varepsilon^4)\) queries. The paper also supplements this result with a lower bound of \(\widetilde{\Omega}(1/\varepsilon^2)\) queries.</p>



<p>If I missed something, please let me know. This is my first post on PT Review and I might have botched up a few things.</p>



<p><strong>References</strong></p>



<p>[1] Talya Eden, Amit Levi, Dana Ron and C. Seshadhri. Approximately Counting Triangles in Sublinear Time. <em>56th Annual Symposium on Foundations of Computer Science, 2015</em></p>



<p>[2] Talya Eden, Dana Ron and C. Seshadhri. On approximating the number of k-cliques in sublinear time. Proceedings of the <em>50th Annual ACM SIGACT Symposium on Theory of Computing 2018</em>.</p></div>
    </content>
    <updated>2020-06-07T22:22:58Z</updated>
    <published>2020-06-07T22:22:58Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>akumar</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-06-17T05:24:58Z</updated>
    </source>
  </entry>
</feed>
