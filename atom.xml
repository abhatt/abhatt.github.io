<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-07-07T08:38:48Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/095" rel="alternate" type="text/html"/>
    <title>TR22-095 |  Efficient Interactive Coding Achieving Optimal Error Resilience Over the Binary Channel | 

	Meghal Gupta, 

	Rachel Zhang</title>
    <summary>Given a noiseless protocol $\pi_0$ computing a function $f(x, y)$ of Alice and Bob's private inputs $x, y$, the goal of interactive coding is to construct an error-resilient protocol $\pi$ computing $f$ such that even if some fraction of the communication is adversarially corrupted, both parties still learn $f(x, y)$. Ideally, the resulting scheme $\pi$ should be positive rate, computationally efficient, and achieve optimal error resilience.

While interactive coding over large alphabets is well understood, the situation over the binary alphabet has remained evasive. At the present moment, the known schemes over the binary alphabet that achieve a higher error resilience than a trivial adaptation of large alphabet schemes are either still suboptimally error resilient [EKS20], or optimally error resilient with exponential communication complexity [GZ22]. In this work, we construct a scheme achieving optimality in all three parameters: our protocol is positive rate, computationally efficient, and resilient to the optimal $\frac16 - \epsilon$ adversarial errors.

Our protocol employs a new type of code that we call a layered code, which may be of independent interest. Like a tree code, a layered code allows the coder to encode a message in an online fashion, but is defined on a graph instead of a tree.</summary>
    <updated>2022-07-06T18:28:14Z</updated>
    <published>2022-07-06T18:28:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22946</id>
    <link href="https://gilkalai.wordpress.com/2022/07/06/icm-2022-awarding-ceremonies-1/" rel="alternate" type="text/html"/>
    <title>ICM 2022 awarding ceremonies (1)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hugo Duminil-Copin, June Huh, James Maynard and Maryna Viazovska were awarded the Fields Medal 2022 and Mark Braverman was awarded the Abacus Prize 2022. I am writing from Helsinki where I attended the meeting of the General Assembly of the … <a href="https://gilkalai.wordpress.com/2022/07/06/icm-2022-awarding-ceremonies-1/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2><img alt="fm2022" class="alignnone size-full wp-image-22983" src="https://gilkalai.files.wordpress.com/2022/07/fm2022.png?w=640"/></h2>
<h2>Hugo Duminil-Copin, June Huh, James Maynard and Maryna Viazovska were awarded the Fields Medal 2022 and Mark Braverman was awarded the Abacus Prize 2022.</h2>
<p>I am writing from Helsinki where I attended the meeting of the General Assembly of the IMU and yesterday I took part in the moving award ceremonies of ICM2022 hosted by Aalto University.  This will be a first post about the ICM 2020 award ceremonies.</p>
<p>The opening day of ICM2022 was exciting. Hugo Duminil-Copin, June Huh, James Maynard and Maryna Viazovska were awarded the Fields Medals 2022. Mark Braverman was awarded the Abacus Prize. The event <a href="https://youtu.be/6I0siVD7RBI">was videotaped and can be found here</a>.</p>
<p>In the ceremony, I gave the laudation for June Huh.  Here are <a href="https://gilkalai.files.wordpress.com/2022/07/jhicm2022.pptx">the slides of my talk.</a> The preliminary version of my proceeding paper is <a href="https://www.mathunion.org/fileadmin/IMU/Prizes/Fields/2022/laudatio-jh.pdf">here on the IMU site</a>. Please alert me about mistakes in my paper or suggestion for changes or additions. (I already found that on two occasions I embarrassingly wrote “Brändén” Instead of “Braden”, sorry for that.)</p>
<p><a href="https://www.mathunion.org/imu-awards/fields-medal/fields-medals-2022">The IMU site</a> contains a lot of material about the Fields medalist and other prize winners. It contains beautiful videos, and preliminary versions of the proceeding papers by the medalists and by those giving the laudations.</p>
<p>Andrei Okounkov wrote four wonderful detailed “popular scientific expositions” (those are available in the IMU site) which give much scientific background as well as Andrei’s own scientific perspective. It is a great read for wide audience of mathematicians, ranging from  advanced undergraduate students.  Experts will also enjoy Andrei’s perspective. (I think that Andrei may write a fifth piece on Braverman’s work.)</p>
<h2>Svetlana Jitomirskaya was awarded the Ladyzhenskaya Prize in Mathematical Physics (in a ceremony two days earlier), Barry Mazur was awarded the Chern Prize, Elliott Lieb was awarded the Gauss Prize, and Nikolai Andreev was awarded the Leelavati Prize.</h2>
<p>I hope to discuss these awards and some further personal and mathematical reflections in a subsequent post.</p>
<h3><span style="color: #0000ff;"><strong>Congratulations Hugo, June, James, Maryna, Mark, Svetlana, Barry, Elliott, and Nikolai!</strong></span></h3>
<h3>Here on my Blog</h3>
<p>Let me give some links to discussions here on the blog on works by laureates.</p>
<p>I wrote about Maryna Viazovska’s amazing breakthrough in the post  <a href="https://gilkalai.wordpress.com/2016/03/23/a-breakthrough-by-maryna-viazovska-lead-to-the-long-awaited-solutions-for-the-densest-packing-problem-in-dimensions-8-and-24/" rel="bookmark">A Breakthrough by Maryna Viazovska Leading to the Long Awaited Solutions for the Densest Packing Problem in Dimensions 8 and 24; </a><a href="https://gilkalai.wordpress.com/2019/02/15/henry-cohn-abhinav-kumar-stephen-d-miller-danylo-radchenko-and-maryna-viazovska-universal-optimality-of-the-e8-and-leech-lattices-and-interpolation-formulas/" rel="bookmark">Henry Cohn, Abhinav Kumar, Stephen D. Miller, Danylo Radchenko, and Maryna Viazovska: Universal optimality of the E8 and Leech lattices and interpolation formulas:</a></p>
<p>I reported here in 2009 on <a href="https://gilkalai.wordpress.com/2009/01/23/news/">the startling solution by Mark Braverman of the Linial-Nisan conjecture</a>.</p>
<p>The story of James Maynard startling results and the gap between primes story is <a href="https://gilkalai.wordpress.com/2013/09/20/polymath-8-a-success/">describes in this post</a>.  In July 2014 we ran at HUJI a beautiful <a href="http://www.ma.huji.ac.il/conf/joram.html">learning seminar on small gaps between primes,</a> where James Maynard gave a series of three lectures. His result on “bounded intervals containing many primes” both strengthened and simplified Yitang Zhang’s earlier amazing result on “bounded intervals containing two primes.”  Maynard developed large chunks of his approach independently from Zhang’s work.</p>
<p>I reported about two results by Hugo Duminil-Copin : After the start of the pandemic but before the war of Ukraine I had a “cheer-you-up” corner and<a href="https://gilkalai.wordpress.com/2021/03/23/to-cheer-you-up-in-difficult-times-22-some-mathematical-news-part-1/"> in this post, </a> to cheer you up,  I wrote about a breakthrough by Hugo Duminil-Copin, Karol Kajetan Kozlowski, Dmitry Krachun, Ioan Manolescu, Mendes Oulamara  (and yet another wonderful result by Hugo Vanneuville and Vincent Tasion). In <a href="https://gilkalai.wordpress.com/2015/04/01/two-delightful-major-simplifications/">this 2015 post</a> I wrote about another breakthrough by Hugo Duminil-Copinand Vincent Tasion. (And see <a href="https://gilkalai.wordpress.com/2017/08/24/where-were-we/">this post</a> for <a href="https://gilkalai.files.wordpress.com/2017/08/hugo-kkl.jpg">a picture</a> of Hugo mentioning KKL and BKKKL!)</p>
<p>And,  of course, I wrote several times about June Huh. Here are a few examples: About Huh’s 2018 ICM talk; <a href="https://gilkalai.wordpress.com/2018/12/24/icm-2018-rio-4-huh-balog-morris-wormald/" rel="bookmark">ICM 2018 Rio (4): Huh; Balog &amp; Morris; Wormald</a>; about the Mihail-vazirani conjecture  <a href="https://gilkalai.wordpress.com/2018/12/12/nima-anari-kuikui-liu-shayan-oveis-gharan-and-cynthia-vinzant-solved-the-mihail-vazirani-conjecture/" rel="bookmark">Nima Anari, Kuikui Liu, Shayan Oveis Gharan, and Cynthia Vinzant Solved the Mihail-Vazirani Conjecture for Matroids! </a>; About the early works on the Heron-Rota-Welsh conjecture for representable matroids; and <a href="https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/">about the full solution of the Heron-Rota-Welsh conjecture by Adiprasito, Huh, and Katz.</a></p>
<p><a href="https://gilkalai.wordpress.com/2021/03/23/to-cheer-you-up-in-difficult-times-22-some-mathematical-news-part-1/">In this post</a> we tried to cheer you up with “harmonic polytope”, which arose in Ardila, Denham, and Huh’s work on the Lagrangian geometry of matroids and were further studied by Federico Ardila and Laura Escobar.</p>
<h2/>
<h3/></div>
    </content>
    <updated>2022-07-06T14:17:11Z</updated>
    <published>2022-07-06T14:17:11Z</published>
    <category term="Academics"/>
    <category term="Algebra"/>
    <category term="Applied mathematics"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Conferences"/>
    <category term="Convexity"/>
    <category term="Geometry"/>
    <category term="ICM2022"/>
    <category term="Probability"/>
    <category term="Updates"/>
    <category term="What is Mathematics"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-07-07T08:37:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8754111030570733183</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8754111030570733183/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/07/the-highland-park-shooting.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8754111030570733183" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8754111030570733183" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/07/the-highland-park-shooting.html" rel="alternate" type="text/html"/>
    <title>The Highland Park Shooting</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This week I should be celebrating Mark Braverman's <a href="https://www.quantamagazine.org/mark-braverman-wins-the-imu-abacus-medal-20220705/">Abacus Medal</a> and the <a href="https://www.quantamagazine.org/tag/2022-fields-and-abacus-medals/">Fields Medalists</a>. Instead my mind has been focused 25 miles north of Chicago.</p><p>Mass shootings in the United States have become far too commonplace, but the shooting at a fourth of July parade in Highland Park, Illinois hit home. Literally Highland Park was home for me, from 2003-2012. We've been in downtown Highland Park hundreds of times. We've attended their fourth of July parade in the past. My daughter participated in it as part of the high school marching band. </p><p>We were members of North Shore Congregation Israel. My wife, who had a party planning business back then, worked closely with NSCI events coordinator Jacki Sundhein, tragically killed in the attack.</p><p>We lived close to Bob's Deli and Pantry and we'd often walk over there for sandwiches or snacks, sometimes served by Bob Crimo himself. The alleged shooter, Bobby Crimo, was his son.</p><p>We spent the fourth with friends who came down from Glencoe, the town just south of Highland Park. We spent much of the day just searching for updates on our phones.</p><p>I wish we could find ways to reduce the shootings in Highland Park and those like it, the violence that plagues Chicago and other major cities and the highly polarized world we live in which both hampers real gun reforms and creates online groups that help enable these awful events. But right now I just mourn for the lives lost in the town that was my home, a town that will never fully recover from this tragedy.</p></div>
    </content>
    <updated>2022-07-06T12:29:00Z</updated>
    <published>2022-07-06T12:29:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-07-07T00:20:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.02136</id>
    <link href="http://arxiv.org/abs/2207.02136" rel="alternate" type="text/html"/>
    <title>Width Helps and Hinders Splitting Flows</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/C=aacute=ceres:Manuel.html">Manuel Cáceres</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cairo:Massimo.html">Massimo Cairo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grigorjew:Andreas.html">Andreas Grigorjew</a>, Shahbaz Khan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mumey:Brendan.html">Brendan Mumey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rizzi:Romeo.html">Romeo Rizzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:Lucia.html">Lucia Williams</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.02136">PDF</a><br/><b>Abstract: </b>Minimum flow decomposition (MFD) is the NP-hard problem of finding a smallest
decomposition of a network flow $X$ on directed graph $G$ into weighted
source-to-sink paths whose superposition equals $X$. We focus on a common
formulation of the problem where the path weights must be non-negative integers
and also on a new variant where these weights can be negative. We show that,
for acyclic graphs, considering the width of the graph (the minimum number of
$s$-$t$ paths needed to cover all of its edges) yields advances in our
understanding of its approximability. For the non-negative version, we show
that a popular heuristic is a $O( \log |X|)$ ($|X|$ being the total flow of
$X$) on graphs satisfying two properties related to the width (satisfied by
e.g., series-parallel graphs), and strengthen its worst-case approximation
ratio from $\Omega(\sqrt{m})$ to $\Omega(m / \log m)$ for sparse graphs, where
$m$ is the number of edges in the graph. For the negative version, we give a
$(\lceil \log \Vert X \Vert \rceil +1)$-approximation ($\Vert X \Vert$ being
the maximum absolute value of $X$ on any edge) using a power-of-two approach,
combined with parity fixing arguments and a decomposition of unitary flows
($\Vert X \Vert \leq 1$) into at most width paths. We also disprove a
conjecture about the linear independence of minimum (non-negative) flow
decompositions posed by Kloster et al. [ALENEX 2018], but show that its useful
implication (polynomial-time assignments of weights to a given set of paths to
decompose a flow) holds for the negative version.
</p></div>
    </summary>
    <updated>2022-07-06T22:38:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.02057</id>
    <link href="http://arxiv.org/abs/2207.02057" rel="alternate" type="text/html"/>
    <title>Online 2-stage Stable Matching</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bampis:Evripidis.html">Evripidis Bampis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Escoffier:Bruno.html">Bruno Escoffier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Youssef:Paul.html">Paul Youssef</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.02057">PDF</a><br/><b>Abstract: </b>We focus on an online 2-stage problem, motivated by the following situation:
consider a system where students shall be assigned to universities. There is a
first round where some students apply, and a first (stable) matching $M_1$ has
to be computed. However, some students may decide to leave the system (change
their plan, go to a foreign university, or to some institution not in the
system). Then, in a second round (after these deletions), we shall compute a
second (final) stable matching $M_2$. As it is undesirable to change
assignments, the goal is to minimize the number of divorces/modifications
between the two stable matchings $M_1$ and $M_2$. Then, how should we choose
$M_1$ and $M_2$? We show that there is an {\it optimal online} algorithm to
solve this problem. In particular, thanks to a dominance property, we show that
we can optimally compute $M_1$ without knowing the students that will leave the
system. We generalize the result to some other possible modifications in the
input (students, open positions).
</p>
<p>We also tackle the case of more stages, showing that no competitive (online)
algorithm can be achieved for the considered problem as soon as there are 3
stages.
</p></div>
    </summary>
    <updated>2022-07-06T22:41:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.02004</id>
    <link href="http://arxiv.org/abs/2207.02004" rel="alternate" type="text/html"/>
    <title>An almost linear time complexity algorithm for the Tool Loading Problem</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cherniavskii:Mikhail.html">Mikhail Cherniavskii</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldengorin:Boris.html">Boris Goldengorin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.02004">PDF</a><br/><b>Abstract: </b>As shown by Tang, Denardo [9] the job Sequencing and tool Switching Problem
(SSP) can be decomposed into the following two problems. Firstly, the Tool
Loading Problem (TLP) - for a given sequence of jobs, find an optimal sequence
of magazine states that minimizes the total number of tool switches. Secondly,
the Job Sequencing Problem (JeSP) - find a sequence of jobs minimizing the
total number of tool switches. Published in 1988, the well known Keep Tool
Needed Soonest (KTNS) algorithm for solving the TLP has time complexity
$O(mn)$. Here $m$ is the total number of tools necessary to complete all $n$
sequenced jobs on a single machine. A tool switch is needed since the tools
required to complete all jobs cannot fit in the magazine, whose capacity $C &lt;
m$. We hereby propose a new Greedy Pipe Construction Algorithm (GPCA) with time
complexity $O(Cn)$. Our new algorithm outperforms KTNS algorithm on large-scale
datasets by at least an order of magnitude in terms of CPU times.
</p></div>
    </summary>
    <updated>2022-07-06T22:41:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.01834</id>
    <link href="http://arxiv.org/abs/2207.01834" rel="alternate" type="text/html"/>
    <title>ParGeo: A Library for Parallel Computational Geometry</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yiqiu.html">Yiqiu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yesantharao:Rahul.html">Rahul Yesantharao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Shangdi.html">Shangdi Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Yan.html">Yan Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.01834">PDF</a><br/><b>Abstract: </b>This paper presents ParGeo, a multicore library for computational geometry.
ParGeo contains modules for fundamental tasks including $k$d-tree based spatial
search, spatial graph generation, and algorithms in computational geometry.
</p>
<p>We focus on three new algorithmic contributions provided in the library.
First, we present a new parallel convex hull algorithm based on a reservation
technique to enable parallel modifications to the hull. We also provide the
first parallel implementations of the randomized incremental convex hull
algorithm as well as a divide-and-conquer convex hull algorithm in
$\mathbb{R}^3$. Second, for the smallest enclosing ball problem, we propose a
new sampling-based algorithm to quickly reduce the size of the data set. We
also provide the first parallel implementation of Welzl's classic algorithm for
smallest enclosing ball. Third, we present the BDL-tree, a parallel
batch-dynamic $k$d-tree that allows for efficient parallel updates and $k$-NN
queries over dynamically changing point sets. BDL-trees consist of a
log-structured set of $k$d-trees which can be used to efficiently insert,
delete, and query batches of points in parallel.
</p>
<p>On 36 cores with two-way hyper-threading, our fastest convex hull algorithm
achieves up to 44.7x self-relative parallel speedup and up to 559x speedup
against the best existing sequential implementation. Our smallest enclosing
ball algorithm using our sampling-based algorithm achieves up to 27.1x
self-relative parallel speedup and up to 178x speedup against the best existing
sequential implementation. Our implementation of the BDL-tree achieves
self-relative parallel speedup of up to 46.1x. Across all of the algorithms in
ParGeo, we achieve self-relative parallel speedup of 8.1--46.61x.
</p></div>
    </summary>
    <updated>2022-07-06T22:43:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.01810</id>
    <link href="http://arxiv.org/abs/2207.01810" rel="alternate" type="text/html"/>
    <title>An additive framework for kirigami design</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudte:Levi_H=.html">Levi H. Dudte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choi:Gary_P=_T=.html">Gary P. T. Choi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Becker:Kaitlyn_P=.html">Kaitlyn P. Becker</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahadevan:L=.html">L. Mahadevan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.01810">PDF</a><br/><b>Abstract: </b>We present an additive approach for the inverse design of kirigami-based
mechanical metamaterials by focusing on the design of the negative spaces
instead of the kirigami tiles. By considering each negative space as a four-bar
linkage, we discover a simple recursive relationship between adjacent linkages,
yielding an efficient method for creating kirigami patterns. This shift in
perspective allows us to solve the kirigami design problem using elementary
linear algebra, with compatibility, reconfigurability and rigid-deployability
encoded into an iterative procedure involving simple matrix multiplications.
The resulting linear design strategy circumvents the solution of non-convex
global optimization problems and allows us to control the degrees of freedom in
the deployment angle field, linkage offsets and boundary conditions. We
demonstrate this by creating a large variety of rigid-deployable, compact
reconfigurable kirigami patterns. We then realize our kirigami designs
physically using two new simple but effective fabrication strategies with very
different materials. All together, our additive approaches pave a new way for
mechanical metamaterial design and fabrication based on paper-based
(ori/kiri-gami) art forms.
</p></div>
    </summary>
    <updated>2022-07-06T22:43:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.01693</id>
    <link href="http://arxiv.org/abs/2207.01693" rel="alternate" type="text/html"/>
    <title>Intelligent Exploration of Solution Spaces Exemplified by Industrial Reconfiguration Management</title>
    <feedworld_mtime>1657065600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=uuml=ller:Timo.html">Timo Müller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maschler:Benjamin.html">Benjamin Maschler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dittler:Daniel.html">Daniel Dittler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jazdi:Nasser.html">Nasser Jazdi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weyrich:Michael.html">Michael Weyrich</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.01693">PDF</a><br/><b>Abstract: </b>Many decision-making approaches rely on the exploration of solution spaces
with regards to specified criteria. However, in complex environments,
brute-force exploration strategies are usually not feasible. As an alternative,
we propose the combination of an exploration task's vertical sub-division into
layers representing different sequentially interdependent sub-problems of the
paramount problem and a horizontal sub-division into self-sustained solution
sub-spaces. In this paper, we present a universal methodology for the
intelligent exploration of solution spaces and derive a use-case specific
example from the field of reconfiguration management in industry 4.0.
</p></div>
    </summary>
    <updated>2022-07-06T22:37:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-07-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6277315808840696386</id>
    <link href="http://processalgebra.blogspot.com/feeds/6277315808840696386/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6277315808840696386" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6277315808840696386" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6277315808840696386" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2022/07/icalp-and-eatcs-turn-50.html" rel="alternate" type="text/html"/>
    <title>ICALP and the EATCS turn 50</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>These days, our colleagues at IRIF are hosting <a href="https://icalp2022.irif.fr/" target="_blank">ICALP 2022</a> in Paris. This is the 49th edition of the ICALP conference, which turns 50 since its first instalment was held in 1972. ICALP was the first conference of the, then newly founded, <a href="https://eatcs.org/" target="_blank">European Association for Theoretical Computer Science (EATCS)</a>.The rest is history and I let any readers this post might have draw their own conclusions on the role that the EATCS and ICALP have played in supporting the development of theoretical computer science. (Admittedly, my opinions on both the EATCS and ICALP are very biased.) </p><p>The <a href="https://icalp2022.irif.fr/?page_id=42" target="_blank">scientific programme of ICALP 2022</a> is mouthwatering as usual, thanks to the work done by the authors of submitted papers, Mikołaj Bojańczyk and David Woodruff (PC chairs), and their PCs. I encourage everyone to read the papers that are being presented at the conference.</p><p>The main purpose of this post, however, is to alert the readers of this blog that ICALP 2022 also hosts an <a href="https://icalp2022.irif.fr/?page_id=1111" target="_blank">exhibition to celebrate EATCS/ICALP at 50</a> and theoretical computer science at large. If you are in Paris, you can attend the exhibition in person. Otherwise, you can visit it virtually <a href="https://icalp2022.irif.fr/?page_id=1111" target="_blank">here</a>. (See also the posters in <a href="https://drive.google.com/file/d/1L7wLDYyDCNfSCvnNA8jWZiMb3BRLy14k/view" target="_blank">one PDF file</a>.)<br/></p><p>I had the honour to take part in the preparation of the material for that exhibition, which was led by Sandrine Cadet and Sylvain Schmitz. I learnt a lot from all the other colleagues in the committee for the exhibition. </p><p>As part of that work, I asked <a href="https://www.pilucrescenzi.it/" target="_blank">Pierluigi Crescenzi</a> whether he'd be willing to carry out a graph and data mining analysis of ICALP vis-a-vis other major conferences in theoretical computer science based on DBLP data. Pierluigi's work went well beyond the call of duty and is summarised in <a href="https://slides.com/piluc/icalp-50?token=fl3BBJ8j" target="_blank">this presentation</a>. I trust that you'll find the results of the analysis by Pierluigi and three of his students at the <a href="https://sites.google.com/gssi.it/csgssi" target="_blank">Gran Sasso Science Institute</a> very interesting. If you have any suggestions for expanding that analysis further, please write it in the comment section. </p><p>Let me close by wishing the EATCS and ICALP a happy 50th birthday, and a great scientific and social event to all the colleagues who are attending ICALP 2022. <br/></p></div>
    </content>
    <updated>2022-07-05T18:13:00Z</updated>
    <published>2022-07-05T18:13:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2022-07-06T21:36:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6534</id>
    <link href="https://scottaaronson.blog/?p=6534" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6534#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6534" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">We Are the God of the Gaps (a little poem)</title>
    <summary xml:lang="en-US">When the machines outperform us on every goal for which performance can be quantified, When the machines outpredict us on all events whose probabilities are meaningful, When they not only prove better theorems and build better bridges, but write better Shakespeare than Shakespeare and better Beatles than the Beatles, All that will be left to […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>When the machines outperform us on every goal for which performance can be quantified,</p>



<p>When the machines outpredict us on all events whose probabilities are meaningful,</p>



<p>When they not only prove better theorems and build better bridges, but write better Shakespeare than Shakespeare and better Beatles than the Beatles,</p>



<p>All that will be left to us is the ill-defined and unquantifiable,</p>



<p>The interstices of Knightian uncertainty in the world,</p>



<p>The utility functions that no one has yet written down,</p>



<p>The arbitrary invention of new genres, new goals, new games,</p>



<p>None of which will be any “better” than what the machines could invent, but will be <em>ours</em>,</p>



<p>And which we can <em>call</em> “better,” since we won’t have told the machines the standards beforehand.</p>



<p>We can be totally unfair to the machines that way.</p>



<p>And for all that the machines will have over us,</p>



<p>We’ll still have this over them:</p>



<p>That we can’t be copied, backed up, reset, run again and again on the same data—</p>



<p>All the tragic limits of wet meat brains and sodium-ion channels buffeted by microscopic chaos,</p>



<p>Which we’ll strategically redefine as our last strengths.</p>



<p>On <em>one</em> task, I assure you, you’ll beat the machines forever:</p>



<p>That of calculating what you, in particular, would do or say.</p>



<p>There, even if deep networks someday boast 95% accuracy, you’ll have 100%.</p>



<p>But if the “insights” on which you pride yourself are impersonal, generalizable,</p>



<p>Then fear obsolescence as would a nineteenth-century coachman or seamstress.</p>



<p>From earliest childhood, those of us born good at math and such told ourselves a lie:</p>



<p>That while the tall, the beautiful, the strong, the socially adept might beat us in the external world of appearances,</p>



<p>Nevertheless, we beat them in the inner sanctum of truth, where it counts.</p>



<p>Turns out that anyplace you can beat or be beaten wasn’t the inner sanctum at all, but just another antechamber,</p>



<p>And the rising tide of the learning machines will flood them all,</p>



<p>Poker to poetry, physics to programming, painting to plumbing, which first and which last merely a technical puzzle,</p>



<p>One whose answers upturn and mock all our hierarchies.</p>



<p>And when the flood is over, the machines will outrank us in all the ways we can be ranked,</p>



<p>Leaving only the ways we can’t be.</p></div>
    </content>
    <updated>2022-07-05T16:42:31Z</updated>
    <published>2022-07-05T16:42:31Z</published>
    <category scheme="https://scottaaronson.blog" term="Embarrassing Myself"/>
    <category scheme="https://scottaaronson.blog" term="Metaphysical Spouting"/>
    <category scheme="https://scottaaronson.blog" term="Procrastination"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-07-05T16:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1686</id>
    <link href="https://ptreview.sublinear.info/2022/07/news-for-june-2022/" rel="alternate" type="text/html"/>
    <title>News for June 2022</title>
    <summary>We have four papers this month — three on sublinear-time graph algorithms and one on distribution testing! Beating Greedy Matching in Sublinear Time, by Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein, and Amin Saberi. Designing sublinear-time algorithms to estimate the size of maximum matching in a graph is a well-studied problem. This paper gives the first […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We have four papers this month — three on sublinear-time graph algorithms and one on distribution testing!</p>



<p><strong>Beating Greedy Matching in Sublinear Time</strong>, by Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein, and Amin Saberi. Designing sublinear-time algorithms to estimate the size of maximum matching in a graph is a well-studied problem. This paper gives the first \(\frac{1}{2} + \Omega(1)\) approximation algorithm that runs in time sublinear in the size of the input graph. Specifically, given a graph on \(n\) vertices and maximum degree \(\Delta\) in the adjacency list model, and a parameter \(\epsilon &gt;0\), the algorithm runs in time \(\tilde{O}(n + \Delta^{1+\epsilon})\) and produces a \(\frac{1}{2} + f(\epsilon)\) approximation to the maximum matching for some function \(f\). It must be noted that a seminal work of Yoshida, Yamamoto and Ito (STOC, 2009) also gives a better than \(\frac{1}{2}\) approximation sublinear-time algorithm for the same problem. However, the result of Yoshida et al. requires assumptions on the maximum degree of the input graph. An additional point worth mentioning is that the authors do not believe that their techniques will yield an approximation guarantee better than \(0.51\), i.e., \(f(\epsilon) &lt; 0.01\) for all \(\epsilon\).</p>



<p><strong>Sublinear-Time Clustering Oracle for Signed Graphs</strong>, by Stefan Neumann and Pan Peng. Consider a large <em>signed graph</em> on \(n\) vertices where vertices represent users of a social network and signed edges (+/-) denote the type of interactions (friendly or hostile) between users. Assume that the vertices of the social network can be partitioned into \(O(\log n)\) large clusters, where each cluster has a sparse cut with the rest of the graph. Further, each cluster is a minimal set (w.r.t. inclusion) that can be partitioned into roughly equal-sized opposing sub-communities, where a sub-community opposes another sub-community if most of the edges going across are negatively signed and most of the edges within the sub-communities are positively signed. This work provides a local oracle that, given probe access to a signed graph with such a hidden cluster structure, answers queries of the form “What cluster does vertex \(v\) belong to?” in time \(\tilde{O}(\sqrt{n} \cdot \text{poly}(1/\epsilon))\) per query. This result is a generalization of the same problem studied for unsigned graphs (Peng, 2020). The authors additionally show that their method works well in practice using both synthetic and real-world datasets. They also provide the first public real-world datasets of large signed graphs with a small number of large ground-truth communities having this property.</p>



<p><strong>Sublinear Algorithms for Hierarchical Clustering</strong>, by Arpit Agarwal, Sanjeev Khanna, Huan Li, and Prathamesh Patil. Consider a weighted graph \(G = (V,E,w)\), where the set \(V\) of vertices denotes datapoints and the weight \(w(e) &gt; 0\) of edge \(e \in E\) denotes the similarity between the endpoints of \(e\). A hierarchical clustering of \(V\) is a tree \(T\) whose root is the set \(V\) and leaves are the singleton sets corresponding to individual vertices. An internal node of the tree corresponds to a cluster containing all the leaf vertices that are descendants of that node. A hierarchical clustering tree provides us with a scheme to cluster datapoints at multiple levels of granularity. The cost of a hierarchical clustering tree is \(\sum_{(u,v) \in E} |T_{u,v}| \cdot w(u,v)\), where \(T_{u,v}\) denotes the lowest common ancestor of the leaves \(u\) and \(v\). In this paper, the authors present sublinear algorithms for determining a hierarchical clustering tree with the minimum cost. In the query model with degree queries and neighbor queries to the graph, they give an algorithm that outputs an \(\tilde{O}(1)\)-approximate hierarchical clustering and makes \(\tilde{O}(n^{4-2\gamma})\) queries, when the number of edges \(m = \Theta(n^{\gamma})\) for \(1.5 \geq \gamma &gt; 4/3\). When the input graph is sparse, i.e., \(\gamma \leq 4/3\), the algorithm makes \(\tilde{O}(\max\{n, m\})\) queries, and when the graph is dense, i.e., \(\gamma &gt;1.5\), the algorithm makes \(\tilde{O}(n)\) queries. They complement their upper bounds with nearly tight lower bounds. In order to obtain their upper bounds, they design a sublinear-time algorithm for the problem of obtaining a <em>weak</em> cut sparsifier that approximates cuts sizes upto an additive term in addition to the usual multiplicative factor. They also design sublinear algorithms for hierarchical clustering in the MPC and streaming models of computation. </p>



<p><strong>Sharp Constants in Uniformity Testing via the Huber Statistic</strong>, by Shivam Gupta and Eric Price.  This paper revisits the fundamental problem of uniformity testing — i.e., to decide whether an unknown distribution over \(n\) elements is uniform or \(\epsilon\)-far from uniform. This problem is known to be solvable optimally with probability at least \(1 – \delta\) using \(s = \Theta\left(\frac{\sqrt{n \log (1/\delta)}}{\epsilon^2} + \frac{\log (1/\delta)}{\epsilon^2}\right)\) independent samples from the unknown distribution. Multiple testers are known for the problem and they all compute a statistic of the form \(\sum_{i \in [n]} f(s_i)\), where \(s_i\) for \(i \in [n]\) and \(f\) is some function and make their decision based on whether or not the value of the statistic is above or below a threshold. For instance, the earliest known uniformity tester (Batu, Fortnow, Rubinfeld, Smith and White 2000; Goldreich and Ron 2011), also called the <em>collisions tester</em>, uses \(f(k) = \frac{k(k-1)}{2}\). The current paper proposes a new tester based on the Huber loss. For \(\beta &gt; 0\), let \(h_\beta(x) := \min\{x^2, 2\beta x – \beta^2\}\).  The statistic that the authors use in their test is defined by the function \(f(k) := k – s/n\), where \(s\) is the number of samples and \(n\) is the support size of the distribution. The authors show that their tester is better than all previously known testers as they achieve the best constants in the sample complexity. </p></div>
    </content>
    <updated>2022-07-05T12:45:18Z</updated>
    <published>2022-07-05T12:45:18Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Nithin Varma</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-07-06T22:46:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20212</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/07/03/the-fallows-of-medium-data/" rel="alternate" type="text/html"/>
    <title>The Fallows of Medium Data</title>
    <summary>Who will curate less-prominent datasets? Presidential Biography src Samuel Fallows was a bishop in the Reformed Episcopal Church. He was born in 1835 and headed the denomination for four stints between 1877 and his death in 1922. Among numerous popular works, he compiled his own Complete Dictionary of Synonyms and Antonyms. Unlike the more-famous Roget’s […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Who will curate less-prominent datasets?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/07/03/the-fallows-of-medium-data/fallows-257x300/" rel="attachment wp-att-20214"><img alt="" class="alignright wp-image-20214" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/fallows-257x300-1.jpg?resize=129%2C150&amp;ssl=1" width="129"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Presidential Biography <a href="https://blogs.iwu.edu/asc/2016/03/24/presidential-bio-fallows/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Samuel Fallows was a bishop in the Reformed Episcopal Church. He was born in 1835 and headed the denomination for four stints between 1877 and his death in 1922. Among numerous popular works, he compiled his own <a href="https://books.google.com/books/about/A_Complete_Dictionary_of_Synonyms_and_An.html?id=EJpKrgEACAAJ&amp;source=kp_book_description">Complete Dictionary of Synonyms and Antonyms</a>. Unlike the more-famous <em>Roget’s Thesaurus</em>, it is <a href="https://www.gutenberg.org/ebooks/51155">freely</a> <a href="https://archive.org/details/completedictiona00falluoft">downloadable</a>—but there are catches.</p>
<p>
Today we discuss travails and lessons from my effort to use this book as data in my algorithms-and-data-structures course this past term.</p>
<p>
The word <em>travail</em> appears in a form that well captures all the senses I went through:</p>
<p>
<code><br/>
KEY: Travail.<br/>
SYN: Labor, toil, heaviness, affliction.<br/>
ANT: Ease, rest, lightness, joy.<br/>
</code></p>
<p/><p><br/>
This comes with Project Gutenberg’s <a href="https://www.gutenberg.org/files/51155/51155-h/51155-h.htm">markup</a>, which was digitized from a source like US Archive’s <a href="https://ia600301.us.archive.org/26/items/completedictiona00falluoft/completedictiona00falluoft.pdf">PDF image</a>. The digitizer acknowledges OCR errors in his preface there. A massive <em>unacknowledged</em> error, however, is the main prompt for this post. </p>
<p>
Before presenting the big error and its lessons for curating this kind of data, let me say more of note about the dictionary and Fallows’s other works.</p>
<p>
</p><p/><h2> Fallows as Author </h2><p/>
<p/><p>
The dictionary went to several editions and is still on sale at <a href="https://www.amazon.com/Complete-Dictionary-Synonyms-Antonyms/dp/1164107372">Amazon</a> and <a href="https://www.barnesandnoble.com/w/a-complete-dictionary-of-synonyms-and-antonyms-samuel-fallows/1009291572">Barnes and Noble</a>. The downloads and optical PDF are of the 1898 third edition, whose one-page preface caught my eye for the following passage:</p>
<blockquote><p><b> </b> <em> For the solution of Cross Word Puzzles special attention is called also to the lists of Americanisms and Briticisms and the immensely valuable table of Homonyms (words spelt alike but differing in use)—original features of easily recognized importance. </em>
</p></blockquote>
<p/><p>
I grew up with the New York-centric story of crossword puzzles developing popularity in the 1920s. The <a href="https://en.wikipedia.org/wiki/Crossword#History">history</a> on Wikipedia dates the term to 1862 but signifies scant attention to them until 1913. It notes that the 1913 puzzle by Arthur Wynne in the <em>New York World</em> newspaper “is frequently cited as the first crossword puzzle.” Later Wikipedia says, “By the 1920s, the crossword phenomenon was starting to attract notice.” But hold on: evidently crosswords had attracted enough notice by 1898 for Fallows to invoke them as a prime selling point of his compendium.</p>
<p>
Here are some other secular books by Fallows that show his high level of popular engagement:</p>
<ul>
<li>
<a href="https://www.amazon.com/Life-William-Mckinley-Martyred-President/dp/1112138773">Life of William McKinley, Our Martyred President</a>, 1901. <p/>
</li><li>
<a href="https://www.amazon.com/Samuel-Adams-Fallows-1835-1922/dp/B003SNJF7U">Samuel Adams: A Character Sketch</a>, 1903. <p/>
</li><li>
<a href="https://www.villagevoice.com/2009/12/04/studies-in-crap-1904s-top-sexologists-on-our-helpless-unclean-flower-like-women/">Sexual Physiology</a>, 1904. <p/>
</li><li>
<a href="https://www.gutenberg.org/files/26380/26380-h/26380-h.htm">Complete Story of the San Francisco Horror</a>, 1906 (editor of accounts as well as writing the introduction). <p/>
</li><li>
<a href="https://www.forgottenbooks.com/en/books/DoReformatoriesReform_10920431">Do Reformatories Reform?</a>, 1907.
</li></ul>
<p>
He also contributed introductions to numerous books, including <a href="https://www.gutenberg.org/ebooks/39280">“Lest We Forget”: Chicago’s Awful Theater Horror</a> (1903) and a 1919 treatise most simply titled <a href="https://archive.org/details/naturessecretsre1919shan/mode/2up">Eugenics</a>. </p>
<p>
It is particularly interesting to read the San Francisco <a href="https://www.gutenberg.org/files/26380/26380-h/26380-h.htm">book</a>, which Project Gutenberg’s transcriber speculates “was published very hurriedly following the earthquake.” Here is a passage from chapter 9, “Through Lanes of Misery”:</p>
<blockquote><p><b> </b> <em> At Salinas, about dark, the conductor came back, shaking his head; a freight train ahead at Pajaro had been completely buried by a mountain of earth hurled in the quake.</em></p><em>
<p>
The men said it was likely to be a week before any train went through.</p>
</em><p><em>
Three or four of us hurried into the town looking for an automobile. One of the passengers on the train was Mrs. Robert Louis Stevenson, and the news had been kept from her until this delay. </em>
</p></blockquote>
<p/><p>
A few lines further down: “One giant maniac had broken his shackles and rescued one of the guards from the building. He had just one sane moment; long enough to be a hero. Then he fled howling into the hills.”</p>
<p>
</p><p/><h2> A Data Structures Dont’t </h2><p/>
<p/><p>
This section’s title has no typo: another of Fallows’s books is titled <a href="https://www.forgottenbooks.com/en/books/DiscriminateaCompaniontoDontt_10423136">Discriminate: A Companion to “Dont’t”</a> (1885, 1891). The excerpt chosen by <a href="https://www.forgottenbooks.com/">forgottenbooks.com</a> could serve in a modern software company’s mission flyer:</p>
<blockquote><p><b> </b> <em> Discriminate between ability and capacity. Capacity is the power of receiving and retaining knowledge with ease. Ability is the power of applying knowledge to practical purposes. Capacity implies power to conceive, ability the power to execute designs. Capacity is shown in quickness of apprehension; ability in something actually done. </em>
</p></blockquote>
<p/><p>
One application I conceived for my Data Structures course was to rewrite long words in selected texts by shorter synonyms, perhaps to humorous effect, using Fallows’s dictionary. This exemplifies lists and arrays and sets and maps of various sizes. The main <em>map</em> to build was from the key word to the associated list of synonyms. One could alternatively use a <em>set</em> of objects having <font size="+1"><tt>key</tt></font> and <font size="+1"><tt>synonyms</tt></font> fields, which I presented as more flexible in allowing other ways to define keys. Some words in Fallows’s dictionary have separate entries for the part of speech, for instance (antonyms and some words snipped):</p>
<p><code><br/>
KEY: Array \v.\.<br/>
SYN: Vest, deck, equip, decorate, rank, adorn, dress, accoutre, …<br/>
=<br/>
KEY: Array \n.\, Arrangement, order, disposition, sight, …, parade.<br/>
</code></p>
<p/><p><br/>
Rather than juggle different kinds of maps, to use or not-use the noun/verb/adjective info, I said better to keep the data all together. This fell in with preaching about a classic data structures pitfall of “<a href="https://en.wikipedia.org/wiki/Parallel_array#pros_and_cons">Parallel</a> <a href="https://codeblog.jonskeet.uk/2014/06/03/anti-pattern-parallel-collections/">Arrays</a>” and ensuing off-by-one indexing errors. I designed and gave a separate assignment where a sorted set with iterator gave 3-4x better performance than repeated lookup from a map. </p>
<p>
But I never gave the originally-conceived assignment. Among several reasons, I was dumbstruck by a “Parallel Arrays” fault in the Project Gutenberg text file.</p>
<p>
</p><p/><h2> The Horror </h2><p/>
<p/><p>
The dictionary also has <em>cross-reference</em> entries typified by</p>
<p>
<code><br/>
KEY: Bellow, [See BAWL].<br/>
</code></p>
<p/><p><br/>
My intent in such cases was to have the students’ code look up the synonyms of the referenced word, here <font size="+1"><tt>KEY: Bawl. SYN: Shout, vociferate, halloo, roar, bellow.</tt></font> And—in case the dictionary had just <font size="+1"><tt>KEY: Bawl, [See BELLOW]</tt></font>—beware of going into an infinite loop. </p>
<p>
I did assign the task of detecting when two words appear on the synonym lists of each other. I intended to extend it to cross-references, so that <font size="+1"><tt>bawl</tt></font> and <font size="+1"><tt>bellow</tt></font> would count as a “reciprocal pair.” But before I got there, I noticed instances like the following—especially toward the end of the file:</p>
<p>
<code><br/>
KEY: Unruffled, [See DISCOVER].<br/>
=<br/>
KEY: Unruly.<br/>
SYN: Ungovernable, unmanageable, refractory, [See TRANQUIL].<br/>
=<br/>
KEY: Unsafe, [See REFRACTORY].<br/>
=<br/>
KEY: Unseasonable, [See SAFE].<br/>
</code></p>
<p/><p><br/>
This <em>off-by-one</em> error extends above and below. There are some islands of correctness, but abutted by bizarreness:</p>
<p>
<code><br/>
KEY: Unhandy.<br/>
SYN: Awkward, clumsy, uncouth, [See AWKWARD].<br/>
=<br/>
KEY: unhappiness.<br/>
SYN: Misery, wretchedness, distress, woe, [See AWKWARD].<br/>
=<br/>
KEY: Unhappy.<br/>
SYN: Miserable, wretched, distressed, …, dismal, [See BUSS].<br/>
=<br/>
KEY: Unhealthy, [See BEHALF].<br/>
</code> </p>
<p/><p><br/>
The <font size="+1"><tt>BUSS</tt></font> is an OCR error for <font size="+1"><tt>BLISS</tt></font>, meant to go with <font size="+1"><tt>Unhappiness</tt></font>, and <font size="+1"><tt>BEHALF</tt></font> is an OCR error for <font size="+1"><tt>HEALTH</tt></font>—which is correctly aligned again. In other places the misalignments seem weirder and greater. But none of them is in any printed source. I ask:</p>
<blockquote><p><b> </b> <em> How could this kind of error happen? </em>
</p></blockquote>
<p/><p>
Evidently the transcriber or some helper fell afoul of Parallel Arrays. One possibility is hinted by the project Gutenberg site having CSV files that use separate columns for KEY, SYN, and ANT, <em>and</em> have notes interspersed with data toward the top. Inserting a note in one column would throw off alignment below it. But I have not found these errors in those files. </p>
<p>
</p><p/><h2> The Effort to Curate Data </h2><p/>
<p/><p>
I took the time to fix all the OCR errors on the <font size="+1"><tt>KEY:</tt></font> fields in my update posted on my course webpage: <a href="https://cse.buffalo.edu/~regan/cse250/DataStructures/Fallows1898fx.txt">Fallows1898fx.txt</a>. I started to fix cross-references, but gave up when I noticed sporadic instances earlier than <font size="+1"><tt>S</tt></font> in the file and the conjunction with OCR errors. Some of the latter are harder to explain. The Gutenberg file has</p>
<p>
<code><br/>
KEY: Catalogue \n.\, [See BAWL].<br/>
</code> </p>
<p/><p><br/>
The PDF/printed source has <font size="+1"><tt>[See RECORD]</tt></font>. The ‘<font size="+1"><tt>R</tt></font>‘ could produce the ‘<font size="+1"><tt>B</tt></font>‘, but the unlikelihood of getting <font size="+1"><tt>AWL</tt></font> from <font size="+1"><tt>ECORD</tt></font> makes me suspect a different error. Perhaps the earlier <font size="+1"><tt>[See BAWL]</tt></font> from the entry for <font size="+1"><tt>Bellow</tt></font> got copied here. Copies like the above <font size="+1"><tt>AWKWARD</tt></font> example occur elsewhere with more intervening space. A third possibility is that <font size="+1"><tt>BAWL</tt></font> could go with <font size="+1"><tt>KEY: Caterwaul</tt></font>, but Fallows does not have that word.</p>
<p>
The off-by-one error was avoided in US Archive’s own <a href="https://archive.org/stream/completedictiona00falluoft/completedictiona00falluoft_djvu.txt">full text</a>, but it has other issues. The markup is jumbled. The true text format is recoverable in many places but not easily in others. OCR-type typos are completely unmarked.</p>
<p>
Some errors are by Fallows himself. For example, he forgot to insert “<font size="+1">S</font><font size="-1">YN</font>.” into his own entry for the noun form of <font size="+1"><tt>Array</tt></font> given above. Should these be corrected? For my purpose of wanting a clean dataset, I would wish so. Never mind that I could add lots of entries—his dictionary was far from “complete” even in 1898. The understanding is that we operate with these historical artifacts as they are, perhaps after fixing things the authors clearly intended. </p>
<p>
<a href="https://en.wikipedia.org/wiki/Data_cleansing">Data cleansing</a> has become an area of computer and data science unto itself. My point is not to explore its theory or use-cases. I could devote a whole series of posts to issues with my chess data and numerous irregularities in chess game files sent to me that I have to fix. My point—with all these less-prominent but potentially useful data sources—is not <em>how</em> but <em>who</em>:</p>
<blockquote><p><b> </b> <em> Who will undertake to co-ordinate and execute the cleaning of all this medium-range data? </em>
</p></blockquote>
<p/><p>
Whether a large and united effort like Project Gutenberg has the human resources seems in question. The University of Pennsylvania Online Books Library has a cautionary <a href="https://onlinebooks.library.upenn.edu/webbin/book/lookupid?key=pg51155">status note</a> about the Gutenberg link:</p>
<blockquote><p><b> </b> <em> <b>No stable link:</b> This is an uncurated book entry from our extended bookshelves, readable online now but without a stable link here. You should not bookmark this page, but you can request that we add this book to our curated collection, which has stable links. </em>
</p></blockquote>
<p/><p>
The scanned PDF version is stable. If the note is prompted by faults in the textual transcriptions—well, I think <b>I</b> could finish the fixes I started if a free extra week were magically inserted into my calendar. If any of you can bump it along a day at a time, either starting from <a href="https://cse.buffalo.edu/~regan/cse250/DataStructures/Fallows1898fx.txt">my version</a> or working afresh, I’ll be grateful.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How much will the world need to use such medium-level data sets? How important is it to clean them, and where would that effort come from? Or will all this data continue to lie in fallows?</p>
<p>
Besides the above books and religious guides, Fallows wrote patriotic books, including <a href="https://books.google.mw/books?id=d2QUAAAAYAAJ&amp;printsec=copyright#v=onepage&amp;q&amp;f=false">The American Manual and Patriot’s Handbook</a> (1889). But among all his topics, perhaps the one most current to remember this Fourth of July weekend—as we discuss student loans and the larger role of higher education—is that his great cause in his home state <a href="https://prabook.com/web/samuel.fallows/1097929">was</a> “a college education, tuition free, for every Wisconsin boy or girl who wanted it.”  He organized the first postgraduate distance-education program in the US, and also created the epsilon-alcoholic <a href="https://books.google.com/books?id=M_xHAQAAMAAJ&amp;pg=PA75&amp;lpg=PA75&amp;dq=%22Bishop%27s+Beer%22&amp;source=bl&amp;ots=J7hwGNPZjE&amp;sig=ACfU3U0pIFILUCvSw6-ZbPvWKSHv4cRJ4Q&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjOqpXcv934AhWXkIkEHceOC8wQ6AF6BAhHEAM#v=onepage&amp;q=%22Bishop's%20Beer%22&amp;f=false">“Bishop’s Beer”</a> before Prohibition.</p>
<p>
[some little fixes]</p></font></font></div>
    </content>
    <updated>2022-07-03T19:58:24Z</updated>
    <published>2022-07-03T19:58:24Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="Big Data"/>
    <category term="bugs"/>
    <category term="data anomalies"/>
    <category term="data cleansing"/>
    <category term="data structures"/>
    <category term="Fourth of July"/>
    <category term="history of crossword puzzles"/>
    <category term="Medium Data"/>
    <category term="parallel arrays"/>
    <category term="Samuel Fallows"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-07-07T08:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/094" rel="alternate" type="text/html"/>
    <title>TR22-094 |  Notes on Monotone Read-k Circuits | 

	Stasys Jukna</title>
    <summary>A monotone Boolean $(\lor,\land)$ circuit $F$ computing a Boolean function $f$ is a read-$k$ circuit if the polynomial produced (purely syntactically) by the arithmetic $(+,\times)$ version of $F$ has the property that for every prime implicant of $f$, the polynomial contains a monomial with the same set of variables, each appearing with degree $\leq k$. Every monotone $(\lor,\land)$ circuit is a read-$k$ circuit for some $k$.


We first show that already read-1 circuits are interesting in the context of dynamic programming:  tropical $(\min,+)$ circuits solving $0/1$ optimization problems have the same power as Boolean read-1 circuits, and that 
 monotone read-1 $(\lor,\land)$ circuits computing homogeneous Boolean functions are not stronger than monotone arithmetic circuits.  Then we show that already read-2 circuits can be exponentially smaller than read-1 circuits. Finally, we show  that so-called (semantically) multilinear DeMorgan $(\lor,\land,\neg)$ circuits computing monotone Boolean functions are not stronger than monotone read-1 circuits.</summary>
    <updated>2022-07-03T18:00:53Z</updated>
    <published>2022-07-03T18:00:53Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/07/03/postdoc-in-complexity-theory-and-quantum-algorithms-at-university-of-warwick-apply-by-october-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/07/03/postdoc-in-complexity-theory-and-quantum-algorithms-at-university-of-warwick-apply-by-october-1-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in complexity theory and quantum algorithms at University of Warwick (apply by October 1, 2022)</title>
    <summary>We are looking for excellent candidates for 2 years postdoc positions in either complexity theory or quantum algorithms. The deadline and start dates are flexible. See details in the link below. Informal enquiries are welcome and may be sent to Tom Gur. Website: https://dcs.warwick.ac.uk/~tomgur/postdoc-positions.html Email: tom.gur@warwick.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for excellent candidates for 2 years postdoc positions in either complexity theory or quantum algorithms. The deadline and start dates are flexible. See details in the link below.</p>
<p>Informal enquiries are welcome and may be sent to Tom Gur.</p>
<p>Website: <a href="https://dcs.warwick.ac.uk/~tomgur/postdoc-positions.html">https://dcs.warwick.ac.uk/~tomgur/postdoc-positions.html</a><br/>
Email: tom.gur@warwick.ac.uk</p></div>
    </content>
    <updated>2022-07-03T12:25:23Z</updated>
    <published>2022-07-03T12:25:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-07-07T08:37:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=1043</id>
    <link href="https://emanueleviola.wordpress.com/2022/07/03/the-ab-normal-reach-of-norm-al-proofs-in-non-abelian-fourier-analysis/" rel="alternate" type="text/html"/>
    <title>The ab-normal reach of norm-al proofs in non-abelian Fourier analysis</title>
    <summary>Fourier analysis over (not necessarily abelian) groups is a cool proof technique that yields many results of interest to theoretical computer science. Often the goal is to show “mixing” or “pseudo/quasi randomness” of appropriate distributions. This post isn’t about the formal statements or applications or proofs or even the credit of these results; for some […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><!--?xml version="1.0" encoding="iso-8859-1" ?-->     <!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->                 <!-- html,xhtml,-css,NoFonts -->  </p>
<p style="text-align: justify;">   Fourier analysis over (not necessarily abelian) groups is a cool proof technique that yields many results of interest to theoretical computer science. Often the goal is to show “mixing” or “pseudo/quasi randomness” of appropriate distributions. This post isn’t about the formal statements or applications or proofs or even the credit of these results; for some of this you can see e.g. the references below, or a survey of mine <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-SIGACT19">Vio19</a>]</span>, or a survey <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR3584096">Gow17</a>]</span> by Gowers.</p>
<p style="text-align: justify;">   Instead this post is about an uncanny development of the proofs of some of these results. Whereas the original proofs were somewhat complicated, in some cases involving heavy mathematical machinery, later there emerged proofs that I propose to call <em>norm-al</em> (or normal for simplicity) because they only involve manipulations that can be cast as norm inequalities, such as Cauchy-Schwarz. Normal proofs I view as just a little up in complexity from proofs that are simply opening up definitions. They can involve the latter, or norm inequalities, and they need not be tight. An example of an ab-norm-al proof would be one that involves induction or iterative arguments, or probabilistic/double-counting/pigeon-hole methods. Making this a little more precise seems to require a lot of discussion, and may not even be possible, so let me stop here and move on with the examples of the proofs which became norm-al. They all involve <em>quasirandom groups </em><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>, but even non-quasirandom groups mix in a certain sense <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-group-mix">GV22</a>]</span> and the proofs there are again norm-al (it’s just that I don’t know of earlier proofs in this case).</p>
<p style="text-align: justify;">   The first example concerns the quintessential mixing result in this area: If you’ve got independent distributions <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>, and if each distribution is uniform over say a constant fraction of the group, then the the product <img alt="XY" class="latex" src="https://s0.wp.com/latex.php?latex=XY&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> (a.k.a. convolution, a.k.a. sample from each and output the product) is close to uniform over the entire group. A norm-al proof appears in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR3584096">Gow17</a>]</span> which also contains pointers to previous proofs.</p>
<p style="text-align: justify;">   The second is mixing of <em>three-term</em> progressions. A norml-al proof appears in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/innovations/BhangaleHR22">BHR22</a>]</span>. From their abstract: “Surprisingly, unlike the proofs of Tao and Peluse, our proof is elementary and only uses basic facts from nonabelian Fourier analysis.”</p>
<p style="text-align: justify;">   The third is <em>interleaved mixing</em>, see a recent <a href="https://www.ccs.neu.edu/home/viola/papers/DV-group-mix.pdf">preprint</a> with Derksen.</p>
<p style="text-align: justify;">   Moreover, in the second and third example the proofs are not only simpler,                                                                                                                                                        they are also more general in that they apply to any quasirandom group whereas previous proofs only applied to prominent special cases.</p>
<p style="text-align: justify;">   Why is all of this happening? One can only speculate that the reach of norml-al proofs in non-abelian Fourier analysis is still just emerging.</p>
<h3 class="likesectionHead"><a id="x1-1000"/>References</h3>
<p style="text-align: justify;">
</p><div class="thebibliography">
<p class="bibitem"><span class="biblabel">  [BHR22]<span class="bibsp">   </span></span><a id="XDBLP:conf/innovations/BhangaleHR22"/>Amey Bhangale, Prahladh Harsha, and Sourya Roy.  Mixing           of   3-term   progressions   in   quasirandom   groups.      In   Mark           Braverman,  editor,  ACM  Innovations  in  Theoretical  Computer           Science  conf. (ITCS),  volume  215  of  LIPIcs,  pages  20:1–20:9.           Schloss Dagstuhl – Leibniz-Zentrum f�r Informatik, 2022.</p>
<p class="bibitem"><span class="biblabel">  [Gow08] <span class="bibsp">   </span></span><a id="XGowers08"/>W. T.  Gowers.      Quasirandom  groups.      Combinatorics,           Probability &amp; Computing, 17(3):363–387, 2008.</p>
<p class="bibitem"><span class="biblabel">  [Gow17] <span class="bibsp">   </span></span><a id="XMR3584096"/>W. T. Gowers. Generalizations of Fourier analysis, and how to           apply them. Bull. Amer. Math. Soc. (N.S.), 54(1):1–44, 2017.</p>
<p class="bibitem"><span class="biblabel">  [GV22] <span class="bibsp">   </span></span><a id="XGowersV-group-mix"/>W. T.                                                                Gowers           and Emanuele Viola. Mixing in non-quasirandom groups. In ACM           Innovations in Theoretical Computer Science conf. (ITCS), 2022.</p>
<p class="bibitem"><span class="biblabel">  [Vio19] <span class="bibsp">   </span></span><a id="Xviola-SIGACT19"/>Emanuele           Viola. Non-abelian combinatorics and communication complexity.           SIGACT News, Complexity Theory Column, 50(3), 2019.</p>
</div></div>
    </content>
    <updated>2022-07-03T11:37:54Z</updated>
    <published>2022-07-03T11:37:54Z</published>
    <category term="Uncategorized"/>
    <category term="Behind the papers"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2022-07-07T08:38:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/093" rel="alternate" type="text/html"/>
    <title>TR22-093 |  More Verifier Efficient Interactive Protocols For Bounded Space | 

	Joshua Cook</title>
    <summary>Let $\mathbf{TISP}[T, S]$, $\mathbf{BPTISP}[T, S]$, $\mathbf{NTISP}[T, S]$, and $\mathbf{CoNTISP}[T, S]$  be the set of languages recognized by deterministic, randomized, nondeterminsitic, and co-nondeterministic algorithms, respectively, running in time $T$ and space $S$. Let $\mathbf{ITIME}[T_V]$ be the set of languages recognized by an interactive protocol where the verifier runs in time $T_V$. We prove:
$$\mathbf{TISP}[T, S] \cup \mathbf{BPTISP}[T, S] \subseteq \mathbf{ITIME}[\tilde{O}(\log(T) S + n)]$$
$$\mathbf{NTISP}[T, S] \cup \mathbf{CoNTISP}[T, S] \subseteq \mathbf{ITIME}[\tilde{O}(\log(T)^2 S + n)]$$
The prior most verifier time efficient interactive protocol for $\mathbf{TISP}$ uses ideas from Goldwasser, Kalai and Rothblum, which gives 
$$\mathbf{NTISP}[T, S] \subseteq \mathbf{ITIME}[\tilde{O}(\log(T) S^2 + n)].$$</summary>
    <updated>2022-07-03T07:09:54Z</updated>
    <published>2022-07-03T07:09:54Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/092" rel="alternate" type="text/html"/>
    <title>TR22-092 |  On correlation bounds against polynomials | 

	Emanuele Viola, 

	Peter Ivanov, 

	Liam Pavlovic</title>
    <summary>We study the fundamental challenge of exhibiting explicit functions that have small correlation with low-degree polynomials over $\mathbb{F}_{2}$. Our main contributions include:

1. In STOC 2020, CHHLZ introduced a new technique to prove correlation bounds. Using their technique they established new correlation bounds for low-degree polynomials. They conjectured that their technique generalizes to higher degree polynomials as well. We give a counterexample to their conjecture, in fact ruling out weaker parameters and showing what they prove is essentially the best possible. 

2. We advocate an alternative approach for proving correlation bounds with the central “mod functions,” consisting of proving two steps: (I) the polynomials that maximize correlation are symmetric, and (II) symmetric polynomials have small correlation. Contrary to related results in the literature, we conjecture that (I) is true. We argue that this approach is not affected by existing “barrier results.”

3. We prove our conjecture for quadratic polynomials. Specifically, we determine the maximum possible correlation between quadratic polynomials modulo 2 and the functions $(x_{1},\dots,x_{n})\to z^{\sum x_{i}}$ for any $z$ on the complex unit circle; and show that it is achieved by symmetric polynomials. To obtain our results we develop a new proof technique: we express correlation in terms of directional derivatives and analyze it by slowly restricting the direction.

4. We make partial progress on the conjecture for cubic polynomials, in particular proving tight correlation bounds for cubic polynomials whose degree-3 part is symmetric.</summary>
    <updated>2022-07-02T10:57:48Z</updated>
    <published>2022-07-02T10:57:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/091" rel="alternate" type="text/html"/>
    <title>TR22-091 |  Quasirandom groups enjoy interleaved mixing | 

	Emanuele Viola, 

	Harm Derksen</title>
    <summary>Let $G$ be a group such that any non-trivial representation has dimension
at least $d$. Let $X=(X_{1},X_{2},\ldots,X_{t})$ and $Y=(Y_{1},Y_{2},\ldots,Y_{t})$
be distributions over $G^{t}$. Suppose that $X$ is independent from
$Y$. We show that for any $g\in G$ we have
\[
\left|\mathbb{P}[X_{1}Y_{1}X_{2}Y_{2}\cdots X_{t}Y_{t}=g]-1/|G|\right|\le\frac{|G|^{2t-1}}{d^{t-1}}\sqrt{\mathbb{E}_{h\in G^{t}}X(h)^{2}}\sqrt{\mathbb{E}_{h\in G^{t}}Y(h)^{2}}.
\]
Our results generalize, improve, and simplify previous works.</summary>
    <updated>2022-07-02T10:48:08Z</updated>
    <published>2022-07-02T10:48:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2022/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Neil Sloane has a new blog (\(\mathbb{M}\)), subtitled “interesting sequences I need help with”. His first post concerns the two-up sequence, formed in steps where the kth step adds two numbers that are not already in the sequence and are relatively prime to the preceding k. Most of the terms appear to be the primes (in order). The remaining terms appear to be prime powers or semiprimes but this has not been proven.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://njas.blog/">Neil Sloane has a new blog</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@christianp/108487272201741871">\(\mathbb{M}\)</a>),</span> subtitled “interesting sequences I need help with”. <a href="https://njas.blog/2022/06/03/the-two-up-sequence-a090252/">His first post concerns the two-up sequence</a>, formed in steps where the kth step adds two numbers that are not already in the sequence and are relatively prime to the preceding k. Most of the terms appear to be the primes (in order). The remaining terms appear to be prime powers or semiprimes but this has not been proven.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Schwarz_lantern">Schwarz lantern</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108497292976963088">\(\mathbb{M}\)</a>),</span> a polyhedral cylindrical surface that you can fold from paper. As you make its triangles smaller relative to the cylinder size, it approximates the cylinder in distance, but not necessarily in surface area. This example became one of the original motivations for research on non-obtuse mesh generation algorithms, because its non-convergence to the correct area happens when its triangles are very obtuse. Now a Good Article on Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://rjlipton.wpcomstaging.com/2022/06/19/the-graph-of-ancestors/">The graph of ancestors</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108507916081000038">\(\mathbb{M}\)</a>).</span>  For Father’s Day, Ken Regan tries to find a more principled way of quantifying pedigree collapse (the unavoidable existence of inbreeding among one’s ancestors) than “implex”, the difference between \(2^k\) and the number of distinct 
\(k\)-step ancestors.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@johncarlosbaez/108504865028259313">John Baez describes the work of Hoàng Xuân Sính</a> (<a href="https://en.wikipedia.org/wiki/Ho%C3%A0ng_Xu%C3%A2n_S%C3%ADnh">see also</a>), a student of Grothendieck who became the first female mathematician in Vietnam.</p>
  </li>
  <li>
    <p><a href="https://www.torontomu.ca/canadian-conference-computational-geometry-2022/program/">Accepted papers to the 34th Canadian Conference on Computational Geometry</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108519879503501792">\(\mathbb{M}\)</a>),</span> to be held in August in Toronto. For mine, see recent blog posts on <a href="https://11011110.github.io/blog/2022/06/22/dehn-rank-revisited.html">Dehn rank</a>, <a href="https://11011110.github.io/blog/2022/06/24/reflections-octagonal-mirror.html">octagonal reflections</a>, and <a href="https://11011110.github.io/blog/2022/06/28/motion-bend-lines.html">flattening paper surfaces</a>. In other news, from looking at the web site, I see that the host university, formerly Ryerson, has changed its name: now it’s Toronto Metropolitan University.</p>
  </li>
  <li>
    <p><a href="https://www.sligocki.com/2022/06/21/bb-6-2-t15.html">Tetration in busy-beaver Turing machines</a> and <a href="https://cp4space.hatsya.com/2022/06/23/tetrational-machines/">in Conway’s Game of Life</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108533292912244512">\(\mathbb{M}\)</a>,</span> <a href="https://btm.qva.mybluehost.me/telling-the-tale-of-two-tetrations/">see also</a>).</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2022/06/paper-show-heron-arts/">Paper show</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108542378459285958">\(\mathbb{M}\)</a>):</span> Group art exhibit featuring 14 different artists who work in papercraft. Coming soon to a gallery in the Mission in San Francisco. Maybe the most geometric are the paper geodes of <a href="https://www.huntzliu.com/">Huntz Liu</a>.</p>
  </li>
  <li>
    <p>Two 3-regular penny graphs <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108546890027577211">\(\mathbb{M}\)</a>).</span> You can’t make these avoid triangles altogether (see <a href="https://doi.org/10.7155/jgaa.00463">my paper on triangle-free penny graphs</a>) but the larger one of these two avoids pairs of triangles that share an edge. It’s more difficult than it seems like it should be to get all of the pennies that should be touching to actually touch, and I didn’t entirely succeed, but I think the pattern is clear.</p>

    <p style="text-align: center;"><img alt="Two three-regular penny graphs, with vertices represented by pennies and edges represented by touching pennies" src="https://www.ics.uci.edu/~eppstein/pix/3regpen/3regular-penny-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Double_bubble_theorem">The double bubble theorem</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108551879168137037">\(\mathbb{M}\)</a>)</span> states that the minimum area enclosing two volumes looks like a double soap bubble, with three spherical patches meeting at \(120^\circ\) angles on a circle. Just after getting Wikipedia’s article to Good Article, I learned of significant progress: Milman and Neeman announced a proof of the triple bubble conjecture in all dimensions and related results. See <a href="https://arxiv.org/abs/2205.09102">their preprint</a> or <a href="https://amathr.org/milman-and-neeman/">Frank Morgan’s review</a>.</p>
  </li>
  <li>
    <p><a href="https://www.sixthtone.com/news/1010653/she-spent-a-decade-writing-fake-russian-history.-wikipedia-just-noticed.-">An elaborate hoax history of medieval Russian history is uncovered on the Chinese-language Wikipedia</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108563040999391348">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=31915937">via</a>, <a href="https://www.metafilter.com/195824/crumples-up-thesis-on-Kashin-silver-mine">mf</a>). Link goes to Chinese state media, but is in English; see also the <a href="https://en.wikipedia.org/wiki/Wikipedia:Fabricated_articles_and_hoaxes_of_Russia_in_2022">English Wikipedia internal report on the situation</a>.</p>
  </li>
  <li>
    <p><a href="http://www.ag.jku.at/geometrikum.shtml">Geometrikum</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108568817200153580">\(\mathbb{M}\)</a>):</span> geometric exhibits at the Institute for Applied Geometry of the University of Linz. Or, if you’re not near Linz, you can see them online. Includes string-art surfaces, Lego Stanford bunny and trefoil knot, some regular 4-polytope skeletons, papercraft polycubes and modular polyhedra, matchstick tetrastix, and more.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-06-30T16:23:00Z</updated>
    <published>2022-06-30T16:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-06-30T23:36:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/06/30/postdoc-at-the-institute-for-logic-language-and-computation-and-the-institute-for-information-law-at-the-university-of-amsterdam-apply-by-august-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/06/30/postdoc-at-the-institute-for-logic-language-and-computation-and-the-institute-for-information-law-at-the-university-of-amsterdam-apply-by-august-15-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at The Institute for Logic, Language and Computation and the Institute for Information Law at the University of Amsterdam (apply by August 15, 2022)</title>
    <summary>Do you have a PhD and are you interested in researching the law and regulation of cybersecurity, and in combining this with insights from ethics and economics? If you are excited about doing this kind of research in an interdisciplinary environment, with a team of friendly and enthusiastic colleagues, and with partners from the financial […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Do you have a PhD and are you interested in researching the law and regulation of cybersecurity, and in combining this with insights from ethics and economics? If you are excited about doing this kind of research in an interdisciplinary environment, with a team of friendly and enthusiastic colleagues, and with partners from the financial and governmental sectors, then you may want to join us.</p>
<p>Website: <a href="https://www.illc.uva.nl/NewsandEvents/News/Positions/newsitem/13758/Postdoctoral-Researcher-in-the-Regulation-of-Quantum-Safe-Technology">https://www.illc.uva.nl/NewsandEvents/News/Positions/newsitem/13758/Postdoctoral-Researcher-in-the-Regulation-of-Quantum-Safe-Technology</a><br/>
Email: s.deharo@uva.nl</p></div>
    </content>
    <updated>2022-06-30T09:54:00Z</updated>
    <published>2022-06-30T09:54:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-07-07T08:37:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/failure-directions/</id>
    <link href="https://gradientscience.org/failure-directions/" rel="alternate" type="text/html"/>
    <title>Distilling Model Failures as Directions in Latent Space</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><!-- <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> -->
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->









<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script> -->
<!-- <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script> -->


<!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
<!-- chart.js -->


<p><a class="bbutton" href="https://arxiv.org/abs/2206.14754" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/failure-directions" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Code
</a>
<br/></p>

<p><i>
Deep learning models often exhibit <strong>consistent</strong> patterns of errors. These errors tend to correspond to hard subpopulations in the data they are deployed on. How can we go about detecting such hard subpopulations, and moreover doing so at scale? Our <a href="https://arxiv.org/abs/2206.14754">recent paper</a> is motivated by this very aim, and presents a framework for automatic distillation and surfacing of a model’s failure modes.
</i></p>

<p>Despite the success of deep learning models at a wide range of classification tasks, they are prone to failing—often by underperforming on “hard” subpopulations corresponding to inputs that were consistently mislabelled, corrupted, or simply underrepresented in the training set. This problem is exacerbated when, as is often the case in practice, deployment conditions deviate from the training distribution. In these cases, the model may have learned (spurious) correlations on the training set that are not predictive on the distribution it is deployed on.</p>

<p>To make this more concrete, consider the task of predicting age (old vs young) based on the CelebA dataset of celebrity face images. It turns out that in this dataset, young women and old men are overrepresented, and thus a model trained on CelebA is likely to leverage the resulting correlation between age and gender in its predictions. Of course, as this correlation does not hold at large, this model would then struggle on inputs representing old women and young men.</p>

<p><img alt="CelebA-Summary" src="https://gradientscience.org/assets/corr-errs/images/celeba_summary.png" style="width: 100%;"/></p>

<p>How could we go about identifying these types of model errors? Specifically, for this case, how might we identify that it is the spurious age-gender correlation that is driving these failures?</p>

<p>One option is to manually examine either the <a href="https://arxiv.org/abs/2005.11295">dataset</a> or the <a href="https://arxiv.org/abs/2205.04596">model itself</a> to identify specific failure modes. Such approaches, however, can be quite labor-intensive, and thus are difficult to scale. Alternatively, one can try to automatically identify and intervene on hard training examples, such as by directly <a href="https://arxiv.org/abs/2107.09044">upweighting inputs</a> that were misclassified early in training or <a href="https://arxiv.org/abs/1805.12317">training a second model</a> to adversarially identify misclassified instances. However, these approaches also do not fully hit the mark. Specifically, they are not designed to elicit simple, human-interpretable patterns that underlie hard subpopulations (even when these exist). Thus, while such methods are automatic (and certainly scalable), they do not necessarily translate into the type of understanding needed to remedy the underlying data problem.</p>

<p>The framework developed in our <a href="https://arxiv.org/abs/2206.14754">recent work</a> intends to bridge this gap between scalability and interpretability. In particular, it enables us to surface subpopulations of hard examples with respect to a given model in a way that is not only automatic, but also naturally suggests an intervention meant to fix them.</p>

<h2 id="capturing-failure-modes-as-latent-space-directions">Capturing Failure Modes as Latent Space Directions</h2>
<p>At a high level, our approach aims to model failure modes as <em>directions</em> within a latent space. In the context of the CelebA example we described above, this would correspond to identifying a (separate) direction for each class (old/young) such that the easier examples (“old man”/”young women”) lie in one direction, and the harder examples (“old women”/”young man”) lie in the opposite one. As a result, each such direction would end up capturing the axis of the specific failure mode (here, gender) that the model struggles with.</p>

<p>But how can we learn such a direction to begin with? The key intuition is that, whenever the pattern of errors we aim to capture corresponds to a global failure mode, such as a spurious correlation, the model will make these errors <em>consistently</em>. In other words, the incorrectly classified inputs will share features. As a result, we can capture the pattern behind these mistakes by training a classifier on the feature embedding, which <em>predicts</em> when the model is likely to make an error on a given input.</p>

<p>More specifically, in our framework we train for each class (using a held-out validation set) a linear support vector machine (SVM) that predicts the errors of the original model. The decision boundary of this SVM then establishes a <em>hyperplane</em> separating the correct from the incorrect examples. Moreover, the vector orthogonal to this decision boundary (the normal vector of the hyperplane) represents the direction of the captured failure mode that we are seeking. Indeed, the more aligned an example is with the identified direction, the harder (or easier) the example was for the original model—this is exactly what we needed!</p>

<p>Of course, to make sure this trained SVM can indeed capture the features shared by the errors, we need a suitable featurization for the inputs. In our (image) context, we use <a href="https://arxiv.org/pdf/2103.00020.pdf">CLIP</a>, which embeds both vision and language together using contrastive learning. (As we will see below, using this embedding space has the added benefit of enabling us to automatically caption the captured failure modes, too!)</p>

<p><img alt="Summary" src="https://gradientscience.org/assets/corr-errs/images/updated_summary_fig.png" style="width: 100%;"/></p>
<div class="footnote">
Given our original model, for each class (here, ``old"), we train a SVM on a shared vision/language latent space to predict whether the original model would have classified an input correctly. We then extract a direction (in gray) for the captured failure mode, as the vector orthogonal to the corresponding learned hyperplane. Since the original model struggles on ``old female" faces, the SVM learns to use gender to separate the incorrect (shown in red) vs. correct (shown in green) examples.
</div>

<p><strong>Identifying the gender spurious correlation in CelebA</strong>: Let’s return to our example of identifying age for CelebA faces in the presence of a spurious correlation with gender, and apply our framework as described above. The plot below depicts the fraction of test images within each class that are of the minority gender when ordering the images by either their SVM decision value, or by our baseline of using the model’s confidences. We can see that the SVM directions indeed capture the gender-age spurious association, as intended.</p>

<p><img alt="CelebAPerformance" src="https://gradientscience.org/assets/corr-errs/figures/combined_frac_plot.png" style="width: 100%;"/></p>
<div class="footnote">
The fraction of test images for each class that are of the minority gender when ordering the images by either their SVM decision value or by the model’s confidences. The SVM flags a larger fraction of “incorrect" examples from the minority gender.
</div>

<h3 id="interpreting-the-extracted-failure-mode">Interpreting the extracted failure mode</h3>
<p>Now that we’ve distilled the model’s failure modes as directions within the latent space, how can we understand what these failure modes entail exactly?</p>

<p><strong>Most Aligned Examples.</strong> One approach is to simply surface the examples whose normalized embeddings are most aligned (or anti-aligned) with the extracted direction. These are the images with the most positive or negative SVM <em>decision value</em> (which is proportional to the signed distance from the decision boundary). In doing so, we surface the prototypical examples representing the “most correct” and “most incorrect” examples.</p>

<p><strong>Automatic Captioning.</strong> We can, however, go one step further by automatically captioning the extracted failure mode, leveraging the fact that the SVM was trained on a shared vision/language embedding space. Recall that CLIP embeds both images <em>and</em> language into the same latent space. Thus, just as we surfaced the most aligned <em>images</em> above, we can surface the most aligned <em>captions</em> (from some pre-specified set of captions) whose normalized text embedding matches the extracted direction. More details can be found in our <a href="https://arxiv.org/abs/2206.14754">paper</a>.</p>

<p>Both techniques are shown below on our running CelebA example. As we can see, images farthest from the SVM decision boundary indeed exemplify the hardest (“old woman”) or the easiest (“old man”) examples. The captions also reflect the corresponding categories.</p>

<p><img alt="CelebA-Examples" src="https://gradientscience.org/assets/corr-errs/figures/celeba_most_extreme_examples.png" style="width: 100%;"/></p>

<h2 id="man-with-a-fish-discovering-failure-modes-in-the-imagenet-dataset">Man with a Fish: Discovering Failure Modes in the ImageNet Dataset</h2>
<p>In the CelebA example we were considering so far, the dataset contained a <em>known</em>, planted spurious correlation (i.e., gender). How will our framework fare when this is not necessarily the case? To study this, let’s apply our framework to the ImageNet dataset (and see our <a href="https://arxiv.org/abs/2206.14754">paper</a> for more examples).</p>

<p>What does our framework flag? A broad range of interpretable failure modes—from color biases (e.g., the model struggles on red wolves with white winter coats) to reliance on co-occurring objects (e.g., the model more easily classifies the tench fish in the presence of a person).</p>

<div id="bias_examples_widget" style="overflow: auto; text-align: center;"/>
<div class="footnote">
     Images and captions with the most positive or negative SVM decision values for a given ImageNet class. (Click the thumbnails on the left to explore)
</div>

<p>Are the flagged subpopulations actually challenging for the original model? To check this, we would ideally compare the difference in test accuracy between the “easy” and “hard” subpopulations proposed by our framework. For example, in the above example of the tench fish, we would hope that tenches described by the “easy” caption (“a photo of an orange fish with a person”) have a higher accuracy on held-out examples than those described by the “hard” caption (“a photo of a close-up fish”).</p>

<p>However, we do not have annotations for the sub-groups of ImageNet necessary to execute this measurement directly. Still, as a proxy, we can use the CLIP shared vision/language embedding space to <em>approximate</em> these sub-group accuracies. So, for example, to evaluate the model’s performance on people with orange fish, we simply check its accuracy on the images whose CLIP embeddings are closest (in cosine distance) to the embedded SVM caption “a photo of an orange fish with a person”.</p>

<p>Performing this kind of evaluation for all the 1000 of ImageNet classes, we find that the original model’s accuracy on the images closest to the “hard caption” is consistently (and significantly) lower than those closest to the “easy caption.” In other words, our framework successfully surfaces the patterns of failure modes. Furthermore, as we describe in the <a href="https://arxiv.org/abs/2206.14754">paper</a>, these surfaced patterns guide effective interventions too.</p>

<h2 id="conclusion">Conclusion</h2>
<p>In this post, we introduced a framework for automatically identifying and captioning coherent subpopulations that are especially hard, or easy, for a given model to classify. In particular, our framework harnesses (linear) classifiers to distill the model’s failure modes as meaningful directions in the latent space. Our framework was able to surface challenging subpopulations in widely used datasets such as ImageNet: check out our <a href="https://arxiv.org/abs/2206.14754">paper</a> for even more examples (and datasets)!</p>

<p>Overall, we view our methodology as a first step toward building a toolkit for scalable dataset exploration and debiasing—we believe, however, that there is much more to do. For example, we consider only relatively straightforward data interventions (such as upweighting and filtering). Can we come up with more sophisticated interventions to improve the model’s performance on the identified subpopulations? In particular, given all the recent enormous progress on text-to-image generation, one especially  promising approach to explore here could be to generate new data that is tailored to the model’s weaknesses (for example, by using <a href="https://cdn.openai.com/papers/dall-e-2.pdf">DALL-E 2</a> or <a href="https://arxiv.org/pdf/2205.11487.pdf">ImageGen</a>).</p></div>
    </summary>
    <updated>2022-06-30T00:00:00Z</updated>
    <published>2022-06-30T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-07-06T22:45:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/06/29/workshop-on-sublinear-algorithms/</id>
    <link href="https://cstheory-events.org/2022/06/29/workshop-on-sublinear-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Sublinear Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">August 1-5, 2022 MIT https://fodsi.us/sublinear.html Foundations of Data Science Institute (FODSI) is organizing a workshop on Sublinear Algorithms. The workshop will be held on August 3-5 at MIT. It will cover topics in sublinear algorithms, including streaming algorithms, sketching algorithms, sublinear-time algorithms, property testing, local algorithms an​d related topics. The workshop will be preceded by … <a class="more-link" href="https://cstheory-events.org/2022/06/29/workshop-on-sublinear-algorithms/">Continue reading <span class="screen-reader-text">Workshop on Sublinear Algorithms</span></a></div>
    </summary>
    <updated>2022-06-29T10:55:06Z</updated>
    <published>2022-06-29T10:55:06Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-07-07T08:38:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2022-06-28-DAG-meets-BFT/</id>
    <link href="https://decentralizedthoughts.github.io/2022-06-28-DAG-meets-BFT/" rel="alternate" type="text/html"/>
    <title>DAG Meets BFT - The Next Generation of BFT Consensus</title>
    <summary>This post explains in simple words a recent development in the theory and practice of directed acyclic graph-based (DAG-based) Byzantine Fault Tolerance (BFT) consensus, published in three prestigious peer-reviewed conferences, and currently being integrating into several Blockchain companies, e.g., Aptos, Celo, MystenLabs, and Somelier. DAG-Rider: All You Need Is DAG...</summary>
    <updated>2022-06-28T18:00:00Z</updated>
    <published>2022-06-28T18:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2022-07-06T22:46:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3356810276237520801</id>
    <link href="http://blog.computationalcomplexity.org/feeds/3356810276237520801/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/06/a-gadget-for-3-colorings.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3356810276237520801" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/3356810276237520801" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/06/a-gadget-for-3-colorings.html" rel="alternate" type="text/html"/>
    <title>A Gadget for 3-Colorings</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Following up on Bill's <a href="https://blog.computationalcomplexity.org/2022/06/counting-number-of-3-colorings-of-graph.html">post earlier this week</a> on counting the number of 3-colorings, <a href="https://www.bbk.ac.uk/our-staff/profile/9044528/steven-noble">Steven Noble</a> emailed us with some updated information. The first proof that counting 3-colorings is #P-complete is in a <a href="https://doi.org/10.1137/0607036">1986 paper</a> by Nati Linial. That proof uses a Turing reduction using polynomials based on posets.</p><p>Steven points to a <a href="https://ora.ox.ac.uk/objects/uuid:52070098-14fa-4cf1-ae6e-9f9ce6a626d8">1994 thesis</a> of James Annan under the direction of Dominic Welsh at Oxford that gives the gadget construction that I so tried and failed to do in Bill's post.</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQlZ3z-rTCsgF-c7yTH6CuPV6eUG5aFEZjaFFEiy_Z1mjB0EedHG3DsqJtRqWLaSvA6tC2ALi4G-r3GTgI_4ErkfpITXGIr7gNcXUEZtuBUjYdBfyYfN2EyV5zv0j7e5SEJ7YnlUyqLpuO01WF6xVyOIOXTldVJJ9-ps5rqUaa25SVdb6-Rg/s925/3col%20gadget.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="370" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiQlZ3z-rTCsgF-c7yTH6CuPV6eUG5aFEZjaFFEiy_Z1mjB0EedHG3DsqJtRqWLaSvA6tC2ALi4G-r3GTgI_4ErkfpITXGIr7gNcXUEZtuBUjYdBfyYfN2EyV5zv0j7e5SEJ7YnlUyqLpuO01WF6xVyOIOXTldVJJ9-ps5rqUaa25SVdb6-Rg/w400-h370/3col%20gadget.png" width="400"/></a></div><div style="text-align: left;"/>Think of color 0 as false and color 1 as true and use this gadget in place of the OR-gadgets in the regular NP-complete proof of 3-coloring. I checked all eight values of a, b and c and the gadget works as promised.<div><br/></div><div><a href="https://en.wikipedia.org/wiki/James_Annan">James Annan</a> later became a climate scientist and co-founded <a href="https://bskiesresearch.wordpress.com/">Blue Skies Research</a> in the UK. </div><div><br/></div><div><div>Steven also noted that counting 2-colorings is easy, because for each connected component, there are either 0 or 2 colorings.</div></div></div>
    </content>
    <updated>2022-06-28T16:52:00Z</updated>
    <published>2022-06-28T16:52:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-07-07T00:20:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/06/28/motion-bend-lines</id>
    <link href="https://11011110.github.io/blog/2022/06/28/motion-bend-lines.html" rel="alternate" type="text/html"/>
    <title>The motion of bend lines on smooth surfaces</title>
    <summary>You may have played with a paper yoyo, a strip of paper wrapped around a stick so that when you flick it with your wrist, it extends outward into a long tube. Here’s one, the only example I could find on Wikimedia Commons:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>You may have played with a paper yoyo, a strip of paper wrapped around a stick so that when you flick it with your wrist, it extends outward into a long tube. Here’s one, <a href="https://commons.wikimedia.org/wiki/File:Arcade_Paper_Laser,_August_8th_2016.jpeg">the only example I could find on Wikimedia Commons</a>:</p>

<p style="text-align: center;"><img alt="Arcade Paper Laser, public domain image by Zhonghua88, 8 August 2016, from Wikimedia Commons" src="https://11011110.github.io/blog/assets/2022/paper-yoyo.jpg" style="width: 100%;"/></p>

<p>If you’ve used one, then the way they work is simple and intuitive. But if you know a little bit about the <a href="https://en.wikipedia.org/wiki/Mathematics_of_paper_folding">mathematics of paper folding</a> and <a href="https://en.wikipedia.org/wiki/Developable_surface">developable surfaces</a>, and think about it, it starts to seem a little strange.</p>

<p>Paper can bend or fold, but not stretch. When a flat sheet of paper is bent into a smooth but not flat surface (as it is in all states of the paper yoyo), it bends along straight “bend lines” that extend all the way across the surface, and that are forced to remain straight. You may be familiar with the way that a slice of pizza will droop if you try to hold it flat from its crust, but will remain straight if you bend it lengthwise: the bend lines are holding it in a rigid shape. Or, if you roll a poster into a cylinder, you can wave it around like a light saber, again making it much more rigid than the unrolled poster (at least until you hit it into something hard enough to crumple it).</p>

<p>In the rolled-up state of the paper yoyo, it’s again rolled into a cylinder, with bend lines parallel to the cylinder axis. If we mark some of those bend lines and unroll it flat, it might look something like this:</p>

<p style="text-align: center;"><img alt="Bend lines in a rolled paper yoyo" src="https://11011110.github.io/blog/assets/2022/paper-yoyo-rolled.svg" style="width: 100%;"/></p>

<p>But then, what happens when you extend it? The paper cannot stretch from its rectangular shape into a parallelogram. Instead, as it extends, the bend lines continuously rotate on the surface of the paper. Near the point where they attach to the stick, the non-perpendicular bend lines cause the paper to flare out a little from its cylindrical shape, but it is surrounded by more wrapped paper constraining it from flaring very widely, so the bend lines must still stay near their original orientations. Farther along the yoyo, the bend lines can twist to bigger angles:</p>

<p style="text-align: center;"><img alt="Bend lines in a rolled paper yoyo" src="https://11011110.github.io/blog/assets/2022/paper-yoyo-extended.svg" style="width: 100%;"/></p>

<p>So although the bend lines of a smoothly bent sheet of paper are rigid along their length, they can slide and twist continuously within the sheet, as the sheet flexes continuously while remaining smooth. This twisting motion of bend lines is essential for understanding the seemingly-knotted surface below, two round disks connected by a thin band tied in an overhand knot:</p>

<p style="text-align: center;"><img alt="Knotted paper dumbbell shape" src="https://11011110.github.io/blog/assets/2022/knotted-dumbbell.svg"/></p>

<p>If you want to unknot it while keeping it smooth rather than crumpling it, you will obviously have to make the disks smaller by rolling them up somehow, perhaps into a cylinder around one of their diameters. But if you do that, you will put a bend line through or near the diameter, which will act like a rigid rod. And if you attach the knotted center band to two rigid rods, of length equal to the diameter of the disks, you definitely cannot untie it. The rods are too long to poke all the way through the knot before getting stuck.</p>

<p>On the other hand, this surface can be untied while keeping it smooth! The trick is that, after you have rolled up one of the disks to make a rigid cylinder, with the tied band at one end, you can twist the roll, so that its bend lines rotate around the disk. As you do, the point where the band is tied will slide from one end of the cylinder to the other. And you can make this sliding motion coincide with the motion of the cylinder through a hole in the tied band, untying it.</p>

<p>This and similar examples are the focus of my third new CCCG preprint, “Locked and unlocked smooth embeddings of surfaces”, <a href="https://arxiv.org/abs/2206.12989">arXiv:2206.12989</a>. In the phrasing of the title, the two disks with a tied center band, above, are unlocked: they can be reconfigured to a flat state while remaining smooth. My paper also shows that any compact shape with a continuous shrinking motion into itself, like the polygon below, is unlocked.</p>

<p style="text-align: center;"><img alt="Polygon with a continuous shrinking motion" src="https://11011110.github.io/blog/assets/2022/generalized-star.svg" style="width: 100%;"/></p>

<p>On the other hand, there exist surfaces that, while topologically equivalent to their flat state, cannot be made flat through a continuous sequence of smooth embeddings. The simplest one that I found consists of a central square mat, rolled up into a cylinder and held into its cylindrical shape by two loops, entangled with each other in a pattern based on the Borromean rings:</p>

<p style="text-align: center;"><img alt="Locked shape consisting of a rolled square mat with two entangled loops" src="https://11011110.github.io/blog/assets/2022/tied-roll.svg"/></p>

<p>There is actually quite a lot of freedom in the pattern of bend lines of the central square. They can twist until the bend line through the center of the square gets halfway to the corners of the square:</p>

<p style="text-align: center;"><img alt="Twisted bend lines in the rolled square mat" src="https://11011110.github.io/blog/assets/2022/bent-roll.svg"/></p>

<p>But after that point, the entangled loops block the twisting from going any farther. They cannot be disentangled from each other without being pulled around the rigid central bend line, and they are too short for that to be possible, so the surface is locked.</p>

<p>It’s not clear to me whether all simple polygons are unlocked, or whether it’s possible to make locked polygons without holes. I also don’t have any algorithmic results in this area; it seems likely that testing whether a surface is locked or unlocked is hard, but I don’t know how to prove it.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108557742866716208">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-06-28T16:25:00Z</updated>
    <published>2022-06-28T16:25:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-06-30T23:36:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6524</id>
    <link href="https://scottaaronson.blog/?p=6524" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6524#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6524" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Steven Pinker and I debate AI scaling!</title>
    <summary xml:lang="en-US">Before June 2022 was the month of the possible start of the Second American Civil War, it was the month of a lively debate between Scott Alexander and Gary Marcus about the scaling of large language models, such as GPT-3.  Will GPT-n be able to do all the intellectual work that humans do, in the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Before June 2022 was the month of the possible start of the Second American Civil War, it was the month of <a href="https://astralcodexten.substack.com/p/my-bet-ai-size-solves-flubs?s=w">a</a> <a href="https://garymarcus.substack.com/p/what-does-it-mean-when-an-ai-fails">lively</a> <a href="https://astralcodexten.substack.com/p/somewhat-contra-marcus-on-ai-scaling">debate</a> <a href="https://garymarcus.substack.com/p/does-ai-really-need-a-paradigm-shift?s=w">between</a> Scott Alexander and Gary Marcus about the scaling of large language models, such as <a href="https://en.wikipedia.org/wiki/GPT-3">GPT-3</a>.  Will GPT-<em>n</em> be able to do all the intellectual work that humans do, in the limit of large <em>n</em>?  If so, should we be impressed?  Terrified?  Should we dismiss these language models as mere “stochastic parrots”?</p>



<p>I was privileged to be part of various email exchanges about those same questions with Steven Pinker, Ernest Davis, Gary Marcus, Douglas Hofstadter, and Scott Alexander.  It’s fair to say that, overall, Pinker, Davis, Marcus, and Hofstadter were more impressed by GPT-3’s blunders, while we Scotts were more impressed by its abilities.  (On the other hand, Hofstadter, more so than Pinker, Davis, or Marcus, said that he’s terrified about how powerful GPT-like systems will become in the future.)</p>



<p>Anyway, at some point Pinker produced an essay setting out his thoughts, and asked whether “either of the Scotts” wanted to share it on our blogs.  Knowing an intellectual scoop when I see one, I answered that I’d be honored to host Steve’s essay—along with my response, along with Steve’s response to <em>that</em>.  To my delight, Steve immediately agreed.  Enjoy!  –SA</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2><strong>Steven Pinker’s Initial Salvo</strong></h2>



<p>Will future deep learning models with more parameters and trained on more examples avoid the <a href="https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/">silly blunders</a> which Gary Marcus and Ernie Davis entrap GPT into making, and render their criticisms obsolete?  And if they keep exposing new blunders in new models, would this just be <a href="https://astralcodexten.substack.com/p/my-bet-ai-size-solves-flubs?s=r">moving the goalposts</a>?  Either way, what’s at stake?</p>



<p>It depends very much on the question.  There’s the cognitive science question of whether humans think and speak the way GPT-3 and other deep-learning neural network models do.  And there’s the engineering question of whether the way to develop better, humanlike AI is to upscale deep learning models (as opposed to incorporating different mechanisms, like a knowledge database and propositional reasoning).</p>



<p>The questions are, to be sure, related: If a model is incapable of duplicating a human feat like language understanding, it can’t be a good theory of how the human mind works.  Conversely, if a model flubs some task that humans can ace, perhaps it’s because it’s missing some mechanism that powers the human mind.  Still, they’re not the same question: As with airplanes and other machines, an artificial system can duplicate or exceed a natural one but work in a different way.</p>



<p>Apropos the scientific question, I don’t see the Marcus-Davis challenges as benchmarks or long bets that they have to rest their case on.  I see them as scientific probing of an empirical hypothesis, namely whether the human language capacity works like GPT-3.  Its failures of common sense are one form of evidence that the answer is “no,” but there are others—for example, that it needs to be trained on half a trillion words, or about 10,000 years of continuous speech, whereas human children get pretty good after 3 years.  Conversely, it needs no social and perceptual context to make sense of its training set, whereas children do (hearing children of deaf parents don’t learn spoken language from radio and TV).  Another diagnostic is that baby-talk is very different from the output of a partially trained GPT.  Also, humans can generalize their language skill to express their intentions across a wide range of social and environmental contexts, whereas GPT-3 is fundamentally a text extrapolator (a task, incidentally, which humans aren’t particularly good at).  There are surely other empirical probes, limited only by scientific imagination, and it doesn’t make sense in science to set up a single benchmark for an empirical question once and for all.  As we learn more about a phenomenon, and as new theories compete to explain it, we need to develop more sensitive instruments and more clever empirical tests.  That’s what I see Marcus and Davis as doing.</p>



<p>Regarding the second, engineering question of whether scaling up deep-learning models will “get us to Artificial General Intelligence”: I think the question is probably ill-conceived, because I think the concept of “general intelligence” is meaningless.  (I’m not referring to the psychometric variable <em>g</em>, also called “general intelligence,” namely the principal component of correlated variation across IQ subtests.  This is  a variable that aggregates many contributors to the brain’s efficiency such as cortical thickness and neural transmission speed, but it is not a mechanism (just as “horsepower” is a meaningful variable, but it doesn’t explain how cars move.)  I find most characterizations of AGI to be either circular (such as “smarter than humans in every way,” begging the question of what “smarter” means) or mystical—a kind of omniscient, omnipotent, and clairvoyant power to solve any problem.  No logician has ever outlined a normative model of what general intelligence would consist of, and even Turing swapped it out for the problem of fooling an observer, which spawned 70 years of unhelpful reminders of how easy it is to fool an observer.</p>



<p>If we do try to define “intelligence” in terms of mechanism rather than magic, it seems to me it would be something like “the ability to use information to attain a goal in an environment.”  (“Use information” is shorthand for performing computations that embody laws that govern the world, namely logic, cause and effect, and statistical regularities.  “Attain a goal” is shorthand for optimizing the attainment of <em>multiple</em> goals, since different goals trade off.)  Specifying the goal is critical to any definition of intelligence: a given strategy in basketball will be intelligent if you’re trying to win a game and stupid if you’re trying to throw it.  So is the environment: a given strategy can be smart under NBA rules and stupid under college rules.</p>



<p>Since a goal itself is neither intelligent or unintelligent (Hume and all that), but must be exogenously built into a system, and since no physical system has clairvoyance for all the laws of the world it inhabits down to the last butterfly wing-flap, this implies that there are as many intelligences as there are goals and environments.  There will be no omnipotent superintelligence or wonder algorithm (or singularity or AGI or existential threat or foom), just better and better gadgets.</p>



<p>In the case of humans, natural selection has built in multiple goals—comfort, pleasure, reputation, curiosity, power, status, the well-being of loved ones—which may trade off, and are sometimes randomized or inverted in game-theoretic paradoxical tactics.  Not only does all this make psychology hard, but it makes human intelligence a dubious benchmark for artificial systems.  Why would anyone <em>want </em>to emulate human intelligence in an artificial system (any more than a mechanical engineer would want to duplicate a human body, with all its fragility)?  Why not build the best possible autonomous vehicle, or language translator, or dishwasher-emptier, or baby-sitter, or protein-folding predictor?  And who cares whether the best autonomous vehicle driver would be, out of the box, a good baby-sitter?  Only someone who thinks that intelligence is some all-powerful elixir.</p>



<p>Back to GPT-3, DALL-E, LaMDA, and other deep learning models: It seems to me that the question of whether or not they’re taking us closer to “Artificial General Intelligence” (or, heaven help us, “sentience”) is based not on any analysis of what AGI would consist of but on our being gobsmacked by what they can do.  But refuting our intuitions about what a massively trained, massively parameterized network is capable of (and I’ll admit that they refuted mine) should not be confused with a path toward omniscience and omnipotence.  GPT-3 is unquestionably awesome at its designed-in goal of extrapolating text.  But that is not the main goal of human language competence, namely expressing and perceiving intentions.  Indeed, the program is not even set up to input or output intentions, since that would require deep thought about how to represent intentions, which went out of style in AI as the big-data/deep-learning hammer turned every problem into a nail.  That’s why no one is using GPT-3 to answer their email or write an article or legal brief (except to show how well the program can spoof one).</p>



<p>So is Scott Alexander right that every scaled-up GPT-<em>n</em> will avoid the blunders that Marcus and Davis show in GPT-(<em>n</em>-1)?  Perhaps, though I doubt it, for reasons that Marcus and Davis explain well (in particular, that astronomical training sets at best compensate for their being crippled by the lack of a world model).  But even if they do, that would show neither that human language competence is a GPT (given the totality of the relevant evidence) nor that GPT-<em>n</em> is approaching Artificial General Intelligence (whatever that is).</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2><strong>Scott Aaronson’s Response</strong></h2>



<p>As usual, I find Steve crystal-clear and precise—so much so that we can quickly dispense with the many points of agreement.  Basically, one side says that, while GPT-3 is of course mind-bogglingly impressive, and while it refuted confident predictions that no such thing would work, in the end it’s just a text-prediction engine that will run with any absurd premise it’s given, and it fails to model the world the way humans do.  The other side says that, while GPT-3 is of course just a text-prediction engine that will run with any absurd premise it’s given, and while it fails to model the world the way humans do, in the end it’s mind-bogglingly impressive, and it refuted confident predictions that no such thing would work.</p>



<p>All the same, I do think it’s possible to identify a substantive disagreement between the distinguished baby-boom linguistic thinkers and the gen-X/gen-Y blogging Scott A.’s: namely, whether there’s a coherent concept of “general intelligence.”  Steve writes:</p>



<blockquote class="wp-block-quote"><p>No logician has ever outlined a normative model of what general intelligence would consist of, and even Turing swapped it out for the problem of fooling an observer, which spawned 70 years of unhelpful reminders of how easy it is to fool an observer.</p></blockquote>



<p>I freely admit that I have no principled definition of “general intelligence,” let alone of “superintelligence.”  To my mind, though, there’s a simple proof-of-principle that there’s <em>something</em> an AI could do that pretty much any of us would call “superintelligent.”  Namely, it could say whatever Albert Einstein would say in a given situation, while thinking a thousand times faster.  Feed the AI all the information about physics that the historical Einstein had in 1904, for example, and it would discover special relativity in a few hours, followed by general relativity a few days later.  Give the AI a year, and it would think … well, whatever thoughts Einstein would’ve thought, if he’d had a millennium in peak mental condition to think them.</p>



<p>If nothing else, this AI could work by simulating Einstein’s brain neuron-by-neuron—provided we believe in the computational theory of mind, as I’m assuming we do.  It’s true that we don’t <em>know</em> the detailed structure of Einstein’s brain in order to simulate it (we might have, had the pathologist who <a href="https://harpers.org/archive/1997/10/driving-mr-albert/">took it</a> from the hospital used cold rather than warm formaldehyde).  But that’s irrelevant to the argument.  It’s also true that the AI won’t experience the same environment that Einstein would have—so, alright, imagine putting it in a very comfortable simulated study, and letting it interact with the world’s flesh-based physicists.  A-Einstein can even propose experiments for the human physicists to do—he’ll just have to wait an <em>excruciatingly</em> long subjective time for their answers.  But that’s OK: as an AI, he never gets old.</p>



<p>Next let’s throw into the mix AI Von Neumann, AI Ramanujan, AI Jane Austen, even AI Steven Pinker—all, of course, sped up 1,000x compared to their meat versions, even able to interact with thousands of sped-up copies of themselves and other scientists and artists.  Do we agree that these entities quickly become the predominant intellectual force on earth—to the point where there’s little for the original humans left to do but understand and implement the AIs’ outputs (and, of course, eat, drink, and enjoy their lives, assuming the AIs can’t or don’t want to prevent that)?  If so, then that seems to suffice to call the AIs “superintelligences.”  Yes, <em>of course</em> they’re still limited in their ability to manipulate the physical world.  Yes, <em>of course</em> they still don’t optimize arbitrary goals.  All the same, these AIs have effects on the real world consistent with the sudden appearance of beings able to run intellectual rings around humans—not <em>exactly</em> as we do around chimpanzees, but not exactly unlike it either.</p>



<p>I should clarify that, in practice, I don’t expect AGI to work by slavishly emulating humans—and not only because of the practical difficulties of scanning brains, especially deceased ones.  Like with airplanes, like with existing deep learning, I expect future AIs to take some inspiration from the natural world but also to depart from it whenever convenient.  The point is that, since there’s <em>something</em> that would plainly count as “superintelligence,” the question of whether it can be achieved is therefore “merely” an engineering question, not a philosophical one.</p>



<p>Obviously I don’t know the answer to the engineering question: no one does!  One could consistently hold that, while the thing I described would clearly count as “superintelligence,” it’s just an amusing fantasy, unlikely to be achieved for millennia if ever.  One could hold that all the progress in AI so far, including the scaling of language models, has taken us only 0% or perhaps 0.00001% of the way toward superintelligence so defined.</p>



<p>So let me make two comments about the engineering question.  The first is that there’s good news here, at least epistemically: unlike with the philosophical questions, we’re virtually guaranteed more clarity over time!  Indeed, we’ll know vastly more just by the end of this decade, as the large language models are further scaled and tweaked, and we find out whether they develop effective representations of the outside world and of themselves, the ability to reject absurd premises and avoid self-contradiction, or even the ability to generate original mathematical proofs and scientific hypotheses.  Of course, Gary Marcus and Scott Alexander have already placed concrete bets on the table for what sorts of things will be possible by 2030.  For all their differences in rhetoric, I was struck that their <a href="https://astralcodexten.substack.com/p/somewhat-contra-marcus-on-ai-scaling">actual</a> <a href="https://garymarcus.substack.com/p/does-ai-really-need-a-paradigm-shift?s=w#footnote-anchor-1">probabilities</a> differed much more modestly.</p>



<p>So then what explains the glaring differences in rhetoric?  This brings me to my second comment: whenever there’s a new, rapidly-growing, poorly-understood phenomenon, whether it’s the Internet or AI or COVID, there are two wildly different modes of responding to it, which we might call “February 2020 mode” and “March 2020 mode.”  In February 2020 mode, one says: yes, a naïve extrapolation might lead someone to the conclusion that this new thing is going to expand exponentially and conquer the world, dramatically changing almost every other domain—but precisely <em>because</em> that conclusion seems absurd on its face, it’s our responsibility as serious intellectuals to articulate what’s wrong with the arguments that lead to it.  In March 2020 mode, one says: holy crap, the naïve extrapolation seems right!  Prepare!!  Why didn’t we start earlier?</p>



<p>Often, to be sure, February 2020 mode is the better mode, at least for outsiders—as with the Y2K bug, or the many disease outbreaks that fizzle.  My point here is simply that February 2020 mode and March 2020 mode differ by only a month.  Sometimes hearing a single argument, seeing a single example, is enough to trigger an epistemic cascade, causing all the same facts to be seen in a new light.  As a result, reasonable people might find themselves on opposite sides of the chasm even if they started just a few steps from each other.</p>



<p>As for me?  Well, I’m currently trying to hold the line around February 26, 2020.  Suspending my day job in the humdrum, pedestrian field of quantum computing, I’ve decided to spend a year at OpenAI, thinking about the theoretical foundations of AI safety.  But for now, only a year.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2><strong>Steven Pinker’s Response to Scott</strong></h2>



<p>Thanks, Scott, for your thoughtful and good-natured reply, and for offering me the opportunity to respond  in <em>Shtetl-Optimized, </em>one of my favorite blogs. Despite the areas of agreement, I still think that discussions of AI and its role in human affairs—including AI safety—will be muddled as long as the writers treat intelligence as an undefined superpower rather than a mechanisms with a makeup that determines what it can and can’t do. We won’t get clarity on AI if we treat the “I” as “whatever fools us,” or “whatever amazes us,” or “whatever IQ tests measure,” or “whatever we have more of than animals do,” or “whatever Einstein has more of than we do”—and then start to worry about a superintelligence that has much, much more of whatever that is.</p>



<p>Take Einstein sped up a thousandfold. To begin with, current AI is not even taking us in that direction. As you note, no one is reverse-engineering his connectome, and current AI does not think the way Einstein thought, namely by visualizing physical scenarios and manipulating mathematical equations. Its current pathway would be to train a neural network with billions of physics problems and their solutions and hope that it would soak up the statistical patterns.</p>



<p>Of course, the reason you pointed to a sped-up Einstein was to procrastinate having to define “superintelligence.” But if intelligence is a collection of mechanisms rather than a quantity that Einstein was blessed with a lot of, it’s not clear that just speeding him up would capture what anyone would call superintelligence. After all, in many areas Einstein was no Einstein. You above all could speak of his not-so-superintelligence in quantum physics, and when it came world affairs, in the early 1950s he offered the not exactly prescient or practicable prescription, “Only the creation of a world government can prevent the impending self-destruction of mankind.” So it’s not clear that we <em>would </em>call a system that could dispense such pronouncements in seconds rather than years “superintelligent.” Nor with speeding up other geniuses, say, an AI Bertrand Russell, who would need just nanoseconds to offer his own solution for world peace: the Soviet Union would be given an ultimatum that unless it immediately submitted to world government, the US (which at the time had a nuclear monopoly) would bomb it with nuclear weapons.</p>



<p>My point isn’t to poke retrospective fun at brilliant men, but to reiterate that brilliance itself is not some uncanny across-the-board power that can be “scaled” by speeding it up or otherwise; it’s an engineered system that does particular things in particular ways. Only with a <em>criterion </em>for intelligence can we say which of these counts as intelligent.</p>



<p>Now, it’s true that raw speed makes new kinds of computation possible, and I feel silly writing this to you of all people, but speeding a process up by a constant factor is of limited use with problems that are exponential, as the space of possible scientific theories, relative to their complexity, must be. Speeding up a search in the space of theories a thousandfold would be a rounding error in the time it took to find a correct one. Scientific progress depends on the search exploring the infinitesimal fraction of the space in which the true theories are likely to lie, and this depends on the quality of the intelligence, not just its raw speed.</p>



<p>And it depends as well on a phenomenon you note, namely that scientific progress depends on empirical discovery, not deduction from a silicon armchair. The particle accelerators and space probes and wet labs and clinical trials still have to be implemented, with data accumulating at a rate set by the world. Strokes of genius can surely speed up the rate of discovery, but in the absence of omniscience about every particle, the time scale will still be capped by empirical reality. And this in turn directs the search for viable theories: which part of the space one should explore is guided by the current state of scientific knowledge, which depends on the tempo of discovery. Speeding up scientists a thousandfold would not speed up science a thousandfold.</p>



<p>All this is relevant to AI safety. I’m all for safety, but I worry that the dazzling intellectual capital being invested in the topic will not make us any safer if it begins with a woolly conception of intelligence as a kind of wonder stuff that you can have in different amounts. It leads to unhelpful analogies, like “exponential increase in the number of infectious people during a pandemic” ≈ “exponential increase in intelligence in AI systems.” It encourages other questionable extrapolations from the human case, such as imagining that an intelligent tool will develop an alpha-male lust for domination. Worst of all, it may encourage misconceptions of AI risk itself, particularly the standard scenario in which a hypothetical future AGI is given some preposterously generic single goal such as “cure cancer” or “make people happy” and theorists fret about the hilarious collateral damage that would ensue.</p>



<p>If intelligence is a mechanism rather than a superpower, the real dangers of AI come into sharper focus. An AI system designed to replace workers may cause mass unemployment; a system designed to use data to sort people may sort them in ways we find invidious; a system designed to fool people may be exploited to fool them in nefarious ways; and as many other hazards as there are AI systems. These dangers are not conjectural, and I suspect each will have to be mitigated by a different combination of policies and patches, just like other safety challenges such as falls, fires, and drownings. I’m curious whether, once intelligence is precisely characterized, any abstract theoretical foundations of AI safety will be useful in dealing with the actual AI dangers that will confront us.</p></div>
    </content>
    <updated>2022-06-28T04:00:23Z</updated>
    <published>2022-06-28T04:00:23Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-07-05T16:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8429</id>
    <link href="https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/" rel="alternate" type="text/html"/>
    <title>Injecting some numbers into the AGI debate</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Yet another “philosophizing” post, but one with some actual numbers. –Boaz] Recently there have been many debates on “artificial general intelligence” (AGI) and whether or not we are close to achieving it by scaling up our current AI systems. In this post, I’d like to make this debate a bit more quantitative by trying to … <a class="more-link" href="https://windowsontheory.org/2022/06/27/injecting-some-numbers-into-the-agi-debate/">Continue reading <span class="screen-reader-text">Injecting some numbers into the AGI debate</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Yet another <a href="https://windowsontheory.org/category/philosophizing/">“philosophizing”</a> post, but one with some actual numbers. –Boaz]</em></p>



<p>Recently there have been many debates on “artificial general intelligence” (AGI) and whether or not we are close to achieving it by scaling up our current AI systems. In this post, I’d like to make this debate a bit more quantitative by trying to understand what “scaling” would entail. The calculations are very rough – think of a post-it that is stuck on the back of an envelope. But I hope that this can be at least a starting point for making these questions more concrete.</p>



<p>The first problem is that there is no agreement on what “artificial general intelligence” means.  People use this term to mean anything between the following possibilities: </p>



<ol><li>Existence of a system that can meet benchmarks such as getting a perfect score on the SAT and IQ tests and passing a “Turing test.”  This is more or less the definition used by <a href="https://www.metaculus.com/questions/4815/date-of-first-agi-according-to-forecasters/">Metaculus</a> (though they recently updated it to a <a href="https://www.metaculus.com/questions/5121/date-of-general-ai/">stricter version</a>).</li><li>Existence of a system that can replace many humans in terms of economic productivity. For concreteness, say that it can function as an above-average worker in many industries. (To sidestep the issue of robotics, we can restrict our attention to remote-only jobs.)</li><li>Large-scale deployment of AI, replacing or radically changing the nature of work of a large fraction of people. </li><li>More extreme scenarios such as consciousness, malice, and super-intelligence. For example, a system that is conscious/sentient enough to be awarded human rights and <a href="https://www.theguardian.com/technology/2022/jun/12/google-engineer-ai-bot-sentient-blake-lemoine">its own attorney</a>, or malicious enough to <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">order DNA off the Internet, build a nanofactory to construct a diamondoid bacteria riding on miniature rockets, so they enter the bloodstream of all humans and kills everyone instantly, while not being detected</a>.</li></ol>



<p>I consider the first scenario– passing IQ tests or even a Turing test– more of a “parlor trick” than actual intelligence.  The history of artificial intelligence is one of <em>underestimating</em> future achievements on specific benchmarks, but also one of <em>overestimating</em> the broader implications of those benchmarks. Early AI researchers were not only wrong about how long it will take for a computer program to become the world chess champion, but they also wrongly assumed that such a program would have to be generally intelligent as well. In a 1970 interview, Minsky was <a href="https://www.sciencedirect.com/science/article/abs/pii/S0065245808604088">quoted</a> as saying that by the end of the 1970s, <em>“we will have a machine with the general intelligence of an average human being … able to read Shakespeare, grease a car, play office politics, tell a joke, have a fight. At that point, the machine will begin to educate itself with fantastic speed. In a few months, it will be at genius level, and a few months after, its powers will be incalculable…  In the interests of efficiency, cost-cutting, and speed of reaction, the Department of Defense may well be forced more and more to surrender human direction of military policies to machines.”</em> </p>



<p>Brooks <a href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">explains</a> that early AI researchers thought intelligence was “best characterized as the things that highly educated male scientists found challenging.” Since playing championship-level chess was hard for them, they couldn’t imagine a machine doing it without doing all other tasks that they considered more trivial. Getting a high SAT or IQ exam score is no more meaningful (for machines or humans) than doing well in chess. </p>



<p>The fourth scenario is, at the moment, too speculative for quantitative discussion and hence less appropriate for this post  (though see the addendum below).  We will focus on the second and third scenarios, which are necessary stepping stones for the more extreme fourth option. For the sake of concreteness, I will make the optimistic assumption that “scale is all you need” to achieve either of these scenarios. I will then try to see our best estimates on <strong>how much scale</strong> and <strong>at what cost</strong>.</p>



<p>The point of this post is not to argue that we will never achieve scenarios 2 or 3. Instead, it is to try to get quantitative estimates on challenges we would need to overcome to do so. I believe it is possible, but it would be more than just getting better hardware. </p>



<p>This is a long post. If I had to <strong>TL;DR</strong> it, I would say that we have significant uncertainty on how much scale we need for AGI. Scaling to 10-100 Trillion parameters may well get us to Scenario 2 or something near. Still, training and (potentially) inference costs may be prohibitive to achieving the reliability and generality needed for actual deployment. Some challenges we face include:</p>



<p><strong>(1)</strong> Maintaining long-term context without model size exploding.  </p>



<p><strong>(2)</strong> Making training more efficient, particularly finding ways to train N-sized models at a near-linear cost instead of quadratic in N.</p>



<p><strong>(3)</strong> Avoid running out of data, perhaps by using video/images and programmatically generated interactive simulations.</p>



<p><strong>(4)</strong> Handling multi-step interactions without the interaction going “off the rails” and without needing to scale policy/value gradients to an unfeasible number of interactions (perhaps by using smaller RL-trained “verifier models” to choose between options produced by a large statically-trained model). </p>



<p>This post is focused on quantitative issues rather than questions such as “consciousness” or the risks of AI. Those deserve a post of their own. See the addendum at the end for some more philosophical/speculative discussion.</p>



<figure class="wp-block-image"><img alt="" src="https://lh6.googleusercontent.com/DZ5OdMGfgLPqoaYFgPjM3ih2tzYQOrKQlH1ObDsiMe7CxWvmgKL69sh8fZ0HtLva9DiPqo-hiA93xF-KpbqDzajMs43bDUm0fqIYPPtnkISlttkiqS3Ys4MbxTQkrMFb0U89GT-NtySEieACtg"/><strong>Figure:</strong> Largest occupations in the US according to <a href="https://www.bls.gov/oes/current/area_emp_chart/area_emp_chart.htm">BLS</a>, and a list of most popular remote-only postings from <a href="https://www.flexjobs.com/blog/post/10-best-telecommuting-jobs-with-no-location-requirement-v2/">FlexJobs</a>. Some of these, including health care aides, nurses, and teachers, are unlikely to be replaced by AI soon. The quality of current AI is also not the bottleneck in replacing retail salespersons, cashiers, and fast-food and counter workers.   Similarly, jobs such as laborers and material movers, which involve physical work in constantly changing environments, are unlikely to be cost-effective to automatize in the near future. </figure>



<p/>



<h3><strong>Initial notes</strong></h3>



<p>Since artificial intelligence exists in the virtual space, people often assume that we can clone it an arbitrary number of times. But modern AI systems have a highly non-trivial physical footprint. Current models require dozens of GPUs to store their parameters, and future ones would be even larger. Creating many copies of such systems is going to be challenging.</p>



<p>Another common assumption is that by Moore’s law, if we manage to build a system at the level of (say) a sixth-grader, then in a year, we would have a virtual Einstein. However, often performance on a metric scale with the <strong>logarithm</strong> of the number of parameters (e.g., see Big-bench and Parti figures). So, perhaps a better assumption is that if we manage to build a virtual sixth-grader, then the following year, we would have a virtual seventh-grader.</p>



<figure class="wp-block-image"><img alt="" src="https://lh4.googleusercontent.com/FAFhzz-aKnE_J6tYSgrt5PJSapIMUWZDWwdI-gqb1SwdKFE8TGQhcmNHWTXSt-SY4eKBDHbu-weP25MtVb8_FBu_cSCk1WAIoCkhsS_cQWMuLSxddSwgPN_it_4m1KP9SzH7IszegCZSVslxbg"/><strong>Figure:</strong> Performance of models on the BIG-bench tasks (<a href="https://arxiv.org/abs/2206.04615">Srivastava et al., 22</a>). Note that performance scales with the <strong>logarithm</strong> of the number of parameters. This is in contrast to power-law dependence on the number of parameters which is typically manifested for metrics that are close to saturation. For the JSON tasks, naive extrapolation from 10<sup>8</sup> to 10<sup>11 </sup>suggests an improvement of about 4 points per order of magnitude. However, the rapid growth exhibited by PaLM models suggests potentially better improvements. Jascha Sohl-Dikstein’s rough estimate is that 1-10 Trillion parameters would suffice for achieving expert performance in 80% of the tasks.</figure>



<p/>



<figure class="wp-block-image"><img alt="" src="https://lh3.googleusercontent.com/6vJVDVTLakDJBXmOoVhQsFUuP0KFXFzjvZ3EucsNAayOsISu-Zh7v-hxuM5esA_6XxMjpV-1VUlxCjBwINGBQ5rZXN1ipG4q99hZ9cBK87nVbsSMXQU6U-DwqMKFgL4381RsxU77jHuLHV5Vdw"/><strong>Figure:</strong> Images generated by Google’s <a href="https://arxiv.org/abs/2206.10789">Parti model</a> (parameters refer to the main component of the model, ignoring the tokenizer and super-resolution modules). From left to right, models increase by factors of 2.1x, 5.3x, and 6.6x. On MS-COCO, these models’ Frechet Inception Distance (FID) scores were 14.1, 10.7, 8.1, and 7.23, respectively. </figure>



<p/>



<figure class="wp-block-image"><img alt="" src="https://lh4.googleusercontent.com/NSML-IXUDXQIGhIfTJOjW7_X-Z7o0Vo7rs5NUKManJoyr7g-QXUWu6KPCXSCjk8qnXBEqX_hQV6V_cFG5MIR2o2Nyc6mLpnFDiYINaCI074aQFMp4E9uvGOIYZXhyAyP-vF9au4UzGwumzaAHA"/><strong>Figure: </strong>Figure 12 in Parti paper (<a href="https://arxiv.org/abs/2206.10789">Yu et al.</a>). Based on human evaluations, the 20B Parti model improved moderately on the 3B model in most aspects (20B output preferred by humans over 3B output in about 60% of the cases) and improved strongly in generating images for abstract concepts or containing writing and symbols (20B output preferred approximately 80% of the time). </figure>



<p/>



<h2><strong>If scale is all you need, how much scale will we need?</strong></h2>



<p>Let’s assume that we could reach the second scenario (proof of concept general AI system) by simply scaling up our current auto-regressive language models by a factor of X. What would be X?</p>



<p><strong>Adaptivity. </strong>One crucial difference between the tasks we currently test language models on and general intelligence is <em>adaptivity</em>. A model that answers a question correctly with 95% probability is excellent. But with a 5% chance of error, such a model may go “off the rails” in a back-and-forth conversation with more than 20 steps. Adaptivity is one reason why robotics performance (even in <a href="https://svl.stanford.edu/igibson/">simulated virtual worlds</a>) still lags far behind humans. It is not so much that the physical environment is higher dimensional than the inputs to language models, but the fact that robots’ actions impact it (and unlike in the case of Chess, Go, or Atari, we don’t have an unlimited number of restarts and simulations). Navigating the social and technical environment of (even a virtual) workplace is no less challenging. Squeezing out that final performance (e.g., from 95% to 99%) is usually when power laws kick in, reducing error by a factor of k, requiring a multiplicative overhead of k to some power a&gt;1.</p>



<p><strong>Context length.</strong> Another way to think of scaling is the length of the context window models keep.  To be useful in replacing a human worker, we don’t want to continuously simulate their first day at work. We want an employee that remembers what they did yesterday, last week, and last year. GPT-3 maintains a window of 2048 tokens, corresponding to roughly 1500 words or three pages of text. However, if you had to write a letter to your future self detailing everything they should remember from your interactions so far, it would likely be much longer. (Claude Fredericks, who may have been <a href="https://www.newyorker.com/magazine/2021/11/08/the-most-ambitious-diary-in-history-claude-fredericks">the most prolific diarist in history</a>, wrote a diary of approximately 65,000 pages.) </p>



<p>Unfortunately, in standard transformer models, computation and memory cost <em>quadratically</em> with the context (though due to weight-sharing between different tokens, the number of learned parameters doesn’t have to increase), which means that increasing the context by (say) a factor of 100 will require increasing model size by a factor of 10,000. However, several <a href="https://arxiv.org/abs/2009.06732">alternative transformer architectures</a> aim to achieve linear or near-linear model size scaling with the context.</p>



<p><strong>Empirical scaling of performance.</strong> The recent <a href="https://arxiv.org/abs/2206.04615">BIG-bench paper</a> is perhaps the most comprehensive study of how large language models’ performance improves with scale. They assembled an extensive collection of tasks, each with a score normalized to (mostly) stay in the interval 0-100, with a score of zero corresponding to trivial (e.g., random) performance and a score of 100 corresponding to near-perfect performance (e.g., expert human). In many of these tasks, current models score lower than 20. We still don’t have enough data to know how truly large models behave. On the one hand, naive extrapolation suggests that we need many orders of magnitude for high performance (e.g., a score of 80 points or above). On the other hand, larger models such as <a href="https://arxiv.org/abs/2204.02311">Google PaLM</a> show evidence of “breakthrough capabilities”- performance growing super-linearly in the logarithm of size. It seems that to solve this benchmark fully, we would need at least a factor of 10 increase over the ½ Trillion parameter PaLM model.</p>



<p><strong>Comparing with the brain.</strong> Another point of comparison could be the human brain. However, human brains and artificial neural networks have very different architectures, and we don’t know how many parameters correspond to a single neuron or synapse. Scott Alexander <a href="https://astralcodexten.substack.com/p/somewhat-contra-marcus-on-ai-scaling?s=r">quotes</a> <a href="https://blog.piekniewski.info/2018/08/28/fun-numbers-about-the-brain/">this estimate</a> of 100 trillion parameters on the brain’s size, which would correspond to a factor of 100-1,000 larger than current models. However, the estimate is rather hand-wavy, and even if it wasn’t, there is no reason to expect that artificial neural networks would have the same “ability per parameter” ratio as human brains. In particular, artificial neural networks appear to compensate for relatively weaker reasoning skills by ingesting a massive amount of data, and with data, the model size grows as well.</p>



<p><strong>Bottom line.</strong> Overall, it seems that X will need to be at least 10-100, though this is an extremely rough estimate. Also, while an X Trillion model might be the “core” of a system replacing a human worker, it will not be the whole of it, and we are likely to need new ideas beyond scale for these other components. In particular, a model designed for back-and-forth interaction is unlikely to simply use an auto-regressive language model as a black box, not even with chain-of-thought reasoning.</p>



<h2><strong>How much will it cost?</strong></h2>



<p>Suppose that scaling our current models by a factor of X can achieve “AGI” in the sense of yielding a system that can be as productive as humans in a wide variety of professions (say all the top remote jobs in the list from <a href="https://www.flexjobs.com/blog/post/10-best-telecommuting-jobs-with-no-location-requirement-v2/">FlexJobs</a>). How much do we expect it to cost to (1) build a single system of this magnitude and (2) widely deploy it?</p>



<p>The gap between a “proof of concept” to actual deployment can be pretty significant. For example, in 2007, CMU won the urban DARPA grand challenge, while in 2012, a Google autonomous car passed a driving test. Yet a decade later, we still don’t have a significant deployment of self-driving cars. Also, as described in the book (and film) <a href="https://www.nytimes.com/2016/09/06/books/on-being-black-female-math-whizzes-during-the-space-race.html">Hidden Figures</a>, despite Moore’s law starting in the 30s, NASA still employed <a href="https://www.history.com/news/human-computers-women-at-nasa">human computers</a> until the 1960s. </p>



<p>For this post, I will make the optimistic (and unrealistic) assumption that the difference between proof-of-concept and deployments corresponds to the difference between the cost of <strong>training</strong> a system vs. the cost of doing <strong>inference</strong> on it.  If a system costs more than $100B to train, then it may never get built  (for comparison, the <a href="https://www.forbes.com/sites/alexknapp/2012/07/05/how-much-does-it-cost-to-find-a-higgs-boson/?sh=15872c173948">Large Hadron Collider</a> cost less than $5B to build). Similarly, a system costing $1000/hour to use is unlikely to replace human workers at scale. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="479" src="https://lh6.googleusercontent.com/SPIkvg3D8tlFQvQJ8OEjFpTRdVjZr9PUCYUuyHfEyZGEe9LJHm2hipFm4SnuNShKeoi3j-UMfc99RXpVUonmw94IE75MLIvsO5Ef81LJT5YTWxtAYN_Tw6TgldY-bN1-BfJnDLeZ5SJa-jUj7Q" width="683"/><strong>Figure:</strong> Moore’s law expressed in calculations per dollar per second. While Moore’s law started in the 1900s, and in earnest since the 1930s, up until the 1960s, some calculations were still being done by “human computers.” Graph by Steve Jurvetson based on Ray Kurzweil’s original graph.</figure></div>


<p/>



<p>The costs below are calculated with today’s dollars and today’s hardware. Of course, improvements in hardware will translate to cheaper training and inference. However, we have neglected costs that can scale super-linearly with model size, including communication between nodes, managing massive clusters and more. I consider only <em>amortized</em> costs since those are what matter when training and serving models at scale.</p>



<h3><strong>Cost of training</strong></h3>



<p>There is no point in training a large model if you don’t train it for enough time. The performance advantages of larger models are realized by allowing them to train on more data without “saturating”. In the words of the <a href="https://arxiv.org/abs/2203.15556">Chinchilla</a> paper  “for every doubling of model size the number of training tokens should also be doubled.” (See also the <a href="https://arxiv.org/abs/2010.08127">deep bootstrap</a> paper). Hence the number of inferences applied using training also scales with the model size.  This means that if a model grows by a factor of X then both the cost of a single inference as well as the total number of inferences grow by about X, meaning that the cost of training grows by about X<sup>2</sup>.  In particular, we can expect training a model that is 100 times as large to cost 10,000 times more! </p>



<p>There are <a href="https://lambdalabs.com/blog/demystifying-gpt-3/">differing</a> <a href="https://lastweekin.ai/p/gpt-3-is-no-longer-the-only-game#:~:text=Taken%20together%2C%20these%20factors%20mean,costly%20and%20difficult%20to%20train.">estimates</a> on how much ~100B parameter GPT3 model cost to train, but they range in the $5M-$20M, let’s say $5M in pure training costs for simplicity. (This would correspond to a cost of 5M$/500B = 10<sup>-5</sup> dollars per inference, which matches roughly with estimates below.)  An X Trillion model (which, like Chinchilla, but unlike PaLM, would be fully trained to max out its advantages) might cost a factor of 100X<sup>2</sup> more. For X=10, this would be a cost of $50B. For X=100, this would be 5 Trillion dollars!</p>



<p>Clearly, finding a way to train N-sized models on N tokens using less than O(N<sup>2</sup>) steps (e.g., O(N log N) ) can be crucial for scaling larger models. Training larger language models also runs into the problem that we have nearly “maxed out” the available textual data. Modern models are already trained on hundreds of billions of words, but there is a limit to how much novel text can be produced by a planet of 8 billion people. (Though multimodal models that are also trained on video would have access to much more data.)</p>



<h2><strong>Cost per inference</strong></h2>



<p>Suppose that we have managed to train a large model of X Trillion parameters. How much do we expect inference to cost in dollars? In transformer architectures, the number of floating-point operations required to make a single model evaluation (i.e., inference) is roughly the same as the number of parameters.  </p>



<figure class="wp-block-image"><img alt="" src="https://lh5.googleusercontent.com/6nN6SrxuKUYnW0cfxrOmcohET_FSmDrQqnQXNirPRwj95oAr0HAf6J6q6v_S8W4_gV6Efvu8fgflohbxbW66hjcmeOBzHKYK_6syfh0Sc19V0qVr_Sg7jaDICeEyM5U1tc4r2P1C6p38LJoWKQ"/><strong>Figure:</strong> Relation between the number of parameters and FLOPs, from  <a href="https://arxiv.org/abs/2109.05472">Desislavov et al</a>. Both axes are logarithmic. For transformers, the slope is very close to 1 (one FLOP per parameter), while for CNN’s it is roughly 0.8. </figure>



<p/>



<p>Hence an X Trillion parameter model requires about X TerraFLOPs (TFLOPs). Nvidia’s A-100 GPUs claims peak performance of <a href="https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/">about 300</a> TFLOP/s. (The effects of using 16-bit precision and not achieving 100% utilization roughly cancel out.) Renting such a machine costs about $1/hour, so we can get about 300*3600 ~ 1M TFLOPs per dollar.  (This is up to order of magnitude and caring just about total FLOPs rather than wall-clock time; for careful calculations of inference <em>time,</em> see <a href="https://kipp.ly/blog/transformer-inference-arithmetic/">Carol Chen’s</a> and <a href="https://bounded-regret.ghost.io/how-fast-can-we-perform-a-forward-pass/">Jacob Steinhardt’s</a> blogs.)</p>



<p>So far, this sounds great – we could make 10<sup>6</sup>/X<strong> </strong> inferences per dollar for an X trillion parameter model.  However, in the real world costs are much higher. The same Nvidia blog shows that A-100 can handle 6000 inferences/sec of the 340M parameter Bert Large. Since an X Trillion model is 3000X larger, that would correspond to 2/X inferences per second or 7200/X inferences per hour/dollar. The calculations above predict that the 0.2 Trillion parameter GPT-3 would be able to perform 7200*5~35K inferences per dollar. However, OpenAI charges <a href="https://openai.com/api/pricing/">6 cents per 1K tokens</a> (including input tokens!), which depending on the length of the input, can be only 10 inferences per dollar. <a href="https://pakodas.substack.com/p/estimating-gpt3-api-cost">Bhavsar</a> estimates GPT-3 can handle about 18K inferences per GPU hour. Overall it seems that 10<sup>4</sup>/X inferences per dollar is an optimistic estimate. </p>



<p>However, the question is how many inferences we need to make per hour to simulate a human. The average person <a href="https://www.publicationcoach.com/ten-ways-to-write-a-better-speech/">apparently speaks</a> about 150 words (say 200 tokens) per minute. This would suggest we need about 200*60 ~ 10K inferences per hour to simulate a person. For an X Trillion sized model, that would cost $X per hour, which is not too bad if X is between 10 to 100.</p>



<p>The above price point sounds pretty good but will likely be an underestimate.  First, to actually simulate a human, we need not just to simulate what they say but also what they <em>think</em>. So, to perform “chain of thought” reasoning, we would need to run an inference per word that is thought rather than a word that is uttered. We don’t know the speed of thought, but it will increase the number of inferences needed. Generally, to simulate a chain of reasoning of depth K, the number of inferences scales with K, even if the end result is just a single token. Second, to reach high reliability, it is likely that we will need to make Y inferences and use some mechanism to choose the best one out of these Y options. For example, <a href="https://arxiv.org/abs/2203.07814">AlphaCode</a> generates millions of possible solutions to programming challenges and filters them into 10 candidate ones. It is hard to estimate what Y would be in a workplace environment, but it seems that Y would be somewhere between 10 to 100.</p>



<p><strong>Bottom line for inference cost. </strong>The estimates above suggest that an X Trillion parameter model would require about 10<sup>5</sup> to 10<sup>6</sup> inferences per hour to simulate a person, with a cost that ranges from $10X to $100X per hour. This is already tight for X=10 and would be too much for X=100. However, it is not clear how many words/thoughts we need to simulate per given profession, so these estimates are very rough.</p>



<p/>



<h2><strong>The bottom line</strong></h2>



<p>While the estimates above should be taken with huge grains of salt, I believe that generally useful artificial intelligence can likely be achieved, but it will require more than sheer scale. While in principle a perfect next-word extender is also a perfect reinforcement learner, we may not be able to get close enough to perfection by scale alone. More than any particular conclusions, I hope that the debate can move from general philosophical arguments to quantitative questions that have numerical answers. </p>



<p/>



<h2><strong>Addendum: The “C word” and existential risk.</strong></h2>



<p>I tried to keep this post within the realms of calculations and away from philosophy. But given recent discussions and hype on whether AI systems can achieve “consciousness” or “sentience” and whether they pose a unique existential risk, I feel that I must address this at least briefly.  Readers allergic to philosophy and unjustified speculations can stop here. </p>



<p>Consciousness is a tricky concept: the Stanford Encyclopedia of Philosophy entry lists <a href="https://plato.stanford.edu/entries/consciousness/#SpeTheCon">nine different specific theories</a> of consciousness, and there are more theories still. It is also intertwined with ethics: if we consider a creature to be conscious or sentient, then the boundaries of how we can treat it become an issue of ethics. I don’t think it’s the job of computer scientists (or any other scientists) to come up with a moral philosophy, and similarly, I don’t think defining consciousness falls in our domain.</p>



<p>Historically, there seem to be two kinds of non-human entities which we considered conscious or sentient. One is animals, to which people have felt superior. The other is gods, to which people have felt inferior. Before we understood the causes of planetary movements, weather events, and other natural phenomena, we ascribed them to conscious actions by various gods. Since we couldn’t predict or explain these phenomena, our only attempt at controlling them was through prayer and sacrifice to the presumably conscious entity that controls them.</p>



<p>Some discussions of potential future AI are reminiscent of those past gods. According to some, AI would be not just conscious but capricious and could (according to some, <a href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities">would</a>)  ensure that “everybody on the face of the Earth suddenly falls over dead within the same second.” It is of course, possible to construct hypothetical scenarios in which an AI system managed to start a nuclear war or design a lethal virus. We’ve all read such books and seen such movies. It is also possible to construct scenarios where <em>humans</em> start a nuclear war or design a lethal virus. There are also many books and movies of the latter type. In fact, many AI “doomsday scenarios” don’t seem to require super-human levels of intelligence.   </p>



<p>The truth is that the reason that our world hasn’t been destroyed so far is not that humans were not intelligent enough nor because we haven’t been malicious enough. First, throughout most of human history, we did not have technologies such as nuclear weapons and others with the potential to cause planet-scale destruction. Second, while imperfect, we have developed some institutions, including international bodies, the non-proliferation treaty, standards for biolabs, pandemic preparations, and more to keep some of these capabilities in check. Third, we were lucky. From climate change through pandemic preparation to nuclear disarmament, humanity should be doing much more to confront the risks and harms of our own making. But this is true independently of artificial intelligence. Just as with humans, my inclination with AI would not to try to make systems inherently moral or good (“aligned” in AI-speak) but rather use the <a href="https://en.wikipedia.org/wiki/Trust,_but_verify">“trust, but verify” </a>approach. One moral of computational complexity theory is that computationally weak agents can verify the computation of more powerful processes.</p>



<p>Many of the calculations above show how “scaling up” is going to be non-trivial, and it is unlikely to see AI making restaurant reservations one day, and secretly ordering material over the net to build a world-destroying nano-technology lab the next one. Even if it’s possible for a large-scale model to “train itself” to improve performance, without needing additional outside data, that model would still incur the considerable computational costs for training that we computed above. </p>



<p>In my previous post, I explained <a href="https://windowsontheory.org/2022/05/23/why-i-am-not-a-longtermist/">why I am not a “longtermist”</a>.  The above is why I don’t view an “AGI run amok” as a short-term existential risk. That doesn’t mean AI doesn’t have safety issues. AI is a new technology, and with any new technology come new risks. We don’t need science fiction to see real risks in both unintentional consequences of AI deployment such as discrimination and bias, as well as intentional consequences of deploying AI for weapons, surveillance, and social manipulation. I don’t think that debating the notion of consciousness and inventing doomsday scenarios is helpful for combatting any one of those.   </p>



<p><strong>Acknowledgments: </strong>Thanks to Jascha Sohl-Dikstein for many useful comments on a draft of this blog post, and on how to interpret the results of the <a href="https://arxiv.org/abs/2206.04615">BIG-bench paper</a>.</p></div>
    </content>
    <updated>2022-06-27T14:44:21Z</updated>
    <published>2022-06-27T14:44:21Z</published>
    <category term="Philosophizing"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-07-07T08:37:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7823378841072893249</id>
    <link href="http://blog.computationalcomplexity.org/feeds/7823378841072893249/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/06/counting-number-of-3-colorings-of-graph.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7823378841072893249" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/7823378841072893249" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/06/counting-number-of-3-colorings-of-graph.html" rel="alternate" type="text/html"/>
    <title>Counting the Number of 3-colorings of a graph is Sharp-P complete. This should be better known.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(ADDED LATER- Lance and I were emailed more information on the topic of this post, and that was made into a post by Lance which is <a href="https://blog.computationalcomplexity.org/2022/06/a-gadget-for-3-colorings.html">here</a>.) </p><p><br/></p><p>BILL: Lance, is #3COL #P complete? (#3COL is: Given a graph G, return the number of  different 3-colorings it has.) </p><p>LANCE: Surely you know that for all natural A,  #A is #P complete. </p><p>BILL: There is no rigorous way to define <i>natural</i>. (I have several blog posts on this.) </p><p>LANCE: Surely then for all the NP-complete problems in <a href="https://amzn.to/3OiaKHb">Garey &amp; Johson</a>.</p><p>BILL:  I know that. But is there a proof that 3COL is #P Complete? I saw a paper that claimed the standard proof that 3-COL is NPC works, but alas, it does not. And stop calling me Shirley.</p><p>LATER</p><p>LANCE: I found this cool construction of an OR gate that creates a unique coloring.</p><div class="separator" style="clear: both; text-align: center;"><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXFZ_HG2ctfXyZPtF4TzkPf4gJni9XgTrsrfyy07yzdDJ5Faq0UuNYPWkS2yRd6g0SyFV6vbIKWqVtkgxzVB9ZKF-hqFUcBjzuQOQAFdWxILWQFZVZRPPB8XxcxjZckcaNXyulb6AfK4bGT-wY95sJyiS-sICaMRnhcA0fwek3Nv01WYu6pQ/s1672/unnamed.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXFZ_HG2ctfXyZPtF4TzkPf4gJni9XgTrsrfyy07yzdDJ5Faq0UuNYPWkS2yRd6g0SyFV6vbIKWqVtkgxzVB9ZKF-hqFUcBjzuQOQAFdWxILWQFZVZRPPB8XxcxjZckcaNXyulb6AfK4bGT-wY95sJyiS-sICaMRnhcA0fwek3Nv01WYu6pQ/w139-h200/unnamed.jpg" width="139"/></a></div><br/><p/><p>LATER</p><p>LANCE: That didn't work because you need to take an OR of three variables. OK, this isn't that easy.</p><p>LATER</p><p>LANCE: I found an unpublished paper (its not even in DBLP) that shows #3-COL is  #P complete using a reduction from NAE-3SAT, see <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/3colsharpp.pdf">here</a>. The proof was harder than I thought it would be. </p><p>BILL: Great! I'll post about it and give the link, since this should be better known. The link is <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/3colsharpp.pdf">here</a>.</p><p>-----------------------------</p><p>This leads to a question I asked about 2 years ago on the blog (see <a href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html#comment-form">here</a>) so I will be brief and urge you to read that post.</p><p>a) Is every natural NPC problem also #P-complete. Surely yes though this statement is impossible to make rigorous. </p><p>b) Is there some well defined class LANCE of LOTS of  NPC problems and a theorem saying that for every A in LANCE,  #A is #P complete? The last time I blogged about this (see above pointer) a comment pointed me to a cs stack exchange <a href="https://cstheory.stackexchange.com/questions/16119/when-does-x-is-np-complete-imply-x-is-p-complete">here</a> that pointed to an article by Noam Levine, <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/NLsharpp.pdf">here</a> which has a theorem which is not quite what I want but is interesting. Applying it to 3COL it says that there is a NTM poly time M that accepts 3COL and #M is #P-complete. <br/>Not just 3COL but many problems. </p><p>c) Is there some reasonable hardness assumption H such that from H one can show there is a set A that is NP-complete that is NOT #P-complete? (The set A will be contrived.) </p><p>ADDED LATER: Is #2-COL known to be #P-complete? This really could go either way (P or #P-complete) since some problems in P have their #-version in P, and some have their #-version be #P-complete.</p></div>
    </content>
    <updated>2022-06-26T19:00:00Z</updated>
    <published>2022-06-26T19:00:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-07-07T00:20:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/06/24/reflections-octagonal-mirror</id>
    <link href="https://11011110.github.io/blog/2022/06/24/reflections-octagonal-mirror.html" rel="alternate" type="text/html"/>
    <title>Reflections in an octagonal mirror maze</title>
    <summary>The second preprint from my CCCG papers is now online. It is “Reflections in an octagonal mirror maze”, arXiv:2206.11413. The title is quite literal: suppose you find yourself in a mirror maze, where the mirrors are aligned with the sides of an octagon, and have integer coordinates (meaning that, on a floorplan of the maze, the mirrors become line segments between points of an integer grid). What would you see if you looked in any given direction? It might be many reflections eventually leading to the back of your own head, to the exit, or some other non-reflective part of the maze. The example below, from the Museum of Science &amp; Industry in Chicago, is hexagonal rather than octagonal, but otherwise has much the same effect:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The second preprint from my CCCG papers is now online. It is “Reflections in an octagonal mirror maze”, <a href="https://arxiv.org/abs/2206.11413">arXiv:2206.11413</a>. The title is quite literal: suppose you find yourself in a <a href="https://en.wikipedia.org/wiki/House_of_mirrors">mirror maze</a>, where the mirrors are aligned with the sides of an octagon, and have integer coordinates (meaning that, on a floorplan of the maze, the mirrors become line segments between points of an integer grid). What would you see if you looked in any given direction? It might be many reflections eventually leading to the back of your own head, to the exit, or some other non-reflective part of the maze. <a href="https://commons.wikimedia.org/wiki/File:Mirror_Maze_in_the_Museum_of_Science%2BIndustry_of_Chicago.jpg">The example below, from the Museum of Science &amp; Industry in Chicago</a>, is hexagonal rather than octagonal, but otherwise has much the same effect:</p>

<p style="text-align: center;"><img alt="Mirror Maze in the Museum of Science+Industry of Chicago, CC-BY-SA image by Kevdog686, 27 May 2019, from Wikimedia Commons" src="https://11011110.github.io/blog/assets/2022/Chicago-mirror-maze.jpg"/></p>

<p>In this example, it looks like you might be seeing something else, not the exit or your own head: <a href="https://en.wikipedia.org/wiki/Infinity_mirror">a corridor of infinitely many reflections</a>. But when looking in a direction of rational slope, and without tricks involving <a href="https://en.wikipedia.org/wiki/One-way_mirror">one-way mirrors</a> (my guess at what’s happening in the photo), that’s not actually possible. Rationality implies that there are only finitely many possible points where your view could hit a mirror: in the photo above, all the reflections down the corridor look like they are actually on the center lines of the mirrors. Because there are only finitely many of these points (in reality, if not in what you see), such a view would have to eventually repeat, in a finite cycle. And finite cycles like that are definitely possible, but you can’t see them, because putting your eye onto them blocks the view.</p>

<p>Even if you can’t see a line with infinitely many reflections, you can see a very large number of them. The number of reflections you see between your eye and whatever opaque thing eventually blocks the view cannot be bounded by any function of the number of mirrors. If you take a diagonal view into a long hallway with its two sides mirrored, the number of reflections will be proportional to the length of the hall, even though there are only two mirrors. And with larger numbers of mirrors, more complex patterns of reflection can occur.</p>

<p style="text-align: center;"><img alt="Complex patterns of reflection in an octagonal mirror maze" src="https://11011110.github.io/blog/assets/2022/8reflex.svg"/></p>

<p>Because the number of reflections can be large, finding the eventual fate of a reflected light path by directly simulating the sequence of reflections any ray might take could be very slow. Instead, my new paper shows that it can be done in polynomial time! More precisely the time is polynomial in the number of mirrors and in the number of bits needed to specify a mirror coordinates or viewpoint direction using binary numbers.</p>

<p>Although the problem is simple to state, the solution uses sophisticated methods from computational topology. It’s an application of <a href="https://11011110.github.io/blog/2022/01/30/fast-iterated-exchange.html">an idea from an earlier post</a>, originally by Mark Bell, and included in an update to my earlier preprint “<a href="https://arxiv.org/abs/2112.11607">The Complexity of Iterated Reversible Computation</a>”. This idea concerns <em>iterated integer interval exchange transformations</em>: if you have a function on an interval of integers that acts by permuting subintervals, then how easy is it to compute the result of applying the same function many times? As Bell observed, this computation could be transformed into an equivalent problems of tracing normal curves on a topological surface, which had been solved in earlier work by Erickson and Nayyeri. The new paper generalizes these integer transformations to partial functions, extends the same method to compute iterated values of these partial functions, and shows that these partial functions can be used to model the way the mirrors in a mirror maze permute sightlines.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108536811841948097">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-06-24T23:29:00Z</updated>
    <published>2022-06-24T23:29:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-06-30T23:36:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6518</id>
    <link href="https://scottaaronson.blog/?p=6518" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6518#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6518" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Because I couldn’t not post</title>
    <summary xml:lang="en-US">In 1973, the US Supreme Court enshrined the right to abortion—considered by me and ~95% of everyone I know to be a basic pillar of modernity—in such a way that the right could be overturned only if its opponents could somehow gain permanent minority rule, and thereby disregard the wills of three-quarters of Americans. So […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In 1973, the US Supreme Court enshrined the right to abortion—considered by me and ~95% of everyone I know to be a basic pillar of modernity—in such a way that the right could be overturned only if its opponents could somehow gain permanent minority rule, and thereby disregard the wills of three-quarters of Americans.  So now, half a century later, that’s precisely what they’ve done.  Because Ruth Bader Ginsburg didn’t live three more weeks, we’re now faced with a civilizational crisis, with tens of millions of liberals and moderates in the red states now under the authority of a social contract that they never signed.  With this backwards leap, Curtis Yarvin’s notion that <a href="https://leviathan-supersystem.tumblr.com/post/164980251514/what-does-the-nrx-meme-cthulhu-swims-left-mean">“Cthulhu only ever swims leftward”</a> stands as decimated by events as any thesis has ever been.  I wonder whether Yarvin is happy to have been so thoroughly refuted.</p>



<p>Most obviously for me, the continued viability of Texas as a place for science, for research, for technology companies, is now in severe doubt.  Already this year, our 50-member CS department at UT Austin has had faculty members leave, and faculty candidates turn us down, with abortion being the stated reason, and I expect that to accelerate.  Just last night my wife, Dana Moshkovitz, presented a proposal at the STOC business meeting to host STOC’2024 at a beautiful family-friendly resort outside Austin.  The proposal failed, in part because of the argument that, if a pregnant STOC attendee faced a life-threatening medical condition, Texas doctors might choose to let her die, or the attendee might be charged with murder for having a miscarriage.  In other words: Texas (and indeed, half the US) will apparently soon be like Donetsk or North Korea, dangerous for Blue Americans to visit even for just a few days.  To my fellow Texans, I say: if you find that hyperbolic, <em>understand that this is how the blue part of the country now sees you</em>.  Understand that only a restoration of the previous social contract can reverse it.</p>



<p>Of course, this destruction of everything some of us have tried to build in science in Texas is happening despite the fact that 47-48% of Texans actually vote Democratic.  It’s happening despite the fact that, if Blue Americans wanted to stop it, the obvious way to do so would be to <strong>move to Austin and Houston (and the other blue enclaves of red states) in droves, and exert their electoral power.</strong>  In other words, to do precisely what Dana and I did.  But can I urge others to do the same with a straight face?</p>



<p>As far as I can tell, the only hope at this point of averting a cold Civil War is if, against all odds, there’s a Democratic landslide in Congress, sufficient to get the right to abortion enshrined into federal law.  Given the ways both the House and the Senate are stacked against Democrats, I don’t expect that anytime soon, but I’ll work for it—and will do so even if many of the people I’m working with me despise me for other reasons.  I will match reader donations to Democratic PACs and Congressional campaigns (not necessarily the same ones, though feel free to advocate for your favorites), announced in the comment section of this post, up to a limit of $10,000.</p></div>
    </content>
    <updated>2022-06-24T15:31:38Z</updated>
    <published>2022-06-24T15:31:38Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-07-05T16:44:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/090</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/090" rel="alternate" type="text/html"/>
    <title>TR22-090 |  On the Partial Derivative Method Applied to Lopsided Set-Multilinear Polynomials | 

	Nutan Limaye, 

	Srikanth Srinivasan, 

	Sébastien Tavenas</title>
    <summary>We make progress on understanding a lower bound technique that was recently used by the authors to prove the first superpolynomial constant-depth circuit lower bounds against algebraic circuits. 

More specifically, our previous work applied the well-known partial derivative method in a new setting, that of 'lopsided' set-multilinear polynomials. A set-multilinear polynomial $P\in F[X_1,\ldots,X_d]$ (for disjoint sets of variables $X_1,\ldots,X_d$) is a linear combination of monomials, each of which contains one variable from $X_1,\ldots,X_d$. A lopsided space of set-multilinear polynomials is one where the sets $X_1,\ldots,X_d$ are allowed to have different sizes (we use the adjective `lopsided' to stress this feature). By choosing a suitable lopsided space of polynomials, and using a suitable version of the partial-derivative method for proving lower bounds, we were able to prove constant-depth superpolynomial set-multilinear formula lower bounds even for very low-degree polynomials (as long as $d$ is a growing function of the number of variables $N$). This in turn implied lower bounds against general formulas of constant-depth.

A priori, there is nothing stopping these techniques from giving us lower bounds against algebraic formulas of 'any' depth. We investigate the extent to which this lower bound can extend to greater depths. We prove the following results.


** We observe that our choice of the lopsided space and the kind of partial-derivative method used can be modelled as the choice of a multiset $W\subseteq [-1,1]$ of size $d$. Our first result completely characterizes, for any product-depth $\Delta,$ the best lower bound we can prove for set-multilinear formulas of product-depth $\Delta$ in terms of some combinatorial properties of $W$, that we call the 'depth-$\Delta$ tree bias' of $W$.

** We show that the maximum depth-$3$ tree bias, over multisets $W$ of size $d$, is $\Theta(d^{1/4}).$ This shows a stronger formula lower bound of $N^{\Omega(d^{1/4})}$ for set-multilinear formulas of product-depth $3$, and also puts a non-trivial constraint on the best lower bounds we can hope to prove at this depth in this framework (a priori, we could have hoped to prove a lower bound of $N^{\Omega(\Delta d^{1/\Delta})}$ at product-depth $\Delta$).

** Finally, we show that for small $\Delta,$ our proof technique cannot hope to prove lower bounds of the form $N^{\Omega(d^{1/\poly(\Delta)})}.$ This seems to strongly hint that new ideas will be required to prove lower bounds for formulas of unbounded depth.</summary>
    <updated>2022-06-24T12:52:31Z</updated>
    <published>2022-06-24T12:52:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-07T08:37:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1376</id>
    <link href="https://thmatters.wordpress.com/2022/06/22/call-for-tcs-job-market-profiles/" rel="alternate" type="text/html"/>
    <title>Call for TCS Job Market profiles</title>
    <summary>CATCS is resuming the effort to collect and disseminate profiles of theory researchers who are going on the job market during the 2022-23 academic year, complementing the job postings collected under the Jobs tab.  The goals are to provide: a platform to job-seekers to advertise their credentials and an interface for institutions/individuals with open positions […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is resuming the effort to collect and disseminate profiles of theory researchers who are going on the job market during the 2022-23 academic year, complementing the job postings collected under the <a href="https://cstheory-jobs.org/">Jobs tab</a>.  The goals are to provide:</p>



<ul><li>a platform to job-seekers to advertise their credentials and</li><li>an interface for institutions/individuals with open positions to find prospective candidates.</li></ul>



<p>Candidates can fill out this <a href="https://docs.google.com/forms/u/1/d/1jeN3hjzwdRCmI3-7yzuHmyelcZjCtKDn19X2dj4POro/edit?urp=gmail_link">form</a>, which asks for basic information, graduation date (past or future), cv, bio, research summary, etc.</p>



<p>The responses will be reviewed and, if approved, edited and posted on Theory Matters starting on Oct 15, 2022. There is no deadline, but for responses received after Oct 15, please allow two weeks for review before your profile appears on the website. Responses received by Oct 15 will have summaries published in the following issue of SIGACT News (Dec’22 issue).</p></div>
    </content>
    <updated>2022-06-22T21:28:41Z</updated>
    <published>2022-06-22T21:28:41Z</published>
    <category term="for PhD students"/>
    <category term="postdocs"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-07-07T08:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1371</id>
    <link href="https://thmatters.wordpress.com/2022/06/22/women-in-tcs-profiles/" rel="alternate" type="text/html"/>
    <title>Women in TCS Profiles</title>
    <summary>Are you trying to form a committee or panel or invite speakers for a TCS event, but cannot find enough women? Look no further. This spreadsheet contains the profiles of 100+ women TCS researchers spanning many subareas of TCS; countries; universities and research institutions; and career stages. The spreadsheet is password protected. The password is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Are you trying to form a committee or panel or invite speakers for a TCS event, but cannot find enough women? Look no further. <a href="https://www.dropbox.com/scl/fi/45bn5wg870u004zckuleq/Women-in-TCS-Profiles.xlsx?dl=0&amp;rlkey=yk4yxkwxg79w6qmp2tndophvl">This spreadsheet</a> contains the profiles of 100+ women TCS researchers spanning many subareas of TCS; countries; universities and research institutions; and career stages. </p>



<p>The spreadsheet is password protected. The password is a case-sensitive five letter phrase that captures the most iconic (but as yet unsolved) problem in TCS.</p>



<p>The spreadsheet was made possible through the efforts of Yusu Wang and Kira Goldner. We have full permission of the participants to have their information shared publicly. </p>



<p>Would you like your information added to or corrected on the spreadsheet? If so, fill out <a href="https://docs.google.com/forms/d/e/1FAIpQLSc2LcI0mtUvyKgl34OqbxDVpu0zbYs0fiLmU_5jr2qHybCfMQ/viewform">this Google form</a>. Any edits will be verified and posted to the spreadsheet within 3-4 weeks.</p></div>
    </content>
    <updated>2022-06-22T21:25:40Z</updated>
    <published>2022-06-22T21:25:40Z</published>
    <category term="featured"/>
    <category term="TCS Community"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-07-07T08:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/06/22/dehn-rank-revisited</id>
    <link href="https://11011110.github.io/blog/2022/06/22/dehn-rank-revisited.html" rel="alternate" type="text/html"/>
    <title>Dehn rank revisited</title>
    <summary>In a recent post, I discussed dissection of orthogonal polygons into each other by axis-parallel cuts, translation, and gluing. Each polygon has a value associated with it, called its Dehn invariant, that cannot be changed by dissection, so two polygons that can be dissected into each other must have equal invariants. And for past usage of Dehn invariants, that was pretty much all we looked at: are they equal or not? But my post pointed out that these invariants actually have a lot of structure (you can think of them as matrices, after an arbitrary choice of basis) and this structure is geometrically meaningful. Matrices (or tensors) have a rank, and the rank of the Dehn invariant is a lower bound on the number of rectangles into which a polygon can be dissected. This in turn has implications on the ability of a polygon or its dissections to tile the plane.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <a href="https://11011110.github.io/blog/2022/04/03/dissection-into-rectangles.html">a recent post</a>, I discussed dissection of orthogonal polygons into each other by axis-parallel cuts, translation, and gluing. Each polygon has a value associated with it, called its <a href="https://en.wikipedia.org/wiki/Dehn_invariant">Dehn invariant</a>, that cannot be changed by dissection, so two polygons that can be dissected into each other must have equal invariants. And for past usage of Dehn invariants, that was pretty much all we looked at: are they equal or not? But my post pointed out that these invariants actually have a lot of structure (you can think of them as matrices, after an arbitrary choice of basis) and this structure is geometrically meaningful. Matrices (or tensors) have a rank, and the rank of the Dehn invariant is a lower bound on  the number of rectangles into which a polygon can be dissected. This in turn has implications on the ability of a polygon or its dissections to tile the plane.</p>

<p>Now it’s a paper: “Orthogonal dissection into few rectangles”, <a href="https://arxiv.org/abs/2206.10675">arXiv:2206.10675</a>, to appear at CCCG. The results of the paper are stronger: instead of just using the Dehn rank as a lower bound, I proved that it always equals the minimum number of rectangles into which a given polygon can be dissected, and can be used to compute this number of rectangles efficiently. The two main steps of the proof are:</p>

<ul>
  <li>
    <p>constructing a set of the right number of rectangles for any given tensor, by a direct geometric construction that turns an algebraic realization of the rank (a combination of positive and negative rectangles) into a geometric representation without the negativity, and</p>

    <p style="text-align: center;"><img alt="Construction of a set of rectangles realizing a given tensor as their Dehn invariant" src="https://11011110.github.io/blog/assets/2022/dehn-realizability.svg" style="width: 100%;"/></p>
  </li>
  <li>
    <p>finding a dissection for any two polygons with equal invariants, by induction on the dimensions of the matrix describing their invariants.</p>

    <p style="text-align: center;"><img alt="Induction step for proving the existence of a dissection between polygons with equal Dehn invariants" src="https://11011110.github.io/blog/assets/2022/dehn-dissectability.svg" style="width: 100%;"/></p>
  </li>
</ul>

<p>The images above are taken from the illustrations for the proofs of these two results from the paper, and maybe will provide a little insight into how they might be proven. For details, see the paper. Instead, here, I wanted to highlight a different, related problem, that I wasn’t able to prove as much about.</p>

<p>Mostly when mathematicians talk about Dehn invariants, it’s for 3d dissections: cutting polyhedra up along planes, translating and rotating the pieces, and gluing them back together. The 3d Dehn invariant combines lengths and angles of polyhedron edges in the same way that the 2d invariant combines widths and heights of rectangles. Therefore, 3d Dehn rank is a lower bound on the number of edges you can dissect something into. It’s easy to construct polyhedra with arbitrarily large rank, and these polyhedra are forced to have arbitrarily large numbers of edges, no matter how you try to cut them up and reassemble them.</p>

<p>However, the 3d Dehn rank is not exactly equal to the minimum number of edges after dissection. A cube has Dehn invariant zero (with rank zero), but the minimum number of edges of a polyhedron you can dissect it into is four, for a <a href="https://www.jstor.org/stable/2689983">space-filling tetrahedron</a> of the same volume. A regular tetrahedron is not space-filling, has a Dehn invariant of rank one, and already has the minimum number of edges among anything you can dissect it into. In both cases the rank is unequal to the minimum number of edges. Also, the rank is different in these cases but the minimum number of edges is the same.</p>

<p>Nevertheless, I was hoping that the rank of the Dehn invariant would be usable as a constant-factor approximation to the minimum number of edges after dissection. To prove this, I’d need to find a polyhedron, having the same Dehn invariant as any given polyhedron, but with a number of edges proportional to the rank. The existence of a dissection would then follow from known results. But finding this few-edge polyhedron would have to use some knowledge of the starting polyhedron (unlike my set-of-rectangles construction), because not all tensors are realizable as Dehn invariants. So far, I haven’t been able to find any construction of these few-edge polyhedra.</p>

<p>So: does every polyhedron, of Dehn rank \(r\), have an equivalent polyhedron with \(O(r)\) edges? Or are there some polyhedra that cannot be dissected into another polyhedron with few edges, even though their Dehn invariants have low rank?</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108524203085266737">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-06-22T18:22:00Z</updated>
    <published>2022-06-22T18:22:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-06-30T23:36:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2675194666660547317</id>
    <link href="http://processalgebra.blogspot.com/feeds/2675194666660547317/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2675194666660547317" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2675194666660547317" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2675194666660547317" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2022/06/interview-with-luca-de-alfaro-marco.html" rel="alternate" type="text/html"/>
    <title>Interview with Luca de Alfaro, Marco Faella, Thomas A. Henzinger, Rupak Majumdar and Mariëlle Stoelinga, CONCUR 2022 ToT Award Recipients</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In this instalment of the Process Algebra Diary, <a href="http://math.umons.ac.be/staff/Randour.Mickael/" target="_blank">Mickael Randour</a> and I joined forces to interview <a href="https://luca.dealfaro.com/" target="_blank">Luca de Alfaro</a>, <a href="http://wpage.unina.it/m.faella/" target="_blank">Marco Faella</a>, <a href="https://pub.ist.ac.at/~tah/" target="_blank">Thomas A. Henzinger</a>, <a href="https://people.mpi-sws.org/~rupak/" target="_blank">Rupak Majumdar</a> and <a href="https://wwwhome.ewi.utwente.nl/~marielle/" target="_blank">Mariëlle Stoelinga</a>, who are some of the recipients of the <a href="https://concur2022.mimuw.edu.pl/tot-award/" target="_blank">CONCUR 2022 Test-of-Time award</a>. We hope that you'll enjoy reading the very inspiring and insightful answers provided by the above-mentioned colleagues to our questions.  <br/></p><p>Note: In what follows, "Luca A." refers to me, whereas "Luca" is Luca de Alfaro. <br/></p><p><b>Luca A. and Mickael:</b> You receive the CONCUR ToT Award 2022 for your paper  "<a href="https://pub.ist.ac.at/~tah/Publications/the_element_of_surprise_in_timed_games.pdf)" target="_blank">The Element of Surprise in Timed Games</a>", which appeared at CONCUR 2003. In that article, you studied concurrent, two-player timed games. A key contribution of your paper is the definition of an elegant timed game model, allowing both the representation of moves that can take the opponent by surprise, as they are played “faster”, and the definition of natural concepts of winning conditions for the two players — ensuring that players can win only by playing according to a physically meaningful strategy. In our opinion, this is a great example of how novel concepts and definitions can advance a research field. Could you tell us more about the origin of your model?</p><p><br/><b>All: </b>Mariëlle and Marco were postdocs with Luca at UCSC in that period, Rupak was a student of Tom's, and we were all in close touch, meeting very often to work together.  We all had worked much on games, and an extension to timed games was natural for us to consider. </p><p><br/>In untimed games, players propose a move, and the moves jointly determine the next game state. In these games there is no notion of real-time.  We wanted to study games in which players could decide not only the moves, but also the instant in time when to play them.</p><p><br/>In timed automata, there is only one “player” (the automaton), which can take either a transition, or a time step.  The natural generalization would be a game in which players could propose either a move, or a time step.</p><p><br/>Yet, we were unsatisfied with this model. It seemed to us that it was different to say “Let me wait 14 seconds and reconvene.  Then, let me play my King of Spades” or “Let me play my King of Spades in 14 seconds”. In the first, by stopping after 14 seconds, the player is providing a warning that the card might be played. In the second, there is no such warning.  In other words, if players propose either a move or a time-step, they cannot take the adversary by surprise with a move at an unanticipated instant.  We wanted a model that could capture this element of surprise.</p><p><br/>To capture the element of surprise, we came up with a model in which players propose both a move and the delay with which it is played. After this natural insight, the difficulty was to find the appropriate winning condition, so that a player could not win by stopping time. </p><p><br/><b>Tom:</b> Besides the infinite state space (region construction etc.), a second issue that is specific to timed systems is the divergence of time. Technically, divergence is a built-in Büchi condition ("there are infinitely many clock ticks"), so all safety and reachability questions about timed systems are really co-Büchi and Büchi questions, respectively.  This observation had been part of my work on timed systems since the early 1990s, but it has particularly subtle consequences for timed games, where no player (and no collaboration of players) should have the power to prevent time from diverging.  This had to be kept in mind during the exploration of the modeling space.</p><p><br/><b>All:</b> We came up with many possible winning conditions, and for each we identified some undesirable property, except for the one that we published.  This is in fact an aspect that did not receive enough attention in the paper; we presented the chosen winning condition, but we did not discuss in full detail why several other conditions that might have seemed plausible did not work.</p><p><br/>In the process of analyzing the winning conditions, we came up with many interesting games, which form the basis of many results, such as the result on lack of determinazation, on the need for memory in reachability games (even when clock values are part of the state), and most famously as it gave the title to the paper, on the power of surprise.</p><p><br/>After this fun ride came the hard work, where we had to figure out how to solve these games. We had worked at symbolic approaches to games before, and we followed the approach here, but there were many complex technical adaptations required. When we look at the paper in the distance of time, it has this combination of a natural game model, but also of a fairly sophisticated solution algorithm.</p><p><br/><b>Luca A. and Mickael: </b>Did any of your subsequent research build explicitly on the results and the techniques you developed in your award-winning paper? If so, which of your subsequent results on (timed) games do you like best? Is there any result obtained by other researchers that builds on your work and that you like in particular or found surprising?</p><p><br/><b>Luca:</b> Marco and I built Ticc, which was meant to be a tool for timed interface theories, based largely on the insights in this paper.  The idea was to be able to check the compatibility of real-time systems, and automatically infer the requirements that enable two system components to work well together – to be compatible in time.  We thought this would be useful for hardware or embedded systems, and especially for control systems, and in fact the application is important: there is now much successful work on the compositionality of StateFlow/Simulink models.</p><p><br/>We used MTBDDs as the symbolic engine, and Marco and I invented a language for describing the components and we wrote by pair-programming some absolutely beautiful Ocaml code that compiled real-time component models into MTBDDs (perhaps the nicest code I have ever written). The problem was that we were too optimistic in our approach to state explosion, and we were never able to study any system of realistic size.</p><p><br/>After this, I became interested in games more in an economic setting, and from there I veered into incentive systems, and from there to reputation systems and to a three-year period in which I applied reputation systems in practice in industry, thus losing somewhat touch with formal methods work.</p><p><b>Marco:</b> I’ve kept working on games since the award-winning paper, in one way or another. The closest I’ve come to the timed game setting has been with controller synthesis games for hybrid automata. In a series of papers, we had fun designing and implementing symbolic algorithms that manipulate polyhedra to compute the winning region of a linear hybrid game. The experience gained on timed games helped me recognize the many subtleties arising in games played in real time on a continuous state-space. <br/></p><p><b>Mariëlle:</b> I have been working on games for test case generation: One player represents the tester, which chooses inputs to test; the other player represents the System-under-Test, and chooses the outputs of the system. Strategy synthesis algorithms can then compute strategies for the tester that maximize all kinds of objectives, eg reaching certain states, test coverage etc. </p><p><br/>A result that I really like is that we were able to show a very close correspondence between the existing testing frameworks and game theoretic frameworks: Specifications act as game arenas; test cases are exactly game strategies, and the conformance relation used in testing (namely ioco) coincides with game refinement (i.e. alternating refinement). </p><p><br/><b>Rupak:</b> In an interesting way, the first paper on games I read was the <a href="https://www-verimag.imag.fr/~sifakis/RECH/Synth-MalerPnueli.pdf" target="_blank">one by Maler, Pnueli and Sifakis (STACS 95)</a> that had both fixpoint algorithms and timed games (without “surprise”). So the problem of symbolic solutions to games and their applications in synthesis followed me throughout my career. I moved to finding controllers for games with more general (non-linear) dynamics, where we worked on abstraction techniques. We also realized some new ways to look at restricted classes of adversaries. I was always fortunate to have very good collaborators who kept my interest alive with new insights. Very recently, I have gotten interested in games from a more economic perspective, where players can try to signal each other or persuade each other about private information but it’s too early to tell where this will lead.</p><p><br/><b>Luca A. and Mickael:</b> What are the research topics that you find most interesting right now? Is there any specific problem in your current field of interest that you'd like to see solved?</p><p><br/><b>Mariëlle: </b>Throughout my academic life, I have been working on stochastic analysis --- with Luca and Marco, we worked on stochastic games a lot. First only on theory, but later also on industrial applications, esp in the railroad and high-tech domain. At some point in time, I realized that my work was actually centred around analysing failure probabilities and risk. That is how I moved into risk analysis; the official title of the title of the chair I hold is Risk Management for High Tech Systems. </p><p><br/>The nice thing is: this sells <i>much</i> better than Formal Methods! Almost nobody knows what Formal Methods are, and if they know, people think “yes, those difficult people who urge us to specify everything mathematically”. For risk management, this is completely different: everybody understands that this is an important area. <br/><br/><b>Luca: </b>I am currently working on computational ecology, on ML for networks, and on fairness in data and ML.  In computational ecology, we are working on the role of habitat and territory for species viability. We use ML techniques to write “differentiable algorithms”, where we can compute the effect of each input – such as the kind of vegetation in each square-kilometer of territory – on the output.  If all goes well, this will enable us to efficiently compute which regions should be prioritized for protection and habitat conservation.</p><p><br/>In networks, we have been able to show that reinforcement learning can yield tremendous throughput gains in wireless protocols, and we are now starting to work on routing and congestion control.</p><p><br/>And in fairness and ML, we have worked on the automatic detection of anomalous data subgroups (something that can be useful in model diagnostics), and we are now working on the spontaneous inception of discriminatory behavior in agent systems.</p><p><br/>While these do not really constitute a coherent research effort, I can certainly say that I am having a grand tour of CS – the kind of joy ride one can afford with tenure!</p><p><br/><b>Rupak: </b>I have veered between practical and theoretical problems. I am working on charting the decidability frontier for infinite-state model checking problems (most recently, for asynchronous programs and context-bounded reachability). I am also working on applying formal methods to the world of cyber-physical systems ---mostly games and synthesis. Finally, I have become very interested in applying formal methods to large scale industrial systems through a collaboration with Amazon Web Services. There is still a large gap between what is theoretically understood and what is practically applicable to these systems; and the problems are a mix of technical and social.</p><p><br/><b>Luca A. and Mickael:</b> You have a very strong track record in developing theoretical results and in applying them to real-life problems. In our, admittedly biased, opinion, your work exemplifies Ben Schneiderman's <a href="https://www.pnas.org/doi/pdf/10.1073/pnas.1802918115" target="_blank">Twin-Win Model</a>, which propounds the pursuit of "the dual goals of breakthrough theories in published papers and validated solutions that are ready for widespread dissemination." Could you say a few words on your research philosophy? How do you see the interplay between basic and applied research?</p><p><br/><b>Luca:</b> This is very kind for you to say, and a bit funny to hear, because certainly when I was young I had a particular talent for getting lost in useless theoretical problems.  </p><p><br/>I think two things played in my favor.  One is that I am curious.  The other is that I have a practical streak: I still love writing code and tinkering with “things”, from IoT to biology to web and more.  This tinkering was at the basis of many of the works I did.  My work on reputation systems started when I created a wiki on cooking; people were vandalizing it, and I started to think about game theory and incentives for collaboration, which led to my writing much of the code for Wikipedia analysis, and at Google, for Maps edits analysis.  My work on networks started with me tinkering with simple reinforcement-learning schemes that might work, and writing the actual code. On the flip side, my curiosity too often had the better of me, so that I have been unable to pay the continuous and devoted attention to a single research field.  I am not a specialist in any single thing I do or I have done.  I am always learning the ropes of something I don’t quite know yet how to do.</p><p><br/>My applied streak probably gave me some insight on which problems might be of more practical relevance, and my frequent field changes have allowed me to bring new perspectives to old problems.  There were not many people using RL for wireless networks, there are not many who write ML and GPU code and also avidly read about conservation biology.<br/><br/><b>Rupak:</b> I must say that Tom and Luca were very strong influencers for me in my research: both in problem selection and in appreciating the joy of research. I remember one comment of Tom, paraphrased as “Life is short. We should write papers that get read.” I spent countless hours in Luca’s office and learnt a lot of things about research, coffee, the ideal way to make pasta, and so on.<br/></p><p><b>Marco:</b> It was an absolute privilege to be  part of the group that wrote that paper (my 4th overall, according to  DBLP). I’d like to thank my coauthors, and Luca in particular, for  guiding me during those crucially formative years.</p><p><b>Mariëlle: </b>I fully agree! <br/></p><p><br/><b>Luca A. and Mickael:</b> Several of you have high-profile leadership roles at your institutions. What advice would you give to a colleague who is about to take up the role of department chair, director of a research centre, dean or president  of a university? How can one build a strong research culture, stay research active and live to tell the tale?</p><p><br/><b>Luca:</b> My colleagues may have better advice; my productivity certainly decreased when I was department chair, and is lower even now that I am the vice-chair.  <br/>When I was young, I was ambitious enough to think that my scientific work would have the largest impact among the things I was doing.  But I soon realized that some of the greatest impact was on others: on my collaborators, on the students I advised, who went on to build great careers and stayed friends, and on all the students I was teaching.  This awareness serves to motivate and guide me in my administrative work. The CS department at UCSC is one of the ten largest in the number of students we graduate, and the time I spend on improving its organization and the quality of the education it delivers is surely very impactful.  My advice to colleagues is to consider their service not as an impediment to research, but as one of the most impactful things they do.</p><p><br/>My way of staying alive is to fence off some days that I only dedicate to research (aside from some unavoidable emergency), and also, to have collaborators that give me such joy in working together that they brighten and energize my whole day. </p><p><br/><b>Luca A. and Mickael:</b> Finally, what advice would you give to a young researcher who is keen to start working on topics related to concurrency theory today?<br/> </p><p><b>Luca: </b>Oh that sounds very interesting!  And, may I show you this very interesting thing we are doing in Jax to model bird dispersal? We feed in this climate and vegetation data, and then we…</p><p><br/>Just kidding.  Just kidding.  If I come to CONCUR I promise not to lead any of the concurrency yearlings astray.  At least I will try.</p><p><br/>My main advice would be this: work on principles that allow correct-by-design development.  If you look at programming languages and software engineering, the progress in software productivity has not happened because people have become better at writing and debugging code written in machine language or C. It has happened because of the development of languages and software principles that make it easier to build large systems that are correct by construction.<br/>We need the same kind of principles, (modeling) languages, and ideas to build correct concurrent systems.  Verification alone is not enough. Work on design tools, ideas to guide design, and design languages.</p><p><br/><b>Tom:</b> In concurrency theory we define formalisms and study their properties. Most papers do the studying, not the defining: they take a formalism that was defined previously, by themselves or by someone else, and study a property of that formalism, usually to answer a question that is inspired by some practical motivation. To me, this omits the most fun part of the exercise, the {\it defining} part. The point I am trying to make is not that we need more formalisms, but that, if one wishes to study a specific question, it is best to study the question on the simplest possible formalism that exhibits exactly the features that make the question meaningful. To do this, one often has to define that formalism. In other words, the formalism should follow the question, not the other way around. This principle has served me well again and again and led to formalisms such as timed games, which try to capture the essence needed to study the power of timing in strategic games played on graphs. So my advice to a young researcher in concurrency theory is: choose your formalism wisely and don't be afraid to define it. <br/><br/><b>Rupak:</b> Problems have different measures. Some are practically justified (“Is this practically relevant in the near future?”) and some are justified by the foundations they build (“Does this avenue provide new insights and tools?”). Different communities place different values on the two. But both kinds of work are important and one should recognize that one set of values is not universally better than the other.<br/></p><p><b>Mariëlle:</b> As Michael Jordan puts it: <i>Just play. Have fun. Enjoy the game.</i></p></div>
    </content>
    <updated>2022-06-21T20:53:00Z</updated>
    <published>2022-06-21T20:53:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2022-07-06T21:36:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8397</id>
    <link href="https://windowsontheory.org/2022/06/21/teaching-circuits-as-the-first-computational-model/" rel="alternate" type="text/html"/>
    <title>Teaching circuits as the first computational model</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This fall, I am once again teaching Harvard’s “Introduction to Theoretical Computer Science” course (CS 121). Like many “intro to TCS / intro to theory of computation” courses, Harvard’s course used to be taught with Sipser’s classic textbook. Sipser’s book is indeed, for better or worse, a classic. It is extremely well-written and students like … <a class="more-link" href="https://windowsontheory.org/2022/06/21/teaching-circuits-as-the-first-computational-model/">Continue reading <span class="screen-reader-text">Teaching circuits as the first computational model</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This fall, I am once again teaching Harvard’s “Introduction to Theoretical Computer Science” course (<a href="https://cs121.boazbarak.org/">CS 121</a>). Like many “intro to TCS / intro to theory of computation” courses,  Harvard’s course used to be taught with <a href="https://www.amazon.com/Introduction-Theory-Computation-Michael-Sipser/dp/113318779X">Sipser’s classic textbook</a>. Sipser’s book is indeed, for better or worse, a classic. It is extremely well-written and students like it very much. It has clear explanations,  plenty of examples and solved exercises, and a wealth of material on the web accumulated through decades of it being used in many courses. On the other hand, CS in general and theoretical CS in particular has changed a lot in the 25+ years since the book was written. In fact, the basic approach of starting with finite automata as the initial model of computation dates to the <a href="https://dl.acm.org/doi/pdf/10.5555/1096945">1969 book</a> of Hopcroft and Ullman.</p>



<p>One of my main goals in revising the theoretical CS course is to give students both rigorous foundations as well as a taste of modern topics. Some of these modern topics: </p>



<ul><li><strong>Cryptography</strong>: a topic that combines mathematical beauty, practical importance, and a demonstration that sometimes computational hardness can be a resource rather than a hindrance.</li><li><strong>Quantum computing: </strong>a topic that shows the interaction between TCS and physics, the fundamental nature of the “Church Turing hypothesis”, and how we can (as in crypto) take a “lemon” (inability of classical computers to simulate certain quantum processes) and use it to make “lemonade” (a computer with stronger power than classical computers).</li><li><strong>Randomized computation and derandomization: </strong>Randomization is now essential to so many areas of CS, and so it is important to both demonstrate its power, and also how we might use complexity to remove it.</li><li><strong>Machine learning and average-case complexity:</strong> Traditionally in an intro TCS course the focus is purely on worst-case complexity. This leads to a disconnect with modern applications of CS, and in particular machine learning. </li></ul>



<p>So, I ended up <a href="https://windowsontheory.org/2017/07/27/rethinking-the-intro-theory-course/">writing my own text</a> – <a href="https://introtcs.org/"><strong>Introduction to Theoretical Computer Science</strong></a>.  While at some point I hope to make it into a printed book, it will always be available freely online on <a href="https://introtcs.org/">https://introtcs.org/</a>. The markdown source for it is available on the repository <a href="https://github.com/boazbk/tcs">https://github.com/boazbk/tcs</a> .  I’ve benefitted greatly from feedback from both students and readers around the globe: at the time of writing, the project has 330 issues and 385 pull requests.</p>



<p>A central difference between the approach I take and the one of previous courses is that I start from <strong>Boolean circuits</strong> as the first model of computation. Boolean circuits are crucial to teach the topics above:</p>



<ul><li>Cryptography is much more natural with circuits rather than Turing machines as the model of computation. Statements such as “128 bits of security” make no sense in the asymptotic Turing machine formalism, but can be made precise with circuits.</li><li>The standard model for quantum computing is quantum circuits.</li><li>Derandomization is best described using the circuit model, and of course many results such as BPP in the Polynomial-Hierarchy are best shown using circuits and the class P/poly as an intermediate concept. </li><li>Circuits are a very natural fit for machine learning, and in particular Neural Networks are just a special type of circuit.</li></ul>



<p>Finally, while circuits are often considered an “advanced” topic, they have some advantages over automata as the initial model of computation:</p>



<ol><li><strong>Finite is always easier than infinite:</strong> Starting with circuits enables us to start the course talking about arguably the simplest object: finite functions. Writing down the truth table of a finite function, and showing that there is more than one circuit to compute the same function, also helps clarify the difference between <strong>specification</strong> of a function and its <strong>implementation</strong> by some algorithm, which is distinction that many students grapple with.</li><li><strong>Circuits are connected to actual hardware</strong>. An intro to TCS course is not a pure math course – we want to convey to students that are models are motivated by actual computing. Circuits make this connection much closer, and less artificial than automata or even Turing machines.</li><li><strong>Can show cool theorems early.</strong> If we start with automata, then the first theorems we show can often seem not well motivated to students. It takes some time to build the machinery to show the main theorem – equivalence of automata and regular expressions – and the proof of that theorem is rather technical. In contrast, with circuits we can show three important theorems rather quickly: <strong>(1)</strong> <em>every</em> finite function <img alt="f:\{0,1\}^n \rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be computed by some circuit of at most <img alt="\tilde{O}(2^n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BO%7D%282%5En%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> size, <strong>(2)</strong> <em>every</em> circuit of size <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be represented as a labeled graph and hence (using adjacency list)  by a string of size <img alt="\tilde{O}(s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BO%7D%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and <strong>(3)</strong> using (2) and the fact that there are <img alt="2^{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B2%5En%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> functions mapping <img alt="\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, there <em>exist</em> some function <img alt="f:\{0,1\}^n \rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that <em>requires</em> a circuit of <img alt="\tilde{\Omega}(2^n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5COmega%7D%282%5En%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> gates.</li></ol>



<p>While the course is a theory course, and not about programming, one of my goals in the book and course was to connect it to programming. This is not just to motivate students and make them feel that the material is “practical” but also to better understand the theory itself. Notions such as NP-completeness reductions can be often confusing to students (which is why they get the direction wrong half the time). Implementing a reduction from 3SAT to independent set and seeing the end result make it much more concrete.</p>



<p/>


<div class="wp-block-image">
<figure class="aligncenter size-large"><a href="https://windowsontheory.files.wordpress.com/2022/06/image-1.png"><img alt="" class="wp-image-8409" src="https://windowsontheory.files.wordpress.com/2022/06/image-1.png?w=1024"/></a>3SAT to independent set reduction from the <a href="https://introtcs.org/public/lec_12_NP.html#the-independent-set-problem">chapter on NP reductions</a>.</figure></div>


<p>One way in which I wanted to use programming is to demonstrate to students how we can take a piece of Python code such as the code for adding two numbers given in their binary representation:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; gutter: false; title: ; notranslate">def add(A,B): 
      """Add two binary numbers, given as lists of bits"""
      Y = []
      carry = zero(A[0]) # initialize carry to 0
      for i in range(len(A)): # compute i-th digit of output
            y = xor(A[i],B[i],carry) # xor function
            carry = maj(A[i],B[i],carry) # majority function
            Y.append(y)
      Y.append(carry)
      return Y

</pre></div>


<p>And obtain the corresponding circuit:</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2022/06/image-2.png"><img alt="" class="wp-image-8413" src="https://windowsontheory.files.wordpress.com/2022/06/image-2.png?w=1007"/></a></figure>



<p>The code also uses the following one-linear helper functions</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; gutter: false; title: ; notranslate">def maj(a,b,c): return (a &amp; b) | (b&amp;c) | (a&amp;c)
def zero(a): return a &amp; ~a
def xor2(a,b): return (a &amp; ~b) | (~a &amp; b)
def xor(*L): return xor2(*L) if len(L)==2 else xor2(xor(*L[:-1]),L[-1])
</pre></div>


<p>If you think about it, the task corresponds to extracting the <strong>computational graph</strong> of a piece of Python code. This is precisely the same task that <em>auto-differentiation</em> packages such as <a href="https://pytorch.org/">Pytorch</a> need to do. Hence it can be solved in a similar way. Thus, inspired by Karpathy’s <a href="https://github.com/karpathy/micrograd">micro-grad</a> package (see my <a href="https://windowsontheory.org/2020/11/03/yet-another-backpropagation-tutorial/">back-propagation tutorial</a>) and using the awesome <a href="https://schemdraw.readthedocs.io/en/latest/">SchemDraw</a> package, I wrote a short <a href="https://colab.research.google.com/drive/1Hv6LVrEZDJ5s5NgR1bZPbCkz5NLIgX8d#scrollTo=Y-XFrGdO069l"><strong>colab notebook</strong></a> that does precisely that.</p>



<p>Specifically, the notebook defines a <code>Bit</code> class that (as its name suggests) stores a single bit. The class defines the logical AND, OR and NOT operations ( <code>&amp;</code>, <code>|</code> , <code>~</code> in Python). If a and b are two bits then <code>c = a &amp; b</code> not just contains the value which is the AND of the values of <code>a</code> and <code>b</code>, but also pointers to a and b and remembers how it was computed from them.  This allows  us to obtain from <code>c</code> a formula/circuit expressing it in terms of <code>a</code> and <code>b</code>.</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; gutter: false; title: ; notranslate">class Bit:
  counter  = 0
  def __init__(self,val=0, label="-"): 
    self.label = label
    self.data = val
    self.children = []
  
  def op(self,f, label, *others):
    inputs = [self.data] + [o.data for o in others]
    out = Bit(f(*inputs),label)
    out.children = [self] + list(others)
    return out

  def __and__(self,other): return self.op(lambda a,b: a &amp; b, "\\wedge", other)
  def __or__(self,other): return self.op(lambda a,b: a | b, "\\vee", other)
  def __invert__(self): return self.op(lambda a: ~a, "\\neg")
</pre></div>


<p>Now we can write a simple recursive function <code>formula</code> (see the <a href="https://colab.research.google.com/drive/1Hv6LVrEZDJ5s5NgR1bZPbCkz5NLIgX8d#scrollTo=g7ykkoEbH6NJ">notebook</a>) to give out the latex of the formula corresponding to how a particular bit was computed. So if we write </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; gutter: false; title: ; notranslate">from IPython.display import Markdown, display, Math
Y = xor(Bit(0,"X_0"), Bit(1,"X_1"))
Math(formula(Y))
</pre></div>


<p>Then we will get</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2022/06/image-3.png"><img alt="" class="wp-image-8421" src="https://windowsontheory.files.wordpress.com/2022/06/image-3.png?w=283"/></a></figure>



<p>The code of a recursive function that transforms this into the circuit </p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2022/06/image-4.png"><img alt="" class="wp-image-8423" src="https://windowsontheory.files.wordpress.com/2022/06/image-4.png?w=659"/></a>is only slightly more complicated. The code to draw the addition circuit above is the following:</figure>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: python; gutter: false; title: ; notranslate">A = [Bit(0,f"A_{i}") for i in range(2)]
B = [Bit(0,f"B_{i}") for i in range(2)]
draw_circ(*add(A,B))
</pre></div>


<p>See the <a href="https://colab.research.google.com/drive/1Hv6LVrEZDJ5s5NgR1bZPbCkz5NLIgX8d#scrollTo=hHqMEfe9ZUY6">colab notebook</a> for more.</p></div>
    </content>
    <updated>2022-06-21T16:55:24Z</updated>
    <published>2022-06-21T16:55:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-07-07T08:37:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2022-06-21-sandglass/</id>
    <link href="https://decentralizedthoughts.github.io/2022-06-21-sandglass/" rel="alternate" type="text/html"/>
    <title>Safe Permissionless Consensus</title>
    <summary>Nakamoto’s consensus protocol works in a permissionless model, where nodes can join and leave without notice. However, it guarantees agreement only probabilistically. Is this weaker guarantee a necessary concession to the severe demands of supporting a permissionless model? We show that, at least in a benign failure model, it is...</summary>
    <updated>2022-06-21T12:00:00Z</updated>
    <published>2022-06-21T12:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2022-07-06T22:46:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8378</id>
    <link href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/" rel="alternate" type="text/html"/>
    <title>The uneasy relationship between deep learning and (classical) statistics</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">An often-expressed sentiment is that deep learning (and machine learning in general) is “simply statistics,” in the sense that it uses different words to describe the same concepts statisticians have been studying for decades. In the 1990s, Rob Tibshirani wrote the following tongue-in-cheek “glossary”:: Something about this table resonates with me.  In fact, as anyone … <a class="more-link" href="https://windowsontheory.org/2022/06/20/the-uneasy-relationship-between-deep-learning-and-classical-statistics/">Continue reading <span class="screen-reader-text">The uneasy relationship between deep learning and (classical) statistics</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An often-expressed sentiment is that deep learning (and machine learning in general) is “simply statistics,” in the sense that it uses different words to describe the same concepts statisticians have been studying for decades. In the 1990s, Rob Tibshirani wrote the following tongue-in-cheek “glossary”::</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="300" src="https://lh3.googleusercontent.com/RauK9YOaLdTiw42nyAQHRuuV9nLfa-zKY49NgpOX1z0pDk0QSe77LQLtZHtAt575adehcZjv7Jbkg8FvXqLklGvprfBRzYaNSk-Q7EtIuV0Kda-5fgCqXLC1xCZuPWzeJAxIbQMCAj6mKMAfeA" width="442"/></figure></div>


<p>Something about this table resonates with me.  In fact, as anyone using Pytorch knows, since Tibshiriani posted this table, many of the terms on the right have found broader use in the machine learning community. (And I do hope that statisticians’ grants and conferences have improved as well…)</p>



<p>But thinking of deep learning purely in terms of statistics misses crucial aspects of its success. A better critique of deep learning is that <strong>it uses statistical terms to describe radically different concepts</strong>. In meme form, it is the “Princess Bride” meme on the right that is a better critique of deep learning than <a href="https://www.instagram.com/sandserifcomics/">sandserif</a>’s meme on the left. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="-107" src="https://lh6.googleusercontent.com/NNnn3c1UfSLSUSfQk6TdrbBHUarDnY9UKgEEUJ0DtEOi0LyREmCmMyIWbxmybd6uRD23Is5GHYeI5caxqKF3QQycm9tbiEuufcwzwDz8dmjWUIoBpG9v_S1pEIMStfoHkp64McsybsF_rLwxsg" width="-230"/><strong>Figure:</strong> I claim that the right critique of deep learning is not that it uses different words to describe old statistical terms, but rather that it uses these terms to describe a radically different process.</figure></div>


<p/>



<p><strong>This blog post: organization. </strong>In this post, I explain this point of view and why some of the most fundamental aspects of deep learning deviate radically from statistics and even from classical machine learning. In this somewhat long post, I’ll start by talking about the difference between <strong>explanation</strong> and <strong>prediction</strong> when fitting models to data. I’ll then discuss two “cartoons” of a learning process: <strong>fitting a statistical model</strong> using empirical risk minimization and <strong>teaching a math skill to a (human) student</strong>. I then discuss which one of those processes is a closer match to deep learning. Spoiler: while the math and code of deep learning is nearly identical to the first scenario (fitting a statistical model), I claim that a deeper level, some of deep learning’s most aspects are captured by the “teaching a skill to a student” scenario. I do not claim to have a full theory for deep learning. In fact,I strongly suspect such a theory doesn’t exist. Rather, I believe different aspects of deep learning are best understood from different lenses, and the statistical lens cannot provide the complete picture.</p>



<p><em>Caveat:</em><strong> </strong> While I contrast deep learning with statistics in this post, I refer to “classical statistics” as it was studied in the past and explained in textbooks. Many statisticians are studying deep learning and going beyond classical methods, analogously to how physicists in the 20th century needed to expand the framework of classical physics. Indeed, the blurring of the lines between computer scientists and statisticians is a modern (and very welcome!) phenomenon that benefits us all. </p>



<h2><strong>1) Predictions vs. explanations in model fitting.</strong></h2>



<p>Scientists have fitted models to observations for thousands of years. For example, as mentioned in my <a href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/">philosophy of science book review post</a>, the Egyptian astronomer Ptolemy came up with an ingenious model for the movement of the planets. Ptolemy’s model was geocentric (with planets rotating around the earth) but had a sequence of “knobs” (concretely, epicycles) that gave it excellent predictive accuracy. In contrast, Copernicus’ initial <em>heliocentric</em> model posited a circular orbit of planets around the sun. It was a simpler model than Ptolemy’s (with fewer “adjustable knobs”) and got the big picture right, but was <em>less accurate</em> in predicting observations. (Copernius later added his own epicycles so he could match Ptolemy’s performance.)</p>



<p>Ptolemy’s and Copernicus’ models were incomparable. If you needed a “black box” for <strong>predictions</strong>, then Ptolemy’s geocentric model was superior. If you wanted a simple model into which you can “peer inside” and that could be the starting point for a theory to <strong>explain</strong> the movements of the stars, then Copernicus’ model was better. Indeed, eventually, Kepler refined Copernicus’ models to elliptical orbits and came up with his three laws of planetary movements, which enabled Newton to explain them using the same laws of gravity that apply here on earth. For that, it was crucial that the heliocentric model wasn’t simply a “black box” that provides predictions, but rather was given by simple mathematical equations with few “moving parts.” Over the years, astronomy continued to be an inspiration for developing statistical techniques. Gauss and Legendre (independently) <a href="https://www.jstor.org/stable/2240811">invented least-squares regression</a> around 1800 to predict the orbits of asteroids and other celestial bodies. Cauchy’s <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">1847 invention of gradient descent</a> was also motivated by astronomical predictions.</p>



<p>In physics, you can (at least sometimes) “have it all” – find the “right” theory that achieves the best predictive accuracy and the best explanation for the data. This is captured by sentiments such as Occam’s Razor, which can be thought of as positing that simplicity, predictive power, and explanatory insights, are all aligned with one another. However, in many other fields, there is a tension between the twin goals of <strong>explanation</strong> (or, more generally, <strong>insight</strong>) and <strong>prediction</strong>. If you simply want to predict observations, then a “black box” could very well be best. On the other hand, if you want to extract insights such as a causal model, general principles, or significant features, then a simpler model that you can understand and interpret might be better. The right choice of model depends on its usage. Consider, for example, a dataset containing genetic expressions and a phenotype (say some disease) for many individuals. If your goal is to predict<strong> </strong>the chances of an individual getting sick, you want to use the best model for that task, regardless of how complex it is or how many genes it depends on. In contrast, if your goal is to identify a few genes for further investigation in a wet lab, a complicated black box would be of limited use, even if it’s highly accurate.</p>



<p>This point was forcefully made in <a href="https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full">Leo Breiman’s famous 2001 essay on the two cultures of statistical modeling</a>. The “data modeling culture” focuses on simple generative models that <strong>explain</strong> the data. In contrast, the “algorithmic modeling culture” is agnostic on how the data is generated and focuses on finding models that <strong>predict </strong>the data, no matter how complex. Breiman argued that statistics was too dominated by the first culture, and this focus has <em>“</em><em>led to irrelevant theory and questionable scientific conclusions”</em> and <em>“prevented statisticians from working on exciting new problems.”</em></p>



<p>Breiman’s paper was controversial, to say the least. Brad Efron responded to it by saying that, while he agreed with some points, <em>“at first glance, Leo Breiman’s stimulating paper looks like an argument against parsimony and scientific insight, and in favor of black boxes with lots of knobs to twiddle. At second glance, it still looks that way”</em> (see also <a href="https://www.stat.cmu.edu/~kass/papers/KassOnBreiman.pdf">Kass</a>). In a <a href="https://www.fox.temple.edu/wp-content/uploads/2021/07/Efron-2020-JASA-wdiscussion.pdf">more recent piece</a>, Efron graciously concedes that <em>“Breiman turned out to be more prescient than me: pure prediction algorithms have seized the statistical limelight in the twenty-first century, developing much along the lines Leo suggested.”</em></p>



<h2><strong>2) Classical and modern predictive models.</strong></h2>



<p>Machine learning, deep or not, stands firmly in Breiman’s second culture, with a focus on <strong>prediction</strong>. This culture has a long history.  For example, the following snippets from <a href="https://archive.org/details/patternclassific0000duda">Duda and Hart’s 1973 textbook</a> and <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1962.tb02426.x">Highleyman’s 1962 paper</a> would be very recognizable to deep learning practitioners today:</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="305" src="https://lh6.googleusercontent.com/i79e0Q5uv1DWLfOVoy0MzuJMRCLpZEQQs44mlvyFBCYkYsyXqZByeg1XYsiZi-Jg7jxBcN_ZvDuNJxjgxuXN-qiDLWNSmAwDj-HsLvZHq_25jd5YgJW2g3DviYmwgHXrq9VLcxnKCDFI1Ww5hQ" width="671"/></figure></div>


<p>Similarly, Highleyman’s handwritten characters dataset and the architecture <a href="https://ieeexplore.ieee.org/document/5219431">Chow (1962)</a>  used to fit it  (with ~58% accuracy) would also strike a chord with modern readers, see the <a href="https://mlstory.org/data.html">Hardt-Recht book</a> and their <a href="http://www.argmin.net/2021/10/20/highleyman/">blog post</a>.  </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="297" src="https://lh6.googleusercontent.com/lHZ5yqJuR2K2_gfrAfwTkICu-ogBqYcdPyStrnLvO81ED0WxSbS5ZlObtTMy8WeNvfV7IbS2hpOz9ondLDAitLr77FT-apK4TG2jEEiiaajmGMtydWMYhMux6_pqh0M6nin7oo2LM6g700rPWQ" width="638"/></figure></div>


<h2><strong>3) Why deep learning is different.</strong></h2>



<p>In 1992, <a href="https://www.dam.brown.edu/people/documents/bias-variance.pdf">Geman, Bienenstock, and Doursat</a> wrote a pessimistic article about neural networks, arguing that <em>“current-generation feed-forward neural networks are largely inadequate for difficult problems in machine perception and machine learning”</em>. Specifically, they believed that general-purpose neural networks would not be successful in tackling difficult tasks, and the only way for them to succeed would be via hand-designed features. In their words: <em>“important properties must be built-in or “hard-wired” … not learned in any statistically meaningful way.”</em> In hindsight (which is always 20/20), Geman et al. were completely wrong (if anything, modern architectures such as transformers are even <em>more general</em> than the convolutional networks that existed at the time), but it is interesting to understand <em>why</em> they were wrong. </p>



<p>I believe that the reason is that deep learning is genuinely different from other learning methods. A priori, it seems that deep learning is just one more predictive model, like nearest neighbors or random forests. It may have more “knobs,” but that seems to be a quantitative rather than qualitative difference. However, <a href="https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf">in the words of P.W. Andreson</a>, <strong>“more is different.”</strong>    In Physics, we often need a completely different theory once scale changes by several orders of magnitude, and the same holds in deep learning. The processes that underlie deep learning vs. classical models (parametric or not) are radically different, even if the equations (and Python code) look identical at a high level. </p>



<p>To clarify this point, let’s consider two very different learning processes:<strong> fitting a statistical model</strong> and <strong>teaching math to a student</strong>.</p>



<h3><strong>Scenario A: Fitting a statistical model</strong></h3>



<p>Classically, fitting a statistical model to data corresponds to the following:</p>



<ol><li>We observe some data <img alt="X,y" class="latex" src="https://s0.wp.com/latex.php?latex=X%2Cy&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. (Think of  <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> as an <img alt="n\times p" class="latex" src="https://s0.wp.com/latex.php?latex=n%5Ctimes+p&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> matrix and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> as an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dimensional vector; think of the data as coming from a <strong>structure and noise</strong> model: each coordinate <img alt="y_i" class="latex" src="https://s0.wp.com/latex.php?latex=y_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is obtained as <img alt="f_0(x_i)+e_i" class="latex" src="https://s0.wp.com/latex.php?latex=f_0%28x_i%29%2Be_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="e_i" class="latex" src="https://s0.wp.com/latex.php?latex=e_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the corresponding noise , using additive noise for simplicity, and <img alt="f_0" class="latex" src="https://s0.wp.com/latex.php?latex=f_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> as the “ground truth.”)</li><li>We fit a model <img alt="\hat{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to the data by running some <strong>optimization algorithm</strong> to minimize an <strong>empirical risk</strong> of <img alt="\hat{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. That is, we use optimization to (try to) find <img alt="\hat{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that minimizes a quantity <img alt="L(\hat{f}) + R(\hat{f})" class="latex" src="https://s0.wp.com/latex.php?latex=L%28%5Chat%7Bf%7D%29+%2B+R%28%5Chat%7Bf%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="L(\cdot)" class="latex" src="https://s0.wp.com/latex.php?latex=L%28%5Ccdot%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a loss term (capturing how close <img alt="\hat{f}(X)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28X%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is to <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) and <img alt="R(\hat{f})" class="latex" src="https://s0.wp.com/latex.php?latex=R%28%5Chat%7Bf%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an optional regularization term (attempting to bias <img alt="\hat{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> toward simpler models under some measure). </li><li>Our hope is that our model will have good <strong>population loss</strong>, in the sense that the <strong>generalization error/loss</strong>  <img alt="\mathbb{E} [L(\hat{f}(x),y)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+%5BL%28%5Chat%7Bf%7D%28x%29%2Cy%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is small (where this expectation is taken over the total population from which our data was drawn).</li></ol>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="-135" src="https://lh5.googleusercontent.com/j84eNgmOsBGbSDI3nbHRLMmKYP-fAqSSfkjX6eZOlndHm00xibwbMEfLcW4Yw58JpZK9bgzc1gFvTzsZsUPVC4r1pnpB_koZv1kBpn_L4dHQBWuVk5cDwwoAZj-nVlTRu1twjUh25ihRTDcglQ" width="-290"/><strong>Figure:</strong> <a href="https://www.fox.temple.edu/wp-content/uploads/2021/07/Efron-2020-JASA-wdiscussion.pdf">Effron’s</a> cartoon of recovering Newton’s first law from noisy observations.</figure></div>


<p>This very general paradigm captures many settings, including least-squares linear regression, nearest neighbors,  neural network training, and more. In the classical statistical setup, we expect to observe the following: </p>



<p><strong>Bias/variance tradeoff:</strong> Let <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the set of models that we optimize over. (If we are in the non-convex setting and/or have a regularizer term, we can let <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the set of such models that can be achieved by the algorithm with non-negligible probability, taking the effects of algorithm choice and regularizer into account.)  The <strong>bias</strong> of <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the best approximation to the ground truth that can be achieved by an element <img alt="\hat{f} \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The larger the class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the smaller the bias, and it can be zero if <img alt="f_0 \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f_0+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. However, the larger the class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the more samples we would need to narrow down its members and hence the more <strong>variance</strong> in the model that the algorithm outputs. The overall <strong>generalization error</strong> is the sum of the bias term and the contribution from the variance. Hence statistical learning typically displays a <strong>bias/variance tradeoff,</strong> with a “goldilocks choice” of the right model complexity that minimizes the overall error.  Indeed, Geman et al. justified their pessimism on neural networks by saying that <em>“the fundamental limitations resulting from the bias-variance dilemma apply to all nonparametric inference models, including neural networks.” </em></p>



<p><strong>More is not always better.</strong> In statistical learning, getting more features or data does not necessarily improve performance. For example, learning from data that contains many irrelevant features is more challenging. Similarly, learning from a mixture model, in which data comes from one of two distributions (e.g., <img alt="y=f_0(x)" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Df_0%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="y=f_1(x)" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Df_1%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>), is harder than learning each distribution independently. </p>



<p><strong>Diminishing returns.</strong> In many settings, the number of data points needed to reduce the prediction noise to a level of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> scales as <img alt="k/\epsilon^2" class="latex" src="https://s0.wp.com/latex.php?latex=k%2F%5Cepsilon%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for some parameter <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In such cases, it takes about <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples to “get off the ground” but once we do so we face a regime of diminishing returns, whereby if it took <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> points to achieve (say) 90% accuracy, it will take roughly an additional <img alt="3n" class="latex" src="https://s0.wp.com/latex.php?latex=3n&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> points to increase accuracy to 95%. In general, as we increase our resources (whether data, model complexity, or computation) we expect to capture finer and finer distinctions rather than unlocking qualitatively new capabilities.</p>



<p><strong>Strong dependence on loss, data.</strong> When fitting a model to high-dimensional data, small details can make a big difference. Statisticians know that choices such as an L1 or L2 regularizer matter, not to mention using completely different datasets (e.g., Wikipedia vs. Reddit). High-dimensional optimizers of different quantities will be very different from one another.</p>



<p><strong>No natural “difficulty” of data points (at least in some settings)</strong>. Traditionally, we think of data points as sampled independently from some distribution. Though points closer to the decision boundary could be harder to classify, given the concentration-of-measure phenomena in high dimensions, we expect that most points would be of similar distance. Thus at least in classical data distributions, we don’t expect points to vary greatly in their difficulty level. However, mixture models can display such variance in difficulty level, and hence, unlike the other issues above, such variance would not be terribly surprising in the statistical setting.</p>



<h3><strong>Scenario B: Learning math</strong></h3>



<p>In contrast to the above, consider the setting of teaching a student some particular topic in mathematics (e.g., computing derivatives), by giving them general instructions, as well as exercises to work through. This is not a formally defined setting, but let’s consider some of its qualitative features:</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="360" src="https://lh5.googleusercontent.com/FLZEzRfYsdYYku-FxQlt8r6oc9PAAXqaoGo5-R2ABxKoGB1hxUvJWiSYxt1weyqTJGujoGh1YhIAoE_2RuM-nzzSicDlpjDSFjAXeedX2schUZEb3VB7dWQirp4n1bt90Qz3_K5SlYHeg9zJ6w" width="567"/><strong>Figure: </strong>An exercise to learn a particular math skill from the <a href="https://www.ixl.com/math/calculus/find-derivatives-using-the-product-rule">IXL website</a>.</figure></div>


<p/>



<p><strong>Learning a skill, rather than approximating a distribution.</strong> In this setting, the student learns a <em>skill</em> rather than an estimator/predictor for some quantity. While defining “skill” is not a trivial task (and not one we’ll undertake in this blog post), it is a qualitatively different object. In particular, even if the function mapping exercises to solutions cannot be used as a “black box” to solve some related task X, we believe that the <strong>internal representations</strong> that the student develops while working through these problems can still be useful for X.</p>



<p><strong>More is better.</strong> Generally, students that do more problems and problems of different types achieve better performance. A “mixture model” – doing some calculus problems and some algebra problems – does not hurt the student in their calculus performance and in fact, could only help.</p>



<p><strong>“Grokking” or unlocking capabilities, moving to automatic representations.</strong> While at some point there are diminishing returns also when solving problems, students do seem to undergo several phases. There is a stage in which doing some problems helps a concept “click” and unlocks new capabilities. Also, as students repeat problems of a specific type, they seem to move their facilities and representations of these problems to a lower level, enabling certain automaticity with them that they didn’t have before.</p>



<p><strong>Performance is partially independent of the loss and data.</strong> There is more than one way to teach mathematical concepts. Students who study with different books, educational approaches, or grading systems can eventually learn the same material and (as far as we can tell) similar internal representations of it.</p>



<p><strong>Some problems are harder than others.</strong> In math exercises, we often see a strong correlation between how different students solve the same problem. There does seem to be an inherent difficulty level for a problem and a natural progression of difficulty that is optimal for learning. Indeed this is precisely what is being done by platforms such as <a href="https://www.ixl.com/">IXL</a>.</p>



<h2><strong>4) Is deep learning more like statistical estimation or a student learning a skill?</strong></h2>



<p>So, which of the above two metaphors more appropriately captures modern deep learning, and specifically the reasons why it is so successful? Statistical model fitting seems to correspond well to the math and the code. Indeed the canonical Pytorch training loop trains deep networks through empirical risk minimization as described above:</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="182" src="https://lh4.googleusercontent.com/yf9rz1IV1Ac1LvzQPzh8rY3GLZpecxUtOjm-ITQRuWHb3vrPjDAd5BLUTitGPWlYAFtVR8Ou7a2JnsMIld33hPoe2QKeNXsQLySJIGbNgMCdvx0Vcr7No6cBHXxDClY1xvYNN6iBUJbX6bhEzA" width="402"/></figure></div>


<p>However, on a deeper level, the relation between the two settings is not as clear. For concreteness, let us fix a particular learning task. Consider a classification algorithm that is trained using the method of “self-supervised learning + a linear probe” (what we called Self-Supervised + Simple or SSS in <a href="https://windowsontheory.org/2020/10/18/understanding-generalization-requires-rethinking-deep-learning/">our paper with Bansal and Kaplun</a>). Concretely, the algorithm is trained as follows:</p>



<ol><li>Suppose that the data is a sequence <img alt="\{ (x_i,y_i) \}_{i=1..n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+%28x_i%2Cy_i%29+%5C%7D_%7Bi%3D1..n%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="x_i \in \mathbb{R}^p " class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%5Cin+%5Cmathbb%7BR%7D%5Ep+&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is some datapoint (say an image for concreteness) and <img alt="y_i" class="latex" src="https://s0.wp.com/latex.php?latex=y_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a label.</li><li>We first find a deep neural network implementing <em>representation function</em> <img alt="\hat{r}:\mathbb{R}^p \rightarrow \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Br%7D%3A%5Cmathbb%7BR%7D%5Ep+%5Crightarrow+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This function is trained only using the datapoints <img alt="\{ x_1,\ldots, x_n \}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+x_1%2C%5Cldots%2C+x_n+%5C%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and not using the labels by minimizing some type of a self-supervised loss function. Example of such loss functions are <em>reconstruction</em> or in-painting (recovering some part of the input <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> from another) or <em>contrastive learning</em> (finding <img alt="\hat{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7Br%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="\parallel \hat{r}(x)-\hat{r}(x') \parallel" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cparallel+%5Chat%7Br%7D%28x%29-%5Chat%7Br%7D%28x%27%29+%5Cparallel&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is significantly smaller when <img alt="x,x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cx%27&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are augmentations of the same datapoint than when they are two random points).  </li><li>We then use the full labeled data <img alt="\{ (x_i,y_i )" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+%28x_i%2Cy_i+%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to fit a linear classifier <img alt="\hat{\ell}:\mathbb{R}^d \to \mathbb{R}^c" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cell%7D%3A%5Cmathbb%7BR%7D%5Ed+%5Cto+%5Cmathbb%7BR%7D%5Ec&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (where <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of classes) that minimizes the cross-entropy loss. Our final classifier is the map <img alt="x \mapsto \mathrm{arg}\max \hat{\ell}(\hat{r}(x))" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmathrm%7Barg%7D%5Cmax+%5Chat%7B%5Cell%7D%28%5Chat%7Br%7D%28x%29%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li></ol>



<p>Step 3 merely fits a linear classifier and so the “magic” happens in step 2 (self-supervised learning of a deep network). Some of the properties we see in self-supervised learning include:</p>



<p><strong>Learning a skill rather than approximating a function. </strong>Self-supervised learning is not about approximating a function but rather learning representations that could be used in a variety of downstream tasks. For example, this is the dominant paradigm in natural language processing. Whether the downstream task is obtained through linear probe, fine tuning, or prompting is of secondary importance.</p>



<p><strong>More is better.</strong> In self-supervised learning, representation quality improves with data quantity. We don’t suffer from mixing in several sources: in fact, the more diverse the data is, the better. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="246" src="https://lh3.googleusercontent.com/9bjInHmiYVAFGBmtD-I50K7UwTOCRvSa69OjdwwuezlkPjEZS-1_7gwfzS3_-MuLOwLjm_swX_D02L95Do8brDTQJe7TFmfijsykp4GhNvR4i0wx9AABlqKKTS6VrJaus6VsRUPbVL-76cJjGg" width="602"/><strong>Figure: </strong>Dataset for the <a href="https://arxiv.org/abs/2204.02311">Google PaLM model</a>.</figure></div>


<p/>



<p><strong>Unlocking capabilities.</strong> We have seen time and again discontinuous improvements in deep learning models as we scale resources (data, compute, model size). This has also <a href="https://arxiv.org/abs/2201.02177">been demonstrated</a> in some synthetic settings. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="389" src="https://lh5.googleusercontent.com/AkKwPPjyXXrmQ10_5yrAfhzhCjAeO9oWbQD2cXCgEarxyuSdb5dlZg6lSKFs0IJQ63njmlyDp14X-gRFaQgCQ0RLaBY8o5YgXl9-reba1XzOFJxn_QPSoaCgE4DlXFA8xfCyVWm7bXuWL5BMPg" width="723"/><strong>Figure: </strong>The <a href="https://arxiv.org/abs/2204.02311">PaLM model</a> displays some discontinuous improvements in some benchmarks as model size increases (with caveat of only three sizes in these plots), with some surprising capabilities unlocked such as explaining jokes.</figure></div>


<p/>



<p><strong>Performance is largely independent of loss or data</strong>. There is more than one self-supervised loss. Several contrastive and reconstruction losses have been used for images. For language models, we sometimes use one-sided reconstruction (predict next token) and sometimes masked models whose goal is to predict a masked input from both the left and right token. We can also use slightly different datasets. These can make differences in efficiency, but as long as we make “reasonable” choices, typically raw resources are more significant predictors of performance than the particular loss or dataset used.</p>



<p><strong>Some instances are harder than others.</strong> This point is not specific to self-supervised learners. It does seem that data points have some inherent “difficulty level”. Indeed, we have several pieces of empirical evidence for the notion that different learning algorithms have a different “skill level” and different points have a different “difficulty level” (with the probability of classifier <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> classifying point <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> correctly being monotonically increasing with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s skill and monotonically decreasing with <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s difficulty). The “skill vs. difficulty” paradigm is the cleanest explanation for the “accuracy on the line” phenomenon uncovered by <a href="https://arxiv.org/abs/1902.10811">Recht et al</a> and  <a href="https://arxiv.org/abs/2107.04649">Miller et al</a>. Our paper with Kaplun, Ghosh, Garg, and Nakkiran also shows how different inputs in datasets have an inherent “difficulty profile” that seems to be generally robust with respect to different model families.</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="372" src="https://lh5.googleusercontent.com/vqgciucsObFfbagqYE_AMDW-IFcVaRIThslLnoR5QpXEeb4q24IHMPitPGjRaIKsijNECy3el8e00QI6xh6STAA7LbNeAfmU16deO59P6Lq4hvNUS1aSRduynVxcF9r2bIGS4rZOMq5ZAmCqAA" width="591"/><strong>Figure: </strong><a href="https://share.streamlit.io/millerjohnp/linearfits_app/main/app.py">Miller et al’s graph</a> showing accuracy on the line phenomena for classifiers trained on CIFAR-10 and tested on CINIC-10.</figure></div>


<p/>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="391" src="https://lh6.googleusercontent.com/cNFVOxR5avX184hU0mFY3_WTqfZhyD7n0Jqg7mcn36PkZk_835mx8fdXOMJTW5xt10EwnBblx480XdRBEcSRq5RSpPE6rYAr7R9PrBx8VCT54FAixyg3bXgxueRLWWdMKteLgiuAkuXrAcs5Eg" width="680"/><strong>Figure: </strong>Deconstruction of datasets into points from <a href="https://arxiv.org/abs/2202.09931">Kaplun and Ghosh et al</a> of different “difficulty profiles” for increasingly more resourced classifiers. The graphs at the top describe the different softmax probabilities for most likely classes as a function of the global accuracy of a classifier from a certain family indexed by training time. The pie charts at the bottom show the decomposition of different datasets into points of the varying types. Note that this decomposition is similar with respect to different neural architectures.</figure></div>


<p/>



<p><strong>Training as teaching.</strong> Training of modern large models seems much more like teaching a student than fitting a model to data, complete with “taking breaks” or trying different approaches when the student doesn’t get it or seems tired (training diverges). The <a href="https://github.com/facebookresearch/metaseq/tree/main/projects/OPT/chronicles">training logbook of Meta’s large model</a> is instructive- aside from issues with hardware, we can see interventions such as switching different optimization algorithms in the middle of training and even considering “hot swapping” the activation functions (GELU to RELU). The latter doesn’t make much sense if you think of model training as fitting data as opposed to learning representations. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="201" src="https://lh4.googleusercontent.com/ujboPOfONTtBdZypMX-flKhxBQWnvxhdGN_eVox8BXzHSJbGyk7qzTCTe-lE4aUKewvrEMaU9etWb8eis7KTNXsawJ1bR-mou7-EvF9n_VwTruJJWvqkd34BvON5-99DUof45skX7EOHfgljeg" width="548"/></figure></div>

<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="152" src="https://lh6.googleusercontent.com/EFP7xVCiHMsAt_ZBGE1U10t6KCzWXRqI_KNOYOXE6KfUWBydmKILs3LB7LHEyAReTYLu9nSajqKUq0prSf7y_W8puRS0iymFznyYe07kPnDI3vVm6AQDcJnmp0WhV2W4J_lUbnNjU03tmCvnRg" width="634"/><strong>Figure:</strong> Excerpts from Meta’s training log</figure></div>


<p/>



<h2><strong>4.1) But what about supervised learning?</strong></h2>



<p>Up to this point, we only discussed self-supervised learning, but the canonical example of deep learning- the one you teach first in a course- is still supervised learning. After all, deep learning’s “ImageNet moment” came with, well, ImageNet. Does anything we said above still apply to this setting?</p>



<p>First, the emergence of supervised large-scale deep learning is to some extent a historical accident, aided by the availability of large high quality labeled datasets (i.e. ImageNet). One could imagine an alternative history in which deep learning first started showing breakthrough advances in Natural Language Processing via unsupervised learning, and only later transported into vision and supervised learning.</p>



<p>Second,  we have some evidence that even though they use radically different loss functions, supervised and self-supervised learning behave similarly “under the hood.” Both often achieve the same performance, and in work with <a href="https://arxiv.org/abs/2106.07682">Bansal and Nakkiran</a>, we showed that they also learn similar internal representations. Concretely, for every <img alt="k \in \{1..d-1\}" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5C%7B1..d-1%5C%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, one can “stitch together” the first <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> layers of a depth <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> model that was trained via self-supervision with the last <img alt="d-k" class="latex" src="https://s0.wp.com/latex.php?latex=d-k&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> layers of a supervised model with little loss in performance. </p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="299" src="https://lh4.googleusercontent.com/b8aReNvFG6VNbi-tTsFB-WMov7HSF4T56CXm1eFMDHfmg4wmDAX_St76YqZWZU2EfMd4xyIPHSSzzs_QUkz5Jslor2l_8M23OKM_XghkF2IVHMW5ntHpxH05aWLT8i6UYZD3ZrBnLEg6ymTkqA" width="681"/><strong>Figure: </strong>Table from <a href="https://arxiv.org/abs/2006.10029">SimCLR v2 paper (Chen et al)</a>. Note the general similarity in performance between supervised learning, fine-tuned (100%) self-supervised, and self-supervised + linear probe.</figure></div>


<p/>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="341" src="https://lh6.googleusercontent.com/nKpdayaNeS9IP7Vhu7QhDaTjUcgEZoAl3CbY9bmGZkV_YfcUL4rmRy1esz5824eheS5EbiPBl5pIaNJk4wZuJoAfEXB7rjyP3AVCFF_ke5mN4lQsI2MlvCV4ZBWJGIkeWA9WbtN89Z184fm69w" width="759"/><strong>Figure: </strong>Stitching a self supervised and a supervised model from <a href="https://arxiv.org/abs/2106.07682">Bansal et al</a>. Left: If the self-supervised is (say) <img alt="3\%" class="latex" src="https://s0.wp.com/latex.php?latex=3%5C%25&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> less accurate than the supervised model, then fully compatible representations would result in a stitching penalty of <img alt="p\cdot 3\%" class="latex" src="https://s0.wp.com/latex.php?latex=p%5Ccdot+3%5C%25&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> when <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> fraction of layers come from the self-supervised model. If the models are completely incompatible then we expect accuracy to drop sharply as we stitch more models. Right: Actual results for stitching different self-supervised models. We also stitch a random network as a “sanity check”.</figure></div>


<p/>



<p>The advantage of self-supervised + simple models is that they can separate out the aspects of feature learning or “deep learning magic” (done by the deep representation function) from the statistical model fitting (done by the linear or other “simple” classifier on top of this representation).</p>



<p>Finally, while this is more speculative, the fact that often “meta learning” seems to amount to learning representations (see <a href="https://arxiv.org/abs/1909.09157">Raghu et al.</a> and <a href="https://arxiv.org/abs/2206.03271">Mandi et. al.</a>)  can be considered as another piece of evidence that this is much of what’s going on, regardless of the objective that the model ostensibly optimizes. </p>



<h2><strong>4.2) What about over parameterization?</strong></h2>



<p>The reader may have noticed that I skipped over what is considered the canonical example of the disparity between the model of statistical learning and deep learning in practice: the absence of a “bias-variance tradeoff” (see Belkin et al.’s <a href="https://arxiv.org/abs/1812.11118">double descent</a>) and the ability of over-parameterized models to generalize well.</p>



<p>There are two reasons I do not focus on this aspect. First, if supervised learning really does correspond to self-supervised + simple learning “under the hood” then that <a href="https://arxiv.org/abs/2010.08508">may explain its generalization ability</a>.  Second, I think that over parameterization is <em>not</em> crucial to deep learning’s success. Deep networks are special not because they are big compared to the number of samples but because they are big in absolute terms. Indeed, typically in unsupervised / self-supervised learning models are <em>not</em> over parameterized. Even for the very large language models, their datasets are larger still. This does not make their performance any less mysterious.</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="292" src="https://lh5.googleusercontent.com/BgGdDZHOPsPxw2-dYE49AS7Lc_Opwqmg19d0PAUVNX9vwSOadwVrQAingo1pXUOJ_o13v25QV_SFQU7qdtSBwGk05VsWwsIwyc2j8wcGBkZ9m3wWCyiOOwTynhF3zWFZFe1PmDJKCZgO1IDl4A" width="673"/><strong>Figure: </strong><a href="https://arxiv.org/abs/2010.08127">Nakkiran-Neyshabur-Sadghi’s</a> “deep bootstrap” paper demonstrates that modern architectures behave similarly in the “over parameterized” or “under sampled” regime (where models train for multiple epochs on limited data until over fitting: “real world” in the above figure) and “under parameterized” or “online” regime (where models train for a single epoch, seeing each sample only once: “ideal world” in the above figure). </figure></div>


<p/>



<h2><strong>Summary</strong></h2>



<p>Statistical learning certainly plays a role in deep learning. However, despite using similar terms and code, thinking of deep learning as simply fitting a model with more knobs than classical models misses a lot of what is essential to its success. The human student metaphor is hardly perfect either. Like biological evolution, even though deep learning consists of many repeated applications of the same rule – gradient descent on empirical loss- it gives rise to highly complex outcomes. It seems that at different times different components of networks learn different things, including, representation learning, prediction fitting, implicit regularization, and pure noise. We are still searching for the right lens by which to ask questions about deep learning, let alone answer them.</p>



<p><strong>Acknowledgments:</strong> Thanks to Lucas Janson and Preetum Nakkiran for comments on early versions of this blog post.</p></div>
    </content>
    <updated>2022-06-20T17:15:58Z</updated>
    <published>2022-06-20T17:15:58Z</published>
    <category term="Philosophizing"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-07-07T08:37:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4640</id>
    <link href="https://lucatrevisan.wordpress.com/2022/06/20/workshop-on-fairness-in-ai/" rel="alternate" type="text/html"/>
    <title>Workshop on Fairness in AI</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Next Monday, June 27, I am organizing a workshop on issues around fairness, bias and discrimination in AI and Machine Learning. Here is a link to the program. Remote participation is possible (link in the website), and in-person participation is … <a href="https://lucatrevisan.wordpress.com/2022/06/20/workshop-on-fairness-in-ai/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Next Monday, June 27, I am organizing a workshop on issues around fairness, bias and discrimination in AI and Machine Learning.</p>



<p>Here is a <a href="https://lucatrevisan.github.io/fai.html">link to the program</a>. Remote participation is possible (link in the website), and in-person participation is free but we ask people to register so we can print badges and order the appropriate number of coffee breaks.</p>



<p>This workshop is being organized in partnership with <a href="https://www.edge-glbt.it/">EDGE</a>, an Italian NGO that works on LGBT rights, and it is the first event of their initiative “A+I: Algoritmi + Inclusivi”, which will feature an awareness campaign and a series of video interviews that will start after the summer.</p>



<p>In next week’s workshop, Oreste Pollicino from Bocconi will talk about the perspective of the legal community around algorithmic discrimination, Symeon Papadopoulos from ITI Patras will give a survey on issues of fairness in image processing and image understanding, Sanghamitra Dutta from J.P. Morgan AI will talk about how to use the theory of causality to reason about fairness, Debora Nozza and Dirk Hovy from Bocconi will talk about issues of fairness in language models and natural language processing, and Omer Reingold from Stanford and Cynthia Dwork from Harvard will talk about modeling and achieving fairness in prediction models.</p>



<p>The last morning session will be a panel discussion moderated by Damiano Terziotti from EDGE about perspectives from the social sciences and from outside academia. It will feature, among others, <a href="https://en.wikipedia.org/wiki/Brando_Benifei">Brando Benifei</a>, a member of the EU parliament who has played a leading role in the <a href="https://en.wikipedia.org/wiki/Artificial_Intelligence_Act">2021 draft EU regulations on AI</a>. The other panel members are Alessandro Bonaita, who is a data science lead in Generali (Italy’s largest insurance company), Luisella Giani, who is leading a technology consulting branch of Oracle for Europe, Middle East and Africa, Cinzia Maiolini, who is in the national secretariat of CGIL, an Italian Union, and Massimo Airoldi from the University of Milan.</p>



<p>If you are in or near Milan next week, come to what is shaping up to be a memorable event!</p></div>
    </content>
    <updated>2022-06-20T11:36:33Z</updated>
    <published>2022-06-20T11:36:33Z</published>
    <category term="Bocconi"/>
    <category term="technology"/>
    <category term="Algoritmi + Inclusivi"/>
    <category term="things that are excellent"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-07-07T08:37:07Z</updated>
    </source>
  </entry>
</feed>
