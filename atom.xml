<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-09-29T23:51:47Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/149</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/149" rel="alternate" type="text/html"/>
    <title>TR20-149 |  Robustly Self-Ordered Graphs: Constructions and Applications to Property Testing | 

	Oded Goldreich, 

	Avi Wigderson</title>
    <summary>A graph $G$ is called {\em self-ordered}\/ (a.k.a asymmetric) if the identity permutation is its only automorphism.
Equivalently, there is a unique isomorphism from $G$ to any graph that is isomorphic to $G$. 
We say that $G=(V,E)$ is {\em robustly self-ordered}\/ if the size of the symmetric difference between $E$ and the edge-set of the graph obtained by permuting $V$ using any permutation $\pi:V\to V$ is proportional to the number of non-fixed-points of $\pi$.

We show that robustly self-ordered bounded-degree graphs exist (in abundance), and that they can be constructed efficiently, in a strong sense.
Specifically, given the index of a vertex in such a graph, it is possible to find all its neighbors in polynomial-time (i.e., in time that is poly-logarithmic in the size of the graph).

We provide two very different constructions, in tools and structure. 
The first, a direct construction, is based on proving a sufficient condition for robust self-ordering, 
which requires that an auxiliary graph, on {\em pairs|}\/ of vertices of the original graph, is expanding. 
In this case the original graph is (not only robustly self-ordered but) also expanding.
The second construction proceeds in three steps: It boosts the mere existence of robustly self-ordered graphs, 
which provides explicit graphs of sublogarithmic size, to an efficient construction of polynomial-size graphs, 
and then, repeating it again, to exponential-size(robustly self-ordered) graphs that are locally constructible.
This construction can yield robustly self-ordered graphs that are either expanders or highly disconnected, having logarithmic size connected components. 

We also consider graphs of unbounded degree, seeking correspondingly unbounded robustness parameters.
We again demonstrate that such graphs (of linear degree) exist (in abundance), and give an explicit construction. 
This turns out to require very different tools, and the definition and constructions of new pseudo-random objects. 
Specifically, we show that the construction of such graphs reduces to the construction of non-malleable two-source extractors 
with very weak parameters but with an additional natural feature. 
Next, we reduce the construction of such non-malleable two-source extractors to the construction of ``relocation-detecting'' codes. Loosely speaking, in such code permuting arbitrarily the coordinates of a random codeword yields a string that is far any other codeword. We conclude by showing how to construct relocation-detecting codes (of various types, including ones with constant rate).  

We demonstrate that robustly self-ordered bounded-degree graphs are useful towards obtaining lower bounds on the query complexity of testing graph properties both in the bounded-degree and the dense graph models.  
Indeed, their robustness offers efficient, local and distance preserving reductions from testing problems on ordered structures (like sequences) to the unordered (effectively unlabeled) graphs. 
One of the results that we obtain, via such a reduction, is a subexponential separation 
between the complexity of testing and tolerant testing of graph properties in the bounded-degree graph model.</summary>
    <updated>2020-09-29T19:33:10Z</updated>
    <published>2020-09-29T19:33:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/</id>
    <link href="https://cstheory-jobs.org/2020/09/29/postdoctoral-research-associate-high-performance-parallel-graph-based-machine-learning-at-david-r-cheriton-school-of-computer-science-university-of-waterloo-apply-by-january-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Research Associate, High-Performance Parallel Graph-Based Machine Learning at David R. Cheriton School of Computer Science, University of Waterloo (apply by January 1, 2021)</title>
    <summary>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning. Website: https://jobs.siam.org/job/postdoctoral-research-associate/54755436/ Email: kfountou@uwaterloo.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for a postdoctoral research associate to join our research group (opallab.ca) at the Computer Science department at the University of Waterloo. Our goal is to develop parallel and communication efficient algorithms for large-scale graph-based machine learning.</p>
<p>Website: <a href="https://jobs.siam.org/job/postdoctoral-research-associate/54755436/">https://jobs.siam.org/job/postdoctoral-research-associate/54755436/</a><br/>
Email: kfountou@uwaterloo.ca</p></div>
    </content>
    <updated>2020-09-29T19:26:33Z</updated>
    <published>2020-09-29T19:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T23:49:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/148</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/148" rel="alternate" type="text/html"/>
    <title>TR20-148 |  Simple and fast derandomization from very hard functions: Eliminating randomness at almost no cost | 

	Roei Tell, 

	Lijie Chen</title>
    <summary>Extending the classical ``hardness-to-randomness'' line-of-works, Doron et al. (FOCS 2020) recently proved that derandomization with near-quadratic time overhead is possible, under the assumption that there exists a function in $\mathcal{DTIME}[2^n]$ that cannot be computed by randomized SVN circuits of size $2^{(1-\epsilon)\cdot n}$ for a small $\epsilon$.

In this work we extend their inquiry and answer several open questions that arose from their work. Our main result is that *derandomization with almost no time overhead is possible*, under a plausible hypothesis. Specifically, we show that probabilistic algorithms that run in time $T(n)$ can be deterministically simulated in time $n\cdot T(n)^{1+\epsilon}$, under a hypothesis that is formally incomparable to the one of Doron et al., but is arguably more standard: We assume that there exist non-uniformly secure one-way functions, and that for $\delta=\delta(\epsilon)$ and $k=k_T(\epsilon)$ there exists a problem in $\mathcal{DTIME}[2^{k\cdot n}]$ that is hard for algorithms that run in time $2^{(k-\delta)\cdot n}$ and use $2^{(1-\delta)\cdot n}$ bits of advice. We also show that the latter hypothesis (or, more accurately, a relaxation of it that we use) is in fact necessary to obtain the derandomization conclusion if one relies on a PRG construction (as is indeed our approach).

For sub-exponential time functions $T(n)=2^{n^{o(1)}}$ we further improve the derandomization time to $n^{1+\epsilon}\cdot T(n)$, under a mildly stronger hypothesis. We also show that *the multiplicative time overhead of $n$ is essentially optimal*, conditioned on a counting version of the non-deterministic strong exponential-time hypothesis (i.e., on $\# NSETH$). Nevertheless, we show that *in the average-case setting a faster derandomization is possible*: Under hypotheses similar to the ones in our main result, we show that for every $L\in\mathcal{BPTIME}[n^k]$ there exists a deterministic algorithm $A_L$ running in time $n^{\epsilon}\cdot n^{k}$ such that for every distribution $\mathcal{D}$ over $\{0,1\}^n$ samplable in time $n^k$ it holds that $\Pr_{x\sim\mathcal{D}}[A_L(x)=L(x)]\ge1-n^{-\omega(1)}$. 

Lastly, we present an alternative proof for the result of Doron et al. using a *proof paradigm that is both considerably simpler and more general*; in fact, we show how to simplify the analysis of any construction that ``extracts randomness from a pseudoentropic string''. We use this simpler proof to extend their result, deducing a mildly slower derandomization (i.e., with cubic or quadratic overhead) from weaker hardness assumptions (i.e., for SVN circuits that do not use randomness).</summary>
    <updated>2020-09-29T17:09:04Z</updated>
    <published>2020-09-29T17:09:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1252</id>
    <link href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/" rel="alternate" type="text/html"/>
    <title>It happens to everyone…but it’s not fun</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A recent post on this blog concerned the posting of our paper MIP*=RE on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial … <a href="https://mycqstate.wordpress.com/2020/09/29/it-happens-to-everyonebut-its-not-fun/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h1/>



<p>A <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">recent post</a> on this blog concerned the posting of our paper <a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> on the arXiv and gave a personal history of the the sequence of works that led to the result. Quite unfortunately (dramatically?) a few weeks after initial posting of the paper (and the blog post) John Wright discovered an important error in the proof of a key result in this sequence: my paper <a href="https://doi.org/10.1137/140956622">Three-player entangled XOR games are NP-hard to approximate</a>, published in 2016 in a special issue of the SIAM journal on computing dedicated to selected papers from the FOCS’13 conference. While I did not mention this paper directly in the previous blog post, its main result, a proof of soundness of the Raz-Safra low-degree test against entangled-player strategies, is a key ingredient in the proof of the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>, itself a key ingredient in the MIP*=RE paper. (Strictly speaking the latter paper relies on an extension of my result to two-player games obtained in a <a href="https://arxiv.org/abs/1710.03062">follow-up</a> with Natarajan. Since that paper re-used the flawed part of my earlier analysis in a black-box manner it is similarly impacted.) So then…?</p>



<h2 id="scientific-aspects">Scientific aspects</h2>



<p>I’ll start with the science. The result MIP*=RE, to the best of our knowledge, remains correct. In order to remove the dependence of the proof on the flawed paper we extended the soundness analysis of Babai et al.’s multilinearity test against entangled provers from my <a href="https://arxiv.org/abs/1207.0550">paper with Ito</a> to the case of multivariate polynomials of low individual degree. We just posted a self-contained analysis of that test on the arXiv <a href="https://arxiv.org/abs/2009.12982">here</a> and updated the MIP*=RE paper to account for the replacement (see v2.). The latter paper is currently under review; on this I will simply say that, as for all mathematical works, it is advised to wait until the outcome of the refereeing process is complete before declaring confidence in the validity of the result. For a more in-depth description of the changes made I refer to the introduction of the <a href="https://arxiv.org/abs/2009.12982">new paper</a>.</p>



<p>Our analysis of the “low individual-degree test” mentioned in the preceding paragraph can be used to recover the main result of my SICOMP’16 paper in a weakened form. Since the proof is different and does not directly fix the error I have decided to withdraw the paper from SICOMP. For more details on the error itself and consequences to other works, such as the quantum low-degree test and the quantum games PCP, I refer to the <a href="http://users.cms.caltech.edu/~vidick/errata.pdf">short note</a> I wrote to accompany the withdrawal of the paper. The one-sentence summary is that essentially all subsequent results expressed in terms of “high” complexity classes such as QMA-EXP, NEEXP, etc., still hold, while “scaled-down” results on the hardness of entangled games can only be recovered by allowing a substantial weakening of parameters. In particular, the <a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a> holds in its scaled-up version (testing exp(n) EPR pairs using poly(n) resources), but the scaled-down version requires polylog(n) communication to test n EPR pairs, instead of O(log n) as claimed.</p>



<h2 id="personal-aspects">Personal aspects</h2>



<p>In addition to notifying researchers in the area of the bug, my goal in writing this blog post is to help me exorcise the demon of having a large mistake in one of my papers. In doing so I was inspired by Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=2854">blog post</a> on a similar topic. (I’ll admit that even just linking explicitly to his post helps reassure myself, a power which I believe was one of Scott’s aims in writing the post. So, thanks Scott, and allow me to pass it on!) The faulty paper is not based on a minor back-of-the-envelope observation; in fact it is one that I was quite proud of. The mistake in it is not small either; it’s a mistake that I cannot find any excuse for having made. Yet here I am: after having spent the past 6 months trying to find an alternative proof, I now strongly believe that the problem cannot be solved using the kind of techniques that I had imagined could do so. Whether the theorem statement is true or not, I don’t know; but at the moment I am unable to prove it. I have to accept that there is a bug.</p>



<p>As painful as it is I realize that I am writing this post from a relatively comfortable position. Who knows if I would have been able to do the same had we not been able to recover a full proof of MIP*=RE. Moreover, after having banged my head against the problem for 6 months straight (COVID helping, walls were never far) I am now able to see my failure in a more positive light: the story I told in the previous blog post is not yet closed; there is an open challenge for me to solve. It is a very personal challenge; having spent the past 6 months delineating it I have accumulated sufficient grounds on which to believe that it is an interesting one. I feel grateful for this.</p>



<p>Getting there wasn’t easy. So, even though I am writing from a place of comfort, I want to share the pain that the whole adventure has caused me. This simple acknowledgment is especially directed at younger readers: so that when it happens to you, you will remember this post and know that you’re not the only one. That it happens to others as well and that it is possible to face, accept, and move away from such errors. Of course you will try to fix it first. Here are some quick tips. While banging your head on the problem, make sure that your understanding increases every day. To start with, do you really understand why there is a mistake? Of course some step doesn’t go through, but what is the simplest form of the incriminated statement that fails? Can you write it down? Can you formulate and prove a weaker form of it? Probe the issue with examples. Try to isolate it as much as you can: take it outside of the paper and formulate an entirely self-contained version of it, stripped of all the baggage. Place it in as many different contexts that you can think of: do you still believe it, does it stand on its own? Again, make sure that you learn. Even if you’re not able to fix the claim, are you exploring a new technique, discovering a new perspective? If it didn’t work yesterday it probably won’t work today either: make sure that you always find something new to inject. When you can no longer do this, it is time to stop. So make sure to set yourself some near-term (how much to think about this on any given day) and long-term (when to admit defeat) limits. Always remember that problems are much more often solved in the shower or while walking the dog than at the desk. Finally, be ready to move on. Realize that as bad as it may seem to you, there are more important things in life. You can’t reduce yourself to this one problem: you’ll be stronger for accepting what happened than trying to bury it at all costs. If you don’t see this by yourself, try to talk about it. Explain the situation you’re in to your close non-academia friends, to your parents; practice on your pet first if it helps. You will realize, as I eventually did (although it took quite a while) that <em>it is ok</em>.</p>



<h2 id="social-aspects">Social aspects</h2>



<p>After the scientific and the personal aspects, let me end with the sociological. This is a semi-tangent but it is a good opportunity to discuss a topic that we scientists, possibly even more so us working in the “hard sciences” (as the French call “proof-based” disciplines), are insufficiently sensitized to. This is the topic of how science is made, and what is the reality of this “absolute truth” that we claim to discover and establish in our mathematical results.</p>



<p>My paper was posted on arXiv in 2013, it was accepted to the FOCS conference and published in its proceedings the same year, and it appeared in the journal SICOMP in 2016. Both publications were refereed. Since its posting the paper has been cited 47 times (google scholar) and its main result is used in an essential way in at least half a dozen papers (my best guess). 7 years later a big hole has been found in the proof. How did the “truth value of my result evolve in the process? Was it always wrong or was there a time where it had truth, in whatever appropriate sense of the word?</p>



<p>I realize that these questions can be given trivial answers—I know what is an axiom and what is a proof system. Yet I am trying to push myself, and my reader, to look a little deeper. An analogy might help. The situation brought to mind a book by French philosopher of science Bruno Latour, called (in its English translation) <a href="https://www.amazon.com/Laboratory-Life-Construction-Scientific-Facts/dp/069102832X">Laboratory Life: The Construction of Scientific Facts</a>. This is a wonderful book, which goes well beyond the classic misconceptions from Popper or even Kuhn; it should be mandatory reading for every scientist. In one of the early chapters of the book Latour makes a detailed study of how subsequent citations can collectively enshrine an initial claim based entirely on the citer’s conscious or unconscious biases in making use of the citation (i.e. in complete independence from any ground “truth” or “importance” of the cited work). An entertaining example of this can be found in <a href="https://journals.sagepub.com/doi/full/10.1177/0306312714535679">this article</a>, which dissects the claim that “The myth from the 1930s that spinach is a rich source of iron was due to misleading information in the original publication: a malpositioned decimal point gave a 10-fold overestimate of iron content.” The example, pursued in great depth in the article, shows very well how one citation at a time the (spoiler: unjustified) claim is given more and more credibility until it eventually becomes a fact: from initial citations written in a tentative tone “according to Z, it could be that…” to more assertive citations “Z has shown that” by more and more well-known researchers in highly-read journals to pure fact (citation above). I highly recommend the article!</p>



<p>It is easy to dismiss this story as being the result of “sloppy” authors misrepresenting a “soft” claim whose truth value is not well-determined in the first place, being a statement about the world rather than about some hypothetical mathematical universe. Yet I believe that it is worth taking the time to examine with an open mind what exactly, if anything, distinguishes a claim about the iron content of spinach from the main “theorem” of my paper. From its initial posting on the arXiv to its presentation in a conference and its journal publication to the multiple citations it received through its use in subsequent works, and including multiple other considerations such as my own credibility (itself the result of so many other considerations) and the results base “believability”, when was the logical statement itself evaluated? Does it matter? Did the unchallenged existence of the result for 7 years impact the course of science? Or was it a mistake that was bound to be discovered and has no lasting consequences?</p>



<p>These are questions for the reader, that can be (and are probably better) asked in other contexts than the limited one of my result. Indeed there is a much broader point to all this, that I only meant to raise in an indirect manner. It is impossible to disregard the fact that our scientific work is grounded in cultural and societal effects, but we may disagree on the impact that this grounding has. We owe it to ourselves and to our readers (broadly interpreted—from colleagues to funding agencies to the broader public) to refuse to hide behind the thin veil of “hard science”, mathematics or logic, and educate ourselves to what it is that we really are doing.</p></div>
    </content>
    <updated>2020-09-29T15:50:43Z</updated>
    <published>2020-09-29T15:50:43Z</published>
    <category term="meta"/>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="Uncategorized"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2020-09-29T23:51:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13317</id>
    <link href="http://arxiv.org/abs/2009.13317" rel="alternate" type="text/html"/>
    <title>A note on differentially private clustering with large additive error</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13317">PDF</a><br/><b>Abstract: </b>In this note, we describe a simple approach to obtain a differentially
private algorithm for k-clustering with nearly the same multiplicative factor
as any non-private counterpart at the cost of a large polynomial additive
error. The approach is the combination of a simple geometric observation
independent of privacy consideration and any existing private algorithm with a
constant approximation.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13316</id>
    <link href="http://arxiv.org/abs/2009.13316" rel="alternate" type="text/html"/>
    <title>Explorable Uncertainty in Scheduling with Non-Uniform Testing Times</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckl:Alexander.html">Alexander Eckl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13316">PDF</a><br/><b>Abstract: </b>The problem of scheduling with testing in the framework of explorable
uncertainty models environments where some preliminary action can influence the
duration of a task. In the model, each job has an unknown processing time that
can be revealed by running a test. Alternatively, jobs may be run untested for
the duration of a given upper limit. Recently, D\"urr et al. [5] have studied
the setting where all testing times are of unit size and have given lower and
upper bounds for the objectives of minimizing the sum of completion times and
the makespan on a single machine. In this paper, we extend the problem to
non-uniform testing times and present the first competitive algorithms. The
general setting is motivated for example by online user surveys for market
prediction or querying centralized databases in distributed computing.
Introducing general testing times gives the problem a new flavor and requires
updated methods with new techniques in the analysis. We present constant
competitive ratios for the objective of minimizing the sum of completion times
in the deterministic case, both in the non-preemptive and preemptive setting.
For the preemptive setting, we additionally give a first lower bound. We also
present a randomized algorithm with improved competitive ratio. Furthermore, we
give tight competitive ratios for the objective of minimizing the makespan,
both in the deterministic and the randomized setting.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13257</id>
    <link href="http://arxiv.org/abs/2009.13257" rel="alternate" type="text/html"/>
    <title>Approximation algorithms for connectivity augmentation problems</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13257">PDF</a><br/><b>Abstract: </b>In Connectivity Augmentation problems we are given a graph $H=(V,E_H)$ and an
edge set $E$ on $V$, and seek a min-size edge set $J \subseteq E$ such that $H
\cup J$ has larger edge/node connectivity than $H$. In the Edge-Connectivity
Augmentation problem we need to increase the edge-connectivity by $1$. In the
Block-Tree Augmentation problem $H$ is connected and $H \cup S$ should be
$2$-connected. In Leaf-to-Leaf Connectivity Augmentation problems every edge in
$E$ connects minimal deficient sets. For this version we give a simple
combinatorial approximation algorithm with ratio $5/3$, improving the previous
$1.91$ approximation that applies for the general case. We also show by a
simple proof that if the Steiner Tree problem admits approximation ratio
$\alpha$ then the general version admits approximation ratio
$1+\ln(4-x)+\epsilon$, where $x$ is the solution to the equation
$1+\ln(4-x)=\alpha+(\alpha-1)x$. For the currently best value of $\alpha=\ln
4+\epsilon$ this gives ratio $1.942$. This is slightly worse than the best
ratio $1.91$, but has the advantage of using Steiner Tree approximation as a
"black box", giving ratio $&lt; 1.9$ if ratio $\alpha \leq 1.35$ can be achieved.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13198</id>
    <link href="http://arxiv.org/abs/2009.13198" rel="alternate" type="text/html"/>
    <title>Discrimination of attractors with noisy nodes in Boolean networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Xiaoqing.html">Xiaoqing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ching:Wai=Ki.html">Wai-Ki Ching</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Sini.html">Sini Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13198">PDF</a><br/><b>Abstract: </b>Observing the internal state of the whole system using a small number of
sensor nodes is important in analysis of complex networks. Here, we study the
problem of determining the minimum number of sensor nodes to discriminate
attractors under the assumption that each attractor has at most K noisy nodes.
We present exact and approximation algorithms for this minimization problem.
The effectiveness of the algorithms is also demonstrated by computational
experiments using both synthetic data and realistic biological data.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13184</id>
    <link href="http://arxiv.org/abs/2009.13184" rel="alternate" type="text/html"/>
    <title>The canonical directed tree decomposition and its applications to the directed disjoint paths problem</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giannopoulou:Archontia_C=.html">Archontia C. Giannopoulou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kreutzer:Stephan.html">Stephan Kreutzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwon:O=joung.html">O-joung Kwon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13184">PDF</a><br/><b>Abstract: </b>The canonical tree-decomposition theorem, given by Robertson and Seymour in
their seminal graph minors series, turns out to be one of the most important
tool in structural and algorithmic graph theory. In this paper, we provide the
canonical tree decomposition theorem for digraphs. More precisely, we construct
directed tree-decompositions of digraphs that distinguish all their tangles of
order $k$, for any fixed integer $k$, in polynomial time. As an application of
this canonical tree-decomposition theorem, we provide the following result for
the directed disjoint paths problem:
</p>
<p>For every fixed $k$ there is a polynomial-time algorithm which, on input $G$,
and source and terminal vertices $(s_1, t_1), \dots, (s_k, t_k)$, either
</p>
<p>1. determines that there is no set of pairwise vertex-disjoint paths
connecting each source $s_i$ to its terminal $t_i$, or
</p>
<p>2.finds a half-integral solution, i.e., outputs paths $P_1, \dots, P_k$ such
that $P_i$ links $s_i$ to $t_i$, so that every vertex of the graph is contained
in at most two paths. Given known hardness results for the directed disjoint
paths problem, our result cannot be improved for general digraphs, neither to
fixed-parameter tractability nor to fully vertex-disjoint directed paths. As
far as we are aware, this is the first time to obtain a tractable result for
the $k$-disjoint paths problem for general digraphs. We expect more
applications of our canonical tree-decomposition for directed results.
</p></div>
    </summary>
    <updated>2020-09-29T23:22:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13090</id>
    <link href="http://arxiv.org/abs/2009.13090" rel="alternate" type="text/html"/>
    <title>A note on weak near unanimity polymorphisms</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Arash.html">Arash Rafiey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13090">PDF</a><br/><b>Abstract: </b>We show that deciding whether a given relational structure $\mathcal{R}$
admits a weak near unanimity polymorphism is polynomial time solvable.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.13071</id>
    <link href="http://arxiv.org/abs/2009.13071" rel="alternate" type="text/html"/>
    <title>$\epsilon$-net Induced Lazy Witness Complexes on Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arafat:Naheed_Anjum.html">Naheed Anjum Arafat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Debabrota.html">Debabrota Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bressan:St=eacute=phane.html">Stéphane Bressan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.13071">PDF</a><br/><b>Abstract: </b>Computation of persistent homology of simplicial representations such as the
Rips and the C\v{e}ch complexes do not efficiently scale to large point clouds.
It is, therefore, meaningful to devise approximate representations and evaluate
the trade-off between their efficiency and effectiveness. The lazy witness
complex economically defines such a representation using only a few selected
points, called landmarks.
</p>
<p>Topological data analysis traditionally considers a point cloud in a
Euclidean space. In many situations, however, data is available in the form of
a weighted graph. A graph along with the geodesic distance defines a metric
space. This metric space of a graph is amenable to topological data analysis.
</p>
<p>We discuss the computation of persistent homologies on a weighted graph. We
present a lazy witness complex approach leveraging the notion of $\epsilon$-net
that we adapt to weighted graphs and their geodesic distance to select
landmarks. We show that the value of the $\epsilon$ parameter of the
$\epsilon$-net provides control on the trade-off between choice and number of
landmarks and the quality of the approximate simplicial representation.
</p>
<p>We present three algorithms for constructing an $\epsilon$-net of a graph. We
comparatively and empirically evaluate the efficiency and effectiveness of the
choice of landmarks that they induce for the topological data analysis of
different real-world graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12982</id>
    <link href="http://arxiv.org/abs/2009.12982" rel="alternate" type="text/html"/>
    <title>Quantum soundness of the classical low individual degree test</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Zhengfeng.html">Zhengfeng Ji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Anand.html">Anand Natarajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vidick:Thomas.html">Thomas Vidick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wright:John.html">John Wright</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuen:Henry.html">Henry Yuen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12982">PDF</a><br/><b>Abstract: </b>Low degree tests play an important role in classical complexity theory,
serving as basic ingredients in foundational results such as $\mathsf{MIP} =
\mathsf{NEXP}$ [BFL91] and the PCP theorem [AS98,ALM+98]. Over the last ten
years, versions of these tests which are sound against quantum provers have
found increasing applications to the study of nonlocal games and the complexity
class~$\mathsf{MIP}^*$. The culmination of this line of work is the result
$\mathsf{MIP}^* = \mathsf{RE}$ [JNV+20].
</p>
<p>One of the key ingredients in the first reported proof of $\mathsf{MIP}^* =
\mathsf{RE}$ is a two-prover variant of the low degree test, initially shown to
be sound against multiple quantum provers in [Vid16]. Unfortunately a mistake
was recently discovered in the latter result, invalidating the main result of
[Vid16] as well as its use in subsequent works, including [JNV+20].
</p>
<p>We analyze a variant of the low degree test called the low individual degree
test. Our main result is that the two-player version of this test is sound
against quantum provers. This soundness result is sufficient to re-derive
several bounds on~$\mathsf{MIP}^*$ that relied on [Vid16], including
$\mathsf{MIP}^* = \mathsf{RE}$.
</p></div>
    </summary>
    <updated>2020-09-29T23:20:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12981</id>
    <link href="http://arxiv.org/abs/2009.12981" rel="alternate" type="text/html"/>
    <title>Parametric UMAP: learning embeddings with deep neural networks for representation and semi-supervised learning</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sainburg:Tim.html">Tim Sainburg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McInnes:Leland.html">Leland McInnes</a>, Timothy Q Gentner <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12981">PDF</a><br/><b>Abstract: </b>We propose Parametric UMAP, a parametric variation of the UMAP (Uniform
Manifold Approximation and Projection) algorithm. UMAP is a non-parametric
graph-based dimensionality reduction algorithm using applied Riemannian
geometry and algebraic topology to find low-dimensional embeddings of
structured data. The UMAP algorithm consists of two steps: (1) Compute a
graphical representation of a dataset (fuzzy simplicial complex), and (2)
Through stochastic gradient descent, optimize a low-dimensional embedding of
the graph. Here, we replace the second step of UMAP with a deep neural network
that learns a parametric relationship between data and embedding. We
demonstrate that our method performs similarly to its non-parametric
counterpart while conferring the benefit of a learned parametric mapping (e.g.
fast online embeddings for new data). We then show that UMAP loss can be
extended to arbitrary deep learning applications, for example constraining the
latent distribution of autoencoders, and improving classifier accuracy for
semi-supervised learning by capturing structure in unlabeled data. Our code is
available at https://github.com/timsainb/ParametricUMAP_paper.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12892</id>
    <link href="http://arxiv.org/abs/2009.12892" rel="alternate" type="text/html"/>
    <title>The Complexity of Connectivity Problems in Forbidden-Transition Graphs and Edge-Colored Graphs</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shaohua.html">Shaohua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Okrasa:Karolina.html">Karolina Okrasa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sorge:Manuel.html">Manuel Sorge</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12892">PDF</a><br/><b>Abstract: </b>The notion of forbidden-transition graphs allows for a robust generalization
of walks in graphs. In a forbidden-transition graph, every pair of edges
incident to a common vertex is permitted or forbidden; a walk is compatible if
all pairs of consecutive edges on the walk are permitted. Forbidden-transition
graphs and related models have found applications in a variety of fields, such
as routing in optical telecommunication networks, road networks, and
bio-informatics.
</p>
<p>We initiate the study of fundamental connectivity problems from the point of
view of parameterized complexity, including an in-depth study of tractability
with regards to various graph-width parameters. Among several results, we prove
that finding a simple compatible path between given endpoints in a
forbidden-transition graph is W[1]-hard when parameterized by the
vertex-deletion distance to a linear forest (so it is also hard when
parameterized by pathwidth or treewidth). On the other hand, we show an
algebraic trick that yields tractability when parameterized by treewidth of
finding a properly colored Hamiltonian cycle in an edge-colored graph; properly
colored walks in edge-colored graphs is one of the most studied special cases
of compatible walks in forbidden-transition graphs.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12809</id>
    <link href="http://arxiv.org/abs/2009.12809" rel="alternate" type="text/html"/>
    <title>Rank/Select Queries over Mutable Bitmaps</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanda:Shunsuke.html">Shunsuke Kanda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12809">PDF</a><br/><b>Abstract: </b>The problem of answering rank/select queries over a bitmap is of utmost
importance for many succinct data structures. When the bitmap does not change,
many solutions exist in the theoretical and practical side. In this work we
consider the case where one is allowed to modify the bitmap via a flip(i)
operation that toggles its i-th bit. By adapting and properly extending some
results concerning prefix-sum data structures, we present a practical solution
to the problem, tailored for modern CPU instruction sets. Compared to the
state-of-the-art, our solution improves runtime with no space degradation.
Moreover, it does not incur in a significant runtime penalty when compared to
the fastest immutable indexes, while providing even lower space overhead.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12685</id>
    <link href="http://arxiv.org/abs/2009.12685" rel="alternate" type="text/html"/>
    <title>The smoothed complexity of Frank-Wolfe methods via conditioning of random matrices and polytopes</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rademacher:Luis.html">Luis Rademacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shu:Chang.html">Chang Shu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12685">PDF</a><br/><b>Abstract: </b>Frank-Wolfe methods are popular for optimization over a polytope. One of the
reasons is because they do not need projection onto the polytope but only
linear optimization over it. To understand its complexity, Lacoste-Julien and
Jaggi introduced a condition number for polytopes and showed linear convergence
for several variations of the method. The actual running time can still be
exponential in the worst case (when the condition number is exponential). We
study the smoothed complexity of the condition number, namely the condition
number of small random perturbations of the input polytope and show that it is
polynomial for any simplex and exponential for general polytopes. Our results
also apply to other condition measures of polytopes that have been proposed for
the analysis of Frank-Wolfe methods: vertex-facet distance (Beck and Shtern)
and facial distance (Pe\~na and Rodr\'iguez).
</p>
<p>Our argument for polytopes is a refinement of an argument that we develop to
study the conditioning of random matrices. The basic argument shows that for
$c&gt;1$ a $d$-by-$n$ random Gaussian matrix with $n \geq cd$ has a $d$-by-$d$
submatrix with minimum singular value that is exponentially small with high
probability. This has consequences on results about the robust uniqueness of
tensor decompositions.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12457</id>
    <link href="http://arxiv.org/abs/2009.12457" rel="alternate" type="text/html"/>
    <title>A Block-Based Triangle Counting Algorithm on Heterogeneous Environments</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Abdurrahman Yaşar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajamanickam:Sivasankaran.html">Sivasankaran Rajamanickam</a>, Jonathan Berry, Ümit V. Çatalyürek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12457">PDF</a><br/><b>Abstract: </b>Triangle counting is a fundamental building block in graph algorithms. In
this paper, we propose a block-based triangle counting algorithm to reduce data
movement during both sequential and parallel execution. Our block-based
formulation makes the algorithm naturally suitable for heterogeneous
architectures. The problem of partitioning the adjacency matrix of a graph is
well-studied. Our task decomposition goes one step further: it partitions the
set of triangles in the graph. By streaming these small tasks to compute
resources, we can solve problems that do not fit on a device. We demonstrate
the effectiveness of our approach by providing an implementation on a compute
node with multiple sockets, cores and GPUs. The current state-of-the-art in
triangle enumeration processes the Friendster graph in 2.1 seconds, not
including data copy time between CPU and GPU. Using that metric, our approach
is 20 percent faster. When copy times are included, our algorithm takes 3.2
seconds. This is 5.6 times faster than the fastest published CPU-only time.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12442</id>
    <link href="http://arxiv.org/abs/2009.12442" rel="alternate" type="text/html"/>
    <title>Hypergraph $k$-cut for fixed $k$ in deterministic polynomial time</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Karthekeyan.html">Karthekeyan Chandrasekaran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12442">PDF</a><br/><b>Abstract: </b>We consider the Hypergraph-$k$-cut problem. The input consists of a
hypergraph $G=(V,E)$ with non-negative hyperedge-costs $c: E\rightarrow R_+$
and a positive integer $k$. The objective is to find a least-cost subset
$F\subseteq E$ such that the number of connected components in $G-F$ is at
least $k$. An alternative formulation of the objective is to find a partition
of $V$ into $k$ non-empty sets $V_1,V_2,\ldots,V_k$ so as to minimize the cost
of the hyperedges that cross the partition. Graph-$k$-cut, the special case of
Hypergraph-$k$-cut obtained by restricting to graph inputs, has received
considerable attention. Several different approaches lead to a polynomial-time
algorithm for Graph-$k$-cut when $k$ is fixed, starting with the work of
Goldschmidt and Hochbaum (1988). In contrast, it is only recently that a
randomized polynomial time algorithm for Hypergraph-$k$-cut was developed
(Chandrasekaran, Xu, Yu, 2018) via a subtle generalization of Karger's random
contraction approach for graphs. In this work, we develop the first
deterministic polynomial time algorithm for Hypergraph-$k$-cut for all fixed
$k$. We describe two algorithms both of which are based on a divide and conquer
approach. The first algorithm is simpler and runs in $n^{O(k^2)}$ time while
the second one runs in $n^{O(k)}$ time. Our proof relies on new structural
results that allow for efficient recovery of the parts of an optimum
$k$-partition by solving minimum $(S,T)$-terminal cuts. Our techniques give new
insights even for Graph-$k$-cut.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2009.12413</id>
    <link href="http://arxiv.org/abs/2009.12413" rel="alternate" type="text/html"/>
    <title>Covering Tree-Based Phylogenetic Networks</title>
    <feedworld_mtime>1601337600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nathan Davidov, Amanda Hernandez, Justin Jian, Patrick McKenna, K. A. Medlin, Roadra Mojumder, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Owen:Megan.html">Megan Owen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quijano:Andrew.html">Andrew Quijano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodriguez:Amanda.html">Amanda Rodriguez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/John:Katherine_St=.html">Katherine St. John</a>, Katherine Thai, Meliza Uraga <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2009.12413">PDF</a><br/><b>Abstract: </b>Tree-based phylogenetic networks, which may be roughly defined as
leaf-labeled networks built by adding arcs only between the original tree
edges, have elegant properties for modeling evolutionary histories. We answer
an open question of Francis, Semple, and Steel about the complexity of
determining how far a phylogenetic network is from being tree-based, including
non-binary phylogenetic networks. We show that finding a phylogenetic tree
covering the maximum number of nodes in a phylogenetic network can be be
computed in polynomial time via an encoding into a minimum-cost maximum flow
problem.
</p></div>
    </summary>
    <updated>2020-09-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/postdoc-senior-postdoc-at-maynooth-university-apply-by-october-25-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc / Senior Postdoc at Maynooth University (apply by October 25, 2020)</title>
    <summary>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland. Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing. Website: https://dna.hamilton.ie/join.html Email: dna.hamilton.ie@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two 2-year postdoc/senior postdoc/technician positions at the Hamilton Institute, Maynooth University, Ireland.</p>
<p>Our group works on both the theory and the engineering of DNA/molecular computers. Several people in our group have backgrounds in CS theory and have learned experimental wet-lab work, taking direct inspiration from the likes of Alan Turing.</p>
<p>Website: <a href="https://dna.hamilton.ie/join.html">https://dna.hamilton.ie/join.html</a><br/>
Email: dna.hamilton.ie@gmail.com</p></div>
    </content>
    <updated>2020-09-28T14:11:12Z</updated>
    <published>2020-09-28T14:11:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T23:49:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/28/scientific-staff-at-opendp-incubated-by-harvard-university-with-support-from-the-sloan-foundation-apply-by-october-15-2020/" rel="alternate" type="text/html"/>
    <title>Scientific Staff  at OpenDP (Incubated by Harvard University with support from the Sloan Foundation) (apply by October 15, 2020)</title>
    <summary>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security – Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19) […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>OpenDP is hiring scientists to work with Gary King, Salil Vadhan and the OpenDP Community. Candidates should have a graduate-level degree, familiarity with differential privacy, and experience with following: – Implementing software for data science, privacy, and/or security<br/>
– Applied statistics, and an interest in working to apply OpenDP software to data-sharing problems. (i.e. COVID-19)</p>
<p>Website: <a href="https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff">https://projects.iq.harvard.edu/opendp/blog/opendp-hiring-scientific-staff</a><br/>
Email: privacytools-info@seas.harvard.edu</p></div>
    </content>
    <updated>2020-09-28T03:47:53Z</updated>
    <published>2020-09-28T03:47:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T23:49:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9181146391897180370</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9181146391897180370/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9181146391897180370" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/a-quote-from-testla-which-is-very.html" rel="alternate" type="text/html"/>
    <title>A Quote from Tesla which is very predictive in one way, and perhaps not in another way</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Nikola Tesla, famous inventor, who lived 1856--1943 said the following:</p><p><br/></p><p>When wireless is perfectly applied the whole earth will be converted into</p><p>a huge brain, which in fact it is, all things being particles of a real</p><p>and rhythmic whole. We shall be able to communicate with one another</p><p>instantly, irrespective of distance. Not only this but through television</p><p>and telephony, we shall see and hear one another as perfectly as though</p><p>we were face to face, despite intervening distances of thousands of miles;</p><p>and the instruments through which we shall be able to do this will be</p><p>amazingly simple compared with our present telephone. A man will be able to</p><p>carry one in his vest pocket.</p><p><br/></p><p>The `vest pocket' at the end really impressed me.</p><p><br/></p><p>By `a man will be able to carry one...' I don't know if he mean all people or if he actually </p><p>meant that women would not need such a device. If that is what he meant then,</p><p>while high marks for tech-prediction, low marks for social-prediction. </p><p><br/></p><p>This quote is SO right-on for technology that I offer the following challenge: Find other quotes from year X that were very predictive for year X+Y for a reasonably large Y.</p><p>ADDED LATER: I will give two answers to my own challenge:</p><p>1) On the TV show THE HONEYMOONERS, in 1955, Ralph Cramden predicts 3-Dim TV. I blogged about that <a href="https://blog.computationalcomplexity.org/2010/05/ralph-kramden-your-wait-is-over-3d-tv_05.html#comment-form">here</a></p><p>2) Did the TV show Get Smart foreshadow cell phones. Maxwell Smart's shoe-phone was portable but wearing it on his foot seems odd. It also used dial, not touch tone. Mel Brooks (co-creator of the series) points out that in the Pilot episode Max is enjoying a show and his phone goes off so he has to leave and take the call -- which was very strange then but standard now. So the show did predict one of the problems with cell phones, if not cell phones themselves. </p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-09-28T01:44:00Z</updated>
    <published>2020-09-28T01:44:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-29T18:33:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=473</id>
    <link href="https://tcsplus.wordpress.com/2020/09/27/tcs-talk-wednesday-september-30-alex-wein-nyu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 30 — Alex Wein, NYU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Alex Wein from NYU will speak about “Low-Degree Hardness of Random Optimization Problems” (abstract below). You can reserve a spot as an individual or a group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, September 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Alex Wein</strong> from NYU will speak about “<em>Low-Degree Hardness of Random Optimization Problems</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our  website</a> on the day of the talk, so people who did not sign up will still be able to  watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: In high-dimensional statistical problems (including planted clique, sparse PCA, community detection, etc.), the class of “low-degree polynomial algorithms” captures many leading algorithmic paradigms such as spectral methods, approximate message passing, and local algorithms on sparse graphs. As such, lower bounds against low-degree algorithms constitute concrete evidence for average-case hardness of statistical problems. This method has been widely successful at explaining and predicting statistical-to-computational gaps in these settings. <br/>While prior work has understood the power of low-degree algorithms for problems with a “planted” signal, we consider here the setting of “random optimization problems” (with no planted signal), including the problem of finding a large independent set in a random graph, as well as the problem of optimizing the Hamiltonian of mean-field spin glass models. I will define low-degree algorithms in this setting, argue that they capture the best known algorithms, and explain new proof techniques for giving lower bounds against low-degree algorithms in this setting. The proof involves a variant of the so-called “overlap gap property”, which is a structural property of the solution space.<br/><br/>Based on joint work with David Gamarnik and Aukosh Jagannath, available at <a href="https://arxiv.org/abs/2004.12063">arXiv:2004.12063</a>.</p></div>
    </content>
    <updated>2020-09-27T17:15:50Z</updated>
    <published>2020-09-27T17:15:50Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-09-29T23:50:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17636</id>
    <link href="https://rjlipton.wordpress.com/2020/09/27/ibm-conference-on-the-informational-lens/" rel="alternate" type="text/html"/>
    <title>IBM Conference on the Informational Lens</title>
    <summary>Some differences from the Computational Lens Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The virtual workshop begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. Today we preview […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Some differences from the Computational Lens</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png"><img alt="" class="alignright wp-image-17638" height="193" src="https://rjlipton.files.wordpress.com/2020/09/ibmclmods.png?w=153&amp;h=193" width="153"/></a></p>
<p>
Chai Wah Wu, Jonathan Lenchner, Charles Bennett, and Yuhai Tu are the moderators for the four days of the First IBM Research Workshop on the Informational Lens. The <a href="https://sites.google.com/view/informational-lens-workshop-1/home">virtual workshop</a> begins Tuesday morning at 10:45 ET. The conference has free registration and of course is online. </p>
<p>
Today we preview the conference and discuss a few of the talks.</p>
<p>
The workshop’s name echoes the moniker “Through the Computational Lens” of <a href="https://simons.berkeley.edu/news/interdisciplinary-collaboration-at-simons">initiatives</a> led by the Simons Institute at Berkeley and used for a 2014 <a href="https://www.ias.edu/ideas/2015/computational-lens">workshop</a> organized by Avi Wigderson at IAS. A <a href="http://theory.cs.berkeley.edu/computational-lens.html">prospectus</a> by the theory group at U.C. Berkeley led off with quantum computing. So will Tuesday’s talks, a full day on quantum by seven leaders we say more about below.</p>
<p>
Then the meeting will branch in some different directions from the computational-lens themes. The preface on the workshop website says:</p>
<blockquote><p><b> </b> <em> Viewing the world through an informational lens, and understanding constraints and tradeoffs such as energy and parallelism versus reliability and speed, will have profound consequences throughout technology and science. This includes not only mathematics and the natural sciences like physics and biology, but also social sciences such as psychology and linguistics. We aim to bring together leading researchers in science and technology from across the globe to discuss ideas and future research directions through the informational lens. </em>
</p></blockquote>
<p/><p>
The other three days have talks that reach into all these areas, a dazzling array. We have made a collage of the twenty-six speakers currently listed on the schedule. Several faces are long familiar but others are novel to us.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/c1.png"><img alt="" class="aligncenter size-medium wp-image-17639" height="225" src="https://rjlipton.files.wordpress.com/2020/09/c1.png?w=300&amp;h=225" width="300"/></a></p>
<p>
</p><p/><h2> Quantum Tuesday </h2><p/>
<p/><p>
The opening morning has Alexander Holevo between Aram Harrow and Gil Kalai. Among many other accomplishments, Holevo is known for a <a href="https://en.wikipedia.org/wiki/Holevo's_theorem">theorem</a> that implies that <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits can yield at most <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits of classical information. In particular, any attempt to encode the edges of a general <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph via entanglements between pairs among <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> qubits must be extremely lossy. He will talk about <em>quantum channels</em> and give a structure theorem for quantum Gaussian observables.</p>
<p>
We don’t have information yet on Aram’s talk. But Gil will update us on the state of his skepticism about the feasibility of large-scale quantum computing. This was the subject of the 2012 debate between Aram and Gil that <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">spanned</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">eight</a> <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">posts</a> on this blog. Here are Gil’s title and abstract:</p>
<p>
<font color="blue">Computational complexity, mathematical, and statistical aspects of NISQ computers.</font><br/>
<i>Noisy Intermediate-Scale Quantum (NISQ) Computers hold the key for important theoretical and experimental questions regarding quantum computers. In the lecture I will describe some questions about computational complexity, mathematics, and statistics which arose in my study of NISQ systems and are related to: <br/>
a) My general argument “against” quantum computers, <br/>
b) My analysis (with Yosi Rinot and Tomer Shoham) of the Google 2019 “huge quantum advantage” experiment. </i></p>
<p>
IBM have expressed their own skepticism of Google’s claims, which we mentioned in our own <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">review</a> of the experiment last year. IBM of course also have their own quantum computing initiative.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/q.jpeg"><img alt="" class="aligncenter size-medium wp-image-17640" height="169" src="https://rjlipton.files.wordpress.com/2020/09/q.jpeg?w=300&amp;h=169" width="300"/></a></p>
<p>
We may hear about its state from Charlie Bennett, whose talk leads off the afternoon but has yet to be measured, along with the following talk by Isaac Chuang. Then will come Scott Aaronson. If “tomography” in his title sounds to you like a <a href="https://en.wikipedia.org/wiki/CT_scan">CAT scan</a>, you could consider this a “Schrödinger’s Cat” scan. Well, we should let Scott tell it—the 2018 paper he mentions is <a href="https://arxiv.org/abs/1711.01053">this</a>.</p>
<p>
<font color="red">Shadow Tomography of Quantum States: Progress and Prospects. </font><br/>
<i>Given an unknown quantum state <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, and a known list of two-outcome measurements <img alt="{E_1,...,E_M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_1%2C...%2CE_M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_1,...,E_M}"/>, “shadow tomography” is the task of estimating the probability that each <img alt="{E_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E_i}"/> accepts <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>, by carefully measuring only a few copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>. In 2018, I gave the first nontrivial protocol for this task. In 2019, Guy Rothblum and I exploited a new connection between gentle measurement of quantum states and the field of differential privacy, to give a protocol that requires fewer copies of <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> in some cases, and has the additional advantage of being online (that is, the measurements are processed one at a time). Huge challenges remain in making shadow tomography practical with near-term devices; extremely recently Huang, Kueng, and Preskill took some promising steps in that direction. I’ll survey these developments and the challenges that remain.</i> </p>
<p>
Then Srinivasan Arunachalam, who also works at IBM T.J. Watson in Westchester, NY, will finish the day with another talk about inferring from samples:</p>
<p>
<font color="blue">Sample-efficient learning of quantum many-body systems.</font><br/>
<i>We study the problem of learning the Hamiltonian of a quantum many-body system given samples from its Gibbs (thermal) state. The classical analog of this problem, known as learning graphical models or Boltzmann machines, is a well-studied question in machine learning and statistics. In this work, we give the first sample-efficient algorithm for the quantum Hamiltonian learning problem. In particular, we prove that polynomially many samples in the number of particles (qudits) are necessary and sufficient for learning the parameters of a spatially local Hamiltonian in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-norm. Our main contribution is in establishing the strong convexity of the log-partition function of quantum many-body systems, which along with the maximum entropy estimation yields our sample-efficient algorithm. Our work paves the way toward a more rigorous application of machine learning techniques to quantum many-body problems.</i></p>
<p>
</p><p/><h2> B.Y.O.L. </h2><p/>
<p/><p>
The workshop has lunch breaks as usual but they are not lunch breaks. Lunch is served at IBM T.J. Watson, and I (Ken) can vouch from times I have been hosted there by Jon Lenchner that the food is wonderful, but attendees will not be on hand to partake. I have known Jon since we were part of the New York area chess scene in the 1970s. Among Jon’s activities in the past five years have been directing IBM’s research center in Nairobi, Kenya, and helping the Toronto Raptors assemble a championship basketball team via player analytics. The latter is not technically related to my chess analytics, but we have greater shared interests in ideas for lower bounds on uniform complexity classes.</p>
<p>
Instead of physical lunch, the lunch breaks are moderated panel discussions. So you can bring your own lunch while watching and listening via IBM’s WebEx or other portal. Maybe there will be time for remote attendees to ask questions—though not with your mouth full, as our mothers would say. A few years ago, my department began running catered Friday lunch forums under the name “UpBeat,” but those too are now remote and B.Y.O.L.  As for the other thing the “L.” can stand for besides “lunch,” we can mention that the pandemic has rendered onsite restrictions moot.</p>
<p>
There will also be Q &amp; A and panel discussion sessions for 45 minutes after each day’s last talk. </p>
<p>
</p><p/><h2> Some Other Talks </h2><p/>
<p/><p>
We wish we could attend all the talks. We imagine they will be available afterward as recordings, but especially when there is live Q &amp; A it is nice to experience them in the moment as at a physically intimate workshop. Rather than list all the speakers and titles here—you can find them on the abstracts <a href="https://sites.google.com/view/informational-lens-workshop-1/talk-abstracts">page</a>, after all—we will just highlight a few that catch our eye:</p>
<p>
<font color="red">Fun facts about polynomials, and applications to coding theory: Mary Wootters. </font><br/>
<i>Here are some (fun?) facts about polynomials you probably already know. First, given any three points, you can find a parabola through them. Second, if you look at any vertical “slice” of a paraboloid, you get a parabola. These facts, while simple, turn out to be extremely useful in applications! For example, these facts are behind the efficacy of classical Reed-Solomon and Reed-Muller codes, fundamental tools for communication and storage. But this talk is not about those facts — it’s about a few related facts that you might not know. Given less than three points’ worth of information, what can you learn about a parabola going through those points? Are there things other than paraboloids that you can “slice” and always get parabolas? In this talk, I will tell you some (fun!) facts that answer these questions, and discuss applications to error correcting codes.</i></p>
<p>
<font color="blue">Punch Cards and the Difference Engine: William Gibson and Bruce Sterling. </font><br/>
<i>We discuss the <a href="https://en.wikipedia.org/wiki/The_Difference_Engine">power</a> of the card concept. By storing a finite amount of data on a “punch card” we can structure data handling to be straightforward and safe. The machine we plan will be thousands of times slower than even the first vacuum-tube computers were. But our novel use of steam and punch cards does have merits: cards are physical and help solve security and also privacy issues.</i></p>
<p>
<font color="red">Reasoning about Generalization via Conditional Mutual Information: Lydia Zakynthinou. </font><br/>
<i>We provide a framework for studying the generalization properties of machine learning algorithms, which ties together existing approaches, using the unifying language of information theory. We introduce a new notion based on Conditional Mutual Information (CMI) which quantifies how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. Bounds on CMI can be obtained from several methods, including VC dimension, compression schemes, and differential privacy, and bounded CMI implies various forms of generalization guarantees. In this talk, I will introduce CMI, show how to obtain bounds on CMI from existing methods and generalization bounds from CMI, and discuss the capabilities of our framework. Joint work with Thomas Steinke.</i></p>
<p>
<font color="blue">Rebooting Mathematics: Doron Zeilberger. </font><br/>
<i>Mathematics is what it is today due to the accidental fact that it was developed before the invention of the computer, and, with a few exceptions, continues in the same vein, by inertia. It is time to start all over, remembering that math, is, or at least should be, the math that can be handled by computers, keeping in mind that they are both discrete and finite.</i></p>
<p>
Oh wait, one of these talks is both less novel and more <a href="https://www.amazon.com/Difference-Engine-Novel-William-Gibson/dp/0440423627">novel</a> than the others.  Can a virtual workshop have a virtual virtual talk?  The cards were arguably “the” informational lens for almost 100 years.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What have been your experiences with top-of-the-line virtual workshops? Our hats are off to the organizers of this one, and we are looking forward to it.</p>
<p/></font></font></div>
    </content>
    <updated>2020-09-27T15:24:46Z</updated>
    <published>2020-09-27T15:24:46Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="Aram Harrow"/>
    <category term="Chai Wah Wu"/>
    <category term="Charles Bennett"/>
    <category term="debate"/>
    <category term="Gil Kalai"/>
    <category term="IBM"/>
    <category term="informational lens"/>
    <category term="Jonathan Lenchner"/>
    <category term="Physics"/>
    <category term="quantum"/>
    <category term="workshop"/>
    <category term="Yuhai Tu"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-29T23:49:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=63</id>
    <link href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Friday, Oct 09 — Alexandr Andoni from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  Alexandr Andoni from Columbia University will speak about “Approximating Edit Distance in Near-Linear Time”. Abstract: Edit distance is a classic measure of similarity between strings, with<a class="more-link" href="https://dstheory.wordpress.com/2020/09/26/friday-oct-09-alexandr-andoni-from-columbia-university/">Continue reading <span class="screen-reader-text">"Friday, Oct 09 — Alexandr Andoni from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next Foundations of Data Science virtual talk will take place on Friday, Oct 09th at 10:00 AM Pacific Time (1:00 pm Eastern Time, 18:00 Central European Time, 17:00 UTC).  <strong>Alexandr Andoni </strong>from Columbia University will speak about “<em><strong>Approximating Edit Distance in Near-Linear Time</strong></em>”.</p>



<p><strong>Abstract</strong>: Edit distance is a classic measure of similarity between strings, with applications ranging from computational biology to coding. Computing edit distance is also a classic dynamic programming problem, with a quadratic run-time solution, often taught in the “Intro to Algorithms” classes. Improving this runtime has been a decades-old challenge, now ruled likely-impossible using tools from the modern area of fine-grained complexity. We show how to approximate the edit distance between two strings in near-linear time, up to a constant factor. Our result completes a research direction set forth in the breakthrough paper of [Chakraborty, Das, Goldenberg, Koucky, Saks; FOCS’18], which showed the first constant-factor approximation algorithm with a (strongly) sub-quadratic running time.</p>



<p>Joint work with Negev Shekel Nosatzki, available at<a href="https://arxiv.org/abs/2005.07678"> https://arxiv.org/abs/2005.07678</a>.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-09-26T15:46:40Z</updated>
    <published>2020-09-26T15:46:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-09-29T23:51:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/09/25/tenure-track-assistant-professor-at-university-of-vienna-apply-by-october-1-2020/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by October 1, 2020)</title>
    <summary>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams. Website: https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/ Email: monika.henzinger@univie.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for outstanding computer scientists with a research focus on the management of massive data. Examples for research topics of interest are high-performance data mining and machine learning methods in distributed and parallel environments and techniques for the analysis of high-dimensional data, management and analysis of high-throughput data streams.</p>
<p>Website: <a href="https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/">https://informatik.univie.ac.at/en/news-events/article/news/new-tenure-track-professorship-for-the-field-of-management-of-massive-data/</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2020-09-25T07:23:35Z</updated>
    <published>2020-09-25T07:23:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-09-29T23:49:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/147</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/147" rel="alternate" type="text/html"/>
    <title>TR20-147 |  Batch Verification for Statistical Zero Knowledge Proofs | 

	Inbar Kaslasi, 

	Guy Rothblum, 

	Ron Rothblum, 

	Adam Sealfon, 

	Prashant Nalini Vasudevan</title>
    <summary>A statistical zero-knowledge proof (SZK) for a problem $\Pi$ enables a computationally unbounded prover to convince a polynomial-time verifier that $x \in \Pi$ without revealing any additional information about $x$ to the verifier, in a strong information-theoretic sense.

Suppose, however, that the prover wishes to convince the verifier that $k$ separate inputs $x_1,\dots,x_k$ all belong to $\Pi$ (without revealing anything else). A naive way of doing so is to simply run the SZK protocol separately for each input. In this work we ask whether one can do better -- that is, is efficient batch verification possible for SZK?

We give a partial positive answer to this question by constructing a batch verification protocol for a natural and important subclass of SZK -- all problems $\Pi$ that have a non-interactive SZK protocol (in the common random string model). More specifically, we show that, for every such problem $\Pi$, there exists an honest-verifier SZK protocol for batch verification of $k$ instances, with communication complexity $poly(n) + k \cdot poly(\log{n},\log{k})$, where $poly$ refers to a fixed polynomial that depends only on $\Pi$ (and not on $k$). This result should be contrasted with the naive solution, which has communication complexity $k \cdot poly(n)$.

Our proof leverages a new NISZK-complete problem, called Approximate Injectivity, that we find to be of independent interest. The goal in this problem is to distinguish circuits that are nearly injective, from those that are non-injective on almost all inputs.</summary>
    <updated>2020-09-24T13:41:26Z</updated>
    <published>2020-09-24T13:41:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/146</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/146" rel="alternate" type="text/html"/>
    <title>TR20-146 |  On the Hardness of Detecting Macroscopic Superpositions | 

	Scott Aaronson, 

	Yosi Atia, 

	Leonard Susskind</title>
    <summary>When is decoherence "effectively irreversible"? Here we examine this central question of quantum foundations using the tools of quantum computational complexity. We prove that, if one had a quantum circuit to determine if a system was in an equal superposition of two orthogonal states (for example, the $|$Alive$\rangle$ and $|$Dead$\rangle$ states of Schrodinger's cat), then with only a slightly larger circuit, one could also $\mathit{swap}$ the two states (e.g., bring a dead cat back to life). In other words, observing interference between the $|$Alive$\rangle$and $|$Dead$\rangle$ states is a "necromancy-hard" problem, technologically infeasible in any world where death is permanent. As for the converse statement (i.e., ability to swap implies ability to detect interference), we show that it holds modulo a single exception, involving unitaries that (for example) map $|$Alive$\rangle$ to $|$Dead$\rangle$ but $|$Dead$\rangle$ to -$|$Alive$\rangle$. We also show that these statements are robust---i.e., even a $\mathit{partial}$ ability to observe interference implies partial swapping ability, and vice versa. Finally, without relying on any unproved complexity conjectures, we show that all of these results are quantitatively tight. Our results have possible implications for the state dependence of observables in quantum gravity, the subject that originally motivated this study.</summary>
    <updated>2020-09-23T22:45:17Z</updated>
    <published>2020-09-23T22:45:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/145</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/145" rel="alternate" type="text/html"/>
    <title>TR20-145 |  An Improved Exponential-Time Approximation Algorithm for Fully-Alternating Games Against Nature | 

	Andrew Drucker</title>
    <summary>"Games against Nature" [Papadimitriou '85] are two-player games of perfect information, in which one player's moves are made randomly (here, uniformly); the final payoff to the non-random player is given by some $[0, 1]$-valued function of the move history.  Estimating the value of such games under optimal play, and computing near-optimal strategies, is an important goal in the study of decision-making under uncertainty, and has seen significant research in AI and allied areas [Hnich, Rossi, Tarim, Prestwich '11], with only experimental evaluation of most algorithms' performance.  The problem's PSPACE-completeness does not rule out nontrivial algorithms.  Improved algorithms with theoretical guarantees are known in various cases where the payoff function $F$ has special structure, and Littman, Majercik, and Pitassi [LMP'01] give a sampling-based improved algorithm for general $F$, for turn-orders which restrict the number of non-random player strategies.

We study the case of general $F$ for which the players strictly alternate with binary moves $(w_1, r_1, w_2, r_2, \ldots, w_{n/2}, r_{n/2})$---for which the approach of [LMP'01] does not improve over brute force.  We give a randomized algorithm to approximate the value of such games under optimal play, and to execute near-optimal strategies. Our algorithm achieves exponential savings over brute-force, making $2^{(1 - \delta) n}$ queries to $F$ for some absolute constant $\delta &gt; 0$, and certifies a lower bound $\hat{v}$ on the game value $v$ with additive expected error bounded as $E[v - \hat{v}] \leq \exp(-\Omega(n))$.  (On the downside, $\delta$ is tiny and the algorithm uses exponential space.)

Our algorithm is recursive, and bootstraps a "base case" algorithm for fixed-size inputs.  The method of recursive composition used, the specific base-case guarantees needed, and the steps to establish these guarantees are interesting and, we feel, likely to find uses beyond the present work.</summary>
    <updated>2020-09-23T21:48:34Z</updated>
    <published>2020-09-23T21:48:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7113260074896603448</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7113260074896603448/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7113260074896603448" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/remembering-2000.html" rel="alternate" type="text/html"/>
    <title>Remembering 2000</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://www.cs.cmu.edu/~FOCS2000/">FOCS 2000</a> took place in Redondo Beach, just south of Los Angeles, November 12-14. Certainly some great results such as the Reingold-Vadhan-Wigderson <a href="https://doi.org/10.1109/SFCS.2000.892006">Zig-Zag Graph Product Expander construction</a> that would lead to Omer Reingold's <a href="https://blog.computationalcomplexity.org/2014/02/favorite-theorems-connecting-in-log.html">Undirected Connectivity in Log Space</a>. Mostly though I remember the discussions about the presidential election held the week before and whether we might find out our next president during the conference. Spoiler alert: <a href="https://en.wikipedia.org/wiki/2000_United_States_presidential_election_recount_in_Florida">We didn't</a>. </p><p>Consider the following viewpoints for a person X</p><p>1. Did X support Bush or Gore?</p><p>2. Did X interpret the rules of the election that Bush won or Gore won?</p><p>These should be independent events. Your interpretation of the rules should not depend on who you supported. But in fact they were nearly perfectly correlated. Whether you were a politician, a newspaper editorial page writer, a supreme court justice, a computer scientist or pretty much everyone else, if you supported Gore, you believed he won the election and vice-versa. Everyone had their logic why they were right and I'm sure my readers who remember that election still believe their logic was correct. </p><p>As this upcoming election gets messy, as it already has, take care with trying to justify your desired endgame by choosing the logic that makes it work. Would you use the same logic if the candidates were reversed? Everyone says "yes" but it's rarely true. Just like Mitch McConnell, you'll just find some excuse why the opposite situation is different. Trust me, my logic is impeccable. </p></div>
    </content>
    <updated>2020-09-23T21:33:00Z</updated>
    <published>2020-09-23T21:33:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-29T18:33:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20259</id>
    <link href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 12:  Asaf Ferber and David Conlon found new lower bounds for diagonal Ramsey numbers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Update (Sept. 28): Yuval Wigderson has made a further improvement on the multicolor Ramsey number bound for more than three colors. Lower bounds for multicolor Ramsey numbers The Ramsey number r(t; ℓ) is the smallest natural number n such that … <a href="https://gilkalai.wordpress.com/2020/09/23/to-cheer-you-up-in-difficult-times-12-asaf-ferber-and-david-conlon-found-new-lower-bounds-for-diagonal-ramsey-numbers/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="title mathjax"><strong>Update (Sept. 28):</strong> Yuval Wigderson <a href="https://arxiv.org/abs/2009.12020">has made a further improvement on the multicolor Ramsey number bound for more than three colors.</a></p>
<h2><a href="https://arxiv.org/abs/2009.10458">Lower bounds for multicolor Ramsey numbers</a></h2>
<p>The Ramsey number <em>r(t; ℓ)</em> is the smallest natural number <em>n</em> such that every ℓ-coloring of the edges of the complete graph <img alt="K_n" class="latex" src="https://s0.wp.com/latex.php?latex=K_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_n"/> contains a monochromatic <img alt="K_t" class="latex" src="https://s0.wp.com/latex.php?latex=K_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K_t"/>. (<em>r(t;2)</em> is often denoted by<em> R(t,t)</em> and <em>r(t;3)</em> by R<em>(t,t,t)</em> etc.) <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Famously</a>, <em>R(3,3)=6</em>; <em>R(4,4)=18</em>;  and <em>R(3,3,3)=17</em>. Understanding <em>R(t,t)</em> is among the most famous problems in combinatorics. (Understanding if r(3; <em> ℓ</em>) is exponential or superexponential in<em> ℓ</em> is also a very famous problem.)</p>
<p>It is known since the 1940s that <img alt="t/2 +o(1) \le log_2 R(t,t) \le 2t" class="latex" src="https://s0.wp.com/latex.php?latex=t%2F2+%2Bo%281%29+%5Cle+log_2+R%28t%2Ct%29+%5Cle+2t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t/2 +o(1) \le log_2 R(t,t) \le 2t"/>.</p>
<p>Lower bounds for <em>R(t,t)</em> where used by Lefmann in 1987 to give lower bounds on <em>r(t; ℓ)</em> for <em> ℓ</em>&gt;2. Asaf Ferber and David Conlon gave now <span style="color: #ff0000;"><strong>exponential</strong></span> improvement. This is truly remarkable and <a href="https://arxiv.org/abs/2009.10458">the paper is just 4-page long!</a> congratulations Asaf and David!</p>
<p>Expect more cheering news of discrete geometry nature from Oberwolfach. (I take part remotely in the traditional meeting on Discrete and computational geometry, see pictures below).</p>
<p>Update (Sept 24.): <a href="https://anuragbishnoi.wordpress.com/2020/09/23/improved-lower-bounds-for-multicolour-diagonal-ramsey-numbers/">An excellent blog post on Anurag math blog.</a> Anurag describes in details the construction, describes the connections with finite geometries, and improves the construction to get a better result. (See also there many cool posts, e.g., an earlier post with some connections of finite geometries and different Ramsey problems <a href="https://anuragbishnoi.wordpress.com/2020/09/10/heisenberg-groups-irreducible-cubics-and-minimal-ramsey/" rel="bookmark">Heisenberg groups, irreducible cubics and minimal Ramsey</a>.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/09/pak.png"><img alt="" class="alignnone size-medium wp-image-20264" height="188" src="https://gilkalai.files.wordpress.com/2020/09/pak.png?w=300&amp;h=188" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2020/09/ow2.png"><img alt="" class="alignnone size-medium wp-image-20265" height="188" src="https://gilkalai.files.wordpress.com/2020/09/ow2.png?w=300&amp;h=188" width="300"/></a></p></div>
    </content>
    <updated>2020-09-23T11:24:44Z</updated>
    <published>2020-09-23T11:24:44Z</published>
    <category term="Combinatorics"/>
    <category term="Asaf Ferber"/>
    <category term="David Conlon"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-09-29T23:49:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17612</id>
    <link href="https://rjlipton.wordpress.com/2020/09/22/puzzle-reviews-by-a-puzzle-writer/" rel="alternate" type="text/html"/>
    <title>Puzzle Reviews by a Puzzle Writer</title>
    <summary>Not puzzling reviews Princeton University Press page Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums. The former includes a neat paper on expansion properties of a family of graphs associated to block designs, with two undergraduates […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Not puzzling reviews</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg"><img alt="" class="alignright wp-image-17615" height="160" src="https://rjlipton.files.wordpress.com/2020/09/jason-1.jpeg?w=140&amp;h=160" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Princeton University Press <a href="https://press.princeton.edu/our-authors/rosenhouse-jason">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Jason Rosenhouse is professor in the Department of Mathematics at James Madison University. His research focuses on algebraic graph theory and analytic number theory involving exponential sums.  The former includes a neat <a href="https://www.researchgate.net/publication/220620901_Expansion_Properties_Of_Levi_Graphs">paper</a> on expansion properties of a family of graphs associated to block designs, with two undergraduates among its authors.  But besides his “real” research, he has written a number of books on puzzles such as <i><a href="https://www.amazon.com/s?k=Jason+Rosenhouse&amp;i=stripbooks&amp;ref=nb_sb_noss_2">The Monty Hall Problem</a>: The Remarkable Story of Math’s Most Contentious Brain Teaser</i>. Soon his book <i><a href="https://www.amazon.co.uk/Games-Your-Mind-History-Puzzles/dp/0691174075">Games for Your Mind</a>: The History and Future of Logic Puzzles</i> is to be published.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png"><img alt="" class="aligncenter size-thumbnail wp-image-17626" height="150" src="https://rjlipton.files.wordpress.com/2020/09/revbook-1.png?w=103&amp;h=150" width="103"/></a></p>
<p>
Today Ken and I thought we would highlight his recent review of a book on math puzzles.<br/>
<span id="more-17612"/></p>
<p>
I have mixed feelings about puzzles. I like them, and am happy when I can understand their solution. I am even happier when I can solve them. I sometimes feel that I should spend my limited brain cycles on “real” problems. But puzzles are fun. </p>
<p>
Rosenhouse’s <a href="https://www.ams.org/journals/notices/202009/rnoti-p1382.pdf">review</a> is in the recent <em>Notices of the AMS</em> on the book <i><a href="https://bookstore.ams.org/prb-36">Bicycles or Unicycles</a>: A Collection of Intriguing Mathematical Puzzles</i>. This book, the “Bicycle Book,” is authored by Daniel Velleman and Stan Wagon.</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg"><img alt="" class="aligncenter wp-image-17617" height="145" src="https://rjlipton.files.wordpress.com/2020/09/maabook.jpg?w=101&amp;h=145" width="101"/></a></p>
<p>
Their book is a collection of <img alt="{3 \times 5 \times 7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+5+%5Ctimes+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 5 \times 7}"/> mathematical puzzles. Rosenhouse likes their book, which means a lot coming from an author of so many puzzle books himself. </p>
<p>
</p><p/><h2> A Cool Problem </h2><p/>
<p/><p>
Rosenhouse presents this problem from the Bicycle Book. </p>
<blockquote><p><b> </b> <em> You are playing solitaire in the first quadrant of the Cartesian plane, the lower corner of which is shown in Figure 1. You begin with a single checker on square a1. On each turn, a legal move consists of removing one checker from the board and then placing two new checkers in the cells immediately above and to the right of the original checker. If either of those two cells is occupied, then the move is illegal, and a different checker must be selected for removal. </em>
</p></blockquote>
<p/><p>
<a href="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png"><img alt="" class="aligncenter size-full wp-image-17618" src="https://rjlipton.files.wordpress.com/2020/09/solitairepuzzle.png?w=600"/></a></p>
<p>
Show that you can never make all of the <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> lower-left squares empty. This is a complexity question. You describe a computation and assert that certain states cannot be reached. The challenge is two-fold: </p>
<ol>
<li>
The computation is nondeterministic. There can be more than one next state. <p/>
</li><li>
The computation can reach infinitely many states. The task is to prove that no reachable state has the lower nine squares empty.
</li></ol>
<p>
</p><p/><h2> A Cool Solution </h2><p/>
<p/><p>
I must admit I read the solution before I tried to solve the puzzle. I did find an alternative solution. It was not as clever as the one from the book. Let’s look at that solution first. </p>
<p>
The idea is to assign <i>magic</i> values to each square on the checkerboard. The value of a state is the sum over all the values of squares with a checker. We need these to hold: </p>
<ol>
<li>
The value of the initial square is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. <p/>
</li><li>
The value of a move leaves the total sum over all the checkers the same. <p/>
</li><li>
The value of the squares <b>not</b> in the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> is less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>.
</li></ol>
<p>Then there can never be a reachable state that avoids all the lower <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/>. How can we do this? Assign the values as shown below. </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccl%7D+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5Cvdots+%26+%5C%5C+1%2F8+%26+1%2F16+%26+1%2F32+%26+1%2F64+%26+%5Ccdots%5C%5C+1%2F4+%26+1%2F8+%26+1%2F16+%26+1%2F32+%26+%5Ccdots%5C%5C+1%2F2+%26+1%2F4+%26+1%2F8+%26+1%2F16+%26+%5Ccdots%5C%5C+1+%26+1%2F2+%26+1%2F4+%26+1%2F8+%26+%5Ccdots+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccl} \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \\ 1/8 &amp; 1/16 &amp; 1/32 &amp; 1/64 &amp; \cdots\\ 1/4 &amp; 1/8 &amp; 1/16 &amp; 1/32 &amp; \cdots\\ 1/2 &amp; 1/4 &amp; 1/8 &amp; 1/16 &amp; \cdots\\ 1 &amp; 1/2 &amp; 1/4 &amp; 1/8 &amp; \cdots \end{array} "/></p>
<p>
Ken remembers, as a teenager, seeing this puzzle in a collection by the master Martin Gardner, with the same proof. Ken thought of it again when considering problems in physics and combinatorics that involve defining an appropriate potential function as the first step. </p>
<p>
</p><p/><h2> An Uncool Solution </h2><p/>
<p/><p>
Let <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> be the lower-right <img alt="{3 \times 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3 \times 3}"/> corner board. Label the positions as usual with <img alt="{(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,j)}"/> where <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> both are in <img alt="{\{1,2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,3\}}"/>.</p>
<p>
Let <img alt="{N(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)}"/> be the number of checkers in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. Of course <img alt="{N(0)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%280%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(0)=1}"/> and the checker is at <img alt="{(1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(1,1)}"/>.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg"><img alt="" class="aligncenter wp-image-17621" height="107" src="https://rjlipton.files.wordpress.com/2020/09/config33v1.jpg?w=150&amp;h=107" width="150"/></a></p>
<p>
Suppose by way of contradiction that it is possible to make <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> empty. </p>
<p>
Our proof uses that the transition from <img alt="{N(t)&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)&gt;0}"/> to <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/> requires that <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/>. That is <img alt="{N(t)=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=2}"/> or even <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> is impossible. The rule cannot remove two or more checkers from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in one move. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg"><img alt="" class="aligncenter wp-image-17622" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v2.jpg?w=150&amp;h=97" width="150"/></a></p>
<p>
Let <img alt="{N(t)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t)=1}"/> and <img alt="{N(t+1)=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%28t%2B1%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N(t+1)=0}"/>. So where is the checker? A simple case analysis shows it must be at <img alt="{(3,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,3)}"/>. So now we know the last placement. But how did we get to this position? It is easy to see that it had to be previously at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> or <img alt="{(2,3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%282%2C3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(2,3)}"/>. By symmetry we can assume was <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/>. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg"><img alt="" class="aligncenter wp-image-17623" height="98" src="https://rjlipton.files.wordpress.com/2020/09/config33v3.jpg?w=150&amp;h=98" width="150"/></a></p>
<p>
Our goal to show that we cannot place one checker at <img alt="{(3,2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,2)}"/> and no other in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. A little analysis shows that it must be the case that the previous state was one checker at <img alt="{(3,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,1)}"/>. But it is impossible to place a checker there and avoid having more checkers. This yields a contradiction. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg"><img alt="" class="aligncenter wp-image-17624" height="97" src="https://rjlipton.files.wordpress.com/2020/09/config33v4.jpg?w=150&amp;h=97" width="150"/></a></p>
<p/><h2> Another Solution </h2><p/>
<p/><p>
We could use finite state automata theory to supply another solution. The obvious issue is the full game is played on an infinite checkerboard. But we can use a standard trick to reduce the state space to a finite one. Imagine we play the game on just <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. When we have a move that creates checkers outside of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> just throw them away. It is simple to see that no move can place checkers inside <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Thus if we cannot empty <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in this finite version, then there is no way in the full game. </p>
<p>
Now the state space is bounded by <img alt="{2^{9}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B9%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{9}}"/>: each of the nine squares can have a checker or not. We know the initial state and we know the final state. So we can run a finite state search algorithm and decide the answer.</p>
<p>
The value of this solution is that it could handle more complex rules and larger squares. Well at least those within reason. </p>
<p>
</p><p/><h2> Other Puzzles </h2><p/>
<p/><p>
Rosenhouse covers nine other puzzles in his review. In our meta review of his review we will cover just two more. </p>
<p>
The third puzzle in his review comes from the challenge to prove that each matrix in a certain family <img alt="{\{C_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BC_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{C_n\}}"/> has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The particular matrices <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> look like they could have some strange determinant, one that even varies with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. The trick is to show that there are other families <img alt="{\{A_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BA_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{A_n\}}"/> and <img alt="{\{B_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{B_n\}}"/> of matrices, in which each matrix has determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> and that 	</p>
<p align="center"><img alt="\displaystyle  C_n = A_n B_n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C_n+%3D+A_n+B_n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C_n = A_n B_n. "/></p>
<p>Of course this immediately proves that <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/> also have determinant <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The challenge is kind of a factorization problem. </p>
<p>
Another puzzle is to prove that a number <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime if and only if there is exactly one pair of positive integers <img alt="{m,n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m,n}"/> such that </p>
<p align="center"><img alt="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bm%7D+-+%5Cfrac%7B1%7D%7Bn%7D+%3D+%5Cfrac%7B1%7D%7Bp%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1}{m} - \frac{1}{n} = \frac{1}{p}. "/></p>
<p>This seems to be surprising in two ways: First who could think of this? Second who could think of this? Okay it should be why is it true? Indeed Rosenhouse says that the proof is complex. </p>
<p>
Rosenhouse adds that most puzzles in this book are less “bite-sized” than the ones typically posed by the master Gardner. This certainly goes for the title puzzle about whether a bicycle can possibly move along a curve—other than a straight line—that was made by a unicycle. It requires a foray into differential equations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
My “uncool solution” was left somewhat incomplete. Do you see how to complete the analysis?</p>
<p>
[some word fixes]</p></font></font></div>
    </content>
    <updated>2020-09-22T22:01:06Z</updated>
    <published>2020-09-22T22:01:06Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="book reviews"/>
    <category term="Daniel Velleman"/>
    <category term="Jason Rosenhouse"/>
    <category term="puzzles"/>
    <category term="Stan Wagon"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-09-29T23:49:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/144</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/144" rel="alternate" type="text/html"/>
    <title>TR20-144 |  Toward Probabilistic Checking against Non-Signaling Strategies with Constant Locality | 

	Mohammad Jahanara, 

	Sajin Koroth, 

	Igor Shinkar</title>
    <summary>Non-signaling strategies are a generalization of quantum strategies that have been studied in physics over the past three decades. Recently, they have found applications in theoretical computer science, including to proving inapproximability results for linear programming and to constructing protocols for delegating computation. A central tool for these applications is probabilistically checkable proof (PCPs) systems that are sound against non-signaling strategies.

In this paper we show, assuming a certain geometrical hypothesis about noise robustness of non-signaling proofs (or, equivalently, about robustness to noise of solutions to the Sherali-Adams linear program), that a slight variant of the parallel repetition of the exponential-length constant-query PCP construction due to Arora et al. (JACM 1998) is sound against non-signaling strategies with constant locality.

Our proof relies on the analysis of the linearity test and agreement test (also known as the direct product test) in the non-signaling setting.</summary>
    <updated>2020-09-22T11:49:39Z</updated>
    <published>2020-09-22T11:49:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/143</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/143" rel="alternate" type="text/html"/>
    <title>TR20-143 |  Characterizing Average-Case Complexity of PH by Worst-Case Meta-Complexity | 

	Shuichi Hirahara</title>
    <summary>We exactly characterize the average-case complexity of the polynomial-time hierarchy (PH) by the worst-case (meta-)complexity of GapMINKT(PH), i.e., an approximation version of the problem of determining if a given string can be compressed to a short PH-oracle efficient program.  Specifically, we establish the following equivalence:

  DistPH is contained in AvgP (i.e., PH is easy on average) if and only if GapMINKT(PH) is in P.

In fact, our equivalence is significantly broad: A number of statements on several fundamental notions of complexity theory, such as errorless and one-sided-error average-case complexity, sublinear-time-bounded and polynomial-time-bounded Kolmogorov complexity, and PH-computable hitting set generators, are all shown to be equivalent.

Our equivalence provides fundamentally new proof techniques for analyzing average-case complexity through the lens of *meta-complexity* of time-bounded Kolmogorov complexity and resolves, as immediate corollaries, questions of equivalence among different notions of average-case complexity of PH: low success versus high success probabilities (i.e., a hardness amplification theorem for DistPH against uniform algorithms) and errorless versus one-sided-error average-case complexity of PH.

Our results are based on a sequence of new technical results that further develops the proof techniques of the author's previous work on the non-black-box worst-case to average-case reduction and unexpected hardness results for Kolmogorov complexity (FOCS'18, CCC'20, ITCS'20, STOC'20).  Among other things, we prove the following.

  1.  If GapMINKT(NP) is in P, then P = BPP.
  At the core of the proof is a new black-box hitting set generator construction whose reconstruction algorithm uses few random bits, which also improves the approximation quality of the non-black-box worst-case to average-case reduction without using a pseudorandom generator.

  2.  If GapMINKT(PH) is in P, then DistPH is contained in AvgBPP = AvgP.

  3.  If MINKT(PH) is easy on a 1/poly(n)-fraction of inputs, then GapMINKT(PH) is in P.
  This improves the error tolerance of the previous non-black-box worst-case to average-case reduction.</summary>
    <updated>2020-09-21T10:16:37Z</updated>
    <published>2020-09-21T10:16:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4972</id>
    <link href="https://www.scottaaronson.com/blog/?p=4972" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4972#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4972" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Agent 3203.7: Guest post by Eliezer Yudkowsky</title>
    <summary xml:lang="en-US">In his day, Agent 3203.7 had stopped people from trying to kill Adolf Hitler, Richard Nixon, and even, in the case of one unusually thoughtful assassin, Henry David Thoreau. But this was a new one on him. “So…” drawled the seventh version of Agent 3203. His prosthetic hand crushed the simple 21st-century gun into fused […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In his day, Agent 3203.7 had stopped people from trying to kill Adolf Hitler, Richard Nixon, and even, in the case of one unusually thoughtful assassin, Henry David Thoreau. But this was a new one on him.</p>



<p>“So…” drawled the seventh version of Agent 3203. His prosthetic hand crushed the simple 21st-century gun into fused metal and dropped it. “You traveled to the past in order to kill… of all people… Donald Trump. Care to explain why?”</p>



<p>The time-traveller’s eyes looked wild. Crazed. Nothing unusual. “How can you ask me that? You’re a time-traveler too! You know what he does!”</p>



<p>That was a surprising level of ignorance even for a 21st-century jumper. “Different timelines, kid. Some are pretty obscure. What the heck did Trump do in yours that’s worth taking your one shot at time travel to assassinate him of all people?”</p>



<p>“He’s destroying my world!”</p>



<p>Agent 3203.7 took a good look at where Donald Trump was pridefully addressing the unveiling of the Trump Taj Mahal in New Jersey, then took another good look at the errant time-traveler. “Destroying it how, exactly? Did Trump turn mad scientist in your timeline?”</p>



<p>“He’s President of the United States!”</p>



<p>Agent 3203.7 took another long stare at his new prisoner. He was apparently serious. “How did Trump become President in your timeline? Strangely advanced technology, subliminal messaging?”</p>



<p>“He was elected in the usual way,” the prisoner said bitterly.</p>



<p>Agent 3203.7 shook his head in amazement. Talk about shooting the messenger. “Kid, I doubt Trump was your timeline’s main problem.”</p>



<p><em>(thanks to Eliezer for giving me permission to reprint here)</em></p></div>
    </content>
    <updated>2020-09-21T04:01:10Z</updated>
    <published>2020-09-21T04:01:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-09-21T04:01:10Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3655236890828727429</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3655236890828727429/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/baseball-can-go-on-forever-it-doesnt.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3655236890828727429" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3655236890828727429" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/09/baseball-can-go-on-forever-it-doesnt.html" rel="alternate" type="text/html"/>
    <title>Baseball can go on forever, it doesn't just seem that way</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Most games have some way to make sure they cannot go on forever.</p><p>1) Chess: I had thought there was a 50-move rule and a 3-times-same-position rule, but its a byte more complicated than that, see <a href="https://en.wikipedia.org/wiki/Draw_(chess)">here</a>. There is also a chess clock. Suffice to say, Chess can never on forever (though it may seem like it does). </p><p>2) NIM: Eventually all of the stones are gone. There may be more complicated versions where you can add some stones, but in those versions I suspect that there is some parameter that goes to 0.</p><p>3) Basketball, Football, Hockey, Soccer: These all have a clock so they are time limited. For overtime there are also rules that make sure the game cannot go on forever. Or maybe its just very rare: what if the Superb Owl (spelled that way to avoid lawsuits, see <a href="https://www.vox.com/the-goods/2019/1/31/18202037/super-bowl-53-ads-trademark-the-big-game-2019">here</a>) is tied 0-0 at the end of the four quarters and goes into overtime and... nobody scores... ever. Could the game go on forever or would the referees declare it a tie? In the regular season there are ties, but in the in the superb owl? Actually this may be more a problem in the playoffs since you need to determine who goes to the next round.</p><p>4) Take your favorite game. I would bet dollars to doughnuts (what an odd phrase---see <a href="https://en.wiktionary.org/wiki/bet_a_dollar_to_a_doughnut">here</a> for more about the phrase) that there is some mechanism to make sure the game ends. An exception that Darling pointed out to me: If in Gin Rummy both players are terrible then the game can go on forever. This is probably true for other games as well and actually makes the question into two questions (a) will a game terminate no matter what the players do, and (b) (not sure how to formalize) will a game terminate if both players are trying to win and are making reasonable moves.</p><p>You may have noticed that in item 3 I left out Baseball. There is no clock in baseball. So one way the game can go on forever is to have a tie and extra innings and nobody scores. I think the umpire has the authority to call it a tie. (Incidentally, the shortened baseball season has a new extra inning rule---each inning starts with a runner on second. See <a href="https://www.mlb.com/news/reasons-new-extra-innings-rule-is-good">here</a>,) When Lance read an earlier version of this post he pointed me to 5 ways a game can go on forever, not counting the example I have later in this post. <a href="https://cs.nyu.edu/~gottlieb/tr/back-issues/1990s/1992/1-jan-scanned.pdf">Here</a> is where Lance found the question and answer (look on the first page under Speed Department for the question, and the very end of the second page for the answer). I also did my own writuep with more details, see <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/baseballforever.pdf">here</a>.  Also of interest (though not if you were actually at the game this happened), the record for number of times a player has a foul with 2 strikes is 16, see <a href="https://www.businessinsider.com/brandon-belts-record-at-bat-pop-fly-2018-4">here</a>. </p><p> However, I came across an  example more obscure than any of those. </p><p>Here is what happened (and you can see the video of it <a href="https://www.youtube.com/watch?v=yDyCRTlKllk">here</a>, though it really starts about a minute into it. Keep reading- it looks like its another post, but its part of this post: </p><div class="q-box qu-borderBottom qu-px--medium qu-py--small" style="border-bottom-style: solid; border-color: rgb(222, 224, 225); border-width: 1px; color: #282829; direction: ltr; font-size: 15px; padding: 8px 16px;"><div class="q-flex qu-justifyContent--space-between" style="direction: ltr; display: flex;"><div class="q-flex qu-alignItems--center" style="direction: ltr; display: flex;"><div class="q-text qu-fontSize--small qu-ml--small qu-color--gray" style="color: #636466; direction: ltr; font-size: 13px; margin-left: 8px;">From your Digest</div></div></div></div><div class="q-box" style="color: #282829; direction: ltr; font-size: 15px;"><div class="q-box" style="direction: ltr;"><div class="q-box qu-pt--medium qu-pb--tiny" style="direction: ltr; padding: 16px 16px 4px;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-box" style="direction: ltr;"><div class="q-flex" style="direction: ltr; display: flex;"><div class="q-box qu-mb--small qu-pr--large" style="direction: ltr; margin-bottom: 8px; padding-right: 24px; width: 546px;"><div class="q-box spacing_log_answer_header" style="direction: ltr;"><div class="q-flex" style="direction: ltr; display: flex; width: 522px;"><div class="q-inlineFlex qu-mr--small qu-alignItems--center" style="direction: ltr; display: inline-flex; margin-right: 8px;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-relative qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><a class="q-box qu-display--inline-flex qu-color--gray_dark qu-cursor--pointer qu-hover--textDecoration--underline" href="https://www.quora.com/profile/Zev-Steinhardt" target="_blank"><div class="q-inlineFlex qu-flex--none" style="direction: ltr; display: inline-flex;"><div class="q-inlineFlex" style="direction: ltr; display: inline-flex;"><div class="q-inlineFlex qu-overflow--hidden qu-borderRadius--circle qu-borderWidth--retinaOverride"><div class="q-box qu-bg--white__ignore_dark_mode qu-borderRadius--circle" style="background-color: white; border-radius: 100%; direction: ltr;"/><img class="q-image qu-display--block qu-size--36 qu-minWidth--36" src="https://qph.fs.quoracdn.net/main-thumb-138599745-200-pbrgkfnbxdzyttabmtnmavtcwavrcktv.jpeg"/><div class="q-box qu-borderRadius--circle qu-borderAll Photo___StyledBox-sc-1x7c6d3-1 djSgZk"/></div></div></div></a></div></div></div></div></div><div class="q-box qu-flex--auto"><div class="q-flex qu-flexWrap--wrap" style="direction: ltr; display: flex;"><div class="q-box" style="direction: ltr;"><div class="q-text qu-bold qu-color--gray_dark qu-fontSize--small qu-passColorToLinks" style="direction: ltr; font-size: 13px; font-weight: bold;"><div class="q-box qu-display--inline" style="direction: ltr; display: inline;"><div class="q-box qu-display--inline" style="direction: ltr; display: inline;"><div class="q-relative qu-display--inline" style="direction: ltr; display: inline;"><div class="q-box qu-display--inline" style="direction: ltr; display: inline;"><a class="q-box qu-color--gray_dark qu-cursor--pointer qu-hover--textDecoration--underline" href="https://www.quora.com/profile/Zev-Steinhardt" target="_blank">Zev Steinhardt</a></div></div></div></div></div></div><span class="q-text qu-mx--tiny qu-color--gray qu-fontSize--small" style="color: #636466; direction: ltr; font-size: 13px; margin-left: 4px; margin-right: 4px;">·</span><div class="q-text qu-color--gray qu-fontSize--small qu-passColorToLinks qu-truncateLines--1"><a class="q-box qu-cursor--pointer qu-hover--textDecoration--underline" href="https://www.quora.com/Has-a-play-ever-happened-in-baseball-that-was-so-out-of-the-ordinary-that-no-written-umpiring-rule-at-the-time-covered-it/answer/Zev-Steinhardt" target="_top">July 9, 2019</a></div></div><div class="q-flex qu-flexWrap--wrap" style="direction: ltr; display: flex; margin-top: 2px;"><div class="q-text qu-truncateLines--2 qu-color--gray qu-passColorToLinks qu-fontSize--small">Studied at <span class="TopicName___StyledSpan-t3tegb-0 crUglW">Pace University</span></div></div></div></div></div></div><div class="q-box qu-pl--tiny" style="direction: ltr; margin-left: auto; padding-left: 4px;"><div class="q-relative qu-size--18" style="direction: ltr; height: 18px; width: 18px;"><div class="q-absolute"><div class="q-box qu-display--inline-block" style="direction: ltr; display: inline-block;"><div class="q-relative" style="direction: ltr;"><div class="q-click-wrapper qu-active--bg--darken qu-active--textDecoration--none qu-focus--bg--darken qu-focus--textDecoration--none qu-borderRadius--pill qu-whiteSpace--nowrap qu-display--inline-block qu-tapHighlight--white qu-textAlign--center qu-cursor--pointer qu-hover--bg--darken qu-hover--textDecoration--none" tabindex="0"><div class="q-flex qu-alignItems--center qu-justifyContent--center" style="direction: ltr; display: flex;"><div class="q-relative qu-display--flex qu-alignItems--center" style="direction: ltr; display: flex;"><span class="q-inlineBlock qu-verticalAlign--text-bottom" name="SmallClose" style="direction: ltr; display: inline-block; height: 24px; line-height: 0; vertical-align: text-bottom; width: 24px;"><span class="CssComponent__CssInlineComponent-sc-1oskqb9-1 Icon___StyledCssInlineComponent-sc-11tmcw7-0 eXDwse"/></span></div></div></div></div></div></div></div></div></div><div class="q-flex" style="direction: ltr; display: flex;"/><div class="q-flex qu-mb--tiny" style="direction: ltr; display: flex; margin-bottom: 4px;"><div class="q-text qu-bold qu-color--gray_dark_dim qu-passColorToLinks qu-userSelect--text qu-lineHeight--regular" style="direction: ltr; font-size: 16px; font-weight: bold; line-height: 1.4;"><span class="CssComponent__CssInlineComponent-sc-1oskqb9-1 TitleText___StyledCssInlineComponent-sc-1hpb63h-0 jPnwvF"><a class="q-box qu-cursor--pointer qu-hover--textDecoration--underline" href="https://www.quora.com/Has-a-play-ever-happened-in-baseball-that-was-so-out-of-the-ordinary-that-no-written-umpiring-rule-at-the-time-covered-it" target="_blank"><div class="q-flex qu-flexDirection--row" style="direction: ltr; display: flex;"><div class="q-inline qu-flexWrap--wrap" style="direction: ltr; display: inline;"><div class="q-text puppeteer_test_question_title" style="direction: ltr;"><span class="q-box qu-userSelect--text" style="direction: ltr;">Has a play ever happened in baseball that was so out of the ordinary that no written umpiring rule at the time covered it?</span></div></div></div></a></span></div></div><div class="q-relative spacing_log_answer_content" style="direction: ltr;"><div class="q-text" style="direction: ltr;"><span class="q-box qu-userSelect--text" style="direction: ltr;"><p class="q-text qu-display--block" style="direction: ltr; margin: 0px 0px 1em; padding: 0px;">Back in 2008, the Yankees drafted a pitcher named Pat Venditte. What made Venditte unusual is that he can throw with both hands. In other words, he’s a switch pitcher. When he was drafted, he was assigned to the Staten Island Yankees, a low A ball team.</p><p class="q-text qu-display--block" style="direction: ltr; margin: 0px 0px 1em; padding: 0px;">In his first game (against the Mets farm team, the Brooklyn Cyclones), Venditte came in to pitch. After getting the first two batters out and giving up a single, he then faced Ralph Henriquez, was a switch hitter. What happened next resembled an Abbott and Costello comedy routine. Venditte would put the glove on one hand (he had a specially made glove that could be worn on either hand) and Henriquez would then step across the plate to bat from the other side. Venditte would then switch his glove hand again and Henriquez went back to the other side.</p><p class="q-text qu-display--block" style="direction: ltr; margin: 0px 0px 1em; padding: 0px;">Eventually, after much discussion, the umpires ruled that Henriquez would have to choose a batting side first, before Venditte had to commit. Henriquez was mad and, after he struck out, he slammed the bat against the ground in frustration.</p><p class="q-text qu-display--block" style="direction: ltr; margin: 0px 0px 1em; padding: 0px;">The umpires were, in essence, winging it, because there was no rule to cover the situation. Eventually, the higher ups in baseball did write a rule to cover the situation — the opposite of the umpires’ decision.</p></span></div></div></div></div></div></div></div></div></div><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-09-20T18:56:00Z</updated>
    <published>2020-09-20T18:56:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-09-29T18:33:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/142</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/142" rel="alternate" type="text/html"/>
    <title>TR20-142 |  Relaxed Locally Correctable Codes with Improved Parameters | 

	Vahid Reza Asadi, 

	Igor Shinkar</title>
    <summary>Locally decodable codes (LDCs) are error-correcting codes $C : \Sigma^k \to \Sigma^n$ that admit a local decoding algorithm that recovers each individual bit of the message by querying only a few bits from a noisy codeword. An important question in this line of research is to understand the optimal trade-off between the query complexity of LDCs and their block length. Despite importance of these objects, the best known constructions of constant query LDCs have super-polynomial length, and there is a significant gap between the best constructions and the known lower bounds in terms of the block length.

For many applications it suffices to consider the weaker notion of relaxed LDCs (RLDCs), which allows the local decoding algorithm to abort if by querying a few bits it detects that the input is not a codeword. This relaxation turned out to allow decoding algorithms with constant query complexity for codes with almost linear length. Specifically, [Ben+06] constructed an $O(q)$-query RLDC that encodes a message of length $k$ using a codeword of block length $n = O(k^{1+1/\sqrt{q}})$.

In this work we improve the parameters of [Ben+06] by constructing an $O(q)$-query RLDC that encodes a message of length $k$ using a codeword of block length $O(k^{1+1/{q}})$. This construction matches (up to a multiplicative constant factor) the lower bounds of [KT00; Woo07] for constant query LDCs, thus making progress toward understanding the gap between LDCs and RLDCs in the constant query regime.

In fact, our construction extends to the stronger notion of relaxed locally correctable codes (RLCCs), introduced in [GRR18], where given a noisy codeword the correcting algorithm either recovers each individual bit of the codeword by only reading a small part of the input, or aborts if the input is detected to be corrupt.</summary>
    <updated>2020-09-20T18:00:19Z</updated>
    <published>2020-09-20T18:00:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-09-29T23:48:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1244</id>
    <link href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/" rel="alternate" type="text/html"/>
    <title>Announcing a short course in Paris</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This coming academic year I am on sabbatical, in Paris. It’s certainly a funny year to be on sabbatical. (It’s a funny year to be doing anything, isn’t it? Or is “funny” not the appropriate word…Yet I can’t find any … <a href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This coming academic year I am on sabbatical, in Paris. It’s certainly a funny year to be on sabbatical. (It’s a funny year to be doing anything, isn’t it? Or is “funny” not the appropriate word…Yet I can’t find any other way to look at it that doesn’t send me straight into the abyss. So, let it be “funny”—knowing that, no, I’m not actually laughing right now.) On the one hand, I am lucky to have escaped the incessant debates on the format of teaching, how many people per square foot are allowed in each building on campus, what distance I should stay from my students were I to attempt to meet them in person, and so many other similar decisions that have come to take up a larger and larger fraction of our professional lives (not to mention of course the incommensurate challenges that many are facing at the personal and familial level). On the other hand, the situation makes it much harder to meet others and engage in new collaborations, one of the goals of my sabbatical. I’ll see how it plays out; I’ll be sure to write more on this blog as time progresses.</p>



<p>During the sabbatical I am being hosted successively by different French institutions. For the first 6 months I had the good fortune of being awarded a “chair” from the “<a href="https://www.sciencesmaths-paris.fr/en/">Fondation Sciences Mathématiques de Paris</a>” (FSMP), a private foundation which supports, in very general terms, the development of the mathematics community in Paris, from the organization of general-public conferences to the support of research collaborations. My only formal obligation during these 6 months is to give 20 hours of lecture on a theme of my choosing. The goal that I elected for the course is provide an in-depth introduction to two major works in quantum complexity and cryptography of the past few years: first, Mahavev’s 2018 result on <a href="https://arxiv.org/abs/1804.01082">classical verification of quantum computation</a> (a result for which I already shared my enthusiasm <a href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/">here</a>); second, my result <a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> with Ji, Natarajan, Wright and Yuen on the power of quantum multi-prover interactive proof systems, which I mentioned in the <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">previous post</a>, and its consequences. For more about the course, including a tentative breakdown of lectures and some resources, see the <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">course webpage</a>. </p>



<p>While at the time of writing the course is still scheduled to start as an in-person meeting (to take place in a very large layered amphitheater with ample space for social distancing), there is no telling how the situation, and regulations, will evolve in the near future. To accommodate participants who are unable or prefer not to travel in person, all lectures starting with the first one will be recorded. In addition I will post course materials, including lecture notes, <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">here</a>. The purpose of this post is to advertise the course: participants from everywhere are welcome to watch the recorded videos, read the notes, and write to me with any questions in suggestions. In particular I plan to outsource the proof-reading of the notes via overleaf and I welcome any participant’s interest in helping with that; draft notes for the first lecture are already available <a href="https://www.overleaf.com/2293291658twkjfbtctsdb">here</a>. Anyone is welcome to make direct corrections, or add inline comments pointing to issues that may need my attention.</p>



<p>The program that I chose is ambitious, and we will see how far we get along. My goal is to start slow, so as to remain inclusive with respect to varying backgrounds in computer science, mathematics or physics. At first I will give complete definitions, state and prove simple lemmas, etc., in order to establish common language. As time progresses I expect that things will become a little more high-level, less self-contained, and more technical. Depending on your background and interests, you may find the first few lectures, or the last few ones, more interesting. Teaching the course will certainly be beneficial for me because I believe that there is a strong unity behind the two works I chose to present. I hope to make that unity apparent by presenting them together. Moreover, both works introduce new techniques that leave many avenues open; I hope that a “clean” presentation will help me, and others, build on them. </p>



<p>A side benefit of an “un-necessary” course such as this one is that it contributes to bringing a certain community together. (By “un-necessary” I mean that the course will not be required for any curriculum; if it did not take place, as long as it was replaced by other research-level activities its absence would not be felt.) COIVD-19 unfortunately turns that opportunity into a challenge. It is because of it that I insist–regulations allowing– on having the course take place in person: as much as we are getting used to Zoom, and as well as it may be working as a replacement for many aspects of our interactive lives, from in-person classes to conferences to research collaborations, a scientific event such as this one, with sustained involvement by a small set of participants coming from distant backgrounds, is probably one of the more challenging ones to make work online. I hope it doesn’t come to that. Even if it does, one of the lessons learned from the Spring 2020 semester on quantum computing at the Simons Institute in Berkeley, which was interrupted half-ways due to the pandemic, is that having an initial in-person phase was of great help to cement future online interactions. So, I hope that I am able to lecture on Tuesday; after that, we will see.</p></div>
    </content>
    <updated>2020-09-20T15:19:18Z</updated>
    <published>2020-09-20T15:19:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2020-09-29T23:51:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5573</id>
    <link href="https://adamsheffer.wordpress.com/2020/09/19/combinatorial-journals-are-changing/" rel="alternate" type="text/html"/>
    <title>Combinatorial Journals are Changing</title>
    <summary>I used to ask most combinatorialists I met for their opinion about the level of various journals. With this feedback, I compiled a rough journal ranking for combinatorics papers (for personal use). This was a very educational experience for me as a new combinatorialist. I learned that different people have rather different opinions. For example, […]</summary>
    <updated>2020-09-19T21:46:10Z</updated>
    <published>2020-09-19T21:46:10Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-09-29T23:50:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/09/19/beyondlogconvavesampling/</id>
    <link href="http://offconvex.github.io/2020/09/19/beyondlogconvavesampling/" rel="alternate" type="text/html"/>
    <title>Beyond log-concave sampling</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As the growing number of posts on this blog would suggest, recent years have seen a lot of progress in understanding optimization beyond convexity. However, optimization is only one of the basic algorithmic primitives in machine learning — it’s used by most forms of risk minimization and model fitting. Another important primitive is sampling, which is used by most forms of inference (i.e. answering probabilistic queries of a learned model).</p>

<p>It turns out that there is a natural analogue of convexity for sampling — <em>log-concavity</em>. Paralleling the state of affairs in optimization, we have a variety of (provably efficient) algorithms for sampling from log-concave distributions, under a variety of access models to the distribution. Log-concavity, however, is very restrictive and cannot model common properties of distributions we frequently wish to sample from in machine learning applications, for example multi-modality and manifold structure in the level sets, which is what we’ll focus on in this and the upcoming post.</p>

<p>Unlike non-convex optimization, the field of sampling beyond log-concavity is very nascent. In this post, we will survey the basic tools and difficulties for sampling beyond log-concavity. In the next post, we will survey recent progress in this direction, in particular with respect to handling multi-modality and manifold structure in the level sets, covering the papers <a href="https://arxiv.org/abs/1812.00793">Simulated tempering Langevin Monte Carlo</a> by Rong Ge, Holden Lee, and Andrej Risteski and <a href="https://arxiv.org/abs/2002.05576">Fast convergence for Langevin diffusion with matrix manifold structure</a> by Ankur Moitra and Andrej Risteski.</p>

<h1 id="formalizing-the-sampling-problem">Formalizing the sampling problem</h1>

<p>The formulation of the sampling problem we will consider is as follows:</p>

<blockquote>
  <p><strong>Problem</strong>: Sample from a distribution $p(x) \propto e^{-f(x)}$ given black-box access to $f$ and $\nabla f$.</p>
</blockquote>

<p>This formalization subsumes a lot of inference tasks involving different kinds of probabilistic models. We give several common examples:</p>

<p><em>1.Posterior inference</em>: Suppose our data is generated from a model with <em>unknown</em> parameters $\theta$ , such that the data-generation process is given by $p(x \mid \theta)$ and we have a prior $p(\theta)$ over the model parameters. Then the <em>posterior distribution</em> $p(\theta \mid x)$ , by Bayes’s Rule, is given by</p>

\[p(\theta \mid x) = \frac{p(x \mid \theta)p(x)}{p(x)}\propto p(x \mid \theta)p(\theta).\]

<p>A canonical example of this is a <em>noisy inference task</em> where a signal (parametrized by $\theta$ ) is perturbed by noise (as specified by $p(x \mid \theta)$ ).</p>

<p><em>2.Posteriors in latent-variable models</em>: If the data-generation process has a <em>latent (hidden) variable</em> $h$ associated to each data point, such that $h$ has a <em>known</em> prior $p(h)$ and a <em>known</em> conditional $p_\theta(x \mid h)$ , then again by Bayes’s rule, we have</p>

\[p_\theta(h \mid x) = \frac{p_\theta(x \mid h)p_\theta(h)}{p_\theta(x)}\propto p_\theta(x \mid h)p_\theta(h).\]

<p>In typical latent-variable models, $p_\theta(x \mid h)$ and $p_\theta(h)$ have a simple parametric form, which makes it easy to evaluate $p_\theta(x \mid h)p_\theta(h)$ . Some examples of latent-variable models are mixture models (where $h$ encodes which component a sample came from), topic models (where $h$ denote the topic proportions in a document), and noisy-OR networks (and latent-variable Bayesian belief networks).</p>

<p><em>3.Sampling from energy models</em>: in energy models, the distribution of the data is parametrized as $p(x) \propto \exp(-E(x))$ for some <em>energy</em> function $E(x)$ which is smaller on points in the data distribution. Recent works by <a href="https://arxiv.org/abs/1907.05600">(Song, Ermon 2019)</a> and <a href="https://arxiv.org/abs/1903.08689">(Du, Mordatch 2019)</a> have scaled up the training of these models on images so that the visual quality of the samples they produce is comparable to that of more popular generative models like GANs and flow models.</p>

<p>The “exponential form” $e^{-f(x)}$ is also helpful in making an analogy to optimization. Namely, if we sample from $p(x)\propto e^{-f(x)}$, a particular point $x$ is more likely to be sampled if $f(x)$ is small. The key difference between with optimization is that while in optimization, we only want to get to the minimum, in sampling, we want to pick points with the correct probabilities.</p>

<h1 id="comparison-with-optimization">Comparison with optimization</h1>

<p>The computational hardness landscape for our sampling problem parallels the one for black-box optimization, in which the goal is to find the minimum of a function $f$, given value/gradient oracle access. When $f$ is <em>convex</em>, there is a unique local minimum, so that local search algorithms like <em>gradient descent</em> are efficient. When $f$ is non-convex, gradient descent can get trapped in potentially poor local minima, and in the worst case, an exponential number of queries is needed.</p>

<p>Similarly, for sampling, when $p$ is <em>log-concave</em>, the distribution is unimodal and a Markov Chain which is a close relative of gradient descent — <em>Langevin Monte Carlo</em> —  is efficient. When $p$ is non-log-concave, Langevin Monte Carlo can get trapped in one of many modes, and and exponential number of queries may also be needed.</p>

<blockquote>
  <p>A distribution $p(x)\propto e^{-f(x)}$ is <strong>log-concave</strong> if $f(x) = -\log p(x)$ is convex. It is $\alpha$-strongly log-concave if $f(x)$ is $\alpha$-strongly convex.</p>
</blockquote>

<p>However, such worst-case hardness rarely stop practitioners from trying to solve the non-convex optimization or non-log-concave sampling problems which are ubiquitous in modern machine learning. Often they manage to do so with great success - for instance, in training deep neural networks, gradient descent and its relatives perform quite well. Similarly, Langevin Monte Carlo and its relatives can do quite well on non-log-concave problems, though they sometimes need to be aided by temperature heuristics and other tricks.</p>

<p>As theorists, we’d like to develop theory that will lead to a better understanding of why and when these heuristics work. Just like we’ve done for optimization, we need to be guided both by hardness results and relevant structure of real-world problems in this endeavour.</p>

<p>The following table summarizes the comparisons we have come up with:</p>

<p><img alt="" src="http://www.andrew.cmu.edu/user/aristesk/table_opt.jpg"/></p>

<p>Before we move on to non-log-concave distributions, though, we need to understand the basic algorithm for sampling and its guarantees for log-concave distributions.</p>

<h1 id="langevin-monte-carlo">Langevin Monte Carlo</h1>

<p>Just as gradient descent is the canonical algorithm for optimization, <em>Langevin Monte Carlo</em> (LMC) is the canonical algorithm for our sampling problem. In a nutshell, it is gradient descent that also injects Gaussian noise:</p>

\[\text{Gradient descent:}\quad 
x_{t+\eta} = x_t - \eta \nabla f(x_t)\]

\[\text{Langevin Monte Carlo:}\quad
x_{t+\eta} = x_t - \eta \nabla f(x_t) + \sqrt{2\eta}\xi_t,\quad \xi_t\sim N(0,I)\]

<p>Both of these processes can be considered as discretizations of a continuous process. For gradient descent, the limit is an <em>ordinary differential equation</em>, and for Langevin Monte Carlo a <em>stochastic differential equation</em>:</p>

\[\text{Gradient flow:} \quad dx_t = -\nabla f(x_t) dt\]

\[\text{Langevin diffusion:} \quad dx_t = -\nabla f(x_t) dt + \sqrt{2} dB_t\]

<p>where $B_t$ denotes Brownian motion of the appropriate dimension.</p>

<p>The crucial property of the above stochastic differential equation is that under fairly mild assumptions on $f$, the stationary distribution is $p(x) \propto e^{-f(x)}$. (If you’re more comfortable with optimization, note that while gradient descent generally converges to (local) minima, the Gaussian noise term prevents LMC from converging to a single point - rather, it converges to a <em>stationary distribution</em>. See animation below.)</p>

<p><img alt="" src="http://www.andrew.cmu.edu/user/aristesk/gd_ld_animated.gif"/></p>

<p>Langevin Monte Carlo fits in the <em>Markov Chain Monte Carlo</em> (MCMC) paradigm: design a random walk, so that the stationary distribution is the desired distribution. “Mixing” means getting close to the stationary distribution, and rapid mixing means this happens quickly.</p>

<p>Like in optimization, Langevin Monte Carlo is the most “basic” algorithm: for example, one can incorporate “acceleration” and obtain <em>underdamped</em> Langevin, or use the physics-inspired Hamiltonian Monte Carlo.</p>

<h1 id="tools-for-bounding-mixing-time-challenges-beyond-log-concavity">Tools for bounding mixing time, challenges beyond log-concavity</h1>

<p>To illustrate the difficulty in moving beyond log-concavity, we’ll describe the tools that are used to prove fast mixing for log-concave distributions, and where they fall short for non-log-concave distributions.</p>

<p>We will do this by an analogy to how we analyze random walks on graphs. One common way to prove rapid mixing of a random walk on a graph is to show the Laplacian has a spectral gap (equivalently, the transition matrix has a gap between the largest and next-to-largest eigenvalue). The analogue of this for Langevin diffusion is showing a <em>Poincaré inequality</em>. (A spectral gap of $1/C$ corresponds to Poincaré constant of $C$.)</p>

<blockquote>
  <p>We say that $p(x)$ satisfies a <strong>Poincaré inequality</strong> with constant $C$ if for all functions $g$ on $\mathbb R^d$ (such that $g$ and $\nabla g$ are square-integrable with respect to $p$),</p>
  <div> $$\text{Var}_p(g) \le C \int_{\mathbb R^d} ||\nabla g(x)||^2 p(x)\,dx.$$ </div>
</blockquote>

<p>A small constant $C$ implies fast mixing in $\chi^2$ divergence, which implies fast mixing in total variation distance. More precisely, the mixing time for Langevin diffusion is on the order of $C$. We note that other functional inequalities imply mixing with respect to other measures (such as log-Sobolev inequalities for KL divergence).</p>

<p>While it may not be obvious what the Poincaré inequality has to do with a spectral gap, it turns out that we can think of the right-hand side as a quadratic form involving the <em>infinitesimal generator</em> of Langevin process, which functions as the continuous analogue of a Laplacian for a graph random walk.</p>

<p>The following table shows the analogy: we can put the discrete and continuous processes on the same footing by defining a quadratic form called the Dirichlet form from the Laplacian or infinitesimal generator.</p>

<p><img alt="" src="http://www.andrew.cmu.edu/user/aristesk/table_mixing.jpg"/></p>

<p>To see how the Poincaré inequality represents a spectral gap in the discrete case, we write it in a more explicit form in a familiar special case: a lazy random walk (i.e. a random walk that with probability $1/2$ stays in the current vertex, and with probability $1/2$ goes to a random neighbor) on a regular graph with $n$ vertices. In this case, $p$ is the uniform distribution, and $v_1=\mathbf 1,\ldots, v_n$ are the eigenvectors of $A$ with eigenvalues $1=\lambda_1\ge \lambda_2\ge \cdots \ge \lambda_n\ge 0$; normalize $v_1,\ldots, v_n$ so they have unit norm with respect to $p$, i.e. $\Vert v_i\Vert_p^2=\frac 1n\sum_j v_{ij}^2=1$.</p>

<p>Writing $g= \sum_i a_i v_i$, since $v_2,\ldots, v_n$ are orthogonal to $v_1=\mathbf 1$, we have $\langle g, \mathbf 1\rangle_p =  a_1$, so</p>

\[\text{Var}_p(g) = \frac{1}{n}(\sum_i  g_i^2) - a_1^2 = \sum_{i=2}^n a_i^2\]

<p>Furthermore, we have</p>

\[\langle g, Lg \rangle_p = \langle \sum_i a_iv_i, (I- A)(\sum_i a_iv_i)\rangle_p=  \sum_{i=2}^n a_i^2(1-\lambda_i)\]

<p>These coefficients are all at most $1-\lambda_2$, i.e. the <em>spectral gap</em>, so</p>

\[\langle g, Lg \rangle_p \ge (1-\lambda_2)\text{Var}_p(g),\]

<p>which shows the Poincaré inequality with constant $(1-\lambda_2)^{-1}$.</p>

<p>A classic theorem establishes a Poincaré inequality for (strongly) log-concave distributions.</p>

<blockquote>
  <p><strong>Theorem (Bakry, Emery 1985)</strong>: If $p(x)$ is $\alpha$-strongly log-concave, then $p(x)$ satisfies a Poincaré inequality with constant $\frac1{\alpha}$.</p>
</blockquote>

<p>Hence, for strongly-log-concave distributions, Langevin diffusion mixes rapidly. To complete the picture, a line of recent works, starting with <a href="https://arxiv.org/abs/1412.7392">(Dalalyan 2014)</a> have established bounds for discretization error to obtain algorithmic guarantees for Langevin Monte Carlo.</p>

<p>However, guarantees break down when we don’t assume log-concavity. Generically, algorithms for sampling depend <em>exponentially</em> on the ambient dimension $d$, or on the “size” of the non-log-concave region (e.g., the distance between modes of the distribution). In terms of their dependence on $d$, they are not doing much better than if we split space into cells and sample each according to its probability, similar to “grid search” for optimization. This is unsurprising: we can’t hope for better guarantees without structural assumptions.</p>

<p>Toward this end, in the next blog post we will consider two kinds of structure that allow efficient sampling:</p>

<ol>
  <li>Simple multimodal distributions, such as a mixture of gaussians with equal variance.</li>
  <li>Manifold structure, arising from symmetries in the level sets of the distribution.</li>
</ol></div>
    </summary>
    <updated>2020-09-19T14:00:00Z</updated>
    <published>2020-09-19T14:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-09-29T23:50:35Z</updated>
    </source>
  </entry>
</feed>
