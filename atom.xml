<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-16T20:22:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/048</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/048" rel="alternate" type="text/html"/>
    <title>TR20-048 |  Improved lifting theorems via robust sunflowers | 

	Jiapeng Zhang, 

	Shachar Lovett, 

	Raghu Meka</title>
    <summary>Lifting theorems are a generic way to lift lower bounds in query complexity to lower bounds in communication complexity, with applications in diverse areas, such as combinatorial optimization, proof complexity, game theory. Lifting theorems rely on a gadget, where smaller gadgets give stronger lower bounds. However, existing proof techniques are known to require somewhat large gadgets.

We focus on one of the most widely used gadgets, the index gadget. For this gadget, existing lifting techniques are known to require at least a quadratic gadget size. We develop a new approach to prove lifting theorems for the indexing gadget, based on a novel connection to the recently developed robust sunflower lemmas. We show that this allows to reduce the gadget size to linear. We conjecture that it can be further improved to poly logarithmic, similar to the known bounds for the corresponding robust sunflower lemmas.</summary>
    <updated>2020-04-16T17:49:17Z</updated>
    <published>2020-04-16T17:49:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-16T20:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/047</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/047" rel="alternate" type="text/html"/>
    <title>TR20-047 |  Explicit Uniquely Decodable Codes for Space Bounded Channels That Achieve List-Decoding Capacity | 

	Jad Silbak, 

	Ronen Shaltiel</title>
    <summary>We consider codes for space bounded channels. This is a model for communication under noise that was introduced by Guruswami and Smith (J. ACM 2016) and lies between the Shannon (random) and Hamming (adversarial) models. In this model, a channel is a space bounded procedure that reads the codeword in one pass, and modifies at most a $p$ fraction of the bits of the codeword.

Explicit uniquely decodable codes for space bounded channels: Our main result is that for every $0 \le p \le \frac{1}{4}$, there exists a constant $\delta\ge 0$ and a \emph{uniquely decodable} code that is \emph{explicit} (meaning that encoding and decoding are in poly-time) and has rate $1-H(p)$ for channels with space $n^{\delta}$.

This improves upon previous explicit codes by Guruswami and Smith, and Kopparty, Shaltiel and Silbak (FOCS 2019). Specifically, we obtain the same space and rate as earlier works, even though prior work gave only list-decodable codes (rather than uniquely decodable codes).

Complete characterization of the capacity of space bounded channels: Together with a result by Guruswami and Smith showing the impossibility of unique decoding for $p \ge \frac{1}{4}$, our techniques also give a complete characterization of the capacity $R(p)$ of space $n^{1-o(1)}$ channels, specifically: $R(p)=1-H(p)$ for $0 \le p \le 1/4$ and $R(p)=0$ for $p \ge 1/4$.

In particular, $R(\cdot)$ is not continuous at $p=1/4$. This capacity is strictly larger than the capacity of Hamming channels for every $0 \le p \le \frac{1}{4}$, and matches the capacity of list decoding, and binary symmetric channels in this range.


Our results are incomparable to recent work on casual channels. Casual channels are stronger channels in which the channel reads the codeword in one pass, but there is no space restriction. The best known codes for casual channels, due to Chen, Jaggi and Langberg (STOC 2015), are shown to exist by the probabilistic method, and no explicit codes are known. Furthermore, our results imply that for $p\ge p_0 \approx 0.0804$, there is a separation between the capacities of space bounded channels and casual channels, and the capacity of the former is strictly larger than that of the latter.


Our approach builds on previous explicit list decodable codes for space bounded channels. We introduce and study a notion of ``\emph{evasivenss}'' of codes, which is concerned with whether a decoding algorithm rejects a word that is obtained when a channel induces few errors to a \emph{uniformly chosen} string. We use evasiveness (as well as several additional new ideas related to coding theory and pseudorandomness) to identify the ``correct'' message in the list. Loosely speaking, this is achieved by arguing that on ``incorrect messages'' the decoding algorithm cannot distinguish the codeword from a uniform string.</summary>
    <updated>2020-04-16T10:28:32Z</updated>
    <published>2020-04-16T10:28:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-16T20:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07220</id>
    <link href="http://arxiv.org/abs/2004.07220" rel="alternate" type="text/html"/>
    <title>Log-Concave Polynomials IV: Exchange Properties, Tight Mixing Times, and Faster Sampling of Spanning Trees</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Kuikui.html">Kuikui Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharan:Shayan_Oveis.html">Shayan Oveis Gharan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinzant:Cynthia.html">Cynthia Vinzant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07220">PDF</a><br/><b>Abstract: </b>We prove tight mixing time bounds for natural random walks on bases of
matroids, determinantal distributions, and more generally distributions
associated with log-concave polynomials. For a matroid of rank $k$ on a ground
set of $n$ elements, or more generally distributions associated with
log-concave polynomials of homogeneous degree $k$ on $n$ variables, we show
that the down-up random walk, started from an arbitrary point in the support,
mixes in time $O(k\log k)$. Our bound has no dependence on $n$ or the starting
point, unlike the previous analyses [ALOV19, CGM19], and is tight up to
constant factors. The main new ingredient is a property we call approximate
exchange, a generalization of well-studied exchange properties for matroids and
valuated matroids, which may be of independent interest.
</p>
<p>Additionally, we show how to leverage down-up random walks to approximately
sample spanning trees in a graph with $n$ edges in time $O(n\log^2 n)$,
improving on the almost-linear time algorithm by Schild [Sch18]. Our analysis
works on weighted graphs too, and is the first to achieve nearly-linear running
time.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07217</id>
    <link href="http://arxiv.org/abs/2004.07217" rel="alternate" type="text/html"/>
    <title>A Small Improvement to the Upper Bound on the Integrality Ratio for the $s-t$ Path TSP</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Xianghui.html">Xianghui Zhong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07217">PDF</a><br/><b>Abstract: </b>In this paper we investigate the integrality ratio of the standard LP
relaxation for the metric $s-t$ path TSP. We make a near-optimal choice for an
auxiliary function used in the analysis of Traub and Vygen which leads to an
improved upper bound for the integrality ratio of 1.5273.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07214</id>
    <link href="http://arxiv.org/abs/2004.07214" rel="alternate" type="text/html"/>
    <title>Enumerating minimal dominating sets in the (in)comparability graphs of bounded dimension posets</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonamy:Marthe.html">Marthe Bonamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Defrain:Oscar.html">Oscar Defrain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Micek:Piotr.html">Piotr Micek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nourine:Lhouari.html">Lhouari Nourine</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07214">PDF</a><br/><b>Abstract: </b>Enumerating minimal transversals in a hypergraph is a notoriously hard
problem. It can be reduced to enumerating minimal dominating sets in a graph,
in fact even to enumerating minimal dominating sets in an incomparability
graph. We provide an output-polynomial time algorithm for incomparability
graphs whose underlying posets have bounded dimension. Through a different
proof technique, we also provide an output-polynomial algorithm for their
complements, i.e., for comparability graphs of bounded dimension posets.
</p>
<p>Our algorithm for incomparability graphs is based on flashlight search and
relies on the geometrical representation of incomparability graphs with bounded
dimension, as given by Golumbic et al. in 1983. It runs with polynomial delay
and only needs polynomial space. Our algorithm for comparability graphs is
based on the flipping method introduced by Golovach et al. in 2015. It performs
in incremental-polynomial time and requires exponential space.
</p>
<p>In addition, we show how to improve the flipping method so that it requires
only polynomial space. Since the flipping method is a key tool for the best
known algorithms enumerating minimal dominating sets in a number of graph
classes, this yields direct improvements on the state of the art.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07151</id>
    <link href="http://arxiv.org/abs/2004.07151" rel="alternate" type="text/html"/>
    <title>An algorithmic framework for colouring locally sparse graphs</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Ewan.html">Ewan Davies</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kang:Ross_J=.html">Ross J. Kang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pirot:Fran=ccedil=ois.html">François Pirot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sereni:Jean=S=eacute=bastien.html">Jean-Sébastien Sereni</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07151">PDF</a><br/><b>Abstract: </b>We develop an algorithmic framework for graph colouring that reduces the
problem to verifying a local probabilistic property of the independent sets.
</p>
<p>With this we give, for any fixed $k\ge 3$ and $\varepsilon&gt;0$, a randomised
polynomial-time algorithm for colouring graphs of maximum degree $\Delta$ in
which each vertex is contained in at most $t$ copies of a cycle of length $k$,
where $1/2\le t\le \Delta^\frac{2\varepsilon}{1+2\varepsilon}/(\log\Delta)^2$,
with $\lfloor(1+\varepsilon)\Delta/\log(\Delta/\sqrt t)\rfloor$ colours.
</p>
<p>This generalises and improves upon several notable results including those of
Kim (1995) and Alon, Krivelevich and Sudakov (1999), and more recent ones of
Molloy (2019) and Achlioptas, Iliopoulos and Sinclair (2019). This bound on the
chromatic number is tight up to an asymptotic factor $2$ and it coincides with
a famous algorithmic barrier to colouring random graphs.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07118</id>
    <link href="http://arxiv.org/abs/2004.07118" rel="alternate" type="text/html"/>
    <title>Complete Edge-Colored Permutation Graphs</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hartmann:Tom.html">Tom Hartmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannach:Max.html">Max Bannach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Middendorf:Martin.html">Martin Middendorf</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stadler:Peter_F=.html">Peter F. Stadler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wieseke:Nicolas.html">Nicolas Wieseke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07118">PDF</a><br/><b>Abstract: </b>We introduce the concept of complete edge-colored permutation graphs as
complete graphs that are the edge-disjoint union of "classical" permutation
graphs. We show that a graph $G=(V,E)$ is a complete edge-colored permutation
graph if and only if each monochromatic subgraph of $G$ is a "classical"
permutation graph and $G$ does not contain a triangle with~$3$ different
colors. Using the modular decomposition as a framework we demonstrate that
complete edge-colored permutation graphs are characterized in terms of their
strong prime modules, which induce also complete edge-colored permutation
graphs. This leads to an $\mathcal{O}(|V|^2)$-time recognition algorithm. We
show, moreover, that complete edge-colored permutation graphs form a superclass
of so-called symbolic ultrametrics and that the coloring of such graphs is
always a Gallai coloring.
</p></div>
    </summary>
    <updated>2020-04-16T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.07058</id>
    <link href="http://arxiv.org/abs/2004.07058" rel="alternate" type="text/html"/>
    <title>Computing Tropical Prevarieties with Satisfiability Modulo Theory (SMT) Solvers</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=uuml=ders:Christoph.html">Christoph Lüders</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.07058">PDF</a><br/><b>Abstract: </b>I am presenting a novel way to use SMT (Satisfiability Modulo Theory) to
compute the tropical prevariety (resp. equilibrium) of a polynomial system. The
new method is benchmarked against a naive approach that uses purely polyhedral
methods. It turns out that the SMT approach is faster than the polyhedral
approach for models that would otherwise take more than one minute to compute,
in many cases by a factor of 25 or more. Furthermore, the new approach offers a
way to compute at least parts of the solution if the polyhedral approach is
infeasible.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06898</id>
    <link href="http://arxiv.org/abs/2004.06898" rel="alternate" type="text/html"/>
    <title>Learning sums of powers of low-degree polynomials in the non-degenerate case</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Ankit.html">Ankit Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kayal:Neeraj.html">Neeraj Kayal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saha:Chandan.html">Chandan Saha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06898">PDF</a><br/><b>Abstract: </b>We develop algorithms for writing a polynomial as sums of powers of low
degree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can
be written as $$f = c_1Q_1^{m} + \ldots + c_s Q_s^{m},$$ where each $c_i\in
\mathbb{F}^{\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m
= d$. In this paper, we give a $\text{poly}((ns)^t)$-time learning algorithm
for finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy
certain non-degeneracy conditions and $n$ is larger than $d^2$. The set of
degenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a
non-trivial variety and hence if the $Q_i$'s are chosen according to any
reasonable (full-dimensional) distribution, then they are non-degenerate with
high probability (if $s$ is not too large).
</p>
<p>Our algorithm is based on a scheme for obtaining a learning algorithm for an
arithmetic circuit model from a lower bound for the same model, provided
certain non-degeneracy conditions hold. The scheme reduces the learning problem
to the problem of decomposing two vector spaces under the action of a set of
linear operators, where the spaces and the operators are derived from the input
circuit and the complexity measure used in a typical lower bound proof. The
non-degeneracy conditions are certain restrictions on how the spaces decompose.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06879</id>
    <link href="http://arxiv.org/abs/2004.06879" rel="alternate" type="text/html"/>
    <title>On the Complexity of the Plantinga-Vegter Algorithm</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cucker:Felipe.html">Felipe Cucker</a>, Alperen A. Ergür, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tonelli=Cueto:Josu=eacute=.html">Josué Tonelli-Cueto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06879">PDF</a><br/><b>Abstract: </b>We introduce a general toolbox for precision control and complexity analysis
of subdivision based algorithms in computational geometry. We showcase the
toolbox on a well known example from this family; the adaptive subdivision
algorithm due to Plantinga and Vegter. The only existing complexity estimate on
this rather fast algorithm was an exponential worst-case upper bound for its
interval arithmetic version. We go beyond the worst-case by considering
smoothed analysis, and prove polynomial time complexity estimates for both
interval arithmetic and finite precision versions of the Plantinga-Vegter
algorithm. The employed toolbox is a blend of robust probabilistic techniques
coming from geometric functional analysis with condition numbers and the
continuous amortization paradigm introduced by Burr, Krahmer and Yap. We hope
this combination of tools from different disciplines would prove useful for
understanding complexity aspects of the broad family of subdivision based
algorithms in computational geometry.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06828</id>
    <link href="http://arxiv.org/abs/2004.06828" rel="alternate" type="text/html"/>
    <title>Population Recovery from the Deletion Channel: Nearly Matching Trace Reconstruction Bounds</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Shyam.html">Shyam Narayanan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06828">PDF</a><br/><b>Abstract: </b>The population recovery problem asks one to recover an unknown distribution
over $n$-bit strings given query access to independent noisy samples of strings
drawn from the distribution. Recently, Ban et. al. [BCF+19] studied the problem
where the unknown distribution over $n$-bit strings is known to be
$\ell$-sparse for some fixed $\ell$, and the noise is induced through the
deletion channel. The deletion channel is a noise model where each bit of the
string is independently deleted with some fixed probability, and the retained
bits are concatenated. We note that if $\ell = 1,$ i.e., we are trying to learn
a single string, learning the distribution is equivalent to the famous trace
reconstruction problem. The best known algorithms for trace reconstruction
require $\exp\left(O(n^{1/3})\right)$ samples.
</p>
<p>For population recovery under the deletion channel, Ban et. al. provided an
algorithm that could learn $\ell$-sparse distributions over strings using
$\exp\left(n^{1/2} \cdot (\log n)^{O(\ell)}\right)$ samples. In this work, we
provide an algorithm that learns the distribution using only
$\exp\big(\tilde{O}(n^{1/3}) \cdot \ell^2\big)$ samples, by developing a
higher-moment analog of the algorithms of [DOS17, NP17]. We also give the first
algorithm with a runtime subexponential in $n$, which solves population
recovery in $\exp\big(\tilde{O}(n^{1/3}) \cdot \ell^3\big)$ samples and time.
</p>
<p>Notably, our dependence on $n$ nearly matches the known upper bound when
$\ell = 1$, and we reduce the dependence on $\ell$ from doubly to nearly singly
exponential. Therefore, we are able to learn the mixture even for much larger
values of $\ell$. For instance, Ban et. al.'s algorithm can only learn a
mixture of $O(\log n/\log \log n)$ strings with a subexponential number of
queries, whereas we are able to learn a mixture of up to $n^{o(1)}$ strings in
subexponential queries and time.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06776</id>
    <link href="http://arxiv.org/abs/2004.06776" rel="alternate" type="text/html"/>
    <title>The Circumbilliard: Any Triangle can be a 3-Periodic</title>
    <feedworld_mtime>1586995200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Ronaldo.html">Ronaldo Garcia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06776">PDF</a><br/><b>Abstract: </b>A Circumconic passes through a triangle's vertices. We define the
Circumbilliard, a circumellipse to a generic triangle for which the latter is a
3-periodic. We study its properties and associated loci.
</p></div>
    </summary>
    <updated>2020-04-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Mathematics as a team sport (). What a week-long research workshop at Oberwolfach (or Dagstuhl, or many similar retreats) can be like. The workshop in the link is on low-dimensional topology, but the story would be the same for many other subjects. In late March, instead of attending a Bellairs workshop, we all collaborated remotely. I think we got a fair amount of research accomplished, but I didn’t have the same sense of all being brought together to do that one thing.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematics-as-a-team-sport-20200331/">Mathematics as a team sport</a> (<a href="https://mathstodon.xyz/@11011110/103927542292984705"/>). What a week-long research workshop at Oberwolfach (or Dagstuhl, or many similar retreats) can be like. The workshop in the link is on low-dimensional topology, but the story would be the same for many other subjects. In late March, instead of attending a Bellairs workshop, we all collaborated remotely. I think we got a fair amount of research accomplished, but I didn’t have the same sense of all being brought together to do that one thing.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.11832">Semidefinite programming bounds for the average kissing number</a> (<a href="https://mathstodon.xyz/@11011110/103932970304148800"/>). Spheres kiss by touching with no overlap. The kissing number is how many unit spheres can touch a central one, and lattice kissing number is how many can touch in a lattice packing; both are 12 in 3d. Average kissing number is for finitely many non-unit spheres. It is ≥ lattice kissing number and ≤ 2x kissing number. One of my papers has a slightly better lower bound in 3d, and now we have better upper bounds in many dimensions.</p>
  </li>
  <li>
    <p><a href="https://mathsedideas.blogspot.com/p/resources.html#RAMs">320 Random Acts of Maths</a> (<a href="https://mathstodon.xyz/@antoinechambertloir/103920121638187355"/>). Pocket-sized problems, teasers, curios, provocations, inspirations, etc.</p>
  </li>
  <li>
    <p><a href="https://www.nature.com/articles/d41586-020-00998-2">Mochizuki will publish his purported proof of the abc conjecture in the journal of which he is editor in chief</a> (<a href="https://mathstodon.xyz/@11011110/103941722283312831"/>, <a href="https://retractionwatch.com/2020/04/04/weekend-reads-covid-19-and-peer-review-blaming-a-spell-checker-for-plagiarism-the-fastest-retracting-country/">via</a>). “The latest announcement seems unlikely to move many researchers over to Mochizuki’s camp.”</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Ring_lemma">The ring lemma</a> (<a href="https://mathstodon.xyz/@11011110/103950535538050348"/>). New Wikipedia article on the ratio between sizes of adjacent circles in a circle packing.</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/site/calculatinghistory/home/computing-linkages">Computing linkages</a> (<a href="https://mathstodon.xyz/@esoterica/103950724802083262"/>). Article by Andries de Man on computing devices built with hinged rods instead of electronics or gears.</p>
  </li>
  <li>
    <p><a href="https://bl.ocks.org/robinhouston/6096950">Doyle spiral explorer</a> (<a href="https://mathstodon.xyz/@11011110/103961199355813355"/>). If you slur “Doyle spiral” enough it kind of sounds like “Dora”. You can also <a href="https://observablehq.com/@mbostock/double-doyle-spiral">Möbius transform these things and get double spirals</a>.</p>
  </li>
  <li>
    <p>This photo (<a href="https://mathstodon.xyz/@11011110/103965972080045328"/>) is actually from a year ago but I neglected to upload it then and only rediscovered it recently while attempting to explain to an older relative, over the phone, how to attach images to text messages. It’s a shallow Showa bowl from Japan, bought when my wife and I visited Tokyo three years ago. We usually hold fruit in it; at the time I posted, it held three bananas and three lemons.</p>

    <p style="text-align: center;"><a href="https://www.ics.uci.edu/~eppstein/pix/radialbowl/index.html"><img alt="Showa bowl from above" src="https://www.ics.uci.edu/~eppstein/pix/radialbowl/RadialBowl-m.jpg" style="border-style: solid; border-color: black;"/></a></p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/C._Doris_Hellman">C. Doris Hellman, historian of astronomy</a> (<a href="https://mathstodon.xyz/@11011110/103970811680488005"/>), now a Good Article on Wikipedia. Through Hellman’s work on the Great Comet of 1577, historians came to see how Tycho Brahe’s observations of the comet moving unobstructed through translunar space <a href="https://en.wikipedia.org/wiki/Copernican_Revolution">became key evidence for heliocentrism and against the geocentric model of crystal spheres holding up the planets</a>. She also translated the definitive biography of Johannes Kepler from German into English.</p>
  </li>
  <li>
    <p>Found in Friedman’s <em>A History of Folding in Mathematics</em>, p. 71, a quote from Francesco Maurolico from <span style="white-space: nowrap;">1537 (<a href="https://mathstodon.xyz/@11011110/103978188972978011"/>):</span> “Item manifestum est in unoquoque regularium solidorum, numerum basium coniunctum cum numero cacuminum conflare numerum, qui binario excedit numerum laterum”. Except for the fact that he considers only Platonic solids, this is Euler’s formula  for convex polyhedra (in the equivalent form ), long before Euler (1752) and Descartes (1630).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Convex_hull">Convex hull</a> (<a href="https://mathstodon.xyz/@11011110/103981026707788374"/>), now a Good Article on Wikipedia.</p>
  </li>
  <li>
    <p>Appreciations of John Conway, following his death from the coronavirus (<a href="https://mathstodon.xyz/@11011110/103987909082094935"/>):</p>

    <ul>
      <li>
        <p><a href="https://cameroncounts.wordpress.com/2020/04/12/john-conway/">Peter Cameron</a></p>
      </li>
      <li>
        <p><a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">Terry Tao</a></p>
      </li>
      <li>
        <p><a href="https://www.scottaaronson.com/blog/?p=4732">Scott Aaronson</a></p>
      </li>
      <li>
        <p><a href="https://www.solipsys.co.uk/new/RememberingConway.html?td12mn">Colin Wright</a></p>
      </li>
      <li>
        <p><a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">Richard Lipton and Ken Regan</a></p>
      </li>
      <li>
        <p><a href="https://xkcd.com/2293/">xkcd</a></p>
      </li>
      <li>
        <p><em><a href="http://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">The Guardian</a></em></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="http://www.dam.brown.edu/people/mumford/blog/2015/WakeUp.html">Wake up!</a> (<a href="https://mathstodon.xyz/@11011110/103998469608885562"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/A_K_Peters">via</a>). A five-year-old blog post by David Mumford on the problems of corporate takeover of academic publishing, and the ensuing destruction of traditional author-editor relations.</p>
  </li>
  <li>
    <p><a href="http://utf8everywhere.org/">utf8 everywhere</a> (<a href="https://mathstodon.xyz/@11011110/104001143871939014"/>, <a href="https://news.ycombinator.com/item?id=22867503">via</a>). Mostly a manifesto about how we should be using utf8 instead of utf16 for unicode text files. But I think the sentiment that we should be treating utf8 as the default instead of ascii (which still is the actual default in many situations) is also valid.</p>
  </li>
  <li>
    <p>In <a href="https://11011110.github.io/blog/2020/03/29/backyard-sunlight.html">the previous batch of photos</a> the stripy shadows were artificial (caused by the slats of a trellis shading our patio) but this time they’re natural: they come from the fronds of one of the palm trees in our garden, shading the trunk of the tree (<a href="https://mathstodon.xyz/@11011110/104005420231873385"/>).</p>

    <p style="text-align: center;"><a href="https://www.ics.uci.edu/~eppstein/pix/palmshadow/index.html"><img alt="Palm tree casts shadows on itself" src="https://www.ics.uci.edu/~eppstein/pix/palmshadow/PalmShadow-m.jpg" style="border-style: solid; border-color: black;"/></a></p>
  </li>
</ul></div>
    </content>
    <updated>2020-04-15T21:54:00Z</updated>
    <published>2020-04-15T21:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-16T19:17:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/046</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/046" rel="alternate" type="text/html"/>
    <title>TR20-046 |  A Robust Version of Heged\H{u}s&amp;#39;s Lemma, with Applications | 

	Srikanth Srinivasan</title>
    <summary>Heged\H{u}s's lemma is the following combinatorial statement regarding polynomials over finite fields. Over a field $\mathbb{F}$ of characteristic $p &gt; 0$ and for $q$ a  power of $p$, the lemma says that any multilinear polynomial $P\in \mathbb{F}[x_1,\ldots,x_n]$ of degree less than $q$ that vanishes at all points in $\{0,1\}^n$ of Hamming weight $k\in [q,n-q]$ must also vanish at all points in $\{0,1\}^n$ of weight $k + q$. This lemma was used by Heged\H{u}s (2009) to give a solution to \emph{Galvin's problem}, an extremal problem about set systems; by Alon, Kumar and Volk (2018) to improve the best-known multilinear circuit lower bounds; and by Hrube\v{s}, Ramamoorthy, Rao and Yehudayoff (2019) to prove optimal lower bounds against depth-$2$ threshold circuits for computing some symmetric functions. 
		
		In this paper, we formulate a robust version of Heged\H{u}s's lemma. Informally, this version says that if a polynomial of degree $o(q)$ vanishes at most points of weight $k$, then it vanishes at many points of weight $k+q$. We prove this lemma and give the following three different applications.
		
		1. Degree lower bounds for the coin problem: The \emph{$\delta$-Coin Problem} is the problem of distinguishing between a coin that is heads with probability $((1/2) + \delta)$ and a coin that is heads with probability $1/2$. We show that over a field of positive (fixed) characteristic, any polynomial that solves the $\delta$-coin problem with error $\varepsilon$ must have degree $\Omega(\frac{1}{\delta}\log(1/\varepsilon)),$ which is tight up to constant factors.
		
		2. Probabilistic degree lower bounds: The \emph{Probabilistic degree} of a Boolean function is the minimum $d$ such that there is a random polynomial of degree $d$ that agrees with the function at each point with high probability. We give tight lower bounds on the probabilistic degree of \emph{every} symmetric Boolean function over positive (fixed) characteristic. As far as we know, this was not known even for some very simple functions such as unweighted Exact Threshold functions, and constant error.
		
		3. A robust version of the combinatorial result of Heged\H{u}s (2009) mentioned above.</summary>
    <updated>2020-04-15T16:25:07Z</updated>
    <published>2020-04-15T16:25:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-16T20:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-104815394733465706</id>
    <link href="https://blog.computationalcomplexity.org/feeds/104815394733465706/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/theoretical-computer-science-for-future.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/104815394733465706" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/104815394733465706" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/theoretical-computer-science-for-future.html" rel="alternate" type="text/html"/>
    <title>Theoretical Computer Science for the Future</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Guest post by the TCS4F initiative
(Antoine Amarilli, Thomas Colcombet, Hugo Férée, Thomas Schwentick) </i><div><br/></div><div><a href="https://tcs4f.org/">TCS4F</a> is an initiative by theoretical computer scientists who are
concerned about that other major crisis of our time: climate change. We
anticipate that the climate crisis will be a major challenge of the
decades to come, that it will require major changes at all levels of
society to mitigate the harm that it will cause, and that researchers in
theoretical computer science, like all other actors, must be part of the
solution and not part of the problem.</div>
<div><br/></div><div>Our initiative is to propose a <a href="https://tcs4f.org/">manifesto</a> to commit
to a reduction of greenhouse gas emissions: following <a href="https://www.ipcc.ch/2018/10/08/summary-for-policymakers-of-ipcc-special-report-on-global-warming-of-1-5c-approved-by-governments/">IPCC goals</a>, the
objective is to reduce by at least 50% before 2030 relative to pre-2020
levels. The manifesto is more than a simple expression of concern,
because it is a pledge with concrete objectives. However, it does not
prescribe specific measures, as we believe this discussion is not
settled yet and the right steps to take can vary depending on everyone's
practices. </div><div><br/>
The manifesto can be signed by individual researchers (like you, dear
reader!), by research groups, and by organizers of conferences and
workshops. Currently, over 50 researchers have signed it. The goal of
TCS4F is also to start organizing a community of concerned researchers,
across theoretical computer science, to think about the issue of climate
change and how to adjust what we do, in particular our travel habits. </div><div><br/>
We need your help to make this initiative a success and help theoretical
CS lead the way towards a sustainable, carbon-neutral future:</div><div><ul style="text-align: left;"><li>If you agree with our concerns and are ready to commit to reducing
 your carbon footprint, consider <a href="https://tcs4f.org/">signing the manifesto</a>. Signing is open to all researchers in
 theoretical CS in the broadest possible sense.</li><li>Advertise your support of the manifesto (e.g., by putting one of our
 badges on your webpage). Talk in your research teams and departments
 about the manifesto, and see if you can gather support for signing the
 manifesto collectively as a research group.</li><li>If you are involved in conferences and workshops, start a discussion
 about the carbon footprint of the event, and whether the event could
 commit to the manifesto's goal. Indeed, now that conferences across
 the globe are moving online because of the COVID-19 pandemic, it is a
 good time to discuss how conferences could evolve towards more
 sustainable models.</li><li>Spread the word about the issue of climate change and the TCS4F
 initiative, and encourage discussion of this important challenge in
 our communities. </li></ul></div><div>
As theoretical researchers, we are not used to discussing uncomfortable
non-scientific questions like the effects of our activities on the
world. However, we believe that the magnitude of the climate crisis
obliges us to act now as a community. We are confident that great
changes can be achieved if we do not limit our creativity to our
specific research areas and also use it to re-think our way to do
research.
<br/></div></div>
    </content>
    <updated>2020-04-15T13:42:00Z</updated>
    <published>2020-04-15T13:42:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-16T14:35:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/045</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/045" rel="alternate" type="text/html"/>
    <title>TR20-045 |  Learning sums of powers of low-degree polynomials in the non-degenerate case | 

	Ankit Garg, 

	Neeraj Kayal, 

	Chandan Saha</title>
    <summary>We develop algorithms for writing a polynomial as sums of powers of low degree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can be written as
$$f = c_1Q_1^{m} + \ldots + c_s Q_s^{m},$$
where each $c_i\in \mathbb{F}^{\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m = d$. In this paper, we give a $\text{poly}((ns)^t)$-time learning algorithm for finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy certain non-degeneracy conditions and $n$ is larger than $d^2$. The set of degenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a non-trivial variety and hence if the $Q_i$'s are chosen according to any reasonable (full-dimensional) distribution, then they are non-degenerate with high probability (if $s$ is not too large). This problem generalizes symmetric tensor decomposition, which corresponds to the $t = 1$ case and is widely studied, having many applications in machine learning. Our algorithm (for $t=2$) allows us to solve the moment problem for mixtures of zero-mean Gaussians in the non-degenerate case.

Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from a lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on how the spaces decompose. Such a scheme is present in a rudimentary form in an earlier work of Kayal and Saha. Here, we make it more general and detailed, and potentially applicable to learning other circuit models.

An exponential lower bound for the representation above (also known as homogeneous $\Sigma \wedge \Sigma \Pi^{[t]}$ circuits) is known using the shifted partials measure. However, the number of linear operators in shifted partials is exponential and also the non-degeneracy condition emerging out of this measure is unlikely to be satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit when the number of variables is large with respect to the degree. We bypass this hurdle by proving a lower bound (which is nearly as strong as the previous bound) using a novel variant of the partial derivatives measure, namely affine projections of partials (APP). The non-degeneracy conditions appearing from this new measure are satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit. The APP measure could be of independent interest for proving other lower bounds.</summary>
    <updated>2020-04-15T07:50:58Z</updated>
    <published>2020-04-15T07:50:58Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-16T20:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4740</id>
    <link href="https://www.scottaaronson.com/blog/?p=4740" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4740#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4740" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The quantum computer that knows all</title>
    <summary xml:lang="en-US">This is my first post in more than a month that’s totally unrelated to the covid crisis. Or rather, it’s related only insofar as it’s about a Hulu miniseries, the sort of thing that many of us have more occasion to watch while holed up at home. Three weeks ago, a journalist named Ben Lindbergh—who’d […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is my first post in more than a month that’s totally unrelated to the covid crisis.  Or rather, it’s related only insofar as it’s about a Hulu miniseries, the sort of thing that many of us have more occasion to watch while holed up at home.</p>



<p>Three weeks ago, a journalist named Ben Lindbergh—who’d previously asked me to <a href="https://www.scottaaronson.com/blog/?p=4184">comment on the scientific accuracy of <em>Avengers: Endgame</em></a>—asked me the same question about the miniseries <a href="https://en.wikipedia.org/wiki/Devs_(miniseries)">Devs</a>, which I hadn’t previously heard of.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">[Warning: Spoilers follow]</span></strong></p>



<p>‘Devs,’ I learned, is a spooky sci-fi action thriller about a secretive Silicon Valley company that builds a quantum computer that can perfectly reconstruct the past, down to what Jesus looked like on the cross, and can also (at least up to a point) predict the future.</p>



<p>And I was supposed, not only to endure such a show, but to comment on the <em>accuracy</em> of its invocations of quantum computing?  This didn’t sound promising.</p>



<p>But, y’know, I was at home quarantined.  So I agreed to watch the first episode.  Which quickly turned into the second, third, fourth, fifth, sixth, and seventh episodes (the eighth and final one isn’t out yet).</p>



<p>It turns out that ‘Devs’ isn’t too bad, <em>except</em> that it’s not particularly about quantum computers.  The latter is simply a buzzword chosen by the writers for a plot concept that would’ve been entirely familiar to the ancient Greeks, who called it the Delphic Oracle.  You know, the mysterious entity that prophesies your fate, so then you try to escape the prophecy, but your very evasive maneuvers make the prophecy come true?  Picture that, except with qubits—and for some reason, in a gleaming golden laboratory that has components that float in midair.</p>



<figure class="wp-block-image"><img alt="Devs Trailer Reveals New Look at FX-Hulu's Upcoming Limited Series" src="https://cdn1-www.comingsoon.net/assets/uploads/2020/01/Screen-Shot-2020-01-09-at-2.52.52-PM.png"/>If you’re never visited a real quantum computing lab: they’re messier and a lot less golden.</figure>



<p>At this point, I’ll just link you to Ben Lindbergh’s article about the show: <a href="https://www.theringer.com/tv/2020/4/10/21216149/devs-hulu-quantum-physics-philosophy-alex-garland">Making Sense of the Science and Philosophy of ‘Devs.’</a>  His long and excellent piece quotes me extensively enough that I see no need <em>also</em> to analyze the show in this blog post.  (It also quotes several academic philosophers.)</p>



<p>Instead, I’ll just share a few tidbits that Ben left out, but that might be amusing to quantum computing fans.</p>



<ul><li>The first episode opens with a conversation between two characters about how even “elliptical curve” cryptography is insecure against attack by quantum computers.  So I immediately knew <em>both</em> that the writers had one or more consultants who actually knew something about QC, and also that those consultants were not as heavily involved as they could’ve been.</li></ul>



<ul><li>Similarly: in a later scene, some employees at the secretive company hold what appears to be a reading group about Shor’s algorithm.  They talk about waves that interfere and cancel each other out, which is great, but beyond that their discussion sounded to me like nonsense.  In particular, their idea seemed to be that the waves would reinforce at the prime factors p and q themselves, rather than at inverse multiples of the period of a periodic function that only indirectly encodes the factoring problem.  (What do you say: should we let this one slide?)</li></ul>



<ul><li>“How many qubits does this thing have?” “A number that there would be no point in describing as a number.”  ROFL</li></ul>



<ul><li>In the show, a crucial break comes when the employees abandon a prediction algorithm based on the deBroglie-Bohm pilot wave interpretation, and substitute one based on Everett’s many-worlds interpretation.  Which I could actually <em>almost</em> believe, except that the many-worlds interpretation seems to contradict the entire premise of the rest of the show?</li></ul>



<ul><li>A new employee, after he sees the code of the superpowerful quantum computer for the first time, is so disoriented and overwhelmed that he runs and vomits into a toilet.  I, too, have had that reaction to the claims of certain quantum computing companies, although in some sense for the opposite reason.</li></ul>



<p>Anyway, none of the above addresses the show’s central conceit: namely, that the <a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">Laplace demon</a> can be made real, the past and future rendered fully knowable (with at most occasional breaks and exceptions) by a machine that’s feasible to build.  This conceit is fascinating to explore, but also <em>false</em>.</p>



<p>In the past, if you’d asked me to justify its falsity, I would’ve talked about chaos, and quantum mechanics, and the unknowability of the fine details of the universe’s state; I might’ve even pointed you to my <a href="https://arxiv.org/abs/1306.0159">Ghost in the Quantum Turing Machine</a> essay.  I also would’ve mentioned the severe conceptual difficulties in forcing Nature to find a fixed-point of a universe where you get to see your own future and act on that information (these difficulties are just a variant of the famous <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">Grandfather Paradox</a>).</p>



<p>But it occurs to me that, just as the coronavirus has now made plain the nature of exponential growth, even to the world’s least abstract-minded person, so too it’s made plain the universe’s unpredictability.  Let’s put it this way: do you find it plausible that the quantum computer from ‘Devs,’ had you booted it up six months ago, would’ve known the exact state of every nucleotide in every virus in every bat in Wuhan?  No?  Then it wouldn’t have known our future.</p>



<p>And I see now that I’ve violated my promise that this post would have nothing to do with covid.</p></div>
    </content>
    <updated>2020-04-15T00:24:30Z</updated>
    <published>2020-04-15T00:24:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-16T03:13:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06690</id>
    <link href="http://arxiv.org/abs/2004.06690" rel="alternate" type="text/html"/>
    <title>Online Graph Exploration on Trees, Unicyclic Graphs and Cactus Graphs</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Robin Fritsch <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06690">PDF</a><br/><b>Abstract: </b>We study the problem of exploring all vertices of an undirected weighted
graph that is initially unknown to the searcher. An edge of the graph is only
revealed when the searcher visits one of its endpoints. Beginning at some start
node, the searcher's goal is to visit every vertex of the graph before
returning to the start node on a tour as short as possible.
</p>
<p>We prove that the Nearest Neighbor algorithm's competitive ratio on trees
with $n$ vertices is $\Theta(\log n)$, i.e. no better than on general graphs.
This also yields a lower bound on the quality of the Nearest Neighbor heuristic
for the traveling salesperson problem on trees. Furthermore, we examine the
algorithm Blocking for a range of parameters not considered previously and
prove it is 3-competitive on unicyclic graphs as well as $5/2+\sqrt{2}\approx
3.91$-competitive on cactus graphs. The best-known lower bound for these two
graph classes is 2.
</p></div>
    </summary>
    <updated>2020-04-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06620</id>
    <link href="http://arxiv.org/abs/2004.06620" rel="alternate" type="text/html"/>
    <title>Dichotomy for Graph Homomorphisms with Complex Values on Bounded Degree Graphs</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Jin=Yi.html">Jin-Yi Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Govorov:Artem.html">Artem Govorov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06620">PDF</a><br/><b>Abstract: </b>The complexity of graph homomorphisms has been a subject of intense study
[11, 12, 4, 42, 21, 17, 6, 20]. The partition function $Z_{\mathbf A}(\cdot)$
of graph homomorphism is defined by a symmetric matrix $\mathbf A$ over
$\mathbb C$. We prove that the complexity dichotomy of [6] extends to bounded
degree graphs. More precisely, we prove that either $G \mapsto Z_{\mathbf
A}(G)$ is computable in polynomial-time for every $G$, or for some $\Delta &gt; 0$
it is #P-hard over (simple) graphs $G$ with maximum degree $\Delta(G) \le
\Delta$. The tractability criterion on $\mathbf A$ for this dichotomy is
explicit, and can be decided in polynomial-time in the size of $\mathbf A$. We
also show that the dichotomy is effective in that either a P-time algorithm
for, or a reduction from #SAT to, $Z_{\mathbf A}(\cdot)$ can be constructed
from $\mathbf A$, in the respective cases.
</p></div>
    </summary>
    <updated>2020-04-15T23:22:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06595</id>
    <link href="http://arxiv.org/abs/2004.06595" rel="alternate" type="text/html"/>
    <title>Counting Small Induced Subgraphs Satisfying Monotone Properties</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmitt:Johannes.html">Johannes Schmitt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellnitz:Philip.html">Philip Wellnitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06595">PDF</a><br/><b>Abstract: </b>Given a graph property $\Phi$, the problem $\#\mathsf{IndSub}(\Phi)$ asks, on
input a graph $G$ and a positive integer $k$, to compute the number of induced
subgraphs of size $k$ in $G$ that satisfy $\Phi$. The search for explicit
criteria on $\Phi$ ensuring that $\#\mathsf{IndSub}(\Phi)$ is hard was
initiated by Jerrum and Meeks [J. Comput. Syst. Sci. 15] and is part of the
major line of research on counting small patterns in graphs. However, apart
from an implicit result due to Curticapean, Dell and Marx [STOC 17] proving
that a full classification into "easy" and "hard" properties is possible and
some partial results on edge-monotone properties due to Meeks [Discret. Appl.
Math. 16] and D\"orfler et al. [MFCS 19], not much is known.
</p>
<p>In this work, we fully answer and explicitly classify the case of monotone,
that is subgraph-closed, properties: We show that for any non-trivial monotone
property $\Phi$, the problem $\#\mathsf{IndSub}(\Phi)$ cannot be solved in time
$f(k)\cdot |V(G)|^{o(k/ {\log^{1/2}(k)})}$ for any function $f$, unless the
Exponential Time Hypothesis fails. By this, we establish that any significant
improvement over the brute-force approach is unlikely; in the language of
parameterized complexity, we also obtain a $\#\mathsf{W}[1]$-completeness
result.
</p></div>
    </summary>
    <updated>2020-04-15T23:20:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06521</id>
    <link href="http://arxiv.org/abs/2004.06521" rel="alternate" type="text/html"/>
    <title>Quantum speedups of some general-purpose numerical optimisation algorithms</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Cezar-Mihail Alexandru, Ella Bridgett-Tomkinson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Linden:Noah.html">Noah Linden</a>, Joseph MacManus, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montanaro:Ashley.html">Ashley Montanaro</a>, Hannah Morris <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06521">PDF</a><br/><b>Abstract: </b>We give quantum speedups of several general-purpose numerical optimisation
methods for minimising a function $f:\mathbb{R}^n \to \mathbb{R}$. First, we
show that many techniques for global optimisation under a Lipschitz constraint
can be accelerated near-quadratically. Second, we show that backtracking line
search, an ingredient in quasi-Newton optimisation algorithms, can be
accelerated up to quadratically. Third, we show that a component of the
Nelder-Mead algorithm can be accelerated by up to a multiplicative factor of
$O(\sqrt{n})$. Fourth, we show that a quantum gradient computation algorithm of
Gily\'en et al. can be used to approximately compute gradients in the framework
of stochastic gradient descent. In each case, our results are based on applying
existing quantum algorithms to accelerate specific components of the classical
algorithms, rather than developing new quantum techniques.
</p></div>
    </summary>
    <updated>2020-04-15T23:20:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06474</id>
    <link href="http://arxiv.org/abs/2004.06474" rel="alternate" type="text/html"/>
    <title>Two halves of a meaningful text are statistically different</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Weibing.html">Weibing Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:R=.html">R. Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:S=.html">S. Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allahverdyan:Armen_E=.html">Armen E. Allahverdyan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06474">PDF</a><br/><b>Abstract: </b>Which statistical features distinguish a meaningful text (possibly written in
an unknown system) from a meaningless set of symbols? Here we answer this
question by comparing features of the first half of a text to its second half.
This comparison can uncover hidden effects, because the halves have the same
values of many parameters (style, genre {\it etc}). We found that the first
half has more different words and more rare words than the second half. Also,
words in the first half are distributed less homogeneously over the text in the
sense of of the difference between the frequency and the inverse spatial
period. These differences hold for the significant majority of several hundred
relatively short texts we studied. The statistical significance is confirmed
via the Wilcoxon test. Differences disappear after random permutation of words
that destroys the linear structure of the text. The differences reveal a
temporal asymmetry in meaningful texts, which is confirmed by showing that
texts are much better compressible in their natural way (i.e. along the
narrative) than in the word-inverted form. We conjecture that these results
connect the semantic organization of a text (defined by the flow of its
narrative) to its statistical features.
</p></div>
    </summary>
    <updated>2020-04-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06455</id>
    <link href="http://arxiv.org/abs/2004.06455" rel="alternate" type="text/html"/>
    <title>Tensor Network Rewriting Strategies for Satisfiability and Counting</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beaudrap:Niel_de.html">Niel de Beaudrap</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kissinger:Aleks.html">Aleks Kissinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meichanetzidis:Konstantinos.html">Konstantinos Meichanetzidis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06455">PDF</a><br/><b>Abstract: </b>We provide a graphical treatment of SAT and \#SAT on equal footing. Instances
of \#SAT can be represented as tensor networks in a standard way. These tensor
networks are interpreted by diagrams of the ZH-calculus: a system to reason
about tensors over $\mathbb{C}$ in terms of diagrams built from simple
generators, in which computation may be carried out by \emph{transformations of
diagrams alone}. In general, nodes of ZH diagrams take parameters over
$\mathbb{C}$ which determine the tensor coefficients; for the standard
representation of \#SAT instances, the coefficients take the value $0$ or $1$.
Then, by choosing the coefficients of a diagram to range over $\mathbb B$, we
represent the corresponding instance of SAT. Thus, by interpreting a diagram
either over the boolean semiring or the complex numbers, we instantiate either
the \emph{decision} or \emph{counting} version of the problem. We find that for
classes known to be in P, such as $2$SAT and \#XORSAT, the existence of
appropriate rewrite rules allows for efficient simplification of the diagram,
producing the solution in polynomial time. In contrast, for classes known to be
NP-complete, such as $3$SAT, or \#P-complete, such as \#$2$SAT, the
corresponding rewrite rules introduce hyperedges to the diagrams, in numbers
which are not easily bounded above by a polynomial. This diagrammatic approach
unifies the diagnosis of the complexity of CSPs and \#CSPs and shows promise in
aiding tensor network contraction-based algorithms.
</p></div>
    </summary>
    <updated>2020-04-15T23:21:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06439</id>
    <link href="http://arxiv.org/abs/2004.06439" rel="alternate" type="text/html"/>
    <title>The quantum query complexity of composition with a relation</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belovs:Aleksandrs.html">Aleksandrs Belovs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Troy.html">Troy Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06439">PDF</a><br/><b>Abstract: </b>The negative weight adversary method, $\mathrm{ADV}^\pm(g)$, is known to
characterize the bounded-error quantum query complexity of any Boolean function
$g$, and also obeys a perfect composition theorem $\mathrm{ADV}^\pm(f \circ
g^n) = \mathrm{ADV}^\pm(f) \mathrm{ADV}^\pm(g)$. Belovs gave a modified version
of the negative weight adversary method, $\mathrm{ADV}_{rel}^\pm(f)$, that
characterizes the bounded-error quantum query complexity of a relation $f
\subseteq \{0,1\}^n \times [K]$, provided the relation is efficiently
verifiable. A relation is efficiently verifiable if $\mathrm{ADV}^\pm(f_a) =
o(\mathrm{ADV}_{rel}^\pm(f))$ for every $a \in [K]$, where $f_a$ is the Boolean
function defined as $f_a(x) = 1$ if and only if $(x,a) \in f$. In this note we
show a perfect composition theorem for the composition of a relation $f$ with a
Boolean function $g$ \[ \mathrm{ADV}_{rel}^\pm(f \circ g^n) =
\mathrm{ADV}_{rel}^\pm(f) \mathrm{ADV}^\pm(g) \enspace . \] For an efficiently
verifiable relation $f$ this means $Q(f \circ g^n) = \Theta(
\mathrm{ADV}_{rel}^\pm(f) \mathrm{ADV}^\pm(g) )$.
</p></div>
    </summary>
    <updated>2020-04-15T23:21:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06436</id>
    <link href="http://arxiv.org/abs/2004.06436" rel="alternate" type="text/html"/>
    <title>Round-Efficient Distributed Byzantine Computation</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hitron:Yael.html">Yael Hitron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06436">PDF</a><br/><b>Abstract: </b>We present the first round efficient algorithms for several fundamental
distributed tasks in the presence of a Byzantine edge. Our algorithms work in
the CONGEST model of distributed computing. In the \emph{Byzantine Broadcast}
problem, given is a network $G=(V,E)$ with an unknown Byzantine edge $e'$.
There is a source node $s$ holding an initial message $m_0$, and the goal is
for all the nodes in the network to receive a copy of $m_0$, while ignoring all
other messages. Perhaps surprisingly, to the best of our knowledge, all
existing algorithms for the problem either assume that the Byzantine behavior
is probabilistic, use polynomially large messages or else suffer from a large
round complexity.
</p>
<p>We give an $\widetilde{O}(D^2)$-round \footnote{The notion $\widetilde{O}$
hides poly-logarithmic terms, and the notion $\widehat{O}$ hides a
multiplicative factor of an $2^{O(\sqrt{\log n})}$ term.} algorithm for the
Byzantine Broadcast problem, where $D$ is the diameter of the graph. The
communication graph is required to be $3$-edge connected, which is known to be
a necessary condition. We also provide a Leader Election algorithm in the
presence of a Byzantine edge with the same round complexity of
$\widetilde{O}(D^2)$ rounds. We use these algorithms to provide the efficient
construction of \emph{Byzantine cycle covers} which serve the basis for (i)
Byzantine BFS algorithms and (ii) a general compiler for algorithms in the
presence of a Byzantine edge.
</p>
<p>We hope that the tools provided in this paper will pave the way towards
obtaining \textbf{round-efficient algorithms} for many more distributed
problems in the presence of Byzantine edges and nodes.
</p></div>
    </summary>
    <updated>2020-04-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06367</id>
    <link href="http://arxiv.org/abs/2004.06367" rel="alternate" type="text/html"/>
    <title>Enumerating Chemical Graphs with Mono-block 2-Augmented Tree Structure from Given Upper and Lower Bounds on Path Frequencies</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yuui Tamura, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishiyama:Yuhei.html">Yuhei Nishiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chenxi.html">Chenxi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yanming.html">Yanming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shurbevski:Aleksandar.html">Aleksandar Shurbevski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagamochi:Hiroshi.html">Hiroshi Nagamochi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06367">PDF</a><br/><b>Abstract: </b>We consider a problem of enumerating chemical graphs from given constraints
concerning their structures, which has an important application to a novel
method for the inverse QSAR/QSPR recently proposed. In this paper, the
structure of a chemical graph is specified by a feature vector each of whose
entries represents the frequency of a prescribed path. We call a graph a
2-augmented tree if it is obtained from a tree (an acyclic graph) by adding
edges between two pairs of nonadjacent vertices. Given a set of feature vectors
as the interval between upper and lower bounds of feature vectors, we design an
efficient algorithm for enumerating chemical 2-augmented trees that satisfy the
path frequency specified by some feature vector in the set. We implemented the
proposed algorithm and conducted some computational experiments.
</p></div>
    </summary>
    <updated>2020-04-15T23:21:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06340</id>
    <link href="http://arxiv.org/abs/2004.06340" rel="alternate" type="text/html"/>
    <title>Hierarchical and Modularly-Minimal Vertex Colorings</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valdivia:Dulce_I=.html">Dulce I. Valdivia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gei=szlig=:Manuela.html">Manuela Geiß</a>, Maribel Hernández Rosales, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stadler:Peter_F=.html">Peter F. Stadler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06340">PDF</a><br/><b>Abstract: </b>Cographs are exactly the hereditarily well-colored graphs, i.e., the graphs
for which a greedy vertex coloring of every induced subgraph uses only the
minimally necessary number of colors $\chi(G)$. We show that greedy colorings
are a special case of the more general hierarchical vertex colorings, which
recently were introduced in phylogenetic combinatorics. Replacing cotrees by
modular decomposition trees generalizes the concept of hierarchical colorings
to arbitrary graphs. We show that every graph has a modularly-minimal coloring
$\sigma$ satisfying $|\sigma(M)|=\chi(M)$ for every strong module $M$ of $G$.
This, in particular, shows that modularly-minimal colorings provide a useful
device to design efficient coloring algorithms for certain hereditary graph
classes. For cographs, the hierarchical colorings coincide with the
modularly-minimal coloring. As a by-product, we obtain a simple linear-time
algorithm to compute a modularly-minimal coloring of $P_4$-sparse graphs.
</p></div>
    </summary>
    <updated>2020-04-15T23:27:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06278</id>
    <link href="http://arxiv.org/abs/2004.06278" rel="alternate" type="text/html"/>
    <title>Squares: A Fast Counter-Based RNG</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Widynski:Bernard.html">Bernard Widynski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06278">PDF</a><br/><b>Abstract: </b>In this article, we present a new counter-based random number generator (RNG)
based on John von Neumann's middle square. We've discovered that only three
rounds of squaring are sufficient to provide satisfactory random data. This
appears to be one of the fastest counter-based RNGs.
</p></div>
    </summary>
    <updated>2020-04-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.06167</id>
    <link href="http://arxiv.org/abs/2004.06167" rel="alternate" type="text/html"/>
    <title>Continuous Credit Networks and Layer 2 Blockchains: Monotonicity and Sampling</title>
    <feedworld_mtime>1586908800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Ashish.html">Ashish Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramseyer:Geoffrey.html">Geoffrey Ramseyer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06167">PDF</a><br/><b>Abstract: </b>To improve transaction rates, many cryptocurrencies have implemented
so-called ''Layer-2'' transaction protocols, where payments are routed across
networks of private payment channels. However, for a given transaction, not
every network state provides a feasible route to perform the payment; in this
case, the transaction must be put on the public ledger. The payment channel
network thus multiplies the transaction rate of the overall system; the less
frequently it fails, the higher the multiplier.
</p>
<p>We build on earlier work on credit networks and show that this network
liquidity problem is connected to the combinatorics of graphical matroids.
Earlier work could only analyze the (unnatural) scenario where transactions had
discrete sizes.
</p>
<p>Superficially, it might seem like the continuous case would be harder to
examine. However, removing this assumption lets us make progress in two
important directions. First, we give a partial answer to the ``monotonicity
conjecture'' that previous work left open. This conjecture asks that the
network's performance not degrade as capacity on any edge increases. And
second, we construct here a network state sampling procedure with much faster
asymptotic performance than off-the-shelf Markov chains ($O(\vert E\vert
\beta(\vert E\vert))$, where $\beta(x)$ is the complexity of solving a linear
program on $x$ constraints.)
</p>
<p>We obtain our results by mapping the underlying graphs to convex bodies and
then showing that the liquidity and sampling problems reduce to bounding and
computing the volumes of these bodies. The transformation relies crucially on
the combinatorial properties of the underlying graphic matroid, as do the
proofs of monotonicity and fast sampling.
</p></div>
    </summary>
    <updated>2020-04-15T23:26:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16931</id>
    <link href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/" rel="alternate" type="text/html"/>
    <title>John Horton Conway 1937–2020</title>
    <summary>An appreciation Names for large numbers source John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope. Today Ken and I thought we would reflect on some of Conway’s many contributions and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>An appreciation</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg"><img alt="" class="alignright wp-image-16933" height="240" src="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg?w=192&amp;h=240" width="192"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Names for large numbers <a href="https://sites.google.com/site/largenumbers/home/2-4/6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope.</p>
<p>
Today Ken and I thought we would reflect on some of Conway’s many contributions and emphasize three in which we see connections to computational complexity. </p>
<p>
Conway was a Fellow of the Royal Society, and was the first recipient of the London Mathematical Society’s Pólya Prize. His nomination to the Royal Society reads:</p>
<blockquote><p><b> </b> <em> A versatile mathematician who combines a deep combinatorial insight with algebraic virtuosity, particularly in the construction and manipulation of “off-beat” algebraic structures which illuminate a wide variety of problems in completely unexpected ways. He has made distinguished contributions to the theory of finite groups, to the theory of knots, to mathematical logic (both set theory and automata theory) and to the theory of games (as also to its practice). </em>
</p></blockquote>
<p>
</p><p/><h2> A Life Force </h2><p/>
<p/><p>
Conway may be most noted for his game of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Life</a>. This is a two-dimensional cellular automaton. Conway invented it in 1970, which he rounded up from 1969. The game—and Martin Gardner’s 1970 column on it in <em>Scientific American</em>—made him famous in the wider community. The website <a href="https://www.conwaylife.com/">conwaylife.com</a> and <a href="https://catagolue.appspot.com/home">several</a> <a href="https://tebs-game-of-life.com/">others</a> link to more information than we could digest in a lifetime.</p>
<p>
We want to emphasize instead how Conway was a special force in mathematics. He applied an almost elementary approach to deep hard problems of mathematics. This is a unique combination. There have been mathematicians who worked on deep problems and also on recreational math, but few who established integral flows across the boundary between them. Conway infused both with magic in a way conveyed by an iconic photograph of his Princeton office in 1993:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg"><img alt="" class="aligncenter wp-image-16934" height="270" src="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg?w=450&amp;h=270" width="450"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Guardian<i> via Dith Pran, <i>NY Times</i> <a href="https://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">source</a> </i></i></font>
</td>
</tr>
</tbody></table>
<p>
What Ken remembers is how accessible Conway was <em>outside</em> his office. “I know I met him at least once while I was an undergraduate at Princeton in 1979 or 1980, though this is overlaid by a memory of finding just him and a few others in the Fine Hall tea room when I was there for my tenth reunion in 1991. My most evocative memory is when Conway gave an evening talk to the undergraduate mathematics club at Oxford when I was there sometime after 1981. It was relatively sparsely attended, perhaps because it was literally a dark and stormy winter night. But after his lecture we all got to huddle around him for another hour in the tea room as he regaled us with stories and mathematical problems.” </p>
<p>
We also remember that Conway was one of Andrew Wiles’s main confidants during the months before Wiles announced his proof of Fermat’s Last Theorem in June 1993. Here is a <a href="https://www.pbs.org/wgbh/nova/transcripts/2414proof.html">transcript</a> of a PBS Nova documentary on the proof in which Conway appears prominently. Ken has picked out two of Conway’s other contributions that we feel may have untapped use for research in complexity theory.</p>
<p>
</p><p/><h2> Conway’s Numbers </h2><p/>
<p/><p>
One of this blog’s “invariants” is first-name last-name style, thus “Godfrey Hardy” not “G.H. Hardy.” But we make an exception in Conway’s case. Partly this owes to how his initials were amplified by Donald Knuth in his novella <em>Surreal Numbers</em>:</p>
<blockquote><p><b> </b> <em> In the beginning, everything was void, and J.H.W.H. Conway began to create numbers. </em>
</p></blockquote>
<p/><p>
Besides the void (that is, <img alt="{\emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset}"/>), the creation uses the idea of a <em>left set</em> <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and a <em>right set</em> <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>. Every number has the form <img alt="{\langle L~|~R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L~|~R \rangle}"/>. The initial number is </p>
<p align="center"><img alt="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. "/></p>
<p>
Once a number is generated, it can be in the <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> or <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> of other numbers. Thus, next come </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Clangle+0+%7E%7C%7E+%5Cemptyset+%5Crangle+%26%3D%26+1%5C%5C+%5Clangle+%5Cemptyset+%7E%7C%7E+0+%5Crangle+%26%3D%26+-1.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} "/></p>
<p>
You might think of <img alt="{\langle 0 ~|~ 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 0 ~|~ 0 \rangle}"/> next, but it violates the invariant </p>
<p align="center"><img alt="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+%5Cell+%5Cin+L%29%28%5Cforall+r+%5Cin+R%29%5Cneg+%28r+%5Cleq+%5Cell%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). "/></p>
<p>which defines an <img alt="{\langle L~|~R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L~|~R \rangle}"/> <em>form</em> to be a <em>number</em>. </p>
<p>
The relation <img alt="{\leq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\leq}"/> is inductively defined for <img alt="{a = \langle L_a ~|~ R_a \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+%5Clangle+L_a+%7E%7C%7E+R_a+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a = \langle L_a ~|~ R_a \rangle}"/> and <img alt="{b = \langle L_b ~|~ R_b \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%3D+%5Clangle+L_b+%7E%7C%7E+R_b+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b = \langle L_b ~|~ R_b \rangle}"/> by </p>
<p align="center"><img alt="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Cleq+b+%5Cquad%5Cequiv%5Cquad+%28%5Cforall+%5Cell_a+%5Cin+L_a%29%28%5Cforall+r_b+%5Cin+R_b%29%5Cneg%28b+%5Cleq+%5Cell_a+%5C%3B%5Clor%5C%3B+r_b+%5Cleq+a%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). "/></p>
<p>
That is, no member of the left-set of <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> “bumps” <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> (in the sense of rowing races) and <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> does not bump any member of the right-set of <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>.  Note that <img alt="{R_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R_a}"/> and <img alt="{L_b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_b}"/> are not involved—they already behave correctly owing to the invariant. The numbers <img alt="{a,b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b}"/> are equal if <img alt="{a \leq b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cleq+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a \leq b}"/> and <img alt="{b \leq a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cleq+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \leq a}"/> both hold. The rule for addition is </p>
<p align="center"><img alt="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%2B+b+%3D+%5Clangle+%28L_a+%5Cboxplus+b%29+%5Ccup+%28a+%5Cboxplus+L_b%29+%7E%7C%7E+%28a+%5Cboxplus+R_b%29+%5Ccup+%28R_a+%5Cboxplus+b%29+%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, "/></p>
<p>
where <img alt="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_a+%5Cboxplus+b+%3D+%5C%7B%5Cell_a+%2B+b%3A+%5Cell_a+%5Cin+L_a%5C%7D+%3D+b+%5Cboxplus+L_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}"/> and so on. The logical rule <img alt="{\emptyset \boxplus a = \emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset+%5Cboxplus+a+%3D+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset \boxplus a = \emptyset}"/> for any <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> makes the definition of addition well-founded. This yields the numerical fact </p>
<p align="center"><img alt="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+0+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%7E%7C%7E+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%5Crangle+%3D+%5Clangle%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. "/></p>
<p>
It is immediate that <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/> is commutative. There is also a rule for multiplication but addition gives us enough to talk about here.</p>
<p>
</p><p/><h2> Redundancy and Simplicity </h2><p/>
<p/><p>
It is straightforward to compute that <img alt="{0 + 1 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%2B+1+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 + 1 = 1}"/> and <img alt="{-1 + 0 = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%2B+0+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 + 0 = -1}"/>. Now consider: </p>
<p align="center"><img alt="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-1+%2B+1+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+1%29+%5Ccup+%28-1+%5Cboxplus+%5C%7B0%5C%7D%29+%7E%7C%7E+%28-1+%5Cboxplus+%5Cemptyset+%29+%5Ccup+%28%5C%7B0%5C%7D+%5Cboxplus+1%29%5Crangle+%3D+%5Clangle+-1+%7E%7C%7E+1%5Crangle.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. "/></p>
<p>This is a legal number. You can check that the relations <img alt="{\langle -1 ~|~ 1\rangle \leq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle -1 ~|~ 1\rangle \leq 0}"/> and <img alt="{0 \leq \langle -1 ~|~ 1\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \leq \langle -1 ~|~ 1\rangle}"/> both hold. Thus—as a number rather than a “form”—the number <img alt="{\langle -1 ~|~ 1\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle -1 ~|~ 1\rangle}"/> equals <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. </p>
<p>
That seems to make sense since <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> is the average of <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, but now compute <img alt="{2 = 1 + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2+%3D+1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2 = 1 + 1}"/> as a formal Conway number and consider <img alt="{c = \langle -1 ~|~ 2\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Clangle+-1+%7E%7C%7E+2%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c = \langle -1 ~|~ 2\rangle}"/>. This also satisfies the relations <img alt="{c \leq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c \leq 0}"/> and <img alt="{0 \leq c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \leq c}"/>, so <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> must likewise equal <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Thus <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> is not some kind of numerical interpolation between <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>. The interpretation that grabbed my imagination as a teenager in 1976 is that:</p>
<blockquote><p><b> </b> <em> <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> equals the <b>simplest</b> number that is between <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R}"/>. </em>
</p></blockquote>
<p/><p>
This is especially evocative in cases like <img alt="{\langle 1 ~|~ \emptyset \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+1+%7E%7C%7E+%5Cemptyset+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 1 ~|~ \emptyset \rangle}"/>, which is what one gets by computing <img alt="{1 + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 + 1}"/>. In general, <img alt="{m+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m+1}"/> is the simplest number between <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{\emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\emptyset}"/>. Conway made this a theorem by giving each number a set-theoretic ordinal for its “time of generation” and proved that <img alt="{\langle L ~|~ R \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle L ~|~ R \rangle}"/> always equals a (the) least-ordinal number <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> such that <img alt="{\ell \leq c \leq r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cleq+c+%5Cleq+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell \leq c \leq r}"/> for every <img alt="{\ell \in L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cin+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell \in L}"/> and <img alt="{r \in R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \in R}"/>. </p>
<p>
Conway’s rules allow <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> and <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> to be infinite sets—any sets of numbers built by the rules of set theory. Then not only do all real numbers emerge at ordinal times, so do infinitesimals and further richness of structure. We should remember that Conway began as a set theorist with a dissertation under Harold Davenport titled <em>Homogeneous ordered sets</em>. All Conway numbers with finite creation times are dyadic rational numbers, which may seem trivial from the standpoint of set theory, but those are akin to binary strings. </p>
<p>
What became magic was how Conway’s rules characterize <em>games</em>. Through games we can also interpret forms like <img alt="{\langle 0 ~|~ 0 \rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\langle 0 ~|~ 0 \rangle}"/> that are not numbers. I did not know about complexity when I purchased Conway’s <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">book</a> <em>On Numbers and Games</em> around 1980, let alone the connections between games and complexity. The book has a lot of depth that might be useful to complexity theory. To quote Peter Sarnak, per this <a href="https://www.ias.edu/ideas/2015/roberts-john-horton-conway">article</a> by Conway’s biographer Siobhan Roberts on Conway’s meeting with Kurt Gödel:</p>
<blockquote><p><b> </b> <em> The surreal numbers will be applied. It’s just a question of how and when. </em>
</p></blockquote>
<p>
</p><p>
</p><p>
</p><p/><h2> Modular Programming </h2><p/>
<p/><p>
Most of us know that the conditional-jump instruction</p>
<p>
<font size="+1"><tt><b><br/>
if (x == 0) goto k<br/>
</b></tt></font></p>
<p/><p><br/>
where <tt><b>k</b></tt> is the label of another instruction, creates a universal programming language when added to the usual programming primitives of assignment, sequencing, and simple arithmetic. Conway was a maven of the “modular-jump”:</p>
<p>
<font size="+1"><tt><b><br/>
if (x == 0 mod m) goto k.<br/>
</b></tt></font></p>
<p/><p><br/>
In complexity theory we know that mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> gates having 0-1 inputs define the idea of <img alt="{\mathsf{ACC}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}}"/> circuits, with <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/> denoting problems solved by families of these circuits having fixed depth and polynomial size. If we don’t insist on fixed depth and unary inputs, we get modular programs. They are more complex than <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/> circuits, but we can learn from what can be done <em>concretely</em> with them.</p>
<p>
Conway created a particular form of modular programs in a language he called <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4808-8_2">FRACTRAN</a>. A program is just a list of positive fractions <img alt="{\frac{a_r}{b_r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Ba_r%7D%7Bb_r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{a_r}{b_r}}"/> in lowest terms. The input is an integer <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> held in a separate register. Each fraction represents the code line</p>
<p/><p align="center"><img alt="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7Bif+%7D+%28n%2Aa_r+%5Cequiv+0+%5Cpmod%7Bb_r%7D%29+%5C%7B+n+%3D+n%5Cfrac%7Ba_r%7D%7Bb_r%7D%3B+%5Ctext%7Bgoto+start%7D+%5C%7D%3B+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; "/></p>
<p>
In other words, each iteration takes the first fraction <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> such that <img alt="{nf}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{nf}"/> is an integer and updates <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to <img alt="{nf}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{nf}"/>; if there is no such fraction then the program exits and outputs <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.</p>
<p>
For example, the following FRACTRAN program given in Wikipedia’s <a href="https://en.wikipedia.org/wiki/FRACTRAN">article</a> implicitly computes integer division: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B91%7D%7B66%7D%2C%7E%5Cfrac%7B11%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B33%7D%2C%7E%5Cfrac%7B85%7D%7B11%7D%2C%7E%5Cfrac%7B57%7D%7B119%7D%2C%7E%5Cfrac%7B17%7D%7B19%7D%2C%7E%5Cfrac%7B11%7D%7B17%7D%2C%7E%5Cfrac%7B1%7D%7B3%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. "/></p>
<p>The notation is unary: The input <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has the form <img alt="{2^n 3^d 11}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En+3%5Ed+11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n 3^d 11}"/> and the ouput is <img alt="{5^q 7^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%5Eq+7%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5^q 7^r}"/> where <img alt="{n = qd + r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+qd+%2B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = qd + r}"/> with remainder <img alt="{r &lt; d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3C+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r &lt; d}"/>. This already hints the fact that FRACTRAN is a universal programming language. Powers of primes serve as memory registers. The following program computes the Hamming weight <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> of the binary expansion of a natural number <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> encoded as <img alt="{2^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^x}"/>, returning the value <img alt="{13^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B13%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{13^k}"/>: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B33%7D%7B20%7D%2C%7E%5Cfrac%7B5%7D%7B11%7D%2C%7E%5Cfrac%7B13%7D%7B10%7D%2C%7E%5Cfrac%7B1%7D%7B5%7D%2C%7E%5Cfrac%7B2%7D%7B3%7D%2C%7E%5Cfrac%7B10%7D%7B7%7D%2C%7E%5Cfrac%7B7%7D%7B2%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. "/></p>
<p>This might help bridge to our notions of <img alt="{\mathsf{ACC}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}}"/>. The Wikipedia article does a good job of de-mystifying the fractions in terms of their actions on the prime-power registers under the unary-style encoding. We wonder what happens when we try to work directly with binary encodings. </p>
<p>
</p><p/><h2> The Collatz Example </h2><p/>
<p/><p>
The famous “<img alt="{3n+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n+1}"/>” problem of Lothar Collatz is a case in point. It iterates the function </p>
<p align="center"><img alt="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T%28n%29+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B3n%2B1%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+odd%7D+%5C%5C+%5Cfrac%7Bn%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+even%7D+%5Cend%7Bcases%7D++&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  "/></p>
<p>The following FRACTRAN program <a href="https://hal.inria.fr/hal-00958971/document">given</a> by Kenneth Monks iterates <img alt="{T(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T(n)}"/> under the unary encoding <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/>: </p>
<p align="center"><img alt="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B1%7D%7B11%7D%2C%7E%5Cfrac%7B136%7D%7B15%7D%2C%7E%5Cfrac%7B5%7D%7B17%7D%2C%7E%5Cfrac%7B4%7D%7B5%7D%2C%7E%5Cfrac%7B26%7D%7B21%7D%2C%7E%5Cfrac%7B7%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B7%7D%2C%7E%5Cfrac%7B33%7D%7B4%7D%2C%7E%5Cfrac%7B5%7D%7B2%7D%2C%7E%5Cfrac%7B7%7D%7B1%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. "/></p>
<p>Note that since the last fraction is an integer the program runs forever. If <img alt="{n = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 1}"/> so that the input is <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, it would go <img alt="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2+%5Crightarrow+5+%5Crightarrow+4+%5Crightarrow+33+%5Crightarrow+3+%5Crightarrow+21+%5Crightarrow+26+%5Crightarrow+14+%5Crightarrow+2+%5Ccdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}"/> and thus cycle, unless we stop it. The powers of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> that appear in its output give the desired sequence. </p>
<p>
More natural to us, however, is the following modular program—which can use binary or any notation:</p>
<p>
<font size="+1"><tt><b><br/>
start: if (n == 1) { halt; }<br/>
if (n == 0 mod 2) { goto div; }<br/>
n = 3*n + 1;<br/>
div: n = n/2;<br/>
goto start;<br/>
</b></tt></font></p>
<p/><p><br/>
One can generalize the Collatz problem to moduli <img alt="{m &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m &gt; 2}"/>. For each <img alt="{k &lt; m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3C+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k &lt; m}"/> we have a linear transformation <img alt="{n \mapsto c_k n + d_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cmapsto+c_k+n+%2B+d_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \mapsto c_k n + d_k}"/> that always gives an integer value when <img alt="{n \equiv k \pmod{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cequiv+k+%5Cpmod%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \equiv k \pmod{m}}"/>. We want to know about the orbits of numbers <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> under this iteration.</p>
<p>
In fact, this is exactly what FRACTRAN does. Take <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> to be the least common multiple of the denominators <img alt="{b_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_r}"/> in a FRACTRAN program <img alt="{[\frac{a_r}{b_r}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cfrac%7Ba_r%7D%7Bb_r%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\frac{a_r}{b_r}]}"/>. Then for each <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> we can list the remainders <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> that are multiples of <img alt="{b_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_r}"/> and we get <img alt="{c_k = \frac{a_r}{\gcd(k,m)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_k+%3D+%5Cfrac%7Ba_r%7D%7B%5Cgcd%28k%2Cm%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_k = \frac{a_r}{\gcd(k,m)}}"/>, with <img alt="{d_k = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_k = 0}"/>. The Turing-universality of FRACTRAN then proves a general theorem Conway stated in 1972:</p>
<blockquote><p><b>Theorem 1</b> <em> Generalized Collatz-type problems for moduli <img alt="{m &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2}"/> are undecidable. </em>
</p></blockquote>
<p/><p>
<a href="https://link.springer.com/chapter/10.1007/978-3-540-72504-6_49">Several</a> <a href="http://julienmalka.me/collatz.pdf">followup</a> <a href="https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Lagarias3-23.pdf">papers</a> have proved stronger and more particular forms of the undecidability. The paper by Monks linked above leverages the unary encoding to show that having <img alt="{d_k = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_k = 0}"/> is essentially without loss of generality for universality; it is titled “<img alt="{3x+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3x%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3x+1}"/> Minus the <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/>.” </p>
<p>
Having digested universality, it is natural to wonder about complexity. Can we use modular programming to achieve stronger connections between number theory and complexity classes—classes above the level of <img alt="{\mathsf{ACC}^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{ACC}^0}"/>, say? One possible mode of connection is exemplified by this <a href="https://www.researchgate.net/publication/220994869_One_Binary_Horn_Clause_is_Enough">paper</a> from STACS 1994, which both Dick and I attended. We wonder whether the kind of connection noted by Terry Tao in his <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">tribute</a> to Conway can also smooth the way to understanding <img alt="{\mathsf{MIP^* = RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{MIP^* = RE}}"/>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Conway posed many open problems himself. Here is a <a href="https://oeis.org/A248380/a248380.pdf">list</a> of five for which he posted cash rewards in the manner of Paul Erdős. The fifth was recently solved. The fourth can be stated in one sentence:</p>
<blockquote><p><b> </b> <em> If a set of points in the plane intersects every convex region of area 1, then must it have pairs of points at arbitrarily small distances? </em>
</p></blockquote>
<p/><p>
Our condolences go out to his family and all who were enthralled by him in the mathematical world. We could talk endlessly about his impact on mathematics education—even about simple things like how to <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=3111964">prove</a> that <img alt="{\sqrt{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{2}}"/> is irrational—or try to tangle with his <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">applications</a> of the “Monster” group to modular forms, but those must be for another time. Also see Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=4732">tribute</a> and its comments section for many more stories and items.</p>
<p/><p><br/>
[some small word and format changes, added link to Scott and may add others as time allows]</p></font></font></div>
    </content>
    <updated>2020-04-14T20:06:27Z</updated>
    <published>2020-04-14T20:06:27Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Teaching"/>
    <category term="Collatz conjecture"/>
    <category term="complexity"/>
    <category term="FRACTRAN"/>
    <category term="in memoriam"/>
    <category term="John Conway"/>
    <category term="Life"/>
    <category term="Logic"/>
    <category term="memorial"/>
    <category term="modular arithmetic"/>
    <category term="Princeton"/>
    <category term="set theory"/>
    <category term="surreal numbers"/>
    <category term="Turing universality"/>
    <category term="undecidability"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-16T20:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=49</id>
    <link href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/" rel="alternate" type="text/html"/>
    <title>A Primer on Private Statistics – Part I</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">By Gautam Kamath and Jonathan Ullman Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a … <a class="more-link" href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">Continue reading<span class="screen-reader-text"> "A Primer on Private Statistics – Part I"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a short series of blog posts, we hope to educate readers on some of the recent advancements in this area, as well as shed light on some of the connections between the old and the new. We’ll describe the settings, cover a couple of technical examples, and give pointers to some other directions in the area. Thanks to <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a> for helping kick off this project, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément Canonne</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, and <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> for helpful comments, and <a href="https://lucatrevisan.github.io/">Luca Trevisan</a> for his <a href="https://lucatrevisan.wordpress.com/latex-to-wordpress/">LaTeX2WP script</a>.</p>
<p><b>1. Introduction </b></p>
<p>Statistics and machine learning are now ubiquitous in data analysis. Given a dataset, one immediately wonders what it allows us to infer about the underlying population. However, modern datasets don’t exist in a vacuum: they often contain sensitive information about the individuals they represent. Without proper care, statistical procedures will result in gross violations of privacy. Motivated by the shortcomings of ad hoc methods for data anonymization, Dwork, McSherry, Nissim, and Smith introduced the celebrated notion of differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>].</p>
<p>From its inception, some of the driving motivations for differential privacy were applications in statistics and the social sciences, notably disclosure limitation for the US Census. And yet, the lion’s share of differential privacy research has taken place within the computer science community. As a result, the specific applications being studied are often not formulated using statistical terminology, or even as statistical problems. Perhaps most significantly, much of the early work in computer science (though definitely not all) focus on estimating some property <em>of a dataset</em> rather than estimating some property <em>of an underlying population</em>.</p>
<p>Although the earliest works exploring the interaction between differential privacy and classical statistics go back to at least 2009 [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>,<a href="https://kamathematics.wordpress.com/feed/#FRY10">FRY10</a>], the emphasis on differentially private statistical inference in the computer science literature is somewhat more recent. However, while earlier results on differential privacy did not always formulate problems in a statistical language, statistical inference was a key motivation for most of this work. As a result many of the techniques that were developed have direct applications in statistics, for example establishing minimax rates for estimation problems.</p>
<p>The purpose of this series of blog posts is to highlight some of those results in the computer science literature, and present them in a more statistical language. Specifically, we will discuss:</p>
<ul>
<li>Tight minimax lower bounds for privately estimating the mean of a multivariate distribution over <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/>, using the technique of <em>tracing attacks</em> developed in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>,<a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>].
<p> </p>
</li>
<li>Upper bounds for estimating a distribution in Kolmogorov distance, using the ubiquitous <em>binary-tree mechanism</em> introduced in [<a href="https://kamathematics.wordpress.com/feed/#DNPR10">DNPR10</a>,<a href="https://kamathematics.wordpress.com/feed/#CSS11">CSS11</a>].</li>
</ul>
<p>In particular, we hope to encourage computer scientists working on differential privacy to pay more attention to the applications of their methods in statistics, and share with statisticians many of the powerful techniques that have been developed in the computer science literature.</p>
<p> </p>
<p><b> 1.1. Formulating Private Statistical Inference </b></p>
<p>Essentially every differentially private statistical estimation task can be phrased using the following setup. We are given a dataset <img alt="{X = (X_1, \dots, X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C+%5Cdots%2C+X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1, \dots, X_n)}"/> of size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, and we wish to design an algorithm <img alt="{M \in \mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \in \mathcal{M}}"/> where <img alt="{\mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}}"/> is the class of mechanisms that are both:</p>
<ol>
<li>differentially private, and</li>
<li>accurate, either in expectation or with high probability, according to some task-specific measure.</li>
</ol>
<p>A few comments about this framework are in order. First, although the accuracy requirement is stochastic in nature (i.e., an algorithm might not be accurate depending on the randomness of the algorithm and the data generation process), the privacy requirement is worst-case in nature. That is, the algorithm must protect privacy for every dataset <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, even those we believe are very unlikely.</p>
<p>Second, the accuracy requirement is stated rather vaguely. This is because the notion of accuracy of an algorithm is slightly more nuanced, depending on whether we are concerned with <em>empirical</em> or <em>population</em> statistics. A particular emphasis of these blog posts is to explore the difference (or, as we will see, the lack of a difference) between these two notions of accuracy. The former estimates a quantity of the observed dataset, while the latter estimates a quantity of an unobserved distribution which is assumed to have generated the dataset.</p>
<p>More precisely, the former can be phrased in terms of empirical loss, of the form:</p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BX+%5Cin+%5Cmathcal%7BX%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_M%28%5Cell%28M%28X%29%2C+f%28X%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), "/></p>
<p>where <img alt="{\mathcal{M}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}}"/> is some class of <em>randomized estimators</em> (e.g., differentially private estimators), <img alt="{\mathcal{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{X}}"/> is some class of <em>datasets</em>, <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is some quantity of interest, and <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> is some <em>loss function</em>. That is, we’re looking to find an estimator that has small expected loss on <em>any dataset</em> in some class.</p>
<p>In contrast, statistical minimax theory looks at statements about population loss, of the form:</p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_%7BX+%5Csim+P%2C+M%7D%28%5Cell%28M%28X%29%2Cf%28P%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), "/></p>
<p>where <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> is some family of <em>distributions</em> over datasets (typically consisting of i.i.d. samples). That is, we’re looking to find an estimator that has small expected loss on random data from <em>any distribution</em> in some class. In particular, note that the randomness in this objective additionally includes the data generating procedure <img alt="{X \sim P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim P}"/>.</p>
<p>These two formulations are formally very different in several ways. First, the empirical formulation requires an estimator to have small loss on <em>worst-case</em> datasets, whereas the statistical formulation only requires the estimator to have small loss <em>on average</em> over datasets drawn from certain distributions. Second, the statistical formulation requires that we estimate the unknown quantity <img alt="{f(P)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(P)}"/>, and thus necessitates a solution to the non-private estimation problem. On the other hand, the empirical formulation only asks us to estimate the known quantity <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>, and thus if there were no privacy constraint it would always be possible to compute <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/> exactly. Third, typically in the statistical formulation, we require that the dataset is drawn i.i.d., which means that we are more constrained when proving lower bounds for estimation than we are in the empirical problem.</p>
<p>However, in practice (more precisely, in the practice of doing theoretical research), these two formulations are more alike than they are different, and results about one formulation often imply results about the other formulation. On the algorithmic side, classical statistical results will often tell us that <img alt="{\ell(f(X),f(P))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(f(X),f(P))}"/> is small, in which case algorithms that guarantee <img alt="{\ell(M(X),f(X))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(M(X),f(X))}"/> is small also guarantee <img alt="{\ell(M(X),f(P))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell(M(X),f(P))}"/> is small.</p>
<p>Moreover, typical lower bound arguments for empirical quantities are often statistical in nature. These typically involving constructing some simple “hard distribution” over datasets such that no private algorithm can estimate well on average for this distribution, and thus these lower bound arguments also apply to estimating population statistics for some simple family of distributions. We will proceed to give some examples of estimation problems that were originally studied by computer scientists with the empirical formulation in mind. These results either implicitly or explicitly provide solutions to the corresponding population versions of the same problems—our goal is to spell out and illustrate these connections.</p>
<p><b>2. DP Background </b></p>
<p>Let <img alt="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2CX_2%2C%5Cdots%2CX_n%29+%5Cin+%5Cmathcal%7BX%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}"/> be a collection of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> samples where each individual sample comes from the domain <img alt="{\mathcal{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{X}}"/>. We say that two samples <img alt="{X,X' \in \mathcal{X}^*}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27+%5Cin+%5Cmathcal%7BX%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,X' \in \mathcal{X}^*}"/> are <em>adjacent</em>, denoted <img alt="{X \sim X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim X'}"/>, if they differ on at most one individual sample. Intuitively, a randomized algorithm <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, which is often called a <em>mechanism</em> for historical reasons, is <em>differentially private</em> if the distribution of <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/> and <img alt="{M(X')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X')}"/> are similar for every pair of adjacent samples <img alt="{X,X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,X'}"/>.</p>
<blockquote>
<p><b>Definition 1 ([<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> A mechanism <img alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}"/> is <em><img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private</em> if for every pair of adjacent datasets <img alt="{X \sim X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X \sim X'}"/>, and every (measurable) <img alt="{R \subseteq R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR+%5Csubseteq+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R \subseteq R}"/> </em></p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%29+%5Cin+R%29+%5Cleq+e%5E%7B%5Cepsilon%7D+%5Ccdot+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%27%29+%5Cin+R%29+%2B+%5Cdelta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. "/></p>
<p> </p>
</blockquote>
<p>We let <img alt="{\mathcal{M}_{\epsilon,\delta}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{M}_{\epsilon,\delta}}"/> denote the set of mechanisms that satisfy <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy.</p>
<blockquote>
<p><b>Remark 1</b> <em> To simplify notation, and to maintain consistency with the literature, we adopt the convention of defining the mechanism only for a fixed sample size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. What this means in practice is that the mechanisms we describe treat the sample size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is <em>public information</em> that need not be kept private. While one could define a more general model where <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is not fixed, it wouldn’t add anything to this discussion other than additional complexity. </em></p>
</blockquote>
<blockquote>
<p><b>Remark 2</b> <em> In these blog posts, we stick to the most general formulation of differential privacy, so-called <em>approximate differential privacy</em>, i.e. <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy for <img alt="{\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &gt; 0}"/> essentially because this is the notion that captures the widest variety of private mechanisms. Almost all of what follows would apply equally well, with minor technical modifications, to slightly stricter notions of <em>concentrated differential privacy [</em><a href="https://kamathematics.wordpress.com/feed/#DR16">DR16</a>, <a href="https://kamathematics.wordpress.com/feed/#BS16">BS16</a>, <a href="https://kamathematics.wordpress.com/feed/#BDRS18">BDRS18</a>], Rényi differential privacy [<a href="https://kamathematics.wordpress.com/feed/#Mir17">Mir17</a>], or <em>Gaussian differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DRS19">DRS19</a>]</em>. While so-called <em>pure differential privacy</em>, i.e. <img alt="{(\epsilon,0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,0)}"/>-differential privacy has also been studied extensively, this notion is artificially restrictive and excludes many differentially private mechanisms. </em></p>
</blockquote>
<p>A key property of differential privacy that helps when desinging efficient estimators is <em>closure under postprocessing</em>:</p>
<blockquote>
<p><b>Lemma 2 (Post-Processing [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> <a name="lempost-processing"/> If <img alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}"/> is <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private and <img alt="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccolon+%5Cmathcal%7BR%7D+%5Crightarrow+%5Cmathcal%7BR%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}"/> is any randomized algorithm, then <img alt="{M' \circ M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccirc+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M' \circ M}"/> is <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private. </em></p>
</blockquote>
<p>The estimators we present in this work will use only one tool for achieving differential privacy, the <em>Gaussian Mechanism</em>.</p>
<blockquote>
<p><b>Lemma 3 (Gaussian Mechanism)</b> <em> <a name="lemgauss-mech"/> Let <img alt="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}"/> be a function and let </em></p>
<p align="center"><img alt="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CDelta_%7Bf%7D+%3D+%5Csup_%7BX%5Csim+X%27%7D+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 "/></p>
<p>denote its <em><img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-sensitivity</em>. The <em>Gaussian mechanism</em></p>
<p align="center"><img alt="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X%29+%3D+f%28X%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280+%2C+%5Cfrac%7B2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2%7D+%5Ccdot+%5CDelta_%7Bf%7D%5E2+%5Ccdot+%7B%5Cmathbb+I%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) "/></p>
<p><em> satisfies <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy. </em></p>
</blockquote>
<p><b>3. Mean Estimation in <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/> </b></p>
<p>Let’s take a dive into the problem of <em>private mean estimation</em> for some family <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> of multivariate distributions over <img alt="{{\mathbb R}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^d}"/>. This problem has been studied for various families <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> and various choices of loss function. Here we focus on perhaps the simplest variant of the problem, in which <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> contains distributions of bounded support <img alt="{[\pm 1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\pm 1]^d}"/> and the loss is the <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> error. We emphasize, however, that the methods we discuss here are quite versatile and can be used to derive minimax bounds for other variants of the mean-estimation problem.</p>
<p>Note that, by a simple argument, the non-private minimax rate for this class is achieved by the empirical mean, and is</p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)"/></p>
<p>The main goal of this section is to derive the minimax bound <a name="eqRd-minimax"/></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Ctilde%5CTheta%5Cleft%28%5Cfrac%7Bd%5E2%7D%7B%5Cepsilon%5E2+n%5E2%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)"/></p>
<p><a name="eqRd-minimax"/> Recall that <img alt="{\tilde \Theta(f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+%5CTheta%28f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde \Theta(f(n))}"/> refers to a function which is both <img alt="{O(f(n) \log^{c_1} f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28f%28n%29+%5Clog%5E%7Bc_1%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(f(n) \log^{c_1} f(n))}"/> and <img alt="{\Omega(f(n) \log^{c_2} f(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28f%28n%29+%5Clog%5E%7Bc_2%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Omega(f(n) \log^{c_2} f(n))}"/> for some constants <img alt="{c_1, c_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C+c_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1, c_2}"/>. The proof of this lower bound is based on <em>robust tracing attacks</em>, also called <em>membership inference attacks</em>, which were developed in a chain of papers [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. We remark that this lower bound is almost identical to the minimax bound for mean estimation proven in the much more recent work of Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>], but it lacks tight dependence on the parameter <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, which we discuss in the following remark.</p>
<blockquote>
<p><b>Remark 3</b> <em> The choice of <img alt="{\delta = 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3D+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta = 1/n}"/> in <a href="https://kamathematics.wordpress.com/feed/#eqRd-minimax">(2)</a> may look strange at first. For the upper bound this choice is arbitrary—as we will see, we can upper bound the rate for any <img alt="{\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &gt; 0}"/> at a cost of a factor of <img alt="{O(\log(1/\delta))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%281%2F%5Cdelta%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log(1/\delta))}"/>. The lower bound applies only when <img alt="{\delta \leq 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cleq+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \leq 1/n}"/>. Note that the rate is qualitatively different when <img alt="{\delta \gg 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \gg 1/n}"/>. However, we emphasize that <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy is not a meaningful privacy notion unless <img alt="{\delta \ll 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \ll 1/n}"/>. In particular, the mechanism that randomly outputs <img alt="{\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta n}"/> elements of the sample satisfies <img alt="{(0,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,\delta)}"/>-differential privacy. However, when <img alt="{\delta \gg 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \gg 1/n}"/>, this mechanism completely violates the privacy of <img alt="{\gg 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gg 1}"/> person in the dataset. Moreover, taking the empirical mean of these <img alt="{\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta n}"/> samples gives rate <img alt="{d/\delta n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%2F%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d/\delta n}"/>, which would violate our lower bound when <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> is large enough. On the other hand, we would expect the minimax rate to become slower when <img alt="{\delta \ll 1/n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta \ll 1/n}"/>. This expectation is, in fact, correct, however the proof we present does not give the tight dependence on the parameter <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>. See [<a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>] for a refinement that can obtain the right dependence on <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, and [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] for the details of how to apply this refinement in the i.i.d. setting. </em></p>
</blockquote>
<p><b> 3.1. A Simple Upper Bound </b></p>
<blockquote>
<p><b>Theorem 4</b> <em> For every <img alt="{n \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \in {\mathbb N}}"/>, and every <img alt="{\epsilon,\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon,\delta &gt; 0}"/>, there exists an <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private private mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> such that <a name="eqmean-est-ub"/></em></p>
<p><em><em><a name="eqmean-est-ub"/></em></em></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%5Cleq+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)"/></p>
<p><em><a name="eqmean-est-ub"/></em></p>
<p><em><a name="eqmean-est-ub"/> </em></p>
</blockquote>
<p><em>Proof:</em> Define the mechanism</p>
<p align="center"><img alt="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Coverline%7BX%7D+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)"/></p>
<p>This mechanism satisfies <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differential privacy by Lemma <a href="https://kamathematics.wordpress.com/feed/#lemgauss-mech">3</a>, noting that for any pair of adjacent samples <img alt="{X_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n}}"/> and <img alt="{X'_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'_{1 \cdots n}}"/>, <img alt="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%5Coverline%7BX%7D+-+%5Coverline%7BX%7D%27%5C%7C_2%5E2+%5Cleq+%5Cfrac%7Bd%7D%7Bn%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}"/>.</p>
<p>Let <img alt="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%5E2+%3D+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}"/>. Note that since the Gaussian noise has mean <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and is independent of <img alt="{\overline{X} - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7BX%7D+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\overline{X} - \mu}"/>, we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu+%5C%7C_2%5E2%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%5Cleq%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D%29+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Csigma%5E2+d+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} "/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p> </p>
<p><b> 3.2. Minimax Lower Bounds via Tracing </b></p>
<blockquote>
<p><b>Theorem 5</b> <em> <a name="thmmean-lb"/> For every <img alt="{n, d \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2C+d+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n, d \in {\mathbb N}}"/>, <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/>, and <img alt="{\delta &lt; 1/96n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3C+1%2F96n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta &lt; 1/96n}"/>, if <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> is the class of all product distributions on <img alt="{\{\pm 1\}^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{\pm 1\}^{d}}"/>, then for some constant <img alt="{C &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C &gt; 0}"/>, </em></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%2CM%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5COmega%5Cleft%28%5Cmin+%5Cleft%5C%7B+%5Cfrac%7Bd%5E2%7D%7B+%5Cepsilon%5E2+n%5E2%7D%2C+d+%5Cright%5C%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). "/></p>
<p> </p>
</blockquote>
<p>Note that it is trivial to achieve error <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> for any distribution using the mechanism <img alt="{M(X_{1 \cdots n}) \equiv 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%5Cequiv+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{1 \cdots n}) \equiv 0}"/>, so the result says that the error must be <img alt="{\Omega(d^2/\epsilon^2 n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28d%5E2%2F%5Cepsilon%5E2+n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Omega(d^2/\epsilon^2 n^2)}"/> whenever this error is significantly smaller than the trivial error of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>.</p>
<p><b>Tracing Attacks.</b></p>
<p>Before giving the formal proof, we will try to give some intuition for the high-level proof strategy. The proof can be viewed as constructing a <em>tracing attack </em>[<a href="https://kamathematics.wordpress.com/feed/#DSSU17">DSSU17</a>] (sometimes called a <em>membership inference attack</em>) of the following form. There is an attacker who has the data of some individual <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> chosen in one of the two ways: either <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a random element of the sample <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, or <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is an independent random sample from the population <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/>. The attacker is given access to the true distribution <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> and the outcome of the mechanism <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/>, and wants to determine which of the two is the case. If the attacker can succeed, then <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> cannot be differentially private. To understand why this is the case, if <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a member of the dataset, then the attacker should say <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is in the dataset, but if we consider the adjacent dataset <img alt="{X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'}"/> where we replace <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> with some independent sample from <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/>, then the attacker will now say <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is independent of the dataset. Thus, <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/> and <img alt="{M(X')}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X')}"/> cannot be close in the sense required by differential privacy.</p>
<p>Thus, the proof works by constructing a test statistic <img alt="{Z = Z(M(X),Y,P),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ+%3D+Z%28M%28X%29%2CY%2CP%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z = Z(M(X),Y,P),}"/> that the attacker can use to distinguish the two possibilities for <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. In particular, we show that there is a distribution over populations <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> such that <img alt="{\mathop{\mathbb E}(Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z)}"/> is small when <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is independent of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, but for <em>every</em> sufficiently accurate mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>, <img alt="{\mathop{\mathbb E}(Z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z)}"/> is large when <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> is a random element of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>.</p>
<p><b>Proof of Theorem <a href="https://kamathematics.wordpress.com/feed/#thmmean-lb">5</a>.</b></p>
<p>We start by constructing a “hard distribution” over the family of product distributions <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/>. Let <img alt="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%3D+%28%5Cmu%5E1%2C%5Cdots%2C%5Cmu%5Ed%29+%5Cin+%5B-1%2C1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}"/> consist of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> independent draws from the uniform distribution on <img alt="{[-1,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[-1,1]}"/> and let <img alt="{P_{\mu}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_{\mu}}"/> be the product distribution over <img alt="{\{\pm 1\}^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{\pm 1\}^{d}}"/> with mean <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>. Let <img alt="{X_1,\dots,X_n \sim P_{\mu}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Csim+P_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_1,\dots,X_n \sim P_{\mu}}"/> and <img alt="{X = (X_1,\dots,X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X = (X_1,\dots,X_n)}"/>.</p>
<p>Let <img alt="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5E%7Bn+%5Ctimes+d%7D+%5Crightarrow+%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}"/> be any <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private mechanism and let</p>
<p align="center"><img alt="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5C%7C+M%28X%29+-+%5Cmu%5C%7C_2%5E2+%29+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)"/></p>
<p>be its expected loss. We will prove the desired lower bound on <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/>.</p>
<p>For every element <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, we define the random variables</p>
<p align="center"><img alt="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+Z_i+%3D+Z_i%28M%28X%29%2CX_i%2C%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle+%5C%5C+Z%27_%7Bi%7D+%3D+Z%27_i%28M%28X_%7B%5Csim+i%7D%29%2C+X_i%2C+%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, "/></p>
<p>where <img alt="{X_{\sim i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B%5Csim+i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{\sim i}}"/> denotes <img alt="{(X_1,\dots,X'_i,\dots,X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X_1%2C%5Cdots%2CX%27_i%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X_1,\dots,X'_i,\dots,X_n)}"/> where <img alt="{X'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'_i}"/> is an independent sample from <img alt="{P_\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_\mu}"/>. Our goal will be to show that, privacy and accuracy imply both upper and lower bounds on <img alt="{\mathop{\mathbb E}(\sum_i Z_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_i+Z_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_i Z_i)}"/> that depend on <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>, and thereby obtain a bound on <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/>.</p>
<p>The first claim says that, when <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/> is <em>not</em> in the sample, then the likelihood random variable has mean <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and variance controlled by the expected <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> error of the mechanism.</p>
<blockquote>
<p><b>Claim 1</b> <em> <a name="clmmean-lb-1"/> For every <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{\mathop{\mathbb E}(Z'_i) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(Z'_i) = 0}"/>, <img alt="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}"/>, and <img alt="{\|Z'_i\|_\infty \leq 4d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CZ%27_i%5C%7C_%5Cinfty+%5Cleq+4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|Z'_i\|_\infty \leq 4d}"/>. </em></p>
</blockquote>
<p><em>Proof:</em> Conditioned on any value of <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>, <img alt="{M(X_{\sim i})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{\sim i})}"/> is independent from <img alt="{X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i}"/>. Moreover, <img alt="{\mathop{\mathbb E}(X_i - \mu) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28X_i+-+%5Cmu%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(X_i - \mu) = 0}"/>, so we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28X_i+-+%5Cmu%29+%5Cright+%5Crangle+%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+0+%5Cright+%5Crangle+%29+%5C%5C+%3D+%260.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} "/></p>
<p>For the second part of the claim, since <img alt="{(X_i - \mu)^2 \leq 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X_i+-+%5Cmu%29%5E2+%5Cleq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X_i - \mu)^2 \leq 4}"/>, we have <img alt="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4+%5Ccdot+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}"/>. The final part of the claim follows from the fact that every entry of <img alt="{M(X_{\sim i}) - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{\sim i}) - \mu}"/> and <img alt="{X_i - \mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_i - \mu}"/> is bounded by <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in absolute value, and <img alt="{Z'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_i}"/> is a sum of <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> such entries, so its absolute value is always at most <img alt="{4d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{4d}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>The next claim says that, because <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> is differentially private, <img alt="{Z_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_i}"/> has similar expectation to <img alt="{Z'_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_i}"/>, and thus its expectation is also small.</p>
<blockquote>
<p><b>Claim 2</b> <em><a name="clmmean-lb-2"/> <img alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}"/> </em></p>
</blockquote>
<p><em>Proof:</em> The proof is a direct calculation using the following inequality, whose proof is relatively simple using the definition of differential privacy:</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%2B+2%5Cepsilon+%5Csqrt%7B%5Cmathrm%7BVar%7D%28Z%27_i%29%7D+%2B+2%5Cdelta+%5C%7C+Z%27_i+%5C%7C_%5Cinfty.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. "/></p>
<p>Given the inequality and Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-1">1</a>, we have</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+0+%2B+%282%5Cepsilon%29%282%5Calpha%29+%2B+%282%5Cdelta%29%282d%29+%3D+4%5Cepsilon+%5Calpha+%2B+8+%5Cdelta+d+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . "/></p>
<p>The claim now follows by summing over all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>The final claim says that, because <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> is accurate, the expected sum of the random variables <img alt="{Z_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_i}"/> is large.</p>
<blockquote>
<p><b>Claim 3</b> <em> <a name="clmmean-lb-3"/> <img alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cgeq+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}"/> </em></p>
</blockquote>
<p>The proof relies on the following key lemma, whose proof we omit.</p>
<blockquote>
<p><b>Lemma 6 (Fingerprinting Lemma [<a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>])</b><em> <a name="lemfp"/> If <img alt="{\mu \in [\pm 1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%5Cin+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu \in [\pm 1]}"/> is sampled uniformly, <img alt="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Cin+%5C%7B%5Cpm+1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_1,\dots,X_n \in \{\pm 1\}^{n}}"/> are sampled independently with mean <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>, and <img alt="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5En+%5Crightarrow+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}"/> is any function, then </em></p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i+-+%5Cmu%29%29+%5Cgeq+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29%5E2%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). "/></p>
<p> </p>
</blockquote>
<p>The lemma is somewhat technical, but for intuition, consider the case where <img alt="{f(X) = \frac{1}{n}\sum_{i} X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%7D+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X) = \frac{1}{n}\sum_{i} X_i}"/> is the empirical mean. In this case we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%28X_i+-+%5Cmu%29%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cfrac%7B1%7D%7Bn%7D+%5Csum_i+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%7D%28+%28X_i+-+%5Cmu%29%5E2%29+%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathrm%7BVar%7D%28X_i%29%29+%3D+%5Cfrac%7B1%7D%7B3%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} "/></p>
<p>The lemma says that, when <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/> is sampled this way, then any modification of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that reduces the correlation between <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/> and <img alt="{\sum_i X_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_i X_i}"/> will increase the mean-squared-error of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> proportionally.</p>
<p>We now prove Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a>.</p>
<p><em>Proof:</em> We can apply the lemma to each coordinate of the estimate <img alt="{M(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X)}"/>.</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%29+%5C%5C+%3D%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i%5Ej+-+%5Cmu%5Ej%29%29+%5C%5C+%5Cgeq%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cleft%28+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5E2%29+%5Cright%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} "/></p>
<p>The inequality is Lemma <a href="https://kamathematics.wordpress.com/feed/#lemfp">6</a>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>Combining Claims <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-2">2</a> and <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a> gives</p>
<p align="center"><img alt="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)"/></p>
<p>Now, if <img alt="{\alpha^2 \geq \frac{d}{6}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \geq \frac{d}{6}}"/> then we’re done, so we’ll assume that <img alt="{\alpha^2 \leq \frac{d}{6}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cleq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \leq \frac{d}{6}}"/>. Further, by our assumption on the value of <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, <img alt="{8n \delta d \leq \frac{d}{12}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8n+%5Cdelta+d+%5Cleq+%5Cfrac%7Bd%7D%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8n \delta d \leq \frac{d}{12}}"/>. In this case we can rearrange terms and square both sides to obtain</p>
<p align="center"><img alt="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%5Cgeq%7B%7D+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+-+8+n%5Cdelta+d%5Cright%29%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B12%7D%5Cright%29%5E2+%3D+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)"/></p>
<p>Combining the two cases for <img alt="{\alpha^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2}"/> gives <img alt="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cmin%5C%7B+%5Cfrac%7Bd%7D%7B6%7D%2C+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}"/>, as desired.</p>
<p><b>Bibliography</b></p>
<p>[BDRS18]<a name="BDRS18"/> Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated CDP. STOC ’18.</p>
<p>[BS16]<a name="BS16"/> Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. TCC ’16-B.</p>
<p>[BSU17]<a name="BSU17"/> Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p>[BUV14]<a name="BUV14"/> Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p>[CSS11]<a name="CSS11"/> T-H Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 14(3):26, 2011.</p>
<p>[CWZ19]<a name="CWZ19"/> T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p>[DMNS06]<a name="DMNS06"/> Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p>[DNPR10]<a name="DNPR10"/> Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. STOC ’10.</p>
<p>[DR16]<a name="DR16"/> Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv, 1603.01887, 2016.</p>
<p>[DRS19]<a name="DRS19"/> Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. arXiv, 1905.02383, 2019.</p>
<p>[DSSU17]<a name="DSSU17"/> Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p>[DSSUV15]<a name="DSSUV15"/> Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a survey of attacks on private data. Annual Review of Statistics and Its Application, 4:61–84, 2017.</p>
<p>[FRY10]<a name="FRY10"/> Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. PSD ’10.</p>
<p>[KLSU19]<a name="KLSU19"/> Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p>[Mir17]<a name="Mir17"/> Ilya Mironov. Rényi differential privacy. CSF ’17.</p>
<p>[SU17a]<a name="SU17a"/> Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p>[SU17b]<a name="SU17b"/> Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p>[VS09]<a name="VS09"/> Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>


<p/></div>
    </content>
    <updated>2020-04-14T14:23:37Z</updated>
    <published>2020-04-14T14:23:37Z</published>
    <category term="Technical"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-04-16T20:22:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-612436836431644422</id>
    <link href="https://blog.computationalcomplexity.org/feeds/612436836431644422/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/john-conway-dies-of-coronvirus.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/612436836431644422" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/612436836431644422" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/john-conway-dies-of-coronvirus.html" rel="alternate" type="text/html"/>
    <title>John Conway Dies of Coronvirus</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">John Conway passed away on April 11, 2020 of the Coronovirus. He is the first person I knew (for some definition of `know') who has died of it. I suspect this is true of many readers of this blog.<br/>
(Fellow bloggers Scott Aaronson and Terry Tao have already posted about John Conway,<br/>
<a href="https://www.scottaaronson.com/blog/">here</a> and <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">here</a>. I suspect there will be others and when they do I will add it here.<br/>
ADDED LATER: nice xkcd <a href="https://xkcd.com/2293/">here</a><br/>
<br/>
John Conway is a great example of how the line between recreational math and serious math is .... non-existent? not important? Take our pick.<br/>
<br/>
Examples<br/>
<br/>
1) Conway invented Surreal Numbers. These can be used to express infinitely big and infinitely small numbers. One can even make sense of things like square root of infinity.  Conway's book is called On Numbers and Games (see <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">here</a> and <a href="https://www.amazon.com/Numbers-Games-John-H-Conway/dp/1568811276">here</a>) Two free sources: <a href="https://thatsmaths.com/2012/11/22/the-root-of-infinity-its-surreal/">here</a> and <a href="https://www.whitman.edu/Documents/Academics/Mathematics/Grimm.pdf">here</a>.<br/>
<br/>
<div>
Note that Conway defined surreals in terms of games. Are they fun games? Probably not, but they are games!</div>
<div>
<br/></div>
<div>
2)  Conway's Game of Life (you really do need to use his name, note the contrast between <i>The game</i> <i>of life <a href="https://en.wikipedia.org/wiki/The_Game_of_Life">here</a> </i>and <i>Conway's Game of Life <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">here</a></i></div>
<div>
<i><br/></i></div>
<div>
<div>
The game is simple (and this one IS fun). You begin with some set of dots placed at lattice points, and a set of rules to tell how they live, die, or reproduce.  The rules are always the same. Different initial patterns form all kinds of patterns.  Sounds fun! Is it easy to tell, given pattern P1 and P2 whether, starting with P1 you can get to P2. No. Its undecidable.</div>
<div>
<br/></div>
<div>
So this simple fun game leads to very complicated patterns.</div>
<div>
<br/></div>
<div>
And nice to have an undecidable problem that does not mention Turing Machines. (I will tell the students it is undecidable this semester, though I won't be proving it.)</div>
<div>
<br/></div>
<div>
3)  Berlekamp, Conway, and Guy wrote <i>Winning Ways for your Mathematical Plays  </i>See <a href="https://en.wikipedia.org/wiki/Winning_Ways_for_your_Mathematical_Plays">here</a> and <a href="http://www.amazon.com/Winning-Ways-Your-Mathematical-Plays/dp/1568811446">here</a></div>
</div>
<div>
<br/></div>
<div>
This is the ultimate book on NIM games.</div>
<div>
<br/></div>
<div>
4) The above is probably what the readers of this blog are familiar with; however, according to his Wikipedia page (see <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">here</a>) he worked in Combinatorial Game Theory, Geometry, Geometric Topology, Group Theory, Number Theory, Algebra, Analysis, Algorithmics and Theoretical Physics.</div>
<div>
<br/></div>
<div>
He will be missed.</div></div>
    </content>
    <updated>2020-04-13T02:21:00Z</updated>
    <published>2020-04-13T02:21:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-16T14:35:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4732</id>
    <link href="https://www.scottaaronson.com/blog/?p=4732" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4732#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4732" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">John Horton Conway (1937-2020)</title>
    <summary xml:lang="en-US">Update (4/13): Check out the comments on this post for some wonderful firsthand Conway stories. Or for the finest tribute I’ve seen so far, see a MathOverflow thread entitled Conway’s lesser known results. Virtually everything there is a gem to be enjoyed by amateurs and experts alike. And if you actually click through to any […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (4/13):</span></strong> Check out the comments on this post for some wonderful firsthand Conway stories.  Or for the finest tribute I’ve seen so far, see a MathOverflow thread entitled <a href="https://mathoverflow.net/questions/357197/conways-lesser-known-results">Conway’s lesser known results</a>.  Virtually everything there is a gem to be enjoyed by amateurs and experts alike.  And if you actually click through to any of Conway’s papers … oh my god, what a rebuke to the way most of us write papers!</p>



<p><a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Horton Conway</a>, one of the great mathematicians and math communicators of the past half-century, has died at age 82.</p>



<blockquote class="wp-block-quote"><p><strong><span class="has-inline-color has-vivid-red-color">Update:</span></strong> John’s widow, Diana Conway, left a <a href="https://www.scottaaronson.com/blog/?p=4732#comment-1836789">nice note</a> in the comments section of this post.  I wish to express my condolences to her and to all of the Conway children and grandchildren.</p></blockquote>



<p>Just a week ago, as part of her quarantine homeschooling, I introduced my seven-year-old daughter Lily to the famous <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a>.  Compared to the other stuff we’ve been doing, like fractions and right triangles and the distributive property of multiplication, the Game of Life was a <em>huge</em> hit: Lily spent a full hour glued to the screen, watching the patterns evolve, trying to guess when they’d finally die out.  So this first-grader knew who John Conway was, when I told her the sad news of his passing.</p>



<p>“Did he die from the coronavirus?” Lily immediately asked.</p>



<p>“I doubt it, but I’ll check,” I said.</p>



<p>Apparently it <em>was</em> the coronavirus.  Yes, the self-replicating snippet of math that’s now terrorizing the whole human race, in part because those in power couldn’t or wouldn’t understand exponential growth.  Conway is perhaps the nasty bugger’s most distinguished casualty so far.</p>



<p>I regrettably never knew Conway, although I did attend a few of his wildly popular and entertaining lectures.  His <a href="https://www.amazon.com/Book-Numbers-John-H-Conway/dp/038797993X">The Book of Numbers</a> (coauthored with Richard Guy, who himself recently passed away at age 103) made a huge impression on me as a teenager.  I worked through every page, gasping at gems like e<sup>π√163</sup> (“no, you can’t be serious…”), embarrassed to be learning so much from a “fun, popular” book but grateful that my ignorance of such basic matters was finally being remedied.</p>



<p>A little like Pascal with his triangle or Möbius with his strip, Conway was fated to become best-known to the public not for his deepest ideas but for his most accessible—although for Conway, a principal puzzle-supplier to Martin Gardner for decades, the boundary between the serious and the recreational may have been more blurred than for any other contemporary mathematician.  Conway invented the <a href="https://en.wikipedia.org/wiki/Surreal_number">surreal number system</a>, discovered three of the 26 <a href="https://en.wikipedia.org/wiki/Sporadic_group">sporadic simple groups</a>, was instrumental in the discovery of <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">monstrous moonshine</a>, and did many other things that bloggers more qualified than I will explain in the coming days.</p>



<p>Closest to my wheelhouse, Conway together with Simon Kochen waded into the foundations of quantum mechanics in 2006, with their <a href="https://en.wikipedia.org/wiki/Free_will_theorem">“Free Will Theorem”</a>—a result Conway liked to summarize provocatively as “if human experimenters have free will, then so do the elementary particles they measure.”  I confess that I wasn’t a fan at the time—partly because Conway and Kochen’s theorem was really about “freshly-generated randomness,” rather than free will in any sense related to agency, but also partly because I’d already known the conceptual point at issue, but had considered it folklore (see, e.g., my <a href="https://arxiv.org/abs/quant-ph/0206089">2002 review</a> of Stephen Wolfram’s <em>A New Kind of Science</em>).  Over time, though, the “Free Will Theorem” packaging grew on me.  Much like with the <a href="https://en.wikipedia.org/wiki/No-cloning_theorem">No-Cloning Theorem</a> and other simple enormities, sometimes it’s worth making a bit of folklore so memorable and compelling that it will never be folklore again.</p>



<p>At a lecture of Conway’s that I attended, someone challenged him that his proposed classification of knots worked only in special cases.  “Oh, of course, this only classifies 0% of knots—but 0% is a start!” he immediately replied, to roars from the audience.  That’s just one line that I remember, but nearly everything out of his mouth was of a similar flavor.  I noted that part of it was in the delivery.</p>



<p>As a mathematical jokester and puzzler who could delight and educate anyone from a Fields Medalist to a first-grader, Conway had no equal.  For no one else who I can think of, even going back centuries and millennia, were entertainment and mathematical depth so closely marbled together.  Here’s to a well-lived Life.</p>



<p>Feel free to share your own Conway memories in the comments.</p></div>
    </content>
    <updated>2020-04-12T07:22:23Z</updated>
    <published>2020-04-12T07:22:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-16T03:13:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=43</id>
    <link href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/" rel="alternate" type="text/html"/>
    <title>Friday, April 17 — Shachar Lovett from UC San Diego</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Shachar Lovett from UC San Diego will speak about “The power of asking more informative questions about the data”. Abstract: Many supervised learning algorithms (such as<a class="more-link" href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/">Continue reading <span class="screen-reader-text">"Friday, April 17 — Shachar Lovett from UC San Diego"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Shachar Lovett</strong> from UC San Diego will speak about “<em>The power of asking more informative questions about the data</em>”.</p>



<p><strong>Abstract</strong>: Many supervised learning algorithms (such as deep learning) need a large collection of labelled data points in order to perform well. However, what is easy to get are large amounts of unlabelled data. Labeling data is an expensive procedure, as it usually needs to be done manually, often by a domain expert. Active learning provides a mechanism to bridge this gap. Active learning algorithms are given a large collection of unlabelled data points. They need to smartly choose a few data points to query their label. The goal is then to automatically infer the labels of many other data points.</p>



<p>In this talk, we will explore the option of giving active learning algorithms additional power, by allowing them to have richer interaction with the data. We will see how allowing for even simple types of queries, such as comparing two data points, can exponentially improve the number of queries needed in various settings. Along the way, we will see interesting connections to both geometry and combinatorics, and a surprising application to fine grained complexity.</p>



<p>Based on joint works with Daniel Kane, Shay Moran and Jiapeng Zhang.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>
    </content>
    <updated>2020-04-11T20:52:09Z</updated>
    <published>2020-04-11T20:52:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-04-16T20:22:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16921</id>
    <link href="https://rjlipton.wordpress.com/2020/04/10/nina-balcan-wins/" rel="alternate" type="text/html"/>
    <title>Nina Balcan Wins</title>
    <summary>Congrats and More [ CMU ] Nina Balcan is a leading researcher in the theory of machine learning. Nina is at Carnegie-Mellon and was previously at Georgia Tech—it was a major loss to have her leave Tech. Today we applaud her winning the ACM Hopper Award. ACM President Cherri Pancake says: Although she is still […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Congrats and More</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/10/nina-balcan-wins/unknown-137/" rel="attachment wp-att-16924"><img alt="" class="alignright  wp-image-16924" src="https://rjlipton.files.wordpress.com/2020/04/unknown.jpeg?w=170" width="170"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ CMU ]</font></td>
</tr>
</tbody>
</table>
<p>
Nina Balcan is a leading researcher in the theory of machine learning. Nina is at Carnegie-Mellon and was previously at Georgia Tech—it was a major loss to have her leave Tech.</p>
<p>
Today we applaud her winning the ACM Hopper Award.<br/>
<span id="more-16921"/></p>
<p>
ACM President Cherri Pancake <a href="https://www.ml.cmu.edu/news/news-archive/2020/april/machine-learning-professor-balcan-receives-acm-grace-hopper-award.html">says</a>: </p>
<blockquote><p><b> </b> <em> Although she is still in the early stages of her career, she has already established herself as the world leader in the theory of how AI systems can learn with limited supervision. More broadly, her work has realigned the foundations of machine learning, and consequently ushered in many new applications that have brought about leapfrog advances in this exciting area of artificial intelligence. </em>
</p></blockquote>
<p>
</p><p/><h2> The Hopper Award </h2><p/>
<p/><p>
The ACM Grace Murray Hopper <a href="https://awards.acm.org/hopper/award-winners">Award</a> is given to: An outstanding young computer professional, on the basis of a single major contribution before the age of 35. Here are five of the most recent winners: </p>
<ul>
<li>
Constantinos Daskalakis, 	(<a href="https://awards.acm.org/award_winners/daskalakis_4121823">2018</a>)	 <p/>
</li><li>
Michael Freedman, 		(<a href="https://awards.acm.org/award_winners/freedman_6665293">2018</a>)	 <p/>
</li><li>
Amanda Randles, 		(<a href="https://awards.acm.org/award_winners/randles_0365390">2017</a>)	 <p/>
</li><li>
Jeffrey Heer, 			(<a href="https://awards.acm.org/award_winners/heer_1520709">2016</a>)	 <p/>
</li><li>
Brent Waters,			(<a href="https://awards.acm.org/award_winners/waters_3058089.cfm">2015</a>)
</li></ul>
<p>
</p><p/><h2> Nina’s Contribution </h2><p/>
<p/><p>
The Hopper award says it is for a “single” major contribution. I believe that Nina is almost a disproof of this statement: I fail to see how she only did one major contribution. In fact, the <a href="https://awards.acm.org/hopper">citation</a> lists three. In any event I thought we might look at one of her top results on learning. It is a <a href="http://www.cs.cmu.edu/~ninamf/papers/agnostic-active.pdf">paper</a> from 2006 with over 400 citations. The ttile is “Agnostic Active Learning” and is joint with Alina Beygelzimer and John Langford.</p>
<p>
<em>Active learning</em> follows a classic idea in computer theory: Making a protocol interactive can often decrease the cost, and almost always makes the protocol more complex to understand. In active learning one is given unlabeled examples. As usual the goal is to classify the samples. However, as the samples are unlabelled, the learning can ask for labels for elected samples—this is the active part of the learning. As you might imagine asking for labels has a cost, so the learner strives to ask for the fewest labels possible. </p>
<p>
The savings can be large when the labels are perfect—that is, noise-free. In general it is much more complex to understand when active learning helps. Nina’s work found examples where noise can be tamed. Her award citation says:</p>
<blockquote><p><b> </b> <em> Balcan established performance guarantees for active learning that hold even in challenging cases when “noise” is present in the data. These guarantees hold under arbitrary forms of noise, that is, anything that distorts or corrupts the data. This can include anything from a blurry photo, a unit of data that is improperly labeled, meaningless information, or data that the algorithm cannot interpret. </em>
</p></blockquote>
<p/><p>
See her papers for the details. </p>
<p>
</p><p/><h2> Other Awards </h2><p/>
<p/><p>
There are various awards for computer scientists, many are from the ACM. Since Alan Perlis won the first Turing award, there have been 69 more winners. Only three have been women:</p>
<ul>
<li>
Shafi Goldwasser, (2012) <p/>
</li><li>
Barbara Liskov, (2008) <p/>
</li><li>
Frances Allen, (2006)
</li></ul>
<p>Here is another quote from the president of the ACM: </p>
<blockquote><p><b> </b> <em> We typically receive one woman nominee [for the Turing Award] every five years. It’s very disturbing. </em>
</p></blockquote>
<p/><p>
The number of nominations is too small. There are plenty of strong women candidates for the Turing award, and for other awards. We need to do a better job. See <a href="https://slate.com/technology/2020/01/turing-award-acm-women-recipients.html">this</a> for more thoughts on this issue.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We do not know about the situation with nominations for the Hopper Award. Nina is only the seventh woman to win since 1971, but four of the last ten Hopper Award winners have been women. How can we recognize more women under 35 who are doing great work?</p>
<p>
Again we congratulate Nina Balcan on her richly deserved honor. </p>
<p>[Fixed typo “Congrats” ]</p></font></font></div>
    </content>
    <updated>2020-04-10T13:05:57Z</updated>
    <published>2020-04-10T13:05:57Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="active"/>
    <category term="interactive"/>
    <category term="learning"/>
    <category term="Nina Balcan"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-16T20:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7686</id>
    <link href="https://windowsontheory.org/2020/04/09/experts-shmexperts/" rel="alternate" type="text/html"/>
    <title>Experts shmexperts</title>
    <summary>(If you’re not already following him, I highly recommend reading Luca Trevisan’s dispatches from Milan, much more interesting than what I write below.) On the topic of my last post, Ross Douthat writes in the New York Times that “In the fog of coronavirus, there are no experts”, even citing Scott Aaronson’s post. Both Aaronson […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(If you’re not already following him, I highly recommend reading <a href="https://lucatrevisan.wordpress.com/">Luca Trevisan’s dispatches from Milan</a>, much more interesting than what I write below.)</em></p>



<p>On the topic of my <a href="https://windowsontheory.org/2020/04/04/in-defense-of-expertise/">last post</a>, Ross Douthat writes in the New York Times that <a href="https://www.nytimes.com/2020/04/07/opinion/coronavirus-science-experts.html?smid=fb-share&amp;fbclid=IwAR1KIcMblvNsaKaAQTh2vCpB2yARYL8O5TVy9j3ZxSqsXsRAMK2GGcvF81o">“In the fog of coronavirus, there are no experts”</a>, even citing <a href="https://www.scottaaronson.com/blog/?p=4695">Scott Aaronson’s post</a>. Both Aaronson and Douthat make the point that the COVID-19 crisis is so surprising and unprecedented, and experts were so much in the dark, that there is no reason to trust them over non expert “common sense” or “armchair epidemiologists”. <br/><br/>It’s true that the “expert models” have significant uncertainty, hardwired constants, noisy data, and dubious assumptions. It is also true that many countries (especially those that didn’t learn from the 2003 SARS epidemic) bungled their initial response. But do we really need to challenge the notion of expertise itself? To what extent was this pandemic not predicted by experts or progressed in ways defying their expectations?</p>



<p>Here is what some of these experts and institutions were saying in the recent past:</p>



<p><em>“The thing I’m most concerned about … is the emergence of a new virus that the body doesn’t have any background experience with, that is very transmissible, highly transmissible from person to person, and has a high degree of morbidity and mortality … a respiratory illness that can spread even before someone is so sick that you want to keep them in bed.”</em>  <a href="https://fivethirtyeight.com/features/dr-fauci-has-been-dreading-a-pandemic-like-covid-19-for-years/">Dr. Anthoni Fauci, 2019</a>.</p>



<p><em>“High-impact respiratory pathogens … pose particular global risks … [they] are spread via respiratory droplets; they can infect a large number of people very quickly and with today’s transportation infrastructure, move rapidly across multiple geographies. … There is insufficient R&amp;D investment and planning for innovative vaccine development and manufacture, broad-spectrum antivirals, … In addition, such a pandemic requires advance planning across multiple sectors … Epidemic control costs would completely overwhelm the current financing arrangements for emergency response.” </em><a href="https://apps.who.int/gpmb/assets/annual_report/GPMB_annualreport_2019.pdf">WHO world at risk report</a>, 2019.</p>



<p><em>“respiratory transmission …. is the transmission route posing the greatest pandemic risk   … [since it] can occur with coughing or simply breathing (in aerosol transmission), making containment much more challenging. …  If a pathogen is capable of causing asymptomatic or mildly symptomatic infections that either do not or only minimally interrupt activities of daily living, many individuals may be exposed. Viruses that cause the common cold, including coronaviruses, have this attribute.”</em> <a href="https://apps.who.int/gpmb/assets/thematic_papers/tr-6.pdf">JHU report</a>, 2019.</p>



<p>As an experiment, I also tried to compare the response of experts and “contrarians” in real time as the novel coronavirus was discovered, trying to see if it’s really the case that, as Douthat says, <em>“up until mid-March you were better off trusting the alarmists of anonymous Twitter than the official pronouncements from the custodians of public health”</em>.  I chose both experts and contrarians that are active on Twitter. I was initially planning to look at several people but due to laziness am just taking Imperial college’s <a href="https://twitter.com/Imperial_JIDEA/">J-IDEA institute</a> for the expert, and <a href="https://twitter.com/robinhanson">Robin Hanson</a> for the contrarian.  I also looked at <a href="https://twitter.com/DouthatNYT">Douthat’s twitter feed</a>, to see if he followed his own advice. Initially I thought I would go all the way to March but have no time so just looked at the period from January 1 till February 14th. I leave any conclusions to the reader.</p>



<h2><strong>January 1-19:</strong> </h2>



<p>(Context: novel coronavirus confirmed in Wuhan, initially unclear if there is human to human transmission – this was confirmed by China on January 20 though suspected before.)</p>



<p>Here is one of the many tweets by Imperial from this period:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Substantial human to human transmission cannot be ruled out – size of novel <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> in Wuhan outbreak likely over 1700 cases. <a href="https://twitter.com/MailOnline?ref_src=twsrc%5Etfw">@MailOnline</a> on <a href="https://twitter.com/MRC_Outbreak?ref_src=twsrc%5Etfw">@MRC_Outbreak</a>, <a href="https://twitter.com/Imperial_JIDEA?ref_src=twsrc%5Etfw">@Imperial_JIDEA</a>, <a href="https://twitter.com/imperialcollege?ref_src=twsrc%5Etfw">@imperialcollege</a> report today.<a href="https://t.co/Iq4hBmx4JL">https://t.co/Iq4hBmx4JL</a> <a href="https://t.co/3n5OMPYNdL">pic.twitter.com/3n5OMPYNdL</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1218295967683874816?ref_src=twsrc%5Etfw">January 17, 2020</a></blockquote></div>
</div></figure>



<p>I didn’t see any tweets from Hanson or Douthat on this topic.</p>



<h2><strong>January 20-31:</strong> </h2>



<p>(Context: first confirmed cases in several countries, including the US, WHO declares emergency in Jan 30, US restricts travel from China on Jan 31. By then there are about 10K confirmed cases and 213 deaths worldwide.)</p>



<p>On January 25th Imperial college estimated the novel coronavirus “R0” parameter as 2.6:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">UPDATE: Transmissibility estimates of <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> <a href="https://twitter.com/hashtag/2019nCoV?src=hash&amp;ref_src=twsrc%5Etfw">#2019nCoV</a> at 2.6<br/><br/>Identification &amp; testing potential cases to be as extensive as permitted by healthcare &amp; testing capacity<br/><br/><img alt="&#x1F530;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f530.png" style="height: 1em;"/><a href="https://t.co/7zpZzG2JOs">https://t.co/7zpZzG2JOs</a><a href="https://twitter.com/neil_ferguson?ref_src=twsrc%5Etfw">@neil_ferguson</a> <a href="https://twitter.com/dr_anne_cori?ref_src=twsrc%5Etfw">@dr_anne_cori</a> <a href="https://twitter.com/SRileyIDD?ref_src=twsrc%5Etfw">@SRileyIDD</a> <a href="https://twitter.com/MarcBaguelin?ref_src=twsrc%5Etfw">@MarcBaguelin</a> <a href="https://twitter.com/IlariaDorigatti?ref_src=twsrc%5Etfw">@IlariaDorigatti</a> <a href="https://t.co/nmhjWsWpfa">pic.twitter.com/nmhjWsWpfa</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1221033477824532480?ref_src=twsrc%5Etfw">January 25, 2020</a></blockquote></div>
</div></figure>



<p>Hanson tweeted approvingly about China’s response and that this situation might help the “more authoritarian” U.S. presidential candidate:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Seems to me the "parasite stress hypothesis of authoritarianism" suggests that if this China Coronavirus ends up being a big deal, that would push US voters toward the more authoritarian presidential candidate. Which one is that?<a href="https://t.co/cWmV2WkroJ">https://t.co/cWmV2WkroJ</a><a href="https://t.co/ysNiZIkfYD">https://t.co/ysNiZIkfYD</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1222184281050697728?ref_src=twsrc%5Etfw">January 28, 2020</a></blockquote></div>
</div></figure>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">I doubt we in US would be as fast to restrict travel in the face of such a still-small pandemic. If so, China is to be praised for their better abilities to coordinate in the face of such threats.<a href="https://t.co/Lro5kGVTvz">https://t.co/Lro5kGVTvz</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1220704857922985984?ref_src=twsrc%5Etfw">January 24, 2020</a></blockquote></div>
</div></figure>



<p>Still no tweet from Douthat on this topic though he did say in January 29th that compared to issues in the past the U.S.’s problems in the 2020’s are “problem of decadence” rather than any crisis like the late 1970’s:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Belated, yes, America's problems in '20 are problems of decadence rather than late-1970s crisis, and economically '16 might have been a better year to gamble on Bernie …<a href="https://t.co/3DaHWXC1k0">https://t.co/3DaHWXC1k0</a></p>— Ross Douthat (@DouthatNYT) <a href="https://twitter.com/DouthatNYT/status/1222566830642024448?ref_src=twsrc%5Etfw">January 29, 2020</a></blockquote></div>
</div></figure>



<h2><strong>February 1-14: </strong></h2>



<p>(Context: Diamond princess cruise ship quaranteed, disease gets COVID-19 official name, first death in Europe)</p>



<p>Imperial continues to tweet extensively, including the following early estimates of the case fatality rates:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">UPDATE: <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> <a href="https://twitter.com/hashtag/2019nCoV?src=hash&amp;ref_src=twsrc%5Etfw">#2019nCoV</a> Severity<br/><br/><img alt="&#x27A1;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" style="height: 1em;"/>Estimated fatality ratio for infections 1%<br/><img alt="&#x27A1;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" style="height: 1em;"/>Estimated CFR for travellers outside mainland China (mix severe &amp; milder cases) 1%-5%<br/><img alt="&#x27A1;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" style="height: 1em;"/>Estimated CFR for detected cases in Hubei (severe cases) 18%<br/><br/><img alt="&#x1F530;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f530.png" style="height: 1em;"/><a href="https://t.co/7zpZzG2JOs">https://t.co/7zpZzG2JOs</a> <a href="https://t.co/gtmzq1vOhq">pic.twitter.com/gtmzq1vOhq</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1226766907396718597?ref_src=twsrc%5Etfw">February 10, 2020</a></blockquote></div>
</div></figure>



<p>Robin Hanson correctly realizes this is going to spread wide:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Look at this table and tell me is isn't all over China now, beyond recall: <a href="https://t.co/Ne9UgDlx9G">pic.twitter.com/Ne9UgDlx9G</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1227701511469387777?ref_src=twsrc%5Etfw">February 12, 2020</a></blockquote></div>
</div></figure>



<p>Hanson tweets quite a lot about this, including potential social implications. Up to February 13th there is nothing too “contrarian” at this point, but also no information that could not be gotten from the experts:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">My poll so far estimates ~40% chance that <a href="https://twitter.com/hashtag/COVID19?src=hash&amp;ref_src=twsrc%5Etfw">#COVID19</a> infects large % of world. So seems worth it for social scientists to ask themselves: using social sci, what non-obvious predictions can we make about social outcomes in that case?</p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1227656071021334528?ref_src=twsrc%5Etfw">February 12, 2020</a></blockquote></div>
</div></figure>



<p>In February 14 Hansons makes a very contrarian position when he proposes “controlled infection” as a solution:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">Though it is a disturbing &amp; extreme option, we should seriously consider deliberately infecting folks with coronavirus, to spread out the number of critically ill people over time, and to ensure that critical infrastructure remains available to help sick. <a href="https://t.co/giIfo8z8v0">https://t.co/giIfo8z8v0</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1228400896507367424?ref_src=twsrc%5Etfw">February 14, 2020</a></blockquote></div>
</div></figure>



<p>To the anticipated “you first” objection he responds <em>“I proposed compensating volunteers via cash or medical priority for associates, &amp; I’d seriously consider such offers.”</em>.  He doesn’t mention that he is much less strapped for cash than some of the would be “volunteers”. </p>



<p>Still no tweet from Douthat about COVID-19 though he does write that we live in an “age of decadence”:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p dir="ltr" lang="en">My Sunday essay excerpts my new book: The Age of Decadence: <a href="https://t.co/3cvLqNVQpv">https://t.co/3cvLqNVQpv</a></p>— Ross Douthat (@DouthatNYT) <a href="https://twitter.com/DouthatNYT/status/1225908487198330880?ref_src=twsrc%5Etfw">February 7, 2020</a></blockquote></div>
</div></figure>



<p/></div>
    </content>
    <updated>2020-04-09T19:40:32Z</updated>
    <published>2020-04-09T19:40:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-16T20:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4361</id>
    <link href="https://lucatrevisan.wordpress.com/2020/04/09/the-peak-the-plateau-and-the-phase-two/" rel="alternate" type="text/html"/>
    <title>The peak, the plateau, and the phase two</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">What has been happening in Italy in the last few days, and what can other Western countries expect in the next week or two? The national discourse has been obsessed with “The Peak,” that is, the time when things reach … <a href="https://lucatrevisan.wordpress.com/2020/04/09/the-peak-the-plateau-and-the-phase-two/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>What has been happening in Italy in the last few days, and what can other Western countries expect in the next week or two?</p>
<p>The national discourse has been obsessed with “The Peak,” that is, the time when things reach their worst point, and start improving after that. For the last several days, all indicators, such as new cases, deaths, and ICU occupancy, have been improving. Apparently, then,  “The Peak” is behind us. Virologists have been cautious to say that “peak” is the wrong mountain metaphor to use, and that we have rather reached a “plateau” in which things will change very slowly for a while. </p>
<p>Below is the number of confirmed covid-19 deaths in Italy updated with today’s data, showing that we reached the plateau a couple of weeks ago, meaning that the number of new cases started to plateau about a month ago, when the lockdown started.</p>
<p><img alt="italy-deaths" class="alignnone size-full wp-image-4365" src="https://lucatrevisan.files.wordpress.com/2020/04/italy-deaths.png?w=584"/></p>
<p>The data from New York City continues to track the data from Lombardy, so NYC should be just a few days away from its own plateau, if the match continues.</p>
<p><img alt="lombardy-nyc" class="alignnone size-full wp-image-4366" src="https://lucatrevisan.files.wordpress.com/2020/04/lombardy-nyc.png?w=584"/></p>
<p><img alt="lombardy-nyc-daily" class="alignnone size-full wp-image-4367" src="https://lucatrevisan.files.wordpress.com/2020/04/lombardy-nyc-daily.png?w=584"/></p>
<p>Given all this, people have been wondering when and how we will get out of the lockdown, and reach what everybody has been calling the “Phase Two” of this emergency.</p>
<p><span id="more-4361"/></p>
<p>The lockdown is set to expire this coming Monday, and it is expected that tomorrow or Saturday the prime minister will announce new measures. (Perhaps, according to precedent, he will do so on Sunday night.) It is expected that the stay-at-home order will be extended to early May, or even mid-May, but that the definition of “essential activities” will be relaxed to allow some manufacturing to restart sooner.</p>
<p>Meanwhile, an infrastructure to isolate new cases and trace their contacts, which should have been frantically under construction over the last month, is still non-existent. Last week, the government nominated a committee of 70+ experts to “begin thinking about mapping out possibilities” for what such an infrastructure might be like.</p>
<p>To be honest, I am not too confident that the “Phase Two” will be organized with Taiwanese, or even Korean, efficiency, and my only hope is that the number of cases in Lombardy has been so under-reported that we may already be close to herd immunity.</p>
<p>This is probably not the case, but not by a wide margin. The Italian Institute of Statistics has released 2019 vs 2020 all-cause mortality data from a representative sample of Italian towns. Apparently, during the worst days of March, all-cause mortality roughly doubled nation-wide, while the reported deaths caused by covid-19 account for only about half of the excess deaths. This might mean that there have been 20,000 covid-19 deaths and maybe 2 million infected people out of 10 million in Lombardy. A study of the Imperial College estimates, at the high end, that 6 million Italians have been infected, and since Lombardy’s  data has consistently accounted for half the national data on all measures, it would mean 3 million infected people in Lombardy, or 30%, which is within a factor of two of what might suffice for herd immunity. In any case we will not know until there is a randomized serologic study, which is something else for which experts are almost ready to begin mapping out ways of thinking about how to explore plans for … </p>
<p>What will life be like in “Phase Two”? If the epidemic continues at a slow burn, will we have to continue to keep a one-meter distance from strangers? Will trains and planes run with only every third seat occupied? Will tickets cost three times as much? Will beaches be open during the summer? Will there be riots if Italians are not allowed to go to the beach in August? Apart from the last question, whose answer is obviously yes, everything is up in the air.</p>
<p>What about me, after 32 days of lockdown? I was already in need of a haircut at the end of February, and lately the hair situation had become untenable, so I used my beard trimmer to blindly cut my hair. Mistakes were made, but I would not even rate it among my top ten worst haircuts ever. </p></div>
    </content>
    <updated>2020-04-09T16:55:15Z</updated>
    <published>2020-04-09T16:55:15Z</published>
    <category term="Milan"/>
    <category term="covid-19"/>
    <category term="exploring possibilities for thinking about roadmaps"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-04-16T20:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/044</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/044" rel="alternate" type="text/html"/>
    <title>TR20-044 |  Cryptography from Information Loss | 

	Marshall Ball, 

	Elette Boyle, 

	Akshay Degwekar, 

	Apoorvaa Deshpande, 

	Alon Rosen, 

	Vinod Vaikuntanathan, 

	Prashant Vasudevan</title>
    <summary>Reductions between problems, the mainstay of theoretical computer science, efficiently map an instance of one problem to an instance of another in such a way that solving the latter allows solving the former. The subject of this work is ``lossy'' reductions, where the reduction loses some information about the input instance. We show that such reductions, when they exist, have interesting and powerful consequences for lifting hardness into ``useful'' hardness, namely cryptography.

Our first, conceptual, contribution is a definition of lossy reductions in the language of mutual information. Roughly speaking, our definition says that a reduction $C$ is $t$-lossy if, for any distribution $X$ over its inputs, the mutual information $I(X;C(X)) \leq t$. Our treatment generalizes a variety of seemingly related but distinct notions such as worst-case to average-case reductions, randomized encodings (Ishai and Kushilevitz, FOCS 2000), homomorphic computations (Gentry, STOC 2009), and instance compression (Harnik and Naor, FOCS 2006).

We then proceed to show several consequences of lossy reductions:

1. We say that a language $L$ has an $f$-reduction to a language $L'$ for a Boolean function $f$ if there is a (randomized) polynomial-time algorithm $C$ that takes an $m$-tuple of strings $X = (x_1,\ldots,x_m)$, with each $x_i\in\{0,1\}^n$, and outputs a string $z$ such that with high probability, L'(z) = f(L(x_1),L(x_2),...,L(x_m))
        
2. Suppose a language $L$ has an $f$-reduction $C$ to $L'$ that is $t$-lossy. Our first result is that one-way functions exist if $L$ is worst-case hard and one of the following conditions holds:
   - $f$ is the OR function, $t \leq m/100$, and $L'$ is the same as $L$
   - $f$ is the Majority function, and $t \leq m/100$
   - $f$ is the OR function, $t \leq O(m\log{n})$, and the reduction has no error

This improves on the implications that follow from combining (Drucker, FOCS 2012) with (Ostrovsky and Wigderson, ISTCS 1993) that result in auxiliary-input one-way functions.

3. Our second result is about the stronger notion of $t$-compressing $f$-reductions -- reductions that only output $t$ bits. We show that if there is an average-case hard language $L$ that has a $t$-compressing Majority reduction to some language for $t=m/100$, then there exist collision-resistant hash functions.

This improves on the result of (Harnik and Naor, STOC 2006), whose starting point is a cryptographic primitive (namely, one-way functions) rather than average-case hardness, and whose assumption is a compressing OR-reduction of SAT (which is now known to be false unless the polynomial hierarchy collapses).

Along the way, we define a non-standard one-sided notion of average-case hardness, which is the notion of hardness used in the second result above, that may be of independent interest.</summary>
    <updated>2020-04-08T07:58:37Z</updated>
    <published>2020-04-08T07:58:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-16T20:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4719</id>
    <link href="https://www.scottaaronson.com/blog/?p=4719" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4719#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4719" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">When events make craziness sane</title>
    <summary xml:lang="en-US">This post is simply to say the following (and thereby to make it common knowledge that I said it, and that I no longer give a shit who thinks less of me for saying it): If the pandemic has radicalized you, I won’t think that makes you crazy. It’s radicalized me, noticeably shifted my worldview. […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is simply to say the following (and thereby to make it common knowledge that I said it, and that I no longer give a shit who thinks less of me for saying it):</p>



<p>If the pandemic has radicalized you, I won’t think that makes you crazy.  It’s radicalized me, noticeably shifted my worldview.  And in some sense, I no more apologize for that, than I apologize for my worldview presumably differing from what it would’ve been in some parallel universe with no WWII.</p>



<p>If you suspect that all those earnest, well-intentioned plans and slogans about “flattening the curve” are wonderful and essential, but still, <em>“flattening” is only a desperate gambit to buy some time and nothing more</em>; still, flattening or no flattening, the fundamentals of the situation are that either</p>



<p>(1) a vaccine or cure gets discovered and deployed, or else</p>



<p>(2) we continue in quasi-lockdown mode for the rest of our lives, or else</p>



<p>(3) the virus spreads to the point where it definitely kills some people you know,</p>



<p>—if you suspect this, then at least in my book you’re not crazy.  I suspect the same.</p>



<p>If you still don’t understand, no matter how patiently it’s explained to you, why ~18 months is the <em>absolute bare minimum</em> needed to get a vaccine out; if all the talk of Phase 1, 2, and 3 trials and the need to learn more about rare side effects and so forth seems hard to square with the desperate world war that this is; if you wonder whether the Allied commanders and Allied medical authorities in WWII, transported to the present, would <em>agree</em> that 18 months is the bare minimum, or whether they’d already be distributing vaccines a month ago that probably work well enough and do bounded damage if they don’t—I hereby confess that I don’t understand it either.</p>



<p>If you wonder how the US will possibly hold an election in November that the world won’t rightly consider a sham—given that the only safe way will be universal vote-by-mail, but Trump and his five Vichy justices will never allow it—know that I wonder this too.</p>



<p>If you think that all those psychiatrists now doing tele-psychiatry should tell their patients, “listen, I’ve been noticing an unhealthy absence of panic attacks, obsessions about the government trying to kill your family, or compulsive disinfecting of doorknobs, so I think we’d better up your dose of pro-anxiety medication”—I’m with you.</p>



<p>If you see any US state that wants to avoid &gt;2% deaths, being pushed to the brink of openly defying the FDA, smuggling in medical supplies to escape federal confiscation, using illegal tests and illegal masks and illegal ventilators and illegal everything else, and you also see military commanders getting fired for going outside the chain of command to protect their soldiers’ lives, and you wonder whether this is the start of some broader dissolution of the Union—well, <em>I</em> don’t intend to repeat the mistake of underestimating this crisis.</p>



<p>If you think that the feds who <em>literally confiscate medical supplies before they can reach the hospitals</em>, might as well just shoot the patients as they’re wheeled into the ICU and say “we’re sorry, but this action was obligatory under directive 48c(7)”—I won’t judge you for feeling that way. </p>



<p>If you feel like, while there are still pockets of brilliance and kindness and inspiration and even heroism all over US territory, still, as a federal entity the United States <em>effectively no longer exists or functions</em>, at least not if you treat “try to stop the mass death of the population” as a nonnegotiable component of the “life, liberty, and happiness” foundation for the nation’s existence—if you think this, I won’t call you crazy.  I feel more like a citizen of nowhere every day.</p>



<p>If you’d jump, should the opportunity arise (as it won’t), to appoint Bill Gates as temporary sovereign for as long as this crisis lasts, and thereafter hold a new Constitutional Convention to design a stronger democracy, attempting the first-ever Version 2.0 (as opposed to 1.3, 1.4, etc.) of the American founders’ vision, this time with <em>even more</em> safeguards against destruction by know-nothings and demagogues—if you’re in for that, I don’t think you’re crazy.  I’m wondering where to sign up.</p>



<p>Finally, if you’re one of the people who constantly emails me wrong P=NP proofs or local hidden-variable explanations of quantum mechanics … sorry, I still think you’re crazy.  That stuff hasn’t been affected.</p>



<p>Happy Passover and Easter!</p></div>
    </content>
    <updated>2020-04-08T02:58:26Z</updated>
    <published>2020-04-08T02:58:26Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Embarrassing Myself"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-16T03:13:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3470</id>
    <link href="https://agtb.wordpress.com/2020/04/07/call-for-papers-the-2nd-workshop-on-behavioral-economics-and-computation/" rel="alternate" type="text/html"/>
    <title>Call for Papers: The 2nd Workshop on Behavioral Economics and Computation</title>
    <summary>We solicit research contributions and participants for the 2nd Workshop on Behavioral Economics and Computation, to be held in conjunction with the Twenty-First ACM Conference on Economics and Computation (ACM EC '20).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><span><a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br/>
July 17, 2020, Budapest, Hungary<br/>
At the 21st ACM Conference on Economics and Computation (ACM EC ’20)</span></div>
<div><span>**In the event the in-person conference does not happen due to the COVID-19 pandemic, we will hold the workshop virtually.</span></div>
<div/>
<div><strong><span style="color: #ff0000;">SUBMISSIONS DUE May 18, 2020, 11:59pm PDT.</span></strong></div>
<div/>
<div/>
<div><strong>Call for Papers: the 2nd Workshop on Behavioral Economics and Computation</strong></div>
<div/>
<div><span>We solicit research contributions and participants for the 2nd Workshop on Behavioral Economics and Computation, to be held in conjunction with the Twenty-First ACM Conference on Economics and Computation (ACM EC ’20). </span></div>
<div/>
<div><span>Based on the successful workshop last year, we aim to bring together again researchers and practitioners from diverse subareas of EC, who are interested in the intersection of human economic behavior and computation, to share new results and to discuss future directions for behavioral research related to economics and computation. It will be a full-day workshop, and will feature invited speakers, contributed paper presentations and a panel discussion. </span></div>
<div/>
<div><span>The gap between rationality-based analysis that assumes utility-maximizing agents and actual human behavior in the real world has been well recognized in economics, psychology and other social sciences. In recent years, there has been growing interest in conducting behavioral research across many of the sub-areas related to economics and computation to address this gap. In one direction, some of these studies leverage insights on human decision making from the behavioral economics and psychology literature to study economic and computational systems with human users. In the other direction, computational tools are used to study and gain insights on human behavior and a data-driven approach is used to learn behavior models from user-generated data.</span></div>
<div><span><br/>
The 2nd Behavioral EC workshop aims to provide a venue for researchers and practitioners from diverse fields, including but not limited to computer science, economics, psychology and sociology, to exchange ideas related to behavioral research in economics and computation. In addition to sharing new results, we hope the workshop will foster a lively discussion of future directions and methodologies for behavioral research related to economics and computation as well as fruitful cross-pollination of behavioral economics, cognitive psychology and computer science. </span></div>
<div><span><br/>
We welcome studies at the intersection of economic behavior and computation from a rich set of theoretical, experimental and empirical perspectives. The topics of interest for the workshop are behavioral research in all settings covered by EC, including but not limited to:</span></div>
<ul>
<li><span>Behavioral mechanism design and applied mechanism design</span></li>
<li><span>Boundedly-rational models of economic decision making</span></li>
<li><span>Empirical studies of human economic behavior</span></li>
<li><span>Model evaluation and selection based on behavioral data</span></li>
<li><span>Data-driven modelling</span></li>
<li><span>Online prediction markets, online experiments, and crowdsourcing platforms</span></li>
<li><span>Hybrid human-machine systems</span></li>
<li><span>Models and experiments about social considerations (e.g. fairness and trust) in decision making</span></li>
<li><span>Methods for behavioral EC: information aggregation, probability elicitation, quality control</span></li>
</ul>
<div/>
<div/>
<div><span><strong>Submission Instructions</strong><br/>
</span></div>
<div/>
<div><span style="color: #ff0000;">Submission deadline: May 18, 2020, 11:59pm PDT.</span></div>
<div><span style="color: #ff0000;">Notification: June 11, 2020</span></div>
<div/>
<div><span>All submissions will be peer reviewed. We will give priority to new (unpublished) research papers but will also consider ongoing research and recently published papers that may be of interest to the workshop audience. For submissions of published papers, authors must clearly state the venue of publication. Position papers and panel discussion proposals are also welcome. Papers will be reviewed for relevance, significance, originality, research contribution, and likelihood to catalyze discussion. </span></div>
<div><span><br/>
Submissions can be in any format and any length. We recommend the EC submission format. </span><span>The workshop will not have archival proceedings but will post accepted papers on the workshop website. At least one author of each accepted paper will be expected to attend and present their findings at the workshop.<p/>
<p/></span></div>
<div><span>Submissions should be uploaded to Easychair no later than May 18th, 2020, 11:59pm PDT. </span></div>
<div/>
<div/>
<div><span><strong>Organizing Committee</strong><br/>
</span></div>
<div><span><br/>
Yiling Chen, Harvard University<br/>
Dan Goldstein, Microsoft Research<br/>
Kevin Leyton-Brown, University of British Columbia<br/>
Shengwu Li, Harvard University<br/>
Gali Noti, Hebrew University</span></div>
<div/>
<div><span><br/>
<strong>More Information</strong><br/>
</span></div>
<div><span><br/>
For more information or questions, visit the workshop website:<br/>
<a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br/>
or email the organizing committee: <a href="mailto:behavioralec2020@easychair.org">behavioralec2020@easychair.org</a></span></div>
			<div id="atatags-26942-5e8be264da029"/></div>
    </content>
    <updated>2020-04-07T02:15:59Z</updated>
    <published>2020-04-07T02:15:59Z</published>
    <category term="Uncategorized"/>
    <category term="Conferences"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-16T20:20:39Z</updated>
    </source>
  </entry>
</feed>
