<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-21T19:27:22Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4944416293302133989</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4944416293302133989/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html" rel="alternate" type="text/html"/>
    <title>Extra! Extra! Read all about it!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last weekend I saw the documentary <a href="https://www.imdb.com/title/tt7428030/">Joseph Pulitzer: Voice of the People</a>. Pulitzer, as you probably know from the prize named after him, was a major newspaper publisher in the late 19th and early 20th century. He ran two papers, the St. Louis Post-Dispatch and The New York World. The World at one point took on massive proportions, including sheet music of the latest tunes and dress patterns of new fashion that one could make at home. The World was the Internet of the turn of the 20th century.<br/>
<br/>
The movie mentioned the many editions of the paper during the day, including the extra edition. An extra edition came out because of some major breaking news story. Back then newspapers would drum up minor stories to sell extra editions but they tended to disappear over time.<br/>
<br/>
Which brings me to Monday, August 19, 1991. Hard-line members of the communist party of the USSR <a href="https://en.wikipedia.org/wiki/1991_Soviet_coup_d%27%C3%A9tat_attempt">attempted a coup</a> to take over the government from Mikhail Gorbachev. To us in the US, this seemed like the cold war which appeared to be coming to an end might rekindle. At the time I lived in Chicago and on that Monday the Chicago Tribune ran an extra afternoon edition talking about the coup. The return to the cold war didn't happen. Within a couple of days the coup failed and if anything hastened the dissolution of the Soviet Republic.<br/>
<br/>
That was probably the last of the extra editions. By the time of the next major historical event, ten years and twenty-three days later, we had the Internet and cell phones and one no longer needed a newspaper to tell you the world has changed.</div>
    </content>
    <updated>2019-02-21T12:42:00Z</updated>
    <published>2019-02-21T12:42:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-21T18:23:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07660</id>
    <link href="http://arxiv.org/abs/1902.07660" rel="alternate" type="text/html"/>
    <title>Towards Work-Efficient Parallel Parameterized Algorithms</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannach:Max.html">Max Bannach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skambath:Malte.html">Malte Skambath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tantau:Till.html">Till Tantau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07660">PDF</a><br/><b>Abstract: </b>Parallel parameterized complexity theory studies how fixed-parameter
tractable (fpt) problems can be solved in parallel. Previous theoretical work
focused on parallel algorithms that are very fast in principle, but did not
take into account that when we only have a small number of processors (between
2 and, say, 1024), it is more important that the parallel algorithms are
work-efficient. In the present paper we investigate how work-efficient fpt
algorithms can be designed. We review standard methods from fpt theory, like
kernelization, search trees, and interleaving, and prove trade-offs for them
between work efficiency and runtime improvements. This results in a toolbox for
developing work-efficient parallel fpt algorithms.
</p></div>
    </summary>
    <updated>2019-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07657</id>
    <link href="http://arxiv.org/abs/1902.07657" rel="alternate" type="text/html"/>
    <title>The Hairy Ball Problem is PPAD-Complete</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Paul_W=.html">Paul W. Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hollender:Alexandros.html">Alexandros Hollender</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07657">PDF</a><br/><b>Abstract: </b>The Hairy Ball Theorem states that every continuous tangent vector field on
an even-dimensional sphere must have a zero. We prove that the associated
computational problem of computing an approximate zero is PPAD-complete. We
also give a FIXP-hardness result for the general exact computation problem.
</p>
<p>In order to show that this problem lies in PPAD, we provide new results on
multiple-source variants of END-OF-LINE, the canonical PPAD-complete problem.
In particular, finding an approximate zero of a Hairy Ball vector field on an
even-dimensional sphere reduces to a 2-source END-OF-LINE problem. If the
domain is changed to be the torus of genus $g \geq 2$ instead (where the Hairy
Ball Theorem also holds), then the problem reduces to a $2(g-1)$-source
END-OF-LINE problem.
</p>
<p>These multiple-source END-OF-LINE results are of independent interest and
provide new tools for showing membership in PPAD. In particular, we use them to
provide the first full proof of PPAD-completeness for the IMBALANCE problem
defined by Beame et al. in 1998.
</p></div>
    </summary>
    <updated>2019-02-21T02:23:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07599</id>
    <link href="http://arxiv.org/abs/1902.07599" rel="alternate" type="text/html"/>
    <title>Fast, Small, and Simple Document Listing on Repetitive Text Collections</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Dustin Cobas, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07599">PDF</a><br/><b>Abstract: </b>Document listing on string collections is the task of finding all documents
where a pattern appears. It is regarded as the most fundamental document
retrieval problem, and is useful in various applications. Many of the
fastest-growing string collections are composed of very similar documents, such
as versioned code and document collections, genome repositories, etc. Plain
pattern-matching indexes designed for repetitive text collections achieve
orders-of-magnitude reductions in space. Instead, there are not many analogous
indexes for document retrieval. In this paper we present a simple document
listing index for repetitive string collections of total length $n$ that lists
the $ndoc$ distinct documents where a pattern of length $m$ appears in time
$\mathcal{O}(m+ndoc \cdot \log n)$. We exploit the repetitiveness of the
document array (i.e., the suffix array coarsened to document identifiers) to
grammar-compress it while precomputing the answers to nonterminals, and store
them in grammar-compressed form as well. Our experimental results show that our
index sharply outperforms existing alternatives in the space/time tradeoff map.
</p></div>
    </summary>
    <updated>2019-02-21T02:25:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07568</id>
    <link href="http://arxiv.org/abs/1902.07568" rel="alternate" type="text/html"/>
    <title>On Polynomial-Time Combinatorial Algorithms for Maximum $L$-Bounded Flow</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kateřina Altmanová, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolman:Petr.html">Petr Kolman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Voborn=iacute=k:Jan.html">Jan Voborník</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07568">PDF</a><br/><b>Abstract: </b>Given a graph $G=(V,E)$ with two distinguished vertices $s,t\in V$ and an
integer $L$, an {\em $L$-bounded flow} is a flow between $s$ and $t$ that can
be decomposed into paths of length at most $L$. In the {\em maximum $L$-bounded
flow problem} the task is to find a maximum $L$-bounded flow between a given
pair of vertices in the input graph.
</p>
<p>The problem can be solved in polynomial time using linear programming.
However, as far as we know, no polynomial-time combinatorial algorithm for the
$L$-bounded flow is known. The only attempt, that we are aware of, to describe
a combinatorial algorithm for the maximum $L$-bounded flow problem was done by
Koubek and \v{R}\'i ha in 1981. Unfortunately, their paper contains
substantional flaws and the algorithm does not work; in the first part of this
paper, we describe these problems.
</p>
<p>In the second part of this paper we describe a combinatorial algorithm based
on the exponential length method that finds a $(1+\epsilon)$-approximation of
the maximum $L$-bounded flow in time $O(\epsilon^{-2}m^2 L\log L)$ where $m$ is
the number of edges in the graph. Moreover, we show that this approach works
even for the NP-hard generalization of the maximum $L$-bounded flow problem in
which each edge has a length.
</p></div>
    </summary>
    <updated>2019-02-21T02:25:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07562</id>
    <link href="http://arxiv.org/abs/1902.07562" rel="alternate" type="text/html"/>
    <title>Approximate Nearest Neighbor for Curves --- Simple, Efficient, and Deterministic</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Arnold.html">Arnold Filtser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Omrit.html">Omrit Filtser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katz:Matthew_J=.html">Matthew J. Katz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07562">PDF</a><br/><b>Abstract: </b>In the $(1+\varepsilon,r)$-approximate-near-neighbor problem for curves
(ANNC) under some distance measure $\delta$, the goal is to construct a data
structure for a given set $\mathcal{C}$ of curves that supports approximate
near-neighbor queries: Given a query curve $Q$, if there exists a curve
$C\in\mathcal{C}$ such that $\delta(Q,C)\le r$, then return a curve
$C'\in\mathcal{C}$ with $\delta(Q,C')\le(1+\varepsilon)r$. There exists an
efficient reduction from the $(1+\varepsilon)$-approximate-nearest-neighbor
problem to ANNC, where in the former problem the answer to a query is a curve
$C\in\mathcal{C}$ with $\delta(Q,C)\le(1+\varepsilon)\cdot\delta(Q,C^*)$, where
$C^*$ is the curve of $\mathcal{C}$ closest to $Q$.
</p>
<p>Given a set $\mathcal{C}$ of $n$ curves, each consisting of $m$ points in $d$
dimensions, we construct a data structure for ANNC that uses $n\cdot
O(\frac{1}{\varepsilon})^{md}$ storage space and has
$O(md\log(\frac{nm}{\varepsilon}))$ query time (for a query curve of length
$m$), where the similarity between two curves is their discrete Fr\'echet or
dynamic time warping distance. Our approach consists of a discretization of
space based on the input curves, which allows us to prepare a small set of
curves that captures all possible queries approximately. Our method is simple
and deterministic, yet, somewhat surprisingly, it is more efficient than all
previous methods.
</p>
<p>We also apply our method to a version of approximate range counting for
curves and achieve similar bounds.
</p></div>
    </summary>
    <updated>2019-02-21T02:34:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07554</id>
    <link href="http://arxiv.org/abs/1902.07554" rel="alternate" type="text/html"/>
    <title>Load-Balancing for Parallel Delaunay Triangulations</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Funke:Daniel.html">Daniel Funke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sanders:Peter.html">Peter Sanders</a>, Vincent Winkler <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07554">PDF</a><br/><b>Abstract: </b>Computing the Delaunay triangulation (DT) of a given point set in
$\mathbb{R}^D$ is one of the fundamental operations in computational geometry.
Recently, Funke and Sanders (2017) presented a divide-and-conquer DT algorithm
that merges two partial triangulations by re-triangulating a small subset of
their vertices - the border vertices - and combining the three triangulations
efficiently via parallel hash table lookups. The input point division should
therefore yield roughly equal-sized partitions for good load-balancing and also
result in a small number of border vertices for fast merging. In this paper, we
present a novel divide-step based on partitioning the triangulation of a small
sample of the input points. In experiments on synthetic and real-world data
sets, we achieve nearly perfectly balanced partitions and small border
triangulations. This almost cuts running time in half compared to
non-data-sensitive division schemes on inputs exhibiting an exploitable
underlying structure.
</p></div>
    </summary>
    <updated>2019-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07515</id>
    <link href="http://arxiv.org/abs/1902.07515" rel="alternate" type="text/html"/>
    <title>The Weak Call-By-Value {\lambda}-Calculus is Reasonable for Both Time and Space</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Forster:Yannick.html">Yannick Forster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunze:Fabian.html">Fabian Kunze</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07515">PDF</a><br/><b>Abstract: </b>We study the weak call-by-value $\lambda$-calculus as a model for
computational complexity theory and establish the natural measures for time and
space -- the number of beta-reductions and the size of the largest term in a
computation -- as reasonable measures with respect to the invariance thesis of
Slot and van Emde Boas [STOC~84]. More precisely, we show that, using those
measures, Turing machines and the weak call-by-value $\lambda$-calculus can
simulate each other within a polynomial overhead in time and a constant factor
overhead in space for all computations that terminate in (encodings) of 'true'
or 'false'. We consider this result as a solution to the long-standing open
problem, explicitly posed by Accattoli [ENTCS~18], of whether the natural
measures for time and space of the $\lambda$-calculus are reasonable, at least
in case of weak call-by-value evaluation.
</p>
<p>Our proof relies on a hybrid of two simulation strategies of reductions in
the weak call-by-value $\lambda$-calculus by Turing machines, both of which are
insufficient if taken alone. The first strategy is the most naive one in the
sense that a reduction sequence is simulated precisely as given by the
reduction rules; in particular, all substitutions are executed immediately.
This simulation runs within a constant overhead in space, but the overhead in
time might be exponential. The second strategy is heap-based and relies on
structure sharing, similar to existing compilers of eager functional languages.
This strategy only has a polynomial overhead in time, but the space consumption
might require an additional factor of $\log n$, which is essentially due to the
size of the pointers required for this strategy. Our main contribution is the
construction and verification of a space-aware interleaving of the two
strategies, which is shown to yield both a constant overhead in space and a
polynomial overhead in time.
</p></div>
    </summary>
    <updated>2019-02-21T02:20:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07465</id>
    <link href="http://arxiv.org/abs/1902.07465" rel="alternate" type="text/html"/>
    <title>On Termination of Integer Linear Loops</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hosseini:Mehran.html">Mehran Hosseini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouaknine:Jo=euml=l.html">Joël Ouaknine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Worrell:James.html">James Worrell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07465">PDF</a><br/><b>Abstract: </b>We consider the problem of determining termination of single-path loops with
integer variables and affine updates. The problem asks whether such a loop
terminates on all integer initial values. This problem is known to be decidable
for the subclass of loops whose update matrices are diagonalisable. In this
paper we show decidability of determining termination for arbitrary update
matrices, but with a single inequality as the loop guard. Our decision
procedure relies on number-theoretic results concerning Diophantine
approximation. For the class of loops considered in this paper, the question of
deciding termination on a specific initial value is a longstanding open
problem.
</p></div>
    </summary>
    <updated>2019-02-21T02:21:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07408</id>
    <link href="http://arxiv.org/abs/1902.07408" rel="alternate" type="text/html"/>
    <title>Improved efficiency for explicit covering codes matching the sphere-covering bound</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potukuchi:Aditya.html">Aditya Potukuchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yihan.html">Yihan Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07408">PDF</a><br/><b>Abstract: </b>A covering code is a subset of vectors over a finite field with the property
that any vector in the space is close to some codeword in Hamming distance.
Blinovsky [Bli90] showed that most linear codes have covering radius attaining
the sphere-covering bound. Taking the direct sum of all $2^{O(n^2)}$ linear
codes gives an explicit code with optimal covering density, which is, to our
knowledge, the most efficient construction. In this paper, we improve the
randomness efficiency of this construction by proving optimal covering property
of a Wozencraft-type ensemble. This allows us to take the direct sum of only
$2^{O(n\log n)}$ many codes to achieve the same covering goodness. The proof is
an application of second moment method coupled with an iterative random
shifting trick along the lines of Blinovsky.
</p></div>
    </summary>
    <updated>2019-02-21T02:23:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07380</id>
    <link href="http://arxiv.org/abs/1902.07380" rel="alternate" type="text/html"/>
    <title>Optimal Average-Case Reductions to Sparse PCA: From Weak Assumptions to Strong Hardness</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brennan:Matthew.html">Matthew Brennan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bresler:Guy.html">Guy Bresler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07380">PDF</a><br/><b>Abstract: </b>In the past decade, sparse principal component analysis has emerged as an
archetypal problem for illustrating statistical-computational tradeoffs. This
trend has largely been driven by a line of research aiming to characterize the
average-case complexity of sparse PCA through reductions from the planted
clique (PC) conjecture - which conjectures that there is no polynomial-time
algorithm to detect a planted clique of size $K = o(N^{1/2})$ in
$\mathcal{G}(N, \frac{1}{2})$. All previous reductions to sparse PCA either
fail to show tight computational lower bounds matching existing algorithms or
show lower bounds for formulations of sparse PCA other than its canonical
generative model, the spiked covariance model. Also, these lower bounds all
quickly degrade with the exponent in the PC conjecture. Specifically, when only
given the PC conjecture up to $K = o(N^\alpha)$ where $\alpha &lt; 1/2$, there is
no sparsity level $k$ at which these lower bounds remain tight. If $\alpha \le
1/3$ these reductions fail to even show the existence of a
statistical-computational tradeoff at any sparsity $k$. We give a reduction
from PC that yields the first full characterization of the computational
barrier in the spiked covariance model, providing tight lower bounds at all
sparsities $k$. We also show the surprising result that weaker forms of the PC
conjecture up to clique size $K = o(N^\alpha)$ for any given $\alpha \in (0,
1/2]$ imply tight computational lower bounds for sparse PCA at sparsities $k =
o(n^{\alpha/3})$. This shows that even a mild improvement in the signal
strength needed by the best known polynomial-time sparse PCA algorithms would
imply that the hardness threshold for PC is subpolynomial. This is the first
instance of a suboptimal hardness assumption implying optimal lower bounds for
another problem in unsupervised learning.
</p></div>
    </summary>
    <updated>2019-02-21T02:22:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07354</id>
    <link href="http://arxiv.org/abs/1902.07354" rel="alternate" type="text/html"/>
    <title>Competitive Concurrent Distributed Scheduling</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghodselahi:Abdolhamid.html">Abdolhamid Ghodselahi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuhn:Fabian.html">Fabian Kuhn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turau:Volker.html">Volker Turau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07354">PDF</a><br/><b>Abstract: </b>We introduce a new scheduling problem in distributed computing that we call
the DSMS problem. We are given a set of $k \geq 1$ mobile identical servers
that are initially hosted by some processors of the given network. Further, we
are given a set of requests that are issued by the processors possibly at any
time in an online fashion, and the servers must serve them. A request must be
scheduled before the request is served. The delay for scheduling a request is
the time taken since the request is issued until it is scheduled. The goal is
to minimize the average delay.
</p>
<p>Navigating mobile servers in a large-scale distributed system needs a
scalable location service. We devise the distributed GNN protocol, a novel
linked-reversal-based protocol for the DSMS problem that works on overlay
trees. We prove that GNN is a starvation-free protocol that correctly
integrates locating the servers and synchronizing the concurrent access to the
servers despite asynchrony. Further, we analyze the GNN protocol for one-shot
executions where all requests are simultaneously issued. We show that when
running the GNN protocol on top of a special family of tree topologies---known
as hierarchically well-separated trees (HSTs)---we obtain a randomized
distributed protocol with an expected competitive ratio of $O(\log n)$ on
general network topologies for the DSMS problem where $n$ is the number of
processors in the given network. From a technical point of view, the main
result of our paper shows that the GNN protocol optimally solves the DSMS
problem on HSTs for one-shot executions. Our results hold even if communication
is asynchronous.
</p></div>
    </summary>
    <updated>2019-02-21T02:32:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07353</id>
    <link href="http://arxiv.org/abs/1902.07353" rel="alternate" type="text/html"/>
    <title>In oder Aus</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ethan Madison, Zachary Zipper <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07353">PDF</a><br/><b>Abstract: </b>Bloom filters are data structures used to determine set membership of
elements, with applications from string matching to networking and security
problems. These structures are favored because of their reduced memory
consumption and fast wallclock and asymptotic time bounds. Generally, Bloom
filters maintain constant membership query time, making them very fast in their
niche. However, they are limited in their lack of a removal operation, as well
as by their probabilistic nature. In this paper, we discuss various iterations
of and alternatives to the generic Bloom filter that have been researched and
implemented to overcome their inherent limitations. Bloom filters, especially
when used in conjunction with other data structures, are still powerful and
efficient data structures; we further discuss their use in industy and research
to optimize resource utilization.
</p></div>
    </summary>
    <updated>2019-02-21T02:34:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07349</id>
    <link href="http://arxiv.org/abs/1902.07349" rel="alternate" type="text/html"/>
    <title>Solutions sets to systems of equations in hyperbolic groups are EDT0L in PSPACE</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ciobanu:Laura.html">Laura Ciobanu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elder:Murray.html">Murray Elder</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07349">PDF</a><br/><b>Abstract: </b>We show that the full set of solutions to systems of equations and
inequations in a hyperbolic group, with or without torsion, as shortlex
geodesic words, is an EDT0L language whose specification can be computed in
$\mathsf{NSPACE}(n^2\log n)$ for the torsion-free case and
$\mathsf{NSPACE}(n^4\log n)$ in the torsion case. Our work combines deep
geometric results by Rips, Sela, Dahmani and Guirardel on decidability of
existential theories of hyperbolic groups, work of Computer Scientists
including Plandowski, Je\.z, Diekert and others on $\mathsf{PSPACE}$ algorithms
to solve equations in free monoids and groups using compression, and an
intricate language-theoretic analysis.
</p>
<p>The present work gives an essentially optimal formal language description for
all solutions in all hyperbolic groups, and an explicit and surprising low
space complexity to compute them.
</p></div>
    </summary>
    <updated>2019-02-21T02:21:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07336</id>
    <link href="http://arxiv.org/abs/1902.07336" rel="alternate" type="text/html"/>
    <title>A Tight Lower Bound for Index Erasure</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindzey:Nathan.html">Nathan Lindzey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosmanis:Ansis.html">Ansis Rosmanis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07336">PDF</a><br/><b>Abstract: </b>The Index Erasure problem asks a quantum computer to prepare a uniform
superposition over the image of an injective function given by an oracle. We
prove a tight $\Omega(\sqrt{n})$ lower bound on the quantum query complexity of
the non-coherent case of the problem, where, in addition to preparing the
required superposition, the algorithm is allowed to leave the ancillary memory
in an arbitrary function-dependent state. This resolves an open question of
Ambainis, Magnin, Roetteler, and Roland (CCC 2011), who gave a tight bound for
the coherent case, the case where the ancillary memory must return to its
initial state.
</p>
<p>The proof is based on evaluating certain Krein parameters of a symmetric
association scheme defined over partial permutations. The study of this
association scheme may be of independent interest.
</p></div>
    </summary>
    <updated>2019-02-21T02:24:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07334</id>
    <link href="http://arxiv.org/abs/1902.07334" rel="alternate" type="text/html"/>
    <title>Fourier and Circulant Matrices are Not Rigid</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dvir:Zeev.html">Zeev Dvir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Allen.html">Allen Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07334">PDF</a><br/><b>Abstract: </b>The concept of matrix rigidity was first introduced by Valiant in [Val77].
Roughly speaking, a matrix is rigid if its rank cannot be reduced significantly
by changing a small number of entries. There has been extensive interest in
rigid matrices as Valiant showed that rigidity can be used to prove arithmetic
circuit lower bounds.
</p>
<p>In a surprising result, Alman and Williams [AW16] showed that the (real
valued) Hadamard matrix, which was conjectured to be rigid, is actually not
very rigid. This line of work was extended by [DE17] to a family of matrices
related to the Hadamard matrix, but over finite fields. In our work, we take
another step in this direction and show that for any abelian group $G$ and
function $f:G \rightarrow \mathbb C$, the matrix given by $M_{xy} = f(x - y)$
for $x,y \in G$ is not rigid. In particular, we get that complex valued Fourier
matrices, circulant matrices, and Toeplitz matrices are all not rigid and
cannot be used to carry out Valiant's approach to proving circuit lower bounds.
This complements a recent result of Goldreich and Tal who showed that Toeplitz
matrices are nontrivially rigid (but not enough for Valiant's method). Our work
differs from previous non-rigidity results in that those works considered
matrices whose underlying group of symmetries was of the form $\mathbb F_p^n$
with $p$ fixed and $n$ tending to infinity, while in the families of matrices
we study, the underlying group of symmetries can be any abelian group and, in
particular cyclic groups which have very different structure. Our results also
suggest natural new candidates for rigidity in the form of matrices whose
symmetry groups are highly non-abelian.
</p></div>
    </summary>
    <updated>2019-02-21T02:24:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07324</id>
    <link href="http://arxiv.org/abs/1902.07324" rel="alternate" type="text/html"/>
    <title>Computational Hardness of Certifying Bounds on Constrained PCA Problems</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a>, Dmitriy Kunisky, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07324">PDF</a><br/><b>Abstract: </b>Given a random $n \times n$ symmetric matrix $\boldsymbol W$ drawn from the
Gaussian orthogonal ensemble (GOE), we consider the problem of certifying an
upper bound on the maximum value of the quadratic form $\boldsymbol x^\top
\boldsymbol W \boldsymbol x$ over all vectors $\boldsymbol x$ in a constraint
set $\mathcal{S} \subset \mathbb{R}^n$. For a certain class of normalized
constraint sets $\mathcal{S}$, we give strong evidence that there is no
polynomial-time algorithm certifying a better upper bound than the largest
eigenvalue of $\boldsymbol W$. A notable special case included in our results
is the hypercube $\mathcal{S} = \{ \pm 1 / \sqrt{n}\}^n$, which corresponds to
the problem of certifying bounds on the Hamiltonian of the
Sherrington-Kirkpatrick spin glass model from statistical physics.
</p>
<p>Our proof proceeds in two steps. First, we give a reduction from the
detection problem in the negatively-spiked Wishart model to the above
certification problem. We then give evidence that this Wishart detection
problem is computationally hard below the classical spectral threshold, using a
method of Hopkins and Steurer based on approximating the likelihood ratio with
a low-degree polynomial. Our proof can be seen as constructing a distribution
over symmetric matrices that appears computationally indistinguishable from the
GOE, yet is supported on matrices whose maximum quadratic form over
$\boldsymbol x \in \mathcal{S}$ is much larger than that of a GOE matrix.
</p></div>
    </summary>
    <updated>2019-02-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07245</id>
    <link href="http://arxiv.org/abs/1902.07245" rel="alternate" type="text/html"/>
    <title>Continuous Ordinary Differential Equations and Infinite Time Turing Machines</title>
    <feedworld_mtime>1550707200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bournez:Olivier.html">Olivier Bournez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouazzani:Sabrina.html">Sabrina Ouazzani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07245">PDF</a><br/><b>Abstract: </b>We consider Continuous Ordinary Differential Equations (CODE) y'=f(y), where
f is a continuous function. They are known to always have solutions for a given
initial condition y(0)=y0, these solutions being possibly non unique. We
restrict to our attention to a class of continuous functions, that we call
greedy: they always admit unique greedy solutions, i.e. going in greedy way in
some fixed direction.
</p>
<p>We prove that they can be seen as models of computation over the ordinals
(Infinite Time Turing Machines, ITTM) and conversely in a very strong sense.
</p>
<p>In particular, for such ODEs, to a greedy trajectory can be associated some
ordinal corresponding to some time of computation, and conversely models of
computation over the ordinals can be associated to some CODE. In particular,
analyzing reachability for one or the other concept with respect to greedy
trajectories has the same hardness. This also brings new perspectives on
analysis in Mathematics, by providing ways to translate results for ITTMs to
CODEs. This also extends some recent results about the relations between
ordinary differential equations and Turing machines, and more widely with
(generalized) computability theory.
</p></div>
    </summary>
    <updated>2019-02-21T02:20:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-21T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07201</id>
    <link href="http://arxiv.org/abs/1902.07201" rel="alternate" type="text/html"/>
    <title>PIT for depth-$4$ circuits and Sylvester-Gallai conjecture for polynomials</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Milovanov:Alexey.html">Alexey Milovanov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07201">PDF</a><br/><b>Abstract: </b>This text is a development of a preprint of Ankit Gupta.
</p>
<p>We present an approach for devising a deterministic polynomial time blackbox
identity testing (PIT) algorithm for depth-$4$ circuits with bounded top fanin.
This approach is similar to Kayal-Shubhangi approach for depth-$3$ circuits.
Kayal and Shubhangi based their algorithm on Sylvester-Gallai-type theorem
about linear polynomials. We show how it is possible to generalize this
approach to depth-$4$ circuits. However we failed to implement this plan
completely. We succeeded to construct a polynomial time deterministic algorithm
for depth-$4$ circuits with bounded top fanin and its correctness requires a
hypothesis. Also we present a polynomial-time (unconditional) algorithm for
some subclass of depth-$4$ circuits with bounded top fanin.
</p></div>
    </summary>
    <updated>2019-02-20T23:21:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07190</id>
    <link href="http://arxiv.org/abs/1902.07190" rel="alternate" type="text/html"/>
    <title>Approximating Continuous Functions on Persistence Diagrams Using Template Functions</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perea:Jose_A=.html">Jose A. Perea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munch:Elizabeth.html">Elizabeth Munch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khasawneh:Firas_A=.html">Firas A. Khasawneh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07190">PDF</a><br/><b>Abstract: </b>The persistence diagram is an increasingly useful tool arising from the field
of Topological Data Analysis. However, using these diagrams in conjunction with
machine learning techniques requires some mathematical finesse. The most
success to date has come from finding methods for turning persistence diagrams
into vectors in $\mathbb{R}^n$ in a way which preserves as much of the space of
persistence diagrams as possible, commonly referred to as featurization. In
this paper, we describe a mathematical framework for featurizing the
persistence diagram space using template functions. These functions are general
as they are only required to be continuous, have a compact support, and
separate points. We discuss two example realizations of these functions: tent
functions and Chybeyshev interpolating polynomials. Both of these functions are
defined on a grid superposed on the birth-lifetime plane. We then combine the
resulting features with machine learning algorithms to perform supervised
classification and regression on several example data sets, including manifold
data, shape data, and an embedded time series from a Rossler system. Our
results show that the template function approach yields high accuracy rates
that match and often exceed the results of existing methods for featurizing
persistence diagrams. One counter-intuitive observation is that in most cases
using interpolating polynomials, where each point contributes globally to the
feature vector, yields significantly better results than using tent functions,
where the contribution of each point is localized to its grid cell. Along the
way, we also provide a complete characterization of compact sets in persistence
diagram space endowed with the bottleneck distance.
</p></div>
    </summary>
    <updated>2019-02-20T23:36:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07175</id>
    <link href="http://arxiv.org/abs/1902.07175" rel="alternate" type="text/html"/>
    <title>Lower bounds on separation automata for Parity Games</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozachinskiy:Alexander.html">Alexander Kozachinskiy</a>, Mikhail Vyalyi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07175">PDF</a><br/><b>Abstract: </b>Several recently developed quasi-polynomial time algorithms for Parity Games
rely on construction of an automaton with quasi-polynomial number of states
that separates specific languages of infinite words. This motivates a question
of whether a matching quasi-polynomial lower bound on the number of states can
be proved. This would mean impossibility for a separation approach to give
a~polynomial-time algorithm for Parity Games.
</p>
<p>In this paper we study a restricted version of the problem. We bound the
number of moves to be read by a separation automaton before it makes a
decision. In the general problem there is no restriction of this sort. But we
show that lower bounds for unrestricted version of the problem are related to
lower bounds for a restricted one with some explicit bound on the number of
moves.
</p>
<p>We apply communication complexity techniques to get an exponential lower
bound on the number of states of a separation automata which makes a decision
after reading linear number of moves.
</p>
<p>We also prove an exponential lower bound on the number of states of any
deterministic automaton which outputs any repetition in an infinite string
after reading some finite prefix of it. The motivation of this result in
context of separation automata is discussed in a paper.
</p>
<p>Finally, we show an upper bound on a communication problem that we call
Inevitable Intersection problem. Using this upper bound we conclude that a
certain class of reductions from communication complexity are unable to show
super-polynomial lower bounds on separation automata.
</p></div>
    </summary>
    <updated>2019-02-20T23:23:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07063</id>
    <link href="http://arxiv.org/abs/1902.07063" rel="alternate" type="text/html"/>
    <title>Towards Optimal Depth Reductions for Syntactically Multilinear Circuits</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Mrinal.html">Mrinal Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oliveira:Rafael.html">Rafael Oliveira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saptharishi:Ramprasad.html">Ramprasad Saptharishi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07063">PDF</a><br/><b>Abstract: </b>We show that any $n$-variate polynomial computable by a syntactically
multilinear circuit of size $\operatorname{poly}(n)$ can be computed by a
depth-$4$ syntactically multilinear ($\Sigma\Pi\Sigma\Pi$) circuit of size at
most $\exp\left({O\left(\sqrt{n\log n}\right)}\right)$. For degree $d =
\omega(n/\log n)$, this improves upon the upper bound of
$\exp\left({O(\sqrt{d}\log n)}\right)$ obtained by Tavenas~\cite{T15} for
general circuits, and is known to be asymptotically optimal in the exponent
when $d &lt; n^{\epsilon}$ for a small enough constant $\epsilon$. Our upper bound
matches the lower bound of $\exp\left({\Omega\left(\sqrt{n\log
n}\right)}\right)$ proved by Raz and Yehudayoff~\cite{RY09}, and thus cannot be
improved further in the exponent. Our results hold over all fields and also
generalize to circuits of small individual degree.
</p>
<p>More generally, we show that an $n$-variate polynomial computable by a
syntactically multilinear circuit of size $\operatorname{poly}(n)$ can be
computed by a syntactically multilinear circuit of product-depth $\Delta$ of
size at most $\exp\left(O\left(\Delta \cdot (n/\log n)^{1/\Delta} \cdot \log
n\right)\right)$. It follows from the lower bounds of Raz and Yehudayoff (CC
2009) that in general, for constant $\Delta$, the exponent in this upper bound
is tight and cannot be improved to $o\left(\left(n/\log
n\right)^{1/\Delta}\cdot \log n\right)$.
</p></div>
    </summary>
    <updated>2019-02-20T23:23:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07055</id>
    <link href="http://arxiv.org/abs/1902.07055" rel="alternate" type="text/html"/>
    <title>Hardness of exact distance queries in sparse graphs through hub labeling</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kosowski:Adrian.html">Adrian Kosowski</a>, Przemysław Uznański, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Viennot:Laurent.html">Laurent Viennot</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07055">PDF</a><br/><b>Abstract: </b>A distance labeling scheme is an assignment of bit-labels to the vertices of
an undirected, unweighted graph such that the distance between any pair of
vertices can be decoded solely from their labels. An important class of
distance labeling schemes is that of hub labelings, where a node $v \in G$
stores its distance to the so-called hubs $S_v \subseteq V$, chosen so that for
any $u,v \in V$ there is $w \in S_u \cap S_v$ belonging to some shortest $uv$
path. Notice that for most existing graph classes, the best distance labelling
constructions existing use at some point a hub labeling scheme at least as a
key building block. Our interest lies in hub labelings of sparse graphs, i.e.,
those with $|E(G)| = O(n)$, for which we show a lowerbound of
$\frac{n}{2^{O(\sqrt{\log n})}}$ for the average size of the hubsets.
Additionally, we show a hub-labeling construction for sparse graphs of average
size $O(\frac{n}{RS(n)^{c}})$ for some $0 &lt; c &lt; 1$, where $RS(n)$ is the
so-called Ruzsa-Szemer{\'e}di function, linked to structure of induced
matchings in dense graphs. This implies that further improving the lower bound
on hub labeling size to $\frac{n}{2^{(\log n)^{o(1)}}}$ would require a
breakthrough in the study of lower bounds on $RS(n)$, which have resisted
substantial improvement in the last 70 years. For general distance labeling of
sparse graphs, we show a lowerbound of $\frac{1}{2^{O(\sqrt{\log n})}}
SumIndex(n)$, where $SumIndex(n)$ is the communication complexity of the
Sum-Index problem over $Z_n$. Our results suggest that the best achievable
hub-label size and distance-label size in sparse graphs may be
$\Theta(\frac{n}{2^{(\log n)^c}})$ for some $0&lt;c &lt; 1$.
</p></div>
    </summary>
    <updated>2019-02-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07040</id>
    <link href="http://arxiv.org/abs/1902.07040" rel="alternate" type="text/html"/>
    <title>Travelling on Graphs with Small Highway Dimension</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Disser:Yann.html">Yann Disser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klimm:Max.html">Max Klimm</a>, Jochen Konemann <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07040">PDF</a><br/><b>Abstract: </b>We study the Travelling Salesperson (TSP) and the Steiner Tree problem (STP)
in graphs of low highway dimension. This graph parameter was introduced by
Abraham et al. [SODA 2010] as a model for transportation networks, on which TSP
and STP naturally occur for various applications in logistics. It was
previously shown [Feldmann et al. ICALP 2015] that these problems admit a
quasi-polynomial time approximation scheme (QPTAS) on graphs of constant
highway dimension. We demonstrate that a significant improvement is possible in
the special case when the highway dimension is 1, for which we present a
fully-polynomial time approximation scheme (FPTAS). We also prove that STP is
weakly NP-hard for these restricted graphs. For TSP we show NP-hardness for
graphs of highway dimension 6, which answers an open problem posed in [Feldmann
et al. ICALP 2015].
</p></div>
    </summary>
    <updated>2019-02-20T23:34:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07004</id>
    <link href="http://arxiv.org/abs/1902.07004" rel="alternate" type="text/html"/>
    <title>On the dualization in distributive lattices and related problems</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Defrain:Oscar.html">Oscar Defrain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nourine:Lhouari.html">Lhouari Nourine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uno:Takeaki.html">Takeaki Uno</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07004">PDF</a><br/><b>Abstract: </b>In this paper, we study the dualization in distributive lattices, a
generalization of the well known hypergraph dualization problem. We give a
characterization of the complexity of the problem under various combined
restrictions on graph classes and posets, including bipartite, split and
co-bipartite graphs, and variants of neighborhood inclusion posets. In
particular, we show that while the enumeration of minimal dominating sets is
possible with linear delay in split graphs, the problem gets as hard as for
general graphs in distributive lattices. More surprisingly, this result holds
even when the poset coding the lattice is only comparing vertices of included
neighborhoods in the graph. If both the poset and the graph are sufficiently
restricted, we show that the dualization becomes tractable relying on existing
algorithms from the literature.
</p></div>
    </summary>
    <updated>2019-02-20T23:35:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06957</id>
    <link href="http://arxiv.org/abs/1902.06957" rel="alternate" type="text/html"/>
    <title>Covering Vectors by Spaces in Perturbed Graphic Matroids and Their Duals</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06957">PDF</a><br/><b>Abstract: </b>Perturbed graphic matroids are binary matroids that can be obtained from a
graphic matroid by adding a noise of small rank. More precisely, r-rank
perturbed graphic matroid M is a binary matroid that can be represented in the
form I +P, where I is the incidence matrix of some graph and P is a binary
matrix of rank at most r. Such matroids naturally appear in a number of
theoretical and applied settings. The main motivation behind our work is an
attempt to understand which parameterized algorithms for various problems on
graphs could be lifted to perturbed graphic matroids.
</p>
<p>We study the parameterized complexity of a natural generalization (for
matroids) of the following fundamental problems on graphs: Steiner Tree and
Multiway Cut. In this generalization, called the Space Cover problem, we are
given a binary matroid M with a ground set E, a set of terminals T\subseteq E,
and a non-negative integer k. The task is to decide whether T can be spanned by
a subset of E\setminus T of size at most k.
</p>
<p>We prove that on graphic matroid perturbations, for every fixed r, Space
Cover is fixed-parameter tractable parameterized by k. On the other hand, the
problem becomes W[1]-hard when parameterized by r+k+|T| and it is NP-complete
for r\leq 2 and |T|\leq 2.
</p>
<p>On cographic matroids, that are the duals of graphic matroids, Space Cover
generalizes another fundamental and well-studied problem, namely Multiway Cut.
We show that on the duals of perturbed graphic matroids the Space Cover problem
is fixed-parameter tractable parameterized by r+k.
</p></div>
    </summary>
    <updated>2019-02-20T23:24:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06875</id>
    <link href="http://arxiv.org/abs/1902.06875" rel="alternate" type="text/html"/>
    <title>Euclidean TSP, Motorcycle Graphs, and Other New Applications of Nearest-Neighbor Chains</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efrat:Alon.html">Alon Efrat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, Daniel Frishberg, Michael Goodrich, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mamano:Nil.html">Nil Mamano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Pedro.html">Pedro Matias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Polishchuk:Valentin.html">Valentin Polishchuk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06875">PDF</a><br/><b>Abstract: </b>We show new applications of the nearest-neighbor chain algorithm, a technique
that originated in agglomerative hierarchical clustering. We apply it to a
diverse class of geometric problems: we construct the greedy multi-fragment
tour for Euclidean TSP in $O(n\log n)$ time in any fixed dimension and for
Steiner TSP in planar graphs in $O(n\sqrt{n}\log n)$ time; we compute
motorcycle graphs (which are a central part in straight skeleton algorithms) in
$O(n^{4/3+\varepsilon})$ time for any $\varepsilon&gt;0$; we introduce a
narcissistic variant of the $k$-attribute stable matching model, and solve it
in $O(n^{2-4/(k(1+\varepsilon)+2)})$ time; we give a linear-time
$2$-approximation for a 1D geometric set cover problem with applications to
radio station placement.
</p></div>
    </summary>
    <updated>2019-02-20T23:36:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06864</id>
    <link href="http://arxiv.org/abs/1902.06864" rel="alternate" type="text/html"/>
    <title>A sub-quadratic algorithm for the longest common increasing subsequence problem</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duraj:Lech.html">Lech Duraj</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06864">PDF</a><br/><b>Abstract: </b>The Longest Common Increasing Subsequence problem (LCIS) is a natural variant
of the celebrated Longest Common Subsequence (LCS) problem. For LCIS, as well
as for LCS, there is an $O(n^2)$ algorithm and a SETH-based quadratic lower
bound. For LCS, there is also the Masek-Paterson $O(n^2 / \log{n})$ algorithm,
which does not seem to adapt to LCIS in any obvious way. Hence, a natural
question arises: does any sub-quadratic algorithm exist for the Longest Common
Increasing Subsequence problem? We answer this question positively, presenting
a $O(n^2 / \log^a{n})$ algorithm for some $a&gt;0$. The algorithm is not based on
memorizing small chunks of data (often used for logarithmic speedups, including
the "Four Russians Trick" in LCS), but rather utilizes a new technique,
bounding the number of significant symbol matches between the two sequences.
</p></div>
    </summary>
    <updated>2019-02-20T23:24:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06852</id>
    <link href="http://arxiv.org/abs/1902.06852" rel="alternate" type="text/html"/>
    <title>Error reduction of quantum algorithms</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bera:Debajyoti.html">Debajyoti Bera</a>, Tharrmashastha P. V <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06852">PDF</a><br/><b>Abstract: </b>We give a technique to reduce the error probability of quantum algorithms
that determine whether its input has a specified property of interest. The
standard process of reducing this error is statistical processing of the
results of multiple independent executions of an algorithm. Denoting by $\rho$
an upper bound of this probability (wlog., assume $\rho \le \frac{1}{2}$),
classical techniques require $O(\frac{\rho}{[(1-\rho) - \rho]^2})$ executions
to reduce the error to a negligible constant. We investigated when and how
quantum algorithmic techniques like amplitude amplification and estimation may
reduce the number of executions. On one hand, the former idea does not directly
benefit algorithms that can err on both yes and no answers and the number of
executions in the latter approach is $O(\frac{1}{(1-\rho) - \rho})$. We propose
a novel approach named as {\em Amplitude Separation} that combines both these
approaches and achieves $O(\frac{1}{\sqrt{1-\rho} - \sqrt{\rho}})$ executions
that betters existing approaches when the errors are high.
</p>
<p>In the Multiple-Weight Decision Problem, the input is an $n$-bit Boolean
function $f()$ given as a black-box and the objective is to determine the
number of $x$ for which $f(x)=1$, denoted as $wt(f)$, given some possible
values $\{w_1, \ldots, w_k\}$ for $wt(f)$. When our technique is applied to
this problem, we obtain the correct answer, maybe with a negligible error,
using $O(\log_2 k \sqrt{2^n})$ calls to $f()$ that shows a quadratic speedup
over classical approaches and currently known quantum algorithms.
</p></div>
    </summary>
    <updated>2019-02-20T23:20:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06812</id>
    <link href="http://arxiv.org/abs/1902.06812" rel="alternate" type="text/html"/>
    <title>The Complexity of Max-Min $k$-Partitioning</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ismaili:Anisse.html">Anisse Ismaili</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06812">PDF</a><br/><b>Abstract: </b>In this paper we study a max-min $k$-partition problem on a weighted graph,
that could model a robust $k$-coalition formation. We settle the computational
complexity of this problem as complete for class $\Sigma_2^P$. This hardness
holds even for $k=2$ and arbitrary weights, or $k=3$ and non-negative weights,
which matches what was known on \textsc{MaxCut} and \textsc{Min-3-Cut} one
level higher in the polynomial hierarchy.
</p></div>
    </summary>
    <updated>2019-02-20T23:24:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06808</id>
    <link href="http://arxiv.org/abs/1902.06808" rel="alternate" type="text/html"/>
    <title>Characterizing the Integrality Gap of the Subtour LP for the Circulant Traveling Salesman Problem</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutekunst:Samuel_C=.html">Samuel C. Gutekunst</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williamson:David_P=.html">David P. Williamson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06808">PDF</a><br/><b>Abstract: </b>We consider the integrality gap of the subtour LP relaxation of the Traveling
Salesman Problem restricted to circulant instances. De Klerk and Dobre
conjectured that the value of the optimal solution to the subtour LP on these
instances is equal to an entirely combinatorial lower bound from Van der Veen,
Van Dal, and Sierksma. We prove this conjecture by giving an explicit optimal
solution to the subtour LP. We then use it to show that the integrality gap of
the subtour LP is 2 on circulant instances, making such instances one of the
few non-trivial classes of TSP instances for which the integrality gap of the
subtour LP is exactly known. We also show that the degree constraints do not
strengthen the subtour LP on circulant instances, mimicking the parsimonious
property of metric, symmetric TSP instances shown in Goemans and Bertsimas in a
distinctly non-metric set of instances.
</p></div>
    </summary>
    <updated>2019-02-20T23:34:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06803</id>
    <link href="http://arxiv.org/abs/1902.06803" rel="alternate" type="text/html"/>
    <title>How much does randomness help with locally checkable problems?</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balliu:Alkida.html">Alkida Balliu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06803">PDF</a><br/><b>Abstract: </b>Locally checkable labeling problems (LCLs) are distributed graph problems in
which a solution is globally feasible if it is locally feasible in all
constant-radius neighborhoods. Vertex colorings, maximal independent sets, and
maximal matchings are examples of LCLs.
</p>
<p>On the one hand, it is known that some LCLs benefit exponentially from
randomness---for example, any deterministic distributed algorithm that finds a
sinkless orientation requires $\Theta(\log n)$ rounds in the LOCAL model, while
the randomized complexity of the problem is $\Theta(\log \log n)$ rounds. On
the other hand, there are also many LCLs in which randomness is useless.
</p>
<p>Previously, it was not known if there are any LCLs that benefit from
randomness, but only subexponentially. We show that such problems exist: for
example, there is an LCL with deterministic complexity $\Theta(\log^2 n)$
rounds and randomized complexity $\Theta(\log n \log \log n)$ rounds.
</p></div>
    </summary>
    <updated>2019-02-20T23:22:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06796</id>
    <link href="http://arxiv.org/abs/1902.06796" rel="alternate" type="text/html"/>
    <title>Constructive Heuristics for Min-Power Bounded-Hops Symmetric Connectivity Problem</title>
    <feedworld_mtime>1550620800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Roman Plotnikov, Adil Erzin <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06796">PDF</a><br/><b>Abstract: </b>We consider a Min-Power Bounded-Hops Symmetric Connectivity problem that
consists in the construction of communication spanning tree on a given graph,
where the total energy consumption spent for the data transmission is minimized
and the maximum number of hops between two nodes is bounded by some predefined
constant. We focus on the planar Euclidian case of this problem where the nodes
are placed at the random uniformly spread points on a square and the power cost
necessary for the communication between two network elements is proportional to
the squared distance between them. Since this is an NP-hard problem, we propose
different polynomial heuristic algorithms for the approximation solution to
this problem. We perform a posteriori comparative analysis of the proposed
algorithms and present the obtained results in this paper.
</p></div>
    </summary>
    <updated>2019-02-20T23:34:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/021</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/021" rel="alternate" type="text/html"/>
    <title>TR19-021 |  $AC^0[p]$ Lower Bounds and NP-Hardness for Variants of MCSP | 

	Rahul Ilango</title>
    <summary>The Minimum Circuit Size Problem (MCSP) asks whether a (given) Boolean function has a circuit of at most a (given) size. Despite over a half-century of study, we know relatively little about the computational complexity of MCSP. We do know that questions about the complexity of MCSP have significant ramifications on longstanding open problems. In a recent development, Golovnev et al. [11] improves the status of unconditional lower bounds for MCSP, showing that MCSP is not in $AC^0[p]$ for any prime $p$. While their results generalize to most "typical" circuit classes, it fails to generalize to the circuit minimization problem for depth-d formulas, denoted ($AC^0_d$)-MCSP. In particular, their result relies on a Lipchitz hypothesis that is unknown (and possibly false) in the case of ($AC^0_d$)-MCSP. Despite this, we show that ($AC^0_d$)-MCSP is not in $AC^0[p]$ by proving even the failure of the Lipchitzness for $AC^0_d$ formulas implies that MAJORITY reduces to ($AC^0_d$)-MCSP under $AC^0$ truth table reductions. Somewhat remarkably, our proof (in the case of non-Lipchitzness) uses completely different techniques than [11]. To our knowledge, this is the first MCSP reduction that uses modular properties of a function's circuit complexity.

We also define MOCSP, an oracle version of MCSP that takes as input a Boolean function $f$, a size threshold $s$, and oracle Boolean functions $f_1, ..., f_t$, and determines whether there is an oracle circuit of size at most $s$ that computes $f$ when given access to $f_1, ... , f_t$. We prove that MOCSP is $NP$-complete under non-uniform $AC^0$ many-one reductions as well as (uniform) $ZPP$ truth table reductions. We also observe that improving this $ZPP$ reduction to a deterministic polynomial-time reduction requires showing $EXP \neq ZPP$ (using theorems of Hitchcock and Pavan [17] and Murray and Williams [22]). Optimistically, these MOCSP results could be a first step towards $NP$-hardness results for MCSP. At the very least, we believe MOCSP clarifies the barriers towards proving hardness for MCSP and provides a useful "testing ground" for questions about MCSP.</summary>
    <updated>2019-02-19T18:24:23Z</updated>
    <published>2019-02-19T18:24:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-21T19:25:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/020</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/020" rel="alternate" type="text/html"/>
    <title>TR19-020 |  On Tseitin formulas, read-once branching programs and treewidth | 

	Ludmila Glinskih, 

	Dmitry Itsykson</title>
    <summary>We show that any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on an $n\times n$ grid graph has size at least $2^{\Omega(n)}$. Then using the Excluded Grid Theorem by Robertson and Seymour we show that for arbitrary graph $G(V,E)$ any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on $G$ has size at least $2^{\Omega(tw(G)^\delta)}$ for all $\delta &lt;1/36$, where $tw(G)$ is the treewidth of $G$ (for planar graphs and some other classes of graphs the statement holds for $\delta=1$). We also show an upper bound $O(|E| 2^{pw(G)})$, where $pw(G)$ is the pathwidth of $G$.

We apply the mentioned results in the analysis of the complexity of derivation in the proof system $OBDD(\land, reordering)$ and show that any $OBDD(\land, reordering)$-refutation of an unsatisfiable Tseitin formula based on a graph $G$ has size at least $2^{\Omega(tw(G)^\delta)}$.</summary>
    <updated>2019-02-19T18:23:06Z</updated>
    <published>2019-02-19T18:23:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-21T19:25:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-267883685398120378</id>
    <link href="http://blog.geomblog.org/feeds/267883685398120378/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/02/openai-ai-threats-and-norm-building-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/267883685398120378" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/267883685398120378" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/5TqtLogn5Gg/openai-ai-threats-and-norm-building-for.html" rel="alternate" type="text/html"/>
    <title>OpenAI, AI threats, and norm-building for responsible (data) science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">All of twitter is .... atwitter?... over the <a href="https://blog.openai.com/better-language-models/">OpenAI announcement</a> and partial non-release of code/documentation for a language model that purports to generate realistic-sounding text from simple prompts. The system actually addresses many NLP tasks, but the one that's drawing the most attention is the deepfakes-like generation of plausible news copy (<a href="https://blog.openai.com/better-language-models/#sample3">here's one sample</a>).<br/><br/>Most consternation is over the rapid PR buzz around the announcement, including somewhat breathless headlines (that OpenAI is not responsible for) like<br/><br/><blockquote class="tr_bq"><a href="https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/">OpenAI built a text generator so good, it’s considered too dangerous to release</a></blockquote>or<br/><blockquote class="tr_bq"><a href="https://arstechnica.com/information-technology/2019/02/researchers-scared-by-their-own-work-hold-back-deepfakes-for-text-ai/">Researchers, scared by their own work, hold back “deepfakes for text” AI</a></blockquote>There are concerns that OpenAI is overhyping solid but incremental work, that they're disingenuously allowing for overhyped coverage in the way they released the information, or worse that they're deliberately controlling hype as a publicity stunt.<br/><br/>I have nothing useful to add to the discussion above: indeed, see posts by <a href="https://anima-ai.org/2019/02/18/an-open-and-shut-case-on-openai/">Anima Anandkumar,</a> <a href="https://towardsdatascience.com/should-i-open-source-my-model-1c109188b164">Rob Munro</a>, <a href="http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/">Zachary Lipton</a>  and <a href="https://medium.com/@lowe.ryan.t/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8?sk=bc319cebc22fe0459574544828c84c6d">Ryan Lowe</a> for a comprehensive discussion of the issues relating to OpenAI.  Jack Clark from OpenAI has been engaging in a lot of twitter discussion on this as well.<br/><br/>But what I do want to talk about is the larger issues around responsible science that this kerfuffle brings up. Caveat, as Margaret Mitchell puts it in this searing thread.<br/><blockquote class="twitter-tweet"><div dir="ltr" lang="en">It's really hard to watch the GPT-2 conversations unfold like so much else in tech. 1/</div>— MMitchell (@mmitchell_ai) <a href="https://twitter.com/mmitchell_ai/status/1097626427048964098?ref_src=twsrc%5Etfw">February 18, 2019</a></blockquote><br/>To understand the kind of "norm-building" that needs to happen here, let's look at two related domains.<br/><br/>In computer security, there's a fairly well-established model for finding weaknesses in systems. An exploit is discovered, the vulnerable entity is given a chance to fix it, and then the exploit is revealed , often simultaneously with patches that rectify it. Sometimes the vulnerability isn't easily fixed (see <a href="https://meltdownattack.com/">Meltdown and Spectre</a>). But it's still announced.<br/><br/>A defining characteristic of security exploits is that they are targeted, specific and usually suggest a direct patch. The harms might be theoretical, but are still considered with as much seriousness as the exploit warrants.<br/><br/>Let's switch to a different domain: biology. Starting from the sequencing of the human genome through the <a href="https://allofus.nih.gov/">million-person precision medicine project </a>to CRISPR and cloning babies, genetic manipulation has provided both invaluable technology for curing disease as well as grave ethical concerns about misuse of the technology. And professional organizations as well as the NIH have (sometimes slowly) risen to the challenge of articulating norms around the use and misuse of such technology.<br/><br/>Here, the harms are often more diffuse, and the harms are harder to separate from the benefits. But the harm articulation is often focused on the individual patient, especially given the shadow of abuse that darkens the history of medicine.<br/><br/>The harms with various forms of AI/ML technology are myriad and diffuse. They can cause structural damage to society - in the concerns over bias, the ways in which automation affects labor, the way in which fake news can erode trust and a common frame of truth, and so many others - and they can cause direct harm to individuals. And the scale at which these harms can happen is immense.<br/><br/>So where are the professional groups, the experts in thinking about the risks of democratization of ML, and all the folks concerned about the harms associated with AI tech? Why don't we have the equivalent of the <a href="https://en.wikipedia.org/wiki/Asilomar_Conference_on_Recombinant_DNA">Asilomar conference on recombinant DNA</a>?<br/><br/>I appreciate that OpenAI has at least raised the issue of thinking through the ethical ramifications of releasing technology. But as the furore over their decision has shown, no single imperfect actor can really claim to be setting the guidelines for ethical technology release, and "starting the conversation" doesn't count when (again as Margaret Mitchell points out) these kinds of discussions have been going on in different settings for many years already.<br/><br/>Ryan Lowe suggests workshops at major machine learning conferences. That's not a bad idea. But it will attract the people who go to machine learning conferences. It won't bring in the journalists, the people getting SWAT'd (and one case <a href="https://en.wikipedia.org/wiki/2017_Wichita_swatting">killed</a>) by fake news, the women being harassed by trolls online with deep-fake porn images. <br/><br/>News is driven by news cycles. Maybe OpenAI's announcement will lead to us thinking more about issues of responsible data science. But let's not pretend these are new, or haven't been studied for a long time, or need to have a discussion "started".<br/><br/><br/><img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/5TqtLogn5Gg" width="1"/></div>
    </content>
    <updated>2019-02-19T16:00:00Z</updated>
    <published>2019-02-19T16:00:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="ethics"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/02/openai-ai-threats-and-norm-building-for.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="ethics"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-19T16:00:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/019" rel="alternate" type="text/html"/>
    <title>TR19-019 |  Towards Optimal Depth Reductions for Syntactically Multilinear Circuits | 

	Mrinal Kumar, 

	Rafael Mendes de Oliveira, 

	Ramprasad Saptharishi</title>
    <summary>We show that any $n$-variate polynomial computable by a syntactically multilinear circuit of size $\mathop{poly}(n)$ can be computed by a depth-$4$ syntactically multilinear ($\Sigma\Pi\Sigma\Pi$) circuit of size at most $\exp\left({O\left(\sqrt{n\log n}\right)}\right)$. For degree $d = \omega(n/\log n)$, this improves upon the upper bound of $\exp\left({O(\sqrt{d}\log n)}\right)$ obtained by Tavenas (MFCS 2015) for general circuits, and is known to be asymptotically optimal in the exponent when $d &lt; n^{\epsilon}$ for a small enough constant $\epsilon$. Our upper bound matches the lower bound of $\exp\left({\Omega\left(\sqrt{n\log n}\right)}\right)$ proved by Raz and Yehudayoff (CC 2009), and thus cannot be improved further in the exponent. Our results hold over all fields and also generalize to circuits of small individual degree.  

More generally, we show that an $n$-variate polynomial computable by a syntactically multilinear circuit of size $\mathop{poly}(n)$ can be computed by a syntactically multilinear circuit of product-depth $\Delta$ of size at most $\exp\left(O\left(\Delta \cdot (n/\log n)^{1/\Delta} \cdot \log n\right)\right)$. It follows from the lower bounds of Raz and Yehudayoff (CC 2009) that in general, for constant $\Delta$, the exponent in this upper bound is tight and cannot be improved to $o\left(\left(n/\log n\right)^{1/\Delta}\cdot \log n\right)$.</summary>
    <updated>2019-02-19T14:27:13Z</updated>
    <published>2019-02-19T14:27:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-21T19:25:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-335110421348004475</id>
    <link href="https://blog.computationalcomplexity.org/feeds/335110421348004475/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/335110421348004475" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/335110421348004475" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html" rel="alternate" type="text/html"/>
    <title>Using `who will be the dem VP choice' article in class</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I recently read an absurd article that speculated on who the Democratic VICE prez nominees will be. Yes, you read that right, VICE Prez. Gee, wouldn't knowing who the Prez nominees was first help. But leave it to Nate Silver and company to have a fascinating yet... premature article on this. Here is the link: <a href="https://fivethirtyeight.com/features/our-very-first-2020-vice-presidential-draft/">article on who will be Dem VP nominee</a>.  Its hard enough to pick the VP when the Prez is known! I did a blog on how badly intrade would do on predicting VP, <a href="https://blog.computationalcomplexity.org/2008/09/i-would-be-on-intrade-that-intrade-will.html">here</a>. I didn't predict that intrade would go out of business (`intrade' was short hand for `betting markets' just like `Uber' is shorthand for `hailing a car with your phone'- I wonder if the term `Uber' will still be used if they go out of business?)<br/>
<br/>
After reading I thought<br/>
<br/>
<i>Wow- there are so many If-Then clauses in this that I could make half a lecture about it for my Discrete Math class where we are talking about Prop. Logic.</i><br/>
<i><br/></i>
I emailed the students to read it, and we had a lively discussion. I made sure it was a non-partisan discussion. Realize that a statement like:<br/>
<br/>
<i>If the Prez is a female then the VP will likely be a male because it is thought, righly or wrongly, that all-female ticket can't win</i><br/>
<br/>
is not partisan or sexist, it is stating an opinion about how voters would go. It may be incorrect, but its not offensive.<br/>
<br/>
Here is what the class thought the article was saying (and I think they are right) expressed in Logic.<br/>
<br/>
Note one other thing-- the Prez nominees  might not be the choice of the party (Trump wasn't the choice of the Rep party in 2016, though not clear who was, see <a href="https://blog.computationalcomplexity.org/2015/05/the-law-of-excluded-middle-of-road.html">here</a>) but the VP really will be since (I think) the party has more control over that.<br/>
<br/>
If the Prez Nominees is female then the Vice Prez nominee will be male. (I agree)<br/>
<br/>
If the Prez Nominees is white mail then the Vice Prez nominee will be either female or non-white but not both. (Great question to express that as symbols. Not sure what I think- the thought is that two white males will be odd since so many of the candidates are female or non-white. Having said that, in recent years the VP has NOT been someone else who ran:  Clinton-Keane, Keane had not been a candidate, Trump-Pence, Pence had not been a candidate, Romney-Ryan, Ryan had not been a candidate, Obama-Biden, Biden had been a candidate briefly in 2008, but this was not one of these `lets unite the party by picking by OPPONENT to be VP', McCain-Palin, Palin had not been a candidate. Kerry-Edwards. YES- Edwards had been a serious candidate in 2004, though some think he was running for VP all along since he never said an unkind word about his opponents)<br/>
<br/>
Prez from one of the coasts IFF VP from the center. (I won't go over the list again, but this has been less of a thing since Clinton-Gore were both from flyover states.)<br/>
<br/>
Ideology- If Prez is establishment then VP is leftists. (Not sure these terms are so well defined to say this, and their are other ideologies as well, not sure how they fit in.)<br/>
<br/>
If Prez lacks Fed Experience then VP should have Fed Exp. (Quite common: Obama-Biden, Romney-Ryan, Clinton-Gore, Bush-Cheney)<br/>
<br/>If Prez has fed experience than nothing can be deduced about VP Fed Exp.<br/>
<br/>
If Prez lacks gravitas then VP should have gravitas (tricky! Don't want the VP to outshine the Prez!)<br/>
<br/>
Absolute statement: VP should not outshine prez. A Kangaroo ticket is when the people prefer the VP to the Prez (Dukakis-Bentsen had this problem. Kerry-Edwards might have).<br/>
<br/>
If Prez is boring then VP should be exciting. But again tricky! (I think that was why McCain picked Palin. And she was exciting, but not really in a good way. Couldn't he have picked someone exciting, and perhaps female who was, you know, Qualified?)<br/>
<br/>
VP's like doctors: do no harm.<br/>
<br/>
VP from Swing state helpful but not necc.<br/>
<br/>
Bad to have a VP who is a senator from a state where the Governor is republican and picks the replacement senator.<br/>
<br/>
VP should be someone who the country can picture being president without laughing. I am not talking ideology I am talking about seriousness and experience. Palin was the only one in recent memory who even voters of her party worried that she was not up to being president. One pundit defending the choice talked about how McCain was healthy and hence Palin wouldn't become prez so don't worry about it. NOT reassuring! Quayle was also not seen as serious, though not as much as Palin.<br/>
<br/>
If Prez is old then VP mattes more(?)<br/>
<br/>
Many of the above depend on who the Prez is. And that is one of the points: one can write down a long prop formula with many IF-THEN's to determine who properties the VP will have, and then<br/>
<br/>
1) When the Prez is picked many of the variables are set and hence the formula becomes much easeier and<br/>
<br/>
2) Could STILL be wrong!<br/>
<br/>
MY prediction: my last two predictions have been wrong so I am reluctant go predict anything. But I will tell you my WRONG predictions and then my current one<br/>
<br/>
I predicted Paul Ryan would be the Prez Nominee in 2016. He didn't even run.<br/>
<br/>
I predicted that Al Franken would be the Prez Nominess in 2020- he understands TV and was an entertainer, so he could match Trump. Whoops.<br/>
<br/>
So with that sterling record I predict: Prez: Cory Booker, VP: Beto<br/>
<br/>
I am NOT a pundit- so what I predict is not what I hope happens.  What do I hope? In the interest of full disclosure (gee, shouldn't that have come at the beginning) I admit that I want to see Trump lose but I have no idea what makes someone `electable' nowadays.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-19T13:27:00Z</updated>
    <published>2019-02-19T13:27:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-21T18:23:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/018</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/018" rel="alternate" type="text/html"/>
    <title>TR19-018 |  AC0[p] Lower Bounds against MCSP via the Coin Problem | 

	Valentine Kabanets, 

	Alexander Golovnev, 

	Rahul Ilango, 

	Russell Impagliazzo, 

	Antonina Kolokolova, 

	Avishay Tal</title>
    <summary>Minimum Circuit Size Problem (MCSP) asks to decide if a given truth table of an $n$-variate boolean function has circuit complexity less than a given parameter $s$. We prove that MCSP is hard for constant-depth circuits with mod $p$ gates, for any prime $p\geq 2$ (the circuit class $AC^0[p])$. Namely, we show that MCSP requires $d$-depth $AC^0[p]$ circuits of size at least $exp(N^{0.49/d})$, where $N=2^n$ is the size of an input truth table of an $n$-variate boolean function.  Our circuit lower bound proof shows that MCSP can solve the coin problem: distinguish uniformly random $N$-bit strings from those generated using independent samples from a biased random coin which is $1$ with probability $1/2+N^{-0.49}$, and $0$ otherwise. Solving the coin problem with such parameters is known to require exponentially large $AC^0[p]$ circuits. Moreover, this also implies that MAJORITY is computable by a non-uniform $AC^0$ circuit of polynomial size that also has MCSP-oracle gates. The latter has a few other consequences for the complexity of MCSP, e.g., we get that any boolean function in $NC^1$ (i.e., computable by a polynomial-size formula) can also be computed by a non-uniform polynomial-size $AC^0$ circuit with MCSP-oracle gates.</summary>
    <updated>2019-02-18T21:30:49Z</updated>
    <published>2019-02-18T21:30:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-21T19:25:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15645</id>
    <link href="https://rjlipton.wordpress.com/2019/02/18/have-ten-years-brought-us-closer/" rel="alternate" type="text/html"/>
    <title>Have Ten Years Brought Us Closer?</title>
    <summary>To solving the big questions, that is Cropped from Device Plus source Tetsuya Miyamoto is a mathematics teacher who divides his time between Tokyo and Manhattan. He is known for creating in 2004 the popular KenKen puzzle, which the New York Times started running ten years ago. As with its sister puzzles Sudoku and Kakuro, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>To solving the big questions, that is</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/miyamotodeviceplus.png"><img alt="" class="alignright size-thumbnail wp-image-15646" height="150" src="https://rjlipton.files.wordpress.com/2019/02/miyamotodeviceplus.png?w=150&amp;h=150" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Device Plus <a href="https://www.deviceplus.com/inspire/interviews/kenken-puzzle-inventors-tips-for-engineers/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Tetsuya Miyamoto is a mathematics teacher who divides his time between Tokyo and Manhattan. He is known for creating in 2004 the popular <a href="https://en.wikipedia.org/wiki/KenKen">KenKen</a> puzzle, which the New York Times started running ten years ago. As with its sister puzzles Sudoku and Kakuro, unlimited-size versions of it are <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-complete.</p>
<p>
Today we observe the 10th anniversary of this blog and ask what progress has been made on the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question.</p>
<p>
The <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> is a question about <em>asymptotic</em> complexity. From time to time we have tried to raise corresponding questions about <em>concrete</em> complexity that might yield more progress. What catches our eye about the KenKen puzzles is that their generation is a full-blown application within concrete complexity. The NYT’s KenKen puzzles are all generated using software by David Levy that can tailor their hardness. Quoting the NYT anniversary <a href="https://www.nytimes.com/2019/02/09/reader-center/kenken-puzzle-10th-anniversary.html">article</a> by Will Shortz:</p>
<blockquote><p><b> </b> <em>[Levy’s] program knows every possible method for solving a KenKen, which he has rated in difficulty from easy to hard. Thus, when a KenKen has been made, the computer knows exactly how hard it is. </em>
</p></blockquote>
<p/><p>
This seems to say there is a hardness measure that is objective—quite apart from the idea of having human testers try the puzzle and say how hard they found it to be. We surmise that it is lower for instances that have more forced plays at the start. We wonder whether Levy’s criteria can be generalized.</p>
<p>
Incidentally, this is the same Levy who won a challenge chess match in 1978 against the computer Chess 4.7 to complete his win of a famous ten-year $1,000+ <a href="https://en.wikipedia.org/wiki/David_Levy_(chess_player)#Computer_chess_bet">bet</a>. He lost $1,000 back when he was defeated by Deep Thought in 1989. He later became president of the International Computer Games Association (<a href="https://en.wikipedia.org/wiki/International_Computer_Games_Association">ICGA</a>), whose <a href="https://icga.org/?page_id=26"><em>Journal</em></a> published a nice <a href="https://www.cs.wmich.edu/elise/courses/cs431/icga2008.pdf">paper</a> on the <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-completess of the aforementioned puzzles and many others.</p>
<p>
</p><p/><h2> GLL’s Tenth Anniversary </h2><p/>
<p/><p>
GLL’s first <a href="https://rjlipton.wordpress.com/2009/02/12/bait-and-switch-why-lower-bounds-are-so-hard/">post</a>, on 12 Feb. 2009, featured Stephen Rudich and his work on the “<a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/natural.pdf">Natural</a> <a href="https://en.wikipedia.org/wiki/Natural_proof">Proofs</a>.” <a href="https://rjlipton.wordpress.com/2009/02/12/is-np-too-big-or-p-too-small/">Two</a> other <a href="https://rjlipton.wordpress.com/2009/02/12/a-nightmare-about-sat/">posts</a> that day covered other aspects of why the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question is hard. Our question, dear readers, is:</p>
<blockquote><p><b> </b> <em> Has anything happened in the past ten years to make any part of those posts out-of-date in the slightest way? </em>
</p></blockquote>
<p/><p>
We won’t claim any such progress, though we have tried to stir ideas. In the meantime, we have written 806 other posts:</p>
<ul>
<li>
Some have featured our own work and ideas (considering Ken’s chess research in a separate vein); <p/>
</li><li>
some have featured others’ direct attempts at breakthrough lower and upper bounds (with a few successes); <p/>
</li><li>
many have featured other kinds of results by others; <p/>
</li><li>
many have pulled “idea nuggets” from the past; <p/>
</li><li>
many have been humor and social commentary.
</li></ul>
<p>
To date, we’ve had 18,575 comments plus trackbacks on these posts and just over 2.1 million views. We are less able to quantify impacts, beyond occasionally seeing citations of articles on the blog as sources. We try for precision as well as readability and are grateful for reader comments with fixes when we slip up on the former.</p>
<p>
</p><p/><h2> P vs NP </h2><p/>
<p/><p>
There continue to be claims of proofs that <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/> and some that <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> While these proofs do not seem to be correct, there is something that we wish to remark about them. Many argue as follows: </p>
<blockquote><p><b> </b> <em> There is some problem say <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> that seems to require a search of exponentially many objects. Then the proof states that any algorithm for <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> must actually look at all or most of the exponentially many objects. This of course is where the proof is not complete. </em>
</p></blockquote>
<p/><p>
There is some sense to these proofs. They seem related to the oracle proofs that for example show that for some oracle set <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> it is the case that 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BP%7D%5E%7BA%7D+%5Cneq+%5Cmathsf%7BNP%7D%5E%7BA%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A}. "/></p>
<p>we have discussed these types of proofs before—we even said that we did not like them.</p>
<p>
The trouble with these results that are rigorous is that they change <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> vs <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> in a central manner, and this seems to make the results much less interesting. Roughly here is how they argue: Imagine that for each <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> we either put a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> into <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> or we do not. The point is that if we do this in a <i>unpredictable</i> manner then a polynomial time machine will not be able to decide whether for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> there is or is not a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. But a nondeterministic machine with just use its power and guess. This shows, essentially, that 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BP%7D%5E%7BA%7D+%5Cneq+%5Cmathsf%7BNP%7D%5E%7BA%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A} "/></p>
<p>is true.</p>
<p>
There is some relationship to many attempts to show <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/>. The proofs often argue that one must look at all the objects. The counterpart here is that a polynomial time machine will not have enough time to check the <img alt="{2^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n}}"/> strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to see if they are in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. But this works in the oracle case because we allow the rule that decides whether or not a string is in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> to be very complicated. In the real world, in the world where we study the real <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/> question, we cannot assume that <img alt="{NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{NP}"/>-complete problems use a complicated rule. <i>That is precisely what we are trying to prove</i>.</p>
<p>
</p><p/><h2> State of the Game </h2><p/>
<p/><p>
What can we say? Mostly the big open questions remain. We still have no non-linear lower bounds on circuit complexity and no progress of any definite kind on <img alt="{\mathsf{P}=\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}=\mathsf{NP}}"/>. What do you think?</p>
<p>
What is commonly hailed as one of the two biggest results in our field last year was a positive solution to what is intuitively a slightly weaker form of the Unique Games Conjecture (UGC). For UGC we can refer you to Wikipedia’s <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture">article</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2019/02/uniquegameswikipedia.png"><img alt="" class="aligncenter wp-image-15648" height="106" src="https://rjlipton.files.wordpress.com/2019/02/uniquegameswikipedia.png?w=400&amp;h=106" width="400"/></a></p>
<p/><p><br/>
The note [2] is in turn a reference to a 2010 <a href="https://rjlipton.wordpress.com/2010/05/05/unique-games-a-three-act-play/">post</a> here. The new <a href="https://eccc.weizmann.ac.il/report/2018/006/">paper</a> proves hardness for the relaxed situation where, roughly speaking, a trial assignment to a node in a constraint graph limits the other node on any connecting edge to at most two possible values, rather than a unique value as in UGC. This relaxation retains many properties that had caused disbelief in the original UGC, yet it was proved—in that sense a big deal. </p>
<p>
Nevertheless we note that UGC, at its core, is just asserting that for arbitrarily small <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>, with our power to make other parameter(s) as large as desired, we can execute an <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-hardness proof. We have been executing <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-hardness proofs for almost fifty years. That is something we in the field have proven good at. True, these hardness results becomes lower bound proofs if and when <img alt="{\mathsf{NP \neq P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP+%5Cneq+P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP \neq P}}"/> is proved, and true, we have been as vocal as any on the standpoint that significant lower bounds will come from constructions that are usually thought of as being for upper bounds. But the new proof from a year ago doesn’t feel like that. We invite readers to tell us connections from UGC to the possibility of actually constructing lower bounds.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We at GLL thank you all for your help and support these ten years. Ken and I plan to continue doing what we have done in the past. Plan on a visit from our special friend on St. Patrick’s day, for example. Thanks again and let us know how we are doing.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/02/dickken.png"><img alt="" class="aligncenter wp-image-15649" height="112" src="https://rjlipton.files.wordpress.com/2019/02/dickken.png?w=400&amp;h=112" width="400"/></a></p>
<p>
[fixed date of first GLL post]</p></font></font></div>
    </content>
    <updated>2019-02-18T21:14:51Z</updated>
    <published>2019-02-18T21:14:51Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="anniversary"/>
    <category term="Kenken"/>
    <category term="NP-complete"/>
    <category term="puzzles"/>
    <category term="Tetsuya Miyamoto"/>
    <category term="Unique Games Conjecture"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-21T19:26:09Z</updated>
    </source>
  </entry>
</feed>
