<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-07T15:21:38Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3470</id>
    <link href="https://agtb.wordpress.com/2020/04/07/call-for-papers-the-2nd-workshop-on-behavioral-economics-and-computation/" rel="alternate" type="text/html"/>
    <title>Call for Papers: The 2nd Workshop on Behavioral Economics and Computation</title>
    <summary>We solicit research contributions and participants for the 2nd Workshop on Behavioral Economics and Computation, to be held in conjunction with the Twenty-First ACM Conference on Economics and Computation (ACM EC '20).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><span><a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br/>
July 17, 2020, Budapest, Hungary<br/>
At the 21st ACM Conference on Economics and Computation (ACM EC ’20)</span></div>
<div><span>**In the event the in-person conference does not happen due to the COVID-19 pandemic, we will hold the workshop virtually.</span></div>
<div/>
<div><strong><span style="color: #ff0000;">SUBMISSIONS DUE May 18, 2020, 11:59pm PDT.</span></strong></div>
<div/>
<div/>
<div><strong>Call for Papers: the 2nd Workshop on Behavioral Economics and Computation</strong></div>
<div/>
<div><span>We solicit research contributions and participants for the 2nd Workshop on Behavioral Economics and Computation, to be held in conjunction with the Twenty-First ACM Conference on Economics and Computation (ACM EC ’20). </span></div>
<div/>
<div><span>Based on the successful workshop last year, we aim to bring together again researchers and practitioners from diverse subareas of EC, who are interested in the intersection of human economic behavior and computation, to share new results and to discuss future directions for behavioral research related to economics and computation. It will be a full-day workshop, and will feature invited speakers, contributed paper presentations and a panel discussion. </span></div>
<div/>
<div><span>The gap between rationality-based analysis that assumes utility-maximizing agents and actual human behavior in the real world has been well recognized in economics, psychology and other social sciences. In recent years, there has been growing interest in conducting behavioral research across many of the sub-areas related to economics and computation to address this gap. In one direction, some of these studies leverage insights on human decision making from the behavioral economics and psychology literature to study economic and computational systems with human users. In the other direction, computational tools are used to study and gain insights on human behavior and a data-driven approach is used to learn behavior models from user-generated data.</span></div>
<div><span><br/>
The 2nd Behavioral EC workshop aims to provide a venue for researchers and practitioners from diverse fields, including but not limited to computer science, economics, psychology and sociology, to exchange ideas related to behavioral research in economics and computation. In addition to sharing new results, we hope the workshop will foster a lively discussion of future directions and methodologies for behavioral research related to economics and computation as well as fruitful cross-pollination of behavioral economics, cognitive psychology and computer science. </span></div>
<div><span><br/>
We welcome studies at the intersection of economic behavior and computation from a rich set of theoretical, experimental and empirical perspectives. The topics of interest for the workshop are behavioral research in all settings covered by EC, including but not limited to:</span></div>
<ul>
<li><span>Behavioral mechanism design and applied mechanism design</span></li>
<li><span>Boundedly-rational models of economic decision making</span></li>
<li><span>Empirical studies of human economic behavior</span></li>
<li><span>Model evaluation and selection based on behavioral data</span></li>
<li><span>Data-driven modelling</span></li>
<li><span>Online prediction markets, online experiments, and crowdsourcing platforms</span></li>
<li><span>Hybrid human-machine systems</span></li>
<li><span>Models and experiments about social considerations (e.g. fairness and trust) in decision making</span></li>
<li><span>Methods for behavioral EC: information aggregation, probability elicitation, quality control</span></li>
</ul>
<div/>
<div/>
<div><span><strong>Submission Instructions</strong><br/>
</span></div>
<div/>
<div><span style="color: #ff0000;">Submission deadline: May 18, 2020, 11:59pm PDT.</span></div>
<div><span style="color: #ff0000;">Notification: June 11, 2020</span></div>
<div/>
<div><span>All submissions will be peer reviewed. We will give priority to new (unpublished) research papers but will also consider ongoing research and recently published papers that may be of interest to the workshop audience. For submissions of published papers, authors must clearly state the venue of publication. Position papers and panel discussion proposals are also welcome. Papers will be reviewed for relevance, significance, originality, research contribution, and likelihood to catalyze discussion. </span></div>
<div><span><br/>
Submissions can be in any format and any length. We recommend the EC submission format. </span><span>The workshop will not have archival proceedings but will post accepted papers on the workshop website. At least one author of each accepted paper will be expected to attend and present their findings at the workshop.<p/>
<p/></span></div>
<div><span>Submissions should be uploaded to Easychair no later than May 18th, 2020, 11:59pm PDT. </span></div>
<div/>
<div/>
<div><span><strong>Organizing Committee</strong><br/>
</span></div>
<div><span><br/>
Yiling Chen, Harvard University<br/>
Dan Goldstein, Microsoft Research<br/>
Kevin Leyton-Brown, University of British Columbia<br/>
Shengwu Li, Harvard University<br/>
Gali Noti, Hebrew University</span></div>
<div/>
<div><span><br/>
<strong>More Information</strong><br/>
</span></div>
<div><span><br/>
For more information or questions, visit the workshop website:<br/>
<a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br/>
or email the organizing committee: <a href="mailto:behavioralec2020@easychair.org">behavioralec2020@easychair.org</a></span></div>
			<div id="atatags-26942-5e8be264da029"/></div>
    </content>
    <updated>2020-04-07T02:15:59Z</updated>
    <published>2020-04-07T02:15:59Z</published>
    <category term="Uncategorized"/>
    <category term="Conferences"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-07T15:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02580</id>
    <link href="http://arxiv.org/abs/2004.02580" rel="alternate" type="text/html"/>
    <title>Distributed Processing of k Shortest Path Queries over Dynamic Road Networks</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Ziqiang.html">Ziqiang Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Xiaohui.html">Xiaohui Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koudas:Nick.html">Nick Koudas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang.html">Yang Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yifan.html">Yifan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yueting.html">Yueting Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Dingyu.html">Dingyu Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02580">PDF</a><br/><b>Abstract: </b>The problem of identifying the k-shortest paths (KSPs for short) in a dynamic
road network is essential to many location-based services. Road networks are
dynamic in the sense that the weights of the edges in the corresponding graph
constantly change over time, representing evolving traffic conditions. Very
often such services have to process numerous KSP queries over large road
networks at the same time, thus there is a pressing need to identify
distributed solutions for this problem. However, most existing approaches are
designed to identify KSPs on a static graph in a sequential manner (i.e., the
(i+1)-th shortest path is generated based on the i-th shortest path),
restricting their scalability and applicability in a distributed setting. We
therefore propose KSP-DG, a distributed algorithm for identifying k-shortest
paths in a dynamic graph. It is based on partitioning the entire graph into
smaller subgraphs, and reduces the problem of determining KSPs into the
computation of partial KSPs in relevant subgraphs, which can execute in
parallel on a cluster of servers. A distributed two-level index called DTLP is
developed to facilitate the efficient identification of relevant subgraphs. A
salient feature of DTLP is that it indexes a set of virtual paths that are
insensitive to varying traffic conditions, leading to very low maintenance cost
in dynamic road networks. This is the first treatment of the problem of
processing KSP queries over dynamic road networks. Extensive experiments
conducted on real road networks confirm the superiority of our proposal over
baseline methods.
</p></div>
    </summary>
    <updated>2020-04-07T01:23:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02570</id>
    <link href="http://arxiv.org/abs/2004.02570" rel="alternate" type="text/html"/>
    <title>Dynamic Ridesharing in Peak Travel Periods</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Hui.html">Hui Luo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bao:Zhifeng.html">Zhifeng Bao</a>, Farhana M. Choudhury, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Culpepper:J=_Shane.html">J. Shane Culpepper</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02570">PDF</a><br/><b>Abstract: </b>In this paper, we study a variant of the dynamic ridesharing problem with a
specific focus on peak hours: Given a set of drivers and rider requests, we aim
to match drivers to each rider request by achieving two objectives: maximizing
the served rate and minimizing the total additional distance, subject to a
series of spatio-temporal constraints. Our problem can be distinguished from
existing work in three aspects: (1) Previous work did not fully explore the
impact of peak travel periods where the number of rider requests is much
greater than the number of available drivers. (2) Existing solutions usually
rely on single objective optimization techniques, such as minimizing the total
travel cost. (3) When evaluating the overall system performance, the runtime
spent on updating drivers' trip schedules as per incoming rider requests should
be incorporated, while it is excluded by most existing solutions. We propose an
index structure together with a set of pruning rules and an efficient algorithm
to include new riders into drivers' existing trip schedule. To answer new rider
requests effectively, we propose two algorithms that match drivers with rider
requests. Finally, we perform extensive experiments on a large-scale test
collection to validate the proposed methods.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02554</id>
    <link href="http://arxiv.org/abs/2004.02554" rel="alternate" type="text/html"/>
    <title>Simultaneously Achieving Ex-ante and Ex-post Fairness</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aziz:Haris.html">Haris Aziz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02554">PDF</a><br/><b>Abstract: </b>We present a polynomial-time algorithm that computes an ex-ante envy-free
lottery over envy-free up to one item (EF1) deterministic allocations. It has
the following advantages over a recently proposed algorithm: it does not rely
on the linear programming machinery including separation oracles; it is
SD-efficient (both ex-ante and ex-post); and the ex-ante outcome is equivalent
to the outcome returned by the well-known probabilistic serial rule. As a
result, we answer a question raised by Freeman, Shah, and Vaish (2020) whether
the outcome of the probabilistic serial rule can be implemented by ex-post EF1
allocations. In the light of a couple of impossibility results that we prove,
our algorithm can be viewed as satisfying a maximal set of properties. Under
binary utilities, our algorithm is also ex-ante group-strategyproof and ex-ante
Pareto optimal. Finally, we also show that checking whether a given random
allocation can be implemented by a lottery over EF1 and Pareto optimal
allocations is coNP-complete.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02530</id>
    <link href="http://arxiv.org/abs/2004.02530" rel="alternate" type="text/html"/>
    <title>A Fast Algorithm for the Product Structure of Planar Graphs</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Morin:Pat.html">Pat Morin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02530">PDF</a><br/><b>Abstract: </b>Dujmovi\'c et al (FOCS2019) recently proved that every planar graph $G$ is a
subgraph of $H\boxtimes P$, where $\boxtimes$ denotes the strong graph product,
$H$ is a graph of treewidth 8 and $P$ is a path. This result has found numerous
applications to linear graph layouts, graph colouring, and graph labelling. The
proof given by Dujmovi\'c et al is based on a similar decomposition of
Pilipczuk and Siebertz (SODA2019) which is constructive and leads to an
$O(n^2)$ time algorithm for finding $H$ and the mapping from $V(G)$ onto
$V(H\boxtimes P)$. In this note, we show that this algorithm can be made to run
in $O(n\log n)$ time.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02502</id>
    <link href="http://arxiv.org/abs/2004.02502" rel="alternate" type="text/html"/>
    <title>Variable Shift SDD: A More Succinct Sentential Decision Diagram</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakamura:Kengo.html">Kengo Nakamura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Denzumi:Shuhei.html">Shuhei Denzumi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishino:Masaaki.html">Masaaki Nishino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02502">PDF</a><br/><b>Abstract: </b>The Sentential Decision Diagram (SDD) is a tractable representation of
Boolean functions that subsumes the famous Ordered Binary Decision Diagram
(OBDD) as a strict subset. SDDs are attracting much attention because they are
more succinct than OBDDs, as well as having canonical forms and supporting many
useful queries and transformations such as model counting and Apply operation.
In this paper, we propose a more succinct variant of SDD named Variable Shift
SDD (VS-SDD). The key idea is to create a unique representation for Boolean
functions that are equivalent under a specific variable substitution. We show
that VS-SDDs are never larger than SDDs and there are cases in which the size
of a VS-SDD is exponentially smaller than that of an SDD. Moreover, despite
such succinctness, we show that numerous basic operations that are supported in
polytime with SDD are also supported in polytime with VS-SDD. Experiments
confirm that VS-SDDs are significantly more succinct than SDDs when applied to
classical planning instances, where inherent symmetry exists.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02448</id>
    <link href="http://arxiv.org/abs/2004.02448" rel="alternate" type="text/html"/>
    <title>A limitation on the KPT interpolation</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jan Krajicek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02448">PDF</a><br/><b>Abstract: </b>We prove a limitation on a variant of the KPT theorem proposed for
propositional proof systems by Pich and Santhanam 2020, for all proof systems
that prove the disjointness of two NP sets that are hard to distinguish.
</p></div>
    </summary>
    <updated>2020-04-07T01:20:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02437</id>
    <link href="http://arxiv.org/abs/2004.02437" rel="alternate" type="text/html"/>
    <title>A historical note on the 3/2-approximation algorithm for the metric traveling salesman problem</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bevern:Ren=eacute=_van.html">René van Bevern</a>, Viktoriia A. Slugina <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02437">PDF</a><br/><b>Abstract: </b>One of the most fundamental results in combinatorial optimization is the
polynomial-time 3/2-approximation algorithm for the metric traveling salesman
problem. It was presented by Christofides in 1976 and is well known as "the
Christofides algorithm". Recently, some authors started calling it
"Christofides-Serdyukov algorithm", pointing out that the same result was
published independently in the USSR in 1978. We provide some historic
background on Serdyukov's findings and a translation of his article.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02425</id>
    <link href="http://arxiv.org/abs/2004.02425" rel="alternate" type="text/html"/>
    <title>The Bethe and Sinkhorn Permanents of Low Rank Matrices and Implications for Profile Maximum Likelihood</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shiragur:Kirankumar.html">Kirankumar Shiragur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02425">PDF</a><br/><b>Abstract: </b>In this paper we consider the problem of computing the likelihood of the
profile of a discrete distribution, i.e., the probability of observing the
multiset of element frequencies, and computing a profile maximum likelihood
(PML) distribution, i.e., a distribution with the maximum profile likelihood.
For each problem we provide polynomial time algorithms that given $n$ i.i.d.\
samples from a discrete distribution, achieve an approximation factor of
$\exp\left(-O(\sqrt{n} \log n) \right)$, improving upon the previous best-known
bound achievable in polynomial time of $\exp(-O(n^{2/3} \log n))$ (Charikar,
Shiragur and Sidford, 2019). Through the work of Acharya, Das, Orlitsky and
Suresh (2016), this implies a polynomial time universal estimator for symmetric
properties of discrete distributions in a broader range of error parameter.
</p>
<p>We achieve these results by providing new bounds on the quality of
approximation of the Bethe and Sinkhorn permanents (Vontobel, 2012 and 2014).
We show that each of these are $\exp(O(k \log(N/k)))$ approximations to the
permanent of $N \times N$ matrices with non-negative rank at most $k$,
improving upon the previous known bounds of $\exp(O(N))$. To obtain our results
on PML, we exploit the fact that the PML objective is proportional to the
permanent of a certain Vandermonde matrix with $\sqrt{n}$ distinct columns,
i.e. with non-negative rank at most $\sqrt{n}$. As a by-product of our work we
establish a surprising connection between the convex relaxation in prior work
(CSS19) and the well-studied Bethe and Sinkhorn approximations.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02342</id>
    <link href="http://arxiv.org/abs/2004.02342" rel="alternate" type="text/html"/>
    <title>Nonlinear Function Inversion using k-vector</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arnas:David.html">David Arnas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mortari:Daniele.html">Daniele Mortari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02342">PDF</a><br/><b>Abstract: </b>This work introduces a general numerical technique to invert one dimensional
analytic or tabulated nonlinear functions in assigned ranges of interest. The
proposed approach is based on an optimal version of the k-vector range
searching, an ad-hoc modification devised for function inversion. The
optimality consists of retrieving always the same number of data ($1,2,\dots$)
for a specified searching range to initiate the root solver. This provides
flexibility to adapt the technique to a variety of root solvers (e.g.,
bisection, Newton, etc.), using a specified number of starting points. The
proposed method allows to build an inverse function toolbox for a set of
specified nonlinear functions. In particular, the method is suitable when
intensive inversions of the same function are required. The inversion is
extremely fast (almost instantaneous), but it requires a one-time preprocessing
effort.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02339</id>
    <link href="http://arxiv.org/abs/2004.02339" rel="alternate" type="text/html"/>
    <title>Random Sampling using k-vector</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arnas:David.html">David Arnas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leake:Carl.html">Carl Leake</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mortari:Daniele.html">Daniele Mortari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02339">PDF</a><br/><b>Abstract: </b>This work introduces two new techniques for random number generation with any
prescribed nonlinear distribution based on the k-vector methodology. The first
approach is based on inverse transform sampling using the optimal k-vector to
generate the samples by inverting the cumulative distribution. The second
approach generates samples by performing random searches in a pre-generated
large database previously built by massive inversion of the prescribed
nonlinear distribution using the k-vector. Both methods are shown suitable for
massive generation of random samples. Examples are provided to clarify these
methodologies.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02338</id>
    <link href="http://arxiv.org/abs/2004.02338" rel="alternate" type="text/html"/>
    <title>On the Tandem Duplication Distance</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cicalese:Ferdinando.html">Ferdinando Cicalese</a>, Nicolò Pilati <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02338">PDF</a><br/><b>Abstract: </b>A tandem duplication denotes the process of inserting a copy of a segment of
DNA adjacent to its original position. More formally, a tandem duplication can
be thought of as an operation that converts a string $S = AXB$ into a string $T
= AXXB,$ and is denoted by $S \Rightarrow T.$ As they appear to be involved in
genetic disorders, tandem duplications are widely studied in computational
biology. Also, tandem duplication mechanisms have been recently studied in
different contexts, from formal languages, to information theory, to
error-correcting codes for DNA storage systems.
</p>
<p>The problem of determining the complexity of computing the tandem duplication
distance between two given strings was proposed by [Leupold et al., 2004] and,
very recently, it was shown to be NP-hard for the case of unbounded alphabets
[Lafond et al., 2019]. In this paper, we significantly improve this result and
show that the tandem duplication "distance problem" is NP-hard already for the
case of strings over an alphabet of size $\leq 5.$ We also consider the
"existence problem": given strings $S$ and $T$ over the same alphabet, decide
whether there exists a sequence of duplications converting $S$ into $T$. A
polynomial time algorithm that solves this (existence) problem was only known
for the case of the binary alphabet. We focus on a special class of
strings---here referred to as "purely alternating"---that generalize the
special structure of binary strings to larger alphabets. We show that for the
case of purely alternating strings from an alphabet of size $\leq 5$, the
existence problem can be solved in linear time.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02335</id>
    <link href="http://arxiv.org/abs/2004.02335" rel="alternate" type="text/html"/>
    <title>The n-dimensional k-vector and its application to orthogonal range searching</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arnas:David.html">David Arnas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leake:Carl.html">Carl Leake</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mortari:Daniele.html">Daniele Mortari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02335">PDF</a><br/><b>Abstract: </b>This work focuses on the definition and study of the n-dimensional k-vector,
an algorithm devised to perform orthogonal range searching in static databases
with multiple dimensions. The methodology first finds the order in which to
search the dimensions, and then, performs the search using a modified
projection method. In order to determine the dimension order, the algorithm
uses the k-vector, a range searching technique for one dimension that
identifies the number of elements contained in the searching range. Then, using
this information, the algorithm predicts and selects the best approach to deal
with each dimension. The algorithm has a worst case complexity of
$\mathcal{O}(nd(k/n)^{2/d})$, where $k$ is the number of elements retrieved,
$n$ is the number of elements in the database, and $d$ is the number of
dimensions of the database. This work includes a detailed description of the
methodology as well as a study of the algorithm performance.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02298</id>
    <link href="http://arxiv.org/abs/2004.02298" rel="alternate" type="text/html"/>
    <title>Maximum parsimony distance on phylogenetictrees: a linear kernel and constant factor approximation algorithm</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Mark.html">Mark Jones</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kelk:Steven.html">Steven Kelk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stougie:Leen.html">Leen Stougie</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02298">PDF</a><br/><b>Abstract: </b>Maximum parsimony distance is a measure used to quantify the dissimilarity of
two unrooted phylogenetic trees. It is NP-hard to compute, and very few
positive algorithmic results are known due to its complex combinatorial
structure. Here we address this shortcoming by showing that the problem is
fixed parameter tractable. We do this by establishing a linear kernel i.e.,
that after applying certain reduction rules the resulting instance has size
that is bounded by a linear function of the distance. As powerful corollaries
to this result we prove that the problem permits a polynomial-time
constant-factor approximation algorithm; that the treewidth of a natural
auxiliary graph structure encountered in phylogenetics is bounded by a function
of the distance; and that the distance is within a constant factor of the size
of a maximum agreement forest of the two trees, a well studied object in
phylogenetics.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02290</id>
    <link href="http://arxiv.org/abs/2004.02290" rel="alternate" type="text/html"/>
    <title>A new hashing based nearest neighbors selection technique for big datasets</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tchaye=Kondi:Jude.html">Jude Tchaye-Kondi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhai:Yanlong.html">Yanlong Zhai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Liehuang.html">Liehuang Zhu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02290">PDF</a><br/><b>Abstract: </b>KNN has the reputation to be the word simplest but efficient supervised
learning algorithm used for either classification or regression. KNN prediction
efficiency highly depends on the size of its training data but when this
training data grows KNN suffers from slowness in making decisions since it
needs to search nearest neighbors within the entire dataset at each decision
making. This paper proposes a new technique that enables the selection of
nearest neighbors directly in the neighborhood of a given observation. The
proposed approach consists of dividing the data space into subcells of a
virtual grid built on top of data space. The mapping between the data points
and subcells is performed using hashing. When it comes to select the nearest
neighbors of a given observation, we firstly identify the cell the observation
belongs by using hashing, and then we look for nearest neighbors from that
central cell and cells around it layer by layer. From our experiment
performance analysis on publicly available datasets, our algorithm outperforms
the original KNN in time efficiency with a prediction quality as good as that
of KNN it also offers competitive performance with solutions like KDtree
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02282</id>
    <link href="http://arxiv.org/abs/2004.02282" rel="alternate" type="text/html"/>
    <title>Clique-Width of Point Configurations</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Onur Çağırıcı, Petr Hliněný, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pokr=yacute=vka:Filip.html">Filip Pokrývka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankaran:Abhisekh.html">Abhisekh Sankaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02282">PDF</a><br/><b>Abstract: </b>While structural width parameters (of the input) belong to the standard
toolbox of graph algorithms, it is not the usual case in computational
geometry. As a case study we propose a natural extension of the structural
graph parameter of clique-width to geometric point configurations represented
by their order type. We study basic properties of this clique-width notion, and
relate it to the monadic second-order logic of point configurations. As an
application, we provide several linear FPT time algorithms for geometric point
problems which are NP-hard in general, in the special case that the input point
set is of bounded clique-width and the clique-width expression is also given.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02227</id>
    <link href="http://arxiv.org/abs/2004.02227" rel="alternate" type="text/html"/>
    <title>A simple proof for visibility paths in simple polygons</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zarrabi:Mohammad_Reza.html">Mohammad Reza Zarrabi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charkari:Nasrollah_Moghaddam.html">Nasrollah Moghaddam Charkari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02227">PDF</a><br/><b>Abstract: </b>The purpose of this note is to give a simple proof for a necessary and
sufficient condition for visibility paths in simple polygons. A visibility path
is a curve such that every point in the simple polygon is visible from at least
one point of the path. This result is required for the shortest watchman route
problem specially when the route is restricted to curved paths.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02220</id>
    <link href="http://arxiv.org/abs/2004.02220" rel="alternate" type="text/html"/>
    <title>Query-points visibility constraint minimum link paths in simple polygons</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zarrabi:Mohammad_Reza.html">Mohammad Reza Zarrabi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charkari:Nasrollah_Moghaddam.html">Nasrollah Moghaddam Charkari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02220">PDF</a><br/><b>Abstract: </b>We study the query version of constrained minimum link paths between two
points inside a simple polygon with $n$ vertices such that there is at least
one point on the path, visible from a query point. Initially, we solve this
problem for two given points $s$, $t$ and a query point $q$. Then, the proposed
solution would be extended to a general case for three arbitrary query points
$s$, $t$ and $q$. In the former, we propose an algorithm with $O(n)$
preprocessing time. Extending this approach for the latter case, we develop an
algorithm with $O(n^3)$ preprocessing time. The link distance between $s$, $t$
with visibility $q$, and its path are provided in time $O(\log n)$ and
$O(k+\log n)$ for the above two cases, where $k$ is the number of links.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02163</id>
    <link href="http://arxiv.org/abs/2004.02163" rel="alternate" type="text/html"/>
    <title>On the Convergence Analysis of Asynchronous SGD for Solving Consistent Linear Systems</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sahu:Atal_Narayan.html">Atal Narayan Sahu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dutta:Aritra.html">Aritra Dutta</a>, Aashutosh Tiwari, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Richt=aacute=rik:Peter.html">Peter Richtárik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02163">PDF</a><br/><b>Abstract: </b>In the realm of big data and machine learning, data-parallel, distributed
stochastic algorithms have drawn significant attention in the present
days.~While the synchronous versions of these algorithms are well understood in
terms of their convergence, the convergence analyses of their asynchronous
counterparts are not widely studied. In this paper, we propose and analyze a
{\it distributed, asynchronous parallel} SGD in light of solving an arbitrary
consistent linear system by reformulating the system into a stochastic
optimization problem as studied by Richt\'{a}rik and Tak\'{a}\~{c} in [35]. We
compare the convergence rates of our asynchronous SGD algorithm with the
synchronous parallel algorithm proposed by Richt\'{a}rik and Tak\'{a}\v{c} in
[35] under different choices of the hyperparameters---the stepsize, the damping
factor, the number of processors, and the delay factor. We show that our
asynchronous parallel SGD algorithm also enjoys a global linear convergence
rate, similar to the {\em basic} method and the synchronous parallel method in
[35] for solving any arbitrary consistent linear system via stochastic
reformulation. We also show that our asynchronous parallel SGD improves upon
the {\em basic} method with a better convergence rate when the number of
processors is larger than four. We further show that this asynchronous approach
performs asymptotically better than its synchronous counterpart for certain
linear systems. Moreover, for certain linear systems, we compute the minimum
number of processors required for which our asynchronous parallel SGD is
better, and find that this number can be as low as two for some ill-conditioned
problems.
</p></div>
    </summary>
    <updated>2020-04-07T01:21:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02137</id>
    <link href="http://arxiv.org/abs/2004.02137" rel="alternate" type="text/html"/>
    <title>Anomaly Detection and Prototype Selection Using Polyhedron Curvature</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghojogh:Benyamin.html">Benyamin Ghojogh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karray:Fakhri.html">Fakhri Karray</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crowley:Mark.html">Mark Crowley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02137">PDF</a><br/><b>Abstract: </b>We propose a novel approach to anomaly detection called Curvature Anomaly
Detection (CAD) and Kernel CAD based on the idea of polyhedron curvature. Using
the nearest neighbors for a point, we consider every data point as the vertex
of a polyhedron where the more anomalous point has more curvature. We also
propose inverse CAD (iCAD) and Kernel iCAD for instance ranking and prototype
selection by looking at CAD from an opposite perspective. We define the concept
of anomaly landscape and anomaly path and we demonstrate an application for it
which is image denoising. The proposed methods are straightforward and easy to
implement. Our experiments on different benchmarks show that the proposed
methods are effective for anomaly detection and prototype selection.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02129</id>
    <link href="http://arxiv.org/abs/2004.02129" rel="alternate" type="text/html"/>
    <title>#P-completeness of counting update digraphs, cacti, and a series-parallel decomposition method</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Camille Noûs, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perrot:K=eacute=vin.html">Kévin Perrot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sen=eacute=:Sylvain.html">Sylvain Sené</a>, Lucas Venturini <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02129">PDF</a><br/><b>Abstract: </b>Automata networks are a very general model of interacting entities, with
applications to biological phenomena such as gene regulation. In many contexts,
the order in which entities update their state is unknown, and the dynamics may
be very sensitive to changes in this schedule of updates. Since the works of
Aracena et. al, it is known that update digraphs are pertinent objects to study
non-equivalent block-sequential update schedules. We prove that counting the
number of equivalence classes, that is a tight upper bound on the synchronism
sensitivity of a given network, is #P-complete. The problem is nevertheless
computable in quasi-quadratic time for oriented cacti, and for oriented
series-parallel graphs thanks to a decomposition method.
</p></div>
    </summary>
    <updated>2020-04-07T01:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02089</id>
    <link href="http://arxiv.org/abs/2004.02089" rel="alternate" type="text/html"/>
    <title>Event Clustering &amp; Event Series Characterization on Expected Frequency</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Conrad M Albrecht, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freitag:Marcus.html">Marcus Freitag</a>, Theodore G van Kessel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Siyuan.html">Siyuan Lu</a>, Hendrik F Hamann <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02089">PDF</a><br/><b>Abstract: </b>We present an efficient clustering algorithm applicable to one-dimensional
data such as e.g. a series of timestamps. Given an expected frequency $\Delta
T^{-1}$, we introduce an $\mathcal{O}(N)$-efficient method of characterizing
$N$ events represented by an ordered series of timestamps $t_1,t_2,\dots,t_N$.
In practice, the method proves useful to e.g. identify time intervals of
"missing" data or to locate "isolated events". Moreover, we define measures to
quantify a series of events by varying $\Delta T$ to e.g. determine the quality
of an Internet of Things service.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02066</id>
    <link href="http://arxiv.org/abs/2004.02066" rel="alternate" type="text/html"/>
    <title>Girth-reducibility and the algorithmic barrier for coloring</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iliopoulos:Fotis.html">Fotis Iliopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02066">PDF</a><br/><b>Abstract: </b>All known efficient algorithms for constraint satisfaction problems are
stymied by random instances. For example, no efficient algorithm is known that
can q-color a random graph with average degree (1 + \epsilon)q \ln q, even
though random graphs remain q-colorable for average degree up to (2-o(1)) q \ln
q. Similar failure to find solutions at relatively low constraint densities is
known for random CSPs such as random k-SAT and other hypergraph-based problems.
The constraint density where algorithms break down for each CSP is known as the
"algorithmic barrier" and provably corresponds to a phase transition in the
geometry of the space of solutions [Achlioptas and Coja-Oghlan 2008]. In this
paper we aim to shed light on the following question: Can algorithmic success
up to the barrier for each CSP be ascribed to some simple deterministic
property of the inputs?
</p>
<p>We answer this question positively for graph coloring by identifying the
property of \emph{girth-reducibility}. We prove that every girth-reducible
graph of average degree (1-o(1) )q \ln q is efficiently q-colorable and that
the threshold for girth reducibility of random graphs coincides with the
algorithmic barrier. Thus, we link the tractability of graph coloring up to the
algorithmic barrier to a single deterministic property. Our main theorem
actually extends to coloring k-uniform hypergraphs. As such, we believe that it
is an important first step towards discovering the structural properties behind
the tractability of arbitrary k-CSPs for constraint densities up to the
algorithmic barrier.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.02035</id>
    <link href="http://arxiv.org/abs/2004.02035" rel="alternate" type="text/html"/>
    <title>Correction to: A Practical, Provably Linear Time, In-place and Stable Merge Algorithm via the Perfect Shuffle</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ellis:John.html">John Ellis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stege:Ulrike.html">Ulrike Stege</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.02035">PDF</a><br/><b>Abstract: </b>We correct a paper previously submitted to CoRR. That paper claimed that the
algorithm there described was provably of linear time complexity in the average
case. The alleged proof of that statement contained an error, being based on an
invalid assumption, and is invalid. In this paper we present both experimental
and analytical evidence that the time complexity is of order $N^2$ in the
average case, where $N$ is the total length of the merged sequences.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01939</id>
    <link href="http://arxiv.org/abs/2004.01939" rel="alternate" type="text/html"/>
    <title>A Lower Bound for Byzantine Agreement and Consensus for Adaptive Adversaries using VDFs</title>
    <feedworld_mtime>1586217600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dryja:Thaddeus.html">Thaddeus Dryja</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Quanquan_C=.html">Quanquan C. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narula:Neha.html">Neha Narula</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01939">PDF</a><br/><b>Abstract: </b>Large scale cryptocurrencies require the participation of millions of
participants and support economic activity of billions of dollars, which has
led to new lines of work in binary Byzantine Agreement (BBA) and consensus. The
new work aims to achieve communication-efficiency---given such a large $n$, not
everyone can speak during the protocol. Several protocols have achieved
consensus with communication-efficiency, even under an adaptive adversary, but
they require additional strong assumptions---proof-of-work, memory-erasure,
etc. All of these protocols use multicast: every honest replica multicasts
messages to all other replicas. Under this model, we provide a new
communication-efficient consensus protocol using Verifiable Delay Functions
(VDFs) that is secure against adaptive adversaries and does not require the
same strong assumptions present in other protocols.
</p>
<p>A natural question is whether we can extend the synchronous protocols to the
partially synchronous setting---in this work, we show that using multicast, we
cannot. Furthermore, we cannot achieve always safe communication-efficient
protocols (that maintain safety with probability 1) even in the synchronous
setting against a static adversary when honest replicas only choose to
multicast its messages. Considering these impossibility results, we describe a
new communication-efficient BBA protocol in a modified partially synchronous
network model which is secure against adaptive adversaries with high
probability.
</p></div>
    </summary>
    <updated>2020-04-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3272927110650993879</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3272927110650993879/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/return-of-vidcast.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3272927110650993879" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3272927110650993879" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/return-of-vidcast.html" rel="alternate" type="text/html"/>
    <title>Return of the Vidcast</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Bill and I just have a <a href="https://youtu.be/VTX3yiPri5c">discussion</a>, virtually of course.
<br/><br/>
<div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-04-06T21:36:00Z</updated>
    <published>2020-04-06T21:36:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-07T04:40:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/04/06/professorship-in-theoretical-computer-science-at-university-of-copenhagen-apply-by-may-24-2020/</id>
    <link href="https://cstheory-jobs.org/2020/04/06/professorship-in-theoretical-computer-science-at-university-of-copenhagen-apply-by-may-24-2020/" rel="alternate" type="text/html"/>
    <title>Professorship in Theoretical Computer Science at University of Copenhagen (apply by May 24, 2020)</title>
    <summary>University of Copenhagen is seeking candidates for a full professorship in Theoretical Computer Science. More specifically, we are inviting exceptional candidates from the broad fields of algorithms, complexity, and cryptography including privacy. The application deadline is May 24, 2020. Enquiries are welcome and may be sent to Mikkel Thorup (mthorup@di.ku.dk) or Mads Nielsen (madsn@di.ku.dk). Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>University of Copenhagen is seeking candidates for a full professorship in Theoretical Computer Science. More specifically, we are inviting exceptional candidates from the broad fields of algorithms, complexity, and cryptography including privacy. The application deadline is May 24, 2020. Enquiries are welcome and may be sent to Mikkel Thorup (mthorup@di.ku.dk) or Mads Nielsen (madsn@di.ku.dk).</p>
<p>Website: <a href="https://candidate.hr-manager.net/ApplicationInit.aspx/?cid=1307&amp;departmentId=18971&amp;ProjectId=151668">https://candidate.hr-manager.net/ApplicationInit.aspx/?cid=1307&amp;departmentId=18971&amp;ProjectId=151668</a><br/>
Email: mthorup@di.ku.dk</p></div>
    </content>
    <updated>2020-04-06T19:13:00Z</updated>
    <published>2020-04-06T19:13:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-04-07T15:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16911</id>
    <link href="https://rjlipton.wordpress.com/2020/04/05/not-as-easy-as-abc/" rel="alternate" type="text/html"/>
    <title>Not As Easy As ABC</title>
    <summary>Is the claimed proof of the ABC conjecture correct? [ Photo courtesy of Kyodo University ] Shinichi Mochizuki is about to have his proof of the ABC conjecture published in a journal. The proof needs more than a ream of paper—that is, it is over 500 pages long. Today I thought we would discuss his […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Is the claimed proof of the ABC conjecture correct?</em><br/>
<font color="#000000"/></p><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/05/not-as-easy-as-abc/screen-shot-2020-04-05-at-8-22-38-pm/" rel="attachment wp-att-16914"><img alt="" class="alignright size-medium wp-image-16914" height="238" src="https://rjlipton.files.wordpress.com/2020/04/screen-shot-2020-04-05-at-8.22.38-pm.png?w=300&amp;h=238" width="300"/></a><p/>
<p>
<font color="#0044cc">
</font></p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Photo courtesy of Kyodo University ]</font></td>
</tr>
</tbody>
</table>
<p>
Shinichi Mochizuki is about to have his proof of the ABC conjecture <a href="https://futurism.com/the-byte/mathematicians-shocked-paper-published">published</a> in a journal. The proof needs more than a ream of paper—that is, it is over 500 pages long. </p>
<p>
Today I thought we would discuss his claimed proof of this famous conjecture.</p>
<p>
The decision to published is also discussed in an <a href="https://www.nature.com/articles/d41586-020-00998-2">article</a> in <em>Nature</em>. Some of the discussion we have seen <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">elsewhere</a> has been about personal factors. We will just comment briefly on the problem, the proof, and how to tell if a proof has problems. </p>
<p>
</p><p/><h2> The Problem </h2><p/>
<p/><p>
Number theory is hard because addition and multiplication do not play well together. Adding numbers is not too complex by its self; multiplication by its self is also not too hard. For those into formal logic the theory of addition for example is decidable. So in principle there is no hard problem that only uses addition. None. A similar point follows for multiplication. </p>
<p>
But together addition and multiplication is hard. Of course Kurt Gödel proved that the formal theory of arithmetic is hard. It is not complete, for example. There must be statements about addition and multiplication that are unprovable in Peano Arithmetic. </p>
<p>
The ABC conjecture states a property that is between addition and multiplication. Suppose that 	</p>
<p align="center"><img alt="\displaystyle  A + B = C, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A+%2B+B+%3D+C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A + B = C, "/></p>
<p>for some integers <img alt="{1 \le A \le B \le C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+A+%5Cle+B+%5Cle+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le A \le B \le C}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  C \le ABC " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le ABC "/></p>
<p>is trivial. The ABC conjecture says that one can do better and get 	</p>
<p align="center"><img alt="\displaystyle  C \le F(ABC), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le F(ABC), "/></p>
<p>for a function <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/> that is sometimes much smaller than <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. The function <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/> depends not on the size of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> but on the multiplicative structure of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. That is the function depends on the multiplicative structure of the integers. Note, the bound 	</p>
<p align="center"><img alt="\displaystyle  C \le ABC " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le ABC "/></p>
<p>only needed that <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/> were numbers larger than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The stronger bound 	</p>
<p align="center"><img alt="\displaystyle  C \le F(ABC), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le F(ABC), "/></p>
<p>relies essentially on the finer structure of the integers. </p>
<p>
Roughly <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/> operates as follows: Compute all the primes <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> that divide <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. Let <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> be the product of all these primes. Then <img alt="{F(X) \le Q^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29+%5Cle+Q%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X) \le Q^{2}}"/> works: 	</p>
<p align="center"><img alt="\displaystyle  C \le Q^{2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+Q%5E%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le Q^{2}. "/></p>
<p>The key point is: <i>Even if <img alt="{p^{100}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B100%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p^{100}}"/>, for example, divides <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, we only include <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> in the product <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>.</i> This is where the savings all comes from. This is why the ABC conjecture is hard: repeated factors are thrown away.</p>
<p>
Well not exactly, there is a constant missing here, the bound is 	</p>
<p align="center"><img alt="\displaystyle  C \le \alpha Q^{2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+%5Calpha+Q%5E%7B2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le \alpha Q^{2} "/></p>
<p>where <img alt="{\alpha&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha&gt;0}"/> is a universal constant. We can replace <img alt="{Q^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q^{2}}"/> by a smaller number—the precise statement can be found <a href="https://en.wikipedia.org/wiki/Abc_conjecture">here</a>. This is the ABC conjecture. </p>
<p>
The point here is that in many cases <img alt="{F(ABC)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28ABC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(ABC)}"/> is vastly smaller than <img alt="{ABC}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ABC}"/> and so that inequality 	</p>
<p align="center"><img alt="\displaystyle  C \le F(ABC), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le F(ABC), "/></p>
<p>is much better than the obvious one of 	</p>
<p align="center"><img alt="\displaystyle  C \le ABC. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le ABC. "/></p>
<p>For example, suppose that one wishes to know if 	</p>
<p align="center"><img alt="\displaystyle  5^{z} = 2^{x} + 3^{y}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++5%5E%7Bz%7D+%3D+2%5E%7Bx%7D+%2B+3%5E%7By%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  5^{z} = 2^{x} + 3^{y}, "/></p>
<p>is possible. The ABC conjecture shows that this cannot happen for <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> large enough. Note 	</p>
<p align="center"><img alt="\displaystyle  F(2^{x} 3^{y} 5^{z}) = 30 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%282%5E%7Bx%7D+3%5E%7By%7D+5%5E%7Bz%7D%29+%3D+30+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(2^{x} 3^{y} 5^{z}) = 30 "/></p>
<p>for positive integers <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/>.</p>
<p>
</p><p/><h2> Is He Correct? </h2><p/>
<p/><p>
Eight years ago Mochizuki announced his <a href="http://www.kurims.kyoto-u.ac.jp/~motizuki/papers-english.html">proof</a>. Now it is about to be published in a journal. He is famous for work in part of number theory. He solved a major open problem there years ago. This gave him instant credibility and so his claim of solving the ABC conjecture was taken seriously. </p>
<p>
For example, one of his papers is <a href="https://www.math.uni-bielefeld.de/documenta/vol-kato/mochizuki.dm.pdf">The Absolute Anabelian Geometry of Canonical Curves</a>. The paper says: </p>
<blockquote><p><b> </b> <em> How much information about the isomorphism class of the variety <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> is contained in the knowledge of the étale fundamental group? </em>
</p></blockquote>
<p/><p>
A glance at this paper shows that it is for specialists only. But it does seem to be math of the type that we see all the time. And indeed the proof in his paper is long believed to be correct. This is in sharp contrast to his proof of the ABC conjecture. </p>
<p>
</p><p/><h2> Indicators of Correctness </h2><p/>
<p/><p>
The question is: Are there ways to detect if a proof is (in)correct? Especially <a href="https://en.wikipedia.org/wiki/List_of_long_mathematical_proofs">long</a> proofs? Are there ways that rise above just checking the proof line by line? By the way:</p>
<blockquote><p><b> </b> <em> The length of unusually long proofs has increased with time. As a rough rule of thumb, 100 pages in 1900, or 200 pages in 1950, or 500 pages in 2000 is unusually long for a proof. </em>
</p></blockquote>
<p/><p>
There are some ways to gain confidence. Here are some in my opinion that are useful.</p>
<ol>
<li>
Is the proof understood by the experts? <p/>
</li><li>
Has the proof been generalized? <p/>
</li><li>
Have new proofs been found? <p/>
</li><li>
Does the proof have a clear roadmap?
</li></ol>
<p>
The answer to the first question (1) seems to be no for the ABC proof. At least two world experts have raised concerns—see this <a href="https://www.quantamagazine.org/titans-of-mathematics-clash-over-epic-proof-of-abc-conjecture-20180920/">article</a> in <em>Quanta</em>—that appear serious. The proof has not yet been generalized. This is an important milestone for any proof. Andrew Wiles famous proof that the Fermat equation 	</p>
<p align="center"><img alt="\displaystyle  x^{p} + y^{p} = z^{p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bp%7D+%2B+y%5E%7Bp%7D+%3D+z%5E%7Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{p} + y^{p} = z^{p}, "/></p>
<p>has no solutions in integers for <img alt="{xyz \neq 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bxyz+%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{xyz \neq 0}"/> and <img alt="{p \ge 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%5Cge+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p \ge 3}"/> a prime has been extended. This certainly adds confidence to our belief that it is correct.</p>
<p>
Important problems eventually get other proofs. This can take some time. But there is almost always success in finding new and different proofs. Probably it is way too early for the ABC proof, but we can hope. Finally the roadmap issue: This means does the argument used have a nice logical flow. Proofs, even long proofs, often have a logic flow that is not too complex. A proof that says: Suppose there is a object <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> with this property. Then it follows that there must be an object <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> so that <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> Is more believable than one with a much more convoluted logical flow. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Ivan Fesenko of Nottingham has written an <a href="https://www.maths.nottingham.ac.uk/plp/pmzibf/rpp.pdf">essay</a> about the proof and the decision to publish. Among factors he notes is “the potential lack of mathematical infrastructure and language to communicate novel concepts and methods”—noting the steep learning curve of trying to grasp the language and framework in which Mochizuki has set his proof. Will the decision to publish change the dynamics of this effort?</p>
<p>[Fixed typo]</p></font></div>
    </content>
    <updated>2020-04-06T02:30:51Z</updated>
    <published>2020-04-06T02:30:51Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="ABC"/>
    <category term="claimed proof"/>
    <category term="conjecture"/>
    <category term="long proof"/>
    <category term="open problems"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-07T15:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01668</id>
    <link href="http://arxiv.org/abs/2004.01668" rel="alternate" type="text/html"/>
    <title>Relative Error Streaming Quantiles</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cormode:Graham.html">Graham Cormode</a>, Zohar Karnin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberty:Edo.html">Edo Liberty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vesel=yacute=:Pavel.html">Pavel Veselý</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01668">PDF</a><br/><b>Abstract: </b>Approximating ranks, quantiles, and distributions over streaming data is a
central task in data analysis and monitoring. Given a stream of $n$ items from
a data universe $\mathcal{U}$ (equipped with a total order), the task is to
compute a sketch (data structure) of size $\mathrm{poly}(\log(n),
1/\varepsilon)$. Given the sketch and a query item $y \in \mathcal{U}$, one
should be able to approximate its rank in the stream, i.e., the number of
stream elements smaller than $y$.
</p>
<p>Most works to date focused on additive $\varepsilon n$ error approximation,
culminating in the KLL sketch that achieved optimal asymptotic behavior. This
paper investigates multiplicative $(1\pm\varepsilon)$-error approximations to
the rank. The motivation stems from practical demand to understand the tails of
distributions, and hence for sketches to be more accurate near extreme values.
</p>
<p>The most space-efficient algorithms that can be derived from prior work store
either $O(\log(\varepsilon^2 n)/\varepsilon^2)$ or $O(\log^3(\varepsilon
n)/\varepsilon)$ universe items. This paper presents a sketch of size
$O(\log^{1.5}(\varepsilon n)/\varepsilon)$ (ignoring $\text{poly}(\log\log n,
\log(1/\varepsilon))$ factors) that achieves a $1\pm\varepsilon$ multiplicative
error guarantee, without prior knowledge of the stream length or dependence on
the size of the data universe. This is within a $O(\sqrt{\log(\varepsilon n)})$
factor of optimal.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01599</id>
    <link href="http://arxiv.org/abs/2004.01599" rel="alternate" type="text/html"/>
    <title>Geodesic Spanners for Points in $\mathbb{R}^3$ amid Axis-parallel Boxes</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abam:Mohammad_Ali.html">Mohammad Ali Abam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seraji:Mohammad_Javad_Rezaei.html">Mohammad Javad Rezaei Seraji</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01599">PDF</a><br/><b>Abstract: </b>Let $P$ be a set of $n$ points in $\mathbb{R}^3$ amid a bounded number of
obstacles. When obstacles are axis-parallel boxes, we prove that $P$ admits an
$8\sqrt{3}$-spanner with $O(n\log^3 n)$ edges with respect to the geodesic
distance.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01493</id>
    <link href="http://arxiv.org/abs/2004.01493" rel="alternate" type="text/html"/>
    <title>Enumeration of LCP values, LCP intervals and Maximal repeats in BWT-runs Bounded Space</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishimoto:Takaaki.html">Takaaki Nishimoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tabei:Yasuo.html">Yasuo Tabei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01493">PDF</a><br/><b>Abstract: </b>Lcp-values, lcp-intervals, and maximal repeats are powerful tools in various
string processing tasks and have a wide variety of applications. Although many
researchers have focused on developing enumeration algorithms for them, those
algorithms are inefficient in that the space usage is proportional to the
length of the input string. Recently, the run-length-encoded Burrows-Wheeler
transform (RLBWT) has attracted increased attention in string processing, and
various algorithms on the RLBWT have been developed. Developing enumeration
algorithms for lcp-intervals, lcp-values, and maximal repeats on the RLBWT,
however, remains a challenge. In this paper, we present the first such
enumeration algorithms with space usage not proportional to the string length.
The complexities of our enumeration algorithms are $O(n \log \log (n/r))$ time
and $O(r)$ words of working space for string length $n$ and RLBWT size $r$.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01492</id>
    <link href="http://arxiv.org/abs/2004.01492" rel="alternate" type="text/html"/>
    <title>Tensor Rank and Complexity</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ottaviani:Giorgio.html">Giorgio Ottaviani</a>, Philipp Reichenbach <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01492">PDF</a><br/><b>Abstract: </b>These lecture notes are intended as an introduction to several notions of
tensor rank and their connections to the asymptotic complexity of matrix
multiplication. The latter is studied with the exponent of matrix
multiplication, which will be expressed in terms of tensor (border) rank,
(border) symmetric rank and the asymptotic rank of certain tensors. We
introduce the multilinear rank of a tensor as well, deal with the concept of
tensor equivalence and study prehomogeneous vector spaces with the Castling
transform. Moreover, we treat Apolarity Theory and use it to determine the
symmetric rank (Waring rank) of some symmetric tensors.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01491</id>
    <link href="http://arxiv.org/abs/2004.01491" rel="alternate" type="text/html"/>
    <title>The "cardinality of extended solution set" criterion for establishing the intractability of NP problems</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Arun U <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01491">PDF</a><br/><b>Abstract: </b>The intractability of any problem and the randomness of its solutions have an
obvious intuitive connection. However, the challenge till now has been that
there is no practical way to firmly establish if the solution to a problem is
actually random (or whether it has some hidden undiscovered structure, which
upon being detected would render it non-random). This has prevented the
conclusive declaration of hard problems (such as NP) as being definitely
intractable. For dealing with this, a concept called "extensibility" of a
sequence is developed. Based on this, a criterion termed as "cardinality of
extended solution set" is conceived to ascertain the (non)randomness of any
sequence. Further, this can then be used to establish the (in)tractability of
any problem depending on whether its solutions are random or non-random. This
criterion is applied to problems such as 2-SAT, 3-SAT and hardness of
approximation to analyze their (in)tractability. Finally, a proof for the
validity of the Unique Games Conjecture based on the same criterion is also
presented.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01348</id>
    <link href="http://arxiv.org/abs/2004.01348" rel="alternate" type="text/html"/>
    <title>Computational Complexity of the Hylland-Zeckhauser Scheme for One-Sided Matching Markets</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vazirani:Vijay_V=.html">Vijay V. Vazirani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yannakakis:Mihalis.html">Mihalis Yannakakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01348">PDF</a><br/><b>Abstract: </b>In 1979, Hylland and Zeckhauser \cite{hylland} gave a simple and general
scheme for implementing a one-sided matching market using the power of a
pricing mechanism. Their method has nice properties -- it is incentive
compatible in the large and produces an allocation that is Pareto optimal --
and hence it provides an attractive, off-the-shelf method for running an
application involving such a market. With matching markets becoming ever more
prevalant and impactful, it is imperative to finally settle the computational
complexity of this scheme.
</p>
<p>We present the following partial resolution:
</p>
<p>1. A combinatorial, strongly polynomial time algorithm for the special case
of $0/1$ utilities.
</p>
<p>2. An example that has only irrational equilibria, hence proving that this
problem is not in PPAD. Furthermore, its equilibria are disconnected, hence
showing that the problem does not admit a convex programming formulation.
</p>
<p>3. A proof of membership of the problem in the class FIXP.
</p>
<p>We leave open the (difficult) question of determining if the problem is
FIXP-hard. Settling the status of the special case when utilities are in the
set $\{0, {\frac 1 2}, 1 \}$ appears to be even more difficult.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01274</id>
    <link href="http://arxiv.org/abs/2004.01274" rel="alternate" type="text/html"/>
    <title>Does Comma Selection Help To Cope With Local Optima</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doerr:Benjamin.html">Benjamin Doerr</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01274">PDF</a><br/><b>Abstract: </b>One hope of using non-elitism in evolutionary computation is that it aids
leaving local optima. We perform a rigorous runtime analysis of a basic
non-elitist evolutionary algorithm (EA), the $(\mu,\lambda)$ EA, on the most
basic benchmark function with a local optimum, the jump function. We prove that
for all reasonable values of the parameters and the problem, the expected
runtime of the $(\mu,\lambda)$ EA is, apart from lower order terms, at least as
large as the expected runtime of its elitist counterpart, the
$(\mu+\lambda)$~EA (for which we conduct the first runtime analysis to allow
this comparison). Consequently, the ability of the $(\mu,\lambda)$ EA to leave
local optima to inferior solutions does not lead to a runtime advantage.
</p>
<p>We complement this lower bound with an upper bound that, for broad ranges of
the parameters, is identical to our lower bound apart from lower order terms.
This is the first runtime result for a non-elitist algorithm on a multi-modal
problem that is tight apart from lower order terms.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01250</id>
    <link href="http://arxiv.org/abs/2004.01250" rel="alternate" type="text/html"/>
    <title>From Generic Partition Refinement to Weighted Tree Automata Minimization</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wi=szlig=mann:Thorsten.html">Thorsten Wißmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deifel:Hans=Peter.html">Hans-Peter Deifel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Milius:Stefan.html">Stefan Milius</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schr=ouml=der:Lutz.html">Lutz Schröder</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01250">PDF</a><br/><b>Abstract: </b>Partition refinement is a method for minimizing automata and transition
systems of various types. Recently, we have developed a partition refinement
algorithm that is generic in the transition type of the given system and
matches the run time of the best known algorithms for many concrete types of
systems, e.g. deterministic automata as well as ordinary, weighted, and
probabilistic (labelled) transition systems. Genericity is achieved by
modelling transition types as functors on sets, and systems as coalgebras. In
the present work, we refine the run time analysis of our algorithm to cover
additional instances, notably weighted automata and, more generally, weighted
tree automata. For weights in a cancellative monoid we match, and for
non-cancellative monoids such as (the additive monoid of) the tropical semiring
even substantially improve, the asymptotic run time of the best known
algorithms. We have implemented our algorithm in a generic tool that is easily
instantiated to concrete system types by implementing a simple refinement
interface. Moreover, the algorithm and the tool are modular, and partition
refiners for new types of systems are obtained easily by composing
pre-implemented basic functors. Experiments show that even for complex system
types, the tool is able to handle systems with millions of transitions.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01235</id>
    <link href="http://arxiv.org/abs/2004.01235" rel="alternate" type="text/html"/>
    <title>Dots &amp; Polygons</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, Mart Hagedoorn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostitsyna:Irina.html">Irina Kostitsyna</a>, Max van Mulken, Jolan Rensen, Leo van Schooten <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01235">PDF</a><br/><b>Abstract: </b>We present a new game, Dots &amp; Polygons, played on a planar point set. Players
take turns connecting two points, and when a player closes a (simple) polygon,
the player scores its area. We show that deciding whether the game can be won
from a given state, is NP-hard. We do so by a reduction from vertex-disjoint
cycle packing in cubic planar graphs, including a self-contained reduction from
planar 3-Satisfiability to this cycle-packing problem. This also provides a
simple proof of the NP-hardness of the related game Dots &amp; Boxes. For points in
convex position, we discuss a greedy strategy for Dots &amp; Polygons.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01231</id>
    <link href="http://arxiv.org/abs/2004.01231" rel="alternate" type="text/html"/>
    <title>Towards PTAS for Precedence Constrained Scheduling via Combinatorial Algorithms</title>
    <feedworld_mtime>1586131200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shi.html">Shi Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01231">PDF</a><br/><b>Abstract: </b>We study the classic problem of scheduling $n$ precedence constrained
unit-size jobs on $m = O(1)$ machines so as to minimize the makespan. In a
recent breakthrough, Levey and Rothvoss \cite{LR16} developed a
$(1+\epsilon)$-approximation for the problem with running time
$\exp\Big(\exp\Big(O\big(\frac{m^2}{\epsilon^2}\log^2\log n\big)\Big)\Big)$,
via the Sherali-Adams lift of the basic linear programming relaxation for the
problem by $\exp\Big(O\big(\frac{m^2}{\epsilon^2}\log^2\log n\big)\Big)$
levels. Garg \cite{Garg18} recently improved the number of levels to $\log
^{O(m^2/\epsilon^2)}n$, and thus the running time to $\exp\big(\log
^{O(m^2/\epsilon^2)}n\big)$, which is quasi-polynomial for constant $m$ and
$\epsilon$.
</p>
<p>In this paper we present an algorithm that achieves
$(1+\epsilon)$-approximation for the problem with running time
$n^{O\left(\frac{m^4}{\epsilon^3}\log^3\log n\right)}$, which is very close to
a polynomial for constant $m$ and $\epsilon$. Unlike the algorithms of
Levey-Rothvoss and Garg, which are based on linear-programming hierarchy, our
algorithm is purely combinatorial. For this problem, we show that the
conditioning operations on the lifted LP solution can be replaced by making
guesses about the optimum schedule.
</p></div>
    </summary>
    <updated>2020-04-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-06T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/043</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/043" rel="alternate" type="text/html"/>
    <title>TR20-043 |  A combinatorial MA-complete problem | 

	Dorit Aharonov, 

	Alex Bredariol Grilo</title>
    <summary>Despite the interest in the complexity class MA, the randomized analog of NP, there is just a couple of known natural (promise-)MA-complete problems, the first due to Bravyi and Terhal (SIAM Journal of Computing 2009) and the second due to Bravyi (Quantum Information and Computation 2015). Surprisingly, both problems are stated using terminology from quantum computation. This fact makes it hard for classical complexity theorists to study these problems, and prevents possible progress, e.g., on the important question of derandomizing MA.

In this note we define a natural combinatorial problem called SetCSP and prove its MA-completeness. The problem generalizes the constraint satisfaction problem (CSP) into constraints on sets of strings. This note is, in fact, a combination of previously known works: the brilliant work of Bravyi and Terhal, together with an observation made in our previous work (Aharonov and Grilo, FOCS 2019) that a restricted case of the Bravyi and Terhal's MA complete problem (namely, the uniform case) is already complete, and moreover, that this restricted case can be stated using a classical, combinatorial description. Here we flesh out this observation.

This note, along with a translation of the main result of Aharonov and Grilo to the SetCSP language, implies that finding a gap-amplification procedure for SetCSP problems (namely a generalization to SetCSPs of the gap-amplification used in Dinur's PCP proof) would imply MA=NP. This would provide a resolution of the major problem of derandomizing MA; in fact, the problem of finding gap-amplification for SetCSP is in fact equivalent to the MA=NP problem.</summary>
    <updated>2020-04-05T19:37:00Z</updated>
    <published>2020-04-05T19:37:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-07T15:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1285</id>
    <link href="https://ptreview.sublinear.info/?p=1285" rel="alternate" type="text/html"/>
    <title>News for March 2020</title>
    <summary>I hope all of you are keeping safe and healthy in these difficult times. Thank heavens we have our research and our math to keep our sanity… This month has seen two papers, one on testing variable partitions and one on distributed isomorphism testing. Learning and Testing Variable Partitions by Andrej Bogdanov and Baoxiang Wang […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I hope all of you are keeping safe and healthy in these difficult times. Thank heavens we have our research and our math to keep our sanity…</p>



<p>This month has seen two papers, one on testing variable partitions and one on distributed isomorphism testing.</p>



<p><strong>Learning and Testing Variable Partitions</strong> by Andrej Bogdanov and Baoxiang Wang (<a href="https://arxiv.org/abs/2003.12990">arXiv</a>). Consider a function \(f:\Sigma^n \to G\), where \(G\) is Abelian group. Let \(V\) denote the set of variables. The function \(f\) is \(k\)-separable if there is a partition \(V_1, V_2, \ldots, V_k\) of $V$ such that \(f(V)\) can be expressed as the sum \(f_1(V_1) + f_2(V_2) + \ldots + f_k(V_k)\). This is an obviously natural property to study, though the specific application mentioned in the paper is high-dimensional reinforcement learning control. There are a number of learning results, but we’ll focus on the main testing result. The property of \(k\)-separability can be tested with \(O(kn^3/\varepsilon)\) queries, for \(\Sigma = \mathbb{Z}_q\) (and distance between functions is the usual Hamming distance). There is an analogous result (with different query complexity) for \(\Sigma = \mathbb{R}\). It is also shown that testing 2-separability requires \(\Omega(n)\) queries, even with 2-sided error. The paper, to its credit, also has empirical studies of the learning algorithm with applications to reinforcement learning.</p>



<p><strong>Distributed Testing of Graph Isomorphism in the CONGEST model </strong>by Reut Levi and Moti Medina (<a href="https://arxiv.org/pdf/2003.00468.pdf">arXiv</a>). This result follows a recent line of research in distributed property testing algorithms. The main aim is to minimize the number of rounds of (synchronous) communication for a property testing problem. Let \(G_U\) denote the graph representing the distributive network. The aim is to test whether an input graph \(G_K\) is isomorphic to \(G_U\). The main property testing results are as follows. For the dense graph case, isomorphism can be property tested (with two-sided error) in \(O(D + (\varepsilon^{-1}\log n)^2) \) rounds, where \(D\) is the diameter of the graph and \(n\) is the number of nodes. (And, as a reader of this blog, you probably know what \(\varepsilon\) is already…). There is a standard \(\Omega(D)\) lower bound for distributed testing problems. For various classes of sparse graphs (like bounded-degree minor-free classes), constant time isomorphism (standard) property testers are known. This paper provides a simulation argument showing that standard/centralized \(q\)-query property testers can be implemented in the distributed model, in \(O(Dq)\) rounds (this holds for any property, not just isomorphism). Thus, these simulations imply \(O(D)\)-round property testers for isomorphism for bounded-degree minor-free classes.</p></div>
    </content>
    <updated>2020-04-05T05:22:05Z</updated>
    <published>2020-04-05T05:22:05Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-04-06T23:36:55Z</updated>
    </source>
  </entry>
</feed>
