<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-03-07T22:21:39Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=395</id>
    <link href="https://tcsplus.wordpress.com/2020/03/04/tcs-talk-wednesday-march-11-thomas-steinke-ibm-research-almaden/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, March 11 — Thomas Steinke, IBM Research Almaden</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, March 11th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). Thomas Steinke from IBM Research Almaden will speak about “Reasoning About Generalization via Conditional Mutual Information” (abstract below). Please make sure you reserve a spot for your group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, March 11th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Thomas Steinke</strong> from IBM Research Almaden will speak about “<em>Reasoning About Generalization via Conditional Mutual Information</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. In view of the recent travel restrictions and coronavirus precautions, in particular, do not hesitate to reserve a seat even for a group <i class="moz-txt-slash">of size one</i>: there should be enough room for everyone, so don’t be shy!</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We provide an information-theoretic framework for studying the generalization properties of machine learning algorithms. Our framework ties together existing approaches, including uniform convergence bounds and recent methods for adaptive data analysis. Specifically, we use Conditional Mutual Information (CMI) to quantify how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. We show that bounds on CMI can be obtained from VC dimension, compression schemes, differential privacy, and other methods. We then show that bounded CMI implies various forms of generalization.</p>
<p>Based on joint work with Lydia Zakynthinou.</p></blockquote></div>
    </content>
    <updated>2020-03-05T01:16:38Z</updated>
    <published>2020-03-05T01:16:38Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=736</id>
    <link href="https://emanueleviola.wordpress.com/2020/03/02/conferences-in-an-era-of-expensive-carbon/" rel="alternate" type="text/html"/>
    <title>Conferences in an Era of Expensive Carbon</title>
    <summary>At least there’s that: I live in a world where some people care about it and publish their viewpoint in the latest CACM. Read it on your next flight. Some interesting things that won’t shock anyone: There’s a nice picture with different environmental costs based on the location of the conference. It also shows that […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>At least there’s that: I live in a world where some people care about it and publish their <a href="https://cacm.acm.org/magazines/2020/3/243024-conferences-in-an-era-of-expensive-carbon/abstract">viewpoint in the latest CACM</a>. Read it on your next flight.  Some interesting things that won’t shock anyone:</p>



<p>There’s a nice picture with different environmental costs based on the location of the conference.  It also shows that people like to go to nearby conferences, one of the reasons why “The impulse to ignore the issue is entirely understandable.”  For more perspective see some of our earlier posts for example <a href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/">here</a> and <a href="https://emanueleviola.wordpress.com/2020/01/01/publish-and-perish/">here</a>.</p>



<p>The viewpoint also reports on a recent switch from in-person to online program committees for flagship conferences (POPL and ICFP), following a recent trend.  For starters we continue to suggest that <a href="https://emanueleviola.wordpress.com/2017/07/28/stocfocs-pc-meetings-does-nature-of-decisions-justify-cost/">STOC and FOCS do the same, because the nature of decisions does not justify the cost.</a> The latter post also includes hard numbers on the added value of a physical meeting (with respect to accept/reject decisions — of course one can value at infinity meeting in person luminaries in your field, but that can be done in other ways and should not be tied to PC meetings).</p>



<p/></div>
    </content>
    <updated>2020-03-02T15:44:29Z</updated>
    <published>2020-03-02T15:44:29Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/</id>
    <link href="https://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/" rel="alternate" type="text/html"/>
    <title>Prague Summer School on Discrete Mathematics</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">August 24-28, 2020 Prague, Czech Republic http://pssdm.math.cas.cz/ Registration deadline: March 22, 2020 The third edition of Prague Summer School on Discrete Mathematics will feature two lecture series: Subhash Khot (New York University): Hardness of Approximation: From the PCP Theorem to the 2-to-2 Games Theorem, and Shayan Oveis Gharan (University of Washington): Polynomial Paradigm in Algorithm … <a class="more-link" href="https://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/">Continue reading <span class="screen-reader-text">Prague Summer School on Discrete Mathematics</span></a></div>
    </summary>
    <updated>2020-03-02T14:40:44Z</updated>
    <published>2020-03-02T14:40:44Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2386</id>
    <link href="https://francisbach.com/richardson-extrapolation/" rel="alternate" type="text/html"/>
    <title>On the unreasonable effectiveness of Richardson extrapolation</title>
    <summary>This month, I will follow up on last month’s blog post, and describe classical techniques from numerical analysis that aim at accelerating the convergence of a vector sequence to its limit, by only combining elements of the sequence, and without the detailed knowledge of the iterative process that has led to this sequence. Last month,...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">This month, I will follow up on <a href="https://francisbach.com/acceleration-without-pain/">last month’s blog post</a>, and describe classical techniques from numerical analysis that aim at accelerating the convergence of a vector sequence to its limit, by only combining elements of the sequence, and without the detailed knowledge of the iterative process that has led to this sequence. </p>



<p class="justify-text">Last month, I focused on sequences that converge to their limit exponentially fast (which is referred to as <em>linear</em> convergence), and I described <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitken’s \(\Delta^2\) method</a>, the <a href="https://en.wikipedia.org/wiki/Shanks_transformation">Shanks transformation</a>, Anderson acceleration and its <a href="https://arxiv.org/pdf/1606.04133">regularized version</a>. These methods are called “non-linear” acceleration techniques, because, although they combine linearly iterates as \(c_0 x_k + c_1 x_{k+1} + \cdots + c_m x_{k+m}\), the scalar weights in the linear combination depend non-linearly on \(x_k,\dots,x_{k+m}\).</p>



<p class="justify-text">In this post, I will focus on sequences that converge sublinearly, that is, with a difference to their limit that goes to zero as an inverse power of \(k\), typically in \(O(1/k)\). </p>



<h2>Richardson extrapolation</h2>



<p class="justify-text">We consider a sequence \((x_k)_{k \geq 0} \in \mathbb{R}^d\), with an asymptotic expansion of the form $$ x_k = x_\ast + \frac{1}{k}\Delta + O\Big(\frac{1}{k^2}\Big), $$ where \(x_\ast \in \mathbb{R}^d\) is the limit of \((x_k)_k\) and \(\Delta\) a vector in \(\mathbb{R}^d\).</p>



<p class="justify-text">The idea behind <a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">Richardson extrapolation</a> [<a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">1</a>] is to combine linearly two iterates taken at two different values of \(k\) so that the zero-th order term \(x_\ast\) is left unchanged, but the first order term in \(1/k\) cancels out. For \(k\) even, we can consider $$  2 x_k – x_{k/2} =  2 \Big( x_\ast + \frac{1}{k} \Delta  +O\Big(\frac{1}{k^2}\Big)  \Big) \, – \Big( x_\ast +  \frac{2}{k} \Delta  + O\Big(\frac{1}{k^2}\Big) \Big)  =  x_\ast +O\Big(\frac{1}{k^2}\Big).$$</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><a href="https://arxiv.org/pdf/1707.06386"><img alt="" class="wp-image-2421" height="179" src="https://francisbach.com/wp-content/uploads/2020/02/reg_k-1024x454.png" width="404"/></a>Illustration of Richardson extrapolation. Iterates (in black) with their first-order expansions (in red). The deviations (represented by circles) are of order \(O(1/k^2)\). Adapted from [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="https://arxiv.org/pdf/2002.02835">2</a>].  </figure></div>



<p class="justify-text">The key benefit of Richardson extrapolation is that we only need to know that the leading term in the asymptotic expansion is proportional to \(1/k\), <em>without the need to know the vector \(\Delta\)</em>. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2481" height="280" src="https://francisbach.com/wp-content/uploads/2020/02/richardson_2d.gif" width="332"/>Richardson extrapolation in two dimensions. The sequence is of the form \(x_k = \frac{1}{k} \Delta_1 + \frac{(-1)^k}{k^2} \Delta_2\). The extrapolated sequence \(2 x_k – x_{k/2}\) is only plotted for \(k\) even.</figure></div>



<p class="justify-text">In this post, following [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], I will explore situations where Richardson extrapolation can be useful within machine learning. I identified three situations where Richardson extrapolation can be useful (there are probably more):</p>



<ol class="justify-text"><li>Iterates of an optimization algorithms \((x_k)_{k \geq 0}\), and the extrapolation is \( 2x_k – x_{k/2}.\)</li><li>Extrapolation on the step-size of stochastic gradient descent, where we will combine iterates obtained from two different values of the step-size.</li><li>Extrapolation on a regularization parameter.</li></ol>



<p class="justify-text">As we will show, extrapolation techniques come with no significant loss in performance, but in several situations strong gains. It is thus “<a href="https://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences">unreasonably effective</a>“.</p>



<h2>Application to optimization algorithms</h2>



<p class="justify-text">We consider an iterate \(x_k\) of an iterative optimization algorithm which is minimizing a function \(f\), thus converging to a global minimizer \(x_\ast\) of \(f\). Then so is \(x_{k/2}\), and thus also $$  x_k^{(1)} = 2x_k – x_{k/2}.$$ Therefore, performance is never significantly deteriorated (the risk is essentially to lose half of the iterations). The potential gains depend on the way \(x_k\) converges to \(x_\ast\). The existence of a convergence rate of the form \(f(x_k) -f(x_\ast) = O(1/k)\) or \(O(1/k^2)\) is not enough, as Richardson extrapolation requires a specific direction of asymptotic convergence. As illustrated below, some algorithms are oscillating around their solutions, while some converge with a specific direction. Only the latter ones can be accelerated with Richardson extrapolation, while the former ones are good candidates for <a href="https://francisbach.com/acceleration-without-pain/">Anderson acceleration</a>.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2395" height="162" src="https://francisbach.com/wp-content/uploads/2020/02/nonoscillating_oscillating-1024x350.png" width="476"/> Left: Oscillating convergence, where Richardson extrapolation does not lead to any gain. Right: non-oscillating  convergence, with a main direction \(\Delta\) (in red dotted), where Richardson extrapolation can be beneficial if the oscillations orthogonal to the direction \(\Delta\) are negligible compared to convergence along the direction \(\Delta\). </figure></div>



<p class="justify-text"><strong>Averaged gradient descent.</strong> We consider the usual gradient descent algorithm $$x_k = x_{k-1} – \gamma f'(x_{k-1}),$$ where \(\gamma &gt; 0 \) is a step-size, with Polyak-Ruppert averaging [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>]: $$ y_k = \frac{1}{k} \sum_{i=0}^{k-1} x_i.$$ Averaging is key to robustness to potential noise in the gradients [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>, <a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">5</a>]. However it comes with the unintended consequence of losing the exponential forgetting of initial conditions for strongly-convex problems [<a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">6</a>].</p>



<p class="justify-text">A common way to restore exponential convergence (up to the noise level in the stochastic case) is to consider “tail-averaging”, that is, to replace \(y_k\) by the average of only the latest \(k/2\) iterates [<a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">7</a>]. As shown below for \(k\) even, this corresponds exactly to Richardson extrapolation on the sequence \((y_k)_k\): $$ \frac{2}{k} \sum_{i=k/2}^{k-1} x_i = \frac{2}{k} \sum_{i=0}^{k-1} x_i – \frac{2}{k} \sum_{i=0}^{k/2-1} x_i = 2 y_k – y_{k/2}. $$</p>



<p class="justify-text">With basic  assumptions on \(f\), it is shown in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>] that for locally strongly-convex problems: $$y_k = x_\ast + \frac{1}{k} \Delta + O(\rho^k), $$ where  \(\displaystyle \Delta = \sum_{i=0}^\infty (x_i – x_\ast)\) and \(\rho \in (0,1)\) depends on the condition number of \(f”(x_\ast)\). This is illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2507" height="250" src="https://francisbach.com/wp-content/uploads/2020/02/averaged_gradient.png" width="342"/>Averaged gradient descent on a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> problem in dimension \(d=400\), and with \(n=4000\) observations. For the regular averaged recursion, the line in the log-log plot has slope \(-2\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].</figure></div>



<p class="justify-text">We can make the following observations:</p>



<ul class="justify-text"><li>Before Richardson extrapolation, the asymptotic convergence rate after averaging is of order \(O(1/k^2)\), which is better than the usual \(O(1/k)\) upper-bound for the rate of gradient descent, but with a stronger assumption that in fact leads to exponential convergence before averaging.</li><li>While \(\Delta\) has a simple expression, it cannot be computed in practice (but Richardson extrapolation does not need to know it).</li><li>Richardson extrapolation leads to an exponentially convergent algorithm from an algorithm converging asymptotically in \(O(1/k^2)\).</li></ul>



<p class="justify-text"><strong>Accelerated gradient descent.</strong> Above, we considered averaged gradient descent, which is asymptotically converging as \(O(1/k^2)\), and on which Richardson extrapolation could be used with strong gains. Is it possible also for the accelerated gradient descent method [<a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">8</a>], which has a (non-asymptotic) convergence rate of \(O(1/k^2)\) for convex functions?</p>



<p class="justify-text">It turns out that the behavior of the iterates of accelerated gradient descent is exactly of the form depicted in the left plot of the figure above: that is, the iterates \(x_k\) oscillate around the optimum [<a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">9</a>, <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">10</a>], and Richardson extrapolation is of no help, but is not degrading performance too much. See below for an illustration. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2509" height="243" src="https://francisbach.com/wp-content/uploads/2020/02/accelerated_gradient.png" width="332"/>Accelerated gradient descent on a quadratic optimization problem in dimension \(d=1000\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].  </figure></div>



<p class="justify-text"><strong>Other algorithms.</strong> It is tempting to test it on other optimization algorithms. For example, as explained in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], Richardson extrapolation can be used to the <a href="https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm">Frank-Wolfe</a> algorithm, where sometimes it helps, sometimes it doesn’t. Others could be tried.</p>



<h2>Extrapolation on the step-size of stochastic gradient descent</h2>



<p class="justify-text">While above we have focused on Richardson extrapolation applied to the number of iterations of an iterative algorithm, it is most often used in integration methods (for computing integrals or solving ordinary differential equations), and then often referred to as <a href="https://en.wikipedia.org/wiki/Romberg%27s_method">Romberg-Richardson extrapolation</a>. Within machine learning, in a similar spirit, this can be applied to the step-size of stochastic gradient descent [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">11</a>], which I now describe.</p>



<p class="justify-text">We consider the minimization of a function \(F(x)\) defined on \(\mathbb{R}^d\), which can be written as an expectation as $$F(x) = \mathbb{E}_{z} f(x,z).$$ We assume that we have access to \(n\) independent and identically distributed observations (i.i.d.) \(z_1,\dots,z_n\). This is a typical scenario in machine learning, where \(f(x,z)\) represents the loss for the predictor parameterized by \(x\) on the observation \(z\). </p>



<p class="justify-text">The stochastic gradient method is particularly well adapted, and we consider here a single pass, as $$x_i= x_{i-1} – \gamma f'(x_{i-1},z_i),$$ where the gradient is taken with respect to the first variable, for \(i = 1,\dots,n\). It is known that with a constant step-size, when \(n\) tends to infinity, \(x_n\) will <em>not</em> converge to the minimizer \(x_\ast\) of \(F\), as the algorithm always moves [<a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">16</a>], as illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2488" height="279" src="https://francisbach.com/wp-content/uploads/2020/02/logistic_2d-1.gif" width="403"/>Stochastic gradient descent on a logistic regression problem: (blue) without averaging, (red) with averaging.</figure></div>



<p class="justify-text">One way to damp the oscillations is to consider averaging, that is, $$ y_n = \frac{1}{n+1} \sum_{i=0}^{n} x_i$$ (we consider uniform averaging for simplicity). For least-squares regression, this leads to a converging algorithm [<a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">12</a>] with attractive properties for ill-conditioned problems (see also <a href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/">January’s blog post</a>). However, for general loss functions, it is shown in [<a href="https://arxiv.org/pdf/1707.06386">3</a>] that \(y_n\) converges to some \(y^{(\gamma)} \neq x_\ast\). There is a bias due to a step-size \(\gamma\) that does not go to zero. In order to apply Richardson extrapolation, together with Aymeric Dieuleveut and Alain Durmus [<a href="https://arxiv.org/pdf/1707.06386">3</a>], we showed that $$ y^{(\gamma)} = x_\ast + \gamma \Delta + O(\gamma^2),$$ for some \(\Delta \in \mathbb{R}^d\) with some complex expression. Thus, we have $$2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2),$$ thus gaining one order. If we consider the iterate \(y_n^{(\gamma)}\) and \(y_n^{(2 \gamma)}\) associated to the two step-sizes \(\gamma\) and \(2 \gamma\), the linear combination $$2 y_n^{(\gamma)} – y_n^{(2\gamma)} $$ has an improved behavior as it tends to \(2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2)\): it remains not convergent, but get to way smaller values. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2525" height="274" src="https://francisbach.com/wp-content/uploads/2020/02/SGD_logistic-1.png" width="359"/>Averaged stochastic gradient descent on a logistic regression problem in dimension 20.</figure></div>



<p class="justify-text"><strong>Higher-order extrapolation.</strong> If we can accelerate a sequence by extrapolation, why not extrapolate the extrapolated sequence? This is possible if we have an higher-order expansion of the form $$ y^{(\gamma)} = \theta_\ast + \gamma \Delta_1 + \gamma^2 \Delta_2 + O(\gamma^3),$$ for some (typically unknown) vectors \(\Delta_1\) and \(\Delta_2\). Then, the sharp reader can check that $$3 y_n^{(\gamma)} – 3 y_n^{(2\gamma)} +  y_n^{(3\gamma)}, $$ will lead to cancellation of the first two orders \(\gamma\) and \(\gamma^2\). This is illustrated above for SGD.</p>



<p class="justify-text">Then, why not extrapolate the extrapolation of the extrapolated sequence? One can check that $$4 y_n^{(\gamma)} – 6 y_n^{(2\gamma)} + 4  y_n^{(3\gamma)}  -y_n^{(4\gamma)}, $$ will lead to cancellation of the first three orders of an expansion of \(y^{(\gamma)}\). The <a href="https://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a> aficionados have already noticed the pattern there, and checked that $$ \sum_{i=1}^{m+1} (-1)^{i-1} { m+1 \choose i} y_n^{(i\gamma)}$$ will lead to cancellations of the first \(m\) orders.</p>



<p class="justify-text">Then, why not go on forever? First because \(m+1\) recursions have to be run in parallel, and second, because the constant in front of the term in \(\gamma^{m+1}\) typically explodes, a phenomenon common to many expansion methods.</p>



<h2>Extrapolation on a regularization parameter</h2>



<p class="justify-text">We now explore the application of Richardson extrapolation to regularization methods. In a nutshell, regularization allows to make an estimation problem more stable (less subject to variations for statistical problems) or the algorithm faster (for optimization problems). However, regularization adds a bias that needs to be removed. In this section, we apply Richardson extrapolation to the regularization parameter to reduce this bias. I will only present an application to smoothing for non-smooth optimization (see an application to  ridge regression in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>]).</p>



<p class="justify-text"><strong>Non-smooth optimization problems</strong>. We consider the minimization of a convex function of the form \(f = h + g\), where \(h\) is smooth and \(g\) is non-smooth. These optimization problems are ubiquitous in machine learning and signal processing, where the lack of smoothness can come from (a) non-smooth losses such as max-margin losses used in support vector machines and more generally structured output classification [<a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">13</a>], and (b) sparsity-inducing regularizers (see, e.g., [<a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">14</a>] and references therein). While many algorithms can be used to deal with this non-smoothness, we consider a classical smoothing technique below.</p>



<p class="justify-text"><strong>Nesterov smoothing</strong>. In this section, we consider the smoothing approach of Nesterov [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>] where the non-smooth term is “smoothed” into \(g_\lambda\), where \(\lambda\) is a regularization parameter, and accelerated gradient descent is used to minimize \(h+g_\lambda\). </p>



<p class="justify-text">A typical way of smoothing the function \(g\) is to add \(\lambda\) times a strongly convex regularizer (such as the squared Euclidean norm) to the Fenchel conjugate of \(g\); this leads to a function \(g_\lambda\) which has a smoothness constant (defined as the maximum of the largest eigenvalues of all Hessians) proportional to \(1/\lambda\), with a uniform error of \(O(\lambda)\) between \(g\) and \(g_\lambda\). Given that accelerated gradient descent leads to an iterate with excess function values proportional to \(1/(\lambda k^2)\) after \(k\) iterations, with the choice of \(\lambda \propto 1/k\), this leads to an excess in function values proportional to \(1/k\), which improves on the subgradient method which converges in \(O(1/\sqrt{k})\). Note that the amount of regularization depends on the number of iterations, so that this smoothing method is not “anytime”.</p>



<p class="justify-text"><strong>Richardson extrapolation.</strong> If we denote by \(x_\lambda\) the minimizer of \(h+g_\lambda\) and \( x_\ast\) the global minimizer of \( f=h+g\), if we can show that \( x_\lambda = x_\ast + \lambda \Delta + O(\lambda^2)\), then \( x^{(1)}_\lambda = 2 x_\lambda – x_{2\lambda} = O(\lambda^2)\) and we can expand \( f(x_\lambda^{(1)})  = f(x_\ast)  + O(\lambda^2)\), which is better than the \(O(\lambda)\) approximation without extrapolation. </p>



<p class="justify-text">Then, given a number of iterations \(k\), with \( \lambda \propto k^{-2/3}\), to balance the two terms \( 1/(\lambda k^2)\) and \( \lambda^2\),  we get an overall convergence rate for the non-smooth problem of \( k^{-4/3}\). </p>



<p class="justify-text"><strong>\(m\)-step Richardson extrapolation</strong>. Like above for the step-size, we can also consider \(m\)-step Richardson extrapolation \(x_{\lambda}^{(m)}\), which leads to a bias proportional to \(\lambda^{m+1}\). Thus, if we consider \(\lambda \propto 1/k^{2/(m+2)}\), to balance the terms \(1/(\lambda k^2)\) and \(\lambda^{m+1}\), we get an error for the non-smooth problem of \(1/k^{2(m+1)/(m+2)}\), which can get arbitrarily close to \(1/k^2\) when \(m\) gets large. The downsides (like for the extrapolation on the step-size above) are that (a) the constants in front of the asymptotic equivalent may blow up (a classical problem in high-order expansions), and (b) \(m\)-step extrapolation requires running the algorithm \(m\) times (this can be down in parallel). In the experiment below, 3-step extrapolation already brings in most of the benefits.</p>



<p class="justify-text">In order to experimentally study the benefits of extrapolation, for the <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso</a> optimization problem, and for a series of regularization parameters equal to \(2^{i}\) for \(i\) between \(-18\) and \(1\) (sampled every \(1/5\)), we run accelerated gradient descent on \(h+g_\lambda\) and we plot the value of \(f(x)-f(x_\ast)\) for the various estimates, where for each number of iterations, we minimize over the regularization parameter. This is an oracle version of varying \(\lambda\) as a function of the number of iterations. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2530" height="255" src="https://francisbach.com/wp-content/uploads/2020/02/smoothing.png" width="351"/>Excess function values as a function of the number of iterations, <em>taking into account that \(m\)-step Richardson extrapolation requires \(m\)-times more iterations</em>. There is indeed a strong improvement approaching the rate \(1/k^2\).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">These last two blog posts were dedicated to acceleration techniques coming from numerical analysis. They are cheap to implement, typically do not interfere with the underlying algorithm, and when used in the appropriate situation, can bring in significant speed-ups.</p>



<p class="justify-text">Next month, I will most probably host an invited post by my colleague <a href="https://www.di.ens.fr/~ataylor/">Adrien Taylor</a>, who will explain how machines can <s>replace</s> help researchers that prove bounds on optimization algorithms.</p>



<h2>References</h2>



<p class="justify-text">[1] Lewis Fry Richardson. <a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam</a>. <em>Philosophical Transactions of the Royal Society of London, Series A</em>, 210(459-470):307–357, 1911.<br/>[2] Francis Bach. <a href="https://arxiv.org/pdf/2002.02835">On the Effectiveness of Richardson Extrapolation in Machine Learning</a>. Technical report, arXiv:2002.02835, 2020.<br/>[3] Aymeric Dieuleveut, Alain Durmus, Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains</a>. To appear in <em>The Annals of Statistics</em>, 2019.<br/>[4] Boris T. Polyak,  Anatoli B. Juditsky. <a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">Acceleration of stochastic approximation by averaging</a>. <em>SIAM journal on control and optimization</em> 30(4):838-855, 1992.<br/>[5] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>. </em><a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br/>[6] Francis Bach, Eric Moulines. <a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">Non-asymptotic analysis of stochastic approximation algorithms for machine learning</a>. <em>Advances in Neural Information Processing Systems</em>, 2011.<br/>[7] Prateek Jain, Praneeth Netrapalli, Sham Kakade, Rahul Kidambi, Aaron Sidford. <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">Parallelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and model misspecification</a>. <em>The Journal of Machine Learning Research</em>, 18(1), 8258-8299, 2017.<br/>[8] Yurii E. Nesterov. <a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">A method of solving a convex programming problem with convergence rate \(O(1/k^2)\)</a>, <em>Doklady Akademii Nauk SSSR</em>, 269(3):543–547, 1983.<br/>[9] Weijie Su, Stephen Boyd, and Emmanuel J. Candes. <a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">A differential equation for modeling Nesterov’s accelerated gradient method: theory and insights</a>. <em>Journal of Machine Learning Research</em>, 17(1):5312-5354, 2016.<br/>[10] Nicolas Flammarion, and Francis Bach. <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">From Averaging to Acceleration, There is Only a Step-size</a>. <em>Proceedings of the International Conference on Learning Theory (COLT)</em>, 2015. <br/>[11] Alain Durmus, Umut Simsekli, Eric Moulines, Roland Badeau, and Gaël Richard. <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">Stochastic gradient Richardson-Romberg Markov chain Monte Carlo</a>. In <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2016.<br/>[12] Francis Bach and Eric Moulines. <a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2013.<br/>[13] Ben Taskar, Vassil Chatalbashev, Daphne Koller, and Carlos Guestrin. <a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">Learning structured prediction models: A large margin approach</a>. <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2005.<br/>[14] Francis Bach, Rodolphe Jenatton, Julien Mairal, and Guillaume Obozinski. <a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">Optimization with sparsity-inducing penalties</a>. Foundations and Trends in Machine Learning, 4(1):1–106, 2012<br/>[15] Yurii Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions</a>. Mathematical Programming , 103(1):127–152, 2005.<br/>[16] Georg Ch. Pflug. <a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">Stochastic minimization with constant step-size: asymptotic laws</a>. <em>SIAM Journal on Control and Optimization</em>, (24)4:655-666, 1986.</p>



<p/></div>
    </content>
    <updated>2020-03-01T12:41:33Z</updated>
    <published>2020-03-01T12:41:33Z</published>
    <category term="Machine learning"/>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-03-07T22:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=26</id>
    <link href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/" rel="alternate" type="text/html"/>
    <title>Friday, February 28 — Jon Kleinberg from Cornell University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). Jon Kleinberg from Cornell University will speak about “Fairness and Bias in Algorithmic Decision-Making”. Abstract: As data science has broadened its scope in recent years, a<a class="more-link" href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/">Continue reading <span class="screen-reader-text">"Friday, February 28 — Jon Kleinberg from Cornell University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). <strong>Jon Kleinberg</strong> from Cornell University will speak about “<em>Fairness and Bias in Algorithmic Decision-Making</em>”.</p>



<p><strong>Abstract</strong>: As data science has broadened its scope in recent years, a number of domains have applied computational methods for classification and prediction to evaluate individuals in high-stakes settings. These developments have led to an active line of recent discussion in the public sphere about the consequences of algorithmic prediction for notions of fairness and equity. In part, this discussion has involved a basic tension between competing notions of what it means for such classifications to be fair to different groups. We consider several of the key fairness conditions that lie at the heart of these debates, and in particular how these properties operate when the goal is to rank-order a set of applicants by some criterion of interest, and then to select the top-ranking applicants. The talk will be based on joint work with Sendhil Mullainathan and Manish Raghavan.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>
    </content>
    <updated>2020-02-27T23:30:00Z</updated>
    <published>2020-02-27T23:30:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-03-07T22:21:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=389</id>
    <link href="https://tcsplus.wordpress.com/2020/02/20/tcs-talk-wednesday-february-26-henry-yuen-university-of-toronto/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 26 — Henry Yuen, University of Toronto</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Henry Yuen from University of Toronto will speak about “MIP* = RE” (abstract below). Please make sure you reserve a spot for your group to join us live […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 26th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Henry Yuen</strong> from University of Toronto will speak about “<em>MIP* = RE</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: MIP* denotes the class of problems that admit interactive proofs with quantum entangled provers. It has been an outstanding question to characterize the complexity of MIP*. Most notably, there was no known computable upper bound on this class.<br/>
We show that MIP* is equal to the class RE, the set of recursively enumerable languages. In particular, this shows that MIP* contains uncomputable problems. Through a series of known connections, this also yields a negative answer to Connes’ Embedding Problem from the theory of operator algebras. In this talk, I will explain the connection between Connes’ Embedding Problem, quantum information theory, and complexity theory. I will then give an overview of our approach, which involves reducing the Halting Problem to the problem of approximating the entangled value of nonlocal games.<br/>
Joint work with Zhengfeng Ji, Anand Natarajan, Thomas Vidick, and John Wright.</p></blockquote></div>
    </content>
    <updated>2020-02-20T08:30:51Z</updated>
    <published>2020-02-20T08:30:51Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=717</id>
    <link href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/" rel="alternate" type="text/html"/>
    <title>Working remotely will be the most significant transformation since agriculture</title>
    <summary>Its impact on civilization will be exactly opposite. Rather than concentrating population, it will disperse it. Commuting and the traffic crisis will disappear. So will the housing crisis. You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance. You will live away […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Its impact on civilization will be exactly opposite.  Rather than concentrating population, it will disperse it.  Commuting and the traffic crisis will disappear.  So will the housing crisis.  You will have a large lot of land with a robot-ready house built new with safe, eco-friendly material and free of hazardous substance.  You will live away from volcanoes, fault lines, tornadoes, wild fires and other hazards. You’ll be able to move to a location with ideal climate, which for historical reasons are now under-populated.  This will dramatically reduce housing costs, especially heating, and solve  or greatly mitigate the pollution problem. Huge amounts of space will be cleared up and given back to nature, or used for housing.</p>



<p>Doctors will visit patients remotely.  This will enable patients to be followed up more regularly and consistently throughout their lives regardless of where they are.  Doctors will have more time to give meaningful advice rather than having the patient wait 1 year for the appointment and then spend 1 hour to get to the doctor for a 10-minute visit of which 8 are spent looking at the screen and filling reports. Robo-tools will take measurements and send them to the doctor.  If a complicated procedure is required, the expert will connect with the patient and the doctor remotely first, and then the patient will schedule a trip for the procedure.</p>



<p>You’ll take gym classes remotely via a remote gym. The instructor will give you personalized advice and follow your progress anywhere, anytime. Demanding facilities like swimming pools will be next to your house.</p>



<p>Courts of law, and the entire judicial system will be taken off-line.</p>



<p>People will vote from home, elections will be more frequent and granular.  Constituents choosing not to vote will (maybe) have to specifically abstain.  This will finally realize the democratic ideal where the government represents the will of the people.</p>



<p>Constituents will be able to participate to discussions, instead of having to travel 1 hour for a 5-minute in-person discussion.  The level of engagement will be measured by the level of engagement as opposed to travel distance.</p>



<p>Wireless won’t be used on a large scale, since its noxious effects will be undeniable. Instead we will have network cables densely spread out over the earth — one of the few duties of the government will be to maintain these cables for the free, democratic, public use.</p>



<p>Banking will be done remotely, and physical money will disappear.</p>



<p>We will have immersive work-stations with wall-to-wall, solar-powered e-ink screens, holographic images, and audio indistinguishable from reality.  You will be able to attend meetings while exercising, like walking or biking on a machine or outside.  This will boost your health, lowering health care costs for all.</p>



<p>People with special needs will have the same opportunities and duties as everyone else and will be fully integrated.</p>



<p>All learning will be done remotely.  The instructor will be able to provide better, more personalized teaching, and connect with each student face-to-face.  Testing will be done remotely, each student monitored via cameras.  Critical examinations will be administered in special-purpose facilities which are next to your house (similar in spirit to say the way GRE is administered, but much more large scale and flexible, including for example synchronized examination).</p>



<p>You will have farms next to your house, growing organic food that you can eat fresh. Epidemics will be much rarer and more easily controlled, as population will be less concentrated and will travel less.</p>



<p>Fantasy? Actually, many of these things are already happening!</p>



<p/></div>
    </content>
    <updated>2020-02-18T20:38:26Z</updated>
    <published>2020-02-18T20:38:26Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1555</id>
    <link href="https://theorydish.blog/2020/02/11/approx-random-2020/" rel="alternate" type="text/html"/>
    <title>APPROX-RANDOM 2020</title>
    <summary>The CFPs for APPROX 2020 and RANDOM 2020 are out. The conference will be held August 17-19, 2020 at the University of Washington in Seattle. Submissions: April 24, 2020.    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CFPs for <a href="https://approxconference.wordpress.com/approx-2020/">APPROX 2020</a> and <a href="https://randomconference.com/random-2020-home/">RANDOM 2020</a> are out. The conference will be held August 17-19, 2020 at the University of Washington in Seattle. <strong>Submissions:</strong> April 24, 2020.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-02-12T06:21:12Z</updated>
    <published>2020-02-12T06:21:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=40</id>
    <link href="https://kamathematics.wordpress.com/2020/02/08/icalp-and-lics-2020-relocation-and-extended-deadline/" rel="alternate" type="text/html"/>
    <title>ICALP (and LICS) 2020 – Relocation and Extended Deadline</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Due to the Wuhan coronavirus outbreak, the organizers of ICALP and LICS have made the difficult decision to relocate both (co-located) conferences from Beijing, China, to Saarbrücken, Germany. Speaking specifically about ICALP now (I do not have further information about LICS): As a result of previous uncertainty regarding the situation, the deadline has been extended … <a class="more-link" href="https://kamathematics.wordpress.com/2020/02/08/icalp-and-lics-2020-relocation-and-extended-deadline/">Continue reading<span class="screen-reader-text"> "ICALP (and LICS) 2020 – Relocation and Extended Deadline"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Due to the Wuhan coronavirus outbreak, the organizers of ICALP and LICS have made the difficult decision to relocate both (co-located) conferences from Beijing, China, to Saarbrücken, Germany. Speaking specifically about ICALP now (I do not have further information about LICS): As a result of previous uncertainty regarding the situation, the deadline has been extended by about six days, until Tuesday February 18, 2020, at 6 AM GMT. The dates of the conference remain (roughly) the same, July 8 – 11, 2020. <br/>The following is a more official message from ICALP Track A Chair, Artur Czumaj.</p>



<hr class="wp-block-separator"/>



<p>The ICALP and the LICS steering committee have agreed together with the conference chairs in Beijing to relocate the two conferences.<br/>ICALP and LICS 2020 will take place in <strong>Saarbrücken</strong>, Germany, July 8 – 11 2020 (with satellite workshops on July 6 – 7 2020).<br/>The deadline is extended, see below.</p>



<p><strong>Call for Papers – ICALP 2020</strong><br/><strong>July 8 – 11 2020, Saarbrücken, Germany</strong></p>



<p><strong>NEW Paper submission deadline: Tuesday February 18, 2020, 6am GMT</strong><br/><a href="https://easychair.org/conferences/?conf=icalp2020">https://easychair.org/conferences/?conf=icalp2020</a></p>



<p>ICALP (International Colloquium on Automata, Languages and Programming) is the main European conference in Theoretical Computer Science and annual meeting of the European Association for Theoretical Computer Science (EATCS). ICALP 2020 will be hosted on the Saarland Informatics Campus in Saarbrücken, in co-location with LICS 2020 (ACM/IEEE Symposium on Logic in Computer Science).</p>



<p><strong>Invited speakers:</strong><br/>Track A: Virginia Vassilevska (MIT), Robert Krauthgamer (Weizmann)<br/>Track B: Stefan Kiefer (Oxford)<br/>Joint ICALP-LICS: Andrew Yao (Tsinghua), Jérôme Leroux (Bordeaux)</p>



<p><strong>Submission Guidelines:</strong> see <a href="https://easychair.org/conferences/?conf=icalp2020">https://easychair.org/conferences/?conf=icalp2020</a></p>



<p><strong>NEW Paper submission deadline: February 18</strong>, 2020, 6am GMT<br/>notifications: April 15, 2020<br/>camera ready: April 28, 2020</p>



<p>Topics: ICALP 2020 will have the two traditional tracks<br/>A (Algorithms, Complexity and Games – including Algorithmic Game Theory, Distributed Algorithms and Parallel, Distributed and External Memory Computing) and<br/>B (Automata, Logic, Semantics and Theory of Programming).<br/><strong><em>    (Notice that the old tracks A and C have been merged into a single track A.)</em></strong><br/>Papers presenting original, unpublished research on all aspects of theoretical computer science are sought.</p>



<p>Typical, but not exclusive topics are:</p>



<p>Track A — Algorithmic Aspects of Networks and Networking, Algorithms for Computational Biology, Algorithmic Game Theory, Combinatorial Optimization, Combinatorics in Computer Science, Computational Complexity, Computational Geometry, Computational Learning Theory, Cryptography, Data Structures, Design and Analysis of Algorithms, Foundations of Machine Learning, Foundations of Privacy, Trust and Reputation in Network, Network Models for Distributed Computing, Network Economics and Incentive-Based Computing Related to Networks, Network Mining and Analysis, Parallel, Distributed and External Memory Computing, Quantum Computing, Randomness in Computation, Theory of Security in Networks</p>



<p>Track B — Algebraic and Categorical Models, Automata, Games, and Formal Languages, Emerging and Non-standard Models of Computation, Databases, Semi-Structured Data and Finite Model Theory, Formal and Logical Aspects of Learning, Logic in Computer Science, Theorem Proving and Model Checking, Models of Concurrent, Distributed, and Mobile Systems, Models of Reactive, Hybrid and Stochastic Systems, Principles and Semantics of Programming Languages, Program Analysis and Transformation, Specification, Verification and Synthesis, Type Systems and Theory, Typed Calculi</p>



<p><strong>PC Track A chair: Artur Czumaj</strong> (University  of Warwick)<br/><strong>PC Track B chair: Anuj Dawar</strong> (University of Cambridge)</p>



<p>Contact<br/>All questions about submissions should be emailed to the PC Track chairs:<br/>Artur Czumaj <a href="mailto:A.Czumaj@warwick.ac.uk">A.Czumaj@warwick.ac.uk&lt;mailto:A.Czumaj@warwick.ac.uk&gt;</a><br/>Anuj Dawar <a href="mailto:Anuj.Dawar@cl.cam.ac.uk">Anuj.Dawar@cl.cam.ac.uk&lt;mailto:Anuj.Dawar@cl.cam.ac.uk&gt;</a></p></div>
    </content>
    <updated>2020-02-08T15:01:28Z</updated>
    <published>2020-02-08T15:01:28Z</published>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-03-07T22:21:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=387</id>
    <link href="https://tcsplus.wordpress.com/2020/02/06/tcs-talk-wednesday-february-12-albert-atserias-universitat-politecnica-de-catalunya/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 12 — Albert Atserias, Universitat Politecnica de Catalunya</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Albert Atserias from Universitat Politecnica de Catalunya will speak about “Automating Resolution is NP-Hard” (abstract below). Please make sure you reserve a spot for your group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Albert Atserias</strong> from Universitat Politecnica de Catalunya will speak about “<em>Automating Resolution is NP-Hard</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We show that it is NP-hard to distinguish CNF formulas that have Resolution refutations of almost linear length from CNF formulas that do not even have weakly exponentially long ones. It follows from this that Resolution is not automatable in polynomial time unless P = NP, or in weakly exponential time unless ETH fails. The proof of this is simple enough that all its ideas can be explained in a talk. Along the way, I will try to explain the process of discovery that led us to the result. This is joint work with Moritz Müller.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-02-06T22:05:58Z</updated>
    <published>2020-02-06T22:05:58Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5488</id>
    <link href="https://adamsheffer.wordpress.com/2020/02/04/an-algorithms-course-with-minimal-prerequisites/" rel="alternate" type="text/html"/>
    <title>An Algorithms Course with Minimal Prerequisites</title>
    <summary>There are amazing materials for teaching theoretical algorithms courses: excellent books, lecture notes, and online courses. But none of the resources I am familiar with fits the algorithms course I was supposed to prepare. I wanted to teach a course for students who hardly have any prerequisites. My students are non-CS majors (mostly math majors), […]</summary>
    <updated>2020-02-04T20:21:05Z</updated>
    <published>2020-02-04T20:21:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-03-07T22:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2109</id>
    <link href="https://francisbach.com/acceleration-without-pain/" rel="alternate" type="text/html"/>
    <title>Acceleration without pain</title>
    <summary>I don’t know of any user of iterative algorithms who has not complained one day about their convergence speed. Whether the data are too big, the processors not fast or numerous enough, waiting for an algorithm to converge unfortunately remains a core practical component of computer science and applied mathematics. This was already a concern...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">I don’t know of any user of iterative algorithms who has not complained one day about their convergence speed. Whether the data are too big, the processors not fast or numerous enough, waiting for an algorithm to converge unfortunately remains a core practical component of computer science and applied mathematics. This was already a concern long before computers were invented (and most of the techniques I will describe date back to the early 19th century): imagine you are doing all the operations (multiplications, additions, divisions) by hand, wouldn’t you want some cheap way to accelerate your algorithm (and here literally reduce your pain)?</p>



<p class="justify-text">Acceleration is a key concept in numerical analysis and can be carried through in two main ways. The first way is to modify some steps of the algorithm (such as Nesterov acceleration for gradient descent, or <a href="https://francisbach.com/chebyshev-polynomials/">Chebyshev</a> / <a href="https://francisbach.com/jacobi-polynomials/">Jacobi</a> acceleration for linear recursions). This requires a good knowledge of the inner structure of the underlying algorithm. A second way is to totally ignore the specifics of the algorithm, and see the acceleration problem as trying to find good “combinations” of the observed iterates that converge faster.</p>



<p class="justify-text">In this blog post, I thus consider a sequence of iterates \((x_k)_{k \geq 0}\) in \(\mathbb{R}^d\) obtained from an iterative algorithm \(x_{k+1} = T(x_k)\), which will typically be an optimization algorithm. The main question I will address is: Can we do better than outputting the last iterate?</p>



<p class="justify-text">This has a long history in numerical analysis, where many techniques have been developed for uni-dimensional sequences. Acceleration techniques vary according to the <a href="https://en.wikipedia.org/wiki/Rate_of_convergence">type of convergence</a> of the original sequence (quadratic, linear, sublinear), the amount of knowledge about the asymptotic behavior, and the possibility of extensions to high-dimensional and noisy problems.</p>



<p class="justify-text">Acceleration techniques are often based on an explicit or implicit modelling of the sequence \(x_k\), either through a model of the function \(T: \mathbb{R}^d \to \mathbb{R}^d\) (the iteration of the algorithm) or through an asymptotic expansion of \(x_k\). In this post, I will focus on linearly convergent sequences, that is, sequences \(x_k\) converging to some \(x_\ast\) at an exponential rate. As we will see, this will done through modelling \(x_k\) as an autoregressive process.</p>



<p class="justify-text">I will first start from the simplest scheme, the <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitken’s \(\Delta^2\) process</a> from 1926 [1], then look at higher order generalizations still in one dimension, and finally to the general vector case. We will then apply all that to gradient descent.</p>



<h2>Aitken’s \(\Delta^2\) process</h2>



<p class="justify-text">This is the simplest of all techniques and the source of all others in this post. We try to model \(x_k\in \mathbb{R}\) as first-order auto-regressive sequence, that is, \(x_{k+1} = ax_{k}+b\), for \(a,b \in \mathbb{R}\). The method works by (a) estimating \(a\) and \(b\) from a sequence of few consecutive (here three) iterates, and (b) extrapolating by computing the limit \(x_{\rm acc}\) of the estimated model. Given that we fit the model to consecutive iterates \((x_k,x_{k+1},x_{k+2})\), the model \((a,b)\) will also depend on \(k\), as well as its limit \(x_{\rm acc}\). In order to avoid having too many \(k\)’s in my notations, I will drop the dependence in \(k\) of the model parameters.</p>



<p class="justify-text">In this situation, the model recursion has a limit when \(a \neq 1\), and the limit is \(x_{\rm acc} =  \frac{b}{1-a}\). In order to fit the two parameters, we need two equations, which can be obtained by considering two consecutive evaluations of the recursions (which require three iterates). That is, we consider the linear system in \((a,b)\): $$ \Big\{ \begin{array}{ll} ax_{k}+b  &amp; = x_{k+1} \\    ax_{k+1}+b &amp; = x_{k+2} \end{array}$$ which can be solved in a variety of ways. All of them are equivalent, but naturally lead to different extensions.</p>



<p class="justify-text"><strong>Solving by elimination.</strong> We can eliminate \(b\) by subtracting the two equations, leading to $$ x_{k+2}  – x_{k+1} = a ( x_{k+1} – x_{k}),$$  and thus $$a = \frac{ x_{k+2}  – x_{k+1}}{ x_{k+1} – x_{k}}.$$ We then get $$b = x_{k+1} – a x_{k} = x_{k+1} –  \frac{ x_{k+2}  – x_{k+1}}{ x_{k+1} – x_{k}} x_{k} =  \frac{  x_{k+1}^2 – x_{k} x_{k+2}}{ x_{k+1} – x_{k}}, $$ and the extrapolating sequence $$x_{\rm acc} = \frac{b}{1-a} = \frac{x_{k} x_{k+2} – x_{k+1}^2 }{-2 x_{k+1} + x_{k+2} + x_{k}},$$ which we denote \(x^{(1)}_k\), to highlight its dependence on \(k\). Note that to compute \(x^{(1)}_k\), we need access to the three iterates \((x_k,x_{k+1},x_{k+2})\), and thus, when comparing the original sequence to the extrapolated one, we will compare \(x_k\) and \(x^{(1)}_{k-2}\).</p>



<p class="justify-text"><strong>Asymptotic auto-regressive model</strong>. A key feature of the acceleration techniques that I describe in this post is that although they implicitly or explicitly model sequence with auto-regressive processes, the models do not need to be correct, that is, they also work if the autoregressive recursion is true only asymptotically, for example \(\displaystyle \frac{x_{k+1}-x_\ast}{x_k – x_\ast}\) converging to a constant \(a \in [-1,1)\). Then we also get some acceleration, which can be quantified (see the end of the post for details), and for which we present a classical example below.</p>



<p class="justify-text"><strong>Approximating \(\pi\).</strong> We consider the <a href="https://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80">Leibniz formula</a>, which is one of many ways of <a href="https://en.wikipedia.org/wiki/Approximations_of_%CF%80">approximating \(\pi\)</a>: $$ \pi = \lim_{k \to +\infty} x_k  \mbox{ with } x_k = 4 \sum_{k=0}^{+\infty} \frac{(-1)^k}{2k+1}.$$ This formula can be proved by expanding the derivative \(x \mapsto \frac{1}{1+x^2}\) of \(x \mapsto \arctan x\) as a power series and then integrating it. We can check that $$\frac{x_{k+1}-x_\ast}{x_k – x_\ast} =  \ – 1 + \frac{1}{k} + o( \frac{1}{k}), $$ and as detailed at the end of the post, we should expect the error to go from \(1/k\) to \(1/k^3\).  Below, we show the first 10 iterates of the two sequences, with the correct significant digits in bold. $$ \begin{array}{|l|l|l|} \hline k &amp; x_k &amp;  x_k^{(1)} \\ \hline  1  &amp;   4.0000   &amp;  \times \\      2  &amp;  2.6667     &amp;    \times \\  3  &amp;  \mathbf{3}.4667   &amp; \mathbf{3.1}667 \\   4 &amp;   2.8952  &amp;  \mathbf{3.1}333 \\     5  &amp;  \mathbf{3}.3397  &amp;  \mathbf{3.14}52 \\  6 &amp;   2.9760 &amp;   \mathbf{3.1}397 \\   7  &amp;  \mathbf{3}.2837  &amp;  \mathbf{3.14}27 \\   8  &amp;  \mathbf{3}.0171  &amp;  \mathbf{3.14}09 \\  9  &amp;  \mathbf{3}.2524  &amp;  \mathbf{3.14}21 \\   10  &amp;  \mathbf{3}.0418 &amp;  \mathbf{3.141}3 \\ \hline \end{array}$$ We see that the extrapolated sequence converges much faster. This is confirmed in the convergence plot below:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2148" height="283" src="https://francisbach.com/wp-content/uploads/2020/01/deltasquared.png" width="335"/>\(\Delta^2\) method on the Leibniz series.  Notice the improvement from \(O(1/k)\) to \(O(1/k^3)\).</figure></div>



<h2>Higher-order one-dimensional extensions</h2>



<p class="justify-text">The Aitken’s \(\Delta^2\) process relies on fitting a first-order auto-regressive model, or on assuming that \(x_{k+1} – x_\ast – a (x_k – x_\ast) \to 0\) asymptotically. This can be extended to \(m\)-th order constant recursions. This corresponds to modelling \(x_k\) as the sum of \(m\) exponentials.</p>



<p class="justify-text">We thus try to fit the model $$x_{k+m} = a_0 x_k + a_1 x_{k+1} + \cdots + a_{m-1} x_{k+m-1} + b = \sum_{i=0}^{m-1} a_i x_{k+i} + b, $$ which has \(m+1\) parameters. We thus need \(m + 1\) equations, that is we consider the recursion for \(k, k+1,\dots, k+m\), which requires the knowledge of the \(2m+1\) iterates \(x_k, x_{k+1},\dots,x_{k+2m}\). This leads to the \(m+1\) equations: $$x_{k+m+j} = a_0 x_{k+j} + a_1 x_{k+j+1} + \cdots + a_{m-1} x_{k+j+m-1} + b = \sum_{i=0}^{m-1} a_i x_{k+j+i} + b,$$ for \(j \in \{0,\dots,m\}\). This is a system with \(m+1\) unknowns and \(m+1\) equations, from which we could get all \(a_j\)’s and \(b\), and then the model limit as the extrapolated sequence \(x^{(m)}_k = \frac{b}{1 – a_0 – a_1 – \cdots – a_{m-1}}\). </p>



<p class="justify-text">This linear system can be solved in a variety of ways. At the end of the blog post, I show how it can be solved using determinants of Hankel-like matrices, often referred to as the <a href="https://en.wikipedia.org/wiki/Shanks_transformation">Shanks transformation</a>, which then leads to an iterative algorithm dating back from Wynn [2], which is called the <a href="https://fr.wikipedia.org/wiki/Epsilon_algorithme">\(\varepsilon\)-algorithm</a>. In order to smooth our way to the vector case extension, I will present it in a slightly non-standard way. See [3] for a detailed survey on acceleration and extrapolation.</p>



<p class="justify-text">Instead of learning the model parameters to estimate \(x_{k+m}\) from the past iterates, we focus directly on the prediction of the limit \(x_{\rm acc}\) by looking for real numbers \(c_0,\dots,c_m\) such that for all \(k\), $$\sum_{i=0}^m c_i ( x_{k+i} – x_{\rm acc} ) = 0,$$ with the arbitrary normalization \(\sum_{i=0}^m c_i = 1\). The \(c_i\)’s can be obtained from the \(a_i\)’s and \(b\) as \((c_0,c_1,\dots,c_{m-1},c_m)\propto (a_0,a_1,\dots,a_{m-1},-1)\). We then have $$x_{\rm acc} = \sum_{i=0}^m c_{i} x_{k+i}.$$ Again, the parameters \(c_i\)’s depend on \(k\), but we omit this dependence.</p>



<p class="justify-text">In order to estimate the \(m+1\) parameters \(c_0,\dots,c_m\), we subtract two versions of the equality for \(k\) and \(k+1\), leading to $$\sum_{i=0}^m c_i ( x_{k+1+i} – x_{k+i} ) = 0.$$ Defining the matrix \(U \in \mathbb{R}^{m \times (m+1)}\) by $$U_{ji} = x_{k+1+i+j} – x_{k+i+j},$$ for \(i \in \{0,\dots,m\}\) and \(j \in \{0,\dots,m-1\}\), we have $$ U c = 0. $$ Together with the constraint \(1_{m+1}^\top c = 1\), this leads to the correct number of equations to estimate \(c\), from \(2m+1\) iterates \(x_k,\dots,x_{k+2m}\). The extrapolated iterate \(x^{(m)}_k\) is then $$x^{(m)}_k = x_{\rm acc} =   \sum_{i=0}^m c_{i} x_{k+i}.$$ Note that the extrapolation is exact when the sequence is exactly following a \(m\)-th order recursion. See an example of application on the Leibniz formula below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2320" height="330" src="https://francisbach.com/wp-content/uploads/2020/02/shanks_Uc.png" width="424"/>Higher-order acceleration through the Shanks transformation for the Leibniz formula. Acceleration is possible only up to machine precision.</figure></div>



<h2>Extension to vectors</h2>



<p class="justify-text">We now consider accelerating vector sequences \(x_k \in \mathbb{R}^d\). There are multiple approaches to extend acceleration from real numbers to vectors, as presented in [4, 5]. The simplest way is to apply high-order extrapolation to all coordinates separately (which is often called the vector \(\varepsilon\)-algorithm [10]); this depends however a lot on the chosen basis, requires too many linear systems to solve, and performs worse (see examples below for gradient descent). We now present a vector extension which exists under many names: the Eddy-Mesina method [6,7], reduced rank extrapolation [4, 11, 12], or Anderson acceleration [8]. </p>



<p class="justify-text">We want to model the sequence \(x_k \in \mathbb{R}^d\) as $$x_{k+1} = A x_{k} + b,$$ where \(A \in \mathbb{R}^{d \times d}\) and \(b \in \mathbb{R}^d\). By a simple variable / equation counting arguments, there are \(d^2+d\) parameters, and we thus need \(d+1\) equations in \(\mathbb{R}^d\), and thus \(d+2\) consecutive iterates, to estimate \(A\) and \(b\). </p>



<p class="justify-text">In order to use only \(m+2\) iterates, with \(m \) much less than \(d\), we will focus directly on the extrapolation equation $$x_{\rm acc} = c_0 x_k + c_1 x_{k+1}+  \cdots +c_m x_{k+m}, $$ with the constraint that \(c_0+c_1+\cdots+c_m =1\). Therefore, we will not try to explicitly fit the model parameters \(A\) and \(b\).</p>



<p class="justify-text">A sufficient condition for good extrapolation weights is that the extrapolated version is close for two consecutive \(k\)’s, that is $$c_0 x_k + c_1 x_{k+1}+  \cdots +c_m x_{k+m} \approx c_0 x_{k+1} + c_1 x_{k+2}+  \cdots +c_m x_{k+m+1},$$ which can be rewritten as $$c_0 (x_{k}-x_{k+1}) + c_1 ( x_{k+1} -x_{k+2}) + \cdots + c_m (x_{k+m} – x_{k+m+1}) \approx 0.$$ A natural criterion is thus to minimize the \(\ell_2\)-norm $$ \big\| c_0 \Delta x_{k} + c_1  \Delta x_{k+1} + \cdots + c_m \Delta x_{k+m} \big\|_2 \mbox{ such that } c_0+c_1+\cdots+c_m = 1,$$ where \(\Delta x_{i} = x_{i} -x_{i+1}\). Denoting \(U \in \mathbb{R}^{d \times (m+1)}\) the matrix with columns \(\Delta x_{k}, \dots,  \Delta x_{k+m}\), we need to minimize \(\| U c \|_2\) such that \(c^\top 1_{m+1} = 1\), whose solution is $$ c \propto ( U^\top U)^{-1} 1_{m+1}, \mbox{ that is, } c = \frac{1}{1_{m+1}^\top (U^\top U)^{-1} 1_{m+1}}  ( U^\top U)^{-1} 1_{m+1}.$$ Note that while the weights \(c_0,\dots,c_m\) sum to one, they may be negative, that is, the extrapolated sequence is not always a convex combination (hence the name extrapolation). Moreover, note that unless \(m\) is large enough, the optimal \(U c\) is in general not equal to zero (it is when modelling real sequences, see below).</p>



<p class="justify-text">For \(m=1\), the solution is particularly simple, as we need to minimize $$ \|\Delta x_{k+1}  – c_0 ( \Delta x_{k+1} – \Delta x_k ) \|^2,$$ leading to $$c_0 = \frac{\Delta x_{k+1}^\top ( \Delta x_{k+1} – \Delta x_k )}{ \|  \Delta x_{k+1} – \Delta x_k \|^2} \mbox{ and } c_1 = \frac{\Delta x_{k}^\top ( \Delta x_{k} – \Delta x_{k+1} )}{ \|  \Delta x_{k+1} – \Delta x_k \|^2}.$$ The acute reader can check that when \(d=1\), we recover Aitken’s formula. See an example in two dimensions below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-2276" height="319" src="https://francisbach.com/wp-content/uploads/2020/02/anderson_2d.gif" width="380"/>Anderson acceleration in two dimensions. The sequence is following an auto-regressive process with a symmetric \(A\) with eigenvalues in \((-1,1)\). Anderson acceleration cancels the oscillation due to the eigenvalue with largest magnitude.</figure></div>



<p class="justify-text"><strong>Recovering one-dimensional sequence acceleration.</strong> Given a real sequence \(y_k \in \mathbb{R}\), we can define the vector \(x_k\) in \(\mathbb{R}^m\) as $$x_k = \left( \begin{array}{c} y_k \\  y_{k+1} \\ \vdots \\ y_{k+m-1} \end{array} \right).$$ One can then check that the matrix \(U\) defined for this vector sequence is exactly the same as the matrix \(U\) defined earlier for the real valued sequence. The optimal \(\| Uc \|\) is then equal to zero (which is not the case in general).</p>



<p class="justify-text"><strong>When is it exact?</strong> The derivation I followed is only intuitive, and as for the other acceleration mechanisms, a natural question is: when is it exact? We will consider linear recursions.</p>



<p class="justify-text"><strong>Analysis for linear recursions.</strong> Assuming that \(x_{k+1} = A x_{k} + b\) is exact for all \(k \geq 0\), then \(x_k – x_\ast = A^{k} ( x_0 – x_\ast)\), and thus, following [13], $$\sum_{i=0}^m c_i (x_{k+i}-x_{k+i+1}) = \sum_{i=0}^m c_i A^{i} A^{k}(I – A )(x_0 -x_\ast) = P_m(A)(I – A) A^{k}(x_0 -x_\ast) ,$$ for \(P_m(\sigma)  =  \sum_{i=0}^m c_i \sigma^{i}\) a \(m\)-th order polynomial such that \(P_m(1) = 1\). We can write \(Uc\)  as $$ Uc = P_m(A) ( x_k – x_{k+1}) = ( I – A)  P_m(A)  (x_k – x_\ast) .$$ The error between the true limit and the extrapolation is equal to: $$  x_\ast – \sum_{i=0}^m c_i x_{k+i} = \sum_{i=0}^m c_i ( x_\ast – x_{k+i}  ) = P_m(A) (   x_\ast -x_{k}) = (I-A)^{-1} Uc.$$ Thus, we have $$ \Big\| x_\ast – \sum_{i=0}^m c_i x_{k+i} \Big\|_2 \leq \| U c \|_2 \times  \|(I – A)^{-1}\|_{\rm op} \leq \|(I – A)^{-1}\|_{\rm op}  \|I – A\|_{\rm op} \|P_m(A) ( x_k – x_\ast)\|.  $$</p>



<p class="justify-text">The method will be exact when one can find a degree \(m\) polynomial so that \(P_m(A) (x_{k} – x_\ast) = 0 \), and a sufficient condition is that \(P_m(A)=0\), which is only possible if \(A\) had only \(m\) distinct eigenvalues. This is exactly minimal polynomial extrapolation [9]. Another situation is when \(m = d\) (like for the special case of real sequences above). </p>



<p class="justify-text">Otherwise, the method will be inexact, but the method can find a good polynomial \(P_m\), and the error is less than the infimum of \( \|P_m(A) ( x_k – x_\ast)\|\) over all polynomial of degree \(m\) such that \(P_m(1)=1\). Assuming that the matrix \(A\) is symmetric and with all eigenvalues between \(-\rho\) and \(\rho\) (which will be the case for the gradient method below), then the error is less than the infimum of \(\sup_{\sigma \in [-\rho,\rho]} |P_m(\sigma)|\),  which is attained for the Chebyshev polynomial (see a <a href="https://francisbach.com/chebyshev-polynomials/">previous post</a>). The improvement in terms of convergence is similar to Chebyshev acceleration, but (a) without the need to know \(\rho\) in advance (the method is totally adaptive), and (b) with a provable robustness when the iterates deviate from following an autoregressive process (see [13] for details).</p>



<p class="justify-text"><strong>Going beyond linear recursions. </strong>As presented, Anderson acceleration does not lead to stable acceleration (see the experiment below for gradient descent). The main reason is that when iterates deviate from an autoregressive process, or when the recursion is naturally noisy, the estimation of the parameters \(c\) is unstable, in particular because the matrix \(U^\top U\) which has to be inverted is severely ill-conditioned [14]. In a joint work with Damien Scieur and Alexandre d’Aspremont, we considered regularizing  the estimation of \(c\) by penalizing its \(\ell_2\)-norm. We thus minimize  \( \| U c \|_2^2 + \lambda \| c\|_2^2\) such that \(c^\top 1_{m+1} = 1\), whose solution is $$ c \propto ( U^\top U + \lambda I)^{-1} 1_{m+1}, \mbox{ that is, } c = \frac{1}{1_{m+1}^\top (U^\top U + \lambda I)^{-1} 1_{m+1}}  ( U^\top U +  \lambda I)^{-1} 1_{m+1}.$$ This simple modification leads to theoretical guarantees for non-linear recursions, and I will refer to it as regularized non-linear acceleration (RNA, see [13] for details; the “non-linearity” comes from the non-linear dependence of \(c\) on the iterates).</p>



<h2>Application to gradient descent</h2>



<p class="justify-text">We can apply RNA to the recursion, $$x_{k+1}  = x_k – \gamma \nabla f(x_k),$$ where \(f: \mathbb{R}^d \to \mathbb{R}^d\) is a differentiable function, and \(\gamma\) a step-size. In the plot below, we consider accelerating gradient descent with \(m\)-th order RNA, with \(m=8\). We compare this acceleration with applying RNA to each variable separately (“RNA-univ.”), and to the unregularized version (“Anderson”). We can see the benefits of our simple extrapolation steps, and in particular the instability of unregularized acceleration.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2331" height="326" src="https://francisbach.com/wp-content/uploads/2020/02/anderson_grad_nonest.png" width="419"/>Gradient descent on a regularized <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> problem, with 1000 observations in dimension 100. We compare regular gradient descent, to plain Anderson acceleration (with no regularization), RNA [13] applied to each variable separately, and RNA. All accelerations are with order \(m =8\).</figure></div>



<p class="justify-text">In order to obtain stronger benefits from non-linear acceleration, several extensions are considered in [13]; in particular line search to find the good regularization parameter \(\lambda\) is quite useful. Another interesting extension is the <em>online</em> version of the algorithm [16, section 2.5], where the extrapolated sequence is used directly within the acceleration procedure, and not as a separate sequence with no interaction with the original gradient method: this corresponds to using RNA to accelerate iterates coming from RNA!</p>



<p class="justify-text">Moreover, while the simplest theoretical guarantees come for deterministic convex optimization problems and gradient descent, RNA can be extended to stochastic algorithms [15] and to non-convex optimization problems such as the ones encountered in deep learning [16].</p>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I described acceleration techniques that combine iterates of an existing algorithm, without the need to understand finely the inner structure of the original algorithm. They come at little extra-cost and can provide strong benefits.</p>



<p class="justify-text">This month’s post was dedicated to algorithms which converge linearly, that is, the iterates are asymptotically equivalent to sums of exponentials. Next month, I will consider situations where the convergence is sublinear, where <a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">Richardson extrapolation</a> excels.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. This post is based on joint work with Damien Scieur and Alexandre d’Aspremont, and in particular on their presentation slides. I would also like to thank them for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Alexander Aitken, On Bernoulli’s numerical solution of algebraic equations, <em>Proceedings of the Royal Society of Edinburgh</em>, 46:289–305, 1926.<br/>[2] Peter Wynn. On a device for computing the \(e_m(S_n)\) transformation. <em>Mathematical Tables and Other Aids to Computation</em>, 91-96, 1956.<br/>[3] Claude Brezinski. <em>Accélération de la convergence en analyse numérique</em>. Lecture notes in mathematics, Springer (584), 1977.<br/>[4] David A. Smith, William F. Ford, Avram Sidi. Extrapolation methods for vector sequences. <em>SIAM review</em>, 29(2):199-233, 1987<br/>[5] Allan J. Macleod. Acceleration of vector sequences by multi‐dimensional \(\Delta^2\) methods. <em>Communications in Applied Numerical Methods</em>, 2(4):385-392, 1986.<br/>[6] Marián Mešina. Convergence acceleration for the iterative solution of the equations X= AX+ f. <em>Computer Methods in Applied Mechanics and Engineering</em>, <em>10</em>(2), 1977.<br/>[7] Robert P. Eddy. Extrapolating to the limit of a vector sequence. <em>Information linkage between applied mathematics and industry</em>, 387-396, 1979.<br/>[8] Homer F. Walker, Peng Ni. Anderson acceleration for fixed-point iterations. <em>SIAM Journal on Numerical Analysis</em>, 49(4):1715-1735, 2011.<br/>[9] Sidi, Avram, William F. Ford, and David A. Smith. Acceleration of convergence of vector sequences. <em>SIAM Journal on Numerical Analysis</em> 23(1):178-196, 1986.<br/>[10] Peter Wynn. Acceleration techniques for iterated vector and matrix problems. <em>Mathematics of Computation</em>, 16(79), 301-322,  1962.<br/>[11] Stan Cabay,  L. W. Jackson. A polynomial extrapolation method for finding limits and antilimits of vector sequences. <em>SIAM Journal on Numerical Analysis</em>, 13(5), 734-752, 1976.<br/>[12] Stig Skelboe. Computation of the periodic steady-state response of nonlinear networks by extrapolation methods. <em>IEEE Transactions on Circuits and Systems</em>, 27(3), 161-175, 1980.<br/>[13] Damien Scieur, Alexandre d’Aspremont, Francis Bach. Regularized Nonlinear Acceleration. <em>Mathematical Programming</em>, 2018.<br/>[14] Evgenij E. Tyrtyshnikov. How bad are Hankel matrices? <em>Numerische Mathematik</em>, 67(2):261-269, 1994.<br/>[15] Damien Scieur, Alexandre d’Aspremont, Francis Bach. Nonlinear Acceleration of Stochastic Algorithms. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2017.<br/>[16] Damien Scieur, Edouard Oyallon, Alexandre d’Aspremont, Francis Bach. Nonlinear Acceleration of Deep Neural Networks. Technical report, arXiv-1805.09639, 2018.</p>



<h2>Asymptotic analysis for Aitken’s \(\Delta^2\) process</h2>



<p class="justify-text">In one dimension, we do not need the auto-regressive model to be exact, and an asymptotic analysis is possible. The asymptotic condition corresponds to \(\displaystyle \frac{x_{k+1}-x_\ast}{x_k – x_\ast}\) converging to a constant \(a \in [-1,1)\). More precisely if $$\frac{x_{k+1}-x_\ast}{x_k – x_\ast} = a + \varepsilon_{k+1},$$ with \(\varepsilon_k\) tending to zero, then we can estimate \(a\) through the <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitkens \(\Delta^2\) method</a> [1] as, $$ a_{k+1} = \frac{x_{k+1}-x_k}{x_{k}-x_{k-1}} = \frac{(x_{k+1}-x_\ast) – (x_k-x_\ast) }{(x_{k} – x_\ast) -( x_{k-1}-x_\ast) } = \frac{ a + \varepsilon_{k+1} – 1}{1 – 1/(a+\varepsilon_{k})} = a + \varepsilon_{k+1} + o( \varepsilon_{k+1}).$$ A closer Taylor expansion leads to $$ a + \varepsilon_{k} + \frac{1}{a-1}( \varepsilon_{k+1}- \varepsilon_{k}) + O(\varepsilon_{k}^2).$$ We can then provide a better estimate of \(x_\ast\) as $$ \frac{x_{k+1} – a_{k+1}x_k}{1- a_{k+1}} = x_\ast + \frac{x_{k+1} -x_\ast – a_{k+1}( x_k-x_\ast)}{1- a_{k+1}} = x_\ast + \frac{(a+\varepsilon_{k+1}-a_{k+1}) ( x_k – x_\ast)}{1-a_{k+1}},$$ whose difference with \(x_\ast\) is equivalent to $$ \frac{(a+\varepsilon_k-a_{k+1}) ( x_k – x_\ast)}{1-a }  \sim \frac{\varepsilon_{k+1}- \varepsilon_{k}}{(1-a)^2} ( x_k – x_\ast).$$ We have thus provided an acceleration of order \(\displaystyle \frac{\varepsilon_{k+1}- \varepsilon_{k}}{(1-a)^2} \).</p>



<h2>High-order Shanks transformation</h2>



<p>In order to relate our formulas to classical expressions, we first rewrite the recursion for \(m=1\) and then \(m=2\), and then to general \(m\).</p>



<p class="justify-text"><strong>First-order recursion (Aitken’s \(\Delta^2\)).</strong> We write the autorecursive recursion as $$ (x_{k+1} – x_\ast) = a ( x_{k} – x_\ast) \Leftrightarrow c_0(x_k – x_\ast) + c_1 (x_{k+1}-x_\ast) = 0 ,$$ with the constraint \(c_0 + c_1 = 1\), that is, \(c_0 = \frac{-a}{1-a}\) and \(c_1 = \frac{1}{1-a}\). We can then write \(x_\ast = c_0 x_k + c_1 x_{k+1}\), and we have the linear system in \((c_0,c_1,x_\ast)\): $$  \left( \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; 0 \\ 1 &amp; 1 &amp; 0 \\ x_k &amp; x_{k+1} &amp; – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using Cramer’s formula $$x_{\rm acc} = x_\ast = \frac{\left| \begin{array}{cc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2}  \\ x_{k} &amp; x_{k+1} \end{array}\right|}{\left| \begin{array}{cc}  x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2}  \\ 1 &amp; 1 \end{array}\right|},$$  which leads to the same formula for \(x^{(1)}_k\).</p>



<p class="justify-text"><strong>Second-order recursion.</strong> Here, we only consider the case \(m=2\) for simplicity. We consider the model, $$c_0 (x_k – x_\ast) + c_1 (x_{k+1} – x_\ast)+ c_{2} (x_{k+2} – x_\ast) = 0, $$ with the normalization \(c_0 + c_1 + c_2 = 1\). We can then extract \(x_\ast\) as $$ x_\ast = c_0 x_k + c_1 x_{k+1} +  c_2 x_{k+2}.$$ In order to provide the extra \(2\) equations that are necessary to estimate the three parameters, we take first order differences and get $$c_0 (x_k -x_{k+1}) + c_1 (x_{k+1}-x_{k+2}) +  c_2 ( x_{k+2} – x_{k+3} ) =0,$$ for \(k\) and \(k+1\). This leads to the linear system in \((c_0,c_1, c_2, x_\ast)\): $$  \left( \begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3} &amp; 0 \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4} &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0  \\ x_{k} &amp; x_{k+1} &amp; x_{k+2} &amp;  – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ c_2 \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c}  0  \\ 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using <a href="https://en.wikipedia.org/wiki/Cramer%27s_rule">Cramer’s rule</a> (and classical manipulations of determinants) as $$x_k^{(2)} = \frac{\left| \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3}   \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4}   \\ x_{k} &amp; x_{k+1} &amp; x_{k+2}    \end{array} \right|}{\left| \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3}     \\ x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4}   \\ 1 &amp; 1 &amp; 1 &amp;  \end{array} \right|}.$$  </p>



<p class="justify-text">The formula extends to order \(m\) (see below) and is often called the Shanks transformation; it is cumbersome and not easy to use. However, the coefficients can be computed recursively (which is to be expected for a Hankel matrix, but rather tricky to derive), through Wynn’s \(\varepsilon\)-algorithm.  See [3] for a survey on acceleration and extrapolation.</p>



<p class="justify-text"><strong>Higher-order recursion.</strong> We consider the model, for \(m \geq 1\), $$c_0 (x_k – x_\ast) + c_1 (x_{k+1} – x_\ast) + \cdots + c_{m} (x_{k+m} – x_\ast) = 0, $$ with the normalization \(c_0 + c_1 + \cdots + c_m = 1\). We can then extract \(x_\ast\) as $$ x_\ast = c_0 x_k + c_1 x_{k+1} + \cdots + c_m x_{k+m}.$$ In order to provide the extra \(m\) equations, we take first order differences and get $$c_0 (x_k -x_{k+1}) + c_1 (x_{k+1}-x_{k+2}) + \cdots + c_m ( x_{k+m} – x_{k+m+1} ) =0,$$ for \(k, k+1,\dots, k+m-1\). This leads to the linear system in \((c_0,c_1,\cdots, c_m, x_\ast)\): $$  \left( \begin{array}{ccccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} &amp; 0 \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2} &amp; 0 \\ \vdots &amp; \vdots &amp;  &amp; \vdots  &amp; \vdots \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} &amp; 0 \\ 1 &amp; 1 &amp; \dots &amp; 1 &amp; 0  \\ x_{k+m+1} &amp; x_{k+m+2} &amp; \cdots &amp; x_{k+2m+1} &amp;  – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ \vdots \\ c_m \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using Cramer’s formula $$x_\ast = \frac{\left|\begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2}   \\ \vdots &amp; \vdots &amp;  &amp; \vdots  \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} \\ x_{k+m+1} &amp; x_{k+m+2} &amp; \cdots &amp; x_{k+2m+1}  \end{array} \right|}{\left|\begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2}   \\ \vdots &amp; \vdots &amp;  &amp; \vdots  \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} \\ 1 &amp; 1 &amp; \cdots &amp; 1 \end{array}  \right|}.$$  </p>



<p class="justify-text">Like for \(m=1\), Wynn’s \(\varepsilon\)-algorithm can be used to compute the iterates recursively.</p></div>
    </content>
    <updated>2020-02-04T19:44:55Z</updated>
    <published>2020-02-04T19:44:55Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-03-07T22:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=703</id>
    <link href="https://emanueleviola.wordpress.com/2020/02/02/the-will-of-the-framers/" rel="alternate" type="text/html"/>
    <title>The will of the framers</title>
    <summary>What a great title for a legal thriller. And for a history buff like me — something I never thought I would become and that must be a side effect of having learnt absolutely zero history in school — how arousing it is to hear what John Adams said in 1776, and details of the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>What a great title for a legal thriller.  And for a history buff like me — something I never thought I would become and that must be a side effect of having learnt absolutely zero history in school — how arousing it is to hear what John Adams said in 1776, and details of the Great Debate, and the rhetoric!  It is  apt that I am following the discussion on an analog radio, my habit of the last 10 years or so, another thing I never thought I would do but that I actually find quite relaxing now.  It takes my mind off my own worry, and it soothes my eyes.  I recommend it at small doses to avoid sudden onset of nausea.  It is also apt that I follow it from <a href="https://www.redfin.com/MA/Chestnut-Hill/150-Woodland-Rd-02467/home/11457721">my house</a>, built two centuries ago though not as long ago as reported online, as I recently discovered sifting historical records. It comes to my mind that I now know what it means to renovate an old house. This is not something that I can recommend, but it is an experience that has had a profound and lasting impact on me.  I am aware of mortise locks, three-tab shingles, the terminological jungle of drywall et similia, caulking, baseboards, the difference between granite and quartz, between 4-inch and no backsplash, pvc, fixtures, the evolution of toilets and countless other things that I can’t list but that suddenly spring up in my mind when entering any house, including most recent additions such as the electrical system.</p>



<p>Once, while waiting for yet another late sub-contractor I wrote:</p>



<p>The revenge of the housekeepers</p>



<p>For centuries they slept in niches inside their masters’ houses, cooked meals in crammed kitchens, hand-washed laundry bent in basements. Now they are gone, but the houses still stand. Their niches are our offices where we can’t fit a table. We spend most of our family time in the crammed kitchen, the other rooms unused since nobody has the energy to shuttle the food, or clean. And faltering to hoist the laundry load from the basement we bump the head.</p></div>
    </content>
    <updated>2020-02-02T14:38:00Z</updated>
    <published>2020-02-02T14:38:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=385</id>
    <link href="https://tcsplus.wordpress.com/2020/02/01/tcs-spring-approaches-talks-resume/" rel="alternate" type="text/html"/>
    <title>TCS+: Spring approaches, talks resume!</title>
    <summary>The winter hiatus is nearly over, and the new season of TCS+ is about to start! Our first two talks will take place on Feb 12th and 26th, respectively. We’re pretty excited about them… On February 12th, 1pm EST, Albert Atserias (Universitat Politecnica de Catalunya) will tell us all about how Automating Resolution is NP-Hard. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The winter hiatus is nearly over, and the new season of TCS+ is about to start! Our first two talks will take place on Feb 12th and 26th, respectively. We’re pretty excited about them…</p>
<ul>
<li>On February 12th, 1pm EST, <a href="https://www.cs.upc.edu/~atserias/">Albert Atserias</a> (Universitat Politecnica de Catalunya) will tell us all about how <em>Automating Resolution is NP-Hard</em>.</li>
<li>Then, on February 26th, <a href="http://www.henryyuen.net/">Henry Yuen</a> (University of Toronto) will speak about the recent proof that <em>MIP*=RE</em>.</li>
</ul>
<p>Stay tuned for the official talk announcements. And this is only the beginning of the semester…</p>
<p><em>In the meantime, if you have suggestions, <a href="https://sites.google.com/site/plustcs/suggest">here is the link</a>.</em></p></div>
    </content>
    <updated>2020-02-01T20:21:13Z</updated>
    <published>2020-02-01T20:21:13Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/01/28/krajiceks-fest-celebrating-jan-krajiceks-60th-anniversary-and-his-contributions-to-logic-and-complexity/</id>
    <link href="https://cstheory-events.org/2020/01/28/krajiceks-fest-celebrating-jan-krajiceks-60th-anniversary-and-his-contributions-to-logic-and-complexity/" rel="alternate" type="text/html"/>
    <title>Krajíček’s Fest – Celebrating Jan Krajíček’s 60th Anniversary and his Contributions to Logic and Complexity</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 1, 2020 Tábor, Czech Republic https://www.dcs.warwick.ac.uk/~igorcarb/events/krajicek-fest/index.html We would like to invite you to participate in a workshop on the Logical Foundations of Complexity Theory to celebrate Prof. Jan Krajicek’s 60th anniversary. Preliminary list of speakers: Pavel Pudlák (Czech Adacemy of Sciences) Samuel Buss (University of California, San Diego) Neil Thapen (Czech Adacemy of Sciences) … <a class="more-link" href="https://cstheory-events.org/2020/01/28/krajiceks-fest-celebrating-jan-krajiceks-60th-anniversary-and-his-contributions-to-logic-and-complexity/">Continue reading <span class="screen-reader-text">Krajíček’s Fest – Celebrating Jan Krajíček’s 60th Anniversary and his Contributions to Logic and Complexity</span></a></div>
    </summary>
    <updated>2020-01-28T15:05:13Z</updated>
    <published>2020-01-28T15:05:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=697</id>
    <link href="https://emanueleviola.wordpress.com/2020/01/17/what-is-wrong-with-this/" rel="alternate" type="text/html"/>
    <title>What is wrong with this?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-698" src="https://emanueleviola.files.wordpress.com/2020/01/xinfertilitygraph.png?w=350"/></figure></div></div>
    </content>
    <updated>2020-01-17T18:36:31Z</updated>
    <published>2020-01-17T18:36:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1234</id>
    <link href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/" rel="alternate" type="text/html"/>
    <title>A Masters project</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In a previous post I reported on the beautiful recent result by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, . In this post I want to report on follow-up … <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In a <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">previous post</a> I reported on the beautiful <a href="https://arxiv.org/abs/1904.05870">recent result</a> by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, <img alt="{\text{NEEXP} \subseteq \text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEEXP%7D+%5Csubseteq+%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{NEEXP} \subseteq \text{MIP}^\star}"/>. In this post I want to report on follow-up work with Ji, Natarajan, Wright, and Yuen, that we just posted to <a href="https://arxiv.org/abs/2001.04383">arXiv</a>. This time however I will tell the story from a personal point of view, with all the caveats that this implies: the “hard science” will be limited (but there could be a hint as to how “science”, to use a big word, “progresses”, to use an ill-defined one), the story is far too long, and it might be mostly of interest to me only. It’s a one-sided story, but that has to be. (In particular below I may at times attribute credit in the form “X had this idea”. This is my recollection only, and it is likely to be inaccurate. Certainly I am ignoring a lot of important threads.) I wrote this because I enjoyed recollecting some of the best moments in the story just as much as some the hardest; it is fun to look back and find meanings in ideas that initially appeared disconnected. Think of it as an example of how different lines of work can come together in unexpected ways; a case for open-ended research. It’s also an antidote against despair that I am preparing for myself: whenever I feel I’ve been stuck on a project for far too long, I’ll come back to this post and ask myself if it’s been 14 years yet — if not, then press on.</p>
<p>It likely comes as a surprise to me only that I am no longer fresh out of the cradle. My academic life started in earnest some 14 years ago, when in the Spring of 2006 I completed my Masters thesis in Computer Science under the supervision of Julia Kempe, at Orsay in France. I had met Julia the previous term: her class on quantum computing was, by far, the best-taught and most exciting course in the Masters program I was attending, and she had gotten me instantly hooked. Julia agreed to supervise my thesis, and suggested that I look into some interesting recent result by Stephanie Wehner that linked the study of entanglement and nonlocality in quantum mechanics to complexity-theoretic questions about interactive proof systems (specifically, this was Stephanie’s <a href="https://arxiv.org/abs/quant-ph/0508201">paper</a> showing that <img alt="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar+%5Csubseteq+%5Ctext%7BQIP%7D%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}"/>).</p>
<p>At the time the topic was very new. It had been initiated the previous year with a beautiful <a href="https://arxiv.org/abs/quant-ph/0404076">paper</a> by Cleve et al. (that I have recommended to many a student since!). It was a perfect fit for me: the mathematical aspects of complexity theory and quantum computing connected to my undergraduate background, while the relative concreteness of quantum mechanics (it is a physical theory after all) spoke to my desire for real-world connection (not “impact” or even “application” — just “connection”). Once I got myself up to speed in the area (which consisted of three papers: the two I already mentioned, together with a <a href="https://arxiv.org/abs/cs/0102013">paper</a> by Kobayashi and Matsumoto where they studied interactive proofs with quantum messages), Julia suggested looking into the the “entangled-prover” class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> introduced in the aforementioned paper by Cleve et al. Nothing was known about this class! Nothing besides the trivial inclusion of single-prover interactive proofs, IP, and the containment in…ALL, the trivial class that contains all languages.<br/>
Yet the characterization MIP=NEXP of its classical counterpart by Babai et al. in the 1990s had led to one of the most productive lines of work in complexity of the past few decades, through the PCP theorem and its use from hardness of approximation to efficient cryptographic schemes. Surely, studying <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> had to be a productive direction? In spite of its well-established connection to classical complexity theory, via the formalism of interactive proofs, this was a real gamble. The study of entanglement from the complexity-theoretic perspective was entirely new, and bound to be fraught with difficulty; very few results were available and the existing lines of works, from the foundations of nonlocality to more recent endeavors in device-independent cryptography, provided little other starting point than strong evidence that even the simplest examples came with many unanswered questions. But my mentor was fearless, and far from a novice in terms of defraying new areas, having done pioneering work in areas ranging from quantum random walks to Hamiltonian complexity through adiabatic computation. Surely this would lead to something?</p>
<p>It certainly did. More sleepless nights than papers, clearly, but then the opposite would only indicate dullness. Julia’s question led to far more unexpected consequences than I, or I believe she, could have imagined at the time. I am writing this post to celebrate, in a personal way, the latest step in 15 years of research by dozens of researchers: today my co-authors and I uploaded to the quant-ph arXiv what we consider a complete characterization of the power of entangled-prover interactive proof systems by proving the equality <img alt="{\text{MIP}^\star = \text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star = \text{RE}}"/>, the class of all recursively enumerable languages (a complete problem for RE is the halting problem). Without goign too much into the result itself (if you’re interested, we have a long introduction waiting for you), and since this is a personal blog, I will continue on with some personal thoughts about the path that got us there.</p>
<p>When Julia &amp; I started working on the question, our main source of inspiration were the results by Cleve et al. showing that the nonlocal correlations of entanglement had interesting consequences when seen through the lens of interactive proof systems in complexity theory. Since the EPR paper a lot of work in understanding entanglement had already been accomplished in the Physics community, most notably by Mermin, Peres, Bell, and more recently the works in device-indepent quantum cryptography by Acin, Pironio, Scarani and many others stimulated by Ekert’s proposal for quantum key distribution and Mayers and Yao’s idea for “device-independent cryptography”. By then we certainly knew that “spooky action-at-a-distance” did not entail any faster-than-light communication, and indeed was not really “action-at-a-distance” in the first place but merely “correlation-at-a-distance”. What Cleve et al. recognized is that these “spooky correlations-at-a-distance” were sufficiently special so as to not only give numerically different values in “Bell inequalities”, the tool invented by Bell to evidence nonlocality in quantum mechanics, but also have some potentially profound consequences in complexity theory. In particular, examples such as the “Magic Square game” demonstrated that enough correlation could be gained from entanglement so as to defeat basic proof systems whose soundness relied only on the absence of communication between the provers, an assumption that until then had been wrongly equated with the assumption that any computation performed by the provers could be modeled entirely locally. I think that the fallacy of this implicit assumption came as a surprise to complexity theorists, who may still not have entirely internalized it. Yet the perfect quantum strategy for the Magic Square game provides a very concrete “counter-example” to the soundness of the “clause-vs-variable” game for 3SAT. Indeed this game, a reformulation by Aravind and Cleve-Mermin of a Bell Inequality discovered by Mermin and Peres in 1990, can be easily re-framed as a 3SAT system of equations that is <em>not</em> satisfiable and yet is such that the associated two-player clause-vs-variable game has a <em>perfect</em> quantum strategy. It is this observation, made in the paper by Cleve et al., that gave the first strong hint that the use of entanglement in interactive proof systems could make many classical results in the area go awry.</p>
<p>By importing the study of non-locality into complexity theory Cleve et al. immediately brought it into the realm of asymptotic analysis. Complexity theorists don’t study fixed objects, they study families of objects that tend to have a uniform underlying structure and whose interesting properties manifest themselves “in the limit”. As a result of this new perspective focus shifted from the study of single games or correlations to infinite families thereof. Some of the early successes of this translation include the “unbounded violations” that arose from translating asymptotic separations in communication complexity to the language of Bell inequalities and correlations (e.g. this <a href="https://arxiv.org/abs/1012.5043">paper</a>). These early successes attracted the attention of some physicists working in foundations as well as some mathematical physicists, leading to a productive exploration that combined tools from quantum information, functional analysis and complexity theory.</p>
<p>The initial observations made by Cleve et al. had pointed to <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> as a possibly interesting complexity class to study. Rather amazingly, nothing was known about it! They had shown that under strong restrictions on the verifier’s predicate (it should be an XOR of two answer bits), a collapse took place: by the work of Hastad, XOR-MIP equals NEXP, but <img alt="{\text{XOR-MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{XOR-MIP}^\star}"/> is included in EXP. This seemed very fortuitous (the inclusion is proved via a connection with semidefinite programming that seems tied to the structure of XOR-MIP protocols): could entanglement induce a collapse of the entire, unrestricted class? We thought (at this point mostly Julia thought, because I had no clue) that this ought not to be the case, and so we set ourselves to show that the equality <img alt="{\text{MIP}^\star=\text{NEXP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star=\text{NEXP}}"/>, that would directly parallel Babai et al.’s characterization MIP=NEXP, holds. We tried to show this by introducing techniques to “immunize” games against entanglement: modify an interactive proof system so that its structure makes it “resistant” to the kind of “nonlocal powers” that can be used to defeat the clause-vs-variable game (witness the Magic Square). This was partially successful, and led to one of the papers I am most proud of — I am proud of it because I think it introduced elementary techniques (such as the use of the Cauchy-Schwarz inequality — inside joke — more seriously, basic things such as “prover-switching”, “commutation tests”, etc.) that are now routine manipulations in the area. The paper was a hard sell! It’s good to remember the first rejections we received. They were not unjustified: the main point of criticism was that we were only able to establish a hardness result for exponentially small completeness-soundness gap. A result for such a small gap in the classical setting follows directly from a very elementary analysis based on the Cook-Levin theorem. So then why did we have to write so many pages (and so many applications of Cauchy-Schwarz!) to arrive at basically the same result (with a <img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{^\star}"/>)?</p>
<p>Eventually we got lucky and the paper was accepted to a conference. But the real problem, of establishing any non-trivial lower bound on the class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> with constant (or, in the absence of any parallel repetition theorem, inverse-polynomial) completeness-soundness gap, remained. By that time I had transitioned from a Masters student in France to a graduate student in Berkeley, and the problem (pre-)occupied me during some of the most difficult years of my Ph.D. I fully remember spending my first year entirely thinking about this (oh and sure, that systems class I had to pass to satisfy the Berkeley requirements), and then my second year — yet, getting nowhere. (I checked the arXiv to make sure I’m not making this up: two full years, no posts.) I am forever grateful to my fellow student Anindya De for having taken me out of the cycle of torture by knocking on my door with one of the most interesting questions I have studied, that led me into quantum cryptography and quickly resulted in an enjoyable <a href="https://arxiv.org/abs/0911.4680">paper</a>. It was good to feel productive again! (Though the paper had fun reactions as well: after putting it on the arXiv we quickly heard from experts in the area that we had solved an irrelevant problem, and that we better learn about information theory — which we did, eventually leading to another <a href="https://arxiv.org/abs/0912.5514">paper</a>, etc.) The project had distracted me and I set interactive proofs aside; clearly, I was stuck.</p>
<p>About a year later I visited IQC in Waterloo. I don’t remember in what context the visit took place. What I do remember is a meeting in the office of Tsuyoshi Ito, at the time a postdoctoral scholar at IQC. Tsuyoshi asked me to explain our result with Julia. He then asked a very pointed question: the bedrock for the classical analysis of interactive proof systems is the “linearity test” of Blum-Luby-Rubinfeld (BLR). Is there any sense in which we could devise a quantum version of that test?</p>
<p>What a question! This was great. At first it seemed fruitless: in what sense could one argue that quantum provers apply a “linear function”? Sure, quantum mechanics is linear, but that is besides the point. The linearity is a property of the prover’s answers as a function of their question. So what to make of the quantum state, the inherent randomness, etc.?</p>
<p>It took us a few months to figure it out. Once we got there however, the answer was relatively simple — the prover should be making a question-independent measurement that returns a linear function that it applies to its question in order to obtain the answer returned to the verifier — and it opened the path to our subsequent <a href="https://arxiv.org/abs/1207.0550">paper</a> showing that the inclusion of NEXP in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> indeed holds. Tsuyoshi’s question about linearity testing had allowed us to make the connection with PCP techniques; from there to MIP=NEXP there was only one step to make, which is to analyze multi-linearity testing. That step was suggested by my Ph.D. advisor, Umesh Vazirani, who was well aware of the many pathways towards the classical PCP theorem (indeed a lot of the activity that led to the proof of the theorem took place in Berkeley, with many of Umesh’s current or former students making substantial contributions). It took a lot of technical work, yet conceptually a single question from my co-author had sufficed to take me out of a 3-year slumber.</p>
<p>This was in 2012, and I thought we were done. For some reason the converse inclusion, of <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> in NEXP, seemed to resist our efforts, but surely it couldn’t resist much longer. Navascues et al. had introduced a hierarchy of semidefinite programs that seemed to give the right answer (technically they could only show convergence to a relaxation, the commuting value, but that seemed like a technicality; in particular, the values coincide when restricted to finite-dimensional strategies, which is all we computer scientists cared about). There were no convergence bounds on the hierarchy, yet at the same time commutative SDP hierarchies were being used to obtain very strong results in combinatorial optimization, and it seemed like it would only be a matter of time before someone came up with an analysis of the quantum case. (I had been trying to solve a related “dimension reduction problem” with Oded Regev for years, and we were making no progress; yet it seemed <em>someone</em> ought to!)</p>
<p>In Spring 2014 during an open questions session at a <a href="https://simons.berkeley.edu/workshops/qhc2014-1">workshop</a> at the Simons Institute in Berkeley Dorit Aharonov suggested that I ask the question of the possible inclusion of QMA-EXP, the exponential-sized-proofs analogue of QMA, in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/>. A stronger result than the inclusion of NEXP (under assumptions), wouldn’t it be a more natural “fully quantum” analogue of MIP=NEXP? Dorit’s suggestion was motivated by research on the “quantum PCP theorem”, that aims to establish similar hardness results in the realm of the local Hamiltonian problem; see e.g. <a href="https://mycqstate.wordpress.com/2014/10/31/quantum-pcp-conjectures/">this post</a> for the connection. I had no idea how to approach the question — I also didn’t really believe the answer could be positive — but what can you do, if Dorit asks you something… So I reluctantly went to the board and asked the question. Joe Fitzsimons was in the audience, and he immediately picked it up! Joe had the fantastic ideas of using quantum error-correction, or more specifically secret-sharing, to distribute a quantum proof among the provers. His enthusiasm overcame my skepticism, and we eventually <a href="https://arxiv.org/abs/1409.0260">showed</a> the desired inclusion. Maybe <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> <em>was</em> bigger than <img alt="{\text{NEXP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{NEXP}}"/> after all.</p>
<p>Our result, however, had a similar deficiency as the one with Julia, in that the completeness-soundness gap was exponentially small. Obtaining a result with a constant gap took 3 years of couple more years of work and the fantastic energy and insights of a Ph.D. student at MIT, Anand Natarajan. Anand is the first person I know of to have had the courage to dive in to the most technical aspects of the analysis of the aforementioned results, while also bringing in the insights of a “true quantum information theorist” that were supported by Anand’s background in Physics and upbringing in the group of Aram Harrow at MIT. (In contrast I think of myself more as a “raw” mathematician; I don’t really understand quantum states other than as psd matrices…not that I understand math either of course; I suppose I’m some kind of a half-baked mish-mash.) Anand had many ideas but one of the most beautiful ones led to what he poetically called the “Pauli braiding test”, a “truly quantum” analogue of the BLR linearity test that amounts to doing <em>two</em> linearity tests in conjugate bases and piecing the results together into a robust test for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-qubit entanglement (I wrote about our work on this <a href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/">here</a>).</p>
<p>At approximately the same time Zhengfeng Ji had another wonderful idea, that was in some sense orthogonal to our work. (My interpretation of) Zhengfeng’s idea is that one can see an interactive proof system as a computation (verifier-prover-verifier) and use Kitaev’s circuit-to-Hamiltonian construction to transform the entire computation into a “quantum CSP” (in the same sense that the local Hamiltonian problem is a quantum analogue of classical constraint satisfaction problems (CSP)) that could then itself be verified by a quantum multi-prover interactive proof system…with exponential gains in efficiency! Zhengfeng’s result implied an exponential improvement in complexity compared to the result by Julia and myself, showing inclusion of NEEXP, instead of NEXP, in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/>. However, Zhengfeng’s technique suffered from the same exponentially small completeness-soundness gap as we had, so that the best lower bound on <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> per se remained NEXP.</p>
<p>Both works led to follow-ups. With Natarajan we promoted the Pauli braiding test into a “<a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>” that allowed us to show the inclusion of QMA-EXP into <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/>, with constant gap, thereby finally answering the question posed by Aharonov 4 years after it was asked. (I should also say that by then all results on <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> started relying on a sequence of parallel repetition results shown by Bavarian, Yuen, and others; I am skipping this part.) In parallel, with Ji, Fitzsimons, and Yuen we showed that Ji’s compression technique could be “iterated” an arbitrary number of times. In fact, by going back to “first principles” and representing verifiers uniformly as Turing machines we realized that the compression technique could be used iteratively to (up to small caveats) give a new proof of the fact (first <a href="https://arxiv.org/abs/1703.08618">shown</a> by Slofstra using an embedding theorem for finitely presented group) that the zero-gap version of <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> contains the halting problem. In particular, the entangled value is uncomputable! This was not the first time that uncomputability crops in to a natural problem in quantum computing (e.g. the <a href="https://arxiv.org/abs/1502.04573">spectral gap paper</a>), yet it still surprises when it shows up. Uncomputable! How can anything be uncomputable!</p>
<p>As we were wrapping up our paper Henry Yuen realized that our “iterated compression of interactive proof systems” was likely optimal, in the following sense. Even a mild improvement of the technique, in the form of a slower closing of the completeness-soundness gap through compression, would yield a much stronger result: undecidability of the constant-gap class <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/>. It was already known by work of Navascues et al., Fritz, and others, that such a result would have, if not surprising, certainly consequences that seemed like they would be taking us out of our depth. In particular, undecidability of any language in <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> would imply a negative resolution to a series of equivalent conjectures in functional analysis, from Tsirelson’s problem to Connes’ Embedding Conjecture through Kirchberg’s QWEP conjecture. While we liked our result, I don’t think that we believed it could resolve any conjecture(s) in functional analysis.</p>
<p>So we moved on. At least I moved on, I did some cryptography for a change. But Anand Natarajan and his co-author John Wright did not stop there. They had the last major insight in this story, which underlies their recent STOC best paper described in the previous <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">post</a>. Briefly, they were able to combine the two lines of work, by Natarajan &amp; myself on low-degree testing and by Ji et al. on compression, to obtain a compression that is specially tailored to the existing <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> protocol for NEXP and compresses that protocol without reducing its completeness-soundness gap. This then let them show Ji’s result that <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/> contains NEEXP, but this time with constant gap! The result received well-deserved attention. In particular, it is the first in this line of works to not suffer from any caveats (such as a closing gap, or randomized reductions, or some kind of “unfair” tweak on the model that one could attribute the gain in power to), and it implies an unconditional separation between MIP and <img alt="{\text{MIP}^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star}"/>.</p>
<p>As they were putting the last touches on their result, suddenly something happened, which is that a path towards a much bigger result opened up. What Natarajan &amp; Wright had achieved is a one-step gapless compression. In our iterated compression paper we had observed that iterated gapless compression would lead to <img alt="{\text{MIP}^\star=\text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star=\text{RE}}"/>, implying negative answers to the aforementioned conjectures. So then?</p>
<p>I suppose it took some more work, but in some way all the ideas had been laid out in the previous 15 years of work in the complexity of quantum interactive proof systems; we just had to put it together. And so a decade after the characterization <a href="https://arxiv.org/abs/0907.4737">QIP = PSPACE</a> of single-prover quantum interactive proof systems, we have arrived at a characterization of quantum multiprover interactive proof systems, <img alt="{\text{MIP}^\star = \text{RE}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\text{MIP}^\star = \text{RE}}"/>. With one author in common between the two papers: congratulations Zhengfeng!</p>
<p>Even though we just posted a paper, in a sense there is much more left to do. I am hopeful that our complexity-theoretic result will attract enough interest from the mathematicians’ community, and especially operator algebraists, for whom CEP is a central problem, that some of them will be willing to devote time to understanding the result. I also recognize that much effort is needed on our own side to make it accessible in the first place! I don’t doubt that eventually complexity theory will not be needed to obtain the purely mathematical consequences; yet I am hopeful that some of the ideas may eventually find their way into the construction of interesting mathematical objects (such as, who knows, a non-hyperlinear group).</p>
<p>That was a good Masters project…thanks Julia!</p></div>
    </content>
    <updated>2020-01-14T01:32:43Z</updated>
    <published>2020-01-14T01:32:43Z</published>
    <category term="meta"/>
    <category term="QPCP"/>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="interactive proofs"/>
    <category term="qpcp"/>
    <category term="science"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2020-03-07T22:21:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/01/14/socal-theory-day-2020/</id>
    <link href="https://cstheory-events.org/2020/01/14/socal-theory-day-2020/" rel="alternate" type="text/html"/>
    <title>SoCal Theory Day 2020</title>
    <summary>January 20, 2020 UC Riverside https://www.cs.ucr.edu/~silas/ An all day event to celebrate the TCS research community in Southern California</summary>
    <updated>2020-01-14T00:51:47Z</updated>
    <published>2020-01-14T00:51:47Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/01/09/women-in-theory-2020/</id>
    <link href="https://cstheory-events.org/2020/01/09/women-in-theory-2020/" rel="alternate" type="text/html"/>
    <title>Women in Theory 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 16-19, 2020 Simons Institute, Berkeley, CA https://womenintheory.wordpress.com/ Submission deadline: February 7, 2020 Registration deadline: February 7, 2020 The Women in Theory (WIT) Workshop is intended for graduate and exceptional undergraduate students in the area of theory of computer science. The workshop will feature technical talks and tutorials by senior and junior women in the … <a class="more-link" href="https://cstheory-events.org/2020/01/09/women-in-theory-2020/">Continue reading <span class="screen-reader-text">Women in Theory 2020</span></a></div>
    </summary>
    <updated>2020-01-09T16:45:30Z</updated>
    <published>2020-01-09T16:45:30Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1547</id>
    <link href="https://theorydish.blog/2020/01/09/women-in-theory-2018-call-for-application-2/" rel="alternate" type="text/html"/>
    <title>Women in Theory 2020 Call for Application</title>
    <summary>The wonderful Women in Theory (WIT) biennial series of workshops started in 2008 and the 7th meeting will take place at   Simons Institute at Berkeley, Jun 16 – 19, 2020. Please see below the call for application. WIT is one of my favorite (if not the favorite) program in the theory community. Many in our community share my enthusiasm (and theory groups fight for the honor of hosting these meetings). The reactions from past participants leave no room for doubt – this is an important a great and experience. So if you fit the workshop’s qualifications – please do yourself a favor and apply!   The Women in Theory (WIT) Workshop is intended for graduate and exceptional undergraduate students in the area of theory of computer science. The workshop will feature technical talks and tutorials by senior and junior women in the field, as well as social events and activities. The motivation for the workshop is twofold. The first goal is to deliver an invigorating educational program; the second is to bring together theory women students from different departments and foster a sense of kinship and camaraderie. The 7th WIT workshop will take place at  Simons Institute at Berkeley, Jun 16 – [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The wonderful Women in Theory (WIT) biennial series of workshops started in 2008 and the 7th meeting will take place at   <a href="https://simons.berkeley.edu/">Simons Institute at Berkeley</a>, Jun 16 – 19, 2020. Please see below the call for application.</p>
<p>WIT is one of my favorite (if not <em>the</em> favorite) program in the theory community. Many in our community share my enthusiasm (and theory groups fight for the honor of hosting these meetings). The reactions from past participants leave no room for doubt – this is an important a great and experience. So if you fit the workshop’s qualifications – please do yourself a favor and apply!</p>
<hr/>
<p> </p>
<p>The Women in Theory (WIT) Workshop is intended for graduate and exceptional undergraduate students in the area of theory of computer science. The workshop will feature technical talks and tutorials by senior and junior women in the field, as well as social events and activities. The motivation for the workshop is twofold. The first goal is to deliver an invigorating educational program; the second is to bring together theory women students from different departments and foster a sense of kinship and camaraderie.</p>
<p>The 7th WIT workshop will take place at  <a href="https://simons.berkeley.edu/">Simons Institute at Berkeley</a>, Jun 16 – 19, 2020.</p>
<p><strong>Confirmed Speakers</strong>: <a href="https://www.cs.tau.ac.il/~mfeldman/">Michal Feldman</a> (Tel-Aviv University), <a href="https://simons.berkeley.edu/people/shafi-goldwasser">Shafi Goldwasser</a> (Simons, UC Berkeley)<br/>
<strong>Organizers</strong>: <a href="http://researcher.ibm.com/view.php?person=us-talr">Tal Rabin</a> (IBM), <a href="http://www.math.ias.edu/~shubhangi/">Shubhangi Saraf </a>(Rutgers) and <a href="mailto:lisa.zhang@nokia-bell-labs.com">Lisa Zhang</a> (Bell Labs).<br/>
<strong>Local Host Institution:  </strong><a href="https://simons.berkeley.edu/">Simons Institute at Berkeley</a>.<br/>
<b>Local Arrangements</b>:<br/>
<strong>Special Guest:</strong>  <a href="https://omereingold.wordpress.com/">Omer Reingold</a> (Stanford).<br/>
<strong>Contact us:</strong> <a href="mailto:womenintheory2016@gmail.com">womenintheory2020@gmail.com</a>.</p>
<p><strong>To apply</strong>: click <a href="https://womenintheory.wordpress.com/apply">here</a>.</p>
<p><strong>Important dates:</strong><br/>
<strong>Application deadline: </strong>Feb 7, 2020<br/>
<strong>Notification of acceptance: </strong>March 15, 2020<br/>
<strong>Workshop: </strong>June 16-19, 2020.</p></div>
    </content>
    <updated>2020-01-09T16:33:15Z</updated>
    <published>2020-01-09T16:33:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/01/06/complexity-theory-with-a-human-face/</id>
    <link href="https://cstheory-events.org/2020/01/06/complexity-theory-with-a-human-face/" rel="alternate" type="text/html"/>
    <title>Complexity Theory with a Human Face</title>
    <summary>September 1-4, 2020 Czech Republic http://users.math.cas.cz/talebanfard/workshop2020/ The workshop consists of excellent speakers giving enlightening tutorials on delectable aspects of complexity theory which will take place in Tábor, Czech Republic. The event is co-organized with Krajíček’s Fest celebrating the 60th birthday of Jan Krajíček.</summary>
    <updated>2020-01-06T13:42:39Z</updated>
    <published>2020-01-06T13:42:39Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=1734</id>
    <link href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/" rel="alternate" type="text/html"/>
    <title>The sum of a geometric series is all you need!</title>
    <summary>I sometimes joke with my students about one of the main tools I have been using in the last ten years: the explicit sum of a geometric series. Why is this? From numbers to operators The simplest version of this basic result for real numbers is the following: $$ \forall r \neq 1, \ \forall...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">I sometimes joke with my students about one of the main tools I have been using in the last ten years: the explicit sum of a geometric series. <em>Why is this?</em></p>



<h2>From numbers to operators</h2>



<p class="justify-text">The simplest version of this basic result for real numbers is the following: $$ \forall r \neq 1, \ \forall n \geq 0, \   \sum_{k=0}^n r^k = \frac{1-r^{n+1}}{1-r},$$ and is typically proved by multiplying the two sides by \(1-r\) and forming a telescoping sum. When \(|r|&lt;1\), we can let \(n\) tend to infinity and get $$ \forall |r| &lt;  1, \  \sum_{k=0}^\infty r^k = \frac{1}{1-r}.$$</p>



<p class="justify-text"><strong>Proofs without words.</strong> There is a number of classical proofs of the last identities, many of them <a href="https://en.wikipedia.org/wiki/Proof_without_words">without words</a>, presented in the beautiful series of books by Roger Nelsen [1, 2, 3]. I particularly like the two below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1916" height="209" src="https://francisbach.com/wp-content/uploads/2019/12/triangles-1-1024x447.png" width="478"/>Proof of the infinite sum of a geometric series with \(r=\frac{1}{2}.\) The area of the right triangle which is the half of a square with side length equal to \(2\), is equal to \(2\) and to the sum of the areas of the smaller triangles, that is, \(2 = \frac{1}{1- \frac{1}{2}}= 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \cdots\). Adapted from [3, p. 155].</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2005" height="390" src="https://francisbach.com/wp-content/uploads/2019/12/rectangles_r.png" width="430"/>Proof of the finite sum of a geometric series, started at \(k=0\) up to \(k=n=5\). The area of the full square of unit side length is equal to the sum of the areas of all yellow rectangles plus the pink one, that is, \(1 = (1-r) \sum_{k=0}^n r^k + r^{n+1}\). Adapted from [1, p. 118].</figure></div>



<p class="justify-text"><strong>High school: from philosophy to trigonometry.</strong> Before looking at extensions beyond real numbers, I can’t resist mentioning some of <a href="https://en.wikipedia.org/wiki/Zeno%27s_paradoxes">Zeno’s paradoxes</a>, like Achilles and the tortoise, which are intimately linked with the sum of a geometric series (and which were a highlight of my high school philosophy “career”).</p>



<p class="justify-text">Speaking of high school, it is interesting to note that there, the core identity of this blog post, is often used as \(a^{n+1}-b^{n+1} = (a-b)(a^n+a^{n-1}b+\cdots+ab^{n-1}+b^{n})\) in order to factorize polynomials (and not in the other way around like done later in this post).</p>



<p class="justify-text">Another nice elementary use of geometric series comes up with complex numbers, in order to compute sum of cosines, such as: $$\! \sum_{k=0}^n \! \cos k\theta = {\rm Re} \Big(\!\sum_{k=0}^n e^{ i k \theta}\!\Big) = {\rm Re} \Big(\!\frac{e^{i(n+1)\theta}-1}{e^{i\theta}-1}\!\Big) =  {\rm Re} \Big(\! \frac{ \sin \frac{n+1}{2} \theta e^{i(n+1)\theta/2}}{ \sin \frac{\theta}{2} e^{i\theta/2} }\!\Big) = \frac{  \sin \frac{n+1}{2} \theta}{\sin \frac{\theta}{2}} \cos \frac{n\theta}{2}. $$</p>



<p class="justify-text"><strong>Square matrices and operators.</strong> Within applied mathematics, the matrix and operator versions are the most useful. For \(A\) a square matrix or any linear operator, we have $$ \forall A \mbox{ such that } I-A \mbox{ is invertible}, \  \sum_{k=0}^n A^k = (I-A)^{-1}(I-A^{n+1}),$$ with the classical proof: \(\displaystyle (I – A)\sum_{k=0}^n A^k = \sum_{k=0}^n A^k – \sum_{k=1}^{n+1} A^k = I – A^{n+1}.\)</p>



<p class="justify-text">When \(\| A\| &lt;1\) for any <a href="https://en.wikipedia.org/wiki/Matrix_norm">matrix norm</a> induced from a vector norm, we can let \(n\) go to infinity, to obtain the <a href="https://en.wikipedia.org/wiki/Neumann_series">Neumann series</a> \(\displaystyle \sum_{k=0}^n A^k = (I-A)^{-1}\).</p>



<p class="justify-text">We are now ready to talk about machine learning and optimization!</p>



<h2>Stochastic gradient for quadratic functions</h2>



<p class="justify-text">Matrix geometric series come up naturally when analyzing iterative algorithms based on linear recursions. In this blog post, I will focus on stochastic gradient descent (SGD) techniques to solve the following problem: $$ \min_{\theta \in \mathbb{R}^d} F(\theta) = \frac{1}{2} \mathbb{E} \big[ y – \theta^\top \Phi(x) \big]^2,$$ where the expectation is taken with respect to some joint distribution on \((x,y)\). We denote by \(\theta_\ast \in \mathbb{R}^d\) the minimizer of the objective function above (which is assumed to exist). We assume the feature vector \(\Phi(x)\) is high-dimensional, so that the moment matrix \(H = \mathbb{E} \big[ \Phi(x)\Phi(x)^\top \big]\) cannot be assumed to be invertible.</p>



<p class="justify-text"><strong>Stochastic gradient descent recursion. </strong>Starting from some initial guess \(\theta_0 \in \mathbb{R}^d\), typically \(\theta_0 =0\), the SGD recursion is: $$  \theta_n = \theta_{n-1} – \gamma ( \theta_{n-1}^\top \Phi(x_n) \, – y_n) \Phi(x_n),$$ where \((x_n,y_n)\) is an independent sample from the distribution mentioned above, and \(\gamma &gt; 0\) is the step-size. This algorithm dates back to <a href="https://en.wikipedia.org/wiki/Stochastic_approximation">Robbins and Monro</a> in the 50’s and is particularly adapted to machine learning as it updates the parameter \(\theta\) after each observation \((x_n,y_n)\) (as opposed to waiting for a full pass over the data).</p>



<p class="justify-text">Denoting \(\varepsilon_n = y_n – \theta_\ast^\top \Phi(x_n)\) the residual between the observation \(y_n\) and the optimal linear prediction \(\theta_\ast^\top \Phi(x_n)\), we can rewrite the SGD recursion as $$\theta_n = \theta_{n-1} – \gamma ( \theta_{n-1}^\top \Phi(x_n) \, – \theta_{\ast}^\top \Phi(x_n) -\, \varepsilon_n) \Phi(x_n),$$ leading to $$\theta_n \, – \theta_\ast = \big[ I – \gamma \Phi(x_n) \Phi(x_n)^\top \big] ( \theta_{n-1}- \theta_\ast) + \gamma \varepsilon_n \Phi(x_n).$$</p>



<p class="justify-text">This is a stochastic linear recursion on the deviation to optimum \(\theta_n \, – \theta_\ast\). The expectation of the SGD recursion is: $$\mathbb{E} [ \theta_n] \, – \theta_\ast = \big[ I – \gamma H \big] ( \mathbb{E}[ \theta_{n-1}] – \theta_\ast), $$ where \(H = \mathbb{E} \big[ \Phi(x) \Phi(x)^\top \big]\), and where we have used that  \(\gamma \varepsilon_n \Phi(x_n)\) has zero expectation (as a consequence of optimality conditions for \(\theta_\ast\)). This is exactly the gradient descent recursion on the expected loss (which cannot be run in practice because we only have access to a finite amount of data).</p>



<p class="justify-text"><strong>Simplification. </strong>The main difficulty in analyzing the stochastic recursion is the presence of two sources of randomness when compared to the gradient descent recursion: (A) some additive noise \(\gamma \varepsilon_n \Phi(x_n)\) independent of the current iterate \(\theta_{n-1}\) and with zero expectation, and (B) some multiplicative noise \(\gamma \big[  H – \Phi(x_n) \Phi(x_n)^\top \big] (\theta_{n-1} – \theta_\ast)\), which comes from the use of \(  I – \gamma \Phi(x_n) \Phi(x_n)^\top  \) instead of \(I – \gamma H\), and depends on the current iterate \(\theta_{n-1}\).</p>



<p class="justify-text">In this blog post, for simplicity, I will ignore the multiplicative noise and only focus on the additive noise, and thus consider the recursion $$\theta_n\, – \theta_\ast = ( I – \gamma H )  ( \theta_{n-1}- \theta_\ast) + \gamma \varepsilon_n \Phi(x_n).$$ Detailed studies with multiplicative noise can be found in [<a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">4</a>, <a href="http://proceedings.mlr.press/v38/defossez15.pdf">5</a>, <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">6</a>, <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">7</a>], and lead to similar results. Moreover, I will assume (again for simplicity) that \(\varepsilon_n\) and \(\Phi(x_n)\) are independent, and that \(\mathbb{E} [ \varepsilon_n^2 ] = \sigma^2\) (which corresponds to uniform noise of variance \(\sigma^2\) on top of the optimal linear predictions); again, results directly extends without this assumption.</p>



<p class="justify-text"><strong>Bias / variance decomposition. </strong>Having a constant multiplicative term \(I – \gamma H\) in the recursion leads to an explicit formula: $$\theta_n – \theta_\ast = ( I – \gamma H ) ^n ( \theta_{0}- \theta_\ast) + \sum_{k=1}^n \gamma  ( I – \gamma H ) ^{n-k} \varepsilon_k \Phi(x_k),$$ which is now easy to analyze. It is the sum of a deterministic term depending on initial conditions,  and a zero mean term which is the sum of independent zero-mean terms due to the noise in the gradients. Thus, we can compute the expectation of the excess risk \(F(\theta_n)\, – F(\theta_\ast) = \frac{1}{2} ( \theta_n – \theta_\ast)^\top H ( \theta_n – \theta_\ast)\), as follows: $$\! \mathbb{E} \big[ F(\theta_n) \,- F(\theta_\ast)\big] = {\rm Bias} + { \rm Variance}, $$ where the bias term characterizes the forgetting of initial conditions: $$ {\rm Bias} = \frac{1}{2}  ( \theta_0 – \theta_\ast)^\top ( I – \gamma H ) ^{2n} H ( \theta_0 – \theta_\ast),  $$ and the variance term characterizes the effect of the noise: $${\rm Variance} =  \frac{\gamma^2 }{2}\! \sum_{k=1}^n \! \mathbb{E} \big[ \varepsilon_k^2 \Phi(x_k)^\top ( I – \gamma H ) ^{2n-2k}H  \Phi(x_k) \big] = \frac{\gamma^2  \sigma^2}{2}\! \sum_{k=1}^n \! {\rm tr} \big[  ( I – \gamma H ) ^{2n-2k}H^2   \big] .$$</p>



<p class="justify-text">The bias term is exactly the convergence rate of gradient descent on the expected risk, and can be controlled by upper-bounding the eigenvalues of the matrix  \(( I – \gamma H ) ^{2n} H\). As shown at the end of the post, when \(\gamma \leq \frac{1}{L}\), where \(L\) is the largest eigenvalue of \(H\), then this matrix has all eigenvalues less than \(1/(4n\gamma)\), leading to a bound on the bias term of $$ \frac{1}{8 \gamma n} \|\theta_0 – \theta_\ast\|^2.$$ We recover the traditional \(O(1/n)\) convergence rate of gradient descent. For the variance term we use the sum of a geometric series, to obtain the bound $$\frac{\gamma^2  \sigma^2}{2}   {\rm tr} \big[ H^2( I – (I – \gamma H)^2 )^{-1}  \big] = \frac{\gamma^2  \sigma^2}{2}  {\rm tr} \big[ H^2( 2\gamma H – \gamma^2 H^2 )^{-1}  \big] \leq \frac{\gamma  \sigma^2}{2}  {\rm tr}(H) .$$ While the bias term that characterizes the forgetting of initial conditions goes to zero as \(n\) goes to infinity, this is not the case for the variance term. This is the traditional lack of convergence of SGD with a constant step-size. In the left plot of the figure below, we compare deterministic gradient descent to stochastic gradient with a constant step-size. For convergence rates in higher dimension, see further below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-2039" height="236" src="https://francisbach.com/wp-content/uploads/2019/12/paths_video-1.gif" width="564"/>Gradient descent algorithms run from the same starting point. Left plot: plain gradient descent (GD), plain (non-averaged) gradient descent (SGD). Right plot: averaged SGD with uniform weights (ASGD-1) and with weights proportional to the iteration index (ASGD-k).</figure></div>



<p class="justify-text">Convergence can be obtained by using a decreasing step-size, typically of the order \(1 / \sqrt{n},\) leading to an overall convergence rate proportional to \(1 / \sqrt{n}.\) This can be improved through averaging, which I now present.</p>



<h2>Impact of averaging</h2>



<p class="justify-text">We consider the averaged iterate \(\bar{\theta}_n = \frac{1}{n+1} \sum_{k=0}^n \theta_k\), an off-line (no interaction with the stochastic recursion) averaging often referred to as Polyak–Ruppert averaging, after [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">8</a>, 9]. The averaged iterate can also be expressed as a linear function of initial conditions and noise variables as $$\bar{\theta}_n -\theta_\ast = \frac{1}{n+1} \sum_{k=0}^n  ( I – \gamma H ) ^k ( \theta_{0}- \theta_\ast) + \frac{\gamma}{n+1}   \sum_{k=1}^n \sum_{j=k}^n   ( I – \gamma H ) ^{j-k} \varepsilon_k \Phi(x_k).$$ Geometric series come in again! We can get a closed form for \(\bar{\theta}_n -\theta_\ast\) as: $$\frac{1}{n+1} (\gamma H)^{-1} \big[ I – ( I – \gamma H ) ^{n+1} \big] ( \theta_{0}- \theta_\ast) + \frac{\gamma}{n+1} (\gamma H)^{-1} \sum_{k=1}^n \big[ I – ( I – \gamma H ) ^{n-k+1} \big] \varepsilon_k \Phi(x_k).$$</p>



<p class="justify-text">The bound on \(\mathbb{E} \big[ F(\bar{\theta}_n) \,- F(\theta_\ast)\big] \), will here also be composed of a bias term and a variance term. </p>



<p class="justify-text"><strong>Bias.</strong> The bias term is equal to $$\frac{1}{2(n+1)^2}( \theta_{0}- \theta_\ast) ^\top   (\gamma H)^{-2} H \big[ I – ( I – \gamma H ) ^{n+1} \big]^2 ( \theta_{0}- \theta_\ast).$$ Using the fact that the eigenvalues of the matrix \( (\gamma H)^{-2} H \big[ I – ( I – \gamma H ) ^{n+1} \big]^2\) are all less than \((n+1)/\gamma\) (see proof at the end of the post), we obtain the upper bound $$ \frac{1}{2 (n+1)\gamma} \| \theta_0 – \theta_\ast\|^2,$$ which is essentially the same than with averaging (but, see an important difference in the discussion below, regarding the behavior for large \(n\)).</p>



<p class="justify-text"><strong>Variance.</strong> The variance term is equal to $$ \frac{\gamma^2}{2 (n+1)^2}  \sum_{k=1}^n \sigma^2 {\rm tr} \Big( \big[ I – ( I – \gamma H ) ^{n-k+1} \big]^2 (\gamma H)^{-2} H^2 \Big).$$ Using the positivity of the matrix \(( I – \gamma H )\), we finally obtain the following bound for variance term: $$  \frac{ \sigma^2 n {\rm tr}(I)}{2(n+1)^2}\leq \frac{\sigma^2 d}{2n}.$$ We now have a convergent algorithm, and we recover traditional quantities from the statistical analysis of <a href="https://en.wikipedia.org/wiki/Least_squares">least-squares regression</a>.</p>



<p class="justify-text"><strong>Experiments.</strong> Now, both bias and variance are converging at rate \(1/n\). See an illustration in two dimensions in the right plot of the figure above, as well as a convergence rates below. In these two figures, what differs is the decay of eigenvalues of \(H\) (fast in the first figure, slower in the second).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2029" height="235" src="https://francisbach.com/wp-content/uploads/2019/12/rates_d3-1-1024x453.png" width="533"/>Bias (left) and variance (right) terms for plain SGD, averaged SGD with uniform averaging (ASGD-1) and non-uniform averaging (ASGD-k). The matrix \(H\) is of dimension \(100 \times 100\) and has eigenvalues \(1/k^3\), \(k \in \{1,\dots,100\}\). Averaged over 100 replications.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-2030" height="242" src="https://francisbach.com/wp-content/uploads/2019/12/rates_d-1-1024x453.png" width="549"/>Bias (left) and variance (right) terms for plain SGD, averaged SGD with uniform averaging (ASGD-1) and non-uniform averaging (ASGD-k). The matrix \(H\) is of dimension \(100 \times 100\) and has eigenvalues \(1/k\), \(k \in \{1,\dots,100\}\). Averaged over 100 replications.</figure></div>



<p>We can make the following observations:</p>



<ul class="justify-text"><li>Depending on the amount of noise in the gradients, the sum of the variance and the bias terms will either be dominated by one of the two; typically the bias term in early iterations, and then the variance term (see more  details in [<a href="http://proceedings.mlr.press/v38/defossez15.pdf">5</a>]).</li><li>The variance term of non-averaged SGD is converging to a constant (while the bias term is exactly the one of regular gradient descent).</li><li>With averaging, the variance terms decay as a line in a log-log plot. The reader with good eyes can check that the slope is indeed -1, thus illustrating the convergence rate in \(1/n\) (here the bound is tight). For the variance terms (right plots), there is no significant difference between the two eigenvalue decays.</li><li>The bias terms have different behaviors for the two decays. For the fast decays (top plot), the bounds in \(1/n\) are reasonably tight (lines of slope -1). For slower decay, we see some strong-convexity behavior entering the scene, as the slowest eigenvalue is 1/100 and the number of iterations is far larger than 100, and thus the optimization problem looks strongly convex, and then the bias term of plain SGD (which corresponds to deterministic gradient descent) converges exponentially fast, while the two averaging techniques decay as powers of \(n\) (again, the acute reader can spot slopes of -2 and -4, and the smart reader can explain why; more on this in a future post dedicated to SGD).</li></ul>



<p class="justify-text"><strong>Pros and cons of averaging.</strong> Overall, we can see that averaging may slow down the forgetting of initial conditions, while it makes the method robust to noise in the gradients. The trade-off depends on the amount of noise, but in most high-dimensional learning problems and for the accuracies practitioners are interested in (no need to have an excess risk of \(10^{-5}\) then the best risk is of order \(10^{-1}\)), the bias term is the one which is seen the most. Thus, a less-aggressive form of averaging that puts more weights on later iterates seems advantageous (pink curve above). More on this in a future blog post.</p>



<p class="justify-text"><strong>Beyond least-squares.</strong> In this blog post, to illustrate the use of sums of geometric series, I have focused on an idealized version (no multiplicative noise) of least-squares regression. For other losses, e.g., logistic loss, the analysis is more involved, and averaging does not lead to a converging algorithm, but transforms a term in \(\gamma\) into a term in \(\gamma^2\), which is still a significant improvement when the step-size \(\gamma\) is small (see [<a href="https://arxiv.org/pdf/1707.06386">10</a>] for more details).</p>



<h3>Extensions</h3>



<p class="justify-text">The sum of a geometric series can be extended in a variety of ways. For example, we can take the derivative with respect to \(r\), to get $$ \forall r \neq 1, \  \sum_{k=1}^n k r^{k-1} = \frac{1-r^{n+1}}{(1-r)^2} – \frac{ (n+1) r^n}{1-r} = \frac{1 + n r^{n+1} – (n+1) r^n }{(1-r)^2}.$$ This is useful for example to compute the performance of the weighted average \(\frac{2}{n(n+1)} \sum_{k=1}^n k \theta_k\). This can be extended further with the <a href="https://en.wikipedia.org/wiki/Binomial_series">binomial series</a> $$ (1-r)^{-1-\beta} = \sum_{k=0}^\infty { k + \beta \choose k} r^k. $$</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I have essentially used the sum of a geometric series as an excuse to talk about stochastic gradient descent, but there are other places where such series pop out, such as in the analysis of Markov chains and the associated ergodic theorems [11], which are ubiquitous in the analysis of simulation algorithms.</p>



<p class="justify-text">This year, I am still planning to post every first Monday of the month. Expect additional posts on acceleration, stochastic gradient, and orthogonal polynomials, but also new topics should be covered, always with connections with machine learning. </p>



<p class="justify-text">Happy new year!</p>



<h2>References</h2>



<p class="justify-text">[1] Roger B. Nelsen, <em>Proofs without Words: Exercises in Visual Thinking</em>, Mathematical Association of America, 1997.<br/>[2] Roger B. Nelsen, <em>Proofs without Words II: More Exercises in Visual Thinking</em>, Mathematical Association of America, 2000.<br/>[3] Roger B. Nelsen, <em>Proofs Without Words III: Further Exercises in Visual Thinking</em>, Mathematical Association of America, 2015.<br/>[4] Francis Bach and Eric Moulines. <a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2013.<br/>[5] Alexandre Defossez, Francis Bach. <a href="http://proceedings.mlr.press/v38/defossez15.pdf">Averaged Least-Mean-Square: Bias-Variance Trade-offs and Optimal Sampling Distributions</a>. <em>Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2015.<br/>[6] Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression</a>. <em>Journal of Machine Learning Research</em>, 18(101):1−51, 2017.<br/>[7] Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli, Aaron Sidford. <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">Parallelizing Stochastic Gradient Descent for Least Squares Regression: Mini-batching, Averaging, and Model Misspecification</a>. <em>Journal of Machine Learning Research</em>, 18(223):1−42, 2018.<br/>[8] Boris T. Polyak, Anatoli B. Juditsky. <a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">Acceleration of Stochastic Approximation by Averaging</a>. <em>SIAM Journal on Control and Optimization</em>. 30(4):838-855, 1992.<br/>[9] David Ruppert. Efficient estimations from a slowly convergent Robbins-Monro process. Technical Report 781, Cornell University Operations Research and Industrial Engineering, 1988.<br/>[10] Aymeric Dieuleveut, Alain Durmus, Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains</a>. To appear in <em>Annals of Statistics</em>, 2020.<br/>[11] Sean Meyn and Richard L. Tweedie. <em><a href="https://www.cambridge.org/fr/academic/subjects/statistics-probability/applied-probability-and-stochastic-networks/markov-chains-and-stochastic-stability-2nd-edition?format=PB">Markov Chains and Stochastic Stability</a></em>. Cambridge University Press, 2009.</p>



<h2>Detailed computations</h2>



<p><strong>Bounds on eigenvalues – I.</strong> In order to show the first desired inequality on eigenvalues, we simply need to show that \((1-t)^{2n} t \leq 1/(4n)\) for any \(\in [0,1]\), which is the consequence of $$(1-t)^{2n} t \leq (e^{-t})^{2n} t \leq \frac{1}{2n} \sup_{u \geq 0} e^{-u} u = \frac{1}{2e n} \leq \frac{1}{4n}.$$</p>



<p class="justify-text"><strong>Bounds on eigenvalues – II.</strong> In order to show the second desired inequality on eigenvalues, we simply need to show that \(( 1 – ( 1 – t)^{n+1}) \leq \sqrt{n+1} \sqrt{t}\), for any \(t \in [0,1]\). This is a simple consequence of the straightforward inequality \(( 1 – ( 1 – t)^{n+1}) \leq 1\) and the inequality \(( 1 – ( 1 – t)^{n+1}) \leq (n+1) t \), which itself can be obtained by integrating the inequality \((1-u)^n \leq 1\) between \(0\) and \(t\).</p></div>
    </content>
    <updated>2020-01-06T10:35:45Z</updated>
    <published>2020-01-06T10:35:45Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-03-07T22:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=684</id>
    <link href="https://emanueleviola.wordpress.com/2020/01/01/publish-and-perish/" rel="alternate" type="text/html"/>
    <title>Publish and perish</title>
    <summary>Moshe Vardi’s latest insight in the Communications of the ACM (whose title we adopt for this post) agrees with our previous post “Because of pollution, conferences should be virtual.” Vardi calls for “sweeping policy change […] requiring that authors of accepted papers that must fly to participate in a conference may opt out from in-person […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext">Moshe Vardi’s latest insight in the Communications of the ACM </a>(whose title we adopt for this post) agrees with our previous post “<a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Because of pollution, conferences should be virtual.</a>” Vardi calls for “sweeping policy change […] requiring that authors of accepted papers that must fly to  participate in a conference may opt out from in-person involvement and  contribute instead by video.”  Vardi gives some indication of the environmental impact of the travel-based system, and further suspects that in-person conference participation is “much less valuable than we would like to believe.”</p>



<p>These issues are closely related to the decades-old discussion of journals vs. conferences. <a href="https://emanueleviola.wordpress.com/tag/utopia/">Several older posts on this blog </a>were devoted to that. Lance Fortnow, back in 2009, wrote that it’s <a href="https://cacm.acm.org/magazines/2009/8/34492-viewpoint-time-for-computer-science-to-grow-up/abstract">Time for computer science to grow up</a>.  The full text of this article is premium content, but you can read a pre-publication version <a href="http://www.cs.uchicago.edu/~fortnow/papers/growup.pdf">here</a>. Basically, he argues in favor of a journal-based publication system.</p>



<p>Apparently in response, judging from the title, Boaz Barak wrote a piece titled <a href="https://cacm.acm.org/magazines/2016/6/202644-computer-science-should-stay-young/abstract">Computer science should stay young.</a> I can’t quickly find a link to the whole thing, but his bottom line is online “I disagree with the conclusion that we should transition to a classical journal-based model similar to that of other fields. I believe conferences offer a number of unique advantages that have helped make computer science dynamic and successful, and can continue to do so in the future.”</p>



<p>I disagree that conferences are young. They belong to the BI (before internet) era, and so look rather anchored in the past to me.  Historically, I also suppose in-person discussion predates writing, though this is irrelevant.  What is young is the health impact of pollution (Fortnow and Barak’s pieces don’t touch on health issues). (By health impact I include climate change, but I prefer not to use that term for various reasons.)</p>



<p>And what is young and cool is arxiv overlay journals, TCS+ talks, videoconferences,  <a href="https://eccc.weizmann.ac.il/">ECCC</a>, etc.</p>



<p>Instead, we impose on our community most inconvenient transoceanic flights.  To end I’ll quote from <a href="http://www.wisdom.weizmann.ac.il/~oded/MC/269.html">Oded Goldreich’s my choices</a>:</p>



<p><b>Phoenix in June:</b> […] One must be out of their mind to hold a conference under such weather conditions. I guess humans can endure such weather conditions and even worse ones, but why choose to do so? Why call upon people from all over the world to travel to one of the least comfortable locations (per the timing)?</p>


<p><!--EndFragment--><br/><br/></p></div>
    </content>
    <updated>2020-01-01T17:03:39Z</updated>
    <published>2020-01-01T17:03:39Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/12/19/15th-international-computer-science-sysmposium-in-russia/</id>
    <link href="https://cstheory-events.org/2019/12/19/15th-international-computer-science-sysmposium-in-russia/" rel="alternate" type="text/html"/>
    <title>15th International Computer Science Sysmposium in Russia</title>
    <summary>June 29 – July 3, 2020 Yekaterinburg, Russia https://csr2020.sciencesconf.org/ Submission deadline: January 10, 2020 CSR is an annual international conference held in Russia that is designed to cover a broad range of topics in Theoretical Computer Science. The list of previous CSR conferences can be found at https://logic.pdmi.ras.ru/~csr/ .</summary>
    <updated>2019-12-19T20:25:13Z</updated>
    <published>2019-12-19T20:25:13Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1541</id>
    <link href="https://theorydish.blog/2019/12/09/quantum-dna-sequencing-the-ultimate-hardness-hypothesis/" rel="alternate" type="text/html"/>
    <title>Quantum DNA sequencing &amp; the ultimate hardness hypothesis</title>
    <summary>Longest common subsequence (LCS) and edit distance (ED) are fundamental similarity measures of interest to genomic applications (insertions/deletions/substitutions are a pretty good proxy for both mutations and read errors). The fastest known algorithms for computing the LCS/ED between two -character strings run in nearly quadratic time. Breakthroughs in fine-grained complexity [BI18][AHWW16] from the last few years provide some nice formal barriers further progress: in particular, substantially faster algorithms would refute NC-SETH, the hypothesis that given an NC circuit with input bits,  deciding if the circuit has any satisfying assignment requires time. (Note that this is a weaker, aka safer, hypothesis than the standard SETH.)   Quantum algorithms for edit distance? One way to try to circumvent the computational barriers is by approximation algorithms (see my blog post). A different approach is to go with quantum algorithms: Grover’s search can solve NC-SAT in time. Even those of us less skeptic than Gil Kalai can probably agree that quadratic quantum speedups won’t be practical anytime soon. But in theory, I find the question of whether we can design subquadratic quantum algorithms for edit distance very interesting (see also [BEG+18]). Alas, even with the power of quantum computers we don’t know any truly [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Longest common subsequence (LCS) and edit distance (ED) are fundamental similarity measures of interest to genomic applications (insertions/deletions/substitutions are a pretty good proxy for both mutations and read errors). The fastest known algorithms for computing the LCS/ED between two <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/>-character strings run in nearly quadratic time. Breakthroughs in fine-grained complexity <a href="https://arxiv.org/abs/1412.0348">[BI18]</a><a href="https://arxiv.org/abs/1511.06022">[AHWW16]</a> from the last few years provide some nice formal barriers further progress: in particular, substantially faster algorithms would refute <em>NC-SETH</em>, the hypothesis that given an NC circuit with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> input bits,  deciding if the circuit has any satisfying assignment requires <img alt="2^{(1-o(1))n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%281-o%281%29%29n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^{(1-o(1))n}"/> time. (Note that this is a weaker, aka safer, hypothesis than the standard SETH.)</p>
<p> </p>
<h2>Quantum algorithms for edit distance?</h2>
<p>One way to try to circumvent the computational barriers is by approximation algorithms (see my <a href="https://theorydish.blog/2018/07/20/approximating-edit-distance/">blog post</a>). A different approach is to go with quantum algorithms: Grover’s search can solve NC-SAT in <img alt="2^{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2^{n/2}"/> time. Even those of us less skeptic than <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/">Gil Kalai</a> can probably agree that quadratic quantum speedups won’t be practical anytime soon. But in theory, I find the question of whether we can design subquadratic quantum algorithms for edit distance very interesting (see also <a href="https://arxiv.org/abs/1804.04178">[BEG+18]</a>).</p>
<p>Alas, even with the power of quantum computers we don’t know any truly subquadratic algorithms for computing LCS/ED. On the other hand, it is not clear how to rule out even linear-time algorithms. A few weeks ago, Buhrman, Patro, and Speelman, posted a <a href="https://arxiv.org/abs/1911.05686">paper</a> that gives a <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> quantum <em>query complexity </em>lower bound for LCS/ED.</p>
<blockquote><p>Open Problem: Close the <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> vs <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^2"/> gap for quantum query complexity of ED/LCS.</p></blockquote>
<p>What is “query complexity” of ED/LCS? Buhrman et al. consider the following query model: In LCS, we want a <strong>maximum monotone matching</strong> between the characters of the two strings, where we can match two characters if they’re identical. Now suppose that in the query complexity problem we still want to find a maximum monotone matching, but instead of the character-equality graph (which is a union of disjoint cliques), we have an arbitrary bipartite graph, and <strong>given a pair of vertices, the oracle tells you if there is an edge between them</strong>.</p>
<p>This model may seem a bit counter-intuitive at first since the graphs may not correspond to any pair of strings; and indeed other models have been considered before <a href="https://dl.acm.org/citation.cfm?id=321922">[UAH76]</a><a href="https://arxiv.org/abs/1005.4033">[AKO10]</a>. But it turns out that this model is well-motivated by the NC-SETH lower bound (see discussion below).</p>
<p> </p>
<h2>The ultimate hardness hypothesis</h2>
<p>What does the <img alt="n^{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^{3/2}"/> query complexity lower bound mean for algorithms on actual strings? Instead of a black box oracle, our algorithms have access to an NC-circuit that implements it. Intuitively, we don’t know how to do very much with white box circuits, so it seems plausible to hypothesize that the running time will be lower bound by the query complexity. In some sense, this is a special case of the following <em>ultimate hardness hypothesis </em>that unifies a lot of the computational hardness assumptions that we like to assume but have no idea how to prove (e.g. P!=NP, P!=BQP, NC-SETH, FP!=PPAD, etc):</p>
<blockquote><p>[Ultimate Hardness Hypothesis] For every problem, the white-box computational complexity is lower bounded by the black-box query complexity.”</p></blockquote>
<p>In communication complexity similar statements are known and are called simulation/lifting theorems (see e.g. <a href="https://theory.stanford.edu/~mika/thesis.pdf">Mika’s thesis</a>). For computational complexity, there are obvious counter examples such as “decide if the oracle can be implemented by a small circuit”. So it only makes sense to continue to assume the ultimate hardness hypothesis for “reasonable problems” instead of “every problem”.</p>
<p>But Burhman et al. identify the following variant of the ultimate hardness hypothesis which I find very interesting. It is defined with respect to a function <img alt="T:\{0,1\}^{2^n} \rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=T%3A%5C%7B0%2C1%5C%7D%5E%7B2%5En%7D+%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T:\{0,1\}^{2^n} \rightarrow \{0,1\}"/> which takes as input the truth-table of a circuit and outputs True or False. Roughly, they hypothesize that:</p>
<blockquote><p>[Burhman et al.-QSETH, paraphrased] For <em>every</em> <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/>, deciding if <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="T"/> is true or false is as hard whether we’re given the actual circuit, or only the guarantee that the oracle is implemented by a small circuit”</p></blockquote>
<p>At a first read, I thought that arguments a-la impossibility of obfuscation <a href="https://www.iacr.org/archive/crypto2001/21390001.pdf">[BGI+01]</a> should refute this hypothesis, but a few weeks later I still don’t know how to prove it. Do you?</p>
<p> </p>
<h2>A tip for the upcoming holidays</h2>
<p>During my postdoc, I worked on the quantum query complexity of ED/LCS with Shalev Ben-David, Rolando La Placa, and John Wright. I was a bit bummed to find out that we got scooped by Buhrman et al, but I know of at least 3 other groups that were also scooped by the same paper, so at least we’re in good company <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p>At the time, a fellow postdoc from Psychology asked me what I was working on. I resisted the temptation to try to explain the various quantum variants of NC-SETH, and instead told him I was working on “DNA sequencing with quantum computers”. His reaction was priceless. Regardless of what you’re actually working on, try this line during the holidays when your relatives ask you about your work.</p>
<p> </p></div>
    </content>
    <updated>2019-12-09T18:20:46Z</updated>
    <published>2019-12-09T18:20:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>aviad.rubinstein</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=1391</id>
    <link href="https://francisbach.com/jacobi-polynomials/" rel="alternate" type="text/html"/>
    <title>Polynomial magic II : Jacobi polynomials</title>
    <summary>Following up my last post on Chebyshev polynomials, another piece of polynomial magic this month. This time, Jacobi polynomials will be the main players. Since definitions and various formulas are not as intuitive as for Chebyshev polynomials, I will start by the machine learning / numerical analysis motivation, which is an elegant refinement of Chebyshev...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Following up my last post on Chebyshev polynomials, another piece of polynomial magic this month. This time, Jacobi polynomials will be the main players.</p>



<p class="justify-text">Since definitions and various formulas are not as intuitive as for Chebyshev polynomials, I will start by the machine learning / numerical analysis motivation, which is an elegant refinement of Chebyshev acceleration.</p>



<h2>Spectral measures and polynomial acceleration</h2>



<p class="justify-text">Like in the previous post, we consider the iteration in \(\mathbb{R}^n\) $$x_{k+1} = Ax_{k} – b,$$ with \(A \in \mathbb{R}^{n \times n}\) a symmetric matrix with spectrum \({\rm Spec}(A) \subset (-1,1)\), with unique fixed point \(x_\ast\) such that \(x_\ast = A x_\ast – b\), that is, \(x_\ast = ( A – I)^{-1} b\).  These recursions naturally come up in gradient descent for quadratic functions or gossip algorithms (as described later).</p>



<p class="justify-text">In order to speed-up convergence, a classical idea explored in the <a href="https://francisbach.com/chebyshev-polynomials/">last post</a> is to take linear combinations of all past iterates. That is, we consider \(y_k = \sum_{i=0}^k \nu_i^k x_i\) for some weights \(\nu_i^k\) such that \(\sum_{i=0}^k \nu_i^k=1\) (so that if all iterates are already at \(x_\ast\), then the weighted average stays there). We have $$ y_k – x_\ast =  \sum_{i=0}^k \nu_i^k ( x_i – x_\ast) = \sum_{i=0}^k \nu_i^k A^i (x_0-x_\ast) = P_k(A) (x_0-x_\ast),$$ where \(P_k(X) = \sum_{i=0}^k \nu_i^k X^i\) is a polynomial such that \(P_k(1)=1\).  </p>



<p class="justify-text">For Chebyshev acceleration, we used the following bound: $$  \frac{1}{n} \| y_k – x_\ast\|_2^2 =   \frac{1}{n} ( x_0 – x_\ast)^\top P_k(A)^2 (x_0 -x_\ast)   \leq \max_{\lambda \in {\rm Spec}(A)} |P_k(\lambda)|^2 \cdot \frac{1}{n}\|x_0 – x_\ast\|_2^2.$$ Using the fact that  \({\rm Spec}(A) \subset [-1\!+\!\delta,1\!-\!\delta]\) for some \(\delta&gt;0\), minimizing \(\max_{\lambda \in {\rm Spec}(A)} |P_k(\lambda)|^2\) subject to \(P_k(1)=1\) led to a rescaled Chebyshev polynomials. This allowed to go from a convergence rate proportional to \((1\!-\!\delta)^k\) to a convergence rate proportional to \((1 – \sqrt{2\delta})^k\).</p>



<p class="justify-text">When \(\delta\) is small, this is a significant gain. But when \(\delta\) is really small, none of the two techniques converge quickly enough, in particular in early iterations where the exponential convergence regime has not been reached. However, only a few eigenvalues are close to \(-1\) or \(1\)  (see examples in gossip matrices below), and using more information about eigenvalues beyond the smallest and largest ones can be advantageous.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1600" height="159" src="https://francisbach.com/wp-content/uploads/2019/10/comparing_spectra-1-1024x266.png" width="613"/>Histogram of eigenvalues of gossip matrices for gossiping within the 1D, 2D and 3D grid, with the same number of nodes \(n = 4096\): the eigengap \(1-\rho\) is small, and the eigenvalues are well-spread. See more details in the gossip section below.</figure></div>



<p class="justify-text">We will use the spectral decomposition \(A = \sum_{i=1}^n\! \lambda_i u_i u_i^\top\), where \(\lambda_i\) is an eigenvalue of \(A\) with orthonormal eigenvectors \(u_i\), \(i=1,\dots,n\). We thus have $$  \frac{1}{n} \| y_k – x_\ast\|_2^2 = \frac{1}{n} ( x_0 – x_\ast)^\top P_k\Big( \sum_{i=1}^n \lambda_i u_i u_i^\top \Big)^2 ( x_0 – x_\ast) =  \frac{1}{n}\! \sum_{i=1}^n P_k(\lambda_i)^2 \big[ (x_0 – x_\ast)^\top u_i \big]^2.$$ Assuming \(\big[ (x_0 – x_\ast)^\top u_i \big]^2 \leq \tau^2\) for all \(i=1,\dots,n\) (that is, the initial deviation from the optimum has uniform magnitude on all eigenvectors), we need to minimize $$ e(P_k) = \frac{1}{n} \! \sum_{i=1}^n \! P_k(\lambda_i)^2  = \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)$$ with respect to \(P_k\), where \(d\sigma = \frac{1}{n} \sum_{i=1}^n\! \delta_{\lambda_i}\) is the spectral probability measure of \(A\).</p>



<p class="justify-text">Now, the new goal is to minimize \(\displaystyle \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)\) with respect to a polynomial \(P_k\) with degree \(k\) and such that \(P_k(1)=1\). This is where orthogonal polynomials naturally come in. Their use in creating acceleration mechanisms dates back from numerical analysis in the 1980’s and 1990’s (with a very nice and detailed account in [1]).</p>



<h2>Orthogonal polynomials and kernel polynomials</h2>



<p class="justify-text">We consider a sequence of <a href="https://en.wikipedia.org/wiki/Orthogonal_polynomials">orthogonal polynomials</a> \(Q_k\) for the probability measure \(d\sigma\) in support within \([-1,1]\), each of degree \(k\), which we do not assume normalized. They are essentially unique (up to rescaling); see, e.g., the very good books by Gábor Szegő [2] and Theodore Seio Chihara [3].</p>



<p class="justify-text">We denote by \(\alpha_i = \int_{-1}^1 \! Q_i^2(\lambda)d\sigma(\lambda)\), for \(i \geq 0\), the squared norm of \(Q_i\), so that the sequence of polynomials \(({\alpha_i^{-1/2}} Q_i)\) is <em>orthonormal</em>. We can then solve the optimization problem above for \(P_k\), by writing it \(P_k(X) = \sum_{i=0}^k u_i {\alpha_i^{-1/2}} Q_i(X)\), and the problem in \(u \in\mathbb{R}^{k+1}\) becomes: $$\min_{u \in \mathbb{R}^{k+1}} \sum_{i=0}^k u_i^2 \mbox{ such that }  \sum_{i=0}^k u_i {\alpha_i^{-1/2}} Q_i(1) = 1.$$ This optimization problem can be solved in closed form, and the solution is such that \(\displaystyle u_i = \frac{{\alpha_i^{-1/2}} Q_i(1)}{\sum_{j=0}^k \!{\alpha_j^{-1}} Q_j(1)^2}\) for all \(i\), with the optimal polynomial $$P_k(X) =  \frac{\sum_{i=0}^k \! {\alpha_i^{-1}} Q_i(1) Q_i(X) }{\sum_{i=0}^k \!{\alpha_i^{-1}} Q_i(1)^2}.$$ The optimal value is thus equal to $$\big({\sum_{i=0}^k \alpha_i^{-1} Q_i(1)^2 } \big)^{-1}.$$</p>



<p class="justify-text">The polynomials \(\sum_{i=0}^k \alpha_i^{-1} Q_i(X)Q_i(Y)\) are called the <em>kernel polynomials</em> [3, Chapter I, Section 7] associated to \(d\sigma\), and have many properties (beyond the optimality property which we just proved) that we will use below. </p>



<p class="justify-text">At this point, the problem seems essentially solved: one can construct iteratively the polynomials \(Q_k\) using classical second-order recursions for orthogonal polynomials, and thus compute \(P_k(X)\) which is proportional to \(\sum_{i=0}^k \frac{1}{\alpha_i} Q_i(1) Q_i(X)\). This leads however to a somewhat complicated algorithm, and some additional polynomial magic can be invoked.</p>



<p class="justify-text">It turns out that kernel polynomials, of which \(P_k\) is a special case, are themselves proportional to orthogonal polynomials for the modified measure \((1-\lambda) d \sigma(\lambda)\) (see proof at the end of the post). This is useful to generate the optimal polynomial with a second-order recursion.</p>



<p class="justify-text">To summarize, if we know the spectral measure \(d\sigma\), then we can derive a sequence of polynomials \(P_k\) that leads to an optimal value for \(\displaystyle \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)\). However, knowing precisely the spectral density is typically as hard as finding the fixed point of the recursion.</p>



<p class="justify-text">Since convergence properties are dictated by the behavior of the spectral measure around \(-1\) and \(1\), i.e., by the number of eigenvalues around \(-1\) and \(1\), we can model the spectral measure by simple distributions with varied behavior at the two ends of the spectrum. A known family is the rescaled Beta distribution, with density proportional to \((1-x)^\alpha (1+x)^\beta\). This will lead to Jacobi polynomials and “simple” formulas below.</p>



<h2>Jacobi polynomials</h2>



<p class="justify-text">For \(\alpha, \beta &gt; -1\), the \(k\)-th <a href="https://en.wikipedia.org/wiki/Jacobi_polynomials">Jacobi polynomial</a> \(J_k^{(\alpha,\beta)}\) is equal to $$J_k^{(\alpha,\beta)}(x) = \frac{(-1)^k}{2^k k!} (1-x)^{-\alpha} (1+x)^{-\beta} \frac{d^k}{dx^k} \Big\{ (1-x)^{\alpha + k} (1+x)^{\beta + k} \Big\}.$$ </p>



<p class="justify-text">Denoting \(\displaystyle d\sigma(x) =   \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} ( 1 -x )^\alpha (1+x)^\beta dx\) the rescaled <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a> (with \(\Gamma(\cdot)\) the <a href="https://en.wikipedia.org/wiki/Gamma_function">Gamma function</a>), the Jacobi polynomials are orthogonal for the probability measure \(d\sigma\). That is, $$ \int_{-1}^1  \! J_k^{(\alpha,\beta)}(x) J_\ell^{(\alpha,\beta)}(x) d\sigma(x) = 0, $$ if \(k \neq \ell\), and equal to \(\displaystyle \alpha_k = \frac{1}{2k+\alpha + \beta + 1} \frac{\Gamma(\alpha+\beta +2) \Gamma(k+\alpha+1) \Gamma(k+\beta+1)}{\Gamma(\alpha+1) \Gamma(\beta +1)  \Gamma(k+1) \Gamma(k+\alpha+\beta+1)}\) if \(k=\ell\). We have the following equivalent \( \displaystyle \alpha_k \sim \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1) }\frac{1}{2k}\) when \(k\) tends to infinity. All the formulas in these sections can be obtained from standard references on orthogonal polynomials [2, 3] (with a summary on <a href="https://en.wikipedia.org/wiki/Jacobi_polynomials">Wikipedia</a>) and are presented without proofs.</p>



<p class="justify-text">The value at 1 is an important quantity for acceleration, and is equal to: $$ J_k^{(\alpha,\beta)}(1) = {k+\alpha \choose k} = \frac{\Gamma(k+\alpha+1)}{\Gamma(k+1) \Gamma(\alpha+1)} \sim \frac{ (k/e)^\alpha}{\Gamma(\alpha+1)},$$ while the value at -1 is equal to $$ J_k^{(\alpha,\beta)}(-1) =(-1)^k {k+\beta \choose k} = \frac{\Gamma(k+\beta+1)}{\Gamma(k+1) \Gamma(\beta+1)} \sim \frac{ (k/e)^\beta}{\Gamma(\beta+1)}.$$ </p>



<p class="justify-text">In order to compute the polynomials, the following recursion is key: $$  J_{k+1}^{(\alpha,\beta)}(X) = (a_k^{(\alpha,\beta)} X + \tilde{b}_k^{(\alpha,\beta)})J_k^{(\alpha,\beta)} – c_k J_{k-1}^{(\alpha,\beta)}(X),$$ with coefficients with explicit (and slightly complicated) formulas (in the case you wonder why I use \(\tilde{b}\) instead of \(b\), this is to avoid overloading the notation with the iteration \(x_{k+1}= Ax_{k}-b\)): $$a_k^{(\alpha,\beta)} =   \frac{(2k+\alpha+\beta+1)  (2k+2+\alpha+\beta)  }{(2k+2)(k+1+\alpha+\beta)  },\ \ \ \ \ \ \ \ \ $$ $$ \tilde{b}_k^{(\alpha,\beta)}  =   \frac{(2k+\alpha+\beta+1) ( \alpha^2 – \beta^2 )}{(2k+2)(k+1+\alpha+\beta) (2k + \alpha+\beta )},$$ $$c_k^{(\alpha,\beta)}  =\frac{ 2 (k+\alpha)(k+\beta)(2k +2+\alpha+\beta) }{(2k+2)(k+1+\alpha+\beta) (2k + \alpha+\beta )}.  $$ It can be started with \(J_0^{(\alpha,\beta)}(X) = 1\) and \(J_1^{(\alpha,\beta)}(X) = \frac{\alpha – \beta}{2} +\frac{ \alpha + \beta +2}{2} X\).</p>



<p class="justify-text">The class of Jacobi polynomials includes many of other important polynomials, such as <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> (\(\alpha = \beta = -1/2\)), <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomials</a> (\(\alpha = \beta = 0\)) and <a href="https://en.wikipedia.org/wiki/Gegenbauer_polynomials">Gegenbauer polynomials </a>(\(\alpha = \beta = d-1/2\)). Here are plots below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1604" height="202" src="https://francisbach.com/wp-content/uploads/2019/10/jacobi-1.gif" width="387"/>Jacobi polynomials, as used for the acceleration of gossip algorithms in one-dimension, with \((\alpha,\beta) = (1/2,-1/2)\).</figure></div>



<h2>Jacobi acceleration</h2>



<p class="justify-text">We can now apply the polynomial acceleration technique above to the Beta distribution, that is for \(\displaystyle d\sigma(x) =   \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} ( 1 -x )^\alpha (1+x)^\beta dx\), we have:</p>



<ul class="justify-text"><li><strong>Regular recursion error</strong> (no acceleration):  the error \(e(X^k) = \displaystyle \int_{-1}^1 \lambda^{2k} d\sigma(\lambda)\) is asymptotically equivalent to \(\displaystyle \frac{C_{\alpha,\beta}}{k^{\alpha+1}}+\frac{C_{\beta,\alpha}}{k^{\beta+1}}\), for some constants \(C_{\alpha,\beta}\) (see details at the end of the post). Before acceleration, there is thus an equivalent impact of the spectrum around \(-1\) and \(1\).</li><li><strong>Jacobi acceleration error</strong>: as shown at the end of the post, the error \(e(P_k)\) is equivalent to \(\displaystyle  \frac{E_{\alpha,\beta}}{k^{2\alpha+2}} \) for some constant \(E_{\alpha,\beta}\). </li></ul>



<p class="justify-text">What’s happening around \(-1\) and \(1\) is important, and particular the behavior around 1, and we thus see that \(\beta\) is less important for the accelerated version (in fact, using \(\beta=0\) to construct the Jacobi polynomial, as done in [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>], leads to a similar acceleration). In particular, when considering distributions where \(\beta = \alpha\), then we see that Jacobi acceleration transforms a rate proportional to \(1/k^{\alpha+1}\) to a rate proportional to \(1/k^{2\alpha+2}\).</p>



<p class="justify-text">The final recursion is then equal to (see detailed computations at the end of the post): $$ y_{k+1} =  \frac{(2k\!+\!\alpha\!+\!\beta\!+\!2)   }{2(k\!+\!2\!+\!\alpha\!+\!\beta)(k\!+\!\alpha\!+\!2)  }  \big[ (2k\!+\!3\!+\!\alpha\!+\!\beta) (Ay_k-b) +  \frac{ (\alpha\!+\!1)^2\! -\! \beta^2  }{  2k \!+\! 1\!+\!\alpha\!+\!\beta }    y_k    \Big] \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  $$ $$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  –  \frac{    (k+\beta)(2k +3+\alpha+\beta) }{ (k+2+\alpha+\beta) (2k + 1+\alpha+\beta )} \frac{ k }{ k+\alpha+2} y_{k-1}, $$ with initialization \(y_0=x_0\) and \(y_1 = \frac{\alpha+\beta+3}{2\alpha+4}(Ax_0 – b) + \frac{\alpha+1-\beta}{2\alpha+4}x_0\). For \(\alpha = \frac{d}{2}-1\) and \(\beta =0\), this exactly recovers the recursion from [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>].</p>



<h2>Application to gossip</h2>



<p class="justify-text">Like in the previous post we consider the gossip problem. For large grid graphs, the gap is small, equivalent to \(\frac{1}{2d} \frac{1}{n^{2/d}}\) for the \(d\)-dimensional grid. The gap is tending to zero with \(n\), and using acceleration techniques for non-zero gaps, such as Chebyshev acceleration, is not efficient for the earlier iterations.</p>



<p class="justify-text">It turns out that for grid graphs, the spectral measure tends to a limit with behavior \((1-x^2)^{d/2-1}\) around \(-1\) and \(1\). This is formerly true for the grid graph, and the behavior around 1 (which is the one that matters for acceleration) is the same for a large class of graphs with an underlying geometric structure [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>]. This thus corresponds to the Beta distribution of parameters \(\alpha = \beta = \frac{d}{2}-1\).</p>



<p class="justify-text">Below, I consider gossiping on a chain graph with \(n=200\) nodes, and compare regular gossip with Chebyshev acceleration and Jacobi acceleration. In early iterations, Jacobi acceleration is much better. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1714" height="204" src="https://francisbach.com/wp-content/uploads/2019/10/gossip_jacobi_1D.gif" width="673"/>Gossiping a one-dimensional white noise signal of length \(n = 200\), converging to its mean, which is zero. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration</figure></div>



<p class="justify-text">When looking at the convergence rate (plot below), for late iterations, the linear convergence of Chebyshev acceleration does take over; for a method that achieves the best of both world (good in early and late iterations), see [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Section 7].</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1808" height="196" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_1D_double-1024x457.png" width="441"/>Squared gossiping errors (norm between the signal and its average) in natural (left) and logarithmic (right) scale. Chebyshev acceleration is slow at the beginning, and faster at the end (once the error is already quite small).</figure></div>



<p>Similar plots may be made in two dimensions, gossiping a white noise signal, where the stationary behavior is observed much sooner for Jacobi acceleration. Here, Chebyshev acceleration performs worse than the regular iteration because the eigengap is very small (equal to \(6 \times 10^{-4}\)).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-1859" height="180" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_2D-1.gif" width="663"/>Gossiping a two-dimensional white noise signal of size \(n = 64 \times 64 = 4096\), converging to its mean, which is zero. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration.</figure></div>



<p class="justify-text">When gossiping a Dirac signal, we can also observe the spreading of information from the original position of the Dirac to the rest of the grid.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-1858" height="179" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_2D_diracs-1.gif" width="661"/>Gossiping a two-dimensional Dirac signal of size \(n = 64 \times 64 = 4096\), converging to its mean. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration. Note that the color scale is different in the three plots.</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I tried to move from the worst-case analysis of spectral acceleration which typically focuses on largest and smallest eigenvalues of the involved contracting operators, closer to an average-case analysis that takes into account the whole spectrum. This led to acceleration by Jacobi polynomials rather than Chebyshev polynomials. </p>



<p class="justify-text"><strong>Beyond gossip.</strong> While I have focused primarily on applications to gossip where the spectral measure can be well approximated, this can be extended to other situations. For example, Fabian Pedregosa and Damien Scieur [<a href="https://drive.google.com/open?id=1MSVk90bvK3m-GM1y-RirKdy_HRoJzZwV">5</a>] recently considered an application of polynomial acceleration to gradient descent for least-squares regression with independent covariates, where the spectral measure of the covariance matrix tends to the famous <a href="https://en.wikipedia.org/wiki/Marchenko%E2%80%93Pastur_distribution">Marchenko-Pastur</a> distribution (which is close to the rescaled Beta distributions above).</p>



<p class="justify-text"><strong>Jacobi polynomials beyond acceleration.</strong> In this post, I focused only on the acceleration properties of Jacobi polynomials. There are many more interesting applications of these polynomials in machine learning and associated fields. For example, their role in <a href="https://en.wikipedia.org/wiki/Spherical_harmonics">spherical harmonics</a> to provide an orthonormal basis of the square-integrable functions on the unit sphere in any dimension, is quite useful for the theoretical study of neural networks (see, e.g., [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">6</a>] and references therein). I would typically say that this is a topic for another post, but this would be even more technical…</p>



<p class="justify-text">Next month, I will probably take a break in the polynomial magic series, and go back to less technical posts.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Raphaël Berthier for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Bernd Fischer. <em>Polynomial based iteration methods for symmetric linear systems</em>. Springer, 1996. <br/>[2] Gábor Szegő. <em>Orthogonal Polynomials</em>. American Mathematical Society, volume 23, 1939.<br/>[3] Theodore Seio Chihara. <em>An Introduction to Orthogonal Polynomials</em>. Gordon and Breach, 1978.<br/>[4] Raphaël Berthier, Francis Bach, Pierre Gaillard. <a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">Accelerated Gossip in Networks of Given Dimension using Jacobi Polynomial Iterations</a>. To appear in <em>SIAM Journal on Mathematics of Data Science</em>, 2019.<br/>[5] Fabian Pedregosa, Damien Scieur.  <a href="https://drive.google.com/open?id=1MSVk90bvK3m-GM1y-RirKdy_HRoJzZwV">Acceleration through Spectral Modeling</a>. NeurIPS workshop “Beyond First Order Methods in ML”, 2019.<br/>[6] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the Curse of Dimensionality with Convex Neural Networks</a>. <em>Journal of Machine Learning Research</em>, 18(19):1-53, 2017.</p>



<h2>Detailed computations</h2>



<p class="justify-text"><strong>Kernel polynomial as orthogonal polynomial</strong>. We consider a series \((R_k)\) of orthogonal polynomials for the measure \((1-\lambda) d\sigma(\lambda)\). Assuming that \(R_k \neq 0\) (see proof in [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Appendix D]), then we show that the polynomial \(\frac{R_k(X)}{R_k(1)}\) is the optimal polynomial of degree \(k\) minimizing \(\int_{-1}^1 P^2(\lambda) d\sigma(\lambda)\) such that \(P(1)=1\). Indeed, taking any polynomial \(P\) of degree \(k\) and such that \(P(1)=1\), the polynomial \(P(X) \, – \frac{R_k(X)}{R_k(1)}\) vanishes at \(1\) and can thus be written as \(A(X)(X-1)\) with \(A(X)\) of degree equal or less than \(k-1\). Then we have: $$\! \int_{-1}^1 \! \! P(\lambda)^2 d\lambda = \! \int_{-1}^1\!\!   \frac{R_k(\lambda)^2}{R_k(1)^2}d\sigma(\lambda) + 2 \! \int_{-1}^1 \!\!  \frac{R_k(\lambda)}{R_k(1)} A(\lambda)(\lambda-1)d\sigma(\lambda)+ \! \int_{-1}^1  \!\! \! A(\lambda)^2(\lambda-1)^2 d\sigma(\lambda).$$ The second term in the right hand side is equal to zero by orthogonality of \((R_k)\), and the third term is non-negative. Therefore, we must have  \(\displaystyle \! \int_{-1}^1 \! \! P(\lambda)^2 d\lambda \geq  \! \int_{-1}^1\!\!   \frac{R_k(\lambda)^2}{R_k(1)^2}d\sigma(\lambda)\), which shows optimality.</p>



<p class="justify-text"><strong>Jacobi recursion</strong>. Given the original recursion \(x_{k+1} = A x_k – b\), we consider \(y_k = \frac{Q_k(A) ( x_0  – x_\ast)}{Q_k(1)} + x_\ast\), where \(Q_k = J_k^{(\alpha+1,\beta)}\). We get: $$ y_{k+1} =  \frac{(a_k^{(\alpha+1,\beta)} A + b_k^{(\alpha+1,\beta)})Q_{k}(A)( x_0  – x_\ast) – c_k^{(\alpha+1,\beta)} Q_{k-1}(A) ( x_0  – x_\ast)}{Q_{k+1}(1)} + x_\ast.$$ This leads to $$ y_{k+1} =  \frac{(a_k^{(\alpha+1,\beta)} A + b_k^{(\alpha+1,\beta)})Q_{k}(1) (y_k – x_\ast) – c_k^{(\alpha+1,\beta)} Q_{k-1}(1) ( y_{k-1}  – x_\ast)}{Q_{k+1}(1)} + x_\ast.$$ Removing all terms in \(x_\ast\) (which have to cancel), we get: $$ y_{k+1} =  a_k^{(\alpha+1,\beta)} \frac{Q_{k}(1)}{Q_{k+1}(1)}(Ay_k-b) + \tilde{b}_k^{(\alpha+1,\beta)} \frac{Q_{k}(1)}{Q_{k+1}(1)}y_k –  c_k^{(\alpha+1,\beta)} \frac{Q_{k-1}(1)}{Q_{k+1}(1)}y_{k-1}. $$ Using the explicit formula for \(Q_{k}(1)\), we get after some calculations: $$ y_{k+1} =  \frac{(2k\!+\!\alpha\!+\!\beta\!+\!2)   }{2(k\!+\!2\!+\!\alpha\!+\!\beta)(k\!+\!\alpha\!+\!2)  }  \big[ (2k\!+\!3\!+\!\alpha\!+\!\beta) (Ay_k-b) +  \frac{ (\alpha\!+\!1)^2\! -\! \beta^2  }{  2k \!+\! 1\!+\!\alpha\!+\!\beta }    y_k    \Big] \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  $$ $$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  –  \frac{    (k+\beta)(2k +3+\alpha+\beta) }{ (k+2+\alpha+\beta) (2k + 1+\alpha+\beta )} \frac{ k }{ k+\alpha+2} y_{k-1}, $$ with initialization \(y_0 = x_0\) and \(y_1 = \frac{\alpha+\beta+3}{2\alpha+4}(Ax_0 – b) + \frac{\alpha+1-\beta}{2\alpha+4}x_0\).</p>



<p class="justify-text"><strong>Equivalents of performance</strong>. We first provide an equivalent of $$ \int_{-1}^1 \lambda^{2k} d\sigma(\lambda) = \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)}\int_{-1}^1 \! x^{2k} (1-x)^\alpha(1+x)^\beta dx.$$ By splitting the sum in two, this is equivalent to $$ \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)}\Big\{ 2^\beta\!\! \int_{0}^1 \! x^{2k} (1-x)^\alpha dx  + 2^\alpha \!\! \int_{0}^1 \! x^{2k}(1-x)^\beta dx \Big\},$$ leading to, using the normalizing factor of the Beta distribution, $$\frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} \Big\{ 2^\beta\frac{\Gamma(\alpha+1)\Gamma(2k+1)}{\Gamma(\alpha+2k+2)} +2^\alpha\frac{\Gamma(\beta+1)\Gamma(2k+1)}{\Gamma(\beta+2k+2)}   \Big\}, $$ and finally to  $$ \displaystyle \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} \Big\{ 2^\beta\frac{\Gamma(\alpha+1) }{ (2k/e)^{\alpha+1} }  +2^\alpha\frac{\Gamma(\beta+1) }{ (2k/e)^{\beta+1} }    \Big\} ,$$ which is indeed of the form \(\displaystyle \frac{C_{\alpha,\beta}}{k^{\alpha+1}}+\frac{C_{\beta,\alpha}}{k^{\beta+1}}\). </p>



<p class="justify-text">In order to estimate \(e(P_k)\), since \(P_k(X) = \sum_{i=0}^k \frac{1}{\alpha_i} Q_i(1) Q_i(X)\), we first need an equivalent of the term \(\displaystyle \frac{Q_i(1)^2}{\alpha_i^2} \sim \frac{(i/e)^{2\alpha}}{\Gamma(\alpha+1)^2} \Big( \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1) }\frac{1}{2i}\Big)^{-1} \sim E_{\alpha,\beta}’ i^{2\alpha+1}\), for some \(E_{\alpha,\beta}’\), leading to an error of the form \(e(P_k) \displaystyle \sim \frac{1}{ E_{\alpha,\beta}’  \sum_{i=0}^k i^{2\alpha+1}} \sim\frac{2\alpha+2}{ E_{\alpha,\beta}’} \frac{1}{k^{2\alpha+2}} \), which is of the desired form.</p>



<p class="justify-text"><strong>Spectral density of a grid</strong>. As seen at the far end of the <a href="https://francisbach.com/chebyshev-polynomials/">previous blog post</a>, the eigenvalues of \(A\) for the grid in one-dimension, with \(m=n\), is (up to negligible corrections) \(–  \cos \frac{k\pi}{m}\) for \(k =1,\dots,m\). This leads to a limiting spectral measure as \(– \cos \theta\) for \(\theta\) uniformly distributed on \([0,\pi]\). This leads to a spectral density \(\frac{1}{\pi}\frac{1}{\sqrt{1-\lambda^2}}\) supported on \([-1,1]\). In the plot below, we see that the histogram of eigenvalues for a finite \(m\) matches empirically this density.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-1855" height="234" src="https://francisbach.com/wp-content/uploads/2019/12/1D_spectral_density.png" width="308"/>Histogram of eigenvalues for 1D gossip matrix for \(m=4096\), with associated limiting spectral density.</figure></div>



<p class="justify-text">For a \(d\)-dimensional grid, with \(n = m^d\), the spectral density is the one of \(\frac{1}{d} (X_1+\cdots X_d)\) for \(X_i\) independent and distributed as \(\frac{1}{\pi}\frac{1}{\sqrt{1-\lambda^2}} d\lambda\) on \([-1,1]\), for each \(i=1,\dots,d\). This leads to a convolution power of the density above, rescaled to have support in \([-1,1]\). This can be shown to lead to behavior as \((1-\lambda^2)^{d/2-1}\) around \(1\) and \(-1\) (see [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Prop. 5.2]).</p></div>
    </content>
    <updated>2019-12-02T17:42:18Z</updated>
    <published>2019-12-02T17:42:18Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-03-07T22:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/</id>
    <link href="https://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/" rel="alternate" type="text/html"/>
    <title>Tropical Geometry, Berkovich Spaces, Arithmetic D-Modules and p-adic Local Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 15-19, 2020 Imperial College of London (UK) https://www-fourier.ujf-grenoble.fr/~pulitaa/Imperial-Conference/Imperial-Conference.html Registration deadline: March 31, 2020 With this workshop we would like to promote the interaction between the following five fields: Berkovich spaces Tropical geometry p-adic differential equations Arithmetic D-modules and representations of p-adic Lie groups Arithmetic applications of p-adic local systems While the first two are … <a class="more-link" href="https://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/">Continue reading <span class="screen-reader-text">Tropical Geometry, Berkovich Spaces, Arithmetic D-Modules and p-adic Local Systems</span></a></div>
    </summary>
    <updated>2019-12-01T16:59:41Z</updated>
    <published>2019-12-01T16:59:41Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5474</id>
    <link href="https://adamsheffer.wordpress.com/2019/12/01/teenagers-doing-mathematical-research/" rel="alternate" type="text/html"/>
    <title>Teenagers doing Mathematical Research</title>
    <summary>I’d like to ramble about another program that our group is running. We are searching for unusually promising high-school-age students and mentor each in a serious research project. We started doing this already before our REU program. However, I never advertised this program before, because I felt that we were still learning how to do […]</summary>
    <updated>2019-12-01T15:27:45Z</updated>
    <published>2019-12-01T15:27:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-03-07T22:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=381</id>
    <link href="https://tcsplus.wordpress.com/2019/11/27/tcs-talk-wednesday-december-4-nihar-shah-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, December 4 — Nihar Shah, CMU</title>
    <summary>The next TCS+ talk, and last of the Fall season, will take place this coming Wednesday, December 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Nihar Shah from CMU will speak about “Battling Demons in Peer Review” (abstract below). Please make sure you reserve a spot for your group […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk, and last of the Fall season, will take place this coming Wednesday, December 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Nihar Shah</strong> from CMU will speak about “<em>Battling Demons in Peer Review</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Peer review is the backbone of scholarly research. It is however faced with a number of challenges (or “demons”) which cause unfairness to authors, and degrade the overall quality of the process. This talk will present principled and practical approaches to battle these demons in peer review:</p>
<ol>
<li>Subjectivity: How to ensure that all papers are judged by the same yardstick?</li>
<li>Mis-calibration: How to use ratings in presence of arbitrary or adversarial mis-calibration?</li>
<li>Bias: How to rigorously test for existence of (gender/fame/race/…) biases in peer review?</li>
<li>Strategic behavior: How to insulate peer review from strategic behavior of author-reviewers?</li>
<li>Noise: How to assign reviewers to papers to simultaneously ensure fair and accurate evaluations in the presence of review noise?</li>
</ol>
<p>The work uses tools from social choice theory, statistics and learning theory, information theory, game theory and decision theory. No prior knowledge on these topics will be assumed.</p></blockquote>
<p>Bio:<br/>
<em><a href="http://cs.cmu.edu/~nihars">Nihar B. Shah</a> is an Assistant Professor in the Machine Learning and Computer Science departments at Carnegie Mellon University (CMU). His research interests include statistics, machine learning, information theory, and game theory, with a focus on applications to learning from people. He is a recipient of the the 2017 David J. Sakrison memorial prize from EECS Berkeley for a “truly outstanding and innovative PhD thesis”, the Microsoft Research PhD Fellowship 2014-16, the Berkeley Fellowship 2011-13, the IEEE Data Storage Best Paper and Best Student Paper Awards for the years 2011/2012, and the SVC Aiya Medal 2010, and has supervised the Best Student Paper at AAMAS 2019.</em></p></div>
    </content>
    <updated>2019-11-28T01:56:48Z</updated>
    <published>2019-11-28T01:56:48Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/</id>
    <link href="https://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/" rel="alternate" type="text/html"/>
    <title>Quantum Computer Science School 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">January 14-16, 2020 University of Technology Sydney, Australia http://conference.iiis.tsinghua.edu.cn/QCSS2020/ The Quantum Computer Science School 2020 will consist of three days of lectures and academic activities, targeting at senior undergraduates and graduate students in Australian and Asian universities. The lecturers are Mingsheng Ying, Luming Duan, Michael Bremner, Troy Lee, and Ran Duan, and the topics include … <a class="more-link" href="https://cstheory-events.org/2019/11/26/quantum-computer-science-school-2020/">Continue reading <span class="screen-reader-text">Quantum Computer Science School 2020</span></a></div>
    </summary>
    <updated>2019-11-26T01:06:34Z</updated>
    <published>2019-11-26T01:06:34Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1539</id>
    <link href="https://theorydish.blog/2019/11/24/motwani-postdoctoral-fellowship-2/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoctoral Fellowship</title>
    <summary>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/15578 Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below.</p>
<p>Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/15578">https://academicjobsonline.org/ajo/jobs/15578</a><br/>
Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2019-11-25T00:02:30Z</updated>
    <published>2019-11-25T00:02:30Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=680</id>
    <link href="https://emanueleviola.wordpress.com/2019/11/21/manucomic-1/" rel="alternate" type="text/html"/>
    <title>manucomic #1</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" class="wp-image-681" src="https://emanueleviola.files.wordpress.com/2019/11/manucomic1.jpg?w=746"/></figure></div>
    </content>
    <updated>2019-11-21T16:54:34Z</updated>
    <published>2019-11-21T16:54:34Z</published>
    <category term="Uncategorized"/>
    <category term="manucomic"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-07T22:21:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=378</id>
    <link href="https://tcsplus.wordpress.com/2019/11/13/tcs-talk-wednesday-november-20-jason-li-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, November 20 — Jason Li, CMU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, November 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Jason Li from CMU will speak about “The Karger-Stein Algorithm is Optimal for -cut” (abstract below). Please make sure you reserve a spot for your group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, November 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Jason Li</strong> from CMU will speak about “<em>The Karger-Stein Algorithm is Optimal for <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-cut</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-cut problem, we are given an edge-weighted graph and want to find the least-weight set of edges whose deletion breaks the graph into <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/> connected components. Algorithms due to Karger-Stein and Thorup showed how to find such a minimum <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-cut in time approximately <img alt="O(n^{2k-2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B2k-2%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(n^{2k-2})"/>. The best lower bounds come from conjectures about the solvability of the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-clique problem and a reduction from <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-clique to <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-cut, and show that solving <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/>-cut is likely to require time <img alt="\Omega(n^k)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28n%5Ek%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Omega(n^k)"/>. Our recent results have given special-purpose algorithms that solve the problem in time <img alt="n^{1.98k + O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1.98k+%2B+O%281%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="n^{1.98k + O(1)}"/>, and ones that have better performance for special classes of graphs (e.g., for small integer weights).</p></blockquote></div>
    </content>
    <updated>2019-11-13T18:35:24Z</updated>
    <published>2019-11-13T18:35:24Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1525</id>
    <link href="https://theorydish.blog/2019/11/05/next-week-toca-sv-motwani-colloquium/" rel="alternate" type="text/html"/>
    <title>Next week: TOCA-SV + Motwani Colloquium</title>
    <summary>Our first TOCA-SV meeting of the academic year is coming up next Friday, in Tressider Oak Lounge, Stanford. Like last year, it will host the Motwani Colloquium. We have reserved some parking (see instructions below) on a first come first serve basis (so come early). Also see the schedule and abstract below. Parking There are 35 reserved spaces in Tresidder Lot (L-39) on November 15, 2019. Our  space numbers will be 14-48; see map for location. Posted signs to read Reserved for TOCA-SV CS Workshop. To avoid a citation, vehicle information is required to obtain permission to park in the designated reserved area. Use: https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523 See instructions. *Internet browser Chrome or Firefox are recommended and most compatible with the system.   Schedule: 10:30-11:10 Hanie Sedghi, Google AI, Size-free generalization bounds for convolutional neural networks 11:10-11:50 Dean Doron, Stanford University, Nearly Optimal Pseudorandomness from Hardness 11:50-12:30 Barna Saha, UC Berkeley, Algorithms for Fast Sequence Comparison 12:30-1:30 lunch 1:30-3:30 Student’s poster session 3:30-4:15 break 4:15-5:30 Motwani Colloquium, Ronitt Rubinfeld, MIT and Tel Aviv University,Local Computation Algorithms Abstracts Hanie Sedghi, Google AI Size-free generalization bounds for convolutional neural networks We prove bounds on the generalization error of convolutional networks. The bounds are characterized in terms of the training loss, the number of parameters, the Lipschitz constant of [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Our first TOCA-SV meeting of the academic year is coming up next Friday, in Tressider Oak Lounge, Stanford. Like last year, it will host the Motwani Colloquium. We have reserved some parking (see instructions below) on a first come first serve basis (so come early). Also see the schedule and abstract below.</p>
<div>
<p><strong>Parking</strong></p>
<p style="font-weight: 400;">There are <strong>35</strong> reserved spaces in <strong>Tresidder Lot (L-39)</strong> on <strong>November 15, 2019. Our </strong> space numbers will be <strong>14-48</strong>; see <a href="https://theorydish.files.wordpress.com/2019/11/tresidder-lot-l-39.pdf">map </a>for location. Posted signs to read <strong>Reserved for </strong><strong>TOCA-SV CS Workshop</strong><strong>.</strong></p>
<p style="font-weight: 400;"><strong>To avoid a citation, vehicle information is required to obtain permission to park in the designated reserved area. Use: </strong><a href="https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523">https://stanford.nupark.com/v2/portal/eventregister/5201e8f7-9339-4acf-8416-62f137dbc523</a> See <a href="https://theorydish.files.wordpress.com/2019/11/instructions-on-how-to-register-vehicles.pdf">instructions</a>.</p>
<p style="font-weight: 400;"><em>*Internet browser Chrome or Firefox are recommended and most compatible with the system.</em></p>
<p> </p>
</div>
<div><strong>Schedule</strong>:</div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im"><span class="im"><span class="im">10:30-11:10 <a class="Oux49">Hanie Sedghi, Google AI, </a></span></span></span><em><span>Size-free generalization bounds for convolutional neural networks</span></em></div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im">11:10-11:50 Dean Doron, Stanford University, <em>Nearly Optimal Pseudorandomness from Hardness</em></span></div>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im">11:50-12:30 Barna Saha, UC Berkeley, <em>Algorithms for Fast Sequence Comparison</em></span></div>
<div class="sharedaddy sd-sharing-enabled">
<div>
<div/>
<div>12:30-1:30 lunch</div>
<div/>
<div>1:30-3:30 Student’s poster session</div>
<div class="yj6qo ajU">
<div/>
<div class="ajR" id=":m2v"><span>3:30-4:15 break</span></div>
</div>
<div class="adL">
<div/>
<div>
<p>4:15-5:30 Motwani Colloquium, <span><span>Ronitt Rubinfeld, </span></span><span><span>MIT and Tel Aviv University,</span></span><em>Local Computation Algorithms</em></p>
</div>
</div>
</div>
<div/>
<div><strong>Abstracts</strong></div>
</div>
<div/>
<ul>
<li>Hanie Sedghi, Google AI<span class="im"><a class="Oux49"><br/>
</a></span></li>
</ul>
<div/>
<div><em><span>Size-free generalization bounds for convolutional neural networks</span></em></div>
<div/>
<div>We prove bounds on the generalization error of convolutional networks. The bounds are characterized in terms of the training loss, the number of parameters, the Lipschitz constant of the loss, and the distance of the initial and final weights. The bounds are independent of the number of pixels in the input, as well as the width and height of hidden feature maps. These are the first bounds for DNNs with such guarantees.  We present experiments with CIFAR-10, varying hyperparameters of a deep convolutional network, comparing our bounds with practical generalization gaps.</div>
<div/>
<ul>
<li><span class="im">Dean Doron, Stanford University, </span></li>
</ul>
<div/>
<div><span class="im"><em>Nearly Optimal Pseudorandomness from Hardness</em></span></div>
<div/>
<div>
<p>Existing techniques for derandomizing algorithms based on circuit lower bounds yield a large polynomial slowdown in running time. We show that assuming exponential lower bounds against nondeterministic circuits, we can convert any randomized algorithm running in time T to a deterministic one running in time nearly T^2. Under complexity-theoretic assumptions, such a slowdown is nearly optimal.</p>
<p>In this talk I will concentrate on the role of error-correcting codes in those techniques. We will see which properties of error-correcting codes are useful for constructing pseudorandomness primitives sufficient for derandomization, where they came short of achieving better slowdown, and how we can overcome that.</p>
<p>Based on joint work with Dana Moshkovitz, Justin Oh and David Zuckerman</p>
</div>
<div/>
<ul>
<li class="sharedaddy sd-sharing-enabled"><span class="im">Barna Saha, UC Berkeley, </span></li>
</ul>
<div/>
<div class="sharedaddy sd-sharing-enabled"><span class="im"><em>Algorithms for Fast Sequence Comparison</em></span></div>
<div/>
<div/>
<div class="sharedaddy sd-sharing-enabled">
<div>
<div>
<div> There are many basic problems over sequences. For example, computing the edit distance between two sequences, detecting how RNA sequences fold, finding the distance between a sequence and a language (collection of sequences), understanding how disbalanced a parenthesis sequence is. They have natural applications in various areas including computational biology, natural language processing, compiler optimization, and data cleaning. The last few years have seen a plethora of results where new faster algorithms have been developed for these problems with various trade-offs between approximation (quality of solution) and running time (scalability). In this talk, I will present some of the tools that have been developed from my work related to these problems. Depending on time and audience choices, we will cover one or more of the following.</div>
<div/>
<div>(i) A random walk based technique useful to measure how disbalanced a parenthesis sequence is, which has also been useful for streaming computation of edit distance.</div>
<div/>
<div>(ii) A dependent rounding technique that gives nearly optimal result in nearly optimal time for estimating distance between a sequence and a language, which can also be used to speed up other polynomial time problems, such as the all pairs shortest path computation on graphs.</div>
<div/>
<div>(iii) An amnesic dynamic programming technique that gives significantly faster approximation algorithm for RNA-folding, which can also be useful for many dynamic programming based problems that have Lipschitz property (most sequence problems have it).</div>
<div/>
<div>(iv) An elimination of shortest path technique that gives sublinear time algorithms for estimating edit distance for certain regimes of edit distance.</div>
<div/>
<div>The audience is encouraged to pick their favorite and convey that to the speaker at or before (by email) the talk.</div>
</div>
</div>
</div>
<div/>
<div class="sharedaddy sd-sharing-enabled">
<div>
<ul>
<li><span>Ronitt Rubinfeld, </span><span>MIT and Tel Aviv University,</span></li>
</ul>
<div>
<p><em>Local Computation Algorithms</em></p>
<p>Consider a setting in which inputs to and outputs from a computational problem are so large, that there is not time to read them in their entirety.   However, if one is only interested in small parts of the output at any given time, is it really necessary to solve the entire computational problem? Is it even necessary to view the whole input? We survey recent work in the model of  “local computation algorithms” which for a given input, supports queries by a user to values of specified bits of a legal output.  The goal is to design local computation algorithms in such a way that very little of the input needs to be seen in order to determine the value of any single bit of the output. Though this model describes sequential computations, techniques from local distributed algorithms have been extremely important in designing efficient local computation algorithms. In this talk, we describe results on a variety of problems for which sublinear time and space local computation algorithms have been developed — we will give special focus to finding maximal independent sets and sparse spanning graphs.</p>
</div>
</div>
</div>
<p> </p>
<p style="font-weight: 400;"/></div>
    </content>
    <updated>2019-11-06T02:20:06Z</updated>
    <published>2019-11-06T02:20:06Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/</id>
    <link href="https://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/" rel="alternate" type="text/html"/>
    <title>Prague Summer School on Discrete Mathematics 2020</title>
    <summary>August 24, 2012 – August 28, 2020 Prague, Czechia http://pssdm.math.cas.cz/ Registration deadline: March 15, 2020 A one-week summer school primarily for PhD students and postdocs. Lecture courses given by Subhash Khot (New York University) and Shayan Oveis Gharan (University of Washington).</summary>
    <updated>2019-11-05T07:50:37Z</updated>
    <published>2019-11-05T07:50:37Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-07T22:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=1197</id>
    <link href="https://francisbach.com/chebyshev-polynomials/" rel="alternate" type="text/html"/>
    <title>Polynomial magic I : Chebyshev polynomials</title>
    <summary>Orthogonal polynomials pop up everywhere in applied mathematics and in particular in numerical analysis. Within machine learning and optimization, typically (a) they provide natural basis functions which are easy to manipulate, or (b) they can be used to model various acceleration mechanisms. In this post, I will describe one class of such polynomials, the Chebyshev...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">Orthogonal polynomials pop up everywhere in applied mathematics and in particular in numerical analysis. Within machine learning and optimization, typically (a) they provide natural basis functions which are easy to manipulate, or (b) they can be used to model various acceleration mechanisms.</p>



<p class="justify-text">In this post, I will describe one class of such polynomials, the Chebyshev polynomials (Tchebychev in French, Чебышёв in Russian), whose extremal properties (beyond being orthogonal) are useful in the analysis of accelerated algorithms. </p>



<h2>Definition and first properties</h2>



<p class="justify-text">The \(k\)-th <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomial</a> \(T_k\) is classically defined as the unique polynomial such that $$\forall  \theta \in [0,2\pi], \  \cos (k\theta) = T_k(\cos \theta).$$ </p>



<p class="justify-text"><strong>Recurrence</strong>. Summing the two equations \(\cos [(k\pm 1)\theta] = \cos (k\theta) \cos \theta \mp \sin (k\theta) \sin \theta\), the following recurrence relationship can be deduced: $$\forall k &gt;0, \ T_{k+1}(X) = 2X T_k(X) \, – T_{k-1}(X).$$</p>



<p class="justify-text">Together with the first two polynomials \(T_0 (X) = 1\) and \(T_1(X) = X\), this leads to \(T_2(X) = 2X^2 – 1\), \(T_3(X) = 4X^3 – 3X\), and so on.</p>



<p class="justify-text">From the recurrence relationships, one can easily deduce that \(T_k\) has the parity of \(k\) and that \(T_k\) has degree \(k\), with leading coefficient \(2^{k-1}\).</p>



<p class="justify-text"><strong>Oscillatory behavior</strong>. For \(k\theta = j \pi\), for \(j\) integer, we have \(\cos (k \theta)=(-1)^j\), while when \(j\) goes from \(k\) to \(0\), \(\cos \theta = \cos\! \big( \frac{ j \pi}{k}\big)\) goes from -1 to 1. Thus, on \([-1,1]\), \(T_k(x)\) oscillates between \(-1\) and \(1\), with equality for \(\cos\! \big(  \frac{j \pi}{k} \big)\) for \(j = 0,\dots,k\). This oscillatory behavior is illustrated below and crucial for the extremal properties below.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1592" height="223" src="https://francisbach.com/wp-content/uploads/2019/10/chebyshev-3.gif" width="306"/>First 33 Chebyshev polynomials, plotted between -1 and 1. Note the stronger oscillatory behavior between -1 and 1 as \(k\) grows.</figure></div>



<p class="justify-text"><strong>Orthogonality</strong>. Using the orthogonality of the Fourier basis on \([0,2\pi]\), we have for \(k \neq \ell\),  \(\int_0^{\pi} \cos (k\theta) \cos (\ell\theta) d\theta=0\), and with the change of variable \(x = \cos \theta\), we obtain $$\int_{-1}^1 \frac{T_k(x) T_\ell(x)}{\sqrt{1-x^2}} dx = 0.$$ Thus the Chebyshev polynomials inherit from many properties from such <a href="https://en.wikipedia.org/wiki/Orthogonal_polynomials">orthogonal polynomials</a> (such as the two-term recursion above, but for the Chebyshev polynomials, these can obtained more directly). For further properties, see [1].</p>



<h2>Extremal properties</h2>



<p class="justify-text">Chebyshev polynomials exhibit many “extremal properties”, of the form: among all polynomials of degree \(k\) with some form of normalization (e.g., fixed \(k\)-th order coefficient or value at given point), the one with smallest specific norm is proportional to \(T_k\).</p>



<p class="justify-text">The most classical one is as follows: the polynomial \(P\) of degree \(k\) with \(k\)-th order coefficient equal to one, and with minimum \(\ell_\infty\)-norm \(\max_{ x \in [-1,1]} \! | P(x)|\) on \([-1,1]\), is \(P = \frac{1}{2^{k-1}}T_k\). The proof is particularly elegant and simple (see <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">here</a>). Since this is not the property that we need for optimization, we will consider another one.</p>



<p class="justify-text"><strong>Proposition</strong> (<em>largest value outside of \([-1,1]\)</em>). For any polynomial \(P\) of degree \(k\) such that \(|P(x)| \leq 1\) for \(x \in [-1,1]\), and any \(z &gt; 1\), \(|P(z)| \leq T_k(z)\).</p>



<p class="justify-text"><em>Proof</em>. By contradiction, we assume that there exists \(z &gt; 1\) such that \(P(z)&gt;T_k(z)\) (the other possibility \(P(z) &lt; -T_k(z)\) is done by replacing \(P\) by \(-P\)). Without loss of generality, we can assume that \(\max_{x \in [-1,1]} |P(x) | &lt; 1\) (by potentially rescaling \(P\)). Then, the polynomial \(Q = P – T_k\) of degree \(k\) has alternatively strictly positive and negative values between \(-1\) and \(z&gt;1\). Indeed, \(Q(z) &gt; 0\), and \((-1)^j Q\big(\cos\! \big(\frac{j \pi}{k}\big)\big) &lt; 0 \) for all \(j = 0,\dots,k\). Therefore there are \(k+2\) alternating signs, and thus \(k+1\) zeros, which implies that \(Q=0\) since \(Q\) has degree \(k\). This is a contradiction with the existence of \(z\).</p>



<p class="justify-text">Note that for any \(\theta\), \(T_k( \cosh \theta) = \cosh (k\theta)\) (which can be shown by induction), and \(T_k\) is thus increasing on \([1,+\infty)\) with values quickly increasing as \(k\) grows. See an illustration below.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1589" height="221" src="https://francisbach.com/wp-content/uploads/2019/10/chebyshev_beyong_one-1.gif" width="303"/>First 33 Chebyshev polynomials, plotted between 1 and 4 in logarithmic scale. Note the exploding behavior as \(k\) grows.</figure></div>



<h2>Chebyshev acceleration</h2>



<p class="justify-text">We consider a recursion in \(\mathbb{R}^n\) of the form \(x_k = A x_{k-1} – b\), with \(A \in \mathbb{R}^{n \times n}\) a symmetric matrix and eigenvalues in \([-\rho,\rho]\) with \(\rho \in [0,1)\). Such recursions are ubiquitous in data science, as (1) gradient descent on a strongly-convex quadratic function, or (b) gossip for distributed averaging [<a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">2</a>] (see an example in a section below).</p>



<p class="justify-text">The recursion converges to the unique (because \(\rho \in [0,1)\)) fixed point \(x_\ast \in \mathbb{R}^n\) such that \(x_\ast =  A x_\ast – b\). We have, by unrolling the recursion: $$ x_k – x_\ast = A ( x_{k-1} – x_\ast) = A^k (x_0 – x_\ast).$$</p>



<p class="justify-text">This leads to the usual exponential convergence rate \(\| x_k – x_\ast\|_2 \leq \rho^k \| x_0 – x_\ast\|_2\). In the following, writing \(\rho = 1 – ( 1-\rho)\) makes explicit the importance of \(1-\rho\), which is the gap between \(1\) and the largest eigenvalue of \(A\). Increasing this gap is equivalent to accelerating the convergence rate.</p>



<p class="justify-text">In order to speed-up convergence, a classical idea is to take linear combinations of all past iterates. That is, we consider \(y_k = \sum_{i=0}^k \nu_i^k x_i\) for some weights \(\nu_i^k\) such that \(\sum_{i=0}^k \nu_i^k=1\) (so that if all iterates are already at \(x_\ast\), then the weighted average stays there). We have $$ y_k – x_\ast =  \sum_{i=0}^k \nu_i^k ( x_i – x_\ast) = \sum_{i=0}^k \nu_i^k A^i (x_0-x_\ast) = P_k(A) (x_0-x_\ast),$$ where \(P_k(X) = \sum_{i=0}^k \nu_i^k X^i\) is a polynomial such that \(P_k(1)=1\).  Therefore, we have: $$  \| y_k – x_\ast\|_2 \leq \max_{\lambda \in [-\rho, \rho]} |P_k(\lambda)| \cdot \|x_0 – x_\ast\|_2.$$</p>



<p class="justify-text">In order to select the best polynomial, we are looking for \(P_k\) such that \(P_k(1)=1\) and \(\max_{\lambda \in [-\rho,\rho]}\! |P_k(\lambda)|\) is as small as possible. Up to mapping \([-\rho,\rho]\) to \([-1,1]\), we know from the extremal property above that the optimal polynomial is exactly a rescaled Chebyshev polynomial, that is, $$P_k(X) = \frac{T_k(X/\rho)}{T_k(1/\rho)}.$$</p>



<p class="justify-text">The maximal value on \([-\rho,\rho]\) is then \((T_k(1/\rho))^{-1}\). In order to compare to \(\rho^k\) (no acceleration), we can provide an equivalent of \([T_k(1/\rho)]^{-1/k}\) as \(\frac{\rho}{ 1+ \sqrt{1-\rho^2}}\) (see end of the post). There is no real acceleration when \(\rho\) is bounded away from 1, but as \(\rho\) tends to \(1\), this can be shown (see also the end of the post) to be equivalent to \(1 – \sqrt{2(1\!-\!\rho)}\), with the usual “square root” acceleration: \(1\!-\!\rho\) is essentially replaced by \(\sqrt{1\!-\!\rho}\).</p>



<p class="justify-text">We thus get an acceleration, but as is, computing \(y_k\) seems to require to store all values of \(x_1,\dots,x_k\), which is not practical. Since there is a second-order recursion for Chebyshev polynomials, one can derive one as well, directly for the sequence \((y_k)\).  A somewhat lengthy calculation (see end of the post) leads to the recursion $$ y_{k+1} = \omega_{k+1} ( Ay_{k} – b) + (1-\omega_{k+1}) y_{k-1}, $$<br/>with a sequence \(\omega_{k+1}\) also defined by recursion as \(\omega_{k+1} = ( 1 – \frac{\rho^2}{4} \omega_k)^{-1}\), initialized with \(\omega_1 = 2\), \(y_0 = x_0\), \(y_1 = Ax_0 – b\). Therefore, on top of the usual computation of \(A y_k -b\), Chebyshev acceleration comes at no extra computational cost.</p>



<p class="justify-text"><strong>Simpler stationary recursion</strong>. In the recursion above, the parameter \(\omega_k\) varies with \(k\). A similar (then non totally optimal) acceleration can be obtained by replacing all \(\omega_k\)’s by their limit \(\omega\) when \(k\) tends to infinity, which is characterized by the equation \(\omega = ( 1-\frac{\rho^2}{4} \omega)^{-1}\) with smallest solutions \(\frac{ 1/\rho    – \sqrt{1/\rho^2 -1}}{\rho/2}\)  (see end of the post for detailed computations). The now stationary recursion then becomes $$ y_{k+1} = \omega ( Ay_{k} – b) + (1-\omega) y_{k-1}, $$ and is exponentially convergent with rate proportional to \(\rho \omega/2 =  \frac{1}{1/\rho + \sqrt{ 1/\rho^2 – 1}} = \frac{\rho}{1+ \sqrt{ 1 – \rho^2}}\). Thus, the recursion is simpler and the final speed asymptotically the same as full Chebyshev acceleration.</p>



<h2>Relationship with other acceleration mechanisms</h2>



<p class="justify-text"><strong>Non-adaptive schemes</strong>. As seen above for an affine operator \(F:\mathbb{R}^n \to \mathbb{R}^n\) (i.e., \(F(x) = Ax-b\)), Chebyshev acceleration takes a recursion of the form $$x_{k+1} = F(x_{k}),$$ and linearly combines iterates; it ends up creating second-order recursions of the form $$ y_{k+1} = \omega_{k+1} F(y_k) + (1-\omega_{k+1}) y_{k-1}, $$ with the same fixed points. Other formats (with fixed point preservation) can be considered such as $$ y_{k+1} = F(y_k) + \delta_{k+1}(y_k –  y_{k-1}),$$ or $$ y_{k+1} = F(y_k) + \delta_{k+1}(F(y_k) –  F(y_{k-1})), $$ for some constants \(\delta_{k+1}\).</p>



<p class="justify-text">When \(F\) is affine, the format does not matter much (and all end up being essentially equivalent), but for gradient descent algorithms where \(F(x) = x – \gamma f'(x)\) for some non-quadratic function \(f\) and \(\gamma\) a step-size, there is a difference, the last one corresponding to Nesterov acceleration (see a nice post on it <a href="https://blogs.princeton.edu/imabandit/2014/03/06/nesterovs-accelerated-gradient-descent-for-smooth-and-strongly-convex-optimization/">here</a>), and the one before to classical <a href="https://en.wikipedia.org/wiki/Gradient_descent">momentum</a>, also known as the heavy-ball method (see [<a href="https://arxiv.org/pdf/1412.7457">3</a>]).</p>



<p class="justify-text"><strong>Adaptive schemes</strong>. The methods above need to know the bound on the spectrum \(\rho\). They have to commit to such a value (which is typically only known through upper bounds) and cannot “get lucky”, that is, even if the best value \(\rho\) is known, they cannot benefit from additional better properties of the spectrum of \(A\) (e.g., clustered eigenvalues). The <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">conjugate gradient</a> method, which accesses the matrix \(A\) with the slightly stronger oracle of computing \(Ax\) any \(x\) (and not only \(Ax – b\)), or Anderson acceleration (which does not need a stronger oracle), are adaptive for similar problems [<a href="https://epubs.siam.org/doi/pdf/10.1137/10078356X">4</a>, <a href="https://arxiv.org/pdf/1606.04133">5</a>]. Again, Chebyshev polynomials are present; probably more on this in future posts!</p>



<h2>Application to accelerated gossip</h2>



<p class="justify-text">A interesting linear recursion pops out in distributed optimization, where we assume that computers or processors are placed in \(n\) nodes in a network, and the goal is to minimize an average of function \(f_1,\dots,f_n\), each of them only accessible by the corresponding node. The nodes are allowed to communicate messages along each edge of a network. </p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1367" height="221" src="https://francisbach.com/wp-content/uploads/2019/10/2dgrid.png" width="255"/>Two-dimensional grid with \(d = 8 \times 8 = 64\) nodes.</figure></div>



<p class="justify-text">The simplest of such problem is the network averaging problem where \(f_i(\theta) = \frac{1}{2} (\theta – \xi_i)^2\), for a uni-dimensional parameter \(\theta\) and \(\xi \in \mathbb{R}^n\). The solution of this consensus is \(\theta_\ast = \frac{1}{n} \! \sum_{i=1}^n \! \xi_i\).</p>



<p class="justify-text">The gossip algorithm [<a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">2</a>] consists in iteratively replacing the value \(\theta_i\) at a given node by a weighted average \(\sum_{j \sim i} W_{ij} \theta_j\) of the values at neighboring nodes (and node \(i\)). If all \(n\) nodes communicate simultaneously, then the vector \(\theta \) is replaced by \(W \theta\), hence a linear recursion $$ \theta_{k+1} = W \theta_{k},$$ initialized at \(\theta_0 = \xi\). Assuming that \(W\) is symmetric, with non-negative off-diagonal elements, and such that \(W 1_n = 1_n\) (where \(1_n \in \mathbb{R}^n\) is the vector of all ones), then all eigenvalues of \(W\) except the largest one are included in the interval \([-\rho, \rho]\), with \(\rho \in (0,1)\) for a connected graph. A simple such matrix \(W\) can be obtained from the adjacency matrix \(A\) of the graph, such that \(A_{ij} = 1\) if nodes \(i\) and \(j\) are connected, and zero otherwise, as \(W = I – \alpha L \), with \(L = {\rm Diag}(A 1_n) – A\) the <a href="https://en.wikipedia.org/wiki/Laplacian_matrix">Laplacian matrix</a> and \(\alpha\) selected so that the eigenvalues are all between \(-\rho\) and \(\rho\), except one, which is equal to 1 (see values of \(\rho\) and \(\alpha\) at the end of the post). We will see below that this extra eigenvalue which is equal to one is in fact not a problem for analyzing the convergence of this network averaging procedure.</p>



<p class="justify-text">When applying the gossip matrix \(W\) iteratively to \(\theta_0 = \xi\), the projection on the eigensubspace corresponding to the unit eigenvalue is not changed, while all other projections on the other eigensubspaces converge to zero at rate at most \(\rho^k\). Thus \(\theta_k\) converges to the constant vector \(\frac{1}{n} 1_n 1_n^\top \xi\) at rate \(\rho^k\), and thus to a constant vector, with the average \(\frac{1}{n} \! \sum_{i=1}^n \! \xi_i\) in all components.</p>



<p class="justify-text">Given that we have a linear recursion, we can use Chebyshev acceleration defined above and obtain substantial improvements, as illustrated below. For the use of this acceleration within distributed optimization algorithms, see [<a href="https://hal.archives-ouvertes.fr/hal-01478317/document">6</a>] and references therein.</p>



<figure class="wp-block-image is-resized"><img alt="" class="wp-image-1636" height="193" src="https://francisbach.com/wp-content/uploads/2019/10/gossip_threeplots-3.gif" width="696"/>Comparison of gossip algorithms on a two-dimensional grid (each cell correspond to a value \(\xi_i \in [-1,1]\) to average): (left) regular gossip, (center) accelerated second-order recursion with constant coefficients, (right) Chebyshev acceleration. Convergence is much faster with acceleration, (only) slightly better for Chebyshev acceleration, which is the optimal polynomial acceleration.</figure>



<h2>Conclusion</h2>



<p class="justify-text">Among classical classes of orthogonal polynomials, Chebyshev polynomials are special, because beyond being orthogonal, they satisfy extremal properties that are particularly useful in numerical analysis.</p>



<p class="justify-text">In future posts, I plan to go over Jacobi polynomials (which include Legendre, Gegenbauer and Chebyshev polynomials), Hermite polynomials, and finally Bernoulli polynomials (which are not orthogonal but still very special). For all of these, there are natural applications in machine learning.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Raphaël Berthier for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] John C. Mason, and David C. Handscomb. <a href="https://www.crcpress.com/Chebyshev-Polynomials/Mason-Handscomb/p/book/9780849303555">Chebyshev polynomials. Chapman and Hall/CRC</a>, 2002.<br/>[2] Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, Devavrat Shah. <a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">Randomized gossip algorithms</a>. <em>IEEE/ACM Transactions on Networking</em>, 14:2508-2530, 2006.<br/>[3] Euhanna Ghadimi, Hamid Reza Feyzmahdavian, and Mikael Johansson. <a href="https://arxiv.org/pdf/1412.7457">Global convergence of the heavy-ball method for convex optimization</a>. <em>European Control Conference (ECC)</em>, 2015.<br/>[4] Homer F. Walker, Peng Ni. <a href="https://epubs.siam.org/doi/pdf/10.1137/10078356X">Anderson acceleration for fixed-point iterations</a>. <em>SIAM Journal on Numerical Analysis</em>, 49(4):1715-1735, 2011.<br/>[5] Damien Scieur, Alexandre d’Aspremont, Francis Bach. <a href="https://arxiv.org/pdf/1606.04133">Regularized Nonlinear Acceleration</a>. <em>Mathematical Programming</em>, 2018.<br/>[6] Kevin Scaman, Francis Bach, Sébastien Bubeck, Yin-Tat Lee, Laurent Massoulié. <a href="https://hal.archives-ouvertes.fr/hal-01478317/document">Optimal algorithms for smooth and strongly convex distributed optimization in networks</a>.  <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2017.<br/>[7] Mieczysław A. Kłopotek. <a href="https://arxiv.org/pdf/1707.05210">Spectral Analysis of Laplacians of an Unweighted and Weighted Multidimensional Grid Graph — Combinatorial versus Normalized and Random Walk Laplacians</a>. Technical report, ArXiv:1707.05210, 2019.</p>



<h2>Detailed Computations</h2>



<p class="justify-text"><strong>Limit of </strong>\([T_k(1/\rho)]^{-1/k}\). For \(z \geq 1\), then a well-known property of Chebyshev polynomials is that \(T_k(z) = \cosh [ k \, {\rm acosh} (z)]\) (which can be shown by induction using basic <a href="https://en.wikipedia.org/wiki/Hyperbolic_function">hyperbolic trigonometry</a> identities). Moreover, we have \({\rm acosh} (z) = \log( z + \sqrt{z^2-1} )\) and thus $$T_k(z) = \frac{1}{2} \big[ \big( z + \sqrt{z^2-1} \big)^k + \big(z – \sqrt{z^2-1}\big)^k  \big].$$ For \(z = 1/\rho\), and taking limits, we get that \([T_k(z)]^{1/k}\) tends to \( z + \sqrt{z^2-1}\), which leads to the limit \(\frac{\rho}{ 1+ \sqrt{1-\rho^2}}\) for \([T_k(z)]^{-1/k}\). Then a classical Taylor expansion in \(1-\rho\) leads to \(1 – \sqrt{2(1-\rho)}\).</p>



<p class="justify-text"><strong>Recurrence for Chebyshev acceleration</strong>. We have, using the recursion for Chebyshev polynomials $$y_{k+1} – x_\ast = \frac{ 2 }{T_{k+1}(1/\rho)} (A/\rho) T_k(A/\rho) ( x_0 – x_\ast) \ – \frac{ 1  }{T_{k+1}(1/\rho)} T_{k-1}(A/\rho) ( x_0 – x_\ast).$$ Using the equality \(x_\ast = A x_\ast -b\), the terms in \(x_\ast\) cancel (they have to anyway, because \(P_k(1)=1\)). We then get $$y_{k+1}  = \frac{  (2/\rho) T_{k}(1/\rho)}{T_{k+1}(1/\rho)}  ( A y_k – b) \, – \frac{ T_{k-1}(1/\rho)  }{T_{k+1}(1/\rho)} y_{k-1}.$$</p>



<p>Using \(T_{k-1}(1/\rho) = (2/\rho) T_{k}(1/\rho) – T_{k+1}(1/\rho)\), and denoting \(\omega_{k+1} =  \frac{  (2/\rho) T_{k}(1/\rho)}{T_{k+1}(1/\rho)}\), we get $$y_{k+1} = \omega_{k+1} ( A y_{k} – b) + ( 1- \omega_{k+1}) y_{k-1}.$$ Reusing one last time the Chebyshev recursion, we get $$\omega_{k+1}^{-1} = \frac{T_{k+1}(1/\rho)}{  (2/\rho) T_{k}(1/\rho)}= 1 – \frac{T_{k-1}(1/\rho)}{  (2/\rho) T_{k}(1/\rho)} =1  – \frac{\rho^2}{4} \omega_{k},$$ which is the desired recursion.</p>



<p class="justify-text"><strong>Convergence of stationary recursion</strong>. The roots of \(\omega = ( 1-\frac{\rho^2}{4} \omega)^{-1}\) are the ones of \(\frac{\rho^2}{4} \omega^2 – \omega + 1 = 0\), with smallest solutions \(\omega = \frac{ 1/\rho   – \sqrt{1/\rho^2 -1}}{\rho/2}\). In order to study the second-order recursion $$ y_{k+1} = \omega ( Ay_{k} – b) + (1-\omega) y_{k-1}, $$ with constant coefficient, we need to compute the roots of \(r^2 = \omega \lambda r + (1-\omega)\), for \(|\lambda| \leq \rho\). The discriminant of this equation is \(\lambda^2 \omega^2 + 4 (1-\omega) \leq \rho^2 \omega^2 + 4(1-\omega) = 0\), and thus the roots are complex conjugate with squared modulus \((\omega\ – 1) = \frac{1}{4} \rho^2 \omega^2\) independent of \(\lambda\). Thus, as \(k\) tends to infinity, \(\| y_k  – x_\ast\|_2^{1/k}\) tends to \(\frac{1}{2} \rho \omega =   ( 1/\rho – \sqrt{ 1/\rho^2 – 1} ) = \frac{1}{1/\rho + \sqrt{ 1/\rho^2 – 1}}\), which is exactly the rate for Chebyshev acceleration.</p>



<p class="justify-text"><strong>Eigenvalues of the Laplacian matrix of a square grid</strong>. Given a chain of length \(m\) such as depicted below, the \(m \times m\) Laplacian matrix can be shown (see [<a href="https://arxiv.org/pdf/1707.05210">7</a>]) to have eigenvalues \(2 + 2 \cos \frac{k\pi}{m}\) for \(k =1,\dots,m\).</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img alt="" class="wp-image-1562" height="24" src="https://francisbach.com/wp-content/uploads/2019/10/1dgrid.png" width="350"/>One-dimensional grid with \(m = 8\).</figure></div>



<p class="justify-text">For a two-dimensional grid of size \(m \times m\), then the \(m^2 \times m^2\) Laplacian matrix can be shown (see [<a href="https://arxiv.org/pdf/1707.05210">7</a>]) to have eigenvalues \(4 + 2\cos \frac{k_1\pi}{m} + 2\cos \frac{k_2\pi}{m}\) for \(k_1,k_2 =1,\dots,m\). Therefore, the second smallest eigenvalue is \(\lambda_\min = 2 – 2 \cos \frac{\pi}{m}\) and the largest eigenvalue is \(\lambda_\max = 4 + 4  \cos \frac{\pi}{m}\). We then select \(\alpha\) such that \(1-\alpha \lambda_\min = \rho\) and \(1-\alpha \lambda_\max = -\rho\), leading to \(\alpha = \frac{2}{\lambda_\min + \lambda_\max} = \frac{2}{6 + 2 \cos \frac{\pi}{m}}\) and finally \(\rho = \frac{\lambda_\max – \lambda_\min}{\lambda_\max + \lambda_\min} = \frac{2 +6  \cos \frac{\pi}{m} }{6 + 2 \cos \frac{\pi}{m}}\sim \frac{8 – 3 \frac{\pi^2}{m^2}}{8 –  \frac{\pi^2}{m^2}}\sim 1 – \frac{\pi^2}{4 m^2}\). Thus, as a function of \(n = m^2\), the eigengap is proportional to \(1/n\).</p>



<p class="justify-text">More generally, for the grid of size \(m\) in dimension \(d\), then we get \(\lambda_\min = 2 – 2 \cos \frac{\pi}{m}\) and \(\lambda_\max = 2d + 2d  \cos \frac{\pi}{m}\), and \(\rho = \frac{\lambda_\max – \lambda_\min}{\lambda_\max + \lambda_\min} = \frac{2d-2 +(2d+2)  \cos \frac{\pi}{m} }{2d+2 + (2d-2) \cos \frac{\pi}{m}}\sim \frac{4d – (d+1) \frac{\pi^2}{m^2}}{4d –  (d-1)\frac{\pi^2}{m^2}}\sim 1 – \frac{\pi^2}{2d m^2}.\) Thus, as a function of \(n = m^d\), the eigengap is proportional to \(1/n^{2/d}\). Moreover, when \(m\) is large, the normalizing factor \(\alpha\) tends to \(1/(2d)\).</p></div>
    </content>
    <updated>2019-11-04T07:04:11Z</updated>
    <published>2019-11-04T07:04:11Z</published>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-03-07T22:21:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=231</id>
    <link href="https://minimizingregret.wordpress.com/2019/10/31/new-methods-in-control-the-gradient-perturbation-controller/" rel="alternate" type="text/html"/>
    <link href="https://videos.files.wordpress.com/3UT37VGe/cdhbdot0d1kix22v_hd.mp4" length="33976320" rel="enclosure" type="video/mp4"/>
    <title>New Methods in Control: The Gradient Perturbation Controller</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Naman Agarwal, Karan Singh and Elad Hazan, based on this paper and this paper.  The mainstream thought in classical control operates under the simplifying principle that nature evolves according to well-specified dynamics perturbed by i.i.d. Gaussian noise, a field called Optimal Control. While this principle has proven very successful in some real world systems, it … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/10/31/new-methods-in-control-the-gradient-perturbation-controller/">Continue reading <span class="screen-reader-text">New Methods in Control: The Gradient Perturbation Controller</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by Naman Agarwal, Karan Singh and Elad Hazan, based on <a href="https://arxiv.org/abs/1902.08721">this paper</a> and <a href="https://arxiv.org/abs/1909.05062">this paper</a>. </em></p>
<p>The mainstream thought in classical control operates under the simplifying principle that nature evolves according to well-specified dynamics perturbed by i.i.d. Gaussian noise, a field called <b>Optimal Control</b>. While this principle has proven very successful in some real world systems, it does not lend itself to the construction of truly <b>robust</b> controllers. In the real world one can expect all sorts of deviations from this setting, including:</p>
<ul>
<li>Inherent correlations between perturbations across time due to the environment.</li>
<li>Modeling misspecification, which can introduce unforeseeable, non-stochastic deviations from the assumed dynamics.</li>
<li>Completely adversarial perturbations introduced by a malicious entity.</li>
</ul>
<p>Indeed, in the world of classical supervised learning, the presence of the above factors has led to the adoption of <a href="https://ocobook.cs.princeton.edu/">online learning</a> in lieu of statistical learning, which allows for robust noise models and game-theoretic / strategic learning. A natural question arises: <i>what is the analogue of online learning and worst-case regret in robust control? </i></p>
<h2>Linear Dynamical Systems and Optimal Control</h2>
<p>Dynamical systems constitute the formalism to describe time-dependent, dynamic real-world phenomenon, ranging from fluid flow through a pipe, the movement of a pendulum, to the change of weather. The archetypal example here is a linear dynamical system, which permits a particularly intuitive interpretation as a (configurable) vector field (from <a href="https://en.wikipedia.org/wiki/Dynamical_system">wikipedia</a>):</p>
<p><img alt="" height="158" src="https://minimizingregret.files.wordpress.com/2019/10/null.png?w=624&amp;h=158" title="" width="624"/></p>
<p>A linear dynamical system (LDS) posits the state of a system evolves via the following dynamical relation:</p>
<p style="text-align: center;"><img alt="x_{t+1} = Ax_t + Bu_t + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+Ax_t+%2B+Bu_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t+1} = Ax_t + Bu_t + w_t"/></p>
<div class="video-player" id="v-3UT37VGe-1" style="width: 1100px; height: 620px;">
</div>
<p>(video by @<a href="https://twitter.com/robertghrist/status/1185864562299539456">robertghrist</a>)</p>
<p>Here <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t"/> represents the state of the system, <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> represents a control input and <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> is a perturbation introduced to the dynamics, for the time step t. The vector fields above illustrate the behavior of the system for a few different choices of A, when the control input <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> is set to zero. The control inputs, when correctly chosen, can modify the dynamics to induce a particular desired behavior. For example, controlling the thermostat in a data center to achieve a particular temperature, applying a force to a pendulum to keep it upright, or driving a drone to a destination.</p>
<p>The goal of the controller is to produce a sequence of control actions <img alt="u_1 \ldots u_T" class="latex" src="https://s0.wp.com/latex.php?latex=u_1+%5Cldots+u_T&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_1 \ldots u_T"/> aimed at minimizing the cumulative loss <img alt="\sum_t c_t(x_t, u_t)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_t+c_t%28x_t%2C+u_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sum_t c_t(x_t, u_t)"/>. In classical control the loss functions are convex quadratics and known ahead of time. However, in the quest for more robust controllers, henceforth we will consider a broader class of general (possibly non-quadratic) convex cost functions, which may be adversarially chosen, and only be revealed online per-time-step to the controller.</p>
<h2>Previous notions: LQR and H-infinity control</h2>
<p>Perhaps the most fundamental setting in control theory is a LDS is with quadratic costs <img alt="c_t" class="latex" src="https://s0.wp.com/latex.php?latex=c_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t"/> and i.i.d Gaussian perturbations <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>. The solution known as the <a href="https://en.wikipedia.org/wiki/Linear&#x2013;quadratic_regulator">Linear Quadratic Regulator</a>, derived by solving the Riccati equation, is well understood and corresponds to a linear policy (i.e. the control input is a linear function of the state).</p>
<p>The assumption of i.i.d perturbations has been relaxed in classical control theory, with the introduction of a min-max notion, in a subfield known as <a href="https://stephentu.github.io/blog/h-infinity-control/2018/07/01/hinf-optimal-control-dynamic-games.html"><img alt="H_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H_{\infty}"/> control</a>. Informally, the idea behind <img alt="H_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H_{\infty}"/> control is to design a controller which performs well against <i>all </i>sequences of bounded perturbations. There are two shortcomings of this approach; firstly computing such a controller can be a difficult optimization problem in itself. While a closed form for such a controller is known for linear dynamical systems with quadratic costs, no such form is known when costs can be non-quadratic. Secondly and perhaps more importantly, the min-max notion is non-adaptive and hence often too pessimistic. It is possible that during the execution of the system, nature produces a <i>benign (predictable)</i> sequence of perturbations (say, for instance, the perturbations are, in truth, highly correlated). The <img alt="H_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H_{\infty}"/> controller in this setting could be overly pessimistic and lead to a higher cost than what could be achieved via a potentially more adaptive controller. This motivates our approach of minimizing regret, which we describe next.</p>
<h2>A less pessimistic metric: Policy regret</h2>
<p>Our starting point for more robust control is regret minimization in games. Regret minimization is a well-accepted metric in online learning, and we consider applying it to online control.</p>
<p>Formally, we measure the efficacy of a controller through the following notion of <i>policy </i>regret.</p>
<p style="text-align: center;"><img alt="\mathrm{Regret} = \sum_{t} c_t(x_t, u_t) - \min_{\mathrm{stable } K} c_t(x_t(K), -Kx_t)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BRegret%7D+%3D+%5Csum_%7Bt%7D+c_t%28x_t%2C+u_t%29+-+%5Cmin_%7B%5Cmathrm%7Bstable+%7D+K%7D+c_t%28x_t%28K%29%2C+-Kx_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\mathrm{Regret} = \sum_{t} c_t(x_t, u_t) - \min_{\mathrm{stable } K} c_t(x_t(K), -Kx_t)"/></p>
<p>Here in, <img alt="x_t(K)" class="latex" src="https://s0.wp.com/latex.php?latex=x_t%28K%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t(K)"/> represents the state encountered when executing the linear policy $K$. In particular, the second term represents the total cost paid by the best(in hindsight) stable linear policy had it executed in the system facing the same sequence of perturbations as the controller. In this regard the above notion of regret is <b>counterfactual</b> and hence more challenging than the more common stateless notion of regret.<br/>
(Remark: a <span style="font-weight: 400;">stable linear policy K is one which ensures that the spectral radius of  A-BK is strictly less than one. For a formal quantitative definition, please see the </span><a href="https://arxiv.org/abs/1902.08721"><span style="font-weight: 400;">paper</span></a><span style="font-weight: 400;">.)</span></p>
<p>Furthermore, the choice of comparing to a linear policy is made keeping tractability in mind. Note that this nevertheless generalizes the standard Linear Quadratic Regulator and <img alt="H_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=H_%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="H_{\infty}"/> control on Linear Dynamical Systems, as the optimal choice of controllers in those settings is indeed a linear policy (if the cost functions are quadratic, our setting allows more general loss functions).</p>
<p>Algorithms which achieve low regret on the above objective are naturally adaptive as they perform as well as the best controller (upto a negligible additive regret) oblivious to whether the sequence is <i>friendly </i>or <i>adversarial. </i></p>
<h2>A new type of controller</h2>
<p>In successive recent works (<a href="https://arxiv.org/abs/1902.08721">[1] </a>and <a href="https://arxiv.org/abs/1909.05062">[2]</a>), we show that the above notion of policy regret is tractable and can be sublinear (even logarithmic under certain conditions). Using a new parameterization for controller that we detail next, we obtain the following results:</p>
<ul>
<li><b>Robustness to Adversarial Perturbations (<a href="https://arxiv.org/abs/1902.08721">[1]</a>) – </b>For arbitrary, but bounded, perturbations $w_t$, which may even be chosen adversarially, we provide an efficient algorithm that achieves regret of <b><img alt="O(\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{T})"/></b>.</li>
<li><b>Fast Rates under Stochastic Perturbations (</b>[2]<b>) – </b>Further, for strongly convex costs, and i.i.d. perturbations, we give an efficient algorithm with a poly-logarithmic (in T) regret guarantee.</li>
</ul>
<p>The former result is the first such result to establish vanishing average regret in an online setting for control with adversarial perturbations. The latter result offers a significant improvement over the work of <a href="https://arxiv.org/abs/1806.07104">Cohen et al. </a>who established a rate of <img alt="O(\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{T})"/> in a similar (stochastic) setting.</p>
<p>We assume that the dynamical system i.e. (A,B) is completely known to us and the state is fully observable. These assumptions have been eliminated in further work with our collaborators, and will be a subject of a future blog post. We now describe the core ideas which go into achieving both our results.</p>
<h2>The Gradient Perturbation Controller</h2>
<p>Consider how the choice of the linear controller determines the control input.</p>
<p><img alt="" height="120" src="https://minimizingregret.files.wordpress.com/2019/10/null-1.png?w=624&amp;h=120" title="" width="624"/></p>
<p>The above display demonstrates that the action, state, and hence the cost are <b>non-convex</b> functions of the linear controller K. The first piece of our result evades this lack of convexity by over-parametrization, ie. relaxing the notion of a linear policy as described next.</p>
<p>In place of learning a direct representation of a linear controller K, we learn a sequence of matrices <img alt="M_1, M_2 \ldots " class="latex" src="https://s0.wp.com/latex.php?latex=M_1%2C+M_2+%5Cldots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="M_1, M_2 \ldots "/> which represent the dependence of <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> on <img alt="w_{t - i}" class="latex" src="https://s0.wp.com/latex.php?latex=w_%7Bt+-+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_{t - i}"/> under the execution of some linear policy. Schematically, we parameterize our policy as follows</p>
<p><img alt="" height="62" src="https://minimizingregret.files.wordpress.com/2019/10/null-2.png?w=624&amp;h=62" title="" width="624"/></p>
<p>Note that, the assumption that the dynamics is known permits the exact inference of <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>’s and thereby making the execution of such a controller possible. While the choice of the controller ensures that control inputs are linear in <img alt="\{M_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BM_i%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{M_i\}"/>, the superposition principle for linear dynamical systems ensures that the state sequence too is linear in the same variables. Therefore, the cost of execution of such a controller parameterized via <img alt="\{M_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BM_i%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{M_i\}"/> is convex and we can hope to learn them using standard techniques like Gradient Descent. Observe that, by construction, it is possible to emulate the behavior any linear controller K by a suitable choice of <img alt="\{M_i\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BM_i%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{M_i\}"/>’s.</p>
<p>There are two barriers though. First, the number of parameters grows with time $T$ and so can regret and running time. Secondly, since there is a state, the decision a controller makes at a particular instance affects the future. We deal with these two problems formally in the paper and show how they may be circumvented. One of the important techniques we use is <a href="https://arxiv.org/abs/1302.6937">Online Convex Optimization with Memory</a>.</p>
<p>With all the core components in place, we provide a brief specification of our algorithm. Let’s fix some memory length H, and a time step t. Define a proxy cost as</p>
<table>
<tbody>
<tr>
<td>
<p style="text-align: center;"><img alt="c_t(M_1, \ldots M_H)" class="latex" src="https://s0.wp.com/latex.php?latex=c_t%28M_1%2C+%5Cldots+M_H%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t(M_1, \ldots M_H)"/> =</p>
</td>
<td>Cost Paid at Time t, had we execute the policy <img alt="\{M_1, \ldots M_H\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7BM_1%2C+%5Cldots+M_H%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{M_1, \ldots M_H\}"/> for t-H steps, with the system reset to 0</td>
</tr>
</tbody>
</table>
<p>The algorithm now as suggested by <a href="https://arxiv.org/abs/1302.6937">Anava, Hazan and Manor</a>, is to take a gradient step on the above proxy.</p>
<p><img alt="" height="29" src="https://minimizingregret.files.wordpress.com/2019/10/null-3.png?w=624&amp;h=29" title="" width="624"/></p>
<p>The above algorithm achieves <img alt="O(\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{T})"/> regret against <b>worst-case</b> noise. For the full proof and the precise derivation of the algorithm, check out the paper.</p>
<h2>Achieving Logarithmic Regret</h2>
<p>Algorithms for (state-less) online learning often enjoy logarithmic regret guarantees in the presence of strongly convex loss functions. Prima facie, one could hope that for dynamical systems with strongly convex costs, such a stronger regret guarantee would hold. The cautionary note here is that <b>strong convexity of the cost <img alt="c_t(x_t, u_t)" class="latex" src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2C+u_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t(x_t, u_t)"/> in the control input does not imply strong convexity in the controller representation</b>.,</p>
<p>In fact, the strong convexity of our proxy cost function <img alt="c(M_1, \ldots M_H)" class="latex" src="https://s0.wp.com/latex.php?latex=c%28M_1%2C+%5Cldots+M_H%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c(M_1, \ldots M_H)"/> in its natural parameterization over M’s is further hindered by the fact that the space of M’s constitutes a highly over-parametrized representation (say, vs. K). Indeed in the case of adversarial perturbations, it is easy to construct a case where the strong convexity does not transfer over from the control to the controller.</p>
<p>In a future blog post we detail how this technical difficulty can be overcome using the natural gradient method, giving rise to a logarithmic regret algorithm for control.</p>
<h2>Experimental Validation</h2>
<p>Below we provide empirical evaluations of the GPC controller in various scenarios, demonstrating it is indeed more robust to correlated noise than previous notions. <b>(All the plots below are produced by a new research-first control and time series library in the works — Alpha version scheduled to be released soon! STAY TUNED!!!) </b></p>
<p>To start, let’s reproduce the classical setting of controlling an LDS with i.i.d. Gaussian noise. Here, the LQR program is <i>optimal</i>. Yet, the plot below attests that our new control methodology offers a slightly suboptimal, yet comparable, performance. This observation also underlines the message the the proposed controller tracks the optimal controller without any foreknowledge of the structure of the perturbations. Here, for example, GPC is not made aware of the i.i.d. nature of the perturbations.</p>
<p><img alt="" height="205" src="https://minimizingregret.files.wordpress.com/2019/10/null-4.png?w=624&amp;h=205" title="" width="624"/></p>
<p>Moving on to correlated perturbations across time, a simple such setting is when the perturbations are drawn from a Gaussian Random Walk (as opposed to independent Gaussians). Note that here it is possible to derive the <i>optimal </i>controller via the separation principle. Here is the performance plot:</p>
<h1><img alt="" height="205" src="https://minimizingregret.files.wordpress.com/2019/10/null-5.png?w=624&amp;h=205" title="" width="624"/></h1>
<p>Note that the default LQR controller performs much worse, where as GPC is able to track the performance of the optimal controller quite closely. Next up, <b>sinusoidal noise</b>:</p>
<p><img alt="" height="205" src="https://minimizingregret.files.wordpress.com/2019/10/null-6.png?w=624&amp;h=205" title="" width="624"/></p>
<p>Here the full power of regret minimization is exhibited as the consecutive samples of the sine function are very correlated, yet predictable. GPC vastly outperforms LQR as one would expect. But, is this fundamentally a hard setting? What would happen if we use the H-infinity controller, or, god forbid, no control at all? We see this in the next plot (on the log-linear scale):</p>
<p><img alt="" height="202" src="https://minimizingregret.files.wordpress.com/2019/10/null-7.png?w=624&amp;h=202" title="" width="624"/></p>
<h1>What’s next?</h1>
<p>We have surveyed a new family of controls that are fundamentally different than classical optimal control: they are adaptive and attain regret guarantees vs. adversarial noise. Their preliminary experimental tests seem quite promising.</p>
<p>In the coming posts we will:</p>
<ol>
<li>Explain how GPC can obtain the first logarithmic regret in the tracking/Kalman setting,</li>
<li>Reveal our new research-first library for control / time-series prediction,</li>
<li>Tackle more general settings.</li>
</ol>
<h1>Stay tuned! Preferably using the GPC… <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></h1>
<p> </p>
<div><a href="https://minimizingregret.wordpress.com/2019/10/31/new-methods-in-control-the-gradient-perturbation-controller/"><img alt="cDhBDoT0d1KIX22V" height="120" src="https://videos.files.wordpress.com/3UT37VGe/cdhbdot0d1kix22v_std.original.jpg" width="160"/></a></div></div>
    </content>
    <updated>2019-10-31T21:10:48Z</updated>
    <published>2019-10-31T21:10:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2020-03-07T22:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=375</id>
    <link href="https://tcsplus.wordpress.com/2019/10/31/tcs-talk-wednesday-november-6-ryan-odonnell-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, November 6 — Ryan O’Donnell, CMU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, November 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Ryan O’Donnell from CMU will speak about “Explicit near-Ramanujan graphs of every degree” (abstract below). Please make sure you reserve a spot for your group to join us […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, November 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Ryan O’Donnell</strong> from CMU will speak about “<em>Explicit near-Ramanujan graphs of every degree</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: For every constant <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> and <img alt="\varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" title="\varepsilon"/>, we give a deterministic <img alt="\text{poly}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bpoly%7D%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\text{poly}(n)"/>-time algorithm that outputs a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/>-regular graph on <img alt="\approx n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Capprox+n&amp;bg=fff&amp;fg=444444&amp;s=0" title="\approx n"/> vertices that is <img alt="\varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" title="\varepsilon"/>-near-Ramanujan; i.e., its eigenvalues are bounded in magnitude by <img alt="2\sqrt(d-1) + \varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Csqrt%28d-1%29+%2B+%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" title="2\sqrt(d-1) + \varepsilon"/> (excluding the single trivial eigenvalue of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/>).</p>
<p>Joint work with Sidhanth Mohanty (Berkeley) and Pedro Paredes (CMU).</p></blockquote></div>
    </content>
    <updated>2019-10-31T04:48:39Z</updated>
    <published>2019-10-31T04:48:39Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-03-07T22:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1520</id>
    <link href="https://theorydish.blog/2019/10/30/toc-for-society/" rel="alternate" type="text/html"/>
    <title>TOC for Society</title>
    <summary>I am delighted that the Symposium on Foundations of Responsible Computing (FORC) is on its way. This is a new forum that will host mathematical research in computation and society, under an inclusive umbrella. A major purpose is to give a home and to nurture the growing community within the Theory of Computing and neighboring fields whose research is focused on the societal impact of computing. This vision is shared by many in this area, and I am very proud of the remarkable list of steering committee members that have volunteered to create and promote the new conference. The call for papers for FORC 2020 is out. The PC chair, Aaron Roth, has done a remarkable job forming a strong program committee, and we are off to a great start. Please consider sending your research papers and looking forward to seeing many of you at FORC 2020 in the beginning of June at Harvard.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am delighted that <a href="https://responsiblecomputing.org/">the Symposium on Foundations of Responsible Computing (FORC)</a> is on its way. This is a new forum that will host mathematical research in computation and society, under an inclusive umbrella. A major purpose is to give a home and to nurture the growing community within the Theory of Computing and neighboring fields whose research is focused on the societal impact of computing. This vision is shared by many in this area, and I am very proud of the remarkable list of steering committee members that have volunteered to create and promote the new conference.</p>
<p>The <a href="https://responsiblecomputing.org/forc-2020-call-for-paper/">call for papers for FORC 2020</a> is out. The PC chair, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, has done a remarkable job forming a strong program committee, and we are off to a great start. Please consider sending your research papers and looking forward to seeing many of you at FORC 2020 in the beginning of June at Harvard.</p></div>
    </content>
    <updated>2019-10-30T15:54:11Z</updated>
    <published>2019-10-30T15:54:11Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-03-07T22:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5464</id>
    <link href="https://adamsheffer.wordpress.com/2019/10/29/incidences-open-problems-part-2/" rel="alternate" type="text/html"/>
    <title>Incidences: Open Problems (part 2)</title>
    <summary>We now continue our journey of seeing how we still don’t know much about geometric incidences. So far, we looked at two main problems concerning incidences with curves in the plane (see the first post of the series). It might make sense to move to study incidences in higher dimensions. Instead, we are now regressing […]</summary>
    <updated>2019-10-29T18:59:15Z</updated>
    <published>2019-10-29T18:59:15Z</published>
    <category term="Incidences"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2020-03-07T22:21:09Z</updated>
    </source>
  </entry>
</feed>
